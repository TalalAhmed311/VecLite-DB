{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/talal/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from vector_store import VectorStore\n",
    "from tokenizer import Tokenizer\n",
    "from vector_store_schema import VectorParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "vector_store = VectorStore(vector_dim=384,random_proj=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"AAAMLP-569to.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "\n",
    "for page in pages:\n",
    "    vectors.append(tokenizer.create_embedding(page.page_content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_data = []\n",
    "\n",
    "for vector, page in zip(vectors,pages):\n",
    "\n",
    "    vector_data.append(\n",
    "        VectorParams(vector=vector,content=page.page_content,metadata=page.metadata)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[VectorParams(vector=[-0.25878873467445374, -0.003135575680062175, 0.20973438024520874, 0.028174463659524918, 0.2909056544303894, 0.022575490176677704, -0.039057210087776184, -0.16268803179264069, -0.40784916281700134, -0.03540945425629616, -0.18837261199951172, -0.16380876302719116, 0.1935744285583496, -0.31987428665161133, -0.10330004245042801, 0.2691631019115448, 0.029457924887537956, -0.032762620598077774, -0.10579734295606613, -0.25105658173561096, -0.29796475172042847, 0.21266093850135803, -0.09310808777809143, 0.2853040397167206, -0.3027900457382202, -0.2379039227962494, 0.5628688335418701, 0.14174263179302216, 0.006221632938832045, -0.018326641991734505, 0.04987439885735512, -0.05522925406694412, -0.15563629567623138, 0.05948333442211151, -0.11241528391838074, 0.3035445213317871, -0.2581915855407715, 0.1962946355342865, 0.04885981231927872, 0.12421692162752151, 0.263354629278183, -0.05126660689711571, -0.1264577955007553, 0.025036873295903206, 0.2990105450153351, 0.07885703444480896, -0.17686675488948822, -0.3015671372413635, -0.07855546474456787, -0.020549140870571136, -0.6613457798957825, -0.15864764153957367, -0.22281786799430847, 0.055759090930223465, -0.2589171230792999, -0.44949084520339966, -0.23510342836380005, -0.010557536035776138, 0.12578922510147095, -0.19772771000862122, -0.04998914897441864, -0.5158227682113647, -0.08282240480184555, -0.053460367023944855, 0.2628369629383087, 0.03513756021857262, 0.13323698937892914, 0.05311015993356705, -0.04635393247008324, 0.2992551624774933, 0.1059480756521225, 0.42997628450393677, -0.3848254084587097, 0.441001832485199, 0.2256982922554016, -0.15229631960391998, 0.21663959324359894, 0.23479098081588745, 0.37879034876823425, 0.045845888555049896, -0.18007414042949677, -0.2254951000213623, 0.12549906969070435, 0.19075892865657806, 0.15675896406173706, -0.22441379725933075, -0.3536636531352997, -0.04844633862376213, 0.14566127955913544, -0.3521282970905304, -0.003645635675638914, -0.2692705988883972, 0.18158215284347534, -0.1710665225982666, -0.03948008641600609, 0.23017223179340363, 0.11190658062696457, -0.1935769021511078, -0.06716474890708923, 0.3529963493347168, -0.4556584656238556, 0.3500387966632843, 0.1831425130367279, -0.03688446432352066, 0.09659604728221893, 0.0916539803147316, 0.1479942500591278, -0.27286556363105774, 0.38007310032844543, -0.6435282826423645, 0.06551983952522278, -0.3086989223957062, 0.09839320927858353, 0.030291570350527763, -0.09833627194166183, -0.23217251896858215, -0.10804939270019531, -0.012232337146997452, -0.2905917465686798, 0.4072780907154083, -0.1621829867362976, -0.09394347667694092, -0.04214564338326454, 0.33765214681625366, 0.034899868071079254, -0.06299591064453125, -0.3015657067298889, 8.726359455146024e-33, -0.1899036318063736, -0.07898246496915817, 0.13646355271339417, -0.46155786514282227, 0.06700729578733444, -0.33415406942367554, 0.01781020499765873, -0.15417541563510895, 0.05515260994434357, 0.08163227140903473, 0.05380750074982643, 0.11095324158668518, -0.03215983882546425, 0.1546410769224167, 0.144492045044899, -0.13672874867916107, 0.18040195107460022, -0.0021522492170333862, -0.056455112993717194, -0.4700869023799896, 0.3482811748981476, -0.1441914141178131, -0.03974661976099014, -0.1755048632621765, -0.03690188005566597, -0.07182574272155762, 0.353193074464798, -0.14358094334602356, 0.14156967401504517, 0.19165641069412231, -0.17306460440158844, 0.19079573452472687, -0.2993028461933136, 0.2300325334072113, 0.14270608127117157, -0.1718727946281433, 0.0006527350633405149, 0.14495554566383362, -0.02668680064380169, -0.1791830062866211, -0.16138124465942383, 0.08060412853956223, 0.22123859822750092, -0.37626913189888, -0.04574853554368019, 0.04545733705163002, 0.14865697920322418, -0.029518309980630875, -0.07669767737388611, 0.012144487351179123, -0.14062891900539398, -0.19895696640014648, -0.2247210294008255, -0.16657297313213348, 0.07413413375616074, 0.007399636786431074, -0.06360039114952087, -0.02989664487540722, 0.15586310625076294, 0.35343319177627563, 0.27058592438697815, -0.2951238453388214, 0.0699005126953125, 0.023457618430256844, -0.2313254475593567, -0.005035310983657837, 0.12871494889259338, -0.17781785130500793, 0.3127562403678894, 0.025233447551727295, 0.2360583245754242, 0.07520640641450882, -0.04628060758113861, -0.2428112030029297, 0.20673707127571106, -0.018488842993974686, 0.27832329273223877, 0.016997328028082848, 0.008609001524746418, 0.11682789772748947, -0.2988884747028351, 0.27456071972846985, -0.0724756047129631, -0.40421584248542786, -0.15710975229740143, -0.12591145932674408, 0.13291791081428528, -0.19265852868556976, -0.22748364508152008, 0.15317949652671814, -0.34392037987709045, 0.2067040354013443, -0.07974930852651596, 0.042911630123853683, -0.04925619810819626, -1.045656812075341e-32, -0.44339069724082947, 0.017958320677280426, -0.21423816680908203, 0.36549875140190125, 0.00045319931814447045, 0.016232861205935478, -0.07191935181617737, 0.20036250352859497, 0.18751193583011627, 0.017207954078912735, 0.07751293480396271, 0.07280036807060242, 0.1173962652683258, -0.014980061911046505, -0.1280258744955063, 0.3200458288192749, 0.1989210695028305, 0.09943433105945587, -0.0411873385310173, 0.14990368485450745, -0.03966226801276207, 0.4028116464614868, -0.24196955561637878, 0.08850720524787903, 0.08037826418876648, 0.24272418022155762, -0.2088128924369812, 0.48992660641670227, -0.0875028669834137, 0.1989360898733139, -0.3068360686302185, -0.29795917868614197, -0.3652122914791107, -0.03637157753109932, -0.10812744498252869, 0.037869326770305634, 0.2310667335987091, -0.016351070255041122, -0.15664342045783997, 0.35519343614578247, 0.31552252173423767, -0.07346910983324051, -0.663715660572052, 0.03231193125247955, 0.2679997682571411, -0.22782672941684723, -0.26266172528266907, -0.047930214554071426, 0.09979613125324249, -0.17531585693359375, 0.13920924067497253, 0.2114521861076355, 0.05576220899820328, -0.04376732558012009, -0.2769779860973358, 0.48629629611968994, 0.0026268053334206343, 0.0442252941429615, 0.05240067094564438, 0.13876697421073914, -0.3631298840045929, -0.02869873121380806, 0.08124392479658127, 0.15128381550312042, 0.12137869745492935, 0.07351692020893097, 0.039736583828926086, 0.3115313947200775, 0.15346001088619232, -0.054481763392686844, -0.11644227802753448, 0.07126523554325104, -0.29294028878211975, 0.05798039212822914, -0.16158992052078247, 0.15900789201259613, 0.04636724293231964, -0.13721418380737305, -0.1240905374288559, -0.07590944319963455, 0.05830560252070427, -0.026819437742233276, 0.19859415292739868, 0.25025099515914917, 0.23789101839065552, 0.03925067558884621, 0.4855654835700989, -0.18558412790298462, 0.23177558183670044, -0.37960460782051086, 0.022530239075422287, -0.050037022680044174, -0.005477914586663246, 0.3922064006328583, -0.22556184232234955, -9.765825126351046e-08, -0.27489036321640015, -0.1099933460354805, 0.30661073327064514, -0.01514697540551424, 0.7495226263999939, 0.10865942388772964, -0.3676775097846985, 0.3805375397205353, -0.4790518879890442, 0.11320281773805618, 0.08976083248853683, 0.14128565788269043, -0.11066630482673645, 0.29440534114837646, -0.11146222800016403, 0.25205105543136597, -0.1006048396229744, 0.1904028356075287, -0.21017548441886902, 0.031165944412350655, 0.3845597803592682, 0.16479866206645966, 0.14407357573509216, -0.21462082862854004, 0.045698318630456924, -0.1774148941040039, -0.17381620407104492, -0.049703121185302734, 0.12991665303707123, 0.2432042509317398, -0.3978486657142639, 0.12895958125591278, 0.20159731805324554, -0.03509777784347534, 0.2164364755153656, 0.2022813856601715, 0.09912505745887756, 0.012637661769986153, -0.43717363476753235, -0.22503016889095306, -0.06068108230829239, 0.20674246549606323, -0.13728085160255432, 0.010254166088998318, 0.13705600798130035, -0.04798918589949608, 0.24494116008281708, -0.3235241174697876, -0.0034328228794038296, 0.05989382043480873, 0.052898626774549484, 0.037705425173044205, 0.054924376308918, 0.16485881805419922, 0.393227756023407, -0.2034958302974701, -0.01527903787791729, -0.3676568269729614, -0.3006037473678589, 0.02291838452219963, 0.5171616077423096, 0.1525958925485611, -0.09188434481620789, 0.2056778073310852], metadata={'source': 'AAAMLP-569to.pdf', 'page': 0}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 1            Approaching (Almost) Any Machine Learning Problem'),\n",
       " VectorParams(vector=[-0.07233933359384537, -0.01905996911227703, -0.02268570102751255, 0.027089200913906097, -0.042042676359415054, -0.00135666539426893, -0.03573470935225487, -0.02966569922864437, -0.0555231012403965, 0.0012836807873100042, -0.0033880530390888453, 0.033429354429244995, 0.039858486503362656, -0.14785736799240112, -0.12973865866661072, 0.11622895300388336, -0.011009536683559418, -0.006895049009472132, -0.02542923018336296, -0.2212715744972229, -0.06616266816854477, -0.003377580549567938, 0.022971730679273605, -0.06714191287755966, -0.09299478679895401, -0.0616314560174942, 0.08810649812221527, 0.09203401952981949, -0.04188251122832298, -0.1114766001701355, -0.009312856942415237, 0.04770183563232422, -0.016176290810108185, -0.0412738174200058, -0.033317673951387405, 0.08610335737466812, 0.01220980565994978, 0.006683449726551771, 0.07293026894330978, 0.0317225381731987, 0.054556917399168015, -0.040359318256378174, 0.011570977978408337, 0.031872231513261795, 0.18296606838703156, -0.003093777922913432, -0.03527345508337021, -0.07902891933917999, -0.03343303129076958, -0.017368700355291367, -0.17844966053962708, -0.04777710884809494, -0.08532818406820297, 0.04625887796282768, -0.03532429784536362, -0.09919610619544983, -0.013379360549151897, -0.034986354410648346, -0.029856979846954346, -0.10331732779741287, 0.015808694064617157, -0.14057064056396484, -0.10172661393880844, -0.040251560509204865, 0.05246354267001152, 0.013238012790679932, -0.06794817000627518, 0.02060280181467533, -0.03708263859152794, 0.08976387977600098, -0.03890686854720116, 0.07454606890678406, 0.023691745474934578, 0.10179618000984192, -0.043981991708278656, -0.08777199685573578, -0.049102265387773514, -0.0357193797826767, 0.054624177515506744, -0.06977258622646332, -0.04762395843863487, -0.062490690499544144, 0.05958949774503708, 0.023420989513397217, -0.06396202743053436, -0.020671691745519638, -0.0057583097368478775, -0.06783664971590042, -0.051835764199495316, -0.06462330371141434, 0.0808013305068016, -0.025820089504122734, 0.170729860663414, -0.027288291603326797, -0.06988047808408737, 0.07356613874435425, 0.05486192926764488, -0.01740151271224022, -0.09704221785068512, 0.1264197677373886, -0.09182074666023254, 0.035513803362846375, -0.024354251101613045, -0.0028091324493288994, -0.06710908561944962, -0.0591970719397068, 0.02068745531141758, -0.041644137352705, 0.07050342112779617, -0.1364026516675949, -0.026192687451839447, -0.017316455021500587, 0.009059462696313858, 0.04357505217194557, 0.03864646703004837, 0.004280462861061096, 0.033020325005054474, 0.03565796837210655, 0.09997320920228958, 0.11139165610074997, -0.0281741414219141, 0.03175627067685127, -0.03551634028553963, 0.03586255759000778, -0.013459330424666405, -0.0794767513871193, 0.0027950855437666178, 2.654432870480954e-32, -0.11421598494052887, 0.01979697123169899, -0.030432723462581635, -0.0063895913772284985, 0.04501740634441376, -0.1521730273962021, 0.027804289013147354, -0.13180208206176758, -0.061860743910074234, 0.004703906364738941, -0.02072785422205925, 0.002394657349213958, 0.008914394304156303, 0.007070760242640972, -0.027447428554296494, 0.029113171622157097, -0.001996776321902871, 0.020658062770962715, -0.04395537078380585, -0.0469738245010376, 0.11734692007303238, 0.018673090264201164, 0.01467131543904543, -0.05520448461174965, -0.00026168706244789064, 0.0784502848982811, 0.08291249722242355, -0.10669565200805664, 0.11874016374349594, 0.06036949157714844, -0.0002675266587175429, 0.07883930206298828, -0.09824194014072418, -0.02916511707007885, 0.011490059085190296, -0.03554276376962662, -0.008364638313651085, -0.014369979500770569, 0.010278187692165375, -0.02802211605012417, -0.08282503485679626, 0.0005413832841441035, 0.08696581423282623, -0.08190768957138062, -0.015071097761392593, 0.06530816107988358, 0.08029494434595108, 0.013709422200918198, 0.14057298004627228, 0.035390570759773254, -0.07510954141616821, -0.048282425850629807, -0.048956938087940216, 0.03454378619790077, 0.008207264356315136, 0.024953942745923996, -0.042427077889442444, 0.020271558314561844, 0.11804920434951782, 0.05239379405975342, 0.07389659434556961, 0.016025492921471596, 0.005592017434537411, 0.006282472983002663, 0.0321892611682415, -0.030986759811639786, -0.039110325276851654, -0.07181558012962341, 0.07477355003356934, -0.0012515487615019083, 0.0007488208939321339, -0.00802075956016779, 0.08365669846534729, -0.007489049341529608, 0.01661810651421547, -0.03621971607208252, 0.045126479119062424, -0.04201633110642433, -0.017813552170991898, -0.03609330579638481, -0.05988456681370735, 0.08271589875221252, -0.028901949524879456, -0.18986022472381592, -0.08687244355678558, -0.07627487182617188, 0.046087827533483505, -0.128476083278656, -0.07365229725837708, 0.09525545686483383, -0.06541468948125839, 0.10005010664463043, 0.04551099240779877, 0.013726702891290188, -0.021526386961340904, -2.474299234540184e-32, -0.0002456459042150527, -0.041701532900333405, -0.09220555424690247, -0.0025351669173687696, -0.0004031614225823432, -0.022780748084187508, -0.14265890419483185, 0.12650930881500244, 0.09367431700229645, 0.004229873418807983, 0.013229914009571075, 0.004984003957360983, 0.09131436049938202, 0.07128085196018219, -0.01893649250268936, -0.03598061576485634, 0.041754476726055145, -0.004399135708808899, -0.025349976494908333, -0.08766108751296997, -0.008769593201577663, 0.1422768235206604, -0.09884874522686005, 0.0031266692094504833, 0.03193051367998123, 0.09135644137859344, -0.0007415632135234773, 0.06467007845640182, -0.0905216708779335, 0.0885133147239685, -0.04677573963999748, -0.03206521272659302, -0.07485643774271011, 0.04123454540967941, -0.0627780556678772, 0.058078113943338394, 0.04302015155553818, -0.05908024683594704, -0.11274594813585281, 0.06853744387626648, 0.04756566882133484, 0.09684202820062637, -0.13855816423892975, -0.10112538188695908, 0.03228190913796425, -0.048571109771728516, 0.010907638818025589, 0.018284697085618973, -0.040486324578523636, -0.08793436735868454, 0.04229634255170822, 0.020959073677659035, -0.044999126344919205, -0.07922837138175964, -0.050596125423908234, 0.1759510487318039, 0.10894687473773956, -0.04936628043651581, 0.09097765386104584, 0.06344163417816162, -0.1614103466272354, -0.1054181158542633, 0.06732361018657684, 0.015847358852624893, 0.04234644025564194, -0.0655302181839943, -0.00832762848585844, 0.048223454505205154, 0.08999297022819519, 0.017271503806114197, -0.18122312426567078, -0.048592742532491684, -0.0761282816529274, 0.0021806778386235237, -0.021162934601306915, 0.07093527913093567, -0.0746045932173729, 0.0738772600889206, -0.08890186995267868, -0.07928275316953659, 0.03138522431254387, 0.018644126132130623, 0.016446491703391075, 0.17252054810523987, 0.10493370145559311, 0.08976154774427414, 0.07341866195201874, -0.0582953542470932, 0.046005405485630035, -0.052172303199768066, 0.09010692685842514, 0.0646999180316925, 0.13200707733631134, 0.06410226970911026, -0.020061003044247627, -1.0043891052191611e-07, -0.045750074088573456, -0.023187967017292976, 0.009058574214577675, 0.016358621418476105, 0.1328125149011612, 0.010267212055623531, -0.04479100927710533, 0.08676602691411972, -0.1881578266620636, 0.09224110841751099, 0.013899927027523518, 0.03703310713171959, -0.00942610576748848, 0.04123830422759056, -0.03324918448925018, 0.06730229407548904, 0.13429322838783264, 0.11251849681138992, -0.0841151624917984, -0.03608879819512367, 0.19360625743865967, 0.02120090276002884, 0.07119904458522797, -0.04193458333611488, -0.0004345318302512169, 0.032432787120342255, -0.1161961480975151, -0.11253465712070465, 0.04356040805578232, 0.06457553803920746, -0.076732337474823, 0.13489049673080444, 0.08227039873600006, -0.018620934337377548, 0.0390886627137661, 0.13836146891117096, 0.044639952480793, 0.028461992740631104, -0.12119513750076294, -0.0445936918258667, -0.05283304676413536, 0.047962743788957596, 0.03892900049686432, 0.03322711959481239, 0.04407903179526329, -0.07230918109416962, 0.08531007915735245, -0.11766421794891357, 0.04239014908671379, -0.056405458599328995, 0.05314415693283081, -0.07832242548465729, 0.07326950132846832, 0.07125329226255417, 0.0919961929321289, 0.005523044615983963, -0.09933234751224518, 0.028857175260782242, -0.021709846332669258, -0.031878575682640076, 0.2420063018798828, 0.00900572445243597, -0.08433662354946136, 0.0627436563372612], metadata={'source': 'AAAMLP-569to.pdf', 'page': 1}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 2       It would not have been possible for me to write this book without the support of my family and friends. I would also like to thank the reviewers who selflessly devoted their time in reviewing this book (names in alphabetical order).   Aakash Nain Aditya Soni Andreas Müller Andrey Lukyanenko Ayon Roy Bojan Tunguz Gilberto Titericz Jr. Konrad Banachewicz Luca Massaron Nabajeet Barman Parul Pandey Ram Ramrakhya Sanyam Bhutani Sudalai Rajkumar Tanishq Abraham Walter Reade Yuval Reina   I hope I did not miss anyone.'),\n",
       " VectorParams(vector=[-0.13629908859729767, -0.028534220531582832, 0.002270846627652645, 0.027900399640202522, 0.0734669417142868, -0.15684036910533905, 0.0164742860943079, -0.03460207208991051, 0.0038954713381826878, 0.035130713135004044, -0.0164283849298954, 0.1056230366230011, 0.16990967094898224, -0.101528100669384, -0.029140012338757515, 0.05488695576786995, -0.07690949738025665, -0.07501623034477234, -0.10282891988754272, -0.22804343700408936, 0.044101107865571976, 0.007122641894966364, 0.060403868556022644, 0.06089121848344803, 0.008672785013914108, -0.007836339995265007, 0.021542860195040703, 0.08249291777610779, -0.030911138281226158, -0.08027086406946182, -0.039041221141815186, 0.07107451558113098, 0.01407097652554512, -0.0014483906561508775, -0.007309505250304937, 0.21576908230781555, -0.05541321262717247, 0.002229755511507392, 0.005444309674203396, 0.02835501916706562, -0.010459456592798233, -0.05529090762138367, -0.01820823736488819, -0.016530225053429604, 0.08521894365549088, 0.10476049780845642, -0.11943448334932327, 0.009000841528177261, 0.051689401268959045, -0.099900983273983, -0.16566763818264008, 0.032911043614149094, -0.15349021553993225, -0.009117999114096165, -0.016596287488937378, -0.03444903716444969, 0.0862799808382988, -0.021173713728785515, 0.03983971104025841, -0.1681366115808487, -0.04911980405449867, -0.05607928708195686, -0.060389820486307144, 0.03733602538704872, 0.026987535879015923, -0.02184104174375534, -0.04716881364583969, 0.06468389183282852, -0.07600913196802139, 0.10092664510011673, -0.11432018131017685, 0.06732934713363647, 0.023247940465807915, 0.12466014921665192, 0.08603017777204514, -0.08719830960035324, 0.013833362609148026, -0.06391832232475281, 0.06322478502988815, -0.07972519844770432, -0.16154074668884277, -0.10254237055778503, 0.08035751432180405, 0.13984663784503937, 0.06151672080159187, -0.06848227232694626, 0.039570312947034836, 0.06762997806072235, 0.09674966335296631, -0.03791659697890282, 0.09103811532258987, -0.1455826610326767, 0.10110554844141006, 0.03701221942901611, 0.09865403175354004, 0.1861753612756729, 0.06643517315387726, -0.04045474901795387, -0.04721880331635475, 0.21262337267398834, -0.07289137691259384, 0.02278665266931057, 0.15433162450790405, -0.0905580222606659, 0.08151977509260178, 0.05750086158514023, 0.07094695419073105, -0.046355970203876495, 0.12851722538471222, -0.1455734372138977, -0.0013580857776105404, -0.09727416932582855, -0.142531618475914, 0.018899589776992798, 0.037321850657463074, 0.026576567441225052, 0.06691139191389084, -0.06718598306179047, 0.014445529319345951, 0.08640017360448837, 0.06015651300549507, 0.09315714985132217, -0.042386043816804886, 0.08323125541210175, 0.0006053884862922132, -0.10525393486022949, -0.09860850125551224, 6.096063744854473e-33, -0.042994484305381775, -0.048607803881168365, 0.021387480199337006, -0.006584188900887966, 0.028562510386109352, -0.002330743009224534, -0.0016178441001102328, -0.04662559926509857, -0.049332283437252045, 0.10435846447944641, -0.04682989418506622, 0.00972087774425745, -0.021600177511572838, 0.14376859366893768, -0.03432820737361908, 0.026892922818660736, 0.06630252301692963, -0.02476050704717636, -0.04133456572890282, -0.015047235414385796, 0.11857601255178452, -0.060019344091415405, 0.0342298187315464, -0.018002275377511978, -0.07089173793792725, 0.06477289646863937, 0.023112284019589424, -0.08709400147199631, 0.03387709707021713, 0.039103515446186066, -0.15001168847084045, -0.018276797607541084, -0.0753425657749176, -0.0772700086236, 0.024873841553926468, -0.07061010599136353, -0.0283416248857975, -0.06141747906804085, 0.04646766185760498, -0.034622762352228165, -0.03791578486561775, 0.024815209209918976, 0.0238312017172575, -0.018373260274529457, -0.048334669321775436, 0.12050551921129227, -0.01874631643295288, 0.017104094848036766, -0.0459129773080349, 0.17440904676914215, -0.013708546757698059, -0.031185487285256386, 0.036253467202186584, -0.06842923164367676, -0.08128311485052109, -0.00455170962959528, 0.028699951246380806, -0.07277725636959076, 0.028019316494464874, -0.07045957446098328, 0.18332833051681519, 0.06060830131173134, 0.076279416680336, 0.03393219783902168, 0.02126525714993477, 0.02766110748052597, 0.03336144983768463, 0.14863605797290802, 0.11311808973550797, 0.026435285806655884, -0.06619589030742645, 0.11054468899965286, 0.046040717512369156, -0.06664600223302841, 0.0644880086183548, -0.03331341966986656, 0.04778159409761429, -0.11436000466346741, -0.06485917419195175, -0.026905031874775887, 0.07539049535989761, 0.02012547291815281, -0.0348128080368042, -0.16199228167533875, -0.1620297133922577, -0.056264933198690414, 0.11812052875757217, -0.14427785575389862, -0.06706526130437851, 0.012852945365011692, -0.10190637409687042, -0.010712649673223495, -0.05543869361281395, -0.03314795717597008, -0.018999526277184486, -7.745691538029022e-33, 0.01404071319848299, 0.10033050179481506, -0.05103699862957001, -0.015662677586078644, -0.12886838614940643, 0.02171245776116848, -0.08194900304079056, 0.07776790112257004, 0.06781713664531708, -0.13077718019485474, -0.06359255313873291, 0.005618338007479906, -0.04241239279508591, -0.056319765746593475, 0.09308985620737076, 0.03941494971513748, -0.05561082065105438, 0.04107452183961868, -0.037789613008499146, -0.06279514729976654, -0.10820725560188293, 0.13787807524204254, -0.11012116819620132, -0.017998503521084785, -0.060022156685590744, 0.04191044718027115, 0.04398723319172859, 0.058932315558195114, -0.002893754281103611, 0.03682519122958183, -0.05079186335206032, 0.055879876017570496, -0.10094565898180008, 0.06598711758852005, -0.08370599150657654, -0.015603091567754745, 0.020010478794574738, -0.03631196543574333, -0.03071560338139534, -0.064869225025177, 0.23817278444766998, 0.04275652766227722, -0.06098707392811775, -0.030919400975108147, -0.051088035106658936, -0.09081509709358215, 0.029511623084545135, 0.037379853427410126, 0.05054261162877083, -0.07275863736867905, 0.032565221190452576, -0.049099329859018326, 0.024460477754473686, -0.09933527559041977, -0.137008398771286, 0.08231154829263687, -0.00038695576949976385, 0.08980517834424973, -0.02292581833899021, 0.006221383344382048, -0.1858854591846466, -0.0962863564491272, -0.0032149578910320997, 0.02797015570104122, -0.10442125052213669, -0.09471868723630905, -0.21898479759693146, -0.032422930002212524, 0.09024069458246231, 0.037450797855854034, -0.03526151180267334, 0.0627133920788765, 0.011990638449788094, -0.046945925801992416, 0.0027620973996818066, 0.11637155711650848, -0.05699611082673073, 0.03245164081454277, -0.11519009619951248, -0.010555846616625786, 0.08373798429965973, -0.008997517637908459, -0.038417309522628784, 0.15493105351924896, 0.003613702952861786, 0.010508137755095959, 0.10064493864774704, 0.022342052310705185, 0.035250063985586166, -0.04403062164783478, -0.048358701169490814, 0.12774546444416046, 0.056875597685575485, 0.14683277904987335, 0.027680858969688416, -9.918314702872522e-08, -0.06457848101854324, -0.002481484320014715, 0.06738483905792236, 0.041931577026844025, 0.1665484458208084, 0.11421335488557816, -0.020320260897278786, 0.09924046695232391, -0.1578705757856369, 0.03211786225438118, 0.1403750777244568, -0.015656322240829468, -0.03111211583018303, -0.048032552003860474, -0.11095194518566132, 0.2692277431488037, 0.10022386908531189, -0.022267701104283333, -0.060275599360466, 0.009625798091292381, 0.05338582769036293, -0.031690649688243866, 0.02589593641459942, -0.024768777191638947, -0.08245015889406204, -0.02266259305179119, -0.05675101280212402, 0.12551169097423553, -0.08882100135087967, 0.0399644561111927, 0.044797901064157486, 0.046717412769794464, 0.0027522463351488113, -0.0622294545173645, 0.08634848147630692, 0.03569817915558815, 0.004070828668773174, 0.00022940694179851562, 0.030069885775446892, -0.06069892272353172, -0.13556306064128876, 0.024118797853589058, 0.0010320179862901568, -0.035856347531080246, 0.032808467745780945, 0.05036960542201996, 0.047181230038404465, -0.0757795125246048, 0.006431899964809418, 0.01930996961891651, 0.020933831110596657, -0.020965704694390297, -0.05284208059310913, 0.05285040661692619, 0.051047105342149734, -0.01652481034398079, 0.04133634269237518, 0.011950035579502583, 0.0419032908976078, 0.13315102458000183, 0.03990709036588669, 0.05092642828822136, -0.0003843896265607327, 0.02248343825340271], metadata={'source': 'AAAMLP-569to.pdf', 'page': 2}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 3 Before you start, there are a few things that you must be aware of while going through this book.   This is not a traditional book.  The book expects you to have basic knowledge of machine learning and deep learning.   Important terms are bold.   Variable names and function/class names are italic.   ═════════════════════════════════════════════════════════════════════════ All the code is between these two lines ═════════════════════════════════════════════════════════════════════════  Most of the times, the output is provided right after the code blocks.  Figures are locally defined. For example, figure 1 is the first figure   Code is very important in this book and there is a lot of it. You must go through the code carefully and implement it on your own if you want to understand what’s going on.  Comments in Python begin with a hash (#). All the code in this book is explained line-by-line only using comments. Thus, these comments must not be ignored.  Bash commands start with $ or ❯.  If you find a pirated copy of this book (print or e-book or pdf), contact me directly with the details so that I can take necessary actions.       If you didn’t code, you didn’t learn.'),\n",
       " VectorParams(vector=[0.08711707592010498, -0.03717663884162903, -0.10221515595912933, -0.05654322728514671, -0.0638592541217804, 0.010911108925938606, -0.07907141745090485, 0.005588849075138569, -0.15874966979026794, 0.022371426224708557, -0.01993439346551895, -0.11346694827079773, 0.08215644955635071, 0.05307948589324951, -0.0683726817369461, 0.11946381628513336, 0.15902987122535706, 0.02141162008047104, -0.1440584808588028, -0.08211888372898102, 0.021340975537896156, -0.06337632238864899, -0.04637948423624039, -0.03047032840549946, -0.11993904411792755, 0.007429998368024826, 0.055625248700380325, 0.02320718765258789, -0.03880695626139641, -0.06291688233613968, -0.10563594102859497, 0.07885099202394485, -0.06507335603237152, -0.004755128175020218, 0.04674579203128815, 0.04639021307229996, -0.1004275307059288, -0.00520340958610177, -0.09909802675247192, -0.02305942215025425, -0.20607921481132507, -0.1013854593038559, -0.03101489692926407, -0.12041512131690979, 0.15255481004714966, -0.061658743768930435, -0.24344006180763245, -0.11363137513399124, -0.04156770184636116, -0.05257131904363632, -0.18750040233135223, -0.06741434335708618, -0.08717502653598785, -0.021886378526687622, -0.06233552098274231, -0.06986144185066223, 0.08158833533525467, -0.18877717852592468, -0.03561931103467941, 0.0736195296049118, -0.08210780471563339, -0.022534623742103577, -0.03993333876132965, 0.010509082116186619, 0.009352119639515877, 0.015475539490580559, -0.16045793890953064, -0.12015081942081451, -0.08465847373008728, 0.057630933821201324, 0.003215288743376732, 0.017134061083197594, -0.046237826347351074, -0.025061067193746567, 0.04271811246871948, -0.020723911002278328, 0.015779484063386917, -0.06505826860666275, 0.11351321637630463, -0.14269205927848816, -0.03897407278418541, 0.14462164044380188, -0.1069783866405487, 0.053635574877262115, 0.07323170453310013, -0.1396273672580719, -0.0021618707105517387, 0.06729121506214142, -0.016908958554267883, -0.012859968468546867, 0.13252341747283936, -0.024168889969587326, 0.07216213643550873, -0.009680642746388912, -0.03843500465154648, -0.020683400332927704, 0.013627098873257637, -0.07959788292646408, -0.06465141475200653, 0.10091261565685272, -0.1479324996471405, 0.00023649446666240692, -0.1098373681306839, 0.030504349619150162, -0.11009781062602997, 0.07490428537130356, 0.08200854063034058, 0.02189229615032673, -0.017982156947255135, -0.189092755317688, -0.04785459488630295, 0.05773429572582245, -0.184872105717659, -0.1453525424003601, -0.08218515664339066, 0.06234465539455414, 0.05736033245921135, 0.03973938524723053, 0.026677334681153297, 0.17416155338287354, -0.016600050032138824, -0.10715457797050476, 0.25286585092544556, 0.0931820347905159, -0.0440986230969429, -0.10851183533668518, -0.052785299718379974, -2.8664597252746473e-32, -0.21752861142158508, -0.24906247854232788, -0.13765087723731995, -0.04415026307106018, 0.0352378748357296, 0.11207051575183868, 0.06224946305155754, 0.11928574740886688, 0.038321465253829956, -0.08927147090435028, -0.07857061922550201, 0.0039823781698942184, -0.035048842430114746, 0.06251458078622818, 0.09903854876756668, -0.08212351053953171, 0.13319236040115356, 0.2273007184267044, -0.288004070520401, -0.06922313570976257, 0.07593411207199097, -0.14717929065227509, 0.07727785408496857, 0.09970828890800476, 0.08068771660327911, -0.0019517217297106981, 0.04378579184412956, 0.03276612609624863, -0.07240696996450424, 0.026532506570219994, 0.037050243467092514, 0.010934010148048401, -0.10112528502941132, 0.02397594042122364, -0.1324823498725891, -0.037132181227207184, -0.025808122009038925, -0.025892889127135277, 0.13440383970737457, 0.07237972319126129, -0.16440267860889435, -0.008451592177152634, 0.19484475255012512, -0.10193243622779846, -0.12894810736179352, 0.04914921522140503, 0.027914905920624733, 0.021870572119951248, -0.10553283244371414, 0.06157517433166504, -0.13142991065979004, 0.025568552315235138, -0.05763706564903259, -0.10363839566707611, -0.0851030945777893, 0.04035406559705734, 0.0810188576579094, -0.054368406534194946, 0.010771403089165688, 0.13773266971111298, -0.04571276903152466, -0.028095442801713943, -0.1440492421388626, -0.08051308989524841, 0.0843290463089943, 0.005590151064097881, 0.03192294389009476, -0.08021175116300583, 0.21011847257614136, -0.019843265414237976, -0.2021237313747406, 0.004290516953915358, 0.11980846524238586, -0.014547511003911495, 0.0862632542848587, -0.06975074857473373, 0.05294515937566757, 0.04255806282162666, -0.08194215595722198, -0.1849324107170105, -0.020383423194289207, 0.24012422561645508, -0.07109417021274567, -0.20482614636421204, 0.0522821843624115, -0.016133539378643036, -0.10837499797344208, -0.129348024725914, -0.25104206800460815, 0.026056788861751556, -0.16146071255207062, 0.06484314054250717, -0.053871430456638336, 0.05971992388367653, 0.06429547071456909, 5.61667143465022e-33, -0.02423228695988655, 0.10049108415842056, -0.005925788544118404, -0.0045772395096719265, 0.06575950980186462, -0.04903579503297806, -0.041876088827848434, -0.04957366734743118, -0.033696506172418594, 0.027252331376075745, 0.03813733160495758, -0.009613443166017532, -0.09507431089878082, -0.04336140677332878, -0.03491540625691414, 0.1457691490650177, -0.07327744364738464, -0.03635471314191818, -0.098776675760746, 0.05910864472389221, -0.05932765454053879, 0.2810937464237213, -0.05576111376285553, 0.02245311066508293, -0.11823969334363937, -0.009674685075879097, -0.045344531536102295, -0.09237594157457352, -0.03833498805761337, 0.0005936203524470329, -0.13516563177108765, -0.048688627779483795, -0.20952293276786804, 0.07733273506164551, 0.007050103507936001, -0.10357631742954254, 0.04464827477931976, -0.07361272722482681, 0.02073667198419571, 0.16300594806671143, 0.14295853674411774, 0.09275488555431366, -0.18707770109176636, -0.023585166782140732, -0.06234489381313324, 0.006411443464457989, -0.06623835861682892, -0.025364337489008904, -0.011372321285307407, -0.11808425188064575, -0.037972427904605865, 0.015205934643745422, -0.06247614324092865, -0.07859187573194504, -0.055051691830158234, 0.0358700230717659, 0.01385563239455223, -0.07678908109664917, -0.10160016268491745, 0.014199228025972843, -0.00783748459070921, -0.045498669147491455, 0.08677351474761963, 0.11902691423892975, 0.07730954885482788, 0.0211194958537817, -0.030337881296873093, 0.002889234572649002, -0.0903749167919159, 0.010057437233626842, -0.13797782361507416, 0.11518153548240662, -0.0006558655295521021, -0.07862938195466995, -0.03978043049573898, -0.0605841726064682, -0.04597492888569832, -0.006815493106842041, 0.05035850405693054, -0.04849069565534592, -0.12453922629356384, -0.052656833082437515, 0.060507725924253464, 0.06351982802152634, -0.08886915445327759, -0.036183912307024, 0.1318146288394928, -0.060174062848091125, -0.001818887423723936, 0.03186958283185959, -0.06548444926738739, 0.05396198108792305, 0.09669870138168335, -0.037321656942367554, 0.013551825657486916, -1.08282534938553e-07, -0.0698072761297226, -0.10004992038011551, 0.05339980497956276, 0.012738174758851528, 0.057760171592235565, -0.11597109586000443, -0.15316353738307953, 0.0815649926662445, -0.15483644604682922, 0.028068451210856438, 0.1653604954481125, -0.06486552208662033, 0.010297807864844799, 0.20283138751983643, -0.019599497318267822, -0.11098062247037888, 0.10860514640808105, 0.10764209926128387, -0.12399449199438095, -0.03306145220994949, 0.08323744684457779, 0.002469809725880623, 0.031149089336395264, 0.12800897657871246, 0.12769991159439087, -0.2022053599357605, -0.1094660758972168, 0.090952567756176, 0.026443978771567345, 0.001715020276606083, 0.025080278515815735, 0.01744844950735569, -0.005087625700980425, 0.02450326643884182, 0.14184510707855225, 0.043585121631622314, 0.05533169209957123, -0.0025664139539003372, -0.10156658291816711, 0.1472681164741516, -0.00949832983314991, -0.008172087371349335, -0.10701392590999603, 0.08614155650138855, 0.16347190737724304, -0.06596054136753082, -0.059594109654426575, -0.2425628900527954, -0.04825872555375099, -0.05005777254700661, -0.040718138217926025, 0.01838310807943344, -0.05357355251908302, 0.05332053452730179, 0.10400103032588959, -0.03588883951306343, -0.044473808258771896, -0.05802734196186066, -0.025083210319280624, 0.053926073014736176, -0.02004249021410942, -0.043836645781993866, -0.013984998688101768, 0.03886564075946808], metadata={'source': 'AAAMLP-569to.pdf', 'page': 3}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 4  Table of Contents Setting up your working environment ..................................................... 5 Supervised vs unsupervised learning ....................................................... 7 Cross-validation .................................................................................... 14 Evaluation metrics ................................................................................ 30 Arranging machine learning projects ................................................... 73 Approaching categorical variables ........................................................ 85 Feature engineering ........................................................................... 142 Feature selection ................................................................................ 155 Hyperparameter optimization ............................................................. 167 Approaching image classification & segmentation .............................. 185 Approaching text classification/regression .......................................... 225 Approaching ensembling and stacking ................................................ 272 Approaching reproducible code & model serving ................................ 283'),\n",
       " VectorParams(vector=[0.014792484231293201, -0.1092640608549118, -0.2198183834552765, -0.09841703623533249, 0.03034747950732708, -0.11522390693426132, -0.1269054412841797, 0.13382643461227417, -0.11685658991336823, 0.10036084055900574, 0.0950734093785286, -0.06349235028028488, -0.04710680618882179, -0.14771726727485657, 0.05627618730068207, 0.033172328025102615, -0.002409206936135888, 0.003179659601300955, -0.005958564579486847, -0.10183720290660858, 0.027024170383810997, 0.1191658079624176, -0.014522813260555267, -0.11588268727064133, -0.09718910604715347, -0.2041032314300537, 0.06626863032579422, 0.035259079188108444, -0.026464635506272316, -0.10088042914867401, 0.10356272757053375, 0.1400829404592514, -0.02513398416340351, -0.08952242136001587, 0.13333085179328918, 0.11587874591350555, 0.08877121657133102, -0.022700579836964607, -0.05231281742453575, -0.015227589756250381, 0.030358701944351196, 0.1580226719379425, -0.15787461400032043, -0.02077266201376915, -0.08033498376607895, -0.01262215618044138, -0.06496608257293701, -0.05719420313835144, 0.1894349902868271, -0.09552406519651413, -0.1067766547203064, -0.006902226712554693, -0.03334629163146019, -0.014294135384261608, -0.0378592349588871, -0.1330895721912384, -0.030847283080220222, -0.04798856005072594, 0.04263006150722504, 0.006341907661408186, 0.04105636477470398, 0.10551346093416214, -0.047216273844242096, 0.10017459839582443, 0.0032258364371955395, -0.1207323670387268, 0.02047145925462246, -0.03447824716567993, 0.12673817574977875, -0.1131395548582077, -0.15976940095424652, -0.14994919300079346, 0.005147943273186684, -0.04153580591082573, -0.13761022686958313, -0.07495123893022537, 0.19595226645469666, 0.021649762988090515, 0.008501234464347363, 0.022488946095108986, -0.1871318221092224, 0.14275984466075897, 0.017346030101180077, -0.004999156575649977, -0.08046560734510422, -0.07988517731428146, 0.058613039553165436, 0.1562524437904358, 0.08867262303829193, -0.14607976377010345, 0.13729891180992126, -0.053417764604091644, 0.0120467534288764, 0.06464242190122604, 0.049058444797992706, 0.07326417416334152, 0.15314020216464996, 0.0782240778207779, -0.02807489037513733, 0.14885728061199188, -0.07735183089971542, -0.1406375914812088, 0.07969494163990021, 0.04031691700220108, -0.01983283832669258, 0.05912142992019653, 0.12308736890554428, -0.039614707231521606, 0.01552517432719469, 0.005112918093800545, -0.09123165905475616, -0.05469531565904617, -0.04924292117357254, -0.0759500190615654, 0.04964186251163483, 0.019814303144812584, 0.04987040534615517, -0.006620682310312986, 0.06814853101968765, -0.0341024324297905, 0.0759873166680336, -0.020814845338463783, 0.15137504041194916, -0.06973037868738174, 0.1398366242647171, -0.06253263354301453, 0.05545327067375183, 1.1736058456792946e-32, 0.09421660751104355, -0.023847006261348724, -0.06581602245569229, 0.0004149852320551872, 0.13149355351924896, -0.07179143279790878, 0.17490826547145844, -0.03455241769552231, -0.22112104296684265, 0.027618857100605965, -0.021043071523308754, 0.052917562425136566, -0.07455078512430191, -0.023862512782216072, 0.04348434507846832, -0.11052246391773224, -0.07208435982465744, 0.08579497039318085, -0.022901780903339386, 0.0965183824300766, 0.0923328623175621, 0.07996069639921188, 0.0002992705558426678, -0.13476714491844177, 0.1410745233297348, -0.14934562146663666, 0.0521121509373188, -0.017791427671909332, 0.02562517300248146, -0.009926206432282925, -0.07826217263936996, -0.08509917557239532, -0.14671893417835236, -0.013665059581398964, -0.06687819957733154, -0.13699950277805328, -0.12373796850442886, 0.002263623522594571, -0.12868613004684448, -0.011645195074379444, 0.036994777619838715, 0.17746947705745697, 0.12341730296611786, -0.19016914069652557, 0.1336912363767624, 0.042923469096422195, 0.11696836352348328, 0.07002565264701843, 0.05409950762987137, 0.019480599090456963, -0.143657386302948, -0.07524361461400986, 0.11284862458705902, -0.053978994488716125, -0.02974434569478035, 0.07622732222080231, 0.04775018244981766, -0.08286081999540329, 0.20622141659259796, 0.047363199293613434, -0.12894026935100555, -0.03414836898446083, 0.06700684130191803, 0.04968184605240822, 0.10294114798307419, -0.12745007872581482, -0.11565814912319183, 0.018743999302387238, 0.14850309491157532, 0.08321262896060944, -0.21344132721424103, -0.03133257105946541, 0.15871579945087433, 0.050199951976537704, 0.12621478736400604, -0.06309273093938828, 0.07270365953445435, -0.21316100656986237, -0.134405255317688, -0.08852194249629974, 0.027697917073965073, 0.1187133938074112, -0.037991974502801895, -0.056234680116176605, 0.03862987458705902, -0.009953276254236698, 0.048983171582221985, -0.0029902420938014984, -0.036329831928014755, -0.121631920337677, 0.009216805920004845, 0.011524938978254795, 0.022850437089800835, 0.07919757068157196, 0.02086028642952442, -1.2283878497210472e-32, 0.026809118688106537, -0.13549000024795532, 0.09343311935663223, 0.008243237622082233, 0.004230393562465906, 0.09100896120071411, 0.034525685012340546, 0.08065897226333618, -0.1492653489112854, -0.2030704915523529, -0.040726110339164734, -0.002129869069904089, 0.11768064647912979, -0.03531601279973984, 0.023791121318936348, 0.12210981547832489, 0.057846251875162125, -0.05744195356965065, 0.11831391602754593, 0.021462079137563705, -0.1558549702167511, 0.16978254914283752, -0.12787823379039764, -0.21423672139644623, 0.022964583709836006, -0.0014475194038823247, 0.102440744638443, 0.0786321759223938, -0.10137005895376205, 0.0684036985039711, -0.01806061901152134, 0.07639455050230026, -0.2178722769021988, 0.1444336473941803, -0.058021534234285355, -0.01321107242256403, 0.04675420746207237, -0.09917820990085602, -0.10654520243406296, 0.015613289549946785, 0.22799666225910187, 0.0703875944018364, -0.13063199818134308, -0.11558053642511368, -0.041241355240345, -0.06317291408777237, -0.08972485363483429, 0.03954380005598068, -0.0857548639178276, -0.0855729952454567, 0.05944434180855751, -0.11048991978168488, 0.025956179946660995, -0.040200311690568924, 0.06371991336345673, -0.06958021223545074, 0.1318713277578354, 0.15552809834480286, -0.014292535372078419, -0.03533047065138817, -0.12470883876085281, -0.08346910774707794, 0.10752689093351364, -0.06086152419447899, -0.057249270379543304, 0.09720908850431442, -0.2030147761106491, 0.1307239681482315, -0.10088174790143967, -0.015302610583603382, -0.17001351714134216, 0.03650061413645744, 0.10410939157009125, -0.12405601143836975, 0.138045996427536, 0.06228393688797951, -0.08852753043174744, -0.0298515222966671, -0.06475739926099777, 0.16865171492099762, -0.011357947252690792, 0.008307364769279957, -0.05359217897057533, 0.11150940507650375, -0.0361626036465168, 0.05264704301953316, 0.00923743937164545, 0.04463948309421539, 0.02953345887362957, -0.1114552840590477, -0.021168412640690804, 0.09292527288198471, 0.1688406765460968, 0.10428362339735031, 0.0914662703871727, -9.911705944887217e-08, 0.06113022193312645, -0.015908565372228622, 0.029869617894291878, 0.07341638952493668, 0.042213648557662964, 0.11634520441293716, 0.016576725989580154, -0.05085280165076256, -0.05442940071225166, 0.2045496255159378, 0.11686856299638748, -0.018068362027406693, -0.04000939428806305, 0.06659625470638275, -0.18098972737789154, 0.3946019113063812, -0.02290460653603077, 0.04492175579071045, 0.00833564531058073, -0.06366388499736786, 0.10145428776741028, 0.017902594059705734, 0.032185137271881104, 0.09708567708730698, 0.06073109805583954, -0.026033058762550354, 0.09428224712610245, -0.02687631919980049, -0.08324242383241653, -0.05055730417370796, -0.16394443809986115, -0.021143725141882896, -0.09603633731603622, 0.07657600939273834, 0.14619463682174683, -0.09097345918416977, -0.020159201696515083, 0.1131330281496048, 0.00045462281559593976, 0.0014343091752380133, 0.052260540425777435, 0.10514315217733383, 0.02064679004251957, -0.1354992836713791, 0.04343855381011963, 0.03549390658736229, -0.11092092841863632, 0.05245644971728325, -0.03686440736055374, -0.02532588131725788, 0.02154582552611828, -0.073813296854496, 0.011408957652747631, 0.017803199589252472, 0.15975990891456604, 0.0073648132383823395, -0.2328113466501236, -0.04457936808466911, 0.026300713419914246, 0.028080672025680542, 0.00318031944334507, 0.10098686814308167, 0.11728771030902863, 0.0991915762424469], metadata={'source': 'AAAMLP-569to.pdf', 'page': 4}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 5 Setting up your working environment  Before we begin with coding, it’s essential to get everything set-up on your machine. Throughout this book, we will be using Ubuntu 18.04 and Python 3.7.6. If you are a Windows user, you can install Ubuntu in multiple ways. On a virtual machine, for example, Virtual Box which is provided by Oracle and is free software. Alongside Windows as a dual boot system. I prefer dual boot as it is native. If you are not an Ubuntu user, you might face problems with some of the bash scripts in this book. To circumvent that you can install Ubuntu in a VM or go for Linux shell on Windows.  Setting up Python on any machine is quite easy with Anaconda. I particularly like Miniconda, which is a minimal installer for conda. It is available for Linux, OSX and Windows. Since Python 2 support ended at the end of 2019, we will be using the Python 3 distribution. You should keep in mind that miniconda does not come with all the packages as regular Anaconda. We will, thus, be installing packages as we go. Installing miniconda is quite easy.  The first thing that you need to do is download Miniconda3 to your system.  $ cd ~/Downloads $ wget https://repo.anaconda.com/miniconda/...  where the URL after wget command is the URL from miniconda3 webpage. For 64-bit Linux systems, the URL at the time of writing this book was:  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh  Once you have downloaded miniconda3, you can run the following command:  $ sh Miniconda3-latest-Linux-x86_64.sh  Next, please read and follow the instructions on your screen. If you installed everything correctly, you should be able to start the conda environment by typing conda init the terminal. We will create a conda environment that we will be using throughout this book. To create a conda environment, you can type:  $ conda create -n environment_name python=3.7.6'),\n",
       " VectorParams(vector=[-0.0005935703520663083, -0.19246453046798706, -0.05736758932471275, -0.050010696053504944, 0.10799439996480942, -0.030031731352210045, 0.022261742502450943, 0.05363713577389717, -0.11598564684391022, 0.05752290040254593, 0.023025305941700935, -0.06470602750778198, -0.038447409868240356, -0.06464828550815582, 0.07572066783905029, 0.13033007085323334, 0.03142644464969635, -0.01589549146592617, 0.0005504220607690513, -0.17201310396194458, 0.04570882394909859, 0.10008987784385681, -0.006919089704751968, 0.0508565679192543, -0.19414496421813965, -0.0864744558930397, 0.1574111133813858, 0.08449891954660416, 0.02147562988102436, -0.032701924443244934, 0.09265604615211487, 0.15760064125061035, 0.01049745362251997, -0.04390621557831764, 0.07889379560947418, 0.22981321811676025, 0.03381917253136635, 0.01131715252995491, 0.04599699750542641, -0.062086161226034164, 0.07490416616201401, -0.046628352254629135, -0.0974823385477066, -0.1094762533903122, 0.024374010041356087, -0.06721097975969315, 0.009230812080204487, -0.09851226955652237, 0.14066703617572784, -0.06576067209243774, -0.09441375732421875, -0.050566110759973526, -0.13345997035503387, -0.046775463968515396, -0.07579060643911362, -0.010522443801164627, 0.014964921399950981, -0.02814675122499466, -0.048502929508686066, -0.1085578054189682, -0.016230886802077293, 0.07584710419178009, -0.08312026411294937, 0.05566854402422905, -0.10188523679971695, -0.003078693291172385, -0.06112489849328995, 0.16054385900497437, 0.21408794820308685, -0.05005151405930519, -0.06503468751907349, 0.016296247020363808, -0.01303604245185852, -0.12377046793699265, -0.1270993947982788, -0.07242241501808167, 0.03755717724561691, -0.05580152943730354, 0.04408560320734978, -0.009273169562220573, -0.05751140043139458, 0.12690570950508118, 0.06483617424964905, 0.02185620181262493, -0.028464386239647865, -0.03196258470416069, 0.0597497895359993, 0.05333048850297928, 0.03027588501572609, -0.09788984805345535, 0.15040871500968933, -0.11478812247514725, 0.11284244805574417, 0.006555895786732435, 0.01420509722083807, 0.17144836485385895, 0.08566094189882278, -0.029118185862898827, 0.03297392651438713, 0.11722947657108307, -0.18218275904655457, -0.04267081618309021, 0.057126447558403015, 0.02397223934531212, -0.03344184160232544, -0.0036350442096590996, 0.04431177303195, -0.16380028426647186, 0.07342254370450974, -0.07228787988424301, -0.06925100833177567, -0.0751299038529396, -0.05877014249563217, -0.02748253382742405, 0.014682739041745663, 0.04008154571056366, 0.05342434346675873, 0.0017022163374349475, 0.0593695193529129, 0.007385407108813524, -0.026855723932385445, 0.08368289470672607, 0.19038064777851105, -0.0020288212690502405, 0.10527510195970535, -0.024709049612283707, -0.037632834166288376, 9.097687834995215e-33, 0.09313951432704926, -0.012859026901423931, -0.017445433884859085, 0.044109147042036057, 0.1256636083126068, -0.06615611910820007, 0.20322471857070923, -0.0076704733073711395, -0.07378199696540833, 0.006426165346056223, 0.039740875363349915, 0.058056533336639404, -0.16227535903453827, 0.094991534948349, -0.015287342481315136, 0.05836911499500275, -0.11518638581037521, 0.07301335036754608, -0.01637386716902256, -0.0008326544193550944, 0.046602800488471985, -0.0042016212828457355, 0.05051705986261368, 0.04383327066898346, 0.08315645158290863, -0.052439361810684204, 0.0995442271232605, -0.00982489064335823, -0.003373131388798356, 0.02377067692577839, 0.05362670123577118, -0.05072920769453049, -0.08319427818059921, 0.062318913638591766, -0.11347699910402298, 0.018752586096525192, -0.19800244271755219, 0.035855475813150406, -0.01934419572353363, 0.017519405111670494, 0.06004085764288902, 0.1317654848098755, 0.16545076668262482, -0.11698754876852036, 0.09223783761262894, 0.03437720984220505, 0.1328953206539154, -0.0659378245472908, 0.10395438969135284, 0.0017053509363904595, -0.06244618073105812, -0.12000741809606552, 0.010155699215829372, -0.09881517291069031, -0.025065112859010696, -0.05716945603489876, 0.08244510740041733, -0.008727162145078182, 0.23578178882598877, -0.012540169060230255, -0.031115613877773285, -0.050721555948257446, 0.05556826293468475, 0.12036062777042389, 0.11900240182876587, -0.06912209093570709, -0.04383494704961777, 0.05674448981881142, 0.10419522225856781, -0.0010985342087224126, -0.1834583580493927, 0.02032511495053768, -0.04881010949611664, -0.06012178957462311, 0.1251903474330902, -0.09675430506467819, 0.020145021378993988, -0.16065533459186554, -0.16151581704616547, 0.030407031998038292, 0.028456836938858032, 0.03799080103635788, -0.047505851835012436, -0.031637296080589294, 0.015505649149417877, -0.013351189903914928, 0.025851067155599594, -0.06022190302610397, -0.055596329271793365, -0.1229829490184784, -0.04945891350507736, 0.04011565074324608, -0.04840106889605522, 0.008913961239159107, -0.018057124689221382, -1.22885819439817e-32, 0.09643026441335678, -0.0664769858121872, 0.041237279772758484, 0.0951804369688034, -0.022869639098644257, 0.07671642303466797, 0.03002670779824257, -0.030981793999671936, -0.0038639490958303213, -0.1383826583623886, -0.1570596992969513, 0.011391710489988327, 0.10567806661128998, 0.015432974323630333, -0.06729388982057571, 0.03800247237086296, -0.14221473038196564, -0.006750231143087149, -0.006888506002724171, -0.012698822654783726, -0.18440328538417816, 0.11583013087511063, 0.004843763541430235, -0.05537426099181175, 0.078070729970932, -0.07006675750017166, 0.05532290041446686, -0.019852861762046814, -0.07467423379421234, 0.10195530205965042, -0.10822302103042603, 0.10486377030611038, -0.14723582565784454, 0.06068494915962219, -0.22394753992557526, 0.01088061835616827, 0.024298474192619324, -0.07541056722402573, -0.07185515761375427, 0.16374526917934418, 0.1665557622909546, 0.07384558767080307, -0.22913971543312073, -0.18899789452552795, -0.15066687762737274, -0.04709190875291824, -0.05165259912610054, -0.013936708681285381, 0.01972770132124424, -0.030058419331908226, -0.00014746490342076868, 0.004696718417108059, -0.17671950161457062, -0.08418286591768265, 0.04258032515645027, 0.04333193972706795, 0.06462952494621277, 0.155714750289917, -0.05432724952697754, -0.06376592814922333, -0.1726207435131073, -0.0475580096244812, 0.13696372509002686, -0.07190510630607605, -0.13032516837120056, 0.04105443134903908, -0.06587304174900055, 0.14055503904819489, -0.023194430395960808, -0.006722241174429655, -0.10293996334075928, 0.07618755102157593, -0.06428790092468262, -0.05553288012742996, -0.015403568744659424, -0.050092585384845734, -0.07703936100006104, -0.025901036337018013, -0.032416775822639465, 0.11435338854789734, -0.06150839105248451, -0.0773041844367981, -0.06912771612405777, 0.13224859535694122, 0.06460881233215332, -0.01880638860166073, 0.09458649158477783, -0.05279970169067383, 0.1038002148270607, -0.04549892991781235, 0.016498621553182602, 0.0651906207203865, -0.019947413355112076, 0.10780319571495056, 0.08260197192430496, -9.973125969509056e-08, -0.09129933267831802, -0.044140566140413284, 0.015762807801365852, 0.08506061881780624, 0.06669412553310394, 0.06432764232158661, -0.026994574815034866, 0.12875144183635712, -0.06630665808916092, 0.11771821230649948, 0.14683546125888824, 0.012213925831019878, -0.10169392824172974, 0.055451650172472, -0.16741296648979187, 0.2714994549751282, 0.021683672443032265, 0.07307848334312439, -0.08270015567541122, -0.06357622891664505, 0.12075220048427582, 0.052338771522045135, 0.07698206603527069, 0.06906893849372864, 0.041165027767419815, -0.0756729245185852, -0.051319826394319534, -0.0010356369893997908, 0.014286944642663002, -0.033647164702415466, -0.06607934832572937, -0.0597316175699234, -0.050892140716314316, 0.02861643396317959, 0.12598833441734314, -0.042988378554582596, -0.0696469321846962, 0.029729973524808884, 0.010422458872199059, 0.020938316360116005, -0.048576146364212036, 0.05868885666131973, -0.03887218236923218, -0.11561170220375061, 0.03058418072760105, -0.004422915168106556, -0.06321275979280472, -0.02593924105167389, -0.049026969820261, 0.05227968096733093, -0.026532093062996864, -0.04399730637669563, 0.11685089766979218, 0.1659521907567978, 0.1769711971282959, 0.09319283068180084, -0.07855670899152756, -0.061647024005651474, 0.059104204177856445, -0.06381463259458542, -0.026355233043432236, 0.012840446084737778, 0.060713835060596466, -0.05032789334654808], metadata={'source': 'AAAMLP-569to.pdf', 'page': 5}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 6 This command will create a conda environment named environment_name which can be activated using:   $ conda activate environment_name  And we are all set-up with the environment. Now it’s time to install some packages that we would be using. A package can be installed in two different ways when you are in a conda environment. You can either install the package from conda repository or the official PyPi repository.  $ conda/pip install package_name  Note: It might be possible that some packages are not available in the conda repo. Thus, installing using pip would be the most preferred way in this book. I have already created a list of packages used while writing this book which is saved in the environment.yml. You can find it in extra material available in my GitHub repository. You can create the environment using the following command:  $ conda env create -f environment.yml  This command will create an environment called ml. To activate this environment and start using it, you should run:  $ conda activate ml  And we are all set and ready to do some applied machine learning!   Always remember to be in the “ml” environment when coding along with this book.   Let’s start with our real first chapter now.'),\n",
       " VectorParams(vector=[-0.024723991751670837, -0.030698610469698906, 0.008594350889325142, 0.11733554303646088, 0.2211473137140274, 0.03686319291591644, -0.03355595842003822, -0.1000576913356781, -0.11085687577724457, 0.043291669338941574, 0.021739482879638672, -0.11342008411884308, 0.10020393133163452, 0.1443929523229599, 0.005311687011271715, -0.004709211178123951, 0.09611496329307556, -0.043916113674640656, -0.06361761689186096, -0.0092072868719697, 0.047866176813840866, 0.007718605455011129, 0.023688461631536484, 0.12226118892431259, -0.08765488117933273, 0.06847228109836578, 0.10875646024942398, -0.058956243097782135, -0.07264363765716553, -0.040498439222574234, 0.08280567824840546, -0.038580067455768585, -0.10374430567026138, 0.058026909828186035, -0.09156402200460434, 0.0364588238298893, -0.04208723455667496, 0.15011656284332275, -0.0639491006731987, 0.01447224710136652, 0.045769158750772476, -0.08197643607854843, -0.05569445341825485, 0.0052413055673241615, 0.15400491654872894, 0.07062595337629318, -0.03143012151122093, -0.06018916890025139, -0.08534521609544754, -0.05239875987172127, -0.11974293738603592, -0.030646538361907005, -0.03652644529938698, 0.04848797619342804, -0.10452809184789658, -0.06698495149612427, 0.05348791182041168, -0.03819936886429787, 0.04098505154252052, 0.007688448764383793, -0.07449977099895477, -0.12444949895143509, -0.023901980370283127, -0.09865365922451019, 0.0580451600253582, -0.03353576734662056, -0.047509271651506424, -0.019001822918653488, 0.012123769149184227, 0.037460315972566605, 0.13318349421024323, 0.15537837147712708, -0.08421292155981064, 0.08073752373456955, 0.0897131934762001, -0.03130675479769707, 0.06204625591635704, 0.0360688641667366, 0.09647524356842041, 0.019644543528556824, 0.036123305559158325, 0.0014749332331120968, 0.004368855617940426, 0.08150987327098846, 0.2105795294046402, -0.053387343883514404, -0.09796663373708725, 0.03943644091486931, -0.07670154422521591, 0.015316672623157501, -0.03273262083530426, -0.09708704054355621, 0.12544681131839752, 0.017199382185935974, 0.017787402495741844, -0.07432994991540909, 0.064277283847332, -0.020966216921806335, 0.05091927573084831, 0.04481508210301399, -0.1395663022994995, 0.12196674197912216, 0.0027220817282795906, 0.06468672305345535, 0.07827243953943253, -0.00785142183303833, -0.04043315723538399, -0.00722230551764369, 0.10698725283145905, -0.16975440084934235, -0.013037262484431267, -0.0568067766726017, -0.19148746132850647, -0.017014198005199432, -0.04452446103096008, -0.11525706946849823, -0.010960731655359268, -0.07391420751810074, -0.08381572365760803, 0.026640569791197777, -0.10830990970134735, -0.08184409141540527, 0.07436233758926392, 0.03291097283363342, 0.045239612460136414, -0.05659579113125801, -0.17067767679691315, 9.578624450902861e-33, -0.07934517413377762, -0.1776503622531891, -0.10589884966611862, -0.11155080795288086, 0.07114177942276001, -0.07291343063116074, -0.1868903636932373, 0.07258254289627075, 0.15871044993400574, 0.09192384779453278, 0.06763441860675812, -0.006646462716162205, 0.02922144904732704, 0.1086440160870552, 0.17504900693893433, -0.06767957657575607, 0.020928002893924713, 0.121246837079525, -0.12695150077342987, -0.06927917897701263, 0.01369562465697527, 0.078843854367733, 0.03246675059199333, 0.03429372236132622, 0.005845225416123867, -0.06910736858844757, -0.054031845182180405, -0.052223216742277145, 0.12365829944610596, 0.009200884029269218, 0.007825479842722416, -0.0015986424405127764, -0.011864175088703632, 0.11698752641677856, -0.025255097076296806, -0.025137661024928093, -0.022764921188354492, -0.07176422327756882, 0.018250690773129463, -0.017189407721161842, -0.031294263899326324, -0.025895124301314354, 0.16432824730873108, -0.05697227269411087, 0.03903752192854881, 0.01390360202640295, -0.004570928402245045, -0.12026385217905045, -0.13709284365177155, 0.005475755315274, 0.00820622406899929, -0.03246891126036644, -0.03274281322956085, -0.11138221621513367, -0.09533676505088806, 0.09427443891763687, -0.029400886967778206, -0.11827309429645538, -0.06000031530857086, -0.06918001174926758, 0.029208412393927574, -0.06016154587268829, 0.052848391234874725, -0.013470611535012722, 0.047385893762111664, -0.034016333520412445, 0.1102476716041565, 0.06213965266942978, 0.109725221991539, 0.02930666320025921, 0.018917357549071312, 0.10284940898418427, 0.023163119331002235, -0.0378117561340332, 0.13818103075027466, -0.014116300269961357, 0.055752232670784, 0.053885992616415024, -0.11185949295759201, 0.11368929594755173, 0.0352574847638607, -0.007450642995536327, -0.03848569840192795, -0.044512614607810974, -0.08583759516477585, 0.12464042007923126, -0.04923510551452637, -0.05417569726705551, -0.06671904772520065, 0.034041330218315125, -0.07281693816184998, 0.11995425075292587, -0.13833384215831757, 0.0032159616239368916, 0.15814660489559174, -9.836340567061108e-33, -0.04606616124510765, 0.0839569941163063, -0.05967253819108009, 0.015127372927963734, -0.06436293572187424, 0.09376714378595352, -0.059716980904340744, -0.01070364098995924, 0.038131989538669586, -0.09579622000455856, -0.1608661264181137, 0.0004354699922259897, 0.030098166316747665, 0.026991194114089012, -0.16805778443813324, 0.10763227939605713, -0.14633873105049133, -0.03436175361275673, -0.06358984112739563, 0.0555778369307518, -0.1514052450656891, 0.17776603996753693, -0.08332037180662155, -0.00447144964709878, -0.0868004858493805, 0.11243075132369995, -0.06428216397762299, 0.00213204906322062, 0.022558363154530525, 0.07984785735607147, 0.012806165032088757, -0.05802276358008385, -0.06064721941947937, -0.13926653563976288, -0.11087043583393097, 0.05539339780807495, 0.024170193821191788, -0.12290839850902557, -0.052770502865314484, 0.09478458017110825, -0.00016165936540346593, 0.1468178927898407, -0.08335715532302856, 0.02112063206732273, 0.026286104694008827, -0.06588146090507507, -0.035121746361255646, 0.01906551420688629, 0.04477519914507866, -0.06157613545656204, -0.09442859143018723, 0.06966082006692886, -0.06940381973981857, -0.0605599507689476, -0.0636788159608841, 0.02529750019311905, -0.010290700942277908, 0.0342123806476593, -0.01250157505273819, 0.05709322169423103, -0.014061087742447853, 0.051110390573740005, 0.01917506568133831, 0.1269296556711197, -0.0832945927977562, -0.06775083392858505, -0.008431738242506981, -0.01234979834407568, 0.031928304582834244, -0.09841831028461456, -0.08649814873933792, 0.05520833283662796, 0.012300565838813782, 0.023596232756972313, -0.058265168219804764, 0.019589519128203392, -0.029705364257097244, 0.07120318710803986, -0.053642638027668, -0.038278549909591675, 0.07408178597688675, -0.19028827548027039, -0.023580536246299744, 0.07613210380077362, 0.02323666773736477, 0.008637924678623676, 0.13504290580749512, 0.0047838385216891766, 0.05832767114043236, -0.09635157883167267, -0.004334458149969578, 0.02226354368031025, -0.021195905283093452, 0.1440543681383133, -0.024663830175995827, -9.973960857223574e-08, -0.09354107081890106, -0.0586509145796299, 0.0732497125864029, -0.1318461298942566, 0.11770304292440414, 0.0015609759138897061, -0.12356583774089813, 0.14838524162769318, -0.09510326385498047, 0.08902153372764587, 0.052409108728170395, 0.060493458062410355, -0.223163902759552, 0.09062568843364716, -0.06158474087715149, 0.10510849952697754, 0.10297780483961105, 0.047810520976781845, 0.04480063170194626, 0.20601463317871094, 0.011684207245707512, -0.07119376212358475, -0.060589805245399475, 0.021013310179114342, 0.07451973855495453, -0.13627363741397858, 0.05466208606958389, 0.12805554270744324, 0.02483873814344406, 0.060769710689783096, -0.10596805065870285, 0.002912196796387434, 0.07478787004947662, 0.03702005743980408, 0.15520276129245758, 0.05075930804014206, 0.09501760452985764, -0.20257070660591125, -0.1392296701669693, -0.08615145832300186, 0.06501148641109467, 0.19210191071033478, -0.07106054574251175, 0.03066209889948368, 0.048098281025886536, 0.07844211906194687, 0.07680577039718628, -0.06106921285390854, 0.008155272342264652, 0.021826328709721565, -0.07117564231157303, 0.008271514438092709, 0.04778312146663666, 0.07853274792432785, 0.1063750609755516, 0.008047522976994514, 0.004445465747267008, -0.18039986491203308, 0.12881234288215637, 0.10399287194013596, 0.14823806285858154, 0.0632300153374672, -0.04990492761135101, 0.030497359111905098], metadata={'source': 'AAAMLP-569to.pdf', 'page': 6}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 7 Supervised vs unsupervised learning  When dealing with machine learning problems, there are generally two types of data (and machine learning models): • Supervised data: always has one or multiple targets associated with it. • Unsupervised data: does not have any target variable.  A supervised problem is considerably easier to tackle than an unsupervised one. A problem in which we are required to predict a value is known as a supervised problem. For example, if the problem is to predict house prices given historical house prices, with features like presence of a hospital, school or supermarket, distance to nearest public transport, etc. is a supervised problem. Similarly, when we are provided with images of cats and dogs, and we know beforehand which ones are cats and which ones are dogs, and if the task is to create a model which predicts whether a provided image is of a cat or a dog, the problem is considered to be supervised.  \\n Figure 1: A supervised dataset.  As we see in figure 1, every row of the data is associated with a target or label. The columns are different features and rows represent different data points which are usually called samples. The example shows ten samples with ten features and a target variable which can be either a number or a category. If the target is categorical, the problem becomes a classification problem. And if the target is a real'),\n",
       " VectorParams(vector=[-0.11766019463539124, -0.029592830687761307, -0.02389364130795002, 0.07402777671813965, 0.15418878197669983, 0.0205241646617651, 0.03196365013718605, -0.04185465723276138, -0.013771016150712967, 0.0402035266160965, -0.01693614013493061, -0.11993946135044098, 0.11567557603120804, 0.08014361560344696, -0.058067623525857925, -0.06542689353227615, 0.13037636876106262, 0.016474716365337372, -0.13822834193706512, -0.03513671085238457, 0.05065242946147919, -0.0349811352789402, 0.01478857547044754, 0.0511760450899601, -0.07228056341409683, 0.012723103165626526, 0.13670054078102112, -0.099904865026474, -0.13877996802330017, -0.049041494727134705, 0.07421150803565979, 0.10174572467803955, -0.04461821913719177, 0.06956003606319427, -0.1042669266462326, 0.024719158187508583, -0.02207822911441326, 0.14325225353240967, -0.07458031922578812, -0.00022287201136350632, 0.0716775432229042, -0.03462637588381767, -0.0897502452135086, -0.042890917509794235, 0.138347327709198, -0.027111753821372986, -0.06973432749509811, 0.039628881961107254, -0.1230965331196785, -0.04036647081375122, -0.09790205955505371, 0.020940102636814117, -0.03815693035721779, 0.076287642121315, -0.031548190861940384, -0.09870415925979614, 0.17310376465320587, -0.011034902185201645, 0.09386137872934341, -0.08673201501369476, 0.05047282576560974, -0.07287589460611343, 0.04852072149515152, -0.1287301778793335, 0.05618281289935112, 0.04226798191666603, 0.07062782347202301, 0.0764889121055603, -0.003140674903988838, 0.031018327921628952, 0.14951366186141968, 0.1218138337135315, -0.13596439361572266, 0.09183333069086075, 0.01626531034708023, 0.051522232592105865, 0.13884641230106354, 0.06571578234434128, 0.04101348668336868, 0.01395389810204506, 0.09104867279529572, 0.0032584602013230324, -0.00404195673763752, 0.06444977968931198, 0.1895822137594223, -0.03961608558893204, -0.11363762617111206, 0.01356683112680912, -0.07414435595273972, 0.006385309621691704, -0.02332111820578575, 0.031894322484731674, 0.03430187329649925, -0.11566932499408722, 0.055180445313453674, -0.11678653955459595, 0.00821466650813818, -0.011803747154772282, 0.17115551233291626, 0.06846480071544647, -0.11307090520858765, 0.12098562717437744, 0.019392475485801697, -0.07004329562187195, 0.042740706354379654, 0.01741788536310196, 0.004699204117059708, 0.0026696189306676388, 0.15156018733978271, -0.17386704683303833, -0.033225394785404205, 0.03957430645823479, -0.19028496742248535, -0.02768135815858841, 0.04204954206943512, -0.05727449059486389, 0.1440081149339676, -0.014410789124667645, -0.058355364948511124, 0.10706647485494614, 0.007752095349133015, -0.06905946135520935, 0.02958725206553936, 0.03987802192568779, 0.1472465693950653, -0.028758056461811066, -0.20145508646965027, 1.2643029490269113e-32, -0.07960687577724457, -0.11922499537467957, -0.07385016977787018, -0.1422082781791687, 0.07887710630893707, -0.10349182784557343, -0.11230884492397308, 0.05614127218723297, 0.1427300125360489, 0.04847261309623718, -0.009183347225189209, 0.1099860668182373, 0.04044130817055702, 0.02795349806547165, 0.1505596935749054, -0.019657092168927193, 0.023352112621068954, 0.05583637207746506, -0.15800133347511292, -0.13677437603473663, 0.058162715286016464, 0.0071676671504974365, 0.09110498428344727, 0.023311380296945572, -0.0675545334815979, -0.026517052203416824, 0.029730217531323433, -0.12228075414896011, 0.13405615091323853, 0.014007347635924816, -0.023681430146098137, -0.014496123418211937, 0.06223636865615845, 0.1431611329317093, 0.016000699251890182, -0.03062249720096588, -0.038477204740047455, -0.07335779815912247, -0.011498674750328064, -0.08019529283046722, -0.1032208800315857, 0.013747718185186386, 0.12327221781015396, -0.06163035333156586, 0.045524075627326965, 0.09586358070373535, 0.022747548297047615, -0.1248808205127716, 0.019012989476323128, -0.04100621119141579, 0.02128351479768753, -0.0830124244093895, 0.048767633736133575, -0.0691266655921936, -0.09678207337856293, 0.11389334499835968, 0.04527563229203224, -0.16086988151073456, 0.04898715764284134, -0.03260503709316254, -0.06167565658688545, -0.09794466197490692, -0.008860749192535877, -0.08433090150356293, -0.07301085442304611, -0.018086254596710205, 0.003306739032268524, 0.043510802090168, 0.02045481652021408, -0.004001445136964321, -0.0309597160667181, 0.0768616572022438, 0.05408993363380432, -0.0012354827485978603, 0.061381660401821136, 0.06680551171302795, 0.07370607554912567, 0.12156309187412262, -0.10563331842422485, 0.05934278294444084, -0.023503713309764862, -0.018371084704995155, -0.03671824932098389, -0.10778885334730148, -0.07575429975986481, 0.06891155242919922, 0.026812372729182243, -0.04514424130320549, -0.06255795061588287, -0.002955343574285507, -0.06767294555902481, 0.06100685894489288, -0.043906595557928085, 0.017001546919345856, 0.21648883819580078, -1.1190543119987e-32, -0.13966701924800873, 0.0811326801776886, -0.11423648148775101, 0.0158100388944149, -0.030736751854419708, 0.004542974755167961, -0.1061745434999466, 0.019206393510103226, -0.043731480836868286, -0.14666599035263062, -0.1469154953956604, -0.06686929613351822, 0.0542769655585289, 0.09564009308815002, -0.12315511703491211, 0.08894804120063782, -0.015344638377428055, 0.08720025420188904, 0.01581965759396553, 0.11211095750331879, -0.07938140630722046, 0.12337414920330048, -0.0798177570104599, -0.10212380439043045, -0.09843207895755768, 0.1105046421289444, -0.05428902059793472, 0.05107763409614563, -0.00923389382660389, 0.043450236320495605, 0.027968892827630043, 0.031836237758398056, -0.13379386067390442, -0.009220555424690247, -0.10135217756032944, -0.017375560477375984, -0.05208471417427063, -0.07219235599040985, 0.02775793895125389, 0.025611240416765213, 0.08220898360013962, 0.13196837902069092, -0.10020335018634796, -0.03121758997440338, 0.021755937486886978, -0.1661171019077301, 0.009844016283750534, 0.009152556769549847, 0.06032013148069382, -0.001771874725818634, -0.0274482574313879, 0.036980919539928436, -0.02727656252682209, 0.05190623551607132, -0.08761860430240631, 0.11452940106391907, 0.03224894031882286, 0.05886586010456085, 0.02315775863826275, 0.10867210477590561, -0.026110470294952393, 0.04937370866537094, 0.037156909704208374, 0.1263093203306198, 0.02194376289844513, -0.13305345177650452, 0.04775248467922211, 0.032553162425756454, -0.031518951058387756, -0.021970629692077637, -0.15767648816108704, -0.00295732612721622, 0.026415109634399414, 0.07228745520114899, -0.09301013499498367, 0.023529481142759323, -0.11182449758052826, 0.08323626220226288, -0.02754399925470352, -0.06319580972194672, 0.06613852083683014, -0.12738105654716492, 0.008402829058468342, 0.010651370510458946, -0.022676557302474976, 0.01223490759730339, 0.13795635104179382, -0.020738746970891953, 0.11640709638595581, -0.17009954154491425, -0.05315132439136505, 0.0038787464145570993, -0.04944007471203804, 0.02909259684383869, -0.014176077209413052, -9.995292771236564e-08, -0.07770043611526489, -0.09916840493679047, 0.07730744779109955, -0.14155659079551697, 0.17953816056251526, -0.05402866005897522, -0.12751640379428864, 0.19118577241897583, -0.1571301519870758, 0.09690167009830475, 0.08914002776145935, -0.0031068800017237663, -0.1951960325241089, -0.04986800253391266, -0.10901099443435669, 0.03659096360206604, 0.09127849340438843, 0.05753128603100777, -0.02579212188720703, 0.10276106745004654, 0.025890806689858437, -0.042478300631046295, -0.01617315039038658, 0.007512484677135944, 0.013697165064513683, -0.13899865746498108, 0.041843123733997345, 0.03140127658843994, 0.0037224264815449715, 0.038658902049064636, -0.11682827025651932, 0.007834715768694878, 0.02848651632666588, 0.014911795035004616, 0.14653506875038147, 0.15750963985919952, 0.038701046258211136, -0.08191203325986862, -0.1797296553850174, -0.02391325868666172, 0.06361371278762817, 0.15003374218940735, -0.07102569937705994, -0.050260722637176514, 0.0851283073425293, 0.001869169995188713, 0.031882427632808685, -0.019549526274204254, 0.06976160407066345, 0.06397971510887146, -0.06392163038253784, -0.0910918116569519, -0.023819943889975548, 0.06096533685922623, 0.047734834253787994, -0.0004364300984889269, -0.06890877336263657, -0.0895838737487793, 0.14062179625034332, 0.03295198455452919, 0.13460281491279602, -0.0033840639516711235, -0.015999548137187958, 0.06754264235496521], metadata={'source': 'AAAMLP-569to.pdf', 'page': 7}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 8 number, the problem is defined as a regression problem. Thus, supervised problems can be divided into two sub-classes:  • Classification: predicting a category, e.g. dog or cat. • Regression: predicting a value, e.g. house prices.  It must be noted that sometimes we might use regression in a classification setting depending on the metric used for evaluation. But we will come to that later.  Another type of machine learning problem is the unsupervised type. Unsupervised datasets do not have a target associated with them and in general, are more challenging to deal with when compared to supervised problems.  Let’s say you work in a financial firm which deals with credit card transactions. There is a lot of data that comes in every second. The only problem is that it is difficult to find humans who will mark each and every transaction either as a valid or genuine transaction or a fraud. When we do not have any information about a transaction being fraud or genuine, the problem becomes an unsupervised problem. To tackle these kinds of problems we have to think about how many clusters can data be divided into. Clustering is one of the approaches that you can use for problems like this, but it must be noted that there are several other approaches available that can be applied to unsupervised problems. For a fraud detection problem, we can say that data can be divided into two classes (fraud or genuine).  When we know the number of clusters, we can use a clustering algorithm for unsupervised problems. In figure 2, the data is assumed to have two classes, dark colour represents fraud, and light colour represents genuine transactions. These classes, however, are not known to us before the clustering approach. After a clustering algorithm is applied, we should be able to distinguish between the two assumed targets. To make sense of unsupervised problems, we can also use numerous decomposition techniques such as Principal Component Analysis (PCA), t-distributed Stochastic Neighbour Embedding (t-SNE) etc.   Supervised problems are easier to tackle in the sense that they can be evaluated easily. We will read more about evaluation techniques in the following chapters. However, it is challenging to assess the results of unsupervised algorithms and a lot of human interference or heuristics are required. In this book, we will majorly be focusing on supervised data and models, but it does not mean that we will be ignoring the unsupervised data problems.'),\n",
       " VectorParams(vector=[-0.057960145175457, -0.10858223587274551, 0.027160832658410072, 0.03795035928487778, 0.18944790959358215, 0.024623334407806396, -0.011446723714470863, -0.05387618765234947, -0.10616128146648407, -0.06975153833627701, 0.02155766822397709, -0.1025560051202774, 0.017623446881771088, 0.16172464191913605, -0.016720306128263474, -0.12479541450738907, 0.06793307512998581, 0.07694020122289658, -0.22336336970329285, -0.0091344453394413, 0.03120807372033596, -0.06185818836092949, 0.03193891793489456, 0.021626442670822144, -0.08681397140026093, 0.0770634114742279, 0.11835464835166931, -0.08674107491970062, -0.11040453612804413, -0.03737249597907066, 0.08402613550424576, 0.06068601831793785, 0.0378289557993412, 0.08713462203741074, -0.08903930336236954, 0.026293279603123665, 0.0024790368042886257, 0.1682264655828476, -0.05763617530465126, 0.030171165242791176, -0.043487388640642166, -0.0499044694006443, -0.020840924233198166, 0.010611046105623245, 0.20049117505550385, 0.029816104099154472, -0.06061439588665962, -0.005132301244884729, -0.08616415411233902, 0.012629654258489609, -0.09219106286764145, 0.01287422887980938, -0.055351678282022476, 0.12032933533191681, 0.006583342328667641, -0.032646264880895615, 0.1262170672416687, -0.019229944795370102, 0.03265770152211189, -0.005450556054711342, -0.01518398616462946, -0.12719973921775818, 0.020637208595871925, -0.09055553376674652, 0.006171594839543104, 0.02457870915532112, -5.269387474982068e-05, 0.00526978587731719, 0.05881200730800629, -0.05534174293279648, 0.11548715084791183, 0.11052385717630386, -0.08065184950828552, 0.06739936769008636, -0.010251452215015888, 0.06790066510438919, 0.04562527686357498, 0.02238120324909687, 0.06326092034578323, -0.10037622600793839, 0.05767466127872467, -0.0007158430526033044, 0.03152667358517647, 0.09380234777927399, 0.126778706908226, -0.080097496509552, -0.0725087821483612, 0.06337273865938187, -0.13649608194828033, 0.01915454864501953, -0.09436739981174469, 0.01163143664598465, 0.004691264126449823, -0.02685800939798355, 0.0488235168159008, -0.026283476501703262, 0.03898010030388832, -0.05490810424089432, 0.101410873234272, -0.031237173825502396, -0.11853347718715668, 0.04703531786799431, 0.08588914573192596, 0.07712393999099731, 0.05456332117319107, -0.09795203804969788, 0.08573081344366074, 0.0328933522105217, 0.108449786901474, -0.09286133944988251, 0.00021988018124829978, 0.018756955862045288, -0.16604146361351013, -0.04968778416514397, 0.029463883489370346, -0.17001211643218994, -0.045462705194950104, -0.06637296825647354, -0.09227084368467331, 0.15542583167552948, -0.06698879599571228, -0.013905449770390987, 0.006575708277523518, 0.03907039016485214, 0.10037653893232346, 0.004566672258079052, -0.14248459041118622, 1.3083156615736056e-32, -0.08044180274009705, -0.09497977793216705, -0.06148051843047142, -0.06505437940359116, 0.09084336459636688, -0.09755066782236099, -0.1768099069595337, 0.007534646894782782, 0.08937128633260727, 0.0686027854681015, -0.0397111177444458, 0.0877266377210617, -0.02725503407418728, 0.17936895787715912, 0.15698479115962982, -0.04462995380163193, 0.02454637549817562, 0.02680622600018978, -0.10764593631029129, -0.0792117565870285, 0.011919256299734116, 0.06421439349651337, 0.09134478867053986, 0.0021269414573907852, 0.036492720246315, -0.02408246137201786, -0.04560524970293045, -0.05105667933821678, 0.09625070542097092, 0.024533452466130257, -0.0160074420273304, 0.04293512552976608, 0.04513797536492348, 0.07172466814517975, 0.05958344414830208, -0.04632915183901787, 0.007797830738127232, -0.06191025301814079, 0.1045745462179184, 0.016630856320261955, -0.022296709939837456, -0.017500655725598335, 0.12450268119573593, -0.03561455383896828, -0.05544756352901459, 0.018861819058656693, 0.08413249999284744, -0.009678803384304047, -0.10530596971511841, 0.045446544885635376, 5.8040779549628496e-05, -0.04893355071544647, -0.011131222359836102, -0.14791226387023926, -0.10194131731987, 0.09449341148138046, 0.08950851112604141, -0.16063068807125092, -0.00670465175062418, -0.12655237317085266, -0.07946963608264923, -0.024339133873581886, 0.04227374494075775, 0.0031708888709545135, -0.08280026912689209, -0.08224784582853317, 0.004274926148355007, -0.0028392893727868795, 0.02323237992823124, 0.012332209385931492, -0.07061345130205154, 0.1317266970872879, -0.04613528400659561, 0.009390843100845814, 0.020772194489836693, 0.11821863055229187, 0.030916890129446983, 0.12405472993850708, -0.18769724667072296, 0.11089473962783813, 0.041479747742414474, 0.009539918974041939, 0.015442954376339912, -0.06233729422092438, -0.016592470929026604, 0.12291232496500015, 0.08312874287366867, -0.08518320322036743, -0.08841930329799652, -0.018519099801778793, -0.047998279333114624, 0.06047533452510834, -0.09450998902320862, 0.003954099956899881, 0.11100826412439346, -1.1756441528836204e-32, -0.0523470900952816, 0.13453586399555206, -0.08308441936969757, 0.03342607989907265, 0.021953394636511803, 0.08100257813930511, 0.0005274344584904611, 0.006918415427207947, 0.009132026694715023, -0.15361113846302032, -0.09910117089748383, -0.04704904928803444, 0.06573072820901871, -0.04274605214595795, -0.15060454607009888, 0.056951966136693954, -0.0720304623246193, 0.0738554373383522, -0.016321470960974693, 0.03525904193520546, -0.061446789652109146, 0.06323909014463425, -0.19775812327861786, -0.10152526944875717, -0.10106876492500305, 0.1460600197315216, -0.1467025727033615, -0.07297532260417938, -0.04608694091439247, 0.024983154609799385, -0.05532851070165634, -0.02853122539818287, -0.08167269080877304, -0.15424205362796783, -0.09651637822389603, 0.010389677248895168, -0.042183492332696915, -0.08511827886104584, -0.0009495336562395096, 0.06654493510723114, 0.09733204543590546, 0.12323430925607681, -0.0944228544831276, -0.03052425943315029, -0.07047612220048904, -0.16757787764072418, 0.0220628771930933, 0.11431930214166641, 0.026063399389386177, 0.0037543922662734985, -0.04796002805233002, 0.0675288513302803, -0.012219863012433052, 0.010973683558404446, -0.023694658651947975, 0.035854171961545944, 0.0673113614320755, 0.026545589789748192, 0.06733758747577667, 0.08945221453905106, -0.029308121651411057, -0.018604103475809097, 0.005573151633143425, 0.06487219035625458, -0.0634380355477333, -0.15106958150863647, -0.019561156630516052, -0.032700516283512115, -0.039967190474271774, -0.051788728684186935, -0.054754797369241714, -0.020887693390250206, 0.08065611124038696, 0.021922610700130463, -0.0905405655503273, -0.07805681973695755, -0.13838793337345123, 0.11888400465250015, -0.0012578439200296998, -0.006382975727319717, 0.14143791794776917, -0.18586353957653046, 0.002603792818263173, 0.12402227520942688, 0.05273204669356346, 0.10547292232513428, 0.0782955065369606, -0.023108873516321182, 0.058441679924726486, -0.13755112886428833, -0.09183432161808014, -0.07727041095495224, -0.10242170095443726, 0.21120762825012207, 0.0013771898811683059, -9.951288149068205e-08, -0.032692376524209976, -0.10026784986257553, 0.10822923481464386, -0.11850905418395996, 0.136392742395401, -0.059670500457286835, -0.10361340641975403, 0.2563021779060364, -0.030972136184573174, 0.06579328328371048, 0.11775236576795578, 0.013133013620972633, -0.2122538983821869, 0.009124726057052612, -0.03593112900853157, 0.14739343523979187, 0.23549729585647583, 0.024432063102722168, 0.03880588710308075, 0.1482308954000473, -0.0002988831256516278, -0.11059871315956116, 0.006487761624157429, 0.06876417994499207, 0.1367853283882141, -0.11140970885753632, -0.03745359182357788, 0.07722250372171402, 0.0012411263305693865, 0.02891647256910801, -0.09590252488851547, -0.036855295300483704, 0.10638777911663055, 0.004848357755690813, 0.09269856661558151, 0.07200054824352264, -0.014365196228027344, -0.04823747277259827, -0.1712566465139389, -0.12101366370916367, 0.10891640931367874, 0.14580093324184418, -0.053337883204221725, 0.05176779627799988, 0.12398335337638855, 0.008444767445325851, 0.12345606088638306, -0.01698962040245533, 0.07261960208415985, 0.12669077515602112, -0.10714290291070938, -0.004549267701804638, 0.03295331448316574, 0.06806639581918716, 0.008980493992567062, 0.017825376242399216, 0.04475089907646179, -0.06555937975645065, 0.12365058064460754, 0.15052221715450287, 0.020371390506625175, 0.07560137659311295, -0.1102546751499176, -0.036189571022987366], metadata={'source': 'AAAMLP-569to.pdf', 'page': 8}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 9  \\n Figure 2: An unsupervised dataset.  Most of the time, when people start with data science or machine learning, they begin with very well-known datasets, for example, Titanic dataset, or Iris dataset which are supervised problems. In the Titanic dataset, you have to predict the survival of people aboard Titanic based on factors like their ticket class, gender, age, etc. Similarly, in the iris dataset, you have to predict the species of flower based on factors like sepal width, petal length, sepal length and petal width.   Unsupervised datasets may include datasets for customer segmentation. For example, you have data for the customers visiting your e-commerce website or the data for customers visiting a store or a mall, and you would like to segment them or cluster them in different categories. Another example of unsupervised datasets may include things like credit card fraud detection or just clustering several images.  Most of the time, it’s also possible to convert a supervised dataset to unsupervised to see how they look like when plotted.  For example, let’s take a look at the dataset in figure 3. Figure 3 shows MNIST dataset which is a very popular dataset of handwritten digits, and it is a supervised problem in which you are given the images of the numbers and the correct label associated with them. You have to build a model that can identify which digit is it when provided only with the image.   This dataset can easily be converted to an unsupervised setting for basic visualization.'),\n",
       " VectorParams(vector=[-0.10266467183828354, -0.07656536996364594, 0.09946155548095703, -0.13449440896511078, 0.20741485059261322, -0.04745909944176674, -0.044222377240657806, -0.05385064706206322, -0.10653279721736908, -0.009672257117927074, 0.038386981934309006, 0.021920597180724144, 0.27579376101493835, -0.01011440809816122, -0.17722275853157043, 0.0811852216720581, -0.04556764289736748, 0.05149662867188454, -0.05528126284480095, 0.016486642882227898, -0.12612703442573547, -0.03427569940686226, 0.040941666811704636, -0.13287867605686188, 0.252154678106308, -0.016920726746320724, 0.09929756820201874, -0.07957108318805695, 0.008701943792402744, 0.0180356465280056, 0.20253784954547882, 0.034537993371486664, -0.03612936660647392, 0.039075519889593124, 0.015151497907936573, 0.18875709176063538, 0.005236397497355938, 0.180081307888031, -0.11244680732488632, 0.09424550086259842, 0.08792891353368759, 0.025104284286499023, 0.035700973123311996, -0.10577218234539032, 0.07462401688098907, 0.15410512685775757, 0.027133295312523842, -0.1637621968984604, -0.10974317044019699, 0.019884906709194183, -0.09454736113548279, -0.02953425608575344, -0.21236269176006317, 0.17158342897891998, -0.04962022975087166, -0.06789988279342651, 0.04746387153863907, -0.0658101961016655, -0.1186615377664566, 0.0337955467402935, 0.18214569985866547, -0.09414593130350113, -0.027654096484184265, -0.01782919280230999, 0.2315814197063446, -0.10102183371782303, 0.02400660514831543, 0.007505688350647688, 0.09258659929037094, -0.08557034283876419, 0.045688875019550323, 0.0728311687707901, -0.07075603306293488, 0.032253097742795944, -0.10058686137199402, 0.03187905624508858, 0.11900275200605392, -0.042592618614435196, 0.15084625780582428, -0.2318490445613861, 0.03201964870095253, 0.022654816508293152, 0.08657243847846985, -0.07106969505548477, 0.07030083239078522, 0.06859302520751953, -0.12182401865720749, 0.13083641231060028, -0.028273319825530052, -0.00332771148532629, -0.05467512458562851, 0.024808065965771675, -0.0805744156241417, 0.045764461159706116, 0.04250779375433922, -0.12705297768115997, 0.05392569676041603, 0.010884640738368034, -0.017149852588772774, 0.14786435663700104, -0.10252759605646133, -0.023064294829964638, 0.09121732413768768, 0.026440167799592018, 0.12487942725419998, -0.09959622472524643, 0.12604664266109467, -0.05097603797912598, 0.07053699344396591, -0.2363574504852295, 0.028799500316381454, 0.03631402552127838, -0.16754211485385895, 0.10090768337249756, 0.07366183400154114, -0.12572680413722992, 0.0319933146238327, 0.0967549979686737, 0.09325217455625534, -0.05852329358458519, -0.16910181939601898, 0.02867848426103592, -0.06570109724998474, 0.045190852135419846, 0.17317885160446167, -0.04291204363107681, -0.051876250654459, 1.0966197819080659e-32, 0.12371467053890228, -0.0038748334627598524, -0.0029284178745001554, -0.06251794844865799, 0.12322370707988739, 0.04059586673974991, -0.059234198182821274, -0.07571971416473389, 0.002635159995406866, 0.06351859122514725, -0.20110167562961578, -0.08624623715877533, -0.007323561701923609, 0.20405736565589905, -0.08696747571229935, -0.1860499233007431, -0.009607256390154362, 0.04267321154475212, 0.004542832262814045, -0.13743270933628082, 0.004254436586052179, 0.06879784166812897, 0.016124602407217026, 0.04177428036928177, -0.16442236304283142, -0.20078492164611816, 0.1366545855998993, -0.17277255654335022, 0.11888287961483002, 0.05886712297797203, -0.22312219440937042, 0.04575805738568306, -0.03910501301288605, 0.13753460347652435, -0.0050753154791891575, -0.04347173124551773, -0.11610837280750275, 0.0009493283578194678, -0.02048884704709053, -0.09089041501283646, 0.10470757633447647, 0.059895798563957214, -0.005214401986449957, -0.09135107696056366, -0.12564773857593536, -0.008234336972236633, -0.015437206253409386, 0.015131247229874134, -0.026183338835835457, -0.12858958542346954, 0.11487075686454773, 0.031880587339401245, -0.08208337426185608, -0.12356193363666534, -0.04270840436220169, -0.08300838619470596, 0.1630956083536148, 0.035802483558654785, 0.18519887328147888, 0.005233029369264841, -0.052445221692323685, 0.007464311085641384, 0.0042692008428275585, 0.15031889081001282, 0.13221149146556854, 0.12563972175121307, -0.056884072721004486, -0.061799436807632446, -0.0235797967761755, 0.009816709905862808, -0.02622983604669571, 0.10296900570392609, 0.01150419283658266, -0.1629173308610916, 0.03842702507972717, 0.039898794144392014, 0.0284754429012537, 0.014800931327044964, -0.029971893876791, -0.003430084092542529, -0.12554360926151276, -0.02578224055469036, -0.06546381115913391, -0.20354993641376495, -0.15081122517585754, 0.004166812170296907, 0.09668618440628052, -0.231702983379364, -0.06686556339263916, 0.0158719290047884, 0.04005665332078934, 0.008111342787742615, -0.05986747145652771, -0.007097454275935888, 0.00184657983481884, -8.676050500982738e-33, -0.14512428641319275, 0.16679257154464722, 0.07626163214445114, -0.0016816559946164489, -0.054429054260253906, 0.03063860908150673, -0.10741138458251953, 0.061579786241054535, -0.025184983387589455, 0.0369991734623909, 0.060405433177948, -0.12100587785243988, -0.07809722423553467, -0.2429026961326599, -0.09054738283157349, -0.12735959887504578, 0.2701457440853119, 0.022100726142525673, 0.04432891309261322, -0.004002108238637447, -0.040458425879478455, 0.11935406923294067, 0.012033598497509956, 0.059127919375896454, -0.042538419365882874, 0.1837376058101654, 0.0071015567518770695, 0.10907718539237976, 0.02238582633435726, -0.029605433344841003, -0.1312124878168106, -0.2373311072587967, -0.006137317046523094, -0.07873556762933731, -0.05420789122581482, 0.15590082108974457, -0.08827826380729675, 0.02303308993577957, -0.019105780869722366, -0.02523522637784481, 0.14563749730587006, -0.017657365649938583, -0.16601067781448364, 0.19537711143493652, 0.02411588653922081, -0.09157071262598038, -0.18291211128234863, 0.037760794162750244, 0.028954312205314636, -0.000895581382792443, -0.007223787717521191, 0.07435823231935501, -0.020059989765286446, -0.06999354064464569, 0.05307387933135033, 0.014182456769049168, 0.09516315907239914, 0.08391043543815613, 0.10403241962194443, -0.10323533415794373, -0.047146979719400406, -0.20424678921699524, -0.12011117488145828, 0.050878990441560745, 0.0047431206330657005, -0.06495096534490585, -0.08688607066869736, 0.007961212657392025, 0.0551767572760582, 0.1720278561115265, 0.03635099157691002, 0.020021049305796623, 0.06038539484143257, -0.0560394711792469, 0.02807760238647461, -0.16554003953933716, 0.09039270877838135, 0.03327839821577072, 0.09517352283000946, -0.09420077502727509, -0.07267077267169952, -0.05423213168978691, 0.19686836004257202, 0.04214344918727875, 0.17983660101890564, 0.09729675948619843, 0.1215997263789177, -0.11925817281007767, 0.24824023246765137, -0.02616347186267376, 0.0629643052816391, 0.03784962743520737, -0.016094421967864037, 0.14327359199523926, 0.16646575927734375, -9.854821314547735e-08, 0.03299444168806076, -0.05981381610035896, 0.014700804837048054, 0.0008646787027828395, 0.13094447553157806, -0.07674508541822433, 0.0361441895365715, 0.25463777780532837, 0.10836213082075119, -0.018060728907585144, 0.14149309694766998, -0.031121229752898216, -0.12580327689647675, -0.10362984240055084, -0.01962205395102501, -0.03329453617334366, -0.05782511085271835, 0.06263615190982819, -0.02915789932012558, 0.026792356744408607, -0.0580129511654377, -0.04484951123595238, 0.10227682441473007, 0.04197327047586441, -0.06119934469461441, 0.0836767703294754, -0.1563388556241989, 0.06681475788354874, 0.1223979964852333, -0.07048525661230087, -0.024482255801558495, -0.007552536204457283, 0.07243840396404266, 0.007157175336033106, 0.04429517313838005, 0.13651803135871887, -0.0971384048461914, 0.03271755948662758, -0.048712801188230515, -0.06074643135070801, -0.1476433277130127, 0.05482786148786545, 0.03286014124751091, 0.059914812445640564, 0.06842011213302612, 0.02487744763493538, 0.04145706072449684, 0.010433858260512352, 0.014552884735167027, 0.11830070614814758, 0.03710581362247467, -0.009476170875132084, -0.06541849672794342, 0.0704512819647789, 0.07836027443408966, -0.0583471916615963, 0.029363734647631645, -0.10389599949121475, 0.10400617867708206, 0.026465360075235367, -0.08655688166618347, -0.04585226625204086, -0.13560737669467926, -0.1096978411078453], metadata={'source': 'AAAMLP-569to.pdf', 'page': 9}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 10  Figure 3: MNIST dataset1  If we do a t-Distributed Stochastic Neighbour Embedding (t-SNE) decomposition of this dataset, we can see that we can separate the images to some extent just by doing with two components on the image pixels. This is shown in figure 4. \\n Figure 4: t-SNE visualization of the MNIST dataset. 3000 images were used.  Let’s take a look at how this was done. First and foremost is importing all the required libraries.   1 Image source: By Josef Steppan - Own work, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=64810040'),\n",
       " VectorParams(vector=[-0.04243899881839752, -0.1349884420633316, 0.03524662181735039, -0.08184567838907242, 0.18226055800914764, -0.09151512384414673, 0.012875303626060486, 0.0015009300550445914, -0.16875989735126495, 0.059608094394207, -0.07683194428682327, -0.1269746720790863, 0.12461571395397186, -0.06892582029104233, -0.050587791949510574, 0.04123557731509209, -0.13445350527763367, 0.048491161316633224, -0.07211481034755707, 0.01806122250854969, -0.011119978502392769, 0.07573118060827255, -0.025526082143187523, 0.00222363555803895, 0.06554979085922241, 0.060437604784965515, 0.13207082450389862, -0.007341139949858189, -0.17134436964988708, -0.0327284000813961, 0.08653968572616577, 0.06437602639198303, -0.015424656681716442, -0.04837729036808014, 0.03223971277475357, 0.14233870804309845, -0.014035766944289207, 0.10439720749855042, -0.0664861872792244, 0.07362602651119232, 0.01606370136141777, 0.004802599549293518, 0.04956967756152153, -0.049765799194574356, 0.12332337349653244, 0.12944296002388, -0.028340090066194534, -0.17526647448539734, 0.06329301744699478, 0.036175645887851715, -0.09550829976797104, -0.023966126143932343, -0.2076703906059265, 0.0959189161658287, -0.020152069628238678, -0.08565465360879898, -0.004050815012305975, -0.1446463167667389, 0.100887730717659, -0.02765411138534546, -0.01532999612390995, -0.10026683658361435, 0.008310012519359589, -0.02741868607699871, 0.09939819574356079, -0.09270501136779785, -0.006149875000119209, 0.02065512351691723, 0.048758864402770996, -0.017690924927592278, 0.031121719628572464, 0.05407309904694557, -0.00022328575141727924, 0.049793850630521774, -0.06975138187408447, -0.03655300661921501, 0.1721356064081192, -0.019564274698495865, 0.10156255960464478, -0.10568161308765411, -0.005500467028468847, 0.03443250060081482, 0.026796948164701462, -0.018371030688285828, 0.018237115815281868, -0.04955294728279114, -0.045915376394987106, 0.22005441784858704, 0.027676068246364594, -0.0056920102797448635, 0.0364459790289402, 0.025148391723632812, -0.15809649229049683, 0.009500933811068535, 0.08260299265384674, -0.005726886447519064, 0.049348875880241394, 0.05981132760643959, 0.030522936955094337, 0.09589194506406784, 0.032670293003320694, -0.14433054625988007, -0.053144533187150955, 0.05821801722049713, 0.09476925432682037, -0.0211122278124094, 0.20989783108234406, 0.04486973211169243, 0.052261803299188614, -0.12287989258766174, -0.011576595716178417, -0.048496127128601074, -0.13593356311321259, 0.06742445379495621, 0.14996285736560822, 0.018873484805226326, -0.07167160511016846, 0.08139029145240784, -0.16713006794452667, 0.05033920332789421, -0.03933976963162422, 0.016844354569911957, 0.05732978507876396, 0.0540132038295269, 0.017367877066135406, -0.0033946221228688955, -0.18567296862602234, 1.682969221067685e-32, -0.01821717619895935, 0.08745923638343811, 0.028062134981155396, -0.08844572305679321, -0.023594820871949196, -0.06099720299243927, 0.03595301881432533, -0.0001921692310133949, -0.0020701473113149405, 0.09138591587543488, -0.23895086348056793, 0.07813220471143723, -0.011678840033710003, 0.09968695789575577, -0.04365382343530655, -0.0891735628247261, 0.08019519597291946, 0.00990577507764101, -0.07689329236745834, 0.030687730759382248, 0.12142752856016159, 0.055458903312683105, -0.04631584510207176, -0.037950728088617325, -0.12507468461990356, -0.1510559618473053, -0.041908178478479385, 0.008953775279223919, -0.023941857740283012, 0.02152402140200138, -0.11320352554321289, 0.02190643548965454, -0.05084364861249924, -0.0320260114967823, 0.0034398806747049093, -0.2125391811132431, 0.016785945743322372, 0.028676344081759453, -0.04511762410402298, -0.01026198174804449, -0.02852552942931652, 0.1565231829881668, 0.0429321825504303, -0.07114356756210327, -0.041531242430210114, 0.08474282920360565, 0.046349961310625076, 0.15373101830482483, -0.017396563664078712, 0.03856997564435005, 0.020616233348846436, -0.1191154196858406, -0.08949501812458038, 0.004894856363534927, -0.05923735350370407, 0.037022028118371964, 0.09230047464370728, -0.10842385143041611, 0.0678771436214447, 0.010462669655680656, -0.014958150684833527, -0.05918704345822334, 0.12390643358230591, 0.0008104882435873151, 0.08784063160419464, 0.014423511922359467, 0.09158329665660858, -0.010966283269226551, -0.014977745711803436, 0.06507489830255508, -0.11405444890260696, 0.1270296275615692, -0.019241584464907646, -0.14548227190971375, 0.05137450620532036, -0.10415533185005188, -0.017167380079627037, -0.0001681577123235911, -0.13545358180999756, 0.022403784096240997, 0.025925083085894585, 0.05342601239681244, -0.033027783036231995, -0.23857960104942322, -0.1233689934015274, 0.02275189757347107, 0.0599130280315876, -0.15396520495414734, -0.10731644183397293, -0.18304480612277985, -0.1394202709197998, -0.09894296526908875, -0.12597280740737915, -0.10632770508527756, -0.10183386504650116, -1.4532112094861886e-32, 0.05648300051689148, 0.15412403643131256, 0.006060593295842409, 0.05639844387769699, -0.013520247302949429, 0.1057233139872551, 0.05968921259045601, 0.09259055554866791, -0.04701817408204079, -0.08670487254858017, 0.019394243136048317, -0.11752863973379135, 0.055539656430482864, -0.10422618687152863, 0.060196518898010254, -0.034531548619270325, -0.0036850746255367994, 0.03558631241321564, -0.010069942101836205, -0.056715190410614014, -0.1544160693883896, 0.08524459600448608, -0.06616292893886566, -0.05428019165992737, -0.12464853376150131, 0.1412186175584793, -0.08306045830249786, 0.12505406141281128, -0.020539863035082817, -0.07672449946403503, -0.05721169710159302, -0.08637457340955734, -0.14738363027572632, -0.030681705102324486, 0.059266723692417145, 0.1401095688343048, 0.08372493088245392, -0.10246657580137253, -0.11159764230251312, 0.0046903472393751144, 0.15121009945869446, 0.08625305444002151, -0.09874797612428665, 0.057230398058891296, -0.054372869431972504, -0.022415000945329666, -0.013813687488436699, 0.14136387407779694, 0.04576661437749863, 0.028892485424876213, 0.04333678260445595, 0.031161917373538017, -0.0373711921274662, -0.07380269467830658, 0.0012198437470942736, -0.011862233281135559, -0.06672611087560654, 0.05244234949350357, -0.05156221240758896, -0.08105674386024475, -0.04564416781067848, -0.17964144051074982, -0.09275879710912704, 0.02785286121070385, 0.027807585895061493, 0.016566341742873192, -0.1387404352426529, -0.03356606140732765, 0.0010544905671849847, 0.15905269980430603, -0.09746411442756653, -0.06784136593341827, 0.10963620245456696, -0.06194289028644562, -0.031062746420502663, -0.09278810024261475, -0.09352496266365051, -0.032162196934223175, 0.0018590778345242143, 0.060362812131643295, 0.09120919555425644, -0.05172815918922424, 0.18843239545822144, 0.20051494240760803, 0.0833846777677536, 0.12105686962604523, 0.1366027593612671, 0.001359419897198677, 0.15777404606342316, -0.08266593515872955, 0.03504972904920578, -0.0521683506667614, 0.041111983358860016, 0.19370155036449432, 0.0577271468937397, -1.0002205641512774e-07, 0.05909936875104904, -0.01596757397055626, 0.03684048354625702, 0.05662763491272926, -0.008804245851933956, 0.03509091958403587, -0.11714999377727509, 0.09811006486415863, 0.030533911660313606, 0.0324227511882782, 0.09772329032421112, -0.0556599386036396, -0.052144769579172134, 0.016256973147392273, -0.026520412415266037, 0.1332823485136032, 0.08875875174999237, -0.07847470790147781, 0.005110646598041058, 0.09404850006103516, 0.043111834675073624, -0.047819823026657104, 0.014530269429087639, 0.02333124354481697, -0.005090574733912945, 0.03845128417015076, -0.09751977771520615, 0.10503607243299484, 0.06544996052980423, 0.005335751920938492, -0.01449951808899641, -0.17420125007629395, 0.07966787368059158, 0.09327691793441772, 0.1722903847694397, 0.06221817061305046, -0.13760952651500702, 0.03877347707748413, 0.041296232491731644, 0.07495909184217453, -0.17666727304458618, 0.13530512154102325, -0.03394417464733124, 0.020788170397281647, 0.11957427859306335, -0.012004139833152294, 0.008036738261580467, -0.012122614309191704, 0.0863054096698761, 0.053423140197992325, -0.025136029347777367, 0.03304152935743332, -0.027080412954092026, 0.0645221471786499, 0.19875140488147736, -0.06489010900259018, -0.08279818296432495, -0.023343561217188835, 0.06899913400411606, 0.0853845551609993, -0.04880043491721153, -0.022097736597061157, -0.08160056173801422, -0.10970290005207062], metadata={'source': 'AAAMLP-569to.pdf', 'page': 10}, content=\"Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 11 ═════════════════════════════════════════════════════════════════════════ import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns  from sklearn import datasets from sklearn import manifold  %matplotlib inline ═════════════════════════════════════════════════════════════════════════  We use matplotlib and seaborn for plotting, numpy to handle the numerical arrays, pandas to create dataframes from the numerical arrays and scikit-learn (sklearn) to get the data and perform t-SNE.  After the imports, we need to either download the data and read it separately or use sklearn’s built-in function that provides us with the MNIST dataset.  ═════════════════════════════════════════════════════════════════════════ data = datasets.fetch_openml(                   'mnist_784',                    version=1,                    return_X_y=True ) pixel_values, targets = data targets = targets.astype(int) ═════════════════════════════════════════════════════════════════════════  In this part of the code, we have fetched the data using sklearn datasets, and we have an array of pixel values and another array of targets. Since the targets are of string type, we convert them to integers.  pixel_values is a 2-dimensional array of shape 70000x784. There are 70000 different images, each of size 28x28 pixels. Flattening 28x28 gives 784 data points.  We can visualize the samples in this dataset by reshaping them to their original shape and then plotting them using matplotlib.  ═════════════════════════════════════════════════════════════════════════ single_image = pixel_values[1, :].reshape(28, 28)  plt.imshow(single_image, cmap='gray') ═════════════════════════════════════════════════════════════════════════\"),\n",
       " VectorParams(vector=[-0.04310821741819382, -0.12537311017513275, 0.009918760508298874, -0.10668865591287613, 0.17045767605304718, -0.12858539819717407, -0.07358463108539581, -0.026802515611052513, -0.09977855533361435, 0.061733245849609375, -0.07468289881944656, -0.02757907286286354, 0.08522001653909683, -0.029344281181693077, -0.03171883895993233, 0.0882861316204071, -0.09972945600748062, 0.06968838721513748, -0.06525788456201553, -4.379206075100228e-05, 0.051534466445446014, 0.06545418500900269, 0.014262146316468716, -0.026160167530179024, 0.10089488327503204, -0.03812429681420326, 0.2067755162715912, -0.01579323783516884, -0.09898203611373901, 0.02221103012561798, 0.034647028893232346, 0.04385318234562874, -0.1752842664718628, -0.02740897424519062, -0.0838974118232727, 0.12000599503517151, -0.010041207075119019, 0.18943999707698822, -0.01592458412051201, 0.07520826905965805, 0.04213171824812889, 0.03106844052672386, -0.01160457544028759, -0.1083720475435257, 0.1421440690755844, 0.0913238674402237, -0.10456930100917816, -0.14014025032520294, 0.03354819118976593, 0.01808970794081688, -0.08930238336324692, -0.004784628748893738, -0.22805510461330414, 0.09814783930778503, -0.024805452674627304, -0.08057259023189545, 0.03747956454753876, -0.11435045301914215, 0.07850433886051178, -0.01257377676665783, 0.04181097075343132, -0.0444355383515358, 0.05635635182261467, -0.034827686846256256, 0.16996020078659058, -0.05002415180206299, 0.01455115806311369, -0.008692762814462185, 0.023939263075590134, 0.05765126645565033, -0.04131437465548515, 0.032388199120759964, -0.005210281349718571, 0.024700883775949478, -0.056364886462688446, -0.0863775759935379, 0.06015912815928459, 0.04250798374414444, 0.1272125095129013, -0.08305465430021286, 0.029673250392079353, 0.07045003771781921, 0.034779373556375504, 0.051316238939762115, -0.02220151759684086, 0.00525569636374712, -0.07529613375663757, 0.13788293302059174, 0.006735389586538076, 0.0058691552840173244, 0.025917934253811836, -0.0020143231377005577, -0.07697127014398575, 0.026650141924619675, 0.06366276741027832, 0.013933544047176838, 0.08598504215478897, 0.025277182459831238, 0.05893484130501747, -0.013826847076416016, -0.005591636057943106, -0.1380847990512848, -0.029293781146407127, 0.04421060159802437, 0.02054484374821186, -0.060505159199237823, 0.16044728457927704, -0.004667370580136776, 0.0897952988743782, -0.1426761895418167, 0.001980106346309185, -0.07280194759368896, -0.1495753675699234, 0.03037896379828453, 0.07533460855484009, -0.07663208246231079, -0.15659663081169128, 0.04268137365579605, -0.08956275135278702, -0.0018281020456925035, -0.08016551285982132, 0.08729811012744904, -0.0630469024181366, 0.10534253716468811, -0.028452789410948753, 0.01210511289536953, -0.1534474641084671, 9.734573613006607e-33, -0.022261900827288628, 0.0781564712524414, -0.006860374007374048, 0.0006526565412059426, 0.015079179778695107, -0.0162041075527668, -0.01938672922551632, -0.09102515876293182, 0.0437246672809124, 0.13815949857234955, -0.2573045790195465, -0.006917669903486967, -0.002499673515558243, 0.11626067012548447, -0.055678173899650574, -0.16154032945632935, 0.05135223641991615, 0.09492850303649902, -0.02056337147951126, 0.009379708208143711, 0.08265425264835358, 0.09574483335018158, 0.00722490856423974, 0.02000042423605919, -0.056795958429574966, -0.11562984436750412, -0.13148869574069977, 0.06248003989458084, -0.05646077170968056, -0.00017157592810690403, -0.22600789368152618, 0.08244042098522186, -0.03813626989722252, -0.06587577611207962, 0.04346083849668503, -0.24102164804935455, 0.0222807414829731, 0.05932021886110306, 0.012468216940760612, -0.050912536680698395, -0.01333162933588028, 0.06911752372980118, -0.05403376370668411, -0.012135626748204231, -0.0963468924164772, 0.06640718132257462, 0.0055449469946324825, 0.097721166908741, -0.017955999821424484, -0.07066378742456436, -0.0003552348061930388, -0.042832281440496445, 0.013467823155224323, -0.06114494800567627, -0.03606441989541054, 0.013056282885372639, 0.1303938776254654, -0.15718582272529602, 0.13039880990982056, 0.011138374917209148, 0.005339448340237141, -0.023909740149974823, 0.0674843043088913, 0.08798656612634659, 0.05370449274778366, 0.07108671963214874, 0.036021944135427475, 0.0015644695376977324, -0.005039302632212639, 0.0751558393239975, -0.047986023128032684, 0.1718876212835312, -0.029053620994091034, -0.11603503674268723, 0.15426130592823029, -0.053609076887369156, 0.07333066314458847, 0.042565930634737015, -0.1707995980978012, -0.020099332556128502, -0.06711705029010773, 0.04542586952447891, -0.012775863520801067, -0.27589190006256104, -0.10678289830684662, -0.019285570830106735, 0.02902686968445778, -0.18709643185138702, -0.1723349541425705, -0.07461504638195038, -0.04656488820910454, -0.09263122826814651, -0.12012206763029099, 0.0665135607123375, -0.040461864322423935, -9.971861106715502e-33, -0.022245807573199272, 0.1718587577342987, 0.05738120898604393, 0.021387729793787003, -0.042232315987348557, 0.045905422419309616, 0.05841563642024994, 0.030765848234295845, 0.09259762614965439, -0.08039799332618713, 0.004806465934962034, -0.09619273245334625, -0.01648939587175846, -0.0904046967625618, 0.0037283911369740963, 0.04374941065907478, 0.05712350830435753, -0.0012821065029129386, -0.08763483911752701, -0.13413973152637482, -0.01418919488787651, 0.1176133006811142, -0.16329289972782135, -0.013459811918437481, -0.16263218224048615, 0.1714269369840622, 0.002783525502309203, 0.020579764619469643, -0.005635449197143316, -0.04138979688286781, -0.08639129996299744, -0.1262633204460144, -0.05301215872168541, 0.056013427674770355, -0.014705214649438858, 0.16131417453289032, 0.12508833408355713, -0.07975936681032181, -0.08027757704257965, -0.04771123081445694, 0.11949607729911804, 0.0423537939786911, -0.11041765660047531, 0.18540538847446442, -0.015069914981722832, -0.0160656850785017, 0.0882440134882927, 0.07188525050878525, 0.021150296553969383, -0.009180503897368908, 0.04490029811859131, 0.026990190148353577, 0.06513643264770508, -0.059605471789836884, 0.0017079476965591311, -0.016726873815059662, -0.03512261435389519, -0.042601704597473145, 0.044173985719680786, -0.10098834335803986, -0.06864474713802338, -0.13954563438892365, -0.030482448637485504, 0.03669825568795204, -0.014575810171663761, 0.08806922286748886, -0.12202661484479904, -0.040071751922369, 0.02193516679108143, 0.17899960279464722, 0.055188849568367004, -0.03723444789648056, 0.049430426210165024, -0.054989054799079895, -0.063968226313591, -0.13413845002651215, -0.00410353671759367, -0.017196154221892357, -0.050098568201065063, 0.04193739965558052, 0.015648147091269493, -0.12650109827518463, 0.1781434565782547, 0.14142219722270966, 0.02025946043431759, 0.18199923634529114, 0.09558079391717911, 0.02645987831056118, 0.13652899861335754, 0.024673528969287872, 0.01663126051425934, -0.04334675893187523, -0.0701342225074768, 0.168844535946846, 0.1573249101638794, -1.0004688988374255e-07, -0.004331707023084164, -0.00717830890789628, 0.02189650945365429, -0.006866570562124252, 0.06174313277006149, 0.03884592652320862, 0.008971474133431911, 0.2023516297340393, 0.056781284511089325, 0.009062261320650578, 0.029923638328909874, -0.030314644798636436, -0.02753697708249092, -0.05737509950995445, -0.03196091949939728, 0.044164255261421204, 0.015776192769408226, -0.03851562738418579, 0.0224080178886652, -0.0061446609906852245, -0.053556863218545914, -0.06628728657960892, -0.01112371776252985, -0.028868062421679497, 0.03335883840918541, -0.0756831094622612, -0.15319982171058655, 0.08841180056333542, 0.045409783720970154, -0.014162769541144371, -0.04143354669213295, -0.15021157264709473, 0.029325883835554123, 0.11022139340639114, 0.13753516972064972, 0.0347067192196846, -0.01541121955960989, 0.02102796919643879, -0.04256409779191017, 0.03468256816267967, -0.19888047873973846, 0.1385699361562729, 0.005369659047573805, 0.05478467792272568, 0.0790579617023468, 0.1003304049372673, -0.02460671216249466, -0.03652343526482582, 0.13082586228847504, 0.04013577476143837, 0.06863167881965637, -0.005136551801115274, -0.05163121595978737, 0.12450286000967026, 0.13556623458862305, -0.06811650842428207, -0.13993816077709198, 0.036866579204797745, 0.06534255295991898, 0.0205686055123806, -0.0382530651986599, 0.09089802205562592, -0.06593770533800125, -0.12681902945041656], metadata={'source': 'AAAMLP-569to.pdf', 'page': 11}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 12 This code will plot an image like the following:  \\n Figure 5: Plotting a single image from MNIST dataset.  The most important step comes after we have grabbed the data.  ═════════════════════════════════════════════════════════════════════════ tsne = manifold.TSNE(n_components=2, random_state=42)  transformed_data = tsne.fit_transform(pixel_values[:3000, :]) ═════════════════════════════════════════════════════════════════════════  This step creates the t-SNE transformation of the data. We use only two components as we can visualize them well in a two-dimensional setting. The transformed_data, in this case, is an array of shape 3000x2 (3000 rows and 2 columns). A data like this can be converted to a pandas dataframe by calling pd.DataFrame on the array.  ═════════════════════════════════════════════════════════════════════════ tsne_df = pd.DataFrame(     np.column_stack((transformed_data, targets[:3000])),      columns=[\"x\", \"y\", \"targets\"] )  tsne_df.loc[:, \"targets\"] = tsne_df.targets.astype(int) ═════════════════════════════════════════════════════════════════════════ Here we are creating a pandas dataframe from a numpy array. There are three columns: x, y and targets. x and y are the two components from t-SNE decomposition and targets is the actual number. This gives us a dataframe which looks like the one shown in figure 6.'),\n",
       " VectorParams(vector=[-0.04471184313297272, -0.08464404940605164, -0.00046248151920735836, -0.0498637892305851, 0.24464692175388336, -0.009335004724562168, -0.05379628390073776, -0.021098917350172997, -0.0729302316904068, 0.06571392714977264, -0.06810381263494492, -0.1592138111591339, 0.13043096661567688, -0.041585635393857956, -0.059593986719846725, -0.07135991752147675, 0.09484709054231644, -0.028303246945142746, -0.06026454269886017, -0.11323706060647964, 0.04547892138361931, -0.057968441396951675, 0.13108278810977936, 0.013943195343017578, 0.046246737241744995, -0.02092842571437359, 0.0635482519865036, -0.020431650802493095, -0.07908524572849274, 0.02886032871901989, 0.012951786629855633, 0.11022283136844635, -0.053660739213228226, 0.017562100663781166, -0.011565521359443665, 0.13769429922103882, 0.0277318824082613, 0.19948340952396393, -0.1382914036512375, 0.1340930312871933, -0.04214658588171005, -0.0442265048623085, -0.05338104069232941, -0.11280199140310287, 0.10456099361181259, 0.08193158358335495, -0.17266418039798737, -0.06814420223236084, -0.07934338599443436, -0.09022916853427887, -0.03920017182826996, -0.012522292323410511, -0.20820043981075287, 0.09794382750988007, -0.07230858504772186, -0.1025402769446373, 0.01223992183804512, -0.14467285573482513, 0.11108808219432831, -0.10792780667543411, 0.01415468379855156, -0.16494610905647278, 0.08485672622919083, -0.0541420616209507, 0.08233048766851425, -0.005897402763366699, 0.036388445645570755, 0.06133126839995384, 0.04596882686018944, 0.10297232121229172, 0.0839187279343605, 0.09624746441841125, -0.07454396039247513, 0.08271042257547379, -0.09422473609447479, 0.09067726135253906, 0.1141216903924942, -0.0666794404387474, -0.010863305069506168, -0.05086439102888107, 0.05069922283291817, 0.10247185081243515, -0.013718518428504467, 0.053700365126132965, 0.07613468915224075, -0.06641959398984909, -0.2084898054599762, 0.08079183101654053, 0.028995556756854057, -0.009401368908584118, 0.08805304765701294, 0.05237455293536186, -0.00938192754983902, -0.06213197857141495, 0.017025571316480637, -0.006391745992004871, 0.06945797801017761, 0.038155604153871536, 0.09141400456428528, 0.0682501420378685, -0.08499400317668915, -0.06539610028266907, 0.05848062410950661, -0.07212119549512863, 0.10393480956554413, -0.024042431265115738, 0.09372221678495407, 0.0061424546875059605, 0.21997132897377014, -0.07491602748632431, 0.00028310302877798676, -0.02341022901237011, -0.2193821668624878, 0.061874207109212875, 0.050398945808410645, -0.019639184698462486, 0.039755679666996, 0.06605304777622223, -0.03537095710635185, 0.04661206528544426, 0.0019789449870586395, -0.0018582758493721485, 0.09883677214384079, 0.07323805242776871, 0.18869955837726593, -0.018561549484729767, -0.18349146842956543, 6.950050839835265e-33, 0.0375027060508728, -0.007357052993029356, 0.007227638270705938, -0.09703405201435089, 0.010775079019367695, -0.11547364294528961, -0.041832778602838516, -0.03004980832338333, 0.05869961157441139, 0.07471981644630432, -0.19573955237865448, 0.15023671090602875, -0.012980856001377106, 0.06453756242990494, 0.11675563454627991, -0.10217775404453278, 0.05088895186781883, -0.004774000030010939, -0.18851281702518463, -0.11164025962352753, 0.08421041816473007, 0.04248954728245735, 0.05744091421365738, -0.01792052946984768, -0.12662619352340698, -0.05934549495577812, 0.0008439182420261204, -0.12768316268920898, 0.008345741778612137, 0.04405146464705467, -0.1437770128250122, 0.012166430242359638, 0.0146989980712533, 0.06169770658016205, 0.06575603038072586, -0.04022965580224991, -0.10150608420372009, -0.04309869930148125, 0.084500752389431, -0.0927722305059433, -0.07849133759737015, 0.01897529512643814, 0.041802432388067245, -0.08313413709402084, 0.057009924203157425, 0.08800960332155228, 0.04031001776456833, -0.006867286283522844, 0.05697545036673546, -0.03734515979886055, 0.011913918890058994, -0.11731217801570892, 0.041826993227005005, -0.004175360780209303, -0.03320914879441261, 0.14449647068977356, 0.08478017151355743, -0.0983031764626503, 0.1481957882642746, 0.002854493446648121, 0.005626554600894451, -0.15493597090244293, 0.009380352683365345, 0.02939128689467907, -0.02906588651239872, 0.06940517574548721, -0.0423504039645195, 0.0594678595662117, -0.019654598087072372, 0.003538492601364851, -0.07002685964107513, 0.17751678824424744, -0.013722714968025684, 0.016606196761131287, 0.10171542316675186, 0.0663243979215622, 0.07446056604385376, 0.1344207227230072, -0.2443484663963318, 0.03913484886288643, 0.06796733289957047, 0.01724180020391941, -0.21547892689704895, -0.20405249297618866, -0.023435235023498535, 0.005715806502848864, 0.05209081247448921, -0.12797480821609497, -0.1048312857747078, -0.04619796201586723, -0.013557009398937225, 0.0036914467345923185, -0.018921708688139915, -0.025606034323573112, -0.0603373683989048, -8.30207358542435e-33, -0.05599744990468025, 0.14479637145996094, -0.016607768833637238, 0.11556775867938995, -0.025401586666703224, 0.0896618440747261, 0.03669347986578941, 0.11967325210571289, -0.03357090801000595, -0.1026485487818718, -0.062433578073978424, -0.12636996805667877, 0.039887528866529465, -0.0719703882932663, -0.05638812109827995, 0.06413480639457703, 0.029134787619113922, 0.14352229237556458, -0.020876633003354073, -0.03485419228672981, -0.11422596126794815, 0.06645454466342926, -0.09361013025045395, -0.1168798878788948, -0.08555372804403305, 0.11897023767232895, -0.09613532572984695, -0.051196373999118805, -0.14295783638954163, 0.015564942732453346, 0.027462752535939217, -0.03750811517238617, -0.12489815801382065, 0.04869871586561203, 0.02851565182209015, 0.05734865367412567, 0.04749295860528946, -0.11063311994075775, -0.0842924416065216, -0.016002222895622253, 0.10579695552587509, 0.04932614788413048, -0.11041708290576935, 0.08212209492921829, -0.03386227786540985, -0.035968732088804245, -0.06234566122293472, 0.042124006897211075, 0.023878401145339012, -0.11854610592126846, 0.015424967743456364, -0.04307931661605835, 0.003021839540451765, 0.005932353436946869, 0.04578394442796707, 0.017264770343899727, 0.047559384256601334, 0.07704761624336243, -0.07790206372737885, -0.05930553004145622, -0.047203533351421356, -0.12728667259216309, -0.14858107268810272, 0.13673482835292816, -0.07441487163305283, -0.0477532222867012, -0.02504653111100197, 0.02161814086139202, 0.0394037589430809, 0.03206707164645195, -0.10411864519119263, -0.024066653102636337, 0.036208972334861755, -0.058015499264001846, -0.10604513436555862, 0.023088987916707993, 0.0011259735329076648, 0.01679948717355728, -0.059346262365579605, 0.005014107096940279, -0.021412285044789314, -0.1503482609987259, 0.0007046438986435533, 0.10632983595132828, 0.007049939129501581, 0.12085419148206711, 0.18871277570724487, 0.016608020290732384, 0.07245573401451111, -0.046928372234106064, -0.023983532562851906, -0.05736352130770683, 0.034995805472135544, 0.2088398039340973, 0.08142711967229843, -9.98888651793095e-08, -0.014837464317679405, -0.07602852582931519, 0.03181128948926926, -0.15789395570755005, 0.13350363075733185, 0.007580132223665714, -0.017990002408623695, 0.20673325657844543, -0.13593129813671112, 0.0047676051035523415, 0.16764654219150543, -0.02754458785057068, -0.12091818451881409, 0.021126095205545425, -0.08339124172925949, 0.052074167877435684, 0.0604066476225853, 0.08780218660831451, -0.0007044447120279074, 0.11635813862085342, 0.04249396175146103, -0.09995460510253906, 0.0440237782895565, 0.06795620173215866, 0.001620378578081727, -0.035441167652606964, -0.06769412755966187, 0.072672538459301, -0.06361468136310577, -0.0313783697783947, -0.11929983645677567, -0.14493298530578613, 0.01603107713162899, 0.08053235709667206, 0.1398821920156479, 0.1028069332242012, -0.15803848206996918, 0.008489198982715607, -0.03138667345046997, 0.1201958954334259, -0.017873674631118774, 0.24639427661895752, -0.047336727380752563, -0.042983528226614, 0.10030966997146606, 0.12316742539405823, 0.03843533620238304, 0.02696692943572998, 0.02876395359635353, -0.005571280140429735, -0.08218821883201599, -0.04003334790468216, -0.13745763897895813, 0.07079924643039703, 0.09009543806314468, -0.030786745250225067, -0.1460638791322708, -0.0440615639090538, 0.16063463687896729, -0.018543114885687828, 0.1408938765525818, 0.04284001886844635, -0.007646918762475252, -0.011318925768136978], metadata={'source': 'AAAMLP-569to.pdf', 'page': 12}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 13  Figure 6: First 10 rows of pandas dataframe with t-SNE components and targets.  And finally, we can plot it using seaborn and matplotlib.  ═════════════════════════════════════════════════════════════════════════ grid = sns.FacetGrid(tsne_df, hue=\"targets\", size=8)  grid.map(plt.scatter, \"x\", \"y\").add_legend() ═════════════════════════════════════════════════════════════════════════  This is one way of visualizing unsupervised datasets. We can also do k-means clustering on the same dataset and see how it performs in an unsupervised setting. One question that arises all the time is how to find the optimal number of clusters in k-means clustering. Well, there is no right answer. You have to find the number by cross-validation. Cross-validation will be discussed later in this book. Please note that the above code was run in a jupyter notebook.   In this book, we will use jupyter for simple things like the example above and for plotting. For most of the stuff in this book, we will be using python scripts. You can choose what you want to use since the results are going to be the same.   MNIST is a supervised classification problem, and we converted it to an unsupervised problem only to check if it gives any kind of good results and it is apparent that we do get good results with decomposition with t-SNE. The results would be even better if we use classification algorithms. What are they and how to use them? Let’s look at them in the next chapters.'),\n",
       " VectorParams(vector=[-0.08183693885803223, -0.12522196769714355, 0.006362689658999443, 0.055346570909023285, 0.17206989228725433, 0.060758281499147415, -0.09787184745073318, 0.08141810446977615, -0.05039847642183304, -0.07276196032762527, -0.11758285015821457, -0.031726863235235214, -0.01904461346566677, -0.10533640533685684, -0.11761177331209183, -0.005169203504920006, 0.07459761202335358, -0.05121152848005295, -0.2121918946504593, -0.08860740810632706, 0.10489050298929214, -0.09258610010147095, -0.06652253121137619, 0.11777562648057938, -0.0846773162484169, 0.02709873579442501, -0.0930255725979805, 0.05068033188581467, -0.19944317638874054, -0.06043284013867378, 0.09369593113660812, 0.06741958856582642, -0.06874462217092514, -0.11128818243741989, -0.09564812481403351, -0.06577558070421219, 0.07258348912000656, -0.026551803573966026, -0.008170008659362793, 0.09362940490245819, 0.0015481555601581931, 0.014915852807462215, 0.0013596125645563006, 0.16351233422756195, 0.1428252011537552, 0.04087946191430092, -0.0603523775935173, -0.16644243896007538, -0.0018903742311522365, 0.07488583773374557, -0.18800325691699982, -0.0008789681596681476, -0.02610057033598423, -0.051814183592796326, 0.056539278477430344, -0.09025111794471741, -0.0503990575671196, 0.08166196197271347, -0.06472732126712799, -0.043770939111709595, -0.0033286113757640123, -0.20262128114700317, -0.07591434568166733, 0.04673982411623001, 0.005015010479837656, -0.08227762579917908, -0.032161202281713486, 0.05768531188368797, -0.13523435592651367, -0.042347054928541183, -0.10151968896389008, 0.10039009153842926, 0.02696704864501953, 0.10780040174722672, 0.08596119284629822, 0.0651603490114212, 0.0866064727306366, 0.006551068741828203, -0.06911072134971619, -0.035301871597766876, -0.011795642785727978, 0.1636158525943756, -0.045884471386671066, -0.01300968136638403, 0.14784052968025208, -0.09031204879283905, -0.04087156057357788, -0.07581586390733719, -0.0344524160027504, 0.05526744946837425, 0.13197724521160126, -0.06315316259860992, 0.025211161002516747, -0.0056435116566717625, 0.048175688832998276, 0.2302531898021698, 0.024830467998981476, -0.08250752836465836, -0.034667227417230606, -0.020362816751003265, -0.1445307433605194, 0.18406927585601807, 0.10068628191947937, -0.036868806928396225, 0.1197885125875473, -0.03012344054877758, -0.05601198226213455, 0.05687286704778671, 0.16390058398246765, -0.08440350741147995, 0.035342730581760406, 0.06145347282290459, -0.027506420388817787, -0.12079077959060669, 0.0892333984375, 0.12551607191562653, -0.060421422123909, -0.03189175948500633, -0.10162883251905441, 0.08762172609567642, -0.183527871966362, 0.04021458327770233, 0.13561652600765228, -0.0013525472022593021, 0.020750902593135834, -0.08724091947078705, -0.09987428784370422, 4.986643196807937e-33, -0.08136331290006638, -0.011166451498866081, -0.009972311556339264, -0.010110577568411827, -0.023306120187044144, -0.2027222067117691, -0.09225005656480789, 0.009666193276643753, 0.07115428149700165, 0.029528846964240074, -0.05096961930394173, -0.004562918096780777, -0.16607436537742615, 0.019258780404925346, 0.18291500210762024, 0.1457834243774414, -0.0017444283002987504, -0.06179463118314743, -0.09059225767850876, -0.0068693323992192745, 0.05595256760716438, -0.18991996347904205, 0.021542692556977272, 0.06549237668514252, -0.16640564799308777, 0.11092589050531387, 0.1406601220369339, 0.1214909628033638, -0.16807903349399567, 0.029404444620013237, 0.03558181971311569, 0.023927900940179825, 0.10937654972076416, 0.09332706779241562, -0.004932851530611515, -0.03337793052196503, -0.15459786355495453, -0.023107701912522316, 0.1307220757007599, 0.07658786326646805, -0.06741520017385483, 0.050590526312589645, 0.08669686317443848, 0.13858281075954437, 0.09191562235355377, -0.06446653604507446, 0.014072689227759838, -0.0640784204006195, -0.07425671070814133, 0.08160346746444702, -0.13069197535514832, 0.0023979214020073414, 0.03556953743100166, 0.13939924538135529, -0.18746672570705414, 0.16137662529945374, -0.002261294052004814, -0.025866936892271042, -0.07387463748455048, -0.0820557251572609, 0.008280460722744465, -0.015967901796102524, -0.03661452606320381, 0.008577263914048672, -0.13826118409633636, 0.018590183928608894, -0.04291318729519844, -0.04969990998506546, 0.05074519291520119, -0.03844976797699928, -0.03574955463409424, -0.02932526171207428, -0.11630044132471085, 0.04595115780830383, 0.10807923227548599, -0.1057899221777916, 0.08827667683362961, 0.024603450670838356, 0.07300664484500885, 0.025390630587935448, -0.08677097409963608, 0.09532956779003143, -0.09611552953720093, -0.17280125617980957, -0.21847525238990784, -0.04280403256416321, 0.006272946484386921, -0.09261035919189453, -0.01975552923977375, -0.03919677808880806, -0.14583633840084076, 0.05721662566065788, 0.01258707046508789, -0.05691646784543991, 0.03974536433815956, -7.783936981416995e-33, 0.06799422949552536, -0.08843958377838135, 0.07122881710529327, 0.1470201462507248, 0.01021489780396223, -0.04543378949165344, -0.06901150941848755, -0.07437293976545334, -0.027936343103647232, -0.11030856519937515, 0.027578433975577354, 0.08037376403808594, 0.007320863660424948, -0.022562310099601746, -0.089959517121315, 0.11566005647182465, 0.008106430061161518, 0.11184745281934738, 0.06797786802053452, -0.05959263816475868, 0.08551586419343948, 0.21144825220108032, -0.08851167559623718, 0.0753621906042099, -0.056583795696496964, 0.0057575395330786705, -0.16847984492778778, -0.046191923320293427, 0.10449261218309402, 0.06310322880744934, 0.11283446103334427, -0.031086565926671028, -0.07443418353796005, -0.02959783934056759, 0.027534162625670433, 0.038515761494636536, 0.05114395171403885, -0.03450022637844086, -0.02791621908545494, 0.27234959602355957, 0.15199244022369385, 0.050760164856910706, -0.2080565243959427, -0.05960391089320183, 0.05692499876022339, 0.09586235135793686, -0.17021426558494568, -0.09315379709005356, 0.13758346438407898, -0.11827098578214645, 0.16088393330574036, 0.0722634568810463, 0.037907037883996964, 0.13949985802173615, 0.0779811441898346, 0.06213158741593361, -0.06230516359210014, 0.07293985784053802, -0.06168683245778084, 0.09920597076416016, -0.00783450249582529, 0.11218270659446716, -0.027184423059225082, -0.015524598769843578, -0.05438676103949547, 0.124610036611557, 0.02640506438910961, 0.0768335610628128, 0.0962054431438446, -0.060838647186756134, -0.11651607602834702, -0.06628159433603287, -0.054845694452524185, 0.05545150861144066, -0.1659773588180542, -0.033800095319747925, -0.12003310024738312, -0.08943669497966766, -0.09246983379125595, 0.06373506039381027, -0.06831474602222443, -0.12398745864629745, -0.07844910770654678, 0.18954859673976898, 0.09481905400753021, 0.058826956897974014, 0.05509534105658531, 0.004812211729586124, -0.11889252066612244, -0.14400027692317963, -0.06643369048833847, 0.014477837830781937, -0.11503404378890991, 0.09789646416902542, -0.1315499097108841, -9.97597595642219e-08, 0.0333356149494648, -0.0659191831946373, 0.11725448817014694, 0.08226223289966583, 0.03188725560903549, -0.07780968397855759, -0.047941431403160095, 0.08766694366931915, -0.04479973018169403, 0.09168817847967148, 0.015051471069455147, 0.10542237758636475, -0.08546598255634308, 0.0608254112303257, 0.03232451528310776, 0.07643437385559082, -0.03412893787026405, 0.12880711257457733, -0.03447066619992256, 0.19258441030979156, 0.0752408355474472, -0.10727814584970474, -0.02803504280745983, -0.07731093466281891, 0.17785853147506714, -0.21017800271511078, -0.04807145521044731, 0.0970546305179596, 0.014162614941596985, 0.13033628463745117, 0.031439509242773056, -0.007593105547130108, 0.10110162198543549, 0.057513944804668427, 0.045190855860710144, 0.11995957791805267, 0.03650517761707306, -0.10937025398015976, -0.10308021306991577, 0.09209292382001877, -0.0979817658662796, 0.10990656167268753, -0.13447479903697968, -0.0017023517284542322, 0.1289200633764267, -0.04075734689831734, 0.12458532303571701, 0.03128998354077339, -0.10148541629314423, 0.009954526089131832, 0.11177792400121689, 0.06650447845458984, 0.11429417878389359, 0.08086798340082169, 0.024700673297047615, 0.032930873334407806, 0.022937646135687828, -0.014178039506077766, 0.01918807439506054, 0.011034421622753143, 0.13925142586231232, -0.10663548111915588, 0.05680525302886963, 0.031399257481098175], metadata={'source': 'AAAMLP-569to.pdf', 'page': 13}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 14 Cross-validation  We did not build any models in the previous chapter. The reason for that is simple. Before creating any kind of machine learning model, we must know what cross-validation is and how to choose the best cross-validation depending on your datasets.  So, what is cross-validation, and why should we care about it?  We can find multiple definitions as to what cross-validation is. Mine is a one-liner: cross-validation is a step in the process of building a machine learning model which helps us ensure that our models fit the data accurately and also ensures that we do not overfit. But this leads to another term: overfitting.   To explain overfitting, I think it’s best if we look at a dataset. There is a red wine-quality dataset2 which is quite famous. This dataset has 11 different attributes that decide the quality of red wine.   These attributes include: • fixed acidity • volatile acidity • citric acid • residual sugar • chlorides • free sulfur dioxide • total sulfur dioxide • density • pH • sulphates • alcohol  Based on these different attributes, we are required to predict the quality of red wine which is a value between 0 and 10.   2 P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis; Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.'),\n",
       " VectorParams(vector=[0.0200993362814188, -0.04042648896574974, -0.04328817129135132, -0.10896118730306625, -0.013644147664308548, 0.017841210588812828, -0.036810047924518585, -0.12762989103794098, -0.15496115386486053, -0.05657392740249634, -0.02020575851202011, -0.013594997115433216, -0.06802726536989212, 0.010813763365149498, -0.04305553808808327, 0.108355812728405, 0.03615482524037361, -0.02666681818664074, -0.14895574748516083, -0.21542097628116608, -0.006961016450077295, 0.10681700706481934, -0.01590394601225853, 0.1299058049917221, 0.008102871477603912, -0.08528254181146622, 0.07996346056461334, 0.11688282340765, -0.1178908571600914, -0.04027073085308075, -0.05728252977132797, 0.14616692066192627, 0.010652945376932621, -0.11320318281650543, -0.08510369062423706, -0.006740188226103783, -0.010665493085980415, -0.07380136102437973, -0.02183079533278942, 0.07632448524236679, 0.07178786396980286, -0.029695982113480568, -0.02031252346932888, 0.10942695289850235, 9.786134796740953e-06, 0.17464424669742584, -0.13630156219005585, 0.04536961764097214, 0.08042696118354797, -0.04818455129861832, -0.1683431714773178, 0.1264699399471283, -0.15706303715705872, -0.10882971435785294, -0.03210769221186638, -0.2359691709280014, 0.05457964166998863, -0.08263515681028366, 0.0833733081817627, -0.013416150584816933, 0.09675052016973495, -0.07573389261960983, 0.1399078220129013, -0.04842880368232727, -0.0018508733483031392, 0.04840588942170143, -0.14718656241893768, 0.12845478951931, -0.13028985261917114, 0.12791864573955536, -0.061246588826179504, -0.016367508098483086, 0.049209095537662506, -0.02269298955798149, 0.013645469211041927, -0.06407172232866287, 0.11702295392751694, -0.19299766421318054, -0.029595574364066124, 0.03320508450269699, -0.1372978836297989, -0.02544248290359974, -0.01691409945487976, 0.12980443239212036, -0.09811940044164658, -0.19301988184452057, 0.04594535753130913, 0.025499185547232628, -0.016210222616791725, 0.07212064415216446, -0.1250690519809723, -0.0016003069467842579, 0.0924895703792572, -0.07988619059324265, -0.014396948739886284, 0.16973207890987396, 0.21901051700115204, -0.22162295877933502, 0.07638302445411682, 0.0852077379822731, -0.06522784382104874, 0.021402902901172638, 0.011649365536868572, -0.3322865068912506, -0.0263796616345644, 0.05086715146899223, 0.09557155519723892, 0.153590127825737, 0.014514141716063023, -0.16402526199817657, -0.049679651856422424, -0.06089397147297859, -0.06300238519906998, -0.2073158621788025, 0.08803548663854599, -0.06328509002923965, -0.07069208472967148, 0.06786530464887619, -0.20315217971801758, -0.027785755693912506, -0.08257457613945007, 0.0246333759278059, 0.09749730676412582, -0.028691111132502556, -0.08164361864328384, -0.031370505690574646, -0.03039247915148735, 9.445385839657001e-33, -0.10711263865232468, -0.13189129531383514, 0.04529554396867752, -0.0007670984487049282, 0.15172889828681946, -0.1225614845752716, -0.05452257767319679, -0.018857590854167938, 0.05031505227088928, 0.057567816227674484, -0.01090987864881754, 0.09918635338544846, -0.2433980256319046, 0.07022710889577866, 0.15369190275669098, -0.020082902163267136, 0.046931955963373184, -0.05174660682678223, -0.211208313703537, -0.048296064138412476, 0.05958704277873039, -0.18424826860427856, 0.04582536593079567, -0.06616131216287613, -0.03574065864086151, -0.032611213624477386, -0.019900895655155182, 0.14308825135231018, -0.09128165990114212, -0.046743638813495636, -0.134798064827919, 0.16562972962856293, 0.006987718399614096, -0.1350082904100418, 0.12099293619394302, -0.09781277924776077, 0.04957771301269531, 0.1525619477033615, 0.07062636315822601, 0.004514121450483799, -0.030511217191815376, 0.07629397511482239, 0.03971020132303238, 0.08597420901060104, 0.09701067209243774, 0.08821993321180344, 0.061267368495464325, 0.09050694108009338, -0.1051463857293129, 0.11375939846038818, -0.10085408389568329, -0.08592836558818817, 0.1214432418346405, 0.19060571491718292, -0.2615889310836792, 0.046200890094041824, -0.011944134719669819, -0.047208528965711594, -0.035108357667922974, -0.11070233583450317, 0.1266675442457199, -0.014358620159327984, 0.12163425236940384, -0.038011930882930756, -0.01227274164557457, 0.09549971669912338, 0.21003304421901703, -0.026870036497712135, 0.07023829221725464, -0.06219068542122841, 0.05783509835600853, 0.12231792509555817, -0.15787407755851746, -0.116872139275074, 0.08164341002702713, 0.020753953605890274, 0.10481440275907516, 0.04905122518539429, -0.022019201889634132, -0.04466830939054489, -0.048394422978162766, -0.05187999829649925, 0.0313003771007061, -0.2552216649055481, -0.18088023364543915, 0.055748701095581055, -0.0378824919462204, -0.056061480194330215, 0.014750047586858273, -0.09160957485437393, -0.341052770614624, 0.11888754367828369, 0.01359485276043415, 0.012450023554265499, 0.174915611743927, -1.275213593717656e-32, 0.03812750056385994, -0.020758068189024925, 0.10251491516828537, 0.18957678973674774, 0.07887282967567444, 0.07030443847179413, 0.03867353871464729, 0.04432583600282669, 0.14267098903656006, 0.10766322165727615, -0.0309220552444458, 0.026318131014704704, -0.03378942236304283, -0.0499517060816288, -0.18101200461387634, 0.12621471285820007, 0.021807169541716576, 0.17438478767871857, 0.05950533226132393, 0.020393280312418938, 0.03433208540081978, 0.1949937343597412, -0.1197877749800682, 0.10429762303829193, -0.10769309848546982, 0.1945818066596985, -0.06588226556777954, -0.10596130043268204, -0.06628672778606415, -0.06347665190696716, 0.01658051274716854, -0.06282442808151245, 0.026388254016637802, -0.07175550609827042, -0.0033375280909240246, -0.04261069744825363, 0.2155579775571823, -0.1392931193113327, -0.3332696259021759, 0.2301456332206726, 0.27077537775039673, 0.04592683166265488, -0.3050941526889801, 0.008104228414595127, 0.07402412593364716, 0.07866055518388748, 0.05563323199748993, -0.019239753484725952, 0.06935691833496094, 0.017536161467432976, 0.14277693629264832, 0.09158249944448471, -0.09659172594547272, 0.24777670204639435, 0.07044123113155365, 0.025719380006194115, -0.14715735614299774, 0.008266889490187168, -0.12038294970989227, 0.13846412301063538, -0.17633095383644104, 0.008685152046382427, -0.042443789541721344, 0.10993414372205734, 0.07146179676055908, -0.0029744307976216078, -0.011694752611219883, 0.07657857984304428, -0.0340619832277298, -0.14044299721717834, 0.03371591120958328, -0.04821973294019699, 0.11979100108146667, -0.09964990615844727, -0.25918400287628174, -0.11503534018993378, -0.11986546963453293, -0.010414084419608116, -0.023064082488417625, 0.17310777306556702, -0.003621579147875309, -0.20707081258296967, 0.07961978763341904, 0.30334532260894775, -0.07727771997451782, 0.07481441646814346, 0.2837448716163635, -0.15806449949741364, 0.08287147432565689, 0.041808780282735825, -0.028026632964611053, 0.020419903099536896, -0.11245400458574295, -0.03142993152141571, 0.014015520922839642, -9.958122859643481e-08, 0.0162219125777483, -0.031028112396597862, -0.05571949481964111, 0.034415408968925476, -0.07945171743631363, 0.0033270155545324087, -0.08239612728357315, 0.1797986477613449, -0.045088328421115875, 0.11924497783184052, -0.025066424161195755, 0.052805472165346146, -0.18138448894023895, 0.029570437967777252, -0.06159651279449463, 0.1266525387763977, 0.0510021336376667, 0.14162160456180573, 0.018665829673409462, 0.13915887475013733, 0.1610829085111618, -0.008049717172980309, 0.10207931697368622, -0.07091329991817474, 0.028022758662700653, -0.14351771771907806, -0.04153383895754814, -0.07831136137247086, 0.08883398026227951, 0.10414744913578033, 0.006854802370071411, -0.03844445198774338, -0.003090999089181423, -0.044158823788166046, 0.11803299188613892, 0.09318781644105911, -0.21354630589485168, -0.05227086693048477, -0.23754830658435822, 0.06740560382604599, -0.28928107023239136, 0.07982749491930008, -0.27482467889785767, -0.02224106527864933, 0.053384773433208466, 0.028572501614689827, 0.07229766994714737, 0.053553055971860886, 0.12597692012786865, 0.018703047186136246, 0.07550308853387833, 0.09845803678035736, 0.14426517486572266, 0.0020997629035264254, 0.04987959936261177, 0.060127634555101395, -0.04189898818731308, 0.012667766772210598, -0.022312426939606667, -0.09067217260599136, 0.2552485764026642, -0.10300751030445099, 0.10202974826097488, -0.04130013287067413], metadata={'source': 'AAAMLP-569to.pdf', 'page': 14}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 15 Let’s see how this data looks like.  ═════════════════════════════════════════════════════════════════════════ import pandas as pd df = pd.read_csv(\"winequality-red.csv\") ═════════════════════════════════════════════════════════════════════════  This dataset looks something like this:  \\n Figure 1: A snapshot of the red wine quality dataset.  We can treat this problem either as a classification problem or as a regression problem since wine quality is nothing but a real number between 0 and 10. For simplicity, let’s choose classification. This dataset, however, consists of only six types of quality values. We will thus map all quality values from 0 to 5.  ═════════════════════════════════════════════════════════════════════════ # a mapping dictionary that maps the quality values from 0 to 5 quality_mapping = {     3: 0,     4: 1,     5: 2,     6: 3,     7: 4,     8: 5 }  # you can use the map function of pandas with # any dictionary to convert the values in a given # column to values in the dictionary df.loc[:, \"quality\"] = df.quality.map(quality_mapping) ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[-0.10719603300094604, -0.12621666491031647, 0.10276900976896286, -0.01103084348142147, 0.2144453525543213, -0.11539103835821152, -0.011474055238068104, 0.005089046433568001, -0.13714070618152618, -0.038101013749837875, -0.07756214588880539, -0.08059905469417572, -0.035923343151807785, -0.14651794731616974, -0.03544830158352852, 0.05854640528559685, -0.05064436420798302, 0.06957872211933136, -0.162035271525383, -0.15652364492416382, 0.05976711958646774, 0.038041479885578156, -0.046196553856134415, 0.1465185284614563, -0.04542408883571625, 0.04900296404957771, 0.03536336123943329, -0.01447941642254591, -0.14832626283168793, -0.08778760582208633, 0.12030336260795593, 0.016612010076642036, -0.024627400562167168, 0.03915536776185036, -0.24055200815200806, -0.06608358770608902, -0.11429338157176971, -0.05306383594870567, -0.015667244791984558, 0.16990423202514648, 0.010545842349529266, 0.048503562808036804, 0.030018752440810204, 0.04387357458472252, 0.0661814883351326, 0.06454498320817947, -0.07934344559907913, -0.07215801626443863, 0.11635971814393997, 0.04217727854847908, -0.10820300132036209, 0.06800025701522827, -0.07512583583593369, 0.03308820724487305, -0.0813949704170227, -0.2022416889667511, 0.05961386859416962, -0.052277494221925735, 0.028882181271910667, -0.017617521807551384, 0.04105623438954353, -0.10156311839818954, 0.042288098484277725, -0.06610680371522903, -0.004349690396338701, -0.06232403218746185, 0.033725496381521225, 0.009646312333643436, 0.0975463017821312, -0.0018965518102049828, -0.049496717751026154, 0.20450857281684875, -0.09518767893314362, 0.005705628544092178, 0.05711982771754265, 0.05224869027733803, 0.20679204165935516, 0.02720262110233307, 0.04895901679992676, -0.06104707717895508, -0.09092790633440018, 0.06364409625530243, 0.0035164004657417536, 0.00246748817153275, 0.015307554043829441, -0.24745506048202515, -0.004851276054978371, 0.126381516456604, 0.0339791476726532, 0.027322884649038315, 0.06945246458053589, -0.008717505261301994, 0.0876406878232956, -0.09552508592605591, 0.022865166887640953, 0.19667090475559235, 0.024181559681892395, -0.0694568082690239, -0.049575820565223694, 0.11351792514324188, -0.08200298994779587, 0.0812893733382225, 0.002242906019091606, -0.059778422117233276, -0.0015236703911796212, -0.051441740244627, -0.05310754477977753, 0.05011240392923355, 0.08131588250398636, -0.14779865741729736, 0.08093103021383286, -0.07006043940782547, -0.11557663232088089, -0.01712368242442608, 0.11503126472234726, 0.09229979664087296, -0.016405589878559113, -0.0657726377248764, -0.07336346060037613, 0.19343343377113342, -0.1222732663154602, -0.0027004648000001907, -0.020030569285154343, -0.002881950931623578, 0.15068262815475464, -0.0584915354847908, -0.18797573447227478, 1.135783727194412e-32, -0.09406281262636185, -0.02929162047803402, 0.007178515661507845, -0.07846029847860336, 0.08405628800392151, -0.08704158663749695, -0.0022506294772028923, 0.037578415125608444, 0.012701839208602905, 0.05949017405509949, -0.14998507499694824, 0.04155601188540459, -0.018393784761428833, -0.05752846226096153, 0.05186622962355614, -0.09204695373773575, -0.05668080970644951, -0.04437706246972084, -0.06053946912288666, -0.05207127705216408, 0.08434681594371796, -0.05231538414955139, 0.021047450602054596, -0.09952892363071442, -0.04464929178357124, -0.005618802271783352, -0.0515330471098423, 0.0533219575881958, -0.04790561646223068, 0.011698816902935505, -0.11678996682167053, 0.02018039859831333, -0.060140687972307205, -0.003594601061195135, 0.04465317353606224, -0.08900249004364014, -0.007676306180655956, 0.06962123513221741, 0.04101017862558365, 0.01233502384275198, -0.03807936981320381, -0.010697669349610806, 0.039662864059209824, 0.0713563859462738, 0.004567288793623447, 0.05624594911932945, -0.05446331948041916, 0.11627869307994843, 0.030450711026787758, 0.09210391342639923, -0.09377075731754303, -0.08924561738967896, 0.0929923728108406, 0.04500957205891609, -0.12901726365089417, 0.0889386534690857, 0.01891481690108776, -0.018022926524281502, 0.07926500588655472, 0.07065730541944504, 0.07379239052534103, -0.0591827929019928, -0.044063013046979904, 0.11617366969585419, -0.054134394973516464, 0.03479018062353134, -0.03372246399521828, 0.015508417040109634, 0.14327353239059448, 0.017129169777035713, -0.0706753134727478, -0.0011299316538497806, 0.0006577739841304719, -0.09211985766887665, -0.029580367729067802, -0.01996765285730362, 0.10586768388748169, 0.05330168828368187, -0.11412364989519119, -0.033309757709503174, -0.029631104320287704, 0.15025436878204346, 0.08998581022024155, -0.13992522656917572, -0.026172347366809845, -0.046348702162504196, 0.04287998378276825, -0.01039257925003767, -0.12166547030210495, -0.09948086738586426, -0.25716859102249146, -0.016237357631325722, 0.13146208226680756, -0.1262410581111908, 0.11647522449493408, -1.3401296814946415e-32, 0.02618900127708912, 0.0037080675829201937, 0.10469579696655273, 0.1143772304058075, 0.1254889965057373, 0.0944289043545723, -0.042465537786483765, 0.08736000955104828, -0.03587965667247772, -0.11925475299358368, -0.035187095403671265, 0.028146762400865555, 0.11425571143627167, -0.04657650366425514, -0.046315714716911316, -0.023619627580046654, -0.0033660000190138817, 0.10069510340690613, -0.006220838520675898, 0.10969149321317673, -0.05487209931015968, 0.13000087440013885, -0.16287080943584442, -0.013484420254826546, -0.16098332405090332, -0.04695923253893852, -0.04483873397111893, 0.040290284901857376, 0.02875141054391861, -0.017520373687148094, -0.08847321569919586, 0.062127821147441864, -0.06197322532534599, 0.0003635961620602757, 0.07213690131902695, -0.05066366866230965, -0.02275111898779869, -0.0683402568101883, -0.04949801042675972, 0.2305784672498703, 0.12726080417633057, 0.06222226843237877, -0.18395735323429108, 0.070501908659935, 0.01254020631313324, 0.12933547794818878, -0.11886086314916611, -0.017738061025738716, -0.011439303867518902, -0.01989026740193367, 0.050251707434654236, 0.011422401294112206, -0.03203350678086281, 0.04972802847623825, 0.03332250565290451, 0.13207638263702393, -0.05962243303656578, 0.0616188570857048, -0.06156814843416214, 0.03989381715655327, -0.1701289862394333, -0.04642379283905029, 0.030293921008706093, -0.037346482276916504, 0.018943827599287033, -0.00029348020325414836, -0.07048371434211731, 0.045899294316768646, 0.048333510756492615, -0.029688673093914986, -0.14726896584033966, 0.0034235247876495123, 0.04896921664476395, -0.02328605204820633, 0.058822035789489746, 0.005914711393415928, -0.12722136080265045, -0.07277844846248627, 0.04602179303765297, 0.09698572009801865, -0.10325739532709122, -0.14096201956272125, -0.023724406957626343, 0.12539751827716827, 0.06757137179374695, 0.10963613539934158, 0.04998781532049179, 0.12008839100599289, 0.10198837518692017, -0.14508609473705292, -0.032030537724494934, -0.00986968632787466, 0.07121827453374863, 0.07847967743873596, -0.042034391313791275, -1.0030429820062636e-07, 0.007888530381023884, 0.04713370278477669, 0.06904672831296921, 0.1298033893108368, 0.0718376412987709, 0.00285235489718616, -0.015551095828413963, 0.1888737976551056, -0.08690908551216125, 0.020507939159870148, 0.11891462653875351, 0.04198173061013222, -0.05577273294329643, 0.06515730917453766, 0.0246758833527565, 0.09174703061580658, -0.027785392478108406, 0.09872360527515411, -0.011205336079001427, 0.14312267303466797, 0.0029988144524395466, -0.105385422706604, 0.16645582020282745, 0.04652804881334305, 0.08943556994199753, -0.08392912149429321, 0.007132642436772585, 0.046425167471170425, 0.029215648770332336, 0.1034679040312767, -0.02373453415930271, -0.18497692048549652, -0.02510233409702778, 0.026391873136162758, 0.040970832109451294, 0.039232153445482254, 0.03322788327932358, -0.04244477301836014, 0.007273413240909576, 0.036533769220113754, -0.11925859749317169, 0.020873209461569786, -0.09605555981397629, -0.038770172744989395, -0.01219136081635952, -0.028201425448060036, 0.00990572851151228, 0.026782017201185226, 0.043699584901332855, -0.03937695175409317, -0.015268650837242603, 0.015489131212234497, -0.04109855741262436, 0.0023035004269331694, 0.1538015455007553, -0.05553904548287392, -0.09637618064880371, -0.103899747133255, -0.0957515686750412, -0.00582203920930624, 0.10453764349222183, -0.02386772260069847, -0.02890196070075035, -0.02772802673280239], metadata={'source': 'AAAMLP-569to.pdf', 'page': 15}, content=\"Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 16 When we look at this data and consider it a classification problem, a lot of algorithms come to our mind that we can apply to it, probably, we can use neural networks. But it would be a bit of a stretch if we dive into neural networks from the beginning. So, let’s start with something simple that we can visualize too: decision trees.  Before we begin to understand what overfitting is, let’s divide the data into two parts. This dataset has 1599 samples. We keep 1000 samples for training and 599 as a separate set.  Splitting can be done easily by the following chunk of code:  ═════════════════════════════════════════════════════════════════════════ # use sample with frac=1 to shuffle the dataframe # we reset the indices since they change after # shuffling the dataframe df = df.sample(frac=1).reset_index(drop=True)  # top 1000 rows are selected # for training df_train = df.head(1000)  # bottom 599 values are selected # for testing/validation df_test = df.tail(599) ═════════════════════════════════════════════════════════════════════════  We will now train a decision tree model on the training set. For the decision tree model, I am going to use scikit-learn.  ═════════════════════════════════════════════════════════════════════════ # import from scikit-learn from sklearn import tree from sklearn import metrics  # initialize decision tree classifier class # with a max_depth of 3 clf = tree.DecisionTreeClassifier(max_depth=3)  # choose the columns you want to train on # these are the features for the model cols = ['fixed acidity',          'volatile acidity',          'citric acid',\"),\n",
       " VectorParams(vector=[-0.08519481867551804, -0.17551331222057343, -0.03376389294862747, -0.03297458961606026, 0.041279394179582596, -0.18420451879501343, 0.003881316864863038, 0.12801441550254822, -0.10502589493989944, -0.01742619089782238, -0.10595651715993881, -0.2260679453611374, 0.03225407749414444, 0.02955758385360241, -0.03043970838189125, -0.009759965352714062, 0.07878121733665466, 0.07791831344366074, -0.1524297595024109, -0.08004351705312729, 0.10352063179016113, 0.10798180103302002, 0.13593736290931702, 0.1261504739522934, 0.01616937480866909, -0.046826548874378204, -0.027422772720456123, 0.109919972717762, -0.17134718596935272, -0.1381404548883438, -0.015158761292696, 0.024336479604244232, -0.021558236330747604, -0.05139532685279846, -0.04951071739196777, -0.046513527631759644, -0.030397586524486542, -0.11561993509531021, 0.03649928793311119, 0.09394805133342743, -0.03847283869981766, 0.06042493134737015, 0.12431951612234116, 0.10276967287063599, 0.061957575380802155, 0.17608435451984406, -0.14345721900463104, -0.030510343611240387, 0.09728525578975677, -0.04333703592419624, -0.12032292783260345, 0.03833254054188728, -0.12140224874019623, -0.08016554266214371, -0.11293637007474899, -0.04205309972167015, 0.039615411311388016, -0.134140282869339, 0.07669581472873688, -0.08815038949251175, -0.048923615366220474, -0.034631576389074326, -0.015781305730342865, -0.03312632441520691, 0.016608653590083122, -0.048084232956171036, -0.05476514250040054, -0.06794648617506027, -0.0010315150720998645, 0.15113916993141174, -0.044893380254507065, 0.17700575292110443, -0.10237221419811249, -0.09464732557535172, -0.001091575133614242, 0.05497295781970024, 0.12380622327327728, 0.07648162543773651, -0.016928110271692276, -0.23029571771621704, -0.0717860609292984, 0.042126383632421494, 0.030975302681326866, -0.05384409427642822, 0.04457050561904907, -0.19597145915031433, 0.05094875022768974, 0.10995761305093765, 0.06749355792999268, -0.02097044326364994, 0.15466006100177765, -0.0651853010058403, -0.1578449010848999, 0.061218105256557465, 0.02812805399298668, 0.19814732670783997, -0.01299433596432209, -0.056059643626213074, -0.16552715003490448, 0.06594424694776535, -0.08679203689098358, -0.013354052789509296, -0.0616016760468483, -0.15881416201591492, 0.13440266251564026, 0.06797994673252106, 0.06289931386709213, 0.09185167402029037, 0.14007943868637085, 0.019679566845297813, 0.07205404341220856, -0.09311340749263763, -0.0578739196062088, 0.055465470999479294, 0.17112576961517334, 0.3244640529155731, -0.037871427834033966, -0.0070580593310296535, -0.1823999434709549, 0.20777541399002075, -0.1186155378818512, 0.07532516866922379, 0.04508507624268532, 0.004960590973496437, 0.03493727743625641, -0.06126663461327553, -0.11285100132226944, 4.352786153459835e-33, -0.12278681993484497, 0.09837096929550171, 0.0778903141617775, -0.12063628435134888, -0.09982152283191681, 0.01380630861967802, -0.0638398751616478, 0.06943004578351974, 0.03387000039219856, -0.06627604365348816, -0.30764684081077576, 0.052730049937963486, -0.13606441020965576, -0.0714723989367485, 0.1460917741060257, 0.0421738401055336, -0.05419086292386055, 0.09170132130384445, -0.12084776163101196, 0.03374069184064865, 0.24113674461841583, 0.019379887729883194, -0.03116004727780819, -0.1571863740682602, 0.053819671273231506, -0.018492620438337326, 0.07080646604299545, 0.20489029586315155, -0.32311704754829407, 0.003588841063901782, -0.0927220955491066, -0.06040630117058754, 0.0375128835439682, -0.010149829089641571, 0.016636934131383896, -0.13686849176883698, 0.01289184670895338, 0.1263241171836853, -0.049652840942144394, -0.05051802098751068, -0.08866197615861893, -0.025148112326860428, 0.025896236300468445, 0.05767266824841499, -0.08976879715919495, -0.06956112384796143, -0.16998805105686188, 0.09201446175575256, 0.055344559252262115, 0.1910853087902069, -0.02963264286518097, -0.0981079638004303, -0.030171172693371773, 0.031280070543289185, -0.22026175260543823, 0.14707182347774506, 0.09052472561597824, -0.017141006886959076, 0.17875254154205322, 0.008603354915976524, 0.024175578728318214, -0.032530803233385086, 0.02282772772014141, 0.00668560154736042, -0.05895458534359932, 0.08411560207605362, 0.024677613750100136, -0.05130239203572273, 0.12034965306520462, -0.0400562547147274, -0.09616347402334213, -0.06979592144489288, 0.010428383946418762, -0.010055889375507832, 0.05584116280078888, -0.06132271885871887, 0.1578710973262787, -0.06112556532025337, -0.08942656964063644, 0.005947929807007313, -0.011722460389137268, 0.22533035278320312, -0.08069901168346405, -0.23024103045463562, -0.06424388289451599, -0.06818334758281708, 0.08599061518907547, 0.09557780623435974, -0.13195914030075073, -0.0775926262140274, -0.2438695877790451, -0.013218752108514309, 0.06820137798786163, -0.06770883500576019, -0.0008309533004648983, -7.331628795739657e-33, 0.050576385110616684, 0.13452363014221191, 0.15389014780521393, 0.19123625755310059, 0.0734194964170456, 0.023254208266735077, 0.022803228348493576, 0.021426208317279816, -0.0865367203950882, -0.07393409311771393, 0.03869788721203804, -0.0004645473964046687, 0.04156888648867607, -0.00040305120637640357, 0.031306371092796326, 0.08551575243473053, -0.15966621041297913, 0.05936284735798836, 0.0005977940745651722, 0.09518934041261673, 0.01534921396523714, 0.19843780994415283, -0.26992225646972656, 0.08991289883852005, -0.13829874992370605, 0.07306139916181564, -0.08106321096420288, 0.06741992384195328, 0.04742266237735748, -0.12523142993450165, 0.02367955446243286, 0.047841429710388184, -0.17308928072452545, 0.04133148491382599, 0.06649685651063919, -0.1439434140920639, 0.1290254145860672, -0.19207721948623657, -0.09599733352661133, 0.21166224777698517, 0.09621273726224899, 0.12694700062274933, -0.2903681993484497, 0.10157440602779388, 0.0029540385585278273, 0.05212114751338959, 0.13833346962928772, -0.19341927766799927, 0.08296806365251541, -0.07316964864730835, 0.06721685826778412, -0.09263451397418976, -0.057235538959503174, 0.15028494596481323, -0.013654466718435287, 0.1563989371061325, -0.17110686004161835, 0.04334251210093498, -0.08046653121709824, 0.0064066494815051556, -0.05782743915915489, 0.09746996313333511, -0.028377939015626907, -0.08813589066267014, 0.09320441633462906, 0.06657133251428604, -0.14779622852802277, 0.07038258761167526, 0.15567709505558014, 0.049189239740371704, -0.174115851521492, 0.045520104467868805, 0.11854039132595062, -0.06103474646806717, 0.0705622211098671, 0.11308550089597702, -0.04613611847162247, 0.003049065126106143, -0.007534584496170282, 0.09807794541120529, -0.16164162755012512, -0.03585108742117882, -0.027237001806497574, 0.21951749920845032, -0.010932262055575848, 0.04288055747747421, 0.11906209588050842, 0.10902419686317444, 0.06644661724567413, -0.14387425780296326, 0.026472531259059906, -0.03640368953347206, 0.03163151815533638, 0.0772336795926094, -0.07736343890428543, -1.006975622885875e-07, -0.07963275164365768, -0.008543865755200386, 0.01769450679421425, 0.11092859506607056, -0.048403844237327576, 0.01926404982805252, -0.05149201303720474, 0.1490689367055893, -0.08418942987918854, 0.014124037697911263, 0.06224246695637703, 0.015545014292001724, -0.19498851895332336, 0.0711531788110733, -0.07036255300045013, 0.04156918823719025, -0.02491488866508007, 0.1855458915233612, -0.02176019549369812, 0.12401407957077026, 0.11368700116872787, -0.07158158719539642, 0.07098382711410522, 0.0846773087978363, 0.04541822150349617, -0.1085461676120758, -0.008941414766013622, 0.11085227876901627, -0.09983693063259125, 0.2291547805070877, 0.10660688579082489, -0.18639200925827026, 0.031431205570697784, 0.037826597690582275, -0.01782866381108761, 0.029551256448030472, 0.003824187908321619, -0.03930516913533211, 0.022374015301465988, 0.2612961530685425, -0.0681227296590805, 0.1183515191078186, -0.13395839929580688, -0.015339283272624016, 0.0858631357550621, -0.0914054811000824, 0.050699565559625626, 0.05054976046085358, -0.01392468810081482, -0.13737733662128448, -0.05246901139616966, 0.021941224113106728, -0.1905657947063446, 0.020808815956115723, 0.1280602067708969, -0.051841672509908676, -0.16548998653888702, -0.0808328241109848, -0.18770244717597961, 0.013759209774434566, 0.11983823776245117, -0.0934593677520752, -0.006608459632843733, -0.006551177240908146], metadata={'source': 'AAAMLP-569to.pdf', 'page': 16}, content=\"Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 17         'residual sugar',         'chlorides',         'free sulfur dioxide',         'total sulfur dioxide',         'density',         'pH',         'sulphates',         'alcohol']  # train the model on the provided features # and mapped quality from before clf.fit(df_train[cols], df_train.quality) ═════════════════════════════════════════════════════════════════════════  Note that I have used a max_depth of 3 for the decision tree classifier. I have left all other parameters of this model to its default value.  Now, we test the accuracy of this model on the training set and the test set:  ═════════════════════════════════════════════════════════════════════════ # generate predictions on the training set train_predictions = clf.predict(df_train[cols])  # generate predictions on the test set test_predictions = clf.predict(df_test[cols])  # calculate the accuracy of predictions on # training data set train_accuracy = metrics.accuracy_score(     df_train.quality, train_predictions )  # calculate the accuracy of predictions on # test data set test_accuracy = metrics.accuracy_score(     df_test.quality, test_predictions ) ═════════════════════════════════════════════════════════════════════════  The training and test accuracies are found to be 58.9% and 54.25%. Now we increase the max_depth to 7 and repeat the process. This gives training accuracy of 76.6% and test accuracy of 57.3%. Here, we have used accuracy, mainly because it is the most straightforward metric. It might not be the best metric for this problem. What about we calculate these accuracies for different values of max_depth and make a plot?\"),\n",
       " VectorParams(vector=[-0.016584765166044235, -0.03750184550881386, 0.060938067734241486, -0.026478739455342293, 0.14335617423057556, -0.05213465169072151, -0.0022691877093166113, 0.06009313091635704, -0.03258337453007698, -0.009725800715386868, -0.0328485332429409, -0.19781509041786194, -0.02240293100476265, -0.15030807256698608, -0.07425877451896667, 0.07547172158956528, 0.04217101261019707, -0.02524924837052822, -0.07083118706941605, -0.22363324463367462, 0.023935597389936447, 0.13169100880622864, 0.04417996108531952, 0.14333979785442352, 0.012633985839784145, 0.03717973083257675, -0.0650458112359047, 0.1381494551897049, -0.14836031198501587, -0.002474784152582288, -0.01129019632935524, 0.015778062865138054, -0.0009170121629722416, 0.04766395688056946, -0.0835312157869339, -0.0445522740483284, -0.02785279043018818, -0.03626884147524834, 0.024876371026039124, 0.1166248768568039, 0.02510630339384079, 0.07091246545314789, 0.08434973657131195, 0.05829312279820442, 0.05909457802772522, 0.0038357386365532875, -0.16103675961494446, -0.17697809636592865, 0.03819885104894638, -0.0005537426914088428, -0.13284073770046234, -0.018694018945097923, -0.07086323201656342, -0.1690007895231247, -0.08155380189418793, -0.05506224185228348, -0.016282938420772552, -0.12999436259269714, 0.09212906658649445, -0.13623613119125366, -0.014873417094349861, -0.03388571739196777, 0.01415275875478983, -0.07564006000757217, 0.048164550215005875, 0.003016459522768855, 0.05292565003037453, 0.046611085534095764, 0.0033264122903347015, 0.17057208716869354, -0.02703399956226349, 0.11063160747289658, -0.0864483192563057, 0.09492461383342743, 0.014419926330447197, -0.0798359364271164, 0.04472269490361214, -0.02132999524474144, 0.08180587738752365, -0.14703668653964996, -0.13953441381454468, 0.14451423287391663, -0.04471328854560852, 0.01105937547981739, 0.015201962552964687, -0.1570383459329605, 0.02183499187231064, 0.1124134361743927, -0.005315642803907394, -0.019039304926991463, 0.15454846620559692, -0.12432339042425156, -0.14596545696258545, 0.04840075597167015, -0.1453433483839035, 0.08604622632265091, 0.015074016526341438, 0.0034069414250552654, -0.13262227177619934, 0.005710775963962078, -0.08298132568597794, -0.04325703904032707, 0.0011477334192022681, -0.022935746237635612, -0.04177340120077133, -0.010907930321991444, 0.04587666317820549, 0.04284325987100601, 0.1705426722764969, -0.059231337159872055, -0.04872862622141838, -0.1408969908952713, -0.19240802526474, 0.14195966720581055, 0.16295187175273895, 0.17597873508930206, -0.0011583676096051931, -0.12084060162305832, -0.15612654387950897, 0.082948699593544, -0.08574163168668747, 0.01692715846002102, -0.12244708091020584, 0.08621521294116974, -0.042389728128910065, -0.02324865758419037, -0.09566352516412735, 1.1476409387111565e-32, 0.0025471679400652647, -0.029925156384706497, 0.08240087330341339, -0.08899328857660294, 0.016008853912353516, -0.03442061319947243, -0.1464691013097763, 0.009990445338189602, -0.003414635779336095, 0.15459226071834564, -0.1709645539522171, 0.06203337013721466, -0.07011888921260834, -0.02848685346543789, 0.06534392386674881, -0.03403947502374649, -0.006375414784997702, -0.0053776586428284645, -0.09806276112794876, -0.054199837148189545, 0.025204533711075783, -0.03045247122645378, -0.024009551852941513, -0.14902739226818085, -0.03692618012428284, -0.007191184908151627, 0.03368879854679108, 0.10972356796264648, -0.09631102532148361, 0.046303436160087585, -0.06974220275878906, -0.031057963147759438, 0.03642931208014488, -0.09531164169311523, 0.03837088122963905, -0.1508936733007431, -0.019969964399933815, 0.0834137350320816, 0.014928045682609081, -0.05942908301949501, -0.09340185672044754, 0.027598602697253227, 0.08399397879838943, 0.06335875391960144, -0.010252569802105427, 0.032067086547613144, -0.04210371524095535, 0.14432533085346222, 0.08953626453876495, 0.16472500562667847, -0.10361538827419281, -0.051342736929655075, 0.024574754759669304, 0.07570168375968933, -0.13067442178726196, 0.216434508562088, 0.07936542481184006, 0.08091902732849121, 0.05300495773553848, -0.001358500332571566, 0.03399563580751419, -0.050402358174324036, 0.06381121277809143, -0.013190081343054771, 0.017068959772586823, 0.20522911846637726, -0.0502433255314827, -0.06305393576622009, 0.09410572052001953, 0.0650448277592659, -0.10728098452091217, -0.022658077999949455, 0.00030418881215155125, -0.01842166669666767, 0.04368157312273979, -0.09213003516197205, 0.13669787347316742, -0.07960644364356995, -0.16167081892490387, 0.012064854614436626, -0.06218244135379791, 0.001608684309758246, 0.08623349666595459, -0.21576455235481262, -0.06888793408870697, -0.1626083254814148, 0.10594574362039566, 0.02086011879146099, -0.09919650852680206, -0.04869832843542099, -0.143141508102417, -0.07372958213090897, 0.08397148549556732, -0.07272075116634369, -0.04415823146700859, -1.7462390290063438e-32, 0.043542709201574326, 0.05569396913051605, 0.1310299038887024, 0.06149381026625633, 0.03556299954652786, 0.09415718913078308, 0.000998504227027297, 0.13149236142635345, -0.003818476339802146, -0.047049570828676224, 0.01234252005815506, 0.06747546792030334, 0.02491053193807602, -0.06420308351516724, 0.1497970074415207, 0.09872625023126602, -0.08830578625202179, 0.1474239081144333, -0.007874205708503723, 0.01670103520154953, -0.025616051629185677, 0.1731959581375122, -0.07269123941659927, 0.06873201578855515, -0.13062603771686554, -0.0037941341288387775, -0.04948717728257179, -0.004995457362383604, 0.024952979758381844, -0.11076897382736206, -0.08093389123678207, 0.11068364977836609, -0.12890779972076416, -0.053395092487335205, 0.024550898000597954, -0.11093766987323761, 0.06607435643672943, -0.15136483311653137, -0.20476679503917694, 0.21856500208377838, 0.07885278016328812, 0.08202939480543137, -0.2448458969593048, 0.021913697943091393, 0.05557933822274208, 0.09551894664764404, 0.018549269065260887, -0.02776205912232399, 0.007598887663334608, -0.008179581724107265, 0.06975516676902771, 0.019034817814826965, -0.01210001390427351, 0.11335439234972, -0.04431028291583061, 0.1517455279827118, -0.1490023136138916, 0.10379518568515778, -0.0124076372012496, -0.07916904240846634, -0.2040219008922577, -0.07426325231790543, -0.07509543746709824, -0.12036636471748352, 0.07236120104789734, -0.11256492137908936, -0.09690994024276733, -0.032850973308086395, 0.12812313437461853, 0.03985441103577614, -0.060958851128816605, 0.0753323957324028, -0.03851085901260376, -0.10550039261579514, -0.03250838816165924, 0.07205509394407272, -0.1751621514558792, -0.08892843127250671, -0.10588695108890533, 0.14268571138381958, -0.025045307353138924, 0.0801427885890007, 0.08396094292402267, 0.20108431577682495, 0.054585788398981094, 0.017030425369739532, 0.07628002017736435, 0.15675881505012512, 0.01989085040986538, -0.14353899657726288, 0.07606882601976395, -0.075456902384758, -0.009677414782345295, 0.13294339179992676, -0.0910513773560524, -1.011643036008536e-07, -0.024789463728666306, 0.002322702668607235, 0.01647278293967247, 0.12152610719203949, 0.05750061571598053, 0.016520777717232704, 0.012476506642997265, 0.17598700523376465, -0.1225832998752594, 0.11699091643095016, -0.002396101364865899, -0.04448584467172623, -0.14931173622608185, 0.045820921659469604, -0.07604901492595673, 0.0719442069530487, -0.0553043894469738, 0.1361129730939865, -0.00453305896371603, 0.1637880802154541, 0.03492821753025055, -0.07317367941141129, 0.017669910565018654, 0.063100166618824, -0.013927772641181946, -0.1505596786737442, -0.028911663219332695, 0.12183862179517746, -0.024428507313132286, 0.04474308341741562, 0.10509425401687622, -0.09932909905910492, 0.09949446469545364, 0.13079267740249634, -0.001709431642666459, 0.0549108162522316, -0.006686911452561617, 0.020599426701664925, 0.017904359847307205, 0.14888635277748108, -0.22551998496055603, 0.05863445997238159, -0.10429177433252335, 0.002851711818948388, 0.08944613486528397, 0.011375554837286472, 0.07006482034921646, 0.07044536620378494, 0.025650106370449066, -0.05430738627910614, 0.04833944886922836, -0.03893585875630379, -0.18915978074073792, -0.0845000296831131, 0.14024479687213898, -0.01638283021748066, -0.07301142066717148, -0.04329415783286095, -0.08267651498317719, 0.0437881201505661, 0.11615365743637085, -0.06145186722278595, -0.03641774132847786, -0.10900268703699112], metadata={'source': 'AAAMLP-569to.pdf', 'page': 17}, content=\"Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 18 ═════════════════════════════════════════════════════════════════════════ # NOTE: this code is written in a jupyter notebook  # import scikit-learn tree and metrics from sklearn import tree from sklearn import metrics  # import matplotlib and seaborn # for plotting import matplotlib import matplotlib.pyplot as plt import seaborn as sns  # this is our global size of label text # on the plots matplotlib.rc('xtick', labelsize=20)  matplotlib.rc('ytick', labelsize=20)   # This line ensures that the plot is displayed # inside the notebook %matplotlib inline   # initialize lists to store accuracies # for training and test data # we start with 50% accuracy train_accuracies = [0.5] test_accuracies = [0.5]  # iterate over a few depth values for depth in range(1, 25):     # init the model     clf = tree.DecisionTreeClassifier(max_depth=depth)      # columns/features for training     # note that, this can be done outside      # the loop     cols = [         'fixed acidity',          'volatile acidity',         'citric acid',          'residual sugar',         'chlorides',         'free sulfur dioxide',          'total sulfur dioxide',         'density',         'pH',          'sulphates',\"),\n",
       " VectorParams(vector=[0.000415847054682672, -0.12595349550247192, 0.07599236071109772, -0.055404677987098694, 0.16280202567577362, -0.12365584820508957, -0.08132855594158173, 0.09179084748029709, -0.04813389480113983, -0.06363576650619507, -0.09749677777290344, -0.11920194327831268, -0.0022565533872693777, -0.05476565659046173, 0.022159766405820847, 0.06653430312871933, 0.028870856389403343, 0.0251071248203516, -0.07865042239427567, -0.12155065685510635, 0.1138230413198471, 0.08826784789562225, 0.07980427891016006, 0.13081839680671692, -0.010173666290938854, -0.026143131777644157, -0.0037081295158714056, 0.19180519878864288, -0.09246370196342468, -0.07069164514541626, 0.002395556541159749, 0.06284135580062866, 0.05823277682065964, 0.017112618312239647, -0.1177167221903801, -0.07866480946540833, 0.030864916741847992, -0.0007847975939512253, -0.02845075912773609, 0.09156462550163269, -0.008777201175689697, 0.047804247587919235, 0.07754100859165192, 0.04131392762064934, 0.09265917539596558, 0.11915194243192673, -0.1521821767091751, -0.11366625875234604, -0.010740897618234158, 0.024257922545075417, -0.10430995374917984, 0.047125499695539474, -0.08333956450223923, -0.12693415582180023, -0.004708136897534132, 0.006445322651416063, -0.015432707965373993, -0.1034683808684349, 0.14880973100662231, -0.1018005907535553, -0.06278132647275925, 0.003783272812142968, 0.012245017103850842, -0.033020492643117905, 0.04953354224562645, -0.09578172117471695, -0.07705995440483093, -0.00795051734894514, -0.12138336151838303, 0.11177130788564682, 0.03822040185332298, 0.15447337925434113, -0.09609533846378326, 0.01563047058880329, -0.02917766571044922, 0.018827738240361214, 0.057273659855127335, -0.016592970117926598, -0.029088011011481285, -0.10413215309381485, -0.15663957595825195, 0.024255171418190002, 0.026376744732260704, -0.0201296154409647, 0.033417876809835434, -0.2365148812532425, 0.11439845710992813, -0.012369704432785511, -0.04559340327978134, -0.0043637314811348915, 0.2038285732269287, -0.07068696618080139, -0.2056387960910797, 0.08722243458032608, -0.01366314385086298, 0.14147800207138062, 0.056606292724609375, -0.051576342433691025, -0.2173730731010437, 0.011744116432964802, -0.0669778510928154, 0.0022270253393799067, -0.04730415716767311, -0.08501053601503372, 0.1765822321176529, 0.05558329075574875, 0.14280544221401215, 0.056490737944841385, 0.11375497281551361, -0.04224495217204094, 0.012044337578117847, -0.024316873401403427, -0.1092081293463707, 0.0835389718413353, 0.11072373390197754, 0.26947078108787537, -0.11921974271535873, 0.08251958340406418, -0.2087707817554474, 0.0916845053434372, -0.0623592846095562, 0.024537574499845505, 0.03151611238718033, 0.06118233501911163, -0.029388263821601868, -0.10913005471229553, -0.02963334321975708, 1.0002002251238524e-32, -0.13918159902095795, -0.04775530844926834, -0.040716420859098434, -0.10362981259822845, -0.023020898923277855, -0.10217466950416565, -0.04641098529100418, 0.007163855247199535, 0.020566929131746292, 0.002616009907796979, -0.2820669114589691, 0.14365985989570618, -0.08729539066553116, 0.039652079343795776, 0.11394375562667847, -0.009222567081451416, -0.010757346637547016, -0.0259413979947567, -0.12508657574653625, 0.06015026569366455, 0.27624276280403137, -0.008532167412340641, -0.011196953244507313, -0.1599973440170288, -0.008045915514230728, -0.036613330245018005, 0.10737352073192596, 0.13178633153438568, -0.20535066723823547, 0.025130951777100563, -0.23886026442050934, 0.004838591907173395, 0.061616960912942886, 0.015567746013402939, 0.010399572551250458, -0.12044550478458405, 0.04980422183871269, 0.05333920195698738, -0.03320285305380821, -0.021643685176968575, -0.07981785386800766, -0.029697759076952934, -0.02325686812400818, 0.07093792408704758, 0.06666481494903564, -0.05680688098073006, -0.12310199439525604, 0.12728483974933624, 0.0035663547459989786, 0.20475071668624878, -0.023062491789460182, -0.06033647432923317, -0.029054010286927223, 0.03290039300918579, -0.17293120920658112, 0.18640218675136566, 0.0889350026845932, -0.00555532518774271, 0.009379823692142963, -0.036565959453582764, 0.05505768582224846, -0.09596598893404007, -0.008502678014338017, -0.02209542691707611, -0.002286055823788047, 0.23284728825092316, 0.05908345431089401, -0.1453428566455841, 0.10634605586528778, -0.02648979425430298, -0.09178134799003601, 0.041623640805482864, 0.016387052834033966, -0.09876460582017899, 0.01880333200097084, -0.12610137462615967, 0.01618148200213909, 0.029809817671775818, -0.1283811628818512, -0.04212138056755066, -0.00015410683408845216, 0.18923334777355194, -0.06592363119125366, -0.21614521741867065, 0.03347116708755493, -0.10637355595827103, 0.09671765565872192, 0.03416844457387924, -0.08608667552471161, -0.12285959720611572, -0.15978921949863434, -0.04884115234017372, 0.13487833738327026, -0.019123654812574387, 0.04763773828744888, -1.1972562777390605e-32, 0.024726754054427147, 0.04409823939204216, 0.12803807854652405, 0.15632638335227966, 0.08360766619443893, 0.023245587944984436, 0.04233282059431076, 0.05460326001048088, -0.04871871694922447, -0.09615524113178253, -0.004474774934351444, -0.05946619063615799, -0.019763434305787086, -0.03737067058682442, 0.09795943647623062, 0.07124464958906174, -0.10924370586872101, 0.17723000049591064, -0.11649052053689957, -0.021453266963362694, -0.017004210501909256, 0.22120949625968933, -0.10222276300191879, 0.0074718366377055645, -0.15695703029632568, 0.04779171943664551, -0.05992792546749115, 0.05311646685004234, -0.03046480007469654, -0.19592797756195068, -0.03339042142033577, 0.13221518695354462, -0.16858214139938354, 0.040240440517663956, 0.1586141437292099, -0.0713159590959549, 0.09554160386323929, -0.18230190873146057, -0.21336285769939423, 0.18436922132968903, 0.10467696189880371, 0.10323479026556015, -0.17315077781677246, 0.017620794475078583, -0.007269121240824461, 0.12371169030666351, 0.019027195870876312, -0.12130450457334518, 0.10555844753980637, -0.07763300836086273, 0.09499147534370422, -0.06492888182401657, -0.019878573715686798, 0.10325473546981812, 0.03143857419490814, 0.09543924778699875, -0.12095605581998825, 0.050741326063871384, -0.06948623061180115, 0.008020810782909393, -0.04753487929701805, 0.0490044504404068, -0.10311125218868256, -0.0016747214831411839, 0.14929765462875366, 0.07537052035331726, -0.1299942135810852, 0.04707564413547516, 0.18819758296012878, 0.04647131636738777, -0.18335044384002686, -0.012051472440361977, 0.0562225840985775, -0.03111967258155346, 0.007080696057528257, 0.13334612548351288, -0.13124942779541016, -0.02567945420742035, -0.06398915499448776, 0.11394647508859634, -0.08730387687683105, -0.05399549379944801, -0.017265772446990013, 0.19334210455417633, -0.07396791875362396, 0.07280745357275009, 0.0718315914273262, 0.10830432921648026, -0.006944071035832167, -0.15788578987121582, 0.08635467290878296, -0.05407490208745003, -0.030441055074334145, 0.10086072981357574, -0.005774236284196377, -1.0031192942960843e-07, -0.06710053235292435, -0.01190060656517744, -0.007112494204193354, 0.09783710539340973, -0.020757269114255905, -0.06161588430404663, -0.05720572918653488, 0.10590395331382751, -0.08450597524642944, 0.03666461259126663, 0.04758628085255623, 0.032475098967552185, -0.13088266551494598, 0.012475104071199894, -0.02637873962521553, 0.039337385445833206, 0.015076352283358574, 0.0758030116558075, 0.036370404064655304, 0.12058321386575699, 0.05856746807694435, -0.14826573431491852, 0.05903805047273636, 0.13020296394824982, -0.03653176128864288, -0.12623509764671326, -0.05261493846774101, 0.15723951160907745, -0.06084154173731804, 0.1906479299068451, 0.13310623168945312, -0.192404642701149, 0.09903748333454132, 0.1250515580177307, 0.08492215722799301, 0.06453853845596313, 0.009975306689739227, -0.010917320847511292, 0.05968019366264343, 0.2762996256351471, -0.10208167135715485, 0.07012105733156204, -0.07555661350488663, -0.04688309505581856, 0.12560002505779266, -0.07240444421768188, 0.13785740733146667, -0.011814972385764122, 0.0721401646733284, -0.09490757435560226, -0.01563163474202156, 0.03821015730500221, -0.16945698857307434, -0.09564197063446045, 0.11685317009687424, 0.002532225800678134, -0.2185143083333969, -0.028728481382131577, -0.11599588394165039, 0.025565722957253456, 0.08963128924369812, -0.024804528802633286, 0.059474315494298935, 0.0019660084508359432], metadata={'source': 'AAAMLP-569to.pdf', 'page': 18}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 19         \\'alcohol\\'         ]      # fit the model on given features     clf.fit(df_train[cols], df_train.quality)      # create training & test predictions     train_predictions = clf.predict(df_train[cols])     test_predictions = clf.predict(df_test[cols])      # calculate training & test accuracies     train_accuracy = metrics.accuracy_score(         df_train.quality, train_predictions     )     test_accuracy = metrics.accuracy_score(         df_test.quality, test_predictions     )          # append accuracies     train_accuracies.append(train_accuracy)     test_accuracies.append(test_accuracy)    # create two plots using matplotlib # and seaborn plt.figure(figsize=(10, 5)) sns.set_style(\"whitegrid\") plt.plot(train_accuracies, label=\"train accuracy\") plt.plot(test_accuracies, label=\"test accuracy\") plt.legend(loc=\"upper left\", prop={\\'size\\': 15}) plt.xticks(range(0, 26, 5)) plt.xlabel(\"max_depth\", size=20) plt.ylabel(\"accuracy\", size=20) plt.show() ═════════════════════════════════════════════════════════════════════════  This generates a plot, as shown in figure 2.   We see that the best score for test data is obtained when max_depth has a value of 14. As we keep increasing the value of this parameter, test accuracy remains the same or gets worse, but the training accuracy keeps increasing. It means that our simple decision tree model keeps learning about the training data better and better with an increase in max_depth, but the performance on test data does not improve at all.'),\n",
       " VectorParams(vector=[-0.09430795162916183, -0.02399032935500145, 0.06377842277288437, 0.05435248836874962, 0.0958886444568634, -0.0632731020450592, -0.08131879568099976, 0.13990741968154907, -0.0046320389956235886, -0.01502271369099617, -0.09158673882484436, 0.01617228426039219, 0.037972040474414825, -0.12041735649108887, -0.06377911567687988, -0.07265941798686981, 0.08165742456912994, 0.0899076908826828, -0.1602782905101776, -0.04754791036248207, 0.08046700060367584, -0.019463922828435898, 0.023631252348423004, 0.09195353835821152, -0.16663143038749695, -0.07471299916505814, -0.02176474966108799, -0.0941728800535202, -0.037072956562042236, -0.020330337807536125, 0.13397710025310516, 0.009695560671389103, -0.049972135573625565, 0.041829437017440796, -0.016836998984217644, 0.029352163895964622, -0.05358554422855377, 0.07710335403680801, 0.007950917817652225, 0.039555858820676804, -0.0002742503711488098, 0.018227849155664444, 0.005591044668108225, 0.04863937944173813, 0.08062096685171127, 0.07710669934749603, -0.025046629831194878, -0.13421088457107544, -0.02201874926686287, 0.04794785752892494, -0.18093062937259674, 0.0107363136485219, 0.00722151342779398, 0.05311399698257446, -0.03754156082868576, -0.09105034917593002, -0.046936824917793274, -0.002407483058050275, -0.061638183891773224, 0.028929578140378, 0.010232138447463512, -0.13509415090084076, 0.009451597929000854, -0.062014129012823105, -0.003375992411747575, -0.029863793402910233, -0.0016044205985963345, 0.025620726868510246, -0.037700727581977844, 0.10612156242132187, 0.01565069705247879, 0.11421328783035278, -0.06487152725458145, 0.08213944733142853, 0.050360098481178284, -0.0024911384098231792, -0.0006079734885133803, 0.014743351377546787, 0.02642901986837387, 0.0063314312137663364, 0.06524883955717087, 0.001435621757991612, 0.10277210175991058, -0.09263139963150024, 0.06682994961738586, -0.09817231446504593, 0.04075346514582634, -0.07560408115386963, 0.01378717739135027, -0.09648657590150833, -0.009947487153112888, -0.0771234855055809, -0.1297598034143448, 0.07338029891252518, 0.14102803170681, 0.032082200050354004, 0.08330532163381577, -0.022780459374189377, -0.03736534342169762, 0.020535018295049667, -0.019789637997746468, 0.10886797308921814, 0.025953341275453568, -0.023696264252066612, 0.11226093769073486, 0.05069127306342125, -0.005317376926541328, -0.081722691655159, 0.18783603608608246, -0.10080995410680771, 0.0785418227314949, -0.012326929718255997, -0.022875959053635597, -0.06997361779212952, 0.10156398266553879, 0.06224752590060234, -0.07463251054286957, 0.03217386081814766, -0.18596665561199188, 0.18891185522079468, -0.13935865461826324, 0.013905249536037445, -0.018014930188655853, -0.0308629609644413, 0.10698235034942627, 0.024067623540759087, -0.05260774865746498, 1.1047959328652103e-32, -0.041600994765758514, -0.01105286180973053, -0.034993138164281845, -0.05250834673643112, 0.004193658009171486, -0.15998448431491852, 0.07889901846647263, 0.008394300937652588, 0.058114390820264816, 0.07572783529758453, -0.11877356469631195, -0.06912868469953537, -0.07557625323534012, 0.046122509986162186, 0.04824155941605568, 0.0882149487733841, -0.11087051779031754, -0.025914106518030167, -0.02453269250690937, -0.0029615003149956465, 0.15049101412296295, -0.1074967086315155, 0.05491490289568901, -0.11488063633441925, -0.0051875184290111065, -0.026051897555589676, 0.022419260814785957, 0.10115595906972885, -0.1717061996459961, 0.026919392868876457, -0.08815955370664597, 0.02759513445198536, -0.01703719049692154, 0.16441607475280762, 0.02500830963253975, -0.046404413878917694, 0.023001059889793396, 0.023854577913880348, 0.013440364971756935, 0.03370412811636925, -0.05368911102414131, -0.0020779103506356478, 0.016500554978847504, 0.06426487863063812, 0.0613265261054039, -0.08017110824584961, -0.015050029382109642, -0.056096650660037994, -0.11084580421447754, 0.008353118784725666, -0.060362111777067184, -0.04773608222603798, -0.05584888532757759, -0.06830760091543198, -0.13620373606681824, 0.13342221081256866, -0.009142366237938404, -0.07995525747537613, 0.04396318271756172, 0.10172881186008453, 0.006842873990535736, -0.1481771618127823, -0.02982570044696331, 0.1656574010848999, -0.06798744946718216, -0.06351522356271744, 0.007842950522899628, -0.07181400060653687, 0.06078210473060608, 0.05699720233678818, -0.01432740781456232, -0.014750164933502674, -0.06876175105571747, -0.06720907986164093, 0.06011921167373657, 0.015327885746955872, 0.10028315335512161, 0.06792981922626495, 0.016493389382958412, 0.05538386106491089, 0.016876764595508575, 0.13609029352664948, 0.00231748609803617, -0.169194757938385, -0.08055480569601059, -0.0088282385841012, 0.031125593930482864, -0.04794260859489441, -0.01746329851448536, -0.05248063802719116, -0.12513019144535065, -0.02318745292723179, -0.013223502784967422, -0.12882152199745178, 0.01785976253449917, -9.429141977096575e-33, -0.00713192205876112, 0.05107615143060684, -0.053712163120508194, 0.18539902567863464, 0.03553348034620285, -0.022027811035513878, 0.06124907359480858, 0.06616457551717758, -0.12018520385026932, 0.004777129273861647, 0.01576029695570469, 0.007738362532109022, 0.07612093538045883, 0.0010631445329636335, -0.07757475972175598, -0.051032159477472305, 0.027537379413843155, 0.009557461366057396, 0.07015708088874817, -0.09953094273805618, -0.0027376655489206314, 0.08839083462953568, -0.09061532467603683, -0.03451497107744217, -0.040312934666872025, 0.03944484144449234, -0.19454273581504822, 0.11229639500379562, 0.08666477352380753, -0.006507197394967079, 0.0032692078966647387, 0.01628471538424492, -0.013907368294894695, 0.07922784984111786, 0.11299317330121994, 0.11228480190038681, 0.12448068708181381, -0.06145327538251877, 0.009993785060942173, 0.16279231011867523, 0.033872928470373154, 0.05728868767619133, -0.1406526416540146, 0.053787581622600555, 0.012960001826286316, -0.010659225285053253, -0.10746187716722488, -0.08362937718629837, 0.04101583734154701, -0.07746907323598862, 0.09039363265037537, -0.043249521404504776, 0.015727395191788673, 0.1005479246377945, -0.00893867015838623, 0.05895077809691429, -0.09844116121530533, 0.11512910574674606, -0.023347320035099983, 0.09410536289215088, 0.03804337978363037, -0.011533872224390507, -0.008442030288279057, 0.11100127547979355, 0.003844823921099305, 0.10955100506544113, -0.011509864591062069, 0.10954658687114716, 0.1535647064447403, 0.08722764253616333, -0.07208194583654404, -0.0179118812084198, 0.0006155262235552073, 0.025194939225912094, 0.01185405533760786, 0.1276361346244812, -0.049132101237773895, 0.029414931312203407, -0.004899215884506702, -0.01766500622034073, -0.1092446893453598, -0.07727883756160736, -0.12833504378795624, 0.13452117145061493, 0.0842396691441536, 0.08197825402021408, -0.006654449738562107, 0.07173680514097214, -0.006307290866971016, -0.07586570829153061, -0.003155430778861046, -0.050068993121385574, -0.06945174932479858, -0.04833206534385681, -0.127358540892601, -9.950012724857515e-08, -0.07738662511110306, -0.0081624835729599, 0.02026122249662876, -0.08835174888372421, 0.12979084253311157, -0.1337675303220749, 0.0999450832605362, 0.14602462947368622, -0.008076848462224007, 0.07931650429964066, 0.07173121720552444, 0.021290410310029984, -0.0025960970669984818, 0.010169352404773235, -0.00174341828096658, 0.045750487595796585, -0.053280267864465714, 0.11565043777227402, 0.02088247239589691, 0.15568320453166962, 0.031081082299351692, -0.014850668609142303, 0.019627626985311508, 0.0095472177490592, 0.15358735620975494, -0.060766514390707016, -0.05362965911626816, 0.12706533074378967, -0.0791478380560875, 0.05437446013092995, 0.017308102920651436, -0.021734053269028664, 0.04353979602456093, 0.022693878039717674, -0.0003577029856387526, 0.1339287906885147, 0.06081950291991234, -0.07198430597782135, -0.06760819256305695, 0.054478470236063004, -0.13471508026123047, 0.013951892964541912, 0.07045656442642212, -0.006465231068432331, 0.07028952240943909, -0.09144459664821625, 0.06280350685119629, 0.030167968943715096, -0.10145699977874756, -0.185553640127182, -0.07077716290950775, 0.07071485370397568, -0.038667451590299606, -0.01628798246383667, 0.023571157827973366, -0.017503490671515465, -0.07285217195749283, -0.024451252073049545, -0.10712762922048569, 0.04334111884236336, 0.01044979877769947, -0.011968396604061127, -0.08600378036499023, 0.016086149960756302], metadata={'source': 'AAAMLP-569to.pdf', 'page': 19}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 20 This is called overfitting.   The model fits perfectly on the training set and performs poorly when it comes to the test set. This means that the model will learn the training data well but will not generalize on unseen samples. In the dataset above, one can build a model with very high max_depth which will have outstanding results on training data, but that kind of model is not useful as it will not provide a similar result on the real-world samples or live data. \\n Figure 2: Training and test accuracies for different values of max_depth.  One might argue that this approach isn’t overfitting as the accuracy of the test set more or less remains the same. Another definition of overfitting would be when the test loss increases as we keep improving training loss. This is very common when it comes to neural networks.   Whenever we train a neural network, we must monitor loss during the training time for both training and test set. If we have a very large network for a dataset which is quite small (i.e. very less number of samples), we will observe that the loss for both training and test set will decrease as we keep training. However, at some point, test loss will reach its minima, and after that, it will start increasing even though training loss decreases further. We must stop training where the validation loss reaches its minimum value.   This is the most common explanation of overfitting.'),\n",
       " VectorParams(vector=[-0.06724515557289124, -0.04988875985145569, 0.09921836853027344, 0.02571367286145687, 0.1840350180864334, -0.07991570234298706, -0.056014616042375565, -0.011323516257107258, -0.0734960064291954, -0.06911904364824295, -0.07587166130542755, -0.11325579881668091, 0.0020616548135876656, -0.10313862562179565, -0.04745609685778618, 0.004817965906113386, 0.059015482664108276, 0.05745353549718857, -0.14947578310966492, 0.0376550629734993, 0.07616178691387177, -0.03501441329717636, -0.0378691703081131, 0.0843571349978447, -0.1150912344455719, 0.07437833398580551, -0.026345424354076385, -0.017206350341439247, -0.07734721153974533, -0.11756135523319244, 0.08875281363725662, -0.000592067139223218, -0.20405885577201843, -0.08016587048768997, 0.02975037507712841, -0.002334427088499069, -0.006279892288148403, 0.1078914925456047, 0.0012879433343186975, 0.03759286552667618, -0.045593902468681335, -0.00951320119202137, 0.004303836263716221, 0.0034823985770344734, 0.1259821504354477, 0.0553363598883152, 0.037764325737953186, -0.09104536473751068, 0.03277219459414482, 0.031833358108997345, -0.11522766947746277, -0.06643691658973694, -0.1091085895895958, 0.10116645693778992, -0.05335678532719612, -0.06177308410406113, -0.07783970981836319, -0.02044157311320305, -0.04398556053638458, -0.07089116424322128, -0.06261797249317169, -0.10649792104959488, -0.037260860204696655, 0.03909987956285477, -0.11764076352119446, -0.06451617926359177, -0.043104153126478195, 0.007421748712658882, -0.12618179619312286, 0.16126157343387604, 0.0762450322508812, 0.17063885927200317, 0.007282717153429985, 0.16290470957756042, -0.026769723743200302, 0.10422983765602112, 0.06452728062868118, -0.0311279334127903, 0.04929501563310623, 0.014162042178213596, 0.040350716561079025, 0.08094903081655502, -0.04892599210143089, -0.04258954897522926, 0.1387825310230255, -0.05681772530078888, 0.017193499952554703, -0.041830796748399734, -0.02891700156033039, 0.0023152437061071396, 0.06339890509843826, -0.042149774730205536, 0.11710692197084427, -0.008226793259382248, 0.1624448299407959, 0.07642742246389389, 0.04688071459531784, 0.038317952305078506, -0.0010661639971658587, 0.06926710158586502, -0.12258459627628326, 0.16012313961982727, 0.08551149815320969, 0.030750738456845284, 0.1160033717751503, -0.006881628651171923, -0.0067298999056220055, 0.030622098594903946, 0.17725242674350739, -0.11121390759944916, 0.17184390127658844, -0.02128690853714943, -0.053280122578144073, -0.051589760929346085, 0.07023093104362488, 0.11961062252521515, -0.010707654058933258, 0.003046335419639945, -0.033101897686719894, 0.1520695686340332, -0.13112398982048035, 0.040751002728939056, 0.14574004709720612, 0.006623511202633381, 0.07097017765045166, -0.06279055774211884, -0.1118578165769577, 1.188462331032162e-32, -0.08775021135807037, 0.00017612327064853162, -0.016143599525094032, -0.005368766374886036, -0.05972215533256531, -0.12455730140209198, 0.00192888337187469, 0.05278646573424339, 0.02695436216890812, 0.054608967155218124, -0.046311311423778534, -0.05016487091779709, -0.03494378924369812, 0.023570409044623375, 0.11786581575870514, 0.045875415205955505, -0.056498076766729355, -0.01080802921205759, -0.08238349109888077, 0.0036942847073078156, 0.1883658617734909, -0.12885738909244537, 0.015055756084620953, 0.06714019924402237, 0.011834968812763691, -0.02037503384053707, 0.02107028104364872, 0.010170361027121544, -0.0887683779001236, 0.05520841106772423, 0.0031124271918088198, -0.0028609272558242083, 0.03277149796485901, 0.14049763977527618, 0.00433335592970252, -0.10657618194818497, -0.023942980915308, -0.09882839769124985, 0.11086352169513702, 0.05373774468898773, -0.09748201817274094, -0.010546540841460228, 0.014657311141490936, 0.07274569571018219, 0.042170166969299316, -0.08965040743350983, -0.04931022226810455, -0.02204497903585434, -0.1974082738161087, 0.10361199080944061, -0.009551407769322395, -0.013040117919445038, -0.08263441920280457, -0.008837178349494934, -0.3006362020969391, 0.09093569219112396, 0.0056195445358753204, -0.02516431175172329, 0.013821820728480816, 0.024235812947154045, -0.037006229162216187, -0.10695338994264603, -0.07812294363975525, 0.012722352519631386, -0.05929500237107277, -0.0169665664434433, -0.021218229085206985, -0.0521245039999485, 0.012723510153591633, -0.0670444667339325, -0.046481888741254807, -0.03303438052535057, -0.0650925263762474, 0.0008825290715321898, 0.11599612981081009, -0.08053150027990341, 0.09787414222955704, 0.10286027193069458, 0.04020097106695175, -0.007980533875524998, 0.08929654210805893, 0.1208188608288765, -0.03361060842871666, -0.13313107192516327, -0.03736259788274765, 0.014415262266993523, -0.013472890481352806, -0.08905220031738281, -0.1383754163980484, 0.10832265764474869, -0.18618346750736237, 0.01900041475892067, -0.059201110154390335, -0.15870867669582367, 0.021484021097421646, -1.0167935768484567e-32, 0.07277750223875046, -0.011766736395657063, 0.14663192629814148, 0.1444634646177292, 0.04255734011530876, -0.02486547827720642, -0.0491478368639946, -0.12130963802337646, -0.05893661081790924, -0.1707814633846283, -0.02415095828473568, 0.013864085078239441, 0.09580239653587341, -0.0018444668967276812, -0.15773127973079681, -0.007832172326743603, 0.0014306545490399003, 0.06094537675380707, 0.10026513785123825, 0.06306050717830658, -0.07381102442741394, 0.019101958721876144, -0.08436203002929688, 0.024716190993785858, -0.0023166926112025976, 0.07020778208971024, -0.18326251208782196, -0.03274377062916756, 0.13241833448410034, 0.07588613033294678, -0.08909400552511215, 0.03435792028903961, 0.07543843239545822, -0.061836447566747665, -0.04293403774499893, 0.14245983958244324, 0.021727778017520905, -0.04500776529312134, 0.04870022088289261, 0.1875929981470108, 0.05291403457522392, 0.06616545468568802, -0.11319100111722946, -0.06924425810575485, -0.023278439417481422, -0.014038147404789925, -0.1832527071237564, 0.04958527535200119, 0.02270122617483139, -0.04643494263291359, 0.02092038467526436, 0.035831302404403687, -0.023115824908018112, 0.10618885606527328, 0.07858273386955261, 0.024899037554860115, 0.01274948287755251, 0.00907075498253107, -0.13918942213058472, 0.0624251514673233, -0.01946769468486309, 0.013868067413568497, 0.009913631714880466, 0.07398643344640732, 0.11536388099193573, 0.0965653657913208, 0.0858728438615799, 0.041126806288957596, 0.02102023735642433, -0.010499801486730576, -0.14863799512386322, 0.0025427949149161577, 0.0005919671966694295, -0.05192222446203232, 0.07269395142793655, 0.10553471744060516, 0.015875551849603653, 0.008642937988042831, 0.0484529547393322, 0.025726083666086197, -0.03757917508482933, -0.1688256859779358, -0.09676159173250198, 0.11740200966596603, 0.05966711789369583, 0.21304631233215332, 0.06258087605237961, -0.004729056265205145, -0.0444042794406414, -0.10851869732141495, -0.08936399966478348, 0.037638068199157715, -0.020677611231803894, 0.06738121807575226, -0.060277629643678665, -9.898507613570473e-08, 0.036434486508369446, -0.023797737434506416, 0.05769692733883858, -0.013086254708468914, 0.12776483595371246, -0.09604580700397491, -0.054524924606084824, 0.04498559236526489, 0.03292792662978172, -0.03815039247274399, 0.09039600938558578, 0.014044263400137424, 0.036062732338905334, 0.001569382380694151, 0.020876437425613403, 0.015793876722455025, -0.09494022279977798, 0.05543799698352814, -0.05142282694578171, 0.15941470861434937, -0.0005254283896647394, -0.07062460482120514, 0.047036197036504745, 0.015248852781951427, 0.18991784751415253, -0.09664394706487656, -0.08283292502164841, 0.09711603820323944, -0.007079693488776684, 0.04262877255678177, -0.03200370818376541, -0.10938388109207153, 0.0021410933695733547, 0.0282285138964653, 0.06348200142383575, 0.01505846343934536, 0.042958322912454605, -0.06775112450122833, -0.04215371608734131, 0.08954700082540512, 0.10508132725954056, 0.12716636061668396, -0.015024780295789242, -0.0100543899461627, 0.13365596532821655, -0.017395352944731712, 0.10298974812030792, -0.029718006029725075, -0.11474262177944183, -0.04938438907265663, -0.02011963352560997, -0.014523900113999844, 0.00986037589609623, 0.05803479254245758, -0.009291350841522217, -0.02122889831662178, -0.03362950682640076, 0.04122966155409813, 0.06503578275442123, 0.05580970272421837, 0.022886015474796295, -0.1840987354516983, -0.09045529365539551, 0.10979700088500977], metadata={'source': 'AAAMLP-569to.pdf', 'page': 20}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 21 Occam’s razor in simple words states that one should not try to complicate things that can be solved in a much simpler manner. In other words, the simplest solutions are the most generalizable solutions. In general, whenever your model does not obey Occam’s razor, it is probably overfitting.  \\n Figure 3: Most general definition of overfitting.  Now we can go back to cross-validation.  While explaining about overfitting, I decided to divide the data into two parts. I trained the model on one part and checked its performance on the other part. Well, this is also a kind of cross-validation commonly known as a hold-out set. We use this kind of (cross-) validation when we have a large amount of data and model inference is a time-consuming process.  There are many different ways one can do cross-validation, and it is the most critical step when it comes to building a good machine learning model which is generalizable when it comes to unseen data. Choosing the right cross-validation depends on the dataset you are dealing with, and one’s choice of cross-validation on one dataset may or may not apply to other datasets. However, there are a few types of cross-validation techniques which are the most popular and widely used.   These include:  • k-fold cross-validation • stratified k-fold cross-validation'),\n",
       " VectorParams(vector=[-0.06993516534566879, 0.005613240879029036, 0.021162953227758408, 0.005550766363739967, 0.19667407870292664, -0.026701023802161217, -0.030397076159715652, -0.08539486676454544, -0.03969521075487137, -0.10341037064790726, -0.09861458837985992, -0.12611742317676544, 0.05961647629737854, -0.14893193542957306, 0.029464498162269592, 0.0066389343701303005, -0.08003485202789307, 0.11088918149471283, -0.1558089256286621, 0.0181050356477499, 0.03266600891947746, -0.1415620595216751, -0.051629796624183655, 0.0736251175403595, -0.14808976650238037, 0.06433206051588058, -0.015220609493553638, 0.011436214670538902, 0.03475721552968025, -0.030835174024105072, 0.2227504700422287, -0.09254380315542221, -0.10145783424377441, -0.019457098096609116, 0.025210851803421974, -0.0030519338324666023, -0.05589486286044121, 0.14839743077754974, 0.004890641663223505, 0.09717630594968796, -0.04276813939213753, -0.07944449037313461, 0.0407012403011322, 0.03639376908540726, 0.13356594741344452, 0.17696572840213776, -0.10110990703105927, -0.06318320333957672, 0.013001740910112858, 0.024000758305191994, 0.017672520130872726, -0.05667395889759064, -0.055467333644628525, 0.12298167496919632, -0.06355713307857513, -0.07456687837839127, -0.052778713405132294, 0.08269850164651871, -0.025398384779691696, -0.03413447365164757, -0.039486564695835114, -0.16662149131298065, -0.04987126961350441, 0.013694941066205502, 0.04785929247736931, -0.07006716728210449, -0.10009827464818954, 0.07511023432016373, -0.0426609180867672, -0.024572035297751427, 0.00041544451960362494, 0.17709648609161377, 0.049340128898620605, 0.08348768204450607, 0.029225053265690804, 0.12996484339237213, 0.04832712560892105, -0.03735175356268883, 0.042282890528440475, -0.022452890872955322, -0.02991841360926628, 0.009146741591393948, 0.06251893937587738, 0.044998276978731155, 0.060994185507297516, -0.04156799986958504, -0.012279313988983631, -0.07884692400693893, -0.09402455389499664, -0.018012870103120804, 0.10536278784275055, -0.059958361089229584, 0.19578978419303894, 0.03974888101220131, 0.0842379480600357, 0.05105162039399147, 0.04185674339532852, 0.013902021571993828, 0.07938943058252335, 0.042540837079286575, -0.09891947358846664, 0.12438967823982239, 0.14270737767219543, -0.0024364611599594355, 0.055834732949733734, -0.12474371492862701, -0.022129833698272705, -0.11668995022773743, 0.21578770875930786, -0.1818467080593109, 0.10855323076248169, 0.06399047374725342, -0.05233174189925194, -0.021431028842926025, 0.05779418349266052, 0.04384884238243103, -0.10092534124851227, 0.03473588824272156, -0.08128546923398972, 0.16544541716575623, -0.17153191566467285, 0.0006581228226423264, 0.19577260315418243, -0.013022243976593018, 0.12342371791601181, -0.006684137508273125, -0.07016249001026154, 7.713910578886603e-33, -0.04860774800181389, -0.06488741934299469, -0.05155394226312637, 0.02170352078974247, -0.04132083058357239, -0.20558269321918488, -0.09494507312774658, 0.014767404645681381, -0.02860247902572155, 0.0760183110833168, 0.0017655420815572143, -0.08389098942279816, 0.08554664999246597, 0.10938089340925217, 0.14079247415065765, 0.11757960915565491, 0.03982466831803322, -0.04951806366443634, -0.07666614651679993, -0.008026329800486565, 0.08980007469654083, -0.030871473252773285, 0.08944763243198395, 0.08583630621433258, -0.10267752408981323, 0.024679258465766907, -0.043676018714904785, 0.09966713935136795, -0.08521727472543716, 0.08997238427400589, -0.12068437784910202, 0.14024855196475983, -0.060118306428194046, 0.2064559906721115, 0.11533539742231369, 0.07679199427366257, -0.011416726745665073, 0.0015142139745876193, 0.06823938339948654, 0.12344720214605331, -0.021697400137782097, -0.0869421511888504, 0.09712906926870346, 0.0002878400555346161, 0.06222241371870041, -0.18689486384391785, -0.093063123524189, -0.014944879338145256, -0.023581095039844513, 0.03507178649306297, -0.07368192076683044, -0.02070114202797413, -0.024334227666258812, -0.09124787151813507, -0.09139746427536011, 0.1762588769197464, -0.048758264631032944, -0.11258965730667114, 0.08507276326417923, 0.02330354042351246, 0.05382680147886276, -0.07774251699447632, -0.09503421932458878, 0.20053665339946747, -0.11391374468803406, 0.026601692661643028, -0.004415798466652632, -0.10631215572357178, 0.002363918349146843, 0.0023180439602583647, -0.10547955334186554, -0.05679672583937645, -0.11031856387853622, 0.051829658448696136, 0.07734231650829315, -0.10700083523988724, 0.12030954658985138, 0.21184110641479492, -0.06511817127466202, 0.0940479263663292, 0.09246326237916946, 0.10756959021091461, -0.06045294553041458, -0.1733638197183609, -0.009597217664122581, -0.05199725180864334, -0.08375908434391022, -0.10147081315517426, -0.17031072080135345, -0.0416250117123127, -0.21153110265731812, 0.04209272563457489, -0.04861040785908699, -0.12374123930931091, 0.08712087571620941, -8.529491334690154e-33, 0.04294101148843765, 0.18760627508163452, -0.04957752302289009, 0.05241258442401886, 0.06713276356458664, -0.0015284355031326413, 0.054863180965185165, -0.04423331096768379, -0.05700894072651863, 0.0517556294798851, -0.06211591511964798, -0.028841132298111916, 0.044512923806905746, -0.076444610953331, -0.2596403658390045, -0.024170050397515297, -0.06924338638782501, 0.061595816165208817, 0.06279468536376953, -0.035999663174152374, -0.02219950035214424, -0.051954012364149094, -0.08537435531616211, 0.06664599478244781, -0.07167108356952667, -0.009789010509848595, -0.08791710436344147, -0.014204567298293114, 0.12037646025419235, 0.12299834191799164, -0.047332074493169785, -0.13061176240444183, -0.03474690765142441, 0.019794907420873642, 0.009744149632751942, -0.011430066078901291, -0.0225183367729187, -0.04930225759744644, 0.10060776025056839, 0.1683882176876068, 0.002835208084434271, 0.09617549180984497, -0.1375075727701187, -0.011145438067615032, 0.0034011260140687227, 0.026853229850530624, -0.050278693437576294, -0.029903637245297432, -0.09995035827159882, -0.2347899079322815, 0.06411269307136536, 0.06993389874696732, -0.0678211972117424, 0.005958292167633772, 0.029090523719787598, 0.001289213658310473, -0.012113990262150764, 0.09120038151741028, -0.006680884398519993, 0.08785425126552582, -0.05247938632965088, -0.011599164456129074, -0.004853188060224056, 0.17915129661560059, 0.036615367978811264, 0.08785158395767212, -0.008961292915046215, 0.03936415910720825, -5.1139573770342395e-05, 0.024686196818947792, -0.10473708063364029, 0.004999937955290079, 0.018105583265423775, -0.08176930248737335, -0.09271540492773056, -0.001446569338440895, -0.044923946261405945, -0.11953511089086533, 0.016310861334204674, -0.0495942160487175, -0.0009117873851209879, -0.2318059504032135, -0.039839692413806915, 0.12953361868858337, 0.006919145584106445, 0.15323948860168457, 0.08097956329584122, 0.06296142190694809, -0.10891377180814743, -0.15505877137184143, 0.015513249672949314, -0.030008899047970772, 0.08777374774217606, 0.2331644594669342, -0.1284870058298111, -9.920096744053808e-08, 0.04805941879749298, -0.02473369427025318, 0.06576411426067352, 0.04466359317302704, 0.004974300507456064, -0.030701469630002975, -0.05678156018257141, 0.036592572927474976, -0.03592865541577339, 0.004636451601982117, 0.0034227806609123945, 0.05469370633363724, -0.07154664397239685, 0.04555496573448181, 0.07208853214979172, 0.028203003108501434, 0.02029215544462204, 0.19019360840320587, -0.06022920459508896, 0.13913844525814056, 0.13577589392662048, -0.08383271843194962, 0.1022636666893959, 0.0034586098045110703, 0.19874557852745056, -0.08634434640407562, -0.08806359022855759, 0.08822408318519592, -0.09017547219991684, -0.04729384556412697, -0.04480217769742012, -0.052147455513477325, -0.01608271896839142, 0.0946124866604805, 0.09007544070482254, 0.10910864919424057, -0.07672475278377533, -0.005242727696895599, 0.004254544153809547, 0.02736092545092106, -0.02031075954437256, 0.10750260204076767, -0.049029700458049774, 0.028012290596961975, -0.0015630997950211167, 0.028606044128537178, -0.00018012613872997463, 0.03256707638502121, -0.10807603597640991, 0.00177047960460186, 0.0064542959444224834, 0.020015984773635864, 0.06009268760681152, 0.07928851246833801, 0.033215638250112534, 0.012546386569738388, 0.013236495666205883, -0.13168129324913025, 0.04999300092458725, -0.12125561386346817, 0.023960227146744728, -0.03426016494631767, -0.00824600737541914, 0.009570319205522537], metadata={'source': 'AAAMLP-569to.pdf', 'page': 21}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 22 • hold-out based validation • leave-one-out cross-validation • group k-fold cross-validation  Cross-validation is dividing training data into a few parts. We train the model on some of these parts and test on the remaining parts. Take a look at figure 4.  \\n Figure 4: Splitting a dataset into training and validation sets  Figure 4 & 5 say that when you get a dataset to build machine learning models, you separate them into two different sets: training and validation. Many people also split it into a third set and call it a test set. We will, however, be using only two sets. As you can see, we divide the samples and the targets associated with them. We can divide the data into k different sets which are exclusive of each other. This is known as k-fold cross-validation.   Figure 5: K-fold cross-validation'),\n",
       " VectorParams(vector=[-0.12895826995372772, -0.11422458291053772, -0.004505448509007692, -0.07470814883708954, 0.1607377827167511, -0.11021728068590164, 0.010256578214466572, -0.011441806331276894, -0.018806658685207367, 0.010987581685185432, 0.08112887293100357, -0.1802150011062622, 0.08219346404075623, -0.0200264323502779, -0.036776185035705566, -0.015301985666155815, -0.05582749471068382, 0.10116884857416153, -0.2255888730287552, -0.003065243363380432, 0.02431357279419899, -0.03377196937799454, 0.06878542900085449, 0.02776363492012024, -0.13279053568840027, -0.10340411216020584, 0.11450902372598648, 0.06900545209646225, -0.1002502590417862, -0.08199169486761093, 0.09023486822843552, 0.08582797646522522, -0.06706872582435608, -0.04312983527779579, -0.02077304944396019, 0.09841008484363556, -0.15005061030387878, 0.11728940904140472, -0.08789625018835068, 0.16509519517421722, -0.12143276631832123, -0.05718133971095085, -0.05792281776666641, 0.018141547217965126, 0.04291100800037384, 0.12250719219446182, -0.1291886568069458, -0.08676936477422714, 0.1324806809425354, 0.026102215051651, -0.05196194350719452, 0.19460633397102356, -0.2313825637102127, 0.11983044445514679, -0.035381048917770386, -0.14183317124843597, 0.03926912322640419, -0.1308014988899231, 0.013286896981298923, 0.022823967039585114, 0.11041425168514252, -0.14457343518733978, -0.06433508545160294, -0.09346920251846313, 0.05351252481341362, -0.009521148167550564, -0.030240889638662338, -0.07628177851438522, 0.0735427513718605, -0.05048103630542755, -0.011904354207217693, 0.05746269226074219, 0.02505919709801674, 0.0913555920124054, -0.13341683149337769, 0.022461697459220886, 0.22315442562103271, 0.030172161757946014, 0.08313774317502975, -0.05102315917611122, -0.03789415955543518, 0.10824784636497498, 0.11021772772073746, -0.0636054053902626, -0.018911806866526604, -0.17471452057361603, 0.0166143998503685, 0.0918988585472107, 0.028156094253063202, 0.01373550109565258, 0.16568921506404877, 0.0873570442199707, -0.04852079600095749, -0.10841213166713715, -0.0015175639418885112, 0.06032022461295128, 0.09731520712375641, 0.07975174486637115, 0.12263105809688568, 0.05686787888407707, -0.01986086741089821, -0.053907305002212524, -0.01570625603199005, 0.0592203252017498, 0.09329192340373993, -0.13666634261608124, 0.08466237038373947, -0.056328464299440384, 0.1471332460641861, -0.09262020140886307, 0.022677788510918617, 0.0110841765999794, -0.15342403948307037, 0.010307501070201397, 0.09714867919683456, 0.040321074426174164, -0.00610170466825366, 0.11481596529483795, -0.12450406700372696, 0.10048080235719681, -0.11525817960500717, 0.05411148816347122, 0.04257967323064804, -0.058379337191581726, 0.04873703047633171, -0.08090464025735855, -0.025514882057905197, 1.4009641590119842e-32, -0.05902577564120293, -0.019916605204343796, 0.11997520923614502, -0.10793588310480118, -0.0044193449430167675, -0.13406026363372803, -0.12645256519317627, 0.016431253403425217, -0.08689259737730026, 0.09426923096179962, -0.16088591516017914, 0.15994423627853394, -0.029117703437805176, 0.0431378073990345, -0.024283118546009064, 0.006166945677250624, -0.1594848334789276, -0.005107836797833443, -0.040459420531988144, -0.053406812250614166, 0.32342472672462463, -0.03829776495695114, 0.15588104724884033, -0.03718798980116844, -0.034204039722681046, -0.13935686647891998, -0.0922451987862587, 0.009842869825661182, -0.08948174118995667, 0.008729456923902035, -0.29177525639533997, -0.01676907204091549, 0.05298692733049393, -0.06387697905302048, 0.0024136784486472607, -0.04327669367194176, -0.023419994860887527, 0.09685917943716049, -0.11892919987440109, 0.07723395526409149, -0.025905245915055275, 0.08268052339553833, 0.06058904901146889, -0.12041537463665009, 0.022762861102819443, 0.022695204243063927, 0.16612589359283447, 0.13129976391792297, -0.031323835253715515, 0.06849921494722366, 0.11290667951107025, -0.13692137598991394, -0.02309863269329071, -0.0010012219427153468, -0.1304270178079605, 0.1518554538488388, 0.17361241579055786, -0.10341937094926834, 0.08869944512844086, 0.014708532951772213, -0.016454022377729416, -0.03544503077864647, -0.09501224756240845, 0.06798862665891647, -0.02968847006559372, -0.053602173924446106, 0.16855676472187042, -0.04074608534574509, 0.05579004064202309, -0.07047705352306366, -0.1286529004573822, 0.19691810011863708, -0.1402699053287506, -0.110646553337574, -0.002604217967018485, -0.07609224319458008, 0.0644952803850174, 0.08309615403413773, -0.12306620180606842, 0.036175645887851715, -0.06607569009065628, 0.0930529236793518, -0.09247060865163803, -0.3104281425476074, -0.07880838215351105, 0.04733596742153168, 0.08249984681606293, -0.11463307589292526, -0.2629307806491852, -0.2522103786468506, -0.15190590918064117, 0.020298151299357414, -0.006470040883868933, -0.10968276858329773, 0.06972094625234604, -1.3725546646045173e-32, 0.08807976543903351, -0.0864565446972847, 0.06562986224889755, 0.10537031292915344, 0.052986789494752884, 0.17527654767036438, 0.08500668406486511, 0.0977998599410057, -0.19526547193527222, -0.2162398099899292, -0.0634104460477829, -0.06663723289966583, 0.08438017219305038, -0.09865931421518326, -0.09595238417387009, 0.08612798899412155, -0.13139203190803528, 0.19913657009601593, -0.10991016030311584, 0.07031576335430145, -0.04591704159975052, 0.17927952110767365, -0.1355545073747635, -0.044760946184396744, -0.10954251140356064, 0.06377018988132477, 0.009737273678183556, 0.13761581480503082, 0.1739991158246994, -0.02638988383114338, -0.040339019149541855, -0.005662636831402779, -0.12460038810968399, 0.06127197667956352, 0.05182000994682312, -0.08341682702302933, 0.04826568812131882, -0.03296242654323578, -0.03365610912442207, 0.1396135687828064, 0.10417909175157547, 0.2401742935180664, -0.1910371631383896, 0.12261402606964111, -0.01992085389792919, 0.032050736248493195, -0.11477792263031006, -0.01570107974112034, 0.027407970279455185, -0.10993747413158417, 0.03878987580537796, -0.023245910182595253, -0.10227906703948975, 0.10369594395160675, 0.017807157710194588, 0.10015172511339188, -0.16261382400989532, 0.030548151582479477, -0.10616640746593475, 0.10633450001478195, -0.10041070729494095, -0.08537808060646057, -0.055390723049640656, 0.015645509585738182, 0.1244128942489624, 0.0583939291536808, -0.08574128150939941, -0.06008284538984299, -0.03893303871154785, 0.0992644727230072, -0.08643285930156708, 0.03071421943604946, 0.07858669757843018, -0.16562138497829437, -0.00029451109003275633, 0.07370180636644363, 0.03883785381913185, 0.07571448385715485, 0.014542050659656525, 0.051592838019132614, 0.05219690874218941, -0.14103418588638306, 0.051635220646858215, 0.22000691294670105, -0.05806789547204971, 0.1833740919828415, 0.09702268242835999, 0.020790260285139084, 0.15494582056999207, -0.03827277943491936, -0.027159513905644417, -0.042980048805475235, 0.1373293399810791, 0.2635664641857147, 0.03031305782496929, -9.976499626418445e-08, 0.13739463686943054, 0.01832006126642227, 0.049270156770944595, -0.01776835136115551, 0.012965177185833454, 0.0914771780371666, -0.08610378205776215, -0.020355910062789917, -0.03634704276919365, 0.010862353257834911, 0.12577009201049805, 0.008363823406398296, -0.21326881647109985, 0.08720307797193527, -0.06381262838840485, 0.12603633105754852, 0.05811787024140358, 0.17310599982738495, 0.07214431464672089, 0.1647399365901947, 0.019109781831502914, -0.10282725095748901, 0.03213643655180931, 0.004621606785804033, -0.012682865373790264, -0.013132348656654358, -0.022975226864218712, 0.024081023409962654, 0.06504777073860168, -0.0640222579240799, 0.030240146443247795, -0.20764946937561035, 0.008581295609474182, 0.06617471575737, 0.1507766842842102, 0.033024176955223083, -0.07610614597797394, -0.010509822517633438, 0.02933553420007229, 0.13672451674938202, -0.043996717780828476, 0.046494755893945694, -0.11919423192739487, -0.095451720058918, -0.024056287482380867, 0.06430087238550186, -0.005904552526772022, 0.028790956363081932, 0.011692590080201626, 0.13870012760162354, -0.07255951315164566, -0.14084181189537048, -0.12563563883304596, 0.023765793070197105, 0.06871820241212845, 0.13132312893867493, -0.05834630876779556, -0.03374458849430084, 0.09813091158866882, -0.011388900689780712, 0.026699744164943695, -0.026155587285757065, -0.030412694439291954, -0.016329403966665268], metadata={'source': 'AAAMLP-569to.pdf', 'page': 22}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 23 We can split any data into k-equal parts using KFold from scikit-learn. Each sample is assigned a value from 0 to k-1 when using k-fold cross validation.   ═════════════════════════════════════════════════════════════════════════ # import pandas and model_selection module of scikit-learn import pandas as pd from sklearn import model_selection   if __name__ == \"__main__\":     # Training data is in a CSV file called train.csv     df = pd.read_csv(\"train.csv\")          # we create a new column called kfold and fill it with -1     df[\"kfold\"] = -1      # the next step is to randomize the rows of the data     df = df.sample(frac=1).reset_index(drop=True)      # initiate the kfold class from model_selection module     kf = model_selection.KFold(n_splits=5)      # fill the new kfold column     for fold, (trn_, val_) in enumerate(kf.split(X=df)):         df.loc[val_, \\'kfold\\'] = fold      # save the new csv with kfold column      df.to_csv(\"train_folds.csv\", index=False) ═════════════════════════════════════════════════════════════════════════  You can use this process with almost all kinds of datasets. For example, when you have images, you can create a CSV with image id, image location and image label and use the process above.  The next important type of cross-validation is stratified k-fold. If you have a skewed dataset for binary classification with 90% positive samples and only 10% negative samples, you don\\'t want to use random k-fold cross-validation. Using simple k-fold cross-validation for a dataset like this can result in folds with all negative samples. In these cases, we prefer using stratified k-fold cross-validation. Stratified k-fold cross-validation keeps the ratio of labels in each fold constant. So, in each fold, you will have the same 90% positive and 10% negative samples. Thus, whatever metric you choose to evaluate, it will give similar results across all folds.'),\n",
       " VectorParams(vector=[-0.012187611311674118, -0.11007892340421677, -0.07296787202358246, -0.037000227719545364, 0.12540070712566376, 0.05110233649611473, 0.04738495871424675, 0.00907035544514656, -0.15704290568828583, -0.04857164993882179, 0.047612205147743225, -0.1697845458984375, 0.01083013042807579, -0.18099166452884674, -0.03363124281167984, 0.05441324785351753, -0.06091675907373428, 0.015945618972182274, -0.1291528195142746, -0.06040257215499878, 0.04705255851149559, 0.023108769208192825, 0.04252674803137779, 0.08509951829910278, 0.018618620932102203, -0.08792467415332794, 0.055737875401973724, 0.13280493021011353, -0.1295347958803177, -0.07832761853933334, 0.008640694431960583, 0.15867894887924194, -0.03574752062559128, -0.012005901895463467, 0.0052205901592969894, -0.06748418509960175, -0.07283522188663483, 0.07545572519302368, -0.01209224108606577, 0.19656768441200256, -0.020446933805942535, -0.013538792729377747, -0.0022059648763388395, 0.08018764853477478, 0.03752784803509712, 0.14368967711925507, -0.10085485130548477, -0.029338372871279716, 0.06030299887061119, 0.04975796490907669, -0.1033979132771492, 0.056017909198999405, -0.14397551119327545, -0.0552511140704155, -0.02735966630280018, -0.15970748662948608, 0.05461881309747696, -0.11816495656967163, 0.06831753998994827, 0.045106105506420135, 0.01419343613088131, -0.15885978937149048, 0.03792279586195946, -0.058534231036901474, 0.04442211240530014, -0.027576090767979622, -0.033128343522548676, 0.08183310925960541, -0.04703093320131302, 0.018688088282942772, -0.008117549121379852, 0.12697231769561768, -0.015336406417191029, 0.09895946830511093, -0.15204407274723053, 0.014639250934123993, 0.08678006380796432, -0.04635317996144295, 0.03414945304393768, -0.04817638546228409, -0.14456231892108917, 0.007896934635937214, -0.06512550264596939, 0.003484567627310753, -0.02699395827949047, -0.17836925387382507, 0.0164628978818655, 0.010604364797472954, -0.03338130563497543, -0.003045428078621626, 0.09203862398862839, 0.05237334594130516, -0.05954083427786827, -0.05126439407467842, -0.03752118721604347, 0.16139431297779083, 0.11288473755121231, 0.008354677818715572, 0.08559359610080719, 0.10276555269956589, -0.056104082614183426, -0.043750736862421036, 0.00746782636269927, -0.019349699839949608, -0.04920373857021332, -0.0695909783244133, 0.0918058305978775, 0.0268491692841053, 0.10395240783691406, -0.13179323077201843, 0.007238220889121294, -0.022328650578856468, -0.10369144380092621, -0.027699226513504982, 0.1357235610485077, 0.07635614275932312, 0.023882659152150154, 0.10792854428291321, -0.18615642189979553, -0.01770586334168911, -0.07692105323076248, 0.09371454268693924, 0.07358802109956741, -0.028199121356010437, -0.08009112626314163, -0.11973319947719574, 0.03137420862913132, 9.770968387476004e-33, -0.05360395461320877, -0.002629751106724143, 0.04563600942492485, -0.08814441412687302, -0.005036176647990942, -0.18013732135295868, -0.03238333761692047, 0.006118736229836941, -0.0365215502679348, 0.05814909562468529, -0.20809344947338104, 0.09305477142333984, -0.02227284014225006, 0.017920173704624176, 0.012937397696077824, -0.06426052749156952, -0.024458305910229683, 0.05784769356250763, -0.11631711572408676, -0.03461972996592522, 0.30754590034484863, -0.05325223505496979, 0.09218833595514297, -0.0940319150686264, -0.09751327335834503, -0.07032671570777893, -0.060505565255880356, 0.05857086926698685, -0.10277736186981201, -0.0005100340349599719, -0.17890526354312897, 0.013714732602238655, 0.06186762824654579, -0.09346039593219757, 0.05756945535540581, -0.14669619500637054, -0.03784210979938507, 0.16553394496440887, 0.02725536935031414, 0.00998668558895588, 0.034963686019182205, 0.06109732389450073, 0.1451188623905182, 0.01351181697100401, -0.024377379566431046, 0.029784152284264565, 0.015802109614014626, 0.11408962309360504, -0.03409692645072937, 0.07992950081825256, 0.0411677211523056, -0.1964125782251358, 0.04301442578434944, 0.1295413225889206, -0.11663943529129028, 0.2552642822265625, 0.15585830807685852, -0.00572170177474618, 0.040601953864097595, -0.0385768860578537, 0.030567733570933342, -0.013117668218910694, -0.047992341220378876, 0.029771186411380768, 0.06413238495588303, 0.11601216346025467, 0.11688568443059921, -0.1097785010933876, 0.052994225174188614, -0.11085878312587738, -0.05775744095444679, 0.14998942613601685, -0.20246824622154236, -0.08311005681753159, 0.03830535709857941, -0.11141346395015717, -0.06827437877655029, 0.13464970886707306, -0.12436904013156891, -0.06557143479585648, -0.01599043607711792, 0.08515007793903351, -0.1359754353761673, -0.3120235204696655, -0.061169661581516266, -0.012558803893625736, 0.057905297726392746, -0.08370880782604218, -0.20438268780708313, -0.2065603882074356, -0.12220863997936249, -0.012988067232072353, 0.047027166932821274, -0.13158804178237915, 0.13438114523887634, -1.2049533412798479e-32, 0.038944095373153687, 0.030411148443818092, 0.17941631376743317, 0.1638491302728653, 0.10818575322628021, 0.17987023293972015, 0.08413286507129669, 0.10420460999011993, -0.12657631933689117, -0.09474706649780273, -0.12912987172603607, -0.09875554591417313, 0.0303520318120718, -0.09380646795034409, -0.031347066164016724, 0.10099949687719345, -0.03787994757294655, 0.24074605107307434, -0.1086302325129509, 0.008700367994606495, -0.023083170875906944, 0.1646975874900818, -0.07912015169858932, 0.013472361490130424, -0.06913620978593826, 0.03413132205605507, 0.030958225950598717, 0.08498681336641312, 0.08505471795797348, -0.08712484687566757, 0.01857011206448078, -0.029837675392627716, -0.1959371119737625, 0.05541112646460533, 0.030525660142302513, -0.06205771863460541, 0.1465970277786255, -0.1007399708032608, -0.13747021555900574, 0.15045073628425598, 0.15651506185531616, 0.18282106518745422, -0.27582693099975586, 0.11812429130077362, 0.057487331330776215, 0.07556109875440598, -0.07445161789655685, 0.01517112459987402, 0.04155350476503372, -0.06327131390571594, 0.015510759316384792, 0.051670316606760025, -0.06853421032428741, 0.11692702025175095, 0.08894462883472443, 0.07796802371740341, -0.14483408629894257, 0.0004937252961099148, -0.20719337463378906, 0.019093433395028114, -0.16708576679229736, -0.05540359392762184, -0.07679962366819382, -0.04996546730399132, 0.2086905837059021, 0.04408153146505356, -0.09401719272136688, 0.010827889665961266, 0.030955186113715172, 0.00935277808457613, -0.08685581386089325, -0.007753911428153515, 0.04349028319120407, -0.14900289475917816, -0.14058886468410492, -0.0015811577904969454, -0.10404270887374878, 0.011780321598052979, -0.032435111701488495, 0.14635170996189117, -0.0038887476548552513, -0.22113831341266632, 0.1475999355316162, 0.21930913627147675, -0.03440243378281593, 0.07366228848695755, 0.14917930960655212, -0.02516753599047661, 0.05547814443707466, -0.047255367040634155, -0.03983933851122856, -0.06566812843084335, 0.11922045052051544, 0.17239020764827728, -0.006576078478246927, -1.0028246322235645e-07, 0.09116452932357788, 0.03955327346920967, -0.03526158630847931, 0.08248324692249298, 0.036919355392456055, 0.09084446728229523, -0.2236904799938202, 0.014328500255942345, -0.06471730023622513, -0.036299124360084534, 0.005997308995574713, 0.012068318203091621, -0.12072531878948212, 0.0973520576953888, -0.08996456861495972, 0.04283919557929039, 0.04726345092058182, 0.21658621728420258, 0.0027388460002839565, 0.11224523931741714, 0.12000370770692825, -0.09128156304359436, 0.10781178623437881, 0.0028467178344726562, 0.010189737193286419, -0.10703764110803604, -0.07569476962089539, 0.09889780730009079, 0.12073322385549545, 0.05574634298682213, 0.05865050479769707, -0.20523695647716522, -0.05018593743443489, 0.06724613159894943, 0.1486988067626953, 0.04012260586023331, -0.04846620932221413, 0.028183409944176674, 0.11233492195606232, 0.22642973065376282, -0.14921632409095764, 0.08168259263038635, -0.2359943836927414, -0.024460868909955025, 0.03259379044175148, 0.029367074370384216, -0.02864021807909012, -0.03240307793021202, 0.11090908199548721, -0.023739701136946678, -0.00979780312627554, -0.10234015434980392, -0.06336367130279541, -0.018320148810744286, 0.045954782515764236, 0.11922159045934677, -0.09067657589912415, 0.07932186126708984, 0.0121225044131279, -0.04088312014937401, 0.032985761761665344, -0.02883831225335598, 0.003327579703181982, 0.045693907886743546], metadata={'source': 'AAAMLP-569to.pdf', 'page': 23}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 24 It’s easy to modify the code for creating k-fold cross-validation to create stratified k-folds. We are only changing from model_selection.KFold to model_selection.StratifiedKFold and in the kf.split(...) function, we specify the target column on which we want to stratify. We assume that our CSV dataset has a column called “target” and it is a classification problem!  ═════════════════════════════════════════════════════════════════════════ # import pandas and model_selection module of scikit-learn import pandas as pd from sklearn import model_selection  if __name__ == \"__main__\":     # Training data is in a csv file called train.csv     df = pd.read_csv(\"train.csv\")      # we create a new column called kfold and fill it with -1     df[\"kfold\"] = -1      # the next step is to randomize the rows of the data     df = df.sample(frac=1).reset_index(drop=True)      # fetch targets     y = df.target.values      # initiate the kfold class from model_selection module     kf = model_selection.StratifiedKFold(n_splits=5)      # fill the new kfold column     for f, (t_, v_) in enumerate(kf.split(X=df, y=y)):         df.loc[v_, \\'kfold\\'] = f      # save the new csv with kfold column     df.to_csv(\"train_folds.csv\", index=False) ═════════════════════════════════════════════════════════════════════════  For the wine dataset, let’s look at the distribution of labels.  ═════════════════════════════════════════════════════════════════════════ b = sns.countplot(x=\\'quality\\', data=df) b.set_xlabel(\"quality\", fontsize=20) b.set_ylabel(\"count\", fontsize=20) ═════════════════════════════════════════════════════════════════════════  Note that we continue on the code above. So, we have converted the target values. Looking at figure 6 we can say that the quality is very much skewed. Some classes'),\n",
       " VectorParams(vector=[-0.10065391659736633, 0.031181802973151207, -0.054384745657444, -6.76528288749978e-05, 0.04171412065625191, 0.0688856840133667, -0.07446148246526718, 0.10133668035268784, -0.07792484760284424, 0.009031571447849274, -0.061920952051877975, -0.07033460587263107, -0.06197161599993706, -0.1184857115149498, -0.06926896423101425, 0.13194607198238373, -0.034383296966552734, 0.016350170597434044, -0.11460291594266891, -0.03009086847305298, 0.09434223920106888, -0.1716405749320984, -0.06523250788450241, 0.006899601314216852, -0.09756159782409668, -0.01965651847422123, -0.0621306486427784, -0.022972658276557922, 0.005255779251456261, -0.05667869374155998, 0.05778849124908447, 0.13821543753147125, -0.048213329166173935, -0.1254410296678543, -0.04816169664263725, 0.007319224998354912, -0.1725643277168274, 0.03825250640511513, -0.005553732626140118, 0.10801173001527786, 0.14636754989624023, 0.014773129485547543, -0.11355956643819809, 0.06146971136331558, 0.01969332993030548, 0.0525590144097805, -0.006952672731131315, 0.09399013966321945, -0.014668465591967106, 0.1374422311782837, -0.07782894372940063, -0.00785099621862173, -0.1040203720331192, 0.005628771148622036, 0.010075653903186321, -0.1184031069278717, -0.005852240603417158, 0.016582513228058815, -0.06497927010059357, 0.03865779563784599, 0.06241495534777641, -0.19730620086193085, -0.11505507677793503, -0.05265261232852936, 0.03262774273753166, 0.008594293147325516, 0.02282155677676201, 0.08701891452074051, -0.04733375832438469, 0.04847509413957596, 0.027802014723420143, 0.06347242742776871, -0.04435296356678009, 0.0675249844789505, -0.048086658120155334, 0.09845738112926483, 0.10944506525993347, -0.12576435506343842, -0.053216081112623215, 0.03093949519097805, 0.0013785400660708547, 0.07521221041679382, -0.09944882243871689, -0.19165554642677307, -0.06665732711553574, -0.07812164723873138, -0.03047359362244606, 0.02027839422225952, 0.005481576081365347, -0.009248699992895126, 0.09712282568216324, -0.011633585207164288, 0.013976368121802807, 0.014216453768312931, 0.043362051248550415, 0.1917751133441925, 0.026751084253191948, 0.0965324267745018, 0.049178630113601685, 0.052081480622291565, -0.013296832330524921, 0.1705097109079361, 0.09926408529281616, 0.02932674065232277, -0.022841928526759148, -0.14412666857242584, 0.06474286317825317, -0.056771863251924515, 0.03679743781685829, -0.16559939086437225, 0.0286491010338068, 0.07348905503749847, 0.014469104818999767, -0.018635913729667664, 0.07518494874238968, 0.12743328511714935, -0.034030184149742126, -0.017679456621408463, -0.0494145043194294, 0.12155395746231079, -0.051740556955337524, 0.14403189718723297, 0.15605971217155457, -0.007858694531023502, 0.011117570102214813, -0.10624181479215622, -0.0013527109986171126, 3.1758217000150506e-33, -0.040525421500205994, 0.06100163608789444, -0.03620273619890213, -0.012257863767445087, -0.10342661291360855, -0.14760608971118927, -0.009605547413229942, 0.00032064897823147476, -0.10650433599948883, 0.09903691709041595, -0.06913942843675613, 0.006891784258186817, -0.02754857949912548, -0.08241362124681473, 0.1818355768918991, 0.008158130571246147, 0.054311297833919525, 0.13198243081569672, -0.11107495427131653, -0.009233629330992699, 0.22003060579299927, -0.18529504537582397, 0.03309737518429756, 0.04125462844967842, -0.11790701746940613, 0.07825149595737457, 0.06423560529947281, 0.09915240854024887, -0.06407389789819717, 0.03426731005311012, -0.07244942337274551, 0.0699690729379654, 0.03394608944654465, -0.03325439244508743, 0.09404509514570236, 0.013597676530480385, -0.12465064972639084, 0.0274946428835392, 0.07156257331371307, -0.008076702244579792, -0.09003611654043198, 0.07493635267019272, 0.09366845339536667, 0.17924857139587402, 0.05152082443237305, -0.1398046314716339, 0.04285070300102234, 0.017895372584462166, -0.1327153593301773, 0.10915666818618774, 0.037756823003292084, -0.03368857502937317, -0.08206485211849213, 0.049640849232673645, -0.09672687947750092, 0.12132959812879562, 0.09096093475818634, -0.05376235395669937, 0.0023514532949775457, 0.1431875079870224, -0.02392989955842495, -0.12036075443029404, -0.06860554218292236, 0.06694880872964859, -0.09725003689527512, 0.1330219805240631, -0.004812601488083601, -0.11504656076431274, -0.014238685369491577, -0.03125385195016861, -0.02935631573200226, 0.024899056181311607, -0.12766559422016144, -0.01400493923574686, 0.07296111434698105, -0.05268878489732742, 0.20704905688762665, 0.08428527414798737, -0.026565751060843468, -0.018267543986439705, 0.06694226711988449, 0.07748951762914658, -0.07075351476669312, -0.20314675569534302, -0.002845068695023656, -0.030421828851103783, 0.07643400132656097, -0.053369924426078796, -0.008148212917149067, -0.03178311511874199, -0.19148971140384674, 0.040585700422525406, 0.014072977006435394, -0.197129487991333, 0.03616930544376373, -2.6129626787466917e-33, 0.13579261302947998, -0.043323613703250885, 0.09542318433523178, 0.10677704960107803, 0.06386299431324005, 0.09355012327432632, -0.004914226476103067, 0.07380209863185883, -0.13476689159870148, -0.11874549835920334, -0.047332629561424255, 0.016244834288954735, 0.13480275869369507, 0.03696247562766075, -0.18021027743816376, -0.00416214345023036, 0.08715005964040756, 0.04446026310324669, 0.02450532466173172, -0.022836783900856972, 0.07128164917230606, 0.04467478767037392, -0.14625823497772217, 0.0759761855006218, -0.1059848740696907, 0.07217790931463242, -0.18734395503997803, 0.007682933006435633, 0.11204071342945099, -0.024084342643618584, -0.02200273796916008, -0.29174238443374634, -0.07402913272380829, -0.017570549622178078, 0.0026833126321434975, 0.019308151677250862, 0.09802783280611038, 0.029103437438607216, -0.029182588681578636, 0.21718382835388184, 0.08746835589408875, 0.053727392107248306, -0.31230247020721436, -0.015940699726343155, -0.009072569198906422, 0.07695908844470978, -0.23297035694122314, -0.015367471612989902, 0.0930335521697998, -0.1504041850566864, 0.06497593224048615, 0.07086525857448578, -0.11410202831029892, 0.10923507064580917, 0.0639771893620491, 0.05947941169142723, -0.028697149828076363, 0.08599550276994705, -0.1688471883535385, 0.12222571671009064, -0.0489339753985405, -0.007632941007614136, -0.01054092962294817, -0.05931689590215683, 0.08937051892280579, -0.01833762787282467, 0.102328822016716, -0.028438888490200043, -0.04610428214073181, -0.015151035971939564, -0.10731782764196396, 0.017378268763422966, -0.014610102400183678, -0.040331318974494934, -0.06865909695625305, 0.09762758761644363, -0.05373188108205795, -0.01378896925598383, 0.14602521061897278, 0.056705910712480545, -0.1981193870306015, -0.03695544973015785, 0.03681095689535141, 0.11473868787288666, 0.10481620579957962, 0.09794329106807709, 0.104079470038414, -0.10116657614707947, -0.005491452757269144, -0.03352738171815872, -0.012883508577942848, -0.02745204232633114, 0.05392085760831833, 0.10398197919130325, 0.007480002008378506, -9.92570718949537e-08, 0.05941421911120415, 0.12485460937023163, 0.042069561779499054, 0.13456304371356964, 0.10830304026603699, -0.059121180325746536, -0.07168339937925339, 0.035627346485853195, -0.01691216602921486, 0.006828823126852512, 0.14791594445705414, -0.06979607790708542, -0.17254729568958282, 0.11659055203199387, 0.03354227542877197, 0.05326620861887932, -0.0963531956076622, 0.1091461107134819, -0.08877581357955933, 0.14798052608966827, 0.09362215548753738, 0.028464647009968758, 0.12915529310703278, -0.009586043655872345, 0.10162732005119324, -0.10834270715713501, -0.02288014255464077, 0.16783350706100464, 0.039524804800748825, 0.030485866591334343, -0.001090122968889773, -0.1526893973350525, -9.216640319209546e-05, -0.010496770031750202, 0.05857640877366066, 0.0566704235970974, -0.12343713641166687, 0.08179666101932526, 0.044100306928157806, 0.18414872884750366, 0.05691264197230339, -0.019424645230174065, -0.0811074823141098, 0.013518596068024635, 0.05417875200510025, -0.013102537021040916, -0.0860518217086792, -0.0825866237282753, -0.04470229893922806, -0.06268879771232605, -0.02726476453244686, -0.0563303679227829, -0.016084427013993263, 0.06262501329183578, 0.1142188236117363, 0.06957059353590012, -0.04440099373459816, -0.0895804613828659, -0.01816498674452305, -0.07826666533946991, 0.006790843792259693, -0.24745766818523407, -0.0775163322687149, 0.08084150403738022], metadata={'source': 'AAAMLP-569to.pdf', 'page': 24}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 25 have a lot of samples, and some don’t have that many. If we do a simple k-fold, we won’t have an equal distribution of targets in every fold. Thus, we choose stratified k-fold in this case. \\n Figure 6: Distribution of “quality” in wine dataset  The rule is simple. If it’s a standard classification problem, choose stratified k-fold blindly.  But what should we do if we have a large amount of data? Suppose we have 1 million samples. A 5 fold cross-validation would mean training on 800k samples and validating on 200k. Depending on which algorithm we choose, training and even validation can be very expensive for a dataset which is of this size. In these cases, we can opt for a hold-out based validation.  The process for creating the hold-out remains the same as stratified k-fold. For a dataset which has 1 million samples, we can create ten folds instead of 5 and keep one of those folds as hold-out. This means we will have 100k samples in the hold-out, and we will always calculate loss, accuracy and other metrics on this set and train on 900k samples.  Hold-out is also used very frequently with time-series data. Let’s assume the problem we are provided with is predicting sales of a store for 2020, and you are provided all the data from 2015-2019. In this case, you can select all the data for 2019 as a hold-out and train your model on all the data from 2015 to 2018.'),\n",
       " VectorParams(vector=[-0.13299861550331116, -0.01645180955529213, -0.0054581961594522, -0.0024888806510716677, 0.1102847307920456, 0.09137502312660217, -0.09081961214542389, 0.020655574277043343, -0.014996981248259544, -0.03601204231381416, -0.052195217460393906, -0.026046015322208405, -0.026890698820352554, 0.033910658210515976, 0.039319247007369995, -0.028514141216874123, 0.01844136044383049, 0.08846516162157059, -0.04985693469643593, -0.019295988604426384, 0.07186073064804077, -0.14833366870880127, -0.09372197091579437, 0.054894302040338516, -0.08704926073551178, 0.007066658698022366, -0.02853749878704548, -0.027086393907666206, -0.08392824232578278, -0.05889494717121124, -0.0032572727650403976, -0.048866767436265945, -0.05946824327111244, -0.012924485839903355, -0.007117534056305885, -0.03716384246945381, -0.070500947535038, 0.11153481900691986, 0.006721607409417629, 0.04575464501976967, 0.03287594020366669, -0.06935950368642807, -0.04589539021253586, -0.021741973236203194, 0.1058444008231163, -0.041839852929115295, 0.07873864471912384, -0.017231212928891182, -0.053957100957632065, 0.01358164194971323, -0.03534196317195892, -0.010790187865495682, -0.045410268008708954, 0.037863217294216156, 0.02299315109848976, -0.13383261859416962, -0.0741639956831932, 0.031288400292396545, 0.02151637151837349, -0.004375597462058067, 0.019856778904795647, -0.1746409684419632, -0.06074681505560875, -0.09325393289327621, -0.023688720539212227, -0.007331621367484331, -0.000904793618246913, 0.038540344685316086, -0.06101948022842407, 0.12785704433918, 0.021192139014601707, 0.12696081399917603, -0.08489375561475754, 0.0370839387178421, -0.04051898419857025, 0.07852001488208771, 0.16367106139659882, -0.04823844134807587, -0.014038857072591782, 0.04150046780705452, 0.08165445178747177, 0.1342335194349289, -0.05861702561378479, -0.12172412872314453, 0.0037643411196768284, -0.007808852009475231, -0.050415344536304474, 0.028535375371575356, -0.031818635761737823, -0.0467112734913826, 0.11199696362018585, -0.02073160745203495, -0.007890937849879265, 0.014710512943565845, 0.09688348323106766, 0.020740022882819176, 0.08481532335281372, 0.04023030400276184, 0.15296968817710876, 0.033891987055540085, -0.05991791561245918, 0.12764404714107513, 0.1062031015753746, 0.029829321429133415, 0.09823250025510788, -0.0012940594460815191, 0.06186046078801155, -0.027835002169013023, 0.048486676067113876, -0.10062305629253387, 0.026986584067344666, 0.02436939813196659, -0.08870420604944229, 0.002266661496832967, 0.08712177723646164, 0.005561661906540394, -0.11566133052110672, -0.07633800059556961, -0.06948035210371017, 0.15018168091773987, -0.046354737132787704, 0.0932316705584526, 0.1241406798362732, 0.03941968083381653, 0.0783810243010521, 0.05543166771531105, -0.09625407308340073, 1.1376302084143631e-32, -0.029455112293362617, 0.13158519566059113, -0.018023109063506126, -0.09396889805793762, -0.03415549173951149, -0.06944993883371353, -0.007351540960371494, 0.032008349895477295, 0.047696832567453384, 0.08027280867099762, -0.04235793650150299, -0.05425361543893814, -0.018529141321778297, -0.06624346226453781, 0.182156041264534, 0.06359001249074936, 0.041781485080718994, 0.11180728673934937, -0.009631533175706863, -0.007418984081596136, 0.11905617266893387, -0.1881275177001953, -0.0321187861263752, 0.06374505907297134, -0.08847960829734802, -0.05074089393019676, 0.0666707456111908, 0.08676240593194962, -0.021289611235260963, 0.04808294400572777, -0.08262068033218384, 0.03512229770421982, 0.038372915238142014, 0.029163217172026634, 0.0918007642030716, -0.057260166853666306, -0.07023108005523682, -0.07691331952810287, 0.052265215665102005, 0.030224191024899483, -0.0673806294798851, 0.03792145475745201, 0.03807437792420387, 0.11617296934127808, 0.060835596174001694, -0.0487489178776741, 0.04343077912926674, -0.0103975310921669, -0.10995584726333618, 0.08892082422971725, 0.0038645134773105383, 0.011830611154437065, -0.08555485308170319, -0.17950457334518433, -0.05085355043411255, 0.16392254829406738, 0.03061089478433132, -0.17580033838748932, 0.008378234691917896, 0.12350922077894211, -0.08289463818073273, -0.12088654190301895, -0.07981862127780914, -0.043402355164289474, -0.04053908586502075, 0.05290171504020691, 0.061407361179590225, -0.016307100653648376, 0.002204687800258398, -0.09596124291419983, -0.04442634433507919, -0.029537644237279892, -0.03485593944787979, -0.00360667472705245, 0.17964191734790802, -0.05594244226813316, 0.23077096045017242, 0.05603286996483803, -0.01301481667906046, -0.11058994382619858, 0.06481501460075378, 0.08780895918607712, -0.016713880002498627, -0.15310195088386536, 0.04962212219834328, -0.005335384048521519, 0.013774419203400612, -0.03362119570374489, -0.10028502345085144, 0.03327750042080879, -0.16963236033916473, 0.02122032642364502, -0.012688607908785343, -0.08167499303817749, -0.01481777336448431, -8.318687728705285e-33, 0.08683030307292938, -0.03411013260483742, 0.039479807019233704, 0.053923673927783966, 0.058120325207710266, 0.04601021111011505, 0.005500507541000843, -0.0032777495216578245, -0.05071913078427315, -0.10719054192304611, -0.056524306535720825, -0.048628855496644974, 0.1574113368988037, 0.028614049777388573, -0.09343842417001724, 0.006030541379004717, -0.02188182808458805, 0.021321192383766174, 0.043513841927051544, 0.06559855490922928, 0.018907492980360985, -0.008280567824840546, -0.07652544230222702, -0.025588035583496094, -0.13239029049873352, 0.02197742462158203, -0.15396782755851746, 0.1451036036014557, 0.12166384607553482, 0.027454454451799393, 0.013260770589113235, -0.06936761736869812, -0.05759873613715172, -0.06895860284566879, -0.04530571028590202, 0.05026090890169144, -0.05150049552321434, -0.04202812537550926, 0.11494683474302292, 0.08839042484760284, 0.08546978235244751, 0.05577065050601959, -0.11121278256177902, -0.10857557505369186, -0.08011586964130402, 0.04705926030874252, -0.08317647874355316, 0.004110497422516346, 0.021816208958625793, -0.08509442955255508, 0.008155587129294872, 0.01385300513356924, -0.0930962860584259, 0.01651839166879654, -0.00024301421944983304, 0.007229947485029697, -0.07074066251516342, 0.0013767213094979525, -0.07077119499444962, 0.06351875513792038, -0.01673729345202446, 0.013892161659896374, 0.025692623108625412, 0.07725457847118378, 0.09121167659759521, 0.007728526834398508, 0.06899140775203705, -0.010064455680549145, -0.0037155388854444027, -0.004899396561086178, -0.12613362073898315, -0.09403221309185028, 0.0016511569265276194, 0.05564654618501663, -0.11382844299077988, -0.04285323992371559, -0.058622509241104126, 0.020642971619963646, 0.022450558841228485, 0.05372035875916481, -0.05640362575650215, -0.017387710511684418, -0.04099192097783089, -0.018590379506349564, 0.008206401951611042, 0.11774302273988724, 0.11847339570522308, 0.07392270863056183, 0.029779372736811638, -0.042307835072278976, -0.06519465893507004, -0.02048874832689762, 0.11778323352336884, 0.14012661576271057, 0.07127062976360321, -9.902827713403894e-08, 0.08229340612888336, 0.12510819733142853, 0.1107470765709877, 0.0048799095675349236, 0.07180319726467133, -0.11112707853317261, -0.014798109419643879, -0.0023205638863146305, 0.06992286443710327, 0.04189839959144592, 0.09681446850299835, -0.03399351239204407, -0.07240749150514603, 0.07072341442108154, -0.01648572087287903, 0.049940597265958786, -0.05124776065349579, 0.027941221371293068, -0.05912133678793907, 0.09789880365133286, 0.016137495636940002, 0.051805101335048676, 0.050570689141750336, -0.02500533126294613, 0.13521708548069, -0.08043655008077621, 0.07595822215080261, 0.16361533105373383, 0.001181471161544323, 0.03279587998986244, -0.032598093152046204, -0.006718899589031935, -0.04874304682016373, -0.0036948504857718945, 0.05903409421443939, -0.023481814190745354, 0.051903706043958664, 0.006716289557516575, -0.024893509224057198, 0.10871750861406326, 0.12423571944236755, 0.023521985858678818, -0.10904470831155777, -0.03461994603276253, -0.010703290812671185, -0.007886539213359356, -0.009671070612967014, -0.03542075678706169, -0.09341981261968613, -0.03467898443341255, -0.019257154315710068, -0.03890763595700264, -0.08195473253726959, 0.02761242166161537, 0.11762978881597519, 0.13902372121810913, -0.07728547602891922, -0.09795317053794861, 0.015961743891239166, -0.032800376415252686, -0.0265476256608963, -0.12744081020355225, 0.017405595630407333, 0.07169093936681747], metadata={'source': 'AAAMLP-569to.pdf', 'page': 25}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 26  Figure 7: Example of a time-series data  In the example presented in figure 7, let’s say our job is to predict the sales from time step 31 to 40. We can then keep 21 to 30 as hold-out and train our model from step 0 to step 20. You should note that when you are predicting from 31 to 40, you should include the data from 21 to 30 in your model; otherwise, performance will be sub-par.  In many cases, we have to deal with small datasets and creating big validation sets means losing a lot of data for the model to learn. In those cases, we can opt for a type of k-fold cross-validation where k=N, where N is the number of samples in the dataset. This means that in all folds of training, we will be training on all data samples except 1. The number of folds for this type of cross-validation is the same as the number of samples that we have in the dataset.   One should note that this type of cross-validation can be costly in terms of the time it takes if the model is not fast enough, but since it’s only preferable to use this cross-validation for small datasets, it doesn’t matter much.  Now we can move to regression. The good thing about regression problems is that we can use all the cross-validation techniques mentioned above for regression problems except for stratified k-fold. That is we cannot use stratified k-fold directly, but there are ways to change the problem a bit so that we can use stratified k-fold for regression problems. Mostly, simple k-fold cross-validation works for any regression problem. However, if you see that the distribution of targets is not consistent, you can use stratified k-fold.'),\n",
       " VectorParams(vector=[0.043525855988264084, 0.005415064282715321, -0.09078513830900192, -0.08592892438173294, 0.06813715398311615, 0.09820981323719025, -0.02198157086968422, 0.040797051042318344, -0.09729766845703125, 0.085356704890728, -0.07724154740571976, -0.13607783615589142, 0.006873362231999636, -0.02674911357462406, 0.0922565832734108, 0.08450433611869812, -0.04502299800515175, -0.002567509887740016, -0.08969960361719131, -0.16234292089939117, 0.20533643662929535, -0.05573413148522377, -0.013980170711874962, -0.07696034759283066, -0.005315087269991636, -0.08871280401945114, 0.05991887301206589, -0.02744867466390133, -0.0773390382528305, -0.060476988554000854, 0.045276228338479996, 0.08553056418895721, 0.09075053781270981, -0.07612090557813644, -0.006533521227538586, 0.020566409453749657, -0.14840726554393768, 0.04638873040676117, 0.0034667691215872765, 0.11626564711332321, -0.12590177357196808, -0.04277477785944939, 0.008664866909384727, 0.001954264473170042, 0.12881004810333252, -0.009196448139846325, -0.0011858867947012186, 0.12366268038749695, 0.07282199710607529, -0.045226648449897766, 0.12926775217056274, 0.04827243462204933, -0.001965399831533432, 0.10294733941555023, -0.08442804217338562, -0.27145639061927795, -0.09951251745223999, -0.06877451390028, 0.039863795042037964, 0.05586453527212143, -0.042649976909160614, -0.11042077094316483, 0.03434659540653229, -0.13975045084953308, 0.055656012147665024, 0.0245869979262352, 2.527368451410439e-05, -0.034931398928165436, 0.08385340869426727, 0.1375122368335724, 0.0393134206533432, 0.03725814074277878, -0.03649229556322098, 0.022104186937212944, -0.06665027141571045, -0.06199979782104492, 0.18588685989379883, -0.05080315098166466, -0.04333273321390152, 0.03386086970567703, -0.09834963083267212, 0.047056104987859726, -0.010362579487264156, -0.12196169048547745, -0.06566327810287476, -0.044256143271923065, -0.13154055178165436, 0.07438640296459198, -0.049715522676706314, 0.1179102286696434, 0.09780636429786682, 0.010875366628170013, 0.06774604320526123, 0.007318380754441023, 0.10520860552787781, 0.0038072383031249046, -0.029109787195920944, 0.14067156612873077, 0.12138543277978897, 0.09544724971055984, -0.043193090707063675, 0.044566601514816284, 0.03477657958865166, 0.06915207952260971, 0.10747592151165009, -0.04033106565475464, 0.09781094640493393, -0.018138818442821503, -0.015246489085257053, -0.10125136375427246, -0.007345197256654501, 0.0013088005362078547, -0.09507832676172256, 0.0489184707403183, 0.1383538395166397, 0.08500741422176361, -0.01752365753054619, 0.05068431794643402, -0.11764847487211227, 0.15713605284690857, 0.016933567821979523, 0.1725083589553833, 0.05402502417564392, 0.07632461935281754, 0.03164510801434517, -0.07422547042369843, -0.12446800619363785, 1.1556808792603994e-32, -0.018777573481202126, 0.0063736108131706715, 0.07357896119356155, -0.034626323729753494, 0.08101122826337814, -0.09558549523353577, -0.06401577591896057, 0.02012997306883335, -0.002070235088467598, 0.05740123614668846, -0.10020466148853302, 0.018430374562740326, 0.027302637696266174, -0.031527839601039886, -0.021007368341088295, -0.1095464825630188, 0.010563202202320099, 0.1095743477344513, -0.029814327135682106, -0.0781962126493454, -0.07665938138961792, -0.1567963808774948, 0.05024584382772446, 0.025338560342788696, -0.0986587256193161, -0.04073657840490341, 0.005359482951462269, 0.05716666579246521, 0.05134853720664978, 0.09943026304244995, -0.046360474079847336, 0.026636293157935143, 0.04599706083536148, -0.05390159413218498, 0.04711580276489258, -0.020251713693141937, -0.16187869012355804, 0.0992768257856369, 0.03734181076288223, 0.05928375571966171, -0.0127187455072999, 0.04344092682003975, 0.11108750849962234, 0.12483013421297073, -0.016858277842402458, -0.04518473520874977, 0.08252125978469849, 0.03938165679574013, -0.030334072187542915, 0.18382908403873444, 0.023299459367990494, -0.04473135992884636, -0.05456991866230965, 0.07142788916826248, -0.05582919716835022, 0.06925451755523682, 0.057982489466667175, -0.10175810009241104, 0.02183378115296364, 0.05634720250964165, 0.051125966012477875, -0.09150165319442749, -0.09441058337688446, 0.0039542545564472675, 0.09652062505483627, 0.04462429881095886, 0.08713871240615845, 0.013519569300115108, -0.038997769355773926, 0.020710624754428864, -0.1821201890707016, 0.09947718679904938, -0.07006910443305969, -0.00523946899920702, -0.03486961871385574, -0.0019838775042444468, 0.18080343306064606, 0.1513815075159073, -0.07550874352455139, -0.10680999606847763, 0.022355185821652412, 0.0915389135479927, -0.0673617273569107, -0.29156798124313354, -0.022844858467578888, 0.02768927998840809, -0.01777726411819458, -0.008965297602117062, -0.10441793501377106, -0.12749400734901428, -0.2695818543434143, -0.0009929448133334517, -0.13720108568668365, -0.13258884847164154, -0.005669021513313055, -1.430527548061577e-32, 0.01804449036717415, 0.07933671772480011, 0.12556926906108856, 0.06590965390205383, -0.0464957058429718, 0.16737015545368195, 0.058486457914114, -0.07945627719163895, -0.06602694094181061, -0.13506077229976654, -0.05496501177549362, -0.0024070031940937042, 0.1995391696691513, 0.02789023518562317, -0.08859868347644806, 0.04679017886519432, -0.18525363504886627, 0.09070844948291779, -0.03748343512415886, 0.0932319164276123, -0.12526512145996094, 0.0012640510685741901, -0.0732664093375206, -0.1371142417192459, -0.20455500483512878, -0.05381244793534279, -0.16909313201904297, -0.017742350697517395, 0.22335705161094666, -0.010136631317436695, 0.037987105548381805, -0.16405904293060303, -0.22015702724456787, -0.04799959436058998, 0.10200303047895432, -0.04116388037800789, -0.06001126766204834, -0.012585308402776718, 0.134391188621521, 0.06094910949468613, 0.11008930206298828, 0.02929266355931759, -0.24990278482437134, -0.049305275082588196, -0.014349455945193768, 0.012618569657206535, -0.12116139382123947, 0.02500506490468979, 0.09044671058654785, -0.12328138202428818, -0.02243245393037796, 0.16886626183986664, -0.04431487247347832, 0.06854190677404404, 0.04051573574542999, -0.014954263344407082, -0.1302308589220047, 0.12167498469352722, -0.024492545053362846, -0.007119717542082071, -0.08184333890676498, -0.016228675842285156, 0.02593366801738739, 0.03417461737990379, 0.007468867115676403, -0.13957059383392334, -0.058616966009140015, 0.09831957519054413, -0.01595156267285347, 0.03855159878730774, -0.08778297901153564, -0.06526332348585129, 0.016156721860170364, -0.056085094809532166, -0.12824198603630066, -0.039108410477638245, -0.09760867059230804, 0.028406059369444847, 0.04687550663948059, 0.11616118252277374, -0.014626949094235897, -0.0493830107152462, 0.012035531923174858, 0.06893961131572723, 0.09147782623767853, 0.03461531177163124, 0.257154256105423, 0.03647579252719879, 0.13578438758850098, 0.019779052585363388, -0.04130098968744278, -0.011148300021886826, 0.03824262320995331, 0.10835876315832138, 0.054635025560855865, -9.978621307027424e-08, 0.06735552102327347, 0.03855105862021446, 0.12928645312786102, 0.0372149720788002, 0.1938486397266388, 0.1301640123128891, -0.236154243350029, 0.0180412158370018, -0.07823964208364487, -0.05322573333978653, 0.08376260101795197, 0.002938907826319337, -0.16126388311386108, 0.006194327026605606, -0.09282857179641724, -0.003455059602856636, -0.12020861357450485, 0.10682560503482819, 0.07741841673851013, 0.13074235618114471, -0.04683248698711395, -0.0661180391907692, 0.14541944861412048, -0.07752423733472824, 0.042314160615205765, -0.0618479959666729, 0.06244296208024025, 0.06927721947431564, -0.01836259663105011, 0.06594746559858322, 0.08381317555904388, -0.02218971587717533, -0.10036855936050415, -0.11101753264665604, 0.03920278698205948, -0.006949339061975479, -0.15205885469913483, -0.05137696489691734, 0.08513577282428741, 0.14426970481872559, 0.013967377133667469, -0.1127578616142273, -0.013469547964632511, -0.024185990914702415, -0.031347017735242844, 0.11232069134712219, 0.019201211631298065, 0.015895994380116463, -0.11124590039253235, -0.011722752824425697, 0.012997608631849289, -0.017964284867048264, -0.11278308928012848, 0.029111847281455994, 0.06399323046207428, 0.15432322025299072, -0.11837188154459, -0.0815320760011673, 0.049763523042201996, -0.008646585047245026, -0.03180364891886711, -0.06756462156772614, -0.05548972263932228, -0.10957801342010498], metadata={'source': 'AAAMLP-569to.pdf', 'page': 26}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 27 To use stratified k-fold for a regression problem, we have first to divide the target into bins, and then we can use stratified k-fold in the same way as for classification problems. There are several choices for selecting the appropriate number of bins. If you have a lot of samples( > 10k, > 100k), then you don’t need to care about the number of bins. Just divide the data into 10 or 20 bins. If you do not have a lot of samples, you can use a simple rule like Sturge’s Rule to calculate the appropriate number of bins.  Sturge’s rule: Number of Bins = 1 + log2(N)  Where N is the number of samples you have in your dataset. This function is plotted in Figure 8. \\n Figure 8: Plotting samples vs the number of bins by Sturge’s Rule  Let’s make a sample regression dataset and try to apply stratified k-fold as shown in the following python snippet.  ═════════════════════════════════════════════════════════════════════════ # stratified-kfold for regression import numpy as np import pandas as pd  from sklearn import datasets from sklearn import model_selection'),\n",
       " VectorParams(vector=[0.013646534644067287, -0.08459793776273727, 0.005457580555230379, -0.008356628008186817, 0.17197905480861664, -0.06330633908510208, 0.03085591457784176, 0.001175921643152833, -0.08134672790765762, 0.04866825416684151, -0.0006606786628253758, -0.10320266336202621, 0.0012253497261554003, -0.09612424671649933, 0.022590873762965202, 0.08742989599704742, -0.0907488539814949, 0.005890886764973402, -0.1262960284948349, -0.07434266060590744, 0.06162505969405174, 0.09442519396543503, -0.0224557276815176, 0.024353858083486557, 0.019482692703604698, -0.023478087037801743, 0.12996730208396912, 0.05784374848008156, -0.09653114527463913, -0.10606399923563004, 0.007297233212739229, 0.11508156359195709, 0.024568689987063408, -0.024157634004950523, 0.017448166385293007, 0.041183311492204666, -0.15338099002838135, 0.039155442267656326, -0.0043054125271737576, 0.12118101119995117, -0.07987070828676224, -0.0034168469719588757, -0.004378234501928091, -0.043452173471450806, 0.13919104635715485, 0.004704407881945372, -0.0429065003991127, 0.0018168746028095484, 0.12598596513271332, 0.0005535735981538892, 0.029571225866675377, 0.03996485099196434, -0.036377519369125366, -0.019056854769587517, -0.145112544298172, -0.2674589455127716, 0.098979152739048, -0.12773041427135468, 0.06223199889063835, -0.015994416549801826, 0.03538621589541435, -0.06636307388544083, 0.013551614247262478, -0.10102581977844238, 0.025136243551969528, -0.04987124726176262, -0.03513927012681961, 0.011984639801084995, 0.0005612245877273381, 0.10776830464601517, -0.049351032823324203, 0.10841108858585358, -0.044011302292346954, 0.09411873668432236, -0.020412415266036987, -0.03878191486001015, 0.1558438092470169, -0.025605712085962296, 0.04269864782691002, 0.018833840265870094, -0.20153263211250305, -0.01728978380560875, 0.0032316185534000397, -0.05009055137634277, -0.10382064431905746, -0.1964118480682373, 0.03288840875029564, 0.10240476578474045, 0.01950022578239441, -0.028552548959851265, 0.05953599885106087, 0.0478445366024971, -0.04539358615875244, -0.017985234037041664, 0.0002500789996702224, 0.04816267266869545, 0.04506232589483261, 0.01985418237745762, 0.09867879003286362, 0.09568770229816437, -0.08849268406629562, -0.031068356707692146, -0.006617987994104624, 0.03632635623216629, 0.01183423399925232, -0.07518492639064789, 0.1476011425256729, -0.010606135241687298, 0.011166774667799473, -0.086431585252285, 0.001905938726849854, -0.021262308582663536, -0.08582838624715805, 0.14243684709072113, 0.139700248837471, 0.0343199223279953, -0.01142039056867361, -0.019715411588549614, -0.1756405532360077, 0.09841402620077133, -0.011627495288848877, 0.09493077546358109, 0.047583092004060745, 0.0912252813577652, -0.0479150153696537, -0.04813345894217491, -0.08379651606082916, 1.4291317954567695e-32, -0.03635942563414574, -0.07196025550365448, 0.05669397860765457, -0.042060744017362595, 0.10992729663848877, -0.053238701075315475, 0.009118727408349514, -0.05395489186048508, -0.006489884573966265, 0.09316452592611313, -0.21805556118488312, 0.02690211310982704, 0.010669068433344364, -0.07096778601408005, 0.021930566057562828, -0.11006312817335129, -0.03194316104054451, 0.10518133640289307, 0.004495654255151749, 0.012023502960801125, 0.13697122037410736, -0.03399727866053581, 0.06058933213353157, -0.08554862439632416, -0.09404007345438004, -0.06815611571073532, -0.07201880216598511, -0.015670446678996086, -0.0723504051566124, 0.037399519234895706, -0.21125578880310059, 0.04555971547961235, 0.005131744779646397, -0.0364241898059845, -0.04187275841832161, -0.06369347125291824, -0.02609732747077942, 0.09437215328216553, 0.026189759373664856, 0.0003692220489028841, 0.044492416083812714, 0.043742332607507706, 0.08375655859708786, -0.027601463720202446, -0.11108849197626114, -0.0018576730508357286, 0.040375687181949615, 0.13873521983623505, -0.03817222639918327, 0.10209933668375015, 0.023800687864422798, -0.11015705019235611, -0.012171096168458462, 0.029671261087059975, -0.0954698696732521, 0.10269759595394135, 0.0826338529586792, -0.07450807094573975, 0.11687307804822922, 0.03634790703654289, -0.011180823668837547, -0.029347894713282585, -0.09827644377946854, 0.08221210539340973, 0.08719305694103241, 0.0344494953751564, 0.21040590107440948, 0.06596305221319199, 0.11350117623806, -0.0197870172560215, -0.13185109198093414, 0.07190908491611481, -0.07308410108089447, -0.06571851670742035, 0.017665117979049683, -0.07629754394292831, 0.10257189720869064, 0.08379234373569489, -0.09617757797241211, -0.06922277063131332, 0.020925110206007957, 0.15463733673095703, -0.09376563876867294, -0.30584716796875, 0.007144441362470388, -0.02057974971830845, 0.0033176210708916187, -0.06618447601795197, -0.24820835888385773, -0.23283147811889648, -0.1922549456357956, -0.0618123821914196, -0.03663265332579613, -0.12076115608215332, 0.02778039313852787, -1.5982901345175e-32, 0.05669908970594406, 0.035487014800310135, 0.18502403795719147, 0.08545998483896255, 0.10534437745809555, 0.08716998994350433, -0.0029871934093534946, -0.05371823534369469, -0.03152021765708923, -0.1320960819721222, -0.10316865146160126, -0.1126018613576889, 0.12903909385204315, 0.05422000214457512, 0.06901516020298004, 0.04530370607972145, -0.12076868861913681, 0.08704467117786407, -0.07187043130397797, 0.01876724325120449, -0.10859591513872147, 0.04952285438776016, -0.051518023014068604, -0.09990249574184418, -0.23108062148094177, -0.024909110739827156, -0.05059235543012619, 0.07270753383636475, 0.10203422605991364, -0.07100339233875275, -0.07473386824131012, -0.0015834952937439084, -0.21272322535514832, 0.036833442747592926, 0.07233887910842896, -0.04412885755300522, 0.060499995946884155, -0.009888889268040657, 0.010164803825318813, 0.05384190008044243, 0.10509113222360611, 0.08651452511548996, -0.18762008845806122, 0.033416520804166794, 0.023898473009467125, 0.027455776929855347, -0.038127653300762177, 0.05392347648739815, 0.0006500700837932527, -0.10442843288183212, -0.037097055464982986, 0.05090362951159477, -0.07347298413515091, 0.05260465294122696, -0.05220678076148033, 0.057837001979351044, -0.13193807005882263, 0.012405015528202057, -0.05062242969870567, 0.034860558807849884, -0.13475476205348969, -0.018752191215753555, -0.016312794759869576, -0.0189230777323246, 0.104164257645607, -0.01759849488735199, -0.08666084706783295, -0.0036607596557587385, 0.020430589094758034, 0.09887775033712387, -0.10023532062768936, -0.047682542353868484, 0.0667552575469017, -0.04949383810162544, -0.06923901289701462, -0.00892146397382021, -0.0823291689157486, -0.05807477980852127, 0.03537796065211296, 0.16949942708015442, -0.018779072910547256, -0.07741127163171768, 0.050354693084955215, 0.06372272968292236, 0.04327864199876785, 0.01712515577673912, 0.17702147364616394, 0.12136304378509521, 0.08668862283229828, -0.03634478896856308, -0.0531049445271492, -0.05896025523543358, 0.1636735051870346, 0.1852264404296875, -0.00541987968608737, -1.0071669720446152e-07, 0.050848279148340225, 0.10108629614114761, 0.0752929225564003, 0.11101580411195755, 0.11503256112337112, 0.13238701224327087, -0.15803977847099304, 0.0779728814959526, -0.024769797921180725, -0.0332537479698658, 0.08675114065408707, 0.0057192957028746605, -0.06623329967260361, 0.11525137722492218, -0.09878655523061752, 0.0714995339512825, -0.05923604592680931, 0.047063153237104416, 0.04381982609629631, 0.07515479624271393, 0.03769870847463608, -0.08677264302968979, 0.07681044191122055, -0.056701432913541794, 0.04809647426009178, -0.1235840693116188, -0.030923113226890564, 0.06445544213056564, 0.08280903100967407, 0.09967249631881714, 0.04036835953593254, -0.08133918792009354, -0.01310712844133377, 0.031646519899368286, 0.1356542557477951, -0.04550329968333244, 0.0386740043759346, -0.057846467941999435, 0.08429723978042603, 0.08137248456478119, -0.1103362888097763, 0.021770810708403587, -0.07528046518564224, -0.06545328348875046, 0.008582813665270805, 0.10367994010448456, -0.012069095857441425, 0.010543308220803738, 0.11283601820468903, -0.02689245343208313, -0.007742161862552166, -0.08637571334838867, -0.08449205011129379, 0.013634538277983665, 0.1479400396347046, 0.06786932796239853, -0.17149141430854797, 0.0010199503740295768, 0.1271975338459015, -0.06946132332086563, -0.07036402076482773, -0.05399138852953911, -0.026073915883898735, -0.11704500764608383], metadata={'source': 'AAAMLP-569to.pdf', 'page': 27}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 28 def create_folds(data):     # we create a new column called kfold and fill it with -1     data[\"kfold\"] = -1          # the next step is to randomize the rows of the data     data = data.sample(frac=1).reset_index(drop=True)      # calculate the number of bins by Sturge\\'s rule     # I take the floor of the value, you can also     # just round it     num_bins = int(np.floor(1 + np.log2(len(data))))      # bin targets     data.loc[:, \"bins\"] = pd.cut(         data[\"target\"], bins=num_bins, labels=False     )          # initiate the kfold class from model_selection module     kf = model_selection.StratifiedKFold(n_splits=5)          # fill the new kfold column     # note that, instead of targets, we use bins!     for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):         data.loc[v_, \\'kfold\\'] = f          # drop the bins column     data = data.drop(\"bins\", axis=1)     # return dataframe with folds     return data  if __name__ == \"__main__\":     # we create a sample dataset with 15000 samples      # and 100 features and 1 target     X, y = datasets.make_regression(         n_samples=15000, n_features=100, n_targets=1     )      # create a dataframe out of our numpy arrays     df = pd.DataFrame(         X,         columns=[f\"f_{i}\" for i in range(X.shape[1])]     )     df.loc[:, \"target\"] = y      # create folds     df = create_folds(df) ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[-0.08401400595903397, -0.06293503940105438, 0.04140626639127731, -0.036912549287080765, 0.10255876928567886, -0.05412698909640312, -0.08752898126840591, 0.004954385105520487, -0.13878345489501953, -0.09622404724359512, -0.011062751524150372, -0.1573929786682129, 0.0500163659453392, 0.060744233429431915, 0.01878270134329796, -0.012228239327669144, -0.07563362270593643, 0.22111916542053223, -0.09416843205690384, 0.030861293897032738, -0.01191836129873991, -0.09527472406625748, 0.013984610326588154, 0.05232258141040802, -0.1375827193260193, 0.022610049694776535, 0.029144221916794777, -0.027940914034843445, -0.08675626665353775, -0.0670507550239563, 0.17753759026527405, -0.07506389170885086, -0.08600814640522003, -0.009429246187210083, -0.005811235401779413, 0.0407218411564827, -0.024162564426660538, 0.09634396433830261, -0.08173838257789612, 0.0512256994843483, -0.07894790172576904, -0.0660555511713028, -0.00388359185308218, 0.010378659702837467, 0.16640834510326385, 0.04440448060631752, 0.02208665758371353, -0.12120969593524933, 0.08965083211660385, 0.04435501992702484, -0.025809142738580704, -0.05180714651942253, -0.14239534735679626, 0.16720736026763916, 0.06507329642772675, -0.06494662910699844, -0.07189606130123138, -0.038613274693489075, -0.071138396859169, -0.013556239195168018, 0.09260167926549911, -0.1149531677365303, -0.03927060589194298, -0.03888286277651787, 0.0370202362537384, 0.038932327181100845, 0.07404659688472748, 0.035639069974422455, 0.09281723201274872, -0.006354691460728645, 0.0009224643581546843, 0.10292692482471466, -0.01072632148861885, 0.08451290428638458, -0.12233878672122955, 0.06441888958215714, 0.14288625121116638, 0.0249637458473444, 0.1108638346195221, -0.054666902869939804, -0.006752023473381996, 0.1272784024477005, 0.008625496178865433, -0.014452101662755013, 0.08863434195518494, 0.037777457386255264, -0.15621215105056763, 0.028998348861932755, -0.1994985193014145, -0.045195456594228745, 0.17680929601192474, -0.01431705430150032, 0.02848457545042038, 0.00036988555802963674, 0.149729922413826, 0.07131964713335037, 0.07514157891273499, -0.04298356547951698, 0.1590205430984497, 0.06775099784135818, -0.15500852465629578, -0.05422019958496094, 0.08751364797353745, 0.10946261137723923, 0.18367689847946167, -0.06587265431880951, -0.04610265791416168, -0.0861070305109024, 0.10076148808002472, -0.11326046288013458, 0.05000154301524162, 0.03120148926973343, -0.16824989020824432, -0.04718432575464249, 0.07260095328092575, 0.07421369850635529, -0.042050931602716446, -0.01905817911028862, 0.032489579170942307, 0.17644216120243073, -0.13192076981067657, 0.015051419846713543, 0.14087745547294617, 0.0256795771420002, 0.13086681067943573, -0.06885809451341629, -0.06374994665384293, 6.735353408813297e-33, -0.06018959358334541, 0.10212618857622147, 0.06846874207258224, 0.006565580144524574, -0.06829601526260376, -0.12843993306159973, -0.05438454449176788, 0.07149925827980042, -0.03442276269197464, 0.008132198825478554, -0.11639831215143204, -0.01834089681506157, -0.0173195730894804, 0.01026938483119011, 0.12836647033691406, 0.056900009512901306, -0.09062610566616058, -0.01866093836724758, -0.0977896898984909, -0.04961168020963669, 0.10761263966560364, -0.08967951685190201, 0.04701709374785423, 0.12385548651218414, -0.13528689742088318, -0.018627047538757324, 0.024205219000577927, -0.0418219231069088, 0.003895537694916129, 0.07301607728004456, -0.17951154708862305, -0.03213553503155708, 0.042894814163446426, 0.11362110078334808, 0.011464284732937813, 0.04899103567004204, -0.07894706726074219, -0.05699373409152031, 0.05528753995895386, 0.08331190794706345, -0.025901617482304573, 0.0064199841581285, 0.0609171986579895, 0.007045861799269915, 0.08573529124259949, -0.007197034079581499, 0.03893455117940903, -0.02388930693268776, -0.10665137320756912, 0.0023293925914913416, -0.013595270924270153, -0.08426328003406525, -0.07628744840621948, -0.10134967416524887, -0.11281708627939224, 0.1324661821126938, 0.020554881542921066, -0.07502663880586624, 0.0735294297337532, 0.020441681146621704, 0.0006725435960106552, -0.007116826716810465, -0.04759024456143379, 0.06442264467477798, -0.08673462271690369, -0.006568404845893383, 0.08706952631473541, 0.006072958931326866, -0.014875758439302444, -0.0840548574924469, -0.13573111593723297, 0.07303384691476822, -0.11306369304656982, -0.05111071839928627, 0.04829569533467293, -0.04110297933220863, 0.09853321313858032, 0.06455235928297043, -0.11249755322933197, 0.06840489059686661, 0.0027016988024115562, 0.14153893291950226, -0.07547241449356079, -0.14078959822654724, 0.04979320615530014, 0.10892566293478012, -0.03709089010953903, -0.10195089876651764, -0.1464110165834427, 0.010545555502176285, -0.05355154350399971, 0.06485617160797119, 0.026287008076906204, -0.04806338623166084, 0.04263332486152649, -5.987279089525563e-33, 0.06867390125989914, 0.04850713908672333, 0.03698693960905075, 0.06191502511501312, 0.07998060435056686, 0.05411168560385704, 0.0035049133002758026, -0.05382993817329407, -0.105329729616642, -0.07367923110723495, -0.07255653291940689, -0.04917382821440697, 0.12163133919239044, -0.09660492092370987, -0.19725891947746277, 0.02528557740151882, -0.19962823390960693, 0.03183465451002121, 0.06994020938873291, 0.10295889526605606, -0.029349476099014282, 0.08828537911176682, -0.09996530413627625, 0.022937389090657234, -0.09312638640403748, 0.003720361040905118, -0.09587942063808441, -0.01214759610593319, 0.17286115884780884, 0.07052686810493469, 0.021617410704493523, -0.07249821722507477, -0.07610511034727097, -0.02006995864212513, 0.032276131212711334, 0.022885261103510857, -0.0011445007985457778, -0.05228939279913902, 0.11157069355249405, 0.11845988780260086, 0.09714198857545853, 0.09112001210451126, -0.20464526116847992, -0.05430588871240616, 0.023928508162498474, 0.026762185618281364, -0.11905793845653534, -0.010670260526239872, -0.024139873683452606, -0.05553779378533363, 0.02176782302558422, 0.011119130067527294, -0.0785670205950737, -0.027229584753513336, -0.013666636310517788, 0.0434844046831131, -0.025376195088028908, 0.008242924697697163, -0.07979588210582733, 0.09419025480747223, -0.09864459186792374, -0.08098314702510834, -0.02461339719593525, 0.08221059292554855, 0.03836954012513161, -0.004633099306374788, 3.49044130416587e-05, -0.002817318309098482, -0.027929499745368958, 0.0448230504989624, -0.13486097753047943, 0.013407467864453793, -0.016068855300545692, 0.026688382029533386, -0.010303855873644352, -0.014244365505874157, 0.013309686444699764, -0.009629773907363415, 0.016247417777776718, 0.008426587097346783, 1.6842857803567313e-05, -0.12719853222370148, 0.09986405819654465, 0.15148863196372986, 0.041982926428318024, 0.15321491658687592, 0.10500361770391464, -0.002304443623870611, 0.01781482808291912, -0.17563709616661072, -0.07581982016563416, 0.025279341265559196, 0.07028144598007202, 0.1195736676454544, -0.013257377780973911, -9.971524406182652e-08, 0.07255179435014725, 0.05438099429011345, 0.11201749742031097, -0.019085731357336044, 0.06972076743841171, -0.043457794934511185, -0.14319546520709991, 0.037055954337120056, -0.0016470005502924323, 0.008398933336138725, 0.0022049860563129187, 0.012365464121103287, -0.05445265397429466, -0.02253585308790207, -0.0003527598164509982, 0.06659802794456482, 0.03111734427511692, 0.10033226758241653, -0.03587160259485245, 0.10976118594408035, 0.09733621776103973, -0.09852483868598938, 0.05007653310894966, 0.003311695298179984, 0.1022535189986229, -0.09769857674837112, 0.0014071599580347538, 0.06455157697200775, -0.041264764964580536, -0.034070294350385666, -0.05895698815584183, -0.1022905483841896, -0.059153951704502106, 0.07788889110088348, 0.08600437641143799, 0.04881073161959648, 0.06302370131015778, -0.020465465262532234, -0.007640138268470764, 0.07613744586706161, 0.07155527174472809, 0.13312271237373352, -0.05074271559715271, -0.027402296662330627, 0.03246897831559181, 0.001570541295222938, 0.03535456955432892, -0.07148568332195282, -0.07044509798288345, 0.08280593156814575, 0.02668869122862816, -0.029806626960635185, -0.025158952921628952, 0.12872415781021118, -0.006913609337061644, 0.10033824294805527, 0.02363508753478527, -0.042914047837257385, 0.08509887754917145, -0.04252243414521217, -0.029239028692245483, -0.08388036489486694, -0.031462300568819046, 0.011138275265693665], metadata={'source': 'AAAMLP-569to.pdf', 'page': 28}, content=\"Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 29 Cross-validation is the first and most essential step when it comes to building machine learning models. If you want to do feature engineering, split your data first. If you're going to build models, split your data first. If you have a good cross-validation scheme in which validation data is representative of training and real-world data, you will be able to build a good machine learning model which is highly generalizable.   The types of cross-validation presented in this chapter can be applied to almost any machine learning problem. Still, you must keep in mind that cross-validation also depends a lot on the data and you might need to adopt new forms of cross-validation depending on your problem and data.   For example, let’s say we have a problem in which we would like to build a model to detect skin cancer from skin images of patients. Our task is to build a binary classifier which takes an input image and predicts the probability for it being benign or malignant.   In these kinds of datasets, you might have multiple images for the same patient in the training dataset. So, to build a good cross-validation system here, you must have stratified k-folds, but you must also make sure that patients in training data do not appear in validation data. Fortunately, scikit-learn offers a type of cross-validation known as GroupKFold. Here the patients can be considered as groups. But unfortunately, there is no way to combine GroupKFold with StratifiedKFold in scikit-learn. So you need to do that yourself. I’ll leave it as an exercise for the reader.\"),\n",
       " VectorParams(vector=[-0.07748274505138397, -0.1775977462530136, -0.08876794576644897, 0.022954881191253662, 0.09599322825670242, 0.020949771627783775, -0.052773281931877136, 0.08626905083656311, 0.0026574970688670874, 0.08644361048936844, -0.11959877610206604, -0.10492011904716492, -0.006070500239729881, 0.1055464819073677, -0.01582835055887699, -0.1332319676876068, 0.10446076840162277, 0.0436965636909008, -0.06985701620578766, -0.07925757765769958, 0.17671418190002441, 0.052925363183021545, 0.05703187361359596, 0.06418655067682266, -0.0665448009967804, 0.0006945078494027257, 0.03297276422381401, 0.025425728410482407, -0.11850911378860474, 0.010464413091540337, -0.0038260282017290592, -0.0002100654091918841, 0.01975606009364128, -0.014627314172685146, -0.1319158375263214, 0.04881657287478447, 0.05965467914938927, 0.09898354858160019, 0.004455190617591143, -0.08360449224710464, -0.08127687871456146, -0.09266012907028198, 0.001989414682611823, 0.027549974620342255, 0.17135007679462433, -0.061012446880340576, -0.02949354611337185, -0.03601456806063652, -0.050843026489019394, 0.015404018573462963, -0.08204635232686996, 0.023698050528764725, -0.08595860004425049, 0.07246532291173935, 0.0028897211886942387, 0.038369789719581604, -0.005622517317533493, 0.002672504633665085, 0.08402542024850845, -0.04256242886185646, 0.01526421308517456, -0.15856139361858368, -0.06357543915510178, -0.09342637658119202, 0.020613854750990868, -0.04081796854734421, 0.019044024869799614, -0.0015049148350954056, -0.0014592428924515843, 0.11385195702314377, -0.033083219081163406, -0.004173315595835447, -0.09972108900547028, 0.0629558190703392, 0.012759705074131489, 0.026117447763681412, 0.08891838043928146, 0.13127553462982178, -0.004937442485243082, -0.027868026867508888, 0.1258097141981125, 0.11006010323762894, 0.010968739166855812, -0.0018571328837424517, 0.06406539678573608, 0.008614951744675636, 0.06865158677101135, 0.08332695066928864, -0.028946293517947197, -0.014921560883522034, 0.07011207193136215, 0.03034176304936409, -0.05796612426638603, -0.07432101666927338, 0.13757950067520142, -0.03262348473072052, -0.015474068932235241, -0.029175087809562683, 0.021648123860359192, 0.006323109846562147, -0.07582386583089828, 0.07932060211896896, -0.0474080815911293, -0.10196759551763535, 0.07617560774087906, 0.0380903035402298, 0.005434709135442972, -0.030402692034840584, 0.14389722049236298, -0.02993592992424965, -0.018379217013716698, 0.058226291090250015, -0.227777361869812, 0.017931930720806122, 0.08057285845279694, -0.010805193334817886, 0.018414992839097977, -0.047351837158203125, 0.02544270269572735, 0.18839383125305176, -0.168300598859787, -0.02026212401688099, 0.049505073577165604, 0.022708231583237648, 0.08502989262342453, -0.01074574887752533, -0.1824248731136322, 1.0329407549985271e-32, -0.08063691854476929, 0.01984107308089733, -0.05775056406855583, -0.04280887171626091, -0.013558462262153625, -0.024871116504073143, -0.08464977890253067, 0.06989499181509018, 0.15211117267608643, 0.07493533939123154, 0.029401496052742004, 0.1507049798965454, 0.032753948122262955, 0.01265912689268589, 0.1856268346309662, 0.09317271411418915, -0.032539110630750656, 0.010001513175666332, -0.1087178885936737, -0.06293028593063354, 0.030437150970101357, -0.03053445927798748, 0.08588355779647827, 0.03768002986907959, 0.006711388472467661, -0.021669596433639526, 0.021315772086381912, 0.03278995305299759, -0.012547996826469898, 0.012555859982967377, 0.06145961582660675, -0.0648638978600502, -0.0061849262565374374, -0.037196576595306396, 0.006594962440431118, -0.043738674372434616, -0.13839773833751678, 0.05005698278546333, -0.06091153249144554, -0.0728679671883583, -0.14186948537826538, 0.015058957040309906, 0.01201517041772604, -0.019975459203124046, -0.06842151284217834, -0.07309744507074356, -0.039070699363946915, -0.047775998711586, 0.13426990807056427, 0.0005048304446972907, -0.03949657455086708, -0.07102438062429428, 0.005710910074412823, -0.019607240334153175, -0.08906511217355728, 0.15422260761260986, 0.013920256868004799, -0.07716012001037598, -0.012562545947730541, -0.024270612746477127, -0.037169672548770905, -0.07191938161849976, 0.14550332725048065, -0.13907890021800995, -0.0812269002199173, 0.015517673455178738, -0.008347730152308941, 0.15105783939361572, -0.046269290149211884, -0.021008342504501343, -0.0422268882393837, -0.020639775320887566, 0.06471036374568939, 0.006935641635209322, 0.14396105706691742, 0.07132022827863693, 0.1739474982023239, -0.062449827790260315, -0.04174778610467911, 0.10358723253011703, -0.0951414480805397, 0.13754694163799286, 0.01694961078464985, -0.1293681263923645, -0.06265381723642349, 0.008800522424280643, -0.005825059488415718, -0.03224609047174454, -0.10511798411607742, 0.012402405962347984, -0.07185977697372437, 0.06776619702577591, -0.1215049996972084, 0.052207205444574356, -0.0853121280670166, -1.1881286375733224e-32, -0.04199366644024849, 0.06454102694988251, -0.002302637556567788, 0.15650607645511627, -0.006974553689360619, 0.03519650176167488, 0.014542948454618454, 0.00908210501074791, -0.021702000871300697, -0.15063691139221191, -0.1123710498213768, 0.033894844353199005, -0.04044720157980919, 0.12814557552337646, -0.01475892961025238, 0.10198739171028137, -0.1301119476556778, -0.05038963258266449, 0.006674920674413443, 0.09495888650417328, 0.0207420215010643, 0.1434277594089508, -0.03427905589342117, -0.08740250766277313, -0.09160860627889633, 0.027134116739034653, -0.050912339240312576, -0.00010037358151748776, -0.07936694473028183, -0.08243574947118759, 0.12299162149429321, 0.0243227556347847, -0.08545874804258347, 0.03418939560651779, -0.0451851524412632, -0.08444691449403763, 0.02798798866569996, -0.08751600980758667, 0.007966849952936172, 0.16563475131988525, 0.08897897601127625, 0.12415746599435806, -0.12392628192901611, -0.06706048548221588, 0.013327883556485176, -0.07845472544431686, -0.007538530509918928, 0.051034171134233475, 0.06091329827904701, -0.10013207793235779, 0.11084338277578354, 0.035958822816610336, -0.03840072825551033, 0.012047899886965752, -0.021359579637646675, 0.04309134557843208, -0.09541845321655273, -0.0008673667907714844, 0.022281214594841003, 0.07870173454284668, -0.03920789062976837, 0.030138714239001274, 0.026467526331543922, 0.0937255397439003, -0.051027119159698486, -0.009928621351718903, 0.06625356525182724, 0.07114598900079727, -0.09213632345199585, 0.06190483644604683, -0.13486820459365845, 0.016504282131791115, -0.04643763601779938, -0.01278870552778244, -0.09164658188819885, 0.08104302734136581, -0.04250431805849075, -0.006657048594206572, -0.11237148195505142, -0.06644319742918015, 0.11012854427099228, -0.022212447598576546, -0.13679327070713043, 0.04104088991880417, -0.08133811503648758, 0.06249751150608063, 0.17090418934822083, 0.003213008400052786, 0.036774780601263046, -0.13647408783435822, -0.06318413466215134, 0.007721005938947201, -0.07212001085281372, 0.13173742592334747, 0.015858585014939308, -9.968791658820919e-08, -0.016595100983977318, -0.028704321011900902, 0.12254168838262558, -0.10110630840063095, -0.030335886403918266, 0.04010794684290886, -0.21102429926395416, 0.17218497395515442, -0.10608616471290588, 0.0802348181605339, 0.01686154305934906, -0.06320290267467499, -0.2463667243719101, 0.07392553985118866, -0.06836940348148346, 0.0653221532702446, 0.1200077161192894, 0.13184066116809845, -0.028118586167693138, 0.04826829954981804, 0.03960679471492767, 0.005288886371999979, 0.043376512825489044, -0.0599835142493248, 0.07333244383335114, -0.15728074312210083, 0.05042519420385361, -0.03781988099217415, -0.055495649576187134, 0.04046677052974701, 0.014077792875468731, 0.026719721034169197, 0.11907371133565903, -0.0282499510794878, 0.0342622771859169, 0.07875474542379379, 0.04763226956129074, -0.1099621132016182, -0.06194194406270981, 0.07679180800914764, 0.08527882397174835, 0.17980194091796875, -0.023776384070515633, 0.010796282440423965, 0.011408671736717224, -0.028364846482872963, 0.06464823335409164, 0.11940716952085495, -0.09423650056123734, -0.04552973806858063, 0.019144032150506973, -0.02041570469737053, -0.12779220938682556, 0.01689356379210949, 0.07099652290344238, 0.009204699657857418, -0.05855009704828262, -0.1554255485534668, 0.0692148357629776, 0.08357705920934677, 0.03523515537381172, 0.031689051538705826, -0.04613795131444931, 0.03238715976476669], metadata={'source': 'AAAMLP-569to.pdf', 'page': 29}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 30 Evaluation metrics  When it comes to machine learning problems, you will encounter a lot of different types of metrics in the real world. Sometimes, people even end up creating metrics that suit the business problem. It’s out of the scope of this book to introduce and explain each and every type of metric. Instead, we will see some of the most common metrics that you can use when starting with your very first few projects.  At the start of the book, we introduced supervised and unsupervised learning. Although there are some kinds of metrics that you can use for unsupervised learning, we will only focus on supervised. The reason for this is because supervised problems are in abundance compared to un-supervised, and evaluation of unsupervised methods is quite subjective.  If we talk about classification problems, the most common metrics used are: - Accuracy - Precision (P) - Recall (R) - F1 score (F1) - Area under the ROC (Receiver Operating Characteristic) curve or simply AUC (AUC) - Log loss - Precision at k (P@k) - Average precision at k (AP@k) - Mean average precision at k (MAP@k)  When it comes to regression, the most commonly used evaluation metrics are: - Mean absolute error (MAE) - Mean squared error (MSE) - Root mean squared error (RMSE) - Root mean squared logarithmic error (RMSLE) - Mean percentage error (MPE) - Mean absolute percentage error (MAPE) - R2  Knowing about how the aforementioned metrics work is not the only thing we have to understand. We must also know when to use which metrics, and that depends on'),\n",
       " VectorParams(vector=[-0.010398978367447853, 0.09304653853178024, 0.033641595393419266, -0.19158290326595306, 0.19076448678970337, -0.06199517846107483, 0.09489215910434723, 0.06184374913573265, -0.06181303784251213, -0.03631389141082764, -0.07075883448123932, -0.21570007503032684, 0.32074835896492004, 0.15926332771778107, -0.05842543765902519, 0.07066412270069122, -0.11002101749181747, 0.04686771333217621, -0.18038709461688995, 0.1018344983458519, 0.09068938344717026, 0.05250038951635361, 0.01751582697033882, 0.01778840273618698, -0.15756912529468536, 0.03098827786743641, 0.019714605063199997, -0.10216201096773148, 0.017280811443924904, -0.028082450851798058, 0.09132342040538788, -0.01842823252081871, 0.003380959387868643, 0.03143889829516411, -0.010503881610929966, 0.04548079892992973, -0.12617942690849304, 0.14680317044258118, -0.06435248255729675, 0.05507891997694969, 0.026150017976760864, -0.08349720388650894, -0.13542386889457703, -0.011433495208621025, 0.14543810486793518, 0.22882303595542908, -0.12078652530908585, 0.05338861793279648, -0.007792252115905285, 0.026832645758986473, -0.054207831621170044, -0.0218787994235754, -0.2736515998840332, 0.12650376558303833, -0.09556000679731369, -0.0882476270198822, -0.027846304699778557, -0.11094372719526291, -0.05510410666465759, -0.10380151867866516, 0.06563656032085419, -0.20131424069404602, -0.05472170189023018, -0.023766404017806053, 0.16712000966072083, 0.013735882937908173, -0.014132319018244743, -0.018413402140140533, 0.03623901680111885, 0.1342632919549942, 0.05878717452287674, 0.13215626776218414, 0.006249912083148956, 0.20066292583942413, -0.1315571814775467, 0.1037200316786766, 0.12268751859664917, 0.12194684147834778, 0.019508719444274902, -0.0801612138748169, -0.03962206095457077, -0.0457569882273674, 6.585651135537773e-05, -0.028361912816762924, 0.12822145223617554, -0.02691064588725567, -0.15222008526325226, 0.03752321004867554, -0.12232302129268646, 0.0008774642483331263, 0.030892234295606613, 0.08552561700344086, 0.049547407776117325, 0.04797631874680519, 0.21948383748531342, -0.015954453498125076, 0.03574245795607567, 0.03185604140162468, 0.09036997705698013, 0.0790683925151825, -0.17375051975250244, -0.06308670341968536, -0.01992172747850418, -0.08923265337944031, 0.10361756384372711, -0.12911029160022736, 0.019388748332858086, -0.10851294547319412, 0.1608634889125824, -0.16824090480804443, 0.04327758774161339, -0.007914372719824314, -0.01808030530810356, -0.08543839305639267, 0.16073259711265564, 0.14959031343460083, -0.014724270440638065, 0.08199886977672577, -0.03817398473620415, -0.017821483314037323, -0.16051170229911804, -0.15642116963863373, -0.009325152263045311, 0.014711493626236916, 0.13513322174549103, -0.20273514091968536, -0.2192671000957489, 7.54624100342119e-33, -0.08335255831480026, 0.009250065311789513, 0.04070510342717171, -0.05767669156193733, -0.0007280656136572361, -0.017602672800421715, -0.05774635076522827, 0.013896754942834377, 0.06931853294372559, 0.10543307662010193, -0.09674446284770966, 0.0755898728966713, 0.05641671270132065, 0.09976362437009811, 0.10223866999149323, -0.027196530252695084, 0.015292217954993248, 0.1156197190284729, -0.18303082883358002, -0.06903434544801712, 0.0767492800951004, -0.06798221170902252, 0.04676121845841408, 0.06332024186849594, -0.010175257921218872, 0.0380122996866703, -0.056003592908382416, -0.012769732624292374, -0.06869155913591385, -0.040969327092170715, -0.062308572232723236, 0.0700797587633133, 0.07893145829439163, 0.054335083812475204, -0.033066246658563614, -0.04760899394750595, -0.05734657868742943, 0.1529144048690796, -0.059697020798921585, 0.05143364518880844, -0.037647441029548645, 0.05507230758666992, 0.10679833590984344, -0.0992405042052269, 0.03637044504284859, -0.051636990159749985, -0.07641804963350296, -0.008275208994746208, -0.16917771100997925, -0.08997202664613724, 0.06849858909845352, -0.0785275474190712, -0.10507477819919586, -0.07694514095783234, -0.14354540407657623, 0.10221746563911438, -0.15691715478897095, 0.08955320715904236, -0.028169672936201096, -0.015491115860641003, 0.21559832990169525, -0.059703148901462555, 0.013787534087896347, 0.21295297145843506, -0.03195976838469505, 0.07188764959573746, -0.047331079840660095, -0.10374460369348526, 0.07399316877126694, 0.14016389846801758, -0.07148955762386322, 0.0798143520951271, 0.046770185232162476, -0.11833828687667847, 0.14982068538665771, -0.0024074329994618893, 0.05685846135020256, 0.16370633244514465, -0.10439273715019226, -0.06309694796800613, -0.0836552157998085, 0.12401896715164185, 0.04304070025682449, -0.1165960356593132, -0.06375018507242203, 0.02710791490972042, 0.06196857988834381, -0.0865127444267273, -0.2070515900850296, 0.028761327266693115, -0.13027642667293549, 0.0790015235543251, -0.1347539722919464, 0.10297583043575287, 0.0190303735435009, -6.905434217065835e-33, 0.04523186758160591, 0.18805474042892456, 0.07771077752113342, 0.044966645538806915, 0.026515403762459755, 0.11245258897542953, -0.028993556275963783, 0.015194515697658062, -0.034083377569913864, -0.027793336659669876, 0.046309664845466614, 0.043106455355882645, -0.09151965379714966, -0.05784641206264496, -0.3086375594139099, 0.1124831885099411, 0.025303546339273453, -0.024668408557772636, -0.05137890204787254, 0.08573931455612183, 0.1313723772764206, 0.2455776333808899, -0.15248991549015045, -0.011420206166803837, -0.2540997564792633, 0.21354134380817413, 0.027555348351597786, 0.005013901740312576, 0.07409047335386276, -0.029650257900357246, -0.1413573920726776, -0.006852007936686277, -0.09918653219938278, -0.012784232385456562, -0.04925880953669548, -0.06535059958696365, 0.02866624854505062, -0.008164526894688606, 0.05518198013305664, 0.06113094836473465, 0.1428459733724594, 0.09304828941822052, -0.1934867948293686, 0.032232943922281265, 0.03394695743918419, -0.1501649171113968, 0.1980431228876114, -0.026820389553904533, -0.024978768080472946, -0.09749487042427063, -0.03489339351654053, -0.06462837010622025, -0.0847371444106102, 0.1317182183265686, -0.004155147820711136, 0.10916239768266678, -0.1707674264907837, -0.06292713433504105, 0.012596523389220238, 0.0669051855802536, -0.14794595539569855, 0.0010227608727291226, -0.08811108022928238, 0.16576360166072845, -0.014571351930499077, 0.13431568443775177, 0.054279062896966934, 0.07257698476314545, -0.0017570022027939558, 0.1675119549036026, -0.025222448632121086, 0.17867788672447205, -0.003015209222212434, -0.06869540363550186, -0.042487598955631256, 0.09503889828920364, -0.010256496258080006, -0.053996145725250244, -0.022063657641410828, -0.04546944797039032, -0.22625520825386047, -0.17033767700195312, 0.007585178129374981, 0.18376712501049042, 0.02923852764070034, 0.19329269230365753, 0.1507350355386734, -0.11026972532272339, 0.08104012161493301, -0.030397312715649605, -0.019649362191557884, 0.07663340866565704, 0.15237852931022644, -0.00783014576882124, 0.04740678146481514, -1.0000720607195035e-07, -0.08927315473556519, -0.06595169752836227, -0.12429004162549973, 0.021127425134181976, 0.06453204900026321, -0.005038079805672169, -0.1933000087738037, 0.1648329347372055, -0.06283804029226303, -0.10005122423171997, 0.06742256879806519, -0.01728040538728237, -0.19641225039958954, -0.07509656250476837, -0.045775406062603, -0.04763026908040047, -0.11620360612869263, 0.10073398053646088, -0.009119460359215736, 0.11340129375457764, 0.042238302528858185, -0.14611496031284332, 0.15151560306549072, -0.005435057450085878, 0.059954795986413956, -0.1076907068490982, 0.002118433127179742, -0.054376520216464996, 0.07779838889837265, 0.11428861320018768, -0.07885947078466415, -0.025752639397978783, -0.07330416142940521, 0.05535118654370308, 0.20291928946971893, 0.013463628478348255, -0.004007615614682436, -0.11324452608823776, -0.11723262071609497, 0.01226466242223978, 0.040123265236616135, -0.09781408309936523, 0.011422890238463879, -0.026629747822880745, 0.16410288214683533, -0.029361436143517494, 0.03111032210290432, -0.1435878574848175, 0.036255836486816406, -0.050067149102687836, 0.16069404780864716, 0.00978989526629448, 0.00416468596085906, 0.012597612105309963, -0.03317907080054283, 0.07472103089094162, 0.014066227711737156, -0.18748044967651367, 0.07920783013105392, 0.16434994339942932, 0.10549750179052353, -0.12301903963088989, -0.1280599981546402, -0.06272256374359131], metadata={'source': 'AAAMLP-569to.pdf', 'page': 30}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 31 what kind of data and targets you have. I think it’s more about the targets and less about the data.   To learn more about these metrics, let’s start with a simple problem. Suppose we have a binary classification problem, i.e. a problem in which there are only two targets. Let’s suppose it’s a problem of classifying chest x-ray images. There are chest x-ray images with no problem, and some of the chest x-ray images have collapsed lung which is also known as pneumothorax. So, our task is to build a classifier that given a chest x-ray image can detect if it has pneumothorax.  \\n Figure 1: A lung image showing pneumothorax. Image is taken from SIIM-ACR Pneumothorax Segmentation Competition3  We also assume that we have an equal number of pneumothorax and non- pneumothorax chest x-ray images; let’s say 100 each. Thus, we have 100 positive samples and 100 negative samples with a total of 200 images.   The first step is to divide the data described above into two equal sets of 100 images each, i.e. training and validation set. In both the sets, we have 50 positive and 50 negative samples.  3 https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation'),\n",
       " VectorParams(vector=[0.002806031610816717, -0.06211182102560997, -0.0314096063375473, -0.020253291353583336, 0.05561484768986702, -0.17844942212104797, -0.018022198230028152, 0.07651303708553314, -0.06138449162244797, -0.05737266689538956, -0.03632261976599693, -0.087919682264328, 0.12871815264225006, -0.004239309579133987, -0.11253878474235535, -0.09526745229959488, 0.012456588447093964, -0.0023954110220074654, -0.07579278945922852, -0.0795893669128418, 0.03189427778124809, 0.03896074742078781, 0.1107349693775177, 0.03178770840167999, 0.00901910662651062, -0.1365477740764618, 0.007389260921627283, -0.006957360077649355, -0.11670716106891632, -0.08428327739238739, 0.01998789794743061, -0.0028597733471542597, -0.08045676350593567, 0.002527001081034541, -0.09999631345272064, 0.05368645116686821, -0.009782952256500721, -0.04361457750201225, 0.04754151403903961, 0.0305214524269104, -0.08925778418779373, -0.04820738732814789, 0.07516147941350937, 0.021543104201555252, 0.08618152141571045, 0.1679145097732544, -0.13598473370075226, -0.005497737787663937, 0.05018630623817444, 0.0017869035946205258, -0.1063171923160553, 0.14587202668190002, -0.11597736924886703, -0.0032680395524948835, -0.12735016644001007, 0.02060055173933506, 0.028540242463350296, -0.051507726311683655, 0.029270008206367493, -0.04194359481334686, 0.0804748684167862, -0.07568615674972534, -0.0917091965675354, -0.04443554952740669, -0.026792334392666817, -0.015600918792188168, -0.004674769472330809, -0.1142452210187912, 0.014744401909410954, -0.010707818903028965, 0.08092381060123444, 0.10948655754327774, 0.043504830449819565, 0.11772850155830383, -0.02049132250249386, -0.07583074271678925, 0.11375075578689575, 0.16329702734947205, 0.03478850796818733, 0.01142283994704485, -0.0034207080025225878, 0.05700308084487915, 0.012083640322089195, -0.009276922792196274, 0.08372867852449417, -0.19395476579666138, 0.02802860736846924, 0.13279573619365692, 0.054501425474882126, -0.02071983367204666, 0.048211630433797836, -0.07894302159547806, -0.07856613397598267, -0.030793460085988045, 0.11620873957872391, 0.17728129029273987, 0.04106051102280617, -0.007864395156502724, -0.06673140078783035, 0.03463171422481537, -0.08339419960975647, 0.0022658552043139935, -0.0841764584183693, -0.07204630225896835, 0.21713252365589142, 0.05671068653464317, 0.052753858268260956, -0.03203606605529785, 0.15355396270751953, -0.16394516825675964, 0.013706834986805916, -0.11565091460943222, -0.10678021609783173, 0.07234960049390793, 0.1618252545595169, 0.060548990964889526, -0.06606344878673553, 0.12767726182937622, -0.06229724362492561, 0.0749596506357193, -0.10430694371461868, 0.09796801954507828, 0.09167927503585815, 0.00846603512763977, 0.04912932589650154, -0.13039708137512207, -0.14071477949619293, 7.880711757900347e-33, -0.15341417491436005, -0.02397361397743225, 0.015940144658088684, -0.015005878172814846, -0.03631526976823807, -0.057484615594148636, -0.152047798037529, 0.09572436660528183, -0.0026628472842276096, 0.04827898368239403, -0.0672985166311264, 0.005918946582823992, -0.034835219383239746, 0.10342031717300415, 0.09401309490203857, 0.07038791477680206, -0.02399643510580063, -0.009300954639911652, -0.02150021865963936, -0.013405605219304562, 0.03744626045227051, -0.08170900493860245, 0.08395466953516006, -0.1062709242105484, -0.06977177411317825, 0.041707593947649, -0.03668644279241562, 0.041599713265895844, -0.22078007459640503, -0.008568503893911839, -0.0621650367975235, -0.0113011309877038, 0.1360994577407837, -0.037249378859996796, 0.09465467184782028, -0.13741303980350494, 0.033109549432992935, 0.06671163439750671, -0.04833449795842171, -0.021658089011907578, -0.054209958761930466, 0.08829349279403687, -0.006928073707967997, -0.03252068907022476, -0.010417971760034561, -0.04839455708861351, -0.038397710770368576, -0.01880740001797676, 0.028904516249895096, 0.17301255464553833, 0.05029208958148956, -0.12388551235198975, -0.1871303915977478, 0.06105213612318039, -0.1738709807395935, 0.05298011377453804, 0.04770417883992195, 0.032566655427217484, 0.06072614714503288, -0.007514122407883406, 0.08329486101865768, 0.009037686511874199, 0.022588640451431274, -0.04666223004460335, -0.06195397302508354, 0.11650252342224121, 0.12795013189315796, 0.11105666309595108, -0.02997761033475399, 0.11793086677789688, -0.13088269531726837, -0.015940116718411446, -0.03845496103167534, -0.05805530399084091, 0.05141960829496384, -0.02700389176607132, 0.14636948704719543, -0.0855875164270401, -0.07461037486791611, 0.07610820233821869, 0.005254799034446478, 0.13549131155014038, -0.0421302355825901, -0.18254929780960083, -0.08065227419137955, -0.0019970089197158813, 0.047295913100242615, -0.001430510194040835, -0.11201748996973038, -0.08816522359848022, -0.08893086016178131, 0.05624226853251457, 0.00011122725845780224, -0.008221234194934368, -0.1437327265739441, -1.155249032023266e-32, 0.0046664695255458355, 0.03839069977402687, 0.05945736914873123, 0.12453190982341766, -0.020951293408870697, 0.023819657042622566, 0.014087118208408356, 0.029374631121754646, -0.055761661380529404, -0.13438767194747925, 0.0594794899225235, -0.022423457354307175, -0.021869011223316193, 0.028560593724250793, -0.03780630975961685, 0.030614251270890236, -0.1088285893201828, 0.009438756853342056, -0.07336112856864929, 0.09277583658695221, 0.01644875667989254, 0.05324690416455269, -0.04934469237923622, -0.01837744563817978, -0.10678190737962723, 0.1031409278512001, -0.02071734517812729, 0.036208122968673706, 0.0019072775030508637, -0.1027197316288948, 0.03995945304632187, 0.018322942778468132, -0.01571000926196575, 0.028931718319654465, 0.1221085712313652, -0.0627952367067337, -0.02486417628824711, -0.1001611202955246, 0.10672280937433243, 0.027353134006261826, 0.17107462882995605, 0.12203844636678696, -0.21010848879814148, -0.026957526803016663, -0.02441922202706337, -0.021643178537487984, -0.04568057507276535, -0.017944883555173874, 0.06406039744615555, -0.05464174225926399, 0.06645198166370392, 0.05834434553980827, -0.08848457038402557, 0.1320749819278717, 0.014725460670888424, 0.08174142986536026, -0.27740052342414856, 0.017429864034056664, 0.05860807001590729, 0.07748302817344666, -0.11012033373117447, 0.019441060721874237, 0.03731769695878029, 0.07098715007305145, 0.00045995062100701034, 0.12927289307117462, -0.1782568097114563, 0.04538467526435852, -0.009408019483089447, 0.19970503449440002, -0.042619407176971436, 0.10390961915254593, -0.02339811436831951, -0.10664648562669754, -0.06046973168849945, -0.006475391332060099, -0.008058999665081501, -0.043508656322956085, 0.027848143130540848, 0.014998103491961956, -0.020869771018624306, 0.0050373319536447525, -0.02499115839600563, 0.12280059605836868, -0.04419149085879326, 0.06738294661045074, 0.09579725563526154, 0.12814439833164215, 0.05465811491012573, 0.013365987688302994, 0.10664482414722443, 0.0814870148897171, 0.05295176804065704, 0.047766342759132385, 0.05524598807096481, -1.0095572378077122e-07, -0.025055069476366043, -0.00876911636441946, 0.13668251037597656, -0.008323611691594124, 0.03267074003815651, 0.04190964251756668, -0.1559041440486908, 0.0226143691688776, -0.10348819941282272, -0.11685900390148163, 0.11510323733091354, -0.015143129043281078, -0.21739470958709717, -0.015445752069354057, -0.08073709160089493, 0.0890757367014885, 0.021669307723641396, 0.12030912190675735, 0.04305674880743027, 0.11312049627304077, 0.05685858055949211, -0.12723848223686218, 0.12881219387054443, -0.03203511983156204, -0.10260824859142303, -0.020168378949165344, -0.05815648287534714, 0.11843594163656235, -0.0021767185535281897, 0.04628667235374451, 0.06237918883562088, -0.15174634754657745, 0.036176618188619614, -0.016455980017781258, 0.11917348951101303, 0.06605714559555054, -0.04837259277701378, -0.07124251872301102, 0.009874858893454075, -0.05318663641810417, -0.12110872566699982, 0.06527240574359894, -0.08013752102851868, -0.023928450420498848, 0.05382378026843071, -0.05238330364227295, 0.09952856600284576, -0.018863804638385773, -0.0905366837978363, -0.018009010702371597, 0.048792194575071335, 0.06163942441344261, -0.14953863620758057, 0.03228268399834633, 0.01648140884935856, -0.025365520268678665, -0.15734577178955078, -0.11759407818317413, -0.08644364774227142, 0.08157402276992798, -0.02979924902319908, -0.009714210405945778, -0.043853748589754105, -0.03350545093417168], metadata={'source': 'AAAMLP-569to.pdf', 'page': 31}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 32 When we have an equal number of positive and negative samples in a binary classification metric, we generally use accuracy, precision, recall and f1.  Accuracy: It is one of the most straightforward metrics used in machine learning. It defines how accurate your model is. For the problem described above, if you build a model that classifies 90 images accurately, your accuracy is 90% or 0.90. If only 83 images are classified correctly, the accuracy of your model is 83% or 0.83. Simple.  Python code for calculating accuracy is also quite simple.  ═════════════════════════════════════════════════════════════════════════ def accuracy(y_true, y_pred):     \"\"\"     Function to calculate accuracy     :param y_true: list of true values     :param y_pred: list of predicted values     :return: accuracy score     \"\"\"     # initialize a simple counter for correct predictions     correct_counter = 0     # loop over all elements of y_true     # and y_pred \"together\"     for yt, yp in zip(y_true, y_pred):         if yt == yp:             # if prediction is equal to truth, increase the counter             correct_counter += 1      # return accuracy     # which is correct predictions over the number of samples     return correct_counter / len(y_true)  ═════════════════════════════════════════════════════════════════════════  We can also calculate accuracy using scikit-learn.  ═════════════════════════════════════════════════════════════════════════ In [X]: from sklearn import metrics    ...: l1 = [0,1,1,1,0,0,0,1]    ...: l2 = [0,1,0,1,0,1,0,0]    ...: metrics.accuracy_score(l1, l2)  Out[X]: 0.625 ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[-0.004849908873438835, 0.05324208736419678, -0.07818972319364548, -0.05147935822606087, 0.06588643789291382, -0.105513796210289, 0.014754903502762318, 0.05824504420161247, 0.07671047002077103, 0.011196721345186234, 0.014504284597933292, -0.13324958086013794, 0.22241467237472534, 0.12790808081626892, -0.09950070083141327, -0.1205141544342041, 0.06783318519592285, 0.047234464436769485, -0.16442066431045532, 0.11735691875219345, 0.010597871616482735, -0.002068248810246587, 0.07498686760663986, -0.020331397652626038, -0.1742977648973465, -0.09105470776557922, -0.044881053268909454, -0.041990041732788086, -0.06707469373941422, -0.06430871784687042, -0.05720905959606171, 0.07274636626243591, -0.11616505682468414, -0.033544160425662994, -0.05377635359764099, 0.0491817407310009, -0.032878775149583817, 0.17940527200698853, 0.022912023589015007, 0.07419659197330475, 0.005398841574788094, -0.08568255603313446, -0.06625832617282867, -0.023114440962672234, 0.11077490448951721, 0.10164211690425873, -0.07088037580251694, -0.010372746735811234, -0.01805630698800087, 0.05356122925877571, -0.11147168278694153, 0.04709894582629204, -0.21717658638954163, 0.05602521449327469, -0.12646527588367462, 0.03080787882208824, -0.001934155821800232, -0.05292384698987007, -0.07919172942638397, -0.14738309383392334, 0.06594835966825485, -0.10103615373373032, -0.0885111391544342, -0.03700387477874756, 0.16788989305496216, 0.013680021278560162, -0.03468460589647293, -0.0778626948595047, 0.034298352897167206, 0.10167305916547775, 0.09080623835325241, 0.06945860385894775, 0.004441704601049423, 0.10549935698509216, -0.13217435777187347, 0.04056780785322189, 0.09768392145633698, 0.11268912255764008, 0.08585509657859802, 0.004281207919120789, 0.05256142467260361, 0.02305726520717144, -0.04386488348245621, -0.08068867027759552, 0.11729981750249863, -0.017532996833324432, -0.0663464292883873, 0.05473261699080467, -0.07394775748252869, 0.003492396790534258, 0.0716431736946106, -0.001270398497581482, 0.03849712014198303, -0.013460325077176094, 0.19454552233219147, 0.06734443455934525, 0.0010675956727936864, 0.09041868150234222, -0.08097025752067566, 0.03205978497862816, -0.04646270349621773, -0.018719526007771492, -0.11213794350624084, -0.0492330864071846, 0.10233163833618164, -0.08509191125631332, -0.00580668356269598, -0.08898989856243134, 0.18461363017559052, -0.10275962948799133, 0.04089139401912689, 0.0627342164516449, -0.05921686440706253, -0.09763696789741516, 0.06718015670776367, 0.058924201875925064, -0.05788324028253555, 0.025601789355278015, -0.09511974453926086, -0.0005043838173151016, -0.16392643749713898, -0.0677284449338913, 0.052481215447187424, 0.013942456804215908, 0.10418778657913208, -0.11213572323322296, -0.10661939531564713, 8.776721306555097e-33, -0.06571725010871887, 0.05098636820912361, 0.08302535116672516, -0.07765477895736694, -0.015147232450544834, -0.03586376830935478, -0.13250191509723663, 0.0044508036226034164, 0.04987594857811928, 0.07255543768405914, -0.10678012669086456, 0.07392190396785736, -0.013028341345489025, 0.05102092772722244, 0.10573306679725647, 0.1562321037054062, -0.13689091801643372, 0.08679938316345215, -0.11411657929420471, 0.025642048567533493, 0.11984413862228394, -0.019669482484459877, 0.006837789434939623, 0.042627591639757156, -0.024063080549240112, 0.10200580954551697, -0.03175526112318039, 0.0395950973033905, -0.21523967385292053, -0.04050258547067642, -0.060557957738637924, 0.04871087521314621, 0.16681718826293945, -0.015644632279872894, 0.04610166698694229, -0.09325402975082397, -0.06747467815876007, 0.050115667283535004, 0.011394236236810684, 0.011973134241998196, -0.05317378044128418, 0.07653678953647614, 0.02143082767724991, -0.026968328282237053, 0.04860752448439598, -0.023686740547418594, 0.016056649386882782, -0.08478843420743942, -0.11797656118869781, -0.013594333082437515, 0.11106069386005402, -0.017512237653136253, -0.1608613133430481, -0.003338240087032318, -0.14580866694450378, 0.06974530220031738, -0.013956209644675255, 0.07385098189115524, 0.037884216755628586, -0.007045856676995754, 0.1443682610988617, -0.08226402848958969, 0.009051630273461342, 0.07855309545993805, -0.11839164793491364, 0.030294343829154968, -0.06817484647035599, -0.008842231705784798, 0.06991671770811081, -0.006734329275786877, -0.04268485680222511, 0.0016822628676891327, 0.025296533480286598, -0.023164907470345497, 0.13707181811332703, 0.02971435710787773, 0.046870969235897064, 0.07910843193531036, -0.0880303904414177, 0.028973273932933807, -0.023266691714525223, 0.16287656128406525, -0.06546439975500107, -0.09307460486888885, -0.08765581995248795, -0.05534307658672333, 0.07158154249191284, -0.06123260408639908, -0.05314616858959198, 0.03504655510187149, -0.023067541420459747, 0.06308011710643768, -0.1194724515080452, 0.0525413416326046, -0.07383359968662262, -8.280831667821023e-33, -0.030055392533540726, 0.09146065264940262, -0.0730033665895462, 0.07772000133991241, -0.016758538782596588, 0.04077118635177612, 0.04285033792257309, -0.008107412606477737, -0.06258261203765869, -0.09702496230602264, 0.08817809820175171, 0.03544435650110245, -0.12115861475467682, -0.01967092603445053, -0.14692069590091705, 0.019932925701141357, -0.009127759374678135, -0.015019642189145088, -0.09465165436267853, 0.016611112281680107, 0.11348679661750793, 0.09026520699262619, -0.14298968017101288, 0.09574193507432938, -0.1362638920545578, 0.20213142037391663, -0.0669059157371521, 0.011367261409759521, 0.031066372990608215, -0.08564337342977524, -0.006692694034427404, 0.049545709043741226, -0.06247154623270035, -0.014290613122284412, -0.003628523088991642, -0.05966555327177048, 0.030945654958486557, -0.005223821848630905, 0.06625202298164368, 0.09112468361854553, 0.09910356253385544, 0.16231229901313782, -0.139088436961174, 0.052291154861450195, -0.02680381014943123, -0.10605642199516296, 0.08567079901695251, -0.08750329911708832, 0.08298720419406891, -0.07178455591201782, 0.041107967495918274, -0.060226693749427795, -0.049883753061294556, 0.1245591938495636, 0.026113254949450493, 0.03627273440361023, -0.14318719506263733, -0.03359851986169815, 0.045133091509342194, 0.14807046949863434, -0.11872660368680954, 0.027953244745731354, -0.07825374603271484, 0.07248710840940475, -0.051019299775362015, 0.14596280455589294, -0.002142515731975436, 0.07478415220975876, 0.06200399249792099, 0.10751901566982269, -0.12622886896133423, 0.144969180226326, -0.03748738020658493, -0.04962855577468872, -0.043112706393003464, 0.018627291545271873, 0.04665003716945648, 0.034531787037849426, 0.024345356971025467, -0.040105633437633514, -0.18946748971939087, -0.07621249556541443, -0.062322765588760376, 0.05468810349702835, -0.026093026623129845, 0.07062534987926483, 0.0909823626279831, -0.09778311103582382, 0.00934225507080555, -0.012302963994443417, -0.005214918404817581, 0.03297428786754608, 0.05812448263168335, -0.04287491738796234, 0.038005612790584564, -1.0024425023402728e-07, -0.0554044246673584, 0.013221146538853645, 0.06425931304693222, 0.000507172429934144, -0.03722512722015381, -0.033565960824489594, -0.09184866398572922, 0.07313123345375061, -0.01037641055881977, 0.006678041070699692, 0.15045523643493652, -0.05429372191429138, -0.1939040571451187, -0.09097383916378021, 0.04833725094795227, 0.08383893966674805, -0.0438711941242218, 0.09266260266304016, -0.018286731094121933, 0.06051713973283768, 0.0455748587846756, -0.05761898308992386, 0.02007650025188923, 0.013202766887843609, 0.0882655531167984, -0.04353112727403641, 0.012445464730262756, 0.023204557597637177, -0.009160756133496761, 0.11619758605957031, 0.016909809783101082, -0.04741280525922775, -0.0009127316297963262, 0.05581935495138168, 0.05612723529338837, 0.02390589565038681, 0.07550735771656036, -0.050056956708431244, -0.019897224381566048, 0.048497240990400314, -0.003821474500000477, -0.05722673237323761, -0.055737875401973724, -0.051706548780202866, 0.008376983925700188, -0.01715872623026371, 0.019423292949795723, -0.0782783105969429, -0.02614256553351879, 0.0202193446457386, 0.06624892354011536, 0.03605455160140991, -0.08566600829362869, 0.027947058901190758, 0.011163253337144852, 0.06770476698875427, 0.0397198349237442, -0.14248934388160706, 0.0003501288592815399, 0.13325363397598267, 0.09109991788864136, -0.043995268642902374, -0.02747064083814621, 0.01105425227433443], metadata={'source': 'AAAMLP-569to.pdf', 'page': 32}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 33 Now, let’s say we change the dataset a bit such that there are 180 chest x-ray images which do not have pneumothorax and only 20 with pneumothorax. Even in this case, we will create the training and validation sets with the same ratio of positive to negative (pneumothorax to non- pneumothorax) targets. In each set, we have 90 non- pneumothorax and 10 pneumothorax images. If you say that all images in the validation set are non-pneumothorax, what would your accuracy be? Let’s see; you classified 90% of the images correctly. So, your accuracy is 90%.   But look at it one more time.   You didn’t even build a model and got an accuracy of 90%. That seems kind of useless. If we look carefully, we will see that the dataset is skewed, i.e., the number of samples in one class outnumber the number of samples in other class by a lot. In these kinds of cases, it is not advisable to use accuracy as an evaluation metric as it is not representative of the data. So, you might get high accuracy, but your model will probably not perform that well when it comes to real-world samples, and you won’t be able to explain to your managers why.  In these cases, it’s better to look at other metrics such as precision.   Before learning about precision, we need to know a few terms. Here we have assumed that chest x-ray images with pneumothorax are positive class (1) and without pneumothorax are negative class (0).  True positive (TP): Given an image, if your model predicts the image has pneumothorax, and the actual target for that image has pneumothorax, it is considered a true positive.  True negative (TN): Given an image, if your model predicts that the image does not have pneumothorax and the actual target says that it is a non-pneumothorax image, it is considered a true negative.  In simple words, if your model correctly predicts positive class, it is true positive, and if your model accurately predicts negative class, it is a true negative.  False positive (FP): Given an image, if your model predicts pneumothorax and the actual target for that image is non- pneumothorax, it a false positive.'),\n",
       " VectorParams(vector=[-0.10508913546800613, 0.006948618683964014, -0.007243415806442499, 0.04330284520983696, 0.010190817527472973, -0.14739957451820374, 0.023630479350686073, 0.05385331064462662, -0.040265779942274094, 0.01545734703540802, 0.054781462997198105, -0.042949650436639786, 0.16337312757968903, 0.04816349595785141, -0.1063770055770874, -0.044072967022657394, -0.008679968304932117, -0.019261052832007408, 0.017873317003250122, -0.05858085677027702, 0.10989927500486374, 0.05257362127304077, -0.057879555970430374, 0.02847312204539776, -0.020667729899287224, -0.1086738333106041, 0.0563037171959877, 0.04605730623006821, -0.09985178709030151, -0.11450708657503128, -0.10085031390190125, 0.050653208047151566, 0.01106702908873558, -0.004720971919596195, -0.005253111477941275, 0.04037141427397728, -0.05962219461798668, 0.039144232869148254, -0.012730472721159458, 0.07447519898414612, -0.06947994977235794, -0.0856752097606659, -0.034614644944667816, -0.0693170577287674, 0.0783916562795639, 0.05865781754255295, -0.028417173773050308, 0.06641773879528046, 0.028366694226861, -0.04474432021379471, -0.04206400737166405, 0.145381361246109, -0.14878147840499878, -0.014484920538961887, -0.06258074939250946, -0.02830621413886547, 0.12585042417049408, -0.05690275877714157, -0.058593425899744034, -0.10518503934144974, -0.02962198667228222, -0.0420050285756588, -0.059399571269750595, -0.044404271990060806, 0.05168157443404198, 0.06455854326486588, -0.10921474546194077, 0.05973314866423607, 0.0033386244904249907, 0.13269677758216858, 0.04274033382534981, 0.09741964191198349, 0.029706241562962532, 0.06854621320962906, -0.062162335962057114, 0.05142700672149658, 0.19079971313476562, 0.06610351800918579, 0.02416960708796978, 0.05326363444328308, -0.0331982858479023, -0.02408268116414547, -0.010122064501047134, 0.005350717343389988, 0.12820346653461456, -0.10770301520824432, -0.0795283243060112, 0.10439851880073547, 0.07008862495422363, 0.03987174853682518, 0.07683571428060532, -0.027613399550318718, -0.016156794503331184, -0.003647815901786089, 0.06302729994058609, 0.129435732960701, 0.0018868744373321533, -0.10800355672836304, -0.025514446198940277, 0.042243752628564835, -0.1845294088125229, -0.026585789397358894, 0.061133865267038345, -0.10901980847120285, 0.13598501682281494, -0.0032274359837174416, 0.057713836431503296, -0.158674955368042, 0.11629451811313629, -0.22152674198150635, -0.12238600850105286, -0.13224272429943085, -0.026041606441140175, -0.09074503928422928, 0.07075463235378265, 0.1368599385023117, -0.05311816558241844, 0.1492970883846283, -0.09803909808397293, -0.06507916748523712, -0.08696964383125305, 0.084296815097332, 0.030120549723505974, 0.12173178791999817, 0.029468964785337448, -0.1317145973443985, -0.21529942750930786, 1.5312130473133216e-32, -0.11597257852554321, 0.005382634699344635, 0.08547186106443405, -0.07748512178659439, -0.04051034152507782, -0.008748850785195827, -0.03362388536334038, -0.037211429327726364, -0.012836124747991562, 0.11051327735185623, -0.03853701055049896, -0.000552413403056562, -0.047584399580955505, 0.06530176848173141, 0.017816120758652687, 0.029785599559545517, -0.030544647946953773, -0.054409563541412354, -0.08068546652793884, 0.021210484206676483, 0.09181567281484604, -0.08392122387886047, 0.033565398305654526, -0.07296214252710342, -0.04016406089067459, 0.026834694668650627, 0.0014575854875147343, -0.05060303956270218, -0.07420650124549866, -0.013703610748052597, -0.1326213777065277, 0.04710723087191582, 0.09722848981618881, -0.07618524134159088, 0.09072364866733551, -0.08624863624572754, -0.031316183507442474, 0.06728418916463852, -0.11076795309782028, -0.042914312332868576, -0.13968104124069214, -0.0149688133969903, -0.0037115004379302263, -0.03805137425661087, 0.07976452261209488, -0.09132423251867294, 0.017868924885988235, -0.014847866259515285, -0.04021434858441353, 0.09407268464565277, 0.06508971750736237, -0.05354280024766922, -0.09342122822999954, -0.012964826077222824, -0.1590973436832428, -0.01019646693021059, 0.10132896155118942, 0.12615971267223358, 0.07370514422655106, -0.02689051628112793, 0.11799800395965576, -0.12549982964992523, -0.03158138319849968, -0.11294965445995331, -0.06834569573402405, 0.1569334864616394, 0.05836161971092224, -0.007425954565405846, 0.08892668783664703, 0.05165374279022217, 0.0021328201983124018, 0.06049109622836113, -0.019587425515055656, -0.08046521991491318, 0.13132686913013458, -0.053187720477581024, 0.07198728621006012, -0.011962530203163624, -0.007870745845139027, -0.0438881553709507, 0.01280638761818409, 0.022841909900307655, -0.08247283846139908, -0.12225954234600067, -0.02090626396238804, -0.058178097009658813, 0.05942768231034279, 0.008655620738863945, -0.16393229365348816, -0.040947116911411285, -0.11720731109380722, 0.07252755761146545, 0.0327625535428524, 0.08594607561826706, -0.05136272683739662, -1.7950699459602648e-32, 0.006303844973444939, 0.12147367000579834, -0.018262043595314026, -0.004449293948709965, -0.07717359811067581, 0.0007954700849950314, 0.04640648141503334, 0.09614349901676178, 0.05266852676868439, -0.1013118177652359, 0.005432682111859322, -0.08842149376869202, -0.038627490401268005, 0.04692335054278374, -0.07126543670892715, 0.06281011551618576, -0.01544504426419735, -0.04397707059979439, -0.08149361610412598, 0.017933377996087074, -0.09518112987279892, 0.15016089379787445, -0.06325429677963257, -0.024655401706695557, -0.13782277703285217, 0.10676135867834091, -0.007542571984231472, 0.12162407487630844, -0.023390164598822594, 0.019981559365987778, -0.08895896375179291, 0.13920395076274872, -0.05344941467046738, 0.10371308773756027, 0.0012500439770519733, -0.010422203689813614, 0.03245583549141884, -0.028996359556913376, 0.002097266959026456, 0.04884878173470497, 0.18114760518074036, 0.09834165871143341, -0.05521126464009285, -0.007629659958183765, -0.07097457349300385, -0.0050024837255477905, -0.013134709559381008, -0.010466115549206734, 0.07941580563783646, -0.03241311013698578, -0.07681718468666077, 0.03914203494787216, -0.08257090300321579, 0.140388622879982, -0.004237751942127943, 0.020765678957104683, -0.17781083285808563, -0.07148462533950806, -0.029635919257998466, 0.0971207395195961, -0.14033672213554382, -0.11378441751003265, 0.03332708403468132, -0.022471610456705093, -0.06617246568202972, 0.04522086679935455, -0.05071721225976944, 0.06606835126876831, 0.06508871912956238, 0.10998265445232391, -0.005893016699701548, 0.20731909573078156, -0.05197993665933609, -0.10357982665300369, -0.051979344338178635, -0.031298138201236725, -0.07317434251308441, 0.08396990597248077, -0.0027387903537601233, 0.048877254128456116, -0.07928501814603806, -0.03797341510653496, -0.015483532100915909, 0.1394135057926178, -0.06084315478801727, 0.0415719710290432, 0.08614515513181686, 0.13608692586421967, 0.12227979302406311, 0.00017429658328182995, -0.02017253451049328, 0.07741935551166534, 0.069513238966465, 0.1266738623380661, 0.09263591468334198, -1.0136858463738463e-07, -0.09770848602056503, -0.03341953456401825, 0.09429362416267395, 0.060614343732595444, 0.12728388607501984, 0.0020367540419101715, -0.07889313250780106, -0.012507743202149868, -0.08505655080080032, -0.09440744668245316, 0.073166124522686, 0.07265056669712067, -0.12464816123247147, -0.11698414385318756, -0.06439630687236786, 0.11815699189901352, -0.023810695856809616, 0.038680143654346466, 0.050750795751810074, -0.045080188661813736, 0.10384441912174225, -0.1337604820728302, -0.035319264978170395, 0.11831849068403244, 0.0026094415225088596, -0.08743222057819366, -0.08236765116453171, -0.06998207420110703, 0.02787119150161743, 0.015761828050017357, 0.042237117886543274, -0.06651028245687485, 0.03933422267436981, 0.0027148418594151735, 0.08477319031953812, 0.09941240400075912, 0.02850789576768875, 0.01725529320538044, 0.014432216063141823, 0.00010886265954468399, -0.1284637302160263, 0.05045877397060394, -0.13768908381462097, -0.08753001689910889, 0.0343426950275898, 0.020950231701135635, 0.031379565596580505, -0.1427997350692749, 0.006226391531527042, -0.0016818968579173088, -0.009109492413699627, 0.07954757660627365, -0.05787195637822151, 0.062215931713581085, 0.06339839845895767, 0.01428888738155365, -0.05642439052462578, -0.02089979685842991, -0.09879925101995468, 0.0904930830001831, 0.04990692064166069, -0.07527189701795578, -0.012533813714981079, -0.021486682817339897], metadata={'source': 'AAAMLP-569to.pdf', 'page': 33}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 34 False negative (FN): Given an image, if your model predicts non-pneumothorax and the actual target for that image is pneumothorax, it is a false negative.  In simple words, if your model incorrectly (or falsely) predicts positive class, it is a false positive. If your model incorrectly (or falsely) predicts negative class, it is a false negative.  Let’s look at implementations of these, one at a time.  ═════════════════════════════════════════════════════════════════════════ def true_positive(y_true, y_pred):     \"\"\"     Function to calculate True Positives     :param y_true: list of true values     :param y_pred: list of predicted values     :return: number of true positives     \"\"\"     # initialize     tp = 0     for yt, yp in zip(y_true, y_pred):         if yt == 1 and yp == 1:             tp += 1     return tp  def true_negative(y_true, y_pred):     \"\"\"     Function to calculate True Negatives     :param y_true: list of true values     :param y_pred: list of predicted values     :return: number of true negatives     \"\"\"     # initialize     tn = 0     for yt, yp in zip(y_true, y_pred):         if yt == 0 and yp == 0:             tn += 1     return tn  def false_positive(y_true, y_pred):     \"\"\"     Function to calculate False Positives     :param y_true: list of true values     :param y_pred: list of predicted values     :return: number of false positives     \"\"\"     # initialize'),\n",
       " VectorParams(vector=[-0.10307563841342926, -0.011890589259564877, 0.011343387886881828, -0.04085143283009529, 0.144423246383667, -0.09289168566465378, 0.07621477544307709, -0.02827492728829384, -0.11881178617477417, 0.052793361246585846, 0.007356951478868723, -0.1091843917965889, 0.08329588919878006, 0.09108526259660721, -0.09257005900144577, 0.04401698708534241, -0.04217343404889107, 0.011952648870646954, 0.04046560823917389, 0.0020339470356702805, 0.06305699050426483, 0.09072050452232361, -0.0548221655189991, 0.04969999939203262, 0.08381538093090057, -0.15357862412929535, 0.0006423917366191745, 0.09209476411342621, -0.08416206389665604, -0.08097758144140244, -0.011365839280188084, 0.1301204413175583, 0.015396631322801113, -0.022406229749321938, -0.01825461909174919, 0.06882451474666595, -0.035006411373615265, -0.034948162734508514, -0.018415480852127075, 0.09711215645074844, -0.0867735892534256, -0.08810131251811981, 0.0036211598198860884, -0.06534064561128616, 0.06436669081449509, 0.17145872116088867, -0.017126386985182762, 0.050452060997486115, -0.015179289504885674, 0.0027431214693933725, 0.01627185568213463, 0.23128165304660797, -0.1549956351518631, 0.03043411485850811, -0.036980386823415756, -0.10546480119228363, 0.015229836106300354, -0.032731860876083374, -0.07197654247283936, -0.06627127528190613, -0.08512991666793823, -0.03821330517530441, -0.11808837205171585, -0.02908499911427498, 0.08721526712179184, 0.08267635852098465, -0.08968795090913773, 0.02460084669291973, -0.0035925551783293486, 0.19977492094039917, -0.03300373628735542, 0.07806396484375, -0.023694360628724098, 0.01109231635928154, -0.018075866624712944, 0.05984111502766609, 0.23306715488433838, 0.020439686253666878, -0.07485953718423843, 0.0711163580417633, -0.08327402174472809, 0.01325013767927885, 0.03501304239034653, -0.02569219470024109, 0.037041500210762024, -0.23312720656394958, -0.11384229362010956, 0.11254780739545822, 0.13167820870876312, 0.01117118913680315, 0.05922827497124672, 0.0269112940877676, -0.0477714017033577, 0.012468364089727402, 0.07525651901960373, 0.07586922496557236, 0.002106569241732359, -0.021663840860128403, -0.024904483929276466, 0.14010509848594666, -0.22353549301624298, -0.03495549410581589, 0.02687103860080242, -0.16299040615558624, 0.14840786159038544, -0.005529505666345358, 0.06722307950258255, -0.14372004568576813, 0.1507897824048996, -0.28401240706443787, -0.04209340363740921, -0.12787680327892303, 0.10198772698640823, 0.013974964618682861, 0.049606919288635254, 0.11051962524652481, -0.08715752512216568, 0.1455194503068924, 0.08082675188779831, -0.08841044455766678, -0.01661374792456627, 0.055192023515701294, 0.1047704741358757, 0.17678022384643555, 0.02702183835208416, -0.11564230918884277, -0.14937029778957367, 1.529818323266071e-32, -0.12277096509933472, 0.02503504790365696, 0.03840363770723343, -0.12383939325809479, -0.10944758355617523, 0.028058819472789764, 0.04503307119011879, -0.014283303171396255, -0.02535700611770153, 0.13143184781074524, -0.12566950917243958, 0.04612964391708374, -0.06762425601482391, -0.06997114419937134, 0.020203206688165665, -0.010564488358795643, -0.028420424088835716, 0.029556963592767715, 0.01606660895049572, -0.033915888518095016, 0.14464998245239258, -0.04373742267489433, 0.017052652314305305, -0.1768096685409546, -0.00021047526388429105, -0.05510713905096054, -0.05651596933603287, -0.09425634890794754, -0.10750411450862885, 0.03347502648830414, -0.16488608717918396, 0.002825923729687929, 0.06862334907054901, -0.030397146940231323, 0.060845110565423965, -0.08591757714748383, -0.051319826394319534, 0.042624037712812424, -0.0896654725074768, -0.08428137004375458, -0.07718311995267868, 0.045445848256349564, -0.009581036865711212, -0.06532298773527145, 0.03423113748431206, -0.1558493971824646, -0.03274202346801758, 0.06301888078451157, -0.006768884602934122, 0.1800004541873932, 0.06395124644041061, -0.07467722147703171, -0.09143566340208054, -0.0008287018281407654, -0.09053781628608704, -0.01969624124467373, 0.08972723037004471, 0.15356215834617615, 0.04049237072467804, 0.12161750346422195, 0.03183740749955177, -0.020176062360405922, 0.004201723262667656, -0.12542295455932617, -0.07847888022661209, 0.1535380333662033, 0.03051578812301159, -0.005835096817463636, 0.2439841330051422, 0.0784279927611351, -0.07006321847438812, 0.007715532090514898, 0.07612431049346924, -0.09963846951723099, 0.19823646545410156, -0.07097823172807693, 0.10865522176027298, -0.181827113032341, -0.026928462088108063, -0.15235713124275208, 0.028506368398666382, 0.07881342619657516, -0.14121945202350616, -0.08303319662809372, -0.05621730908751488, -0.112447589635849, 0.04618728905916214, -0.06074683740735054, -0.18308910727500916, -0.07972872257232666, -0.19133827090263367, 0.05142710357904434, 0.034247156232595444, 0.005938776768743992, -0.05308745801448822, -1.3968856344250125e-32, -0.07514860481023788, 0.05234190449118614, 0.02199932001531124, 0.043411608785390854, -0.10329574346542358, -0.0006368013564497232, 0.0736180990934372, -0.06718520820140839, 0.11092370748519897, -0.015393048524856567, 0.009925161488354206, -0.07321728020906448, -0.10430724173784256, -0.0009636303875595331, 0.029209472239017487, 0.11116860061883926, -0.09769895672798157, 0.07811742275953293, -0.010671290569007397, 0.12499088793992996, -0.004727810155600309, 0.2593666911125183, -0.1371590942144394, 0.055828794836997986, -0.06176391616463661, 0.1329561322927475, 0.04157896712422371, 0.1831797957420349, 0.0599798858165741, -0.023350529372692108, -0.062193673104047775, 0.04906415939331055, -0.15717433393001556, 0.05894588306546211, 0.015014290809631348, -0.08251667022705078, 0.018028659746050835, -0.06611047685146332, 0.04671528562903404, 0.038573529571294785, 0.14644306898117065, 0.11471693217754364, -0.11943843960762024, -0.057242825627326965, 0.02950412593781948, -0.008678955025970936, 0.018471481278538704, -0.020716262981295586, 0.0740404948592186, -0.09313473850488663, -0.07585091888904572, 0.0790177434682846, -0.1282060146331787, 0.13592135906219482, -0.09032143652439117, 0.05836642161011696, -0.22464820742607117, -0.042598266154527664, -0.03341270238161087, -0.0018735259072855115, -0.12225998938083649, -0.04062934219837189, 0.1175844594836235, 0.11228462308645248, 0.044788721948862076, 0.07360125333070755, -0.0512593574821949, 0.062310852110385895, 0.10631892830133438, 0.19845978915691376, -0.02085108309984207, 0.10554756224155426, -0.029923852533102036, -0.13486133515834808, -0.016435882076621056, 0.014104016125202179, 0.006527192424982786, 0.005885016638785601, -0.04512910172343254, 0.10049521923065186, -0.07730281352996826, 0.047994017601013184, 0.031687717884778976, 0.21347618103027344, -0.1002752035856247, 0.038345713168382645, 0.14398376643657684, 0.16604025661945343, 0.15502701699733734, -0.03609320893883705, 0.10152721405029297, 0.1884927898645401, 0.07467428594827652, 0.1379159539937973, 0.05747717246413231, -1.0013918227969043e-07, -0.10952916741371155, -0.051063455641269684, -0.00642580259591341, 0.08439644426107407, 0.12050416320562363, -0.03830636292695999, -0.1256265938282013, -0.03127039968967438, -0.14543472230434418, -0.1656922698020935, 0.11813554167747498, 0.1289244145154953, -0.15220141410827637, -0.07828522473573685, -0.0392359234392643, 0.030637798830866814, -0.02717226929962635, 0.013941960409283638, -0.024190720170736313, 0.06931769847869873, 0.10535021126270294, -0.016069738194346428, -0.013813193887472153, 0.04099227115511894, -0.04165780171751976, -0.053744882345199585, -0.1433832198381424, -0.03563472628593445, 0.14562705159187317, 0.13918852806091309, 0.03354828059673309, 0.00973412487655878, 0.08817194402217865, -0.001189735485240817, 0.0530569851398468, 0.12810972332954407, 0.016678081825375557, 0.049248144030570984, -0.06567271798849106, -0.031591854989528656, -0.1460496485233307, 0.06890865415334702, -0.16625820100307465, -0.06664071977138519, 0.06585010886192322, -0.04270713031291962, 0.09118637442588806, -0.09181422740221024, -0.0452224425971508, -0.1182912141084671, -0.01515541598200798, 0.10608560591936111, -0.13169421255588531, 0.032614123076200485, 0.07740310579538345, -0.05851168558001518, -0.2319977581501007, -0.07102593034505844, -0.09305346757173538, 0.05565012991428375, -0.04366460070014, 0.016016025096178055, 0.04046362638473511, -0.03927140310406685], metadata={'source': 'AAAMLP-569to.pdf', 'page': 34}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 35     fp = 0     for yt, yp in zip(y_true, y_pred):         if yt == 0 and yp == 1:             fp += 1     return fp  def false_negative(y_true, y_pred):     \"\"\"     Function to calculate False Negatives     :param y_true: list of true values     :param y_pred: list of predicted values     :return: number of false negatives     \"\"\"     # initialize     fn = 0     for yt, yp in zip(y_true, y_pred):         if yt == 1 and yp == 0:             fn += 1     return fn ═════════════════════════════════════════════════════════════════════════  The way I have implemented these here is quite simple and works only for binary classification. Let’s check these functions.  ═════════════════════════════════════════════════════════════════════════ In [X]: l1 = [0,1,1,1,0,0,0,1]    ...: l2 = [0,1,0,1,0,1,0,0]  In [X]: true_positive(l1, l2) Out[X]: 2  In [X]: false_positive(l1, l2) Out[X]: 1  In [X]: false_negative(l1, l2) Out[X]: 2  In [X]: true_negative(l1, l2) Out[X]: 3 ═════════════════════════════════════════════════════════════════════════  If we have to define accuracy using the terms described above, we can write:  Accuracy Score = (TP + TN) / (TP + TN + FP + FN)'),\n",
       " VectorParams(vector=[-0.10584361851215363, -0.041973453015089035, -0.006880859844386578, -0.03137806057929993, 0.08972593396902084, -0.16310778260231018, -0.05645739287137985, 0.05810023844242096, -0.07828731834888458, 0.015158632770180702, -0.014228985644876957, -0.10092496871948242, 0.04082360118627548, 0.009959298186004162, -0.07857372611761093, -0.11829935014247894, 0.058456625789403915, 0.04836096242070198, -0.009299925528466702, -0.03394016623497009, -0.01090499758720398, 0.11668247729539871, -0.04744315892457962, 0.08362722396850586, 0.08046592772006989, -0.1374095231294632, -0.020641515031456947, 0.10750318318605423, -0.12200403958559036, -0.049662284553050995, 0.020128194242715836, 0.1262325644493103, -0.08030592650175095, 0.02675440162420273, -0.10876511037349701, 0.068172387778759, -0.02955637127161026, -0.021425237879157066, -0.024817515164613724, -0.008781127631664276, -0.13852833211421967, -0.10584892332553864, 0.06939813494682312, 0.007866603322327137, 0.11305606365203857, 0.131402850151062, -0.03139709681272507, -0.014837122522294521, -0.006314119789749384, -0.07351040840148926, -0.10630372911691666, 0.18502026796340942, -0.13034319877624512, -0.034712694585323334, 0.02114402875304222, 0.056326474994421005, 0.051171526312828064, -0.04052431508898735, -0.029274238273501396, -0.1164112389087677, 0.00429384782910347, -0.04120234027504921, -0.09204734861850739, -0.02326814830303192, 0.10889726132154465, -0.016132617369294167, -0.03675074130296707, -0.05343499034643173, 0.025747157633304596, 0.15276657044887543, -0.08481509983539581, 0.10084989666938782, 0.003225374035537243, 0.09802346676588058, -0.0015898876590654254, 0.03756247088313103, 0.1363637000322342, 0.064829982817173, 0.044446513056755066, -0.04594378545880318, 0.018351243808865547, 0.04605948179960251, -0.06541135907173157, -0.005194136872887611, 0.05084177479147911, -0.1763773113489151, -0.008344062604010105, 0.1160915195941925, 0.121353879570961, -0.02742725983262062, 0.1854831725358963, -0.03574470430612564, -0.06464774161577225, -0.02338641695678234, 0.08540604263544083, 0.100625179708004, -0.01127739530056715, -0.01689177379012108, -0.002849423326551914, 0.1105494275689125, -0.10617133229970932, 0.0232564527541399, -0.07581710815429688, -0.12592223286628723, 0.1609213948249817, 0.04478898644447327, 0.11572974920272827, -0.05994166433811188, 0.20484332740306854, -0.18316718935966492, 0.06309783458709717, -0.06431669741868973, -0.03168835490942001, 0.050618480890989304, 0.12883062660694122, 0.14204871654510498, -0.05097636580467224, 0.1367035061120987, 0.03625020757317543, 0.10143633931875229, -0.1581643670797348, 0.018187861889600754, 0.05313166603446007, 0.13998842239379883, -0.004254506900906563, -0.025578508153557777, -0.12960277497768402, 1.2035793353205305e-32, -0.17070037126541138, 0.019696582108736038, 0.06222475692629814, -0.1431271880865097, -0.04025602713227272, -0.011853918433189392, -0.07682280242443085, -0.023913083598017693, -0.07473886013031006, 0.04030010849237442, -0.17671814560890198, 0.005698930472135544, -0.08706856518983841, -0.06271376460790634, 0.11872316151857376, -0.01800072193145752, -0.05031781643629074, 0.03477175533771515, 0.0020920494571328163, -0.0256502628326416, 0.2417403757572174, -0.08933326601982117, 0.045054394751787186, -0.1833881288766861, 0.010455481708049774, 0.00564045924693346, -0.015962254256010056, 0.02609795145690441, -0.17499284446239471, 0.009006370790302753, -0.23526181280612946, -0.050450365990400314, 0.0761554017663002, -0.00029486982384696603, 0.10351403802633286, -0.21745014190673828, 0.0008474127389490604, -0.02375216782093048, -0.04556962102651596, -0.11692383140325546, -0.049473654478788376, 0.15188734233379364, -0.013757525011897087, -0.033316101878881454, 0.0024638655595481396, -0.08845294266939163, -0.06764152646064758, 0.06993977725505829, 0.10629715025424957, 0.1272609382867813, 0.03515414148569107, -0.07684767246246338, -0.12114647775888443, -0.023810159415006638, -0.1121138334274292, 8.638395229354501e-05, 0.1261560171842575, 0.01912802830338478, 0.07981569319963455, 0.08463896065950394, 0.04653492942452431, -0.00632083835080266, -0.0022585359402000904, -0.15196694433689117, -0.05695541203022003, 0.16287094354629517, 0.06785300374031067, 0.0770641639828682, 0.16226354241371155, 0.07339642196893692, -0.0833294540643692, 0.012175534851849079, 0.027010595425963402, -0.07606139034032822, 0.17869995534420013, -0.07726471871137619, 0.1561727225780487, -0.17137254774570465, -0.013680246658623219, -0.12067224085330963, -0.047926515340805054, 0.12081766128540039, -0.1635168343782425, -0.14772070944309235, -0.07250148057937622, -0.1237010508775711, 0.006104662083089352, -0.02987201325595379, -0.118501678109169, -0.05255947262048721, -0.18779684603214264, 0.002635096199810505, -0.03678402304649353, 0.0424024760723114, -0.15204377472400665, -1.2495028874028833e-32, -0.10106249898672104, 0.03931710869073868, 0.02111262083053589, 0.18267640471458435, -0.0656912699341774, -0.020516308024525642, -0.0325259193778038, -0.09757643193006516, 0.021419484168291092, -0.04463663697242737, 0.03656085953116417, -0.11488358676433563, 0.018314160406589508, -0.02519656904041767, 0.06584484130144119, 0.06919018179178238, -0.10257947444915771, 0.09616446495056152, -0.04204021394252777, 0.08404207229614258, 0.0248537790030241, 0.19154813885688782, -0.1156386211514473, 0.04665283486247063, -0.0989832654595375, 0.12886258959770203, 0.0046669431030750275, 0.13505318760871887, -0.033944301307201385, -0.11620587110519409, 0.0070585329085588455, 0.029653340578079224, -0.16224347054958344, 0.04166727140545845, 0.10591515898704529, -0.06434322148561478, 0.06234899163246155, -0.11327389627695084, 0.03718382492661476, 0.04943390190601349, 0.2665557563304901, 0.20808811485767365, -0.17746427655220032, -0.040769316256046295, -0.032795682549476624, 0.03290506824851036, 0.005560213699936867, -0.014363425783813, 0.045666538178920746, -0.1093076542019844, 0.06150678172707558, -0.00640148064121604, -0.10881641507148743, 0.13318991661071777, -0.11339950561523438, 0.10341600328683853, -0.12636885046958923, 0.06338192522525787, -0.03156476840376854, 0.043172795325517654, -0.10700753331184387, -0.10621851682662964, 0.05427592620253563, 0.11931214481592178, 0.10311074554920197, 0.1374250054359436, -0.06479475647211075, 0.12885969877243042, 0.10073614865541458, 0.11997818946838379, -0.05618751049041748, 0.07794079929590225, -0.03891834616661072, -0.12221625447273254, -0.0313505120575428, 0.056563541293144226, 0.06093181297183037, 0.01195104606449604, -0.016763338819146156, 0.03442782536149025, -0.003605537349358201, 0.02551356703042984, 0.11749041080474854, 0.14592856168746948, -0.10803427547216415, 0.10930567979812622, 0.08818191289901733, 0.15762859582901, 0.10334622859954834, -0.010779422707855701, 0.03159090876579285, 0.18158939480781555, 0.047049641609191895, -0.007184973452240229, 0.06497081369161606, -1.0031977382141122e-07, -0.09855274856090546, -0.05677980184555054, 0.026008594781160355, 0.10542961955070496, 0.04249229282140732, 0.0014022602699697018, -0.14841704070568085, 0.014403519220650196, -0.12334185093641281, -0.07241366058588028, 0.030583146959543228, -0.002486709738150239, -0.1887284219264984, -0.08690133690834045, -0.05620475485920906, 0.061167966574430466, -0.016625437885522842, 0.09621434658765793, -0.07151004672050476, 0.05026751011610031, 0.08258407562971115, 0.0228564590215683, 0.04866652935743332, -0.0588604211807251, -0.09693904966115952, -0.0006504743359982967, -0.13223609328269958, 0.09129024296998978, 0.07906597852706909, 0.08099719882011414, 0.0047274078242480755, -0.07948236167430878, 0.08125840127468109, 0.04598376527428627, 0.09178300946950912, 0.12045102566480637, -0.0392787829041481, 0.0574176162481308, -0.029478926211595535, 0.08021965622901917, -0.18871982395648956, 0.11153118312358856, -0.14622314274311066, -0.0017137828981503844, 0.06920470297336578, -0.06450992077589035, 0.05949177220463753, 0.0010995481861755252, -0.029996579512953758, -0.06855898350477219, 0.09943242371082306, 0.10399233549833298, -0.1812574416399002, 0.016421165317296982, 0.04114147648215294, -0.0782049149274826, -0.251769095659256, -0.1149294525384903, -0.13579291105270386, 0.03768165782094002, 0.027021264657378197, -0.0013860808685421944, 0.030511554330587387, -0.00664923433214426], metadata={'source': 'AAAMLP-569to.pdf', 'page': 35}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 36 We can now quickly implement accuracy score using TP, TN, FP and FN in python. Let’s call it accuracy_v2.  ═════════════════════════════════════════════════════════════════════════ def accuracy_v2(y_true, y_pred):     \"\"\"     Function to calculate accuracy using tp/tn/fp/fn     :param y_true: list of true values     :param y_pred: list of predicted values     :return: accuracy score     \"\"\"     tp = true_positive(y_true, y_pred)     fp = false_positive(y_true, y_pred)     fn = false_negative(y_true, y_pred)     tn = true_negative(y_true, y_pred)     accuracy_score = (tp + tn) / (tp + tn + fp + fn)     return accuracy_score ═════════════════════════════════════════════════════════════════════════  We can quickly check the correctness of this function by comparing it to our previous implementation and scikit-learn version.  ═════════════════════════════════════════════════════════════════════════ In [X]: l1 = [0,1,1,1,0,0,0,1]    ...: l2 = [0,1,0,1,0,1,0,0]  In [X]: accuracy(l1, l2) Out[X]: 0.625  In [X]: accuracy_v2(l1, l2) Out[X]: 0.625  In [X]: metrics.accuracy_score(l1, l2) Out[X]: 0.625 ═════════════════════════════════════════════════════════════════════════  Please note that in this code, metrics.accuracy_score comes from scikit-learn.  Great. All values match. This means we have not made any mistakes in the implementation.  Now, we can move to other important metrics.  First one is precision. Precision is defined as:'),\n",
       " VectorParams(vector=[-0.028696304187178612, -0.0019251677440479398, -0.002563306363299489, -0.03159254416823387, 0.03488432988524437, -0.11616966873407364, 0.037907425314188004, 0.14902585744857788, 0.011593359522521496, 0.011925237253308296, 0.014020020142197609, -0.08520587533712387, 0.16459143161773682, 0.0550634041428566, -0.07499682903289795, -0.10086606442928314, -0.0293637253344059, 0.015505202114582062, -0.05646156147122383, 0.016596660017967224, 0.07759328931570053, 0.0735611692070961, 0.05450385808944702, 0.018948104232549667, -0.031565696001052856, -0.19804902374744415, -0.010606333613395691, 0.01903672143816948, -0.07658804208040237, -0.03064355067908764, -0.05175122246146202, 0.13707351684570312, -0.1013391837477684, 0.014550642110407352, -0.031698767095804214, 0.031278301030397415, -0.036487966775894165, 0.05222442373633385, 0.11710014939308167, 0.014835639856755733, 0.06202436983585358, -0.1002102717757225, -0.02697925828397274, -0.07591371238231659, 0.11783283948898315, 0.12596166133880615, -0.027728991582989693, 0.08743409812450409, 0.014074091799557209, 0.010027174837887287, -0.06803938001394272, 0.128961980342865, -0.10953331738710403, -0.010290143080055714, -0.14761677384376526, -0.06906940042972565, 0.06876662373542786, -0.0779324620962143, -0.004898125305771828, -0.10409370809793472, 0.0279768705368042, -0.03659873083233833, -0.027515051886439323, -0.09613950550556183, 0.04463458061218262, -0.043711792677640915, -0.03962605074048042, -0.12346794456243515, 0.044642820954322815, 0.09804320335388184, 0.04996359720826149, 0.14796948432922363, 0.06300454586744308, 0.15698161721229553, -0.045398060232400894, -0.10104651004076004, 0.0481400266289711, 0.06503274291753769, 0.06107603758573532, 0.01644325442612171, 0.022715819999575615, -0.042308855801820755, 0.020068125799298286, -0.08360865712165833, 0.17102043330669403, -0.16172486543655396, 0.006212073378264904, 0.13722290098667145, 0.05188508331775665, -0.05897995084524155, 0.04348907247185707, 0.0005631608073599637, -0.07396909594535828, 0.01529566291719675, 0.13197652995586395, 0.09903398156166077, 0.017156243324279785, -0.021798355504870415, -0.0730191245675087, 0.07883542776107788, -0.09034836292266846, -0.015588441863656044, -0.08975988626480103, -0.12869024276733398, 0.08382487297058105, -0.016983307898044586, 0.03424827381968498, -0.0999671146273613, 0.17379999160766602, -0.20768989622592926, -0.025506634265184402, -0.05970832705497742, -0.09713712334632874, -0.0751001164317131, 0.10840973258018494, 0.07106224447488785, -0.068428635597229, 0.0475132018327713, -0.060364820063114166, -0.039404917508363724, -0.11684934794902802, 0.041490696370601654, 0.07805929332971573, 0.13091282546520233, 0.11632277816534042, -0.07838936895132065, -0.1483575850725174, 1.143515173944961e-32, -0.1212773472070694, 0.05468574911355972, 0.07334470748901367, -0.09761512279510498, -0.008267928846180439, -0.010071808472275734, -0.08422955125570297, -0.026503508910536766, -0.03770176321268082, 0.036530617624521255, -0.14388838410377502, -0.04782683402299881, -0.05205856263637543, -0.038231782615184784, 0.06478918343782425, 0.05627216026186943, -0.08039917051792145, 0.022182371467351913, 0.001850862754508853, -0.008818832226097584, 0.20093192160129547, 0.034812070429325104, 0.12261776626110077, -0.00940250139683485, -0.04471782594919205, 0.1287665069103241, -0.042744722217321396, 0.032212719321250916, -0.13239139318466187, -0.0007438113680109382, -0.08865270018577576, -0.048433881253004074, 0.11267442256212234, -0.059050723910331726, 0.04184674844145775, -0.1651313155889511, 0.012801888398826122, 0.029915442690253258, -0.0758940801024437, -0.02635958418250084, -0.01668582484126091, 0.08691075444221497, 0.020945558324456215, 0.033563774079084396, 0.012538381852209568, -0.03832385316491127, -0.017748497426509857, 0.03716018795967102, 0.055447112768888474, 0.08007074147462845, 0.041897863149642944, -0.03482300043106079, -0.16097822785377502, 0.00440587755292654, -0.16023634374141693, 0.0032981724943965673, 0.1192350909113884, 0.08406869322061539, 0.15476718544960022, -0.05832015350461006, 0.13675494492053986, -0.026301754638552666, 0.02577233873307705, -0.06533828377723694, -0.04432917758822441, 0.0939875915646553, 0.06658826768398285, 0.13080117106437683, 0.0313187874853611, 0.061824966222047806, -0.10509613156318665, 0.02634494937956333, -0.016023585572838783, -0.033789947628974915, 0.08470916002988815, -0.008366793394088745, 0.14701992273330688, -0.0490843765437603, -0.008247129619121552, -0.007520393002778292, 0.03341637924313545, 0.07008656859397888, -0.055483944714069366, -0.09905041754245758, -0.15794427692890167, -0.13746291399002075, 0.10205768048763275, 0.02354515716433525, -0.05650092288851738, -0.06566782295703888, -0.08430276811122894, 0.0729631707072258, -0.029292186722159386, 0.016071224585175514, -0.12094755470752716, -1.2793395788890423e-32, -0.10780740529298782, 0.08321362733840942, 0.01288766972720623, 0.13152571022510529, -0.061469316482543945, -0.012294664978981018, 0.01239954773336649, -0.05852577090263367, -0.03319346532225609, -0.07929223030805588, 0.0353454053401947, -0.08704030513763428, -0.059948038309812546, -0.06061778590083122, -0.008411652408540249, 0.035141680389642715, -0.0649874210357666, 0.03254891559481621, -0.08210771530866623, 0.04311041906476021, 0.010072154924273491, 0.0900215432047844, -0.06298305839300156, 0.040502309799194336, -0.11151192337274551, 0.17446565628051758, -0.02590126544237137, 0.03955529257655144, 0.014292088337242603, -0.08233915269374847, -0.09236680716276169, 0.06531400233507156, -0.026061618700623512, 0.02178681269288063, 0.008181177079677582, -0.07072745263576508, -0.039269156754016876, -0.015765752643346786, 0.0681866705417633, 0.08226107805967331, 0.15264609456062317, 0.08455876260995865, -0.186721533536911, 0.03769968822598457, -0.029426895081996918, -0.0022508029360324144, 0.02932073175907135, -0.017328275367617607, 0.020961521193385124, -0.028235185891389847, 0.0654759407043457, 0.044985972344875336, -0.05522511526942253, 0.10611934959888458, 0.043308865278959274, 0.09484167397022247, -0.24916738271713257, -0.023442700505256653, -0.05799295753240585, 0.09279752522706985, -0.12206811457872391, -0.04459226131439209, -0.027784530073404312, 0.07676958292722702, 0.04390783607959747, 0.11562688648700714, -0.09176497906446457, 0.08700521290302277, 0.017238358035683632, 0.14177899062633514, -0.049510642886161804, 0.15810680389404297, -0.054667774587869644, -0.10223504900932312, -0.05091843754053116, -0.011518347077071667, -0.015584787353873253, 0.04811288043856621, 0.06282828748226166, 0.04655912145972252, -0.08701951801776886, -0.04380866140127182, 0.0066760326735675335, 0.05801251903176308, -0.06782457232475281, -0.02700979635119438, 0.10347402840852737, 0.04083802551031113, 0.11089994013309479, -0.05143291503190994, 0.050831541419029236, 0.15410634875297546, 0.0631045550107956, -0.011756797321140766, 0.06896775215864182, -1.0132919925354145e-07, -0.07796622067689896, 0.00700024887919426, 0.06727855652570724, 0.012657813727855682, 0.05057961121201515, -0.09061679989099503, -0.15441007912158966, 0.03429640084505081, -0.043058305978775024, -0.15627726912498474, 0.0431685596704483, -0.06076794117689133, -0.14757385849952698, -0.16778357326984406, 0.03168430179357529, -0.02832176350057125, -0.015257550403475761, 0.09820319712162018, 0.005538126919418573, -0.011618442833423615, -0.03841382637619972, -0.05600627511739731, 0.024391554296016693, -0.05325963348150253, -0.05499616265296936, 0.005726546049118042, -0.1209941953420639, 0.05405552685260773, 0.013469314202666283, 0.07107266783714294, 0.03631770610809326, -0.11244381964206696, 0.029947692528367043, 0.05779068544507027, 0.09006797522306442, 0.10180481523275375, 0.013383184559643269, 0.04836326837539673, -0.015077226795256138, -0.007782271131873131, -0.07921523600816727, -0.017726952210068703, -0.1326909065246582, -0.05506722256541252, 0.03953641653060913, -0.008773542940616608, 0.02620055340230465, -0.09447266161441803, 0.034788019955158234, 0.003320727963000536, 0.04534625634551048, 0.14269420504570007, -0.15040133893489838, 0.024808110669255257, -0.10788539052009583, 0.05626676604151726, -0.1128033995628357, -0.12912258505821228, -0.1765528917312622, 0.03276175633072853, 0.024927696213126183, -0.01106684748083353, -0.00443036574870348, 0.02368846721947193], metadata={'source': 'AAAMLP-569to.pdf', 'page': 36}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 37 Precision = TP / (TP + FP)  Let’s say we make a new model on the new skewed dataset and our model correctly identified 80 non-pneumothorax out of 90 and 8 pneumothorax out of 10. Thus, we identify 88 images out of 100 successfully. The accuracy is, therefore, 0.88 or 88%.   But, out of these 100 samples, 10 non-pneumothorax images are misclassified as having pneumothorax and 2 pneumothorax are misclassified as not having pneumothorax.  Thus, we have:  - TP : 8 - TN: 80 - FP: 10 - FN: 2  So, our precision is 8 / (8 + 10) = 0.444. This means our model is correct 44.4% times when it’s trying to identify positive samples (pneumothorax).  Now, since we have implemented TP, TN, FP and FN, we can easily implement precision in python.  ═════════════════════════════════════════════════════════════════════════ def precision(y_true, y_pred):     \"\"\"     Function to calculate precision     :param y_true: list of true values     :param y_pred: list of predicted values     :return: precision score     \"\"\"     tp = true_positive(y_true, y_pred)     fp = false_positive(y_true, y_pred)     precision = tp / (tp + fp)     return precision ═════════════════════════════════════════════════════════════════════════  Let’s try this implementation of precision.  ═════════════════════════════════════════════════════════════════════════ In [X]: l1 = [0,1,1,1,0,0,0,1]    ...: l2 = [0,1,0,1,0,1,0,0]'),\n",
       " VectorParams(vector=[-0.03420766070485115, -0.018743209540843964, -0.036870602518320084, 0.026641691103577614, 0.08053313940763474, -0.01981932297348976, -0.0026305578649044037, 0.14260806143283844, 0.02752211131155491, -0.0026640966534614563, 0.052648525685071945, -0.05358261615037918, 0.07884868234395981, -0.0025249668397009373, -0.02305181324481964, 0.005870635621249676, 0.015705086290836334, -0.016326937824487686, -0.12481220811605453, 0.003747476963326335, 0.11839528381824493, -0.0009208188857883215, 0.10225721448659897, 0.11290238052606583, 0.011755873449146748, -0.15894362330436707, -0.0022140706423670053, 0.0376148484647274, -0.0765838697552681, -0.09398230910301208, -0.02787039801478386, 0.17005811631679535, -0.07322679460048676, 0.0280435923486948, -0.03975415974855423, 0.08400247991085052, -0.09122423827648163, -0.03355427458882332, 0.05868830159306526, -0.09073787182569504, -0.048734281212091446, 0.00039848004234954715, 0.006240344140678644, -0.07261824607849121, 0.0937260314822197, 0.04828141629695892, 0.0367831327021122, 0.03270375356078148, -0.02088291011750698, -0.02214101143181324, -0.07029607146978378, 0.18903447687625885, -0.15899574756622314, -0.050870366394519806, -0.11703791469335556, 0.021657396107912064, 0.05693904310464859, -0.09688777476549149, -0.0966234803199768, -0.05073609575629234, -0.05794879049062729, -0.09874173998832703, -0.042522039264440536, -0.08485445380210876, -0.05888178572058678, -0.07187468558549881, -0.0482172816991806, -0.04351243004202843, -0.03307598829269409, 0.16018952429294586, 0.0021251405123621225, 0.11071684956550598, -0.008900167420506477, -0.023978613317012787, -0.013169949874281883, 0.027338560670614243, 0.04432401433587074, -0.007335376460105181, 0.01730874553322792, 0.08470933139324188, 0.01945759728550911, -0.037608541548252106, -0.0814349576830864, 0.024945544078946114, 0.097416952252388, -0.22840990126132965, 0.041981834918260574, 0.0054219248704612255, 0.12436455488204956, -0.008118050172924995, 0.0984916090965271, -0.05110398679971695, 0.004584416281431913, -0.025143716484308243, 0.15338298678398132, 0.10809017717838287, 0.10610048472881317, -0.0499824620783329, -0.06826172769069672, 0.06692769378423691, -0.028535764664411545, 0.14740251004695892, -0.020606322214007378, -0.14022459089756012, 0.08268147706985474, -0.017851881682872772, 0.06737518310546875, -0.018429795280098915, 0.15803833305835724, -0.22095651924610138, 0.04728375002741814, -0.048525042831897736, 0.051158931106328964, 0.09062119573354721, 0.06295081228017807, 0.058410756289958954, 0.015300366096198559, 0.026591118425130844, -0.05576691776514053, 0.054933834820985794, -0.047361109405756, 0.04653512313961983, 0.14974170923233032, 0.1591702550649643, 0.021118463948369026, -0.06750626116991043, -0.09977110475301743, 1.2339822477418012e-32, -0.038675457239151, 0.03570173308253288, -0.019894476979970932, -0.12249293178319931, -0.03264130651950836, 0.004784164018929005, -0.14635591208934784, 0.01899249479174614, -0.07324586063623428, 0.048797447234392166, -0.05805056169629097, 0.0005923218559473753, -0.02672569826245308, 0.018848512321710587, 0.07213366776704788, -0.017589757218956947, -0.09829015284776688, 0.0166835505515337, -0.047573551535606384, 0.05148164927959442, 0.04919321835041046, -0.0031130933202803135, 0.06025500223040581, -0.1170625165104866, -0.00862067099660635, 0.01619279570877552, -0.0022424261551350355, 0.040164731442928314, -0.16154876351356506, 0.006114872172474861, -0.16717451810836792, 0.028820853680372238, 0.10182454437017441, 0.0037089779507368803, 0.09853031486272812, -0.023321211338043213, 0.01606951840221882, -0.04743609204888344, 0.005866984371095896, -0.11254905164241791, -0.040049802511930466, 0.1131129041314125, 0.01177147962152958, -0.04025111347436905, -0.006801918148994446, -0.1837478131055832, -0.04287061095237732, -0.026466282084584236, -0.05086313188076019, 0.06636393070220947, 0.05730447173118591, -0.04717148095369339, -0.14934846758842468, 0.00725126639008522, -0.05702254921197891, 0.01268084067851305, 0.07047981768846512, 0.07064444571733475, 0.03783373162150383, 0.15048161149024963, 0.047415606677532196, 0.00033622965565882623, -0.005553325638175011, -0.035763707011938095, -0.07273628562688828, 0.11352381855249405, -0.03824090212583542, 0.12912553548812866, 0.07350508868694305, 0.04646063596010208, 0.012008942663669586, -0.04940607026219368, 0.07484013587236404, -0.002760780043900013, 0.13207735121250153, -0.03818199783563614, 0.14225715398788452, -0.09739507734775543, 0.003206636058166623, -0.1066441461443901, 0.11062069237232208, -0.02073543705046177, -0.13530848920345306, -0.07528051733970642, -0.13894030451774597, -0.08563167601823807, 0.11071187257766724, -0.0694190263748169, -0.08837267756462097, -0.0038688702043145895, -0.17211465537548065, 0.05468009039759636, 0.03602210059762001, 0.030178025364875793, -0.08945951610803604, -1.4359148386713956e-32, -0.1327335089445114, 0.06334157288074493, 0.03758716210722923, 0.025997372344136238, -0.05194128304719925, -0.09020113945007324, 0.07735560089349747, -0.11084006726741791, 0.013505063019692898, -0.11542292684316635, -0.04935538396239281, -0.0546271950006485, -0.04963904246687889, -0.030096299946308136, -0.014822442084550858, -0.02500271238386631, -0.0058708395808935165, -0.025828523561358452, -0.027429800480604172, 0.041290272027254105, -0.01733524724841118, 0.10621418803930283, -0.03226672112941742, 0.08053014427423477, -0.12013960629701614, 0.12523889541625977, -0.0741494670510292, 0.04946405813097954, -0.07841814309358597, -0.15231703221797943, -0.06817261874675751, 0.02743430621922016, 0.0158808846026659, 0.009975295513868332, 0.03257809579372406, -0.10643447190523148, 0.04537027329206467, -0.06875146180391312, 0.0072569758631289005, 0.06900642812252045, 0.1591547280550003, 0.09772142022848129, -0.1309843361377716, 0.025666624307632446, 0.0014252490364015102, -0.09416065365076065, 0.018260613083839417, -0.015327876433730125, 0.1373448222875595, -0.041438691318035126, -0.02654077671468258, 0.010285678319633007, -0.11761163920164108, 0.10414844751358032, -0.04695642367005348, 0.019692275673151016, -0.19229331612586975, -0.08350125700235367, 0.028443116694688797, 0.041306789964437485, -0.1063038557767868, 0.044726040214300156, -0.04883185029029846, 0.03741418197751045, 0.08600812405347824, 0.05373695120215416, -0.0320008285343647, 0.09093289077281952, 0.07507120072841644, 0.13719964027404785, -0.01430482231080532, 0.09351427108049393, -0.0015263344394043088, -0.13545005023479462, 0.004819563589990139, 0.003417412983253598, -0.10260818898677826, 0.02684033289551735, 0.012396973557770252, 0.008431041613221169, -0.07623818516731262, 0.033403050154447556, -0.021395262330770493, 0.04267273470759392, -0.12883958220481873, -0.017605707049369812, 0.0688144639134407, 0.18215836584568024, -0.001997267594560981, 0.007169831544160843, -0.0014612543163821101, 0.14080765843391418, 0.05446397513151169, 0.006407023873180151, 0.042140595614910126, -1.006604932740629e-07, -0.12494004517793655, -0.01335738506168127, 0.059108223766088486, 0.05374540388584137, 0.10130137950181961, -0.06881918758153915, -0.11771874129772186, 0.047719940543174744, -0.07980993390083313, -0.09490183740854263, 0.11265977472066879, 0.028594765812158585, -0.2680489420890808, -0.10271993279457092, 0.008269933052361012, 0.057256877422332764, 0.011416438035666943, 0.13408921658992767, -0.018960850313305855, -0.017439639195799828, 0.0739131048321724, -0.07348925620317459, 0.0468832403421402, 0.03850864991545677, -0.04705912992358208, -0.02247382327914238, -0.031520552933216095, 0.12317939847707748, 0.005153144709765911, 0.11463652551174164, 0.0199809018522501, -0.051106419414281845, 0.09018050134181976, 0.005272009409964085, 0.144249826669693, 0.056064385920763016, 0.030932322144508362, 0.02069617249071598, 0.05331253632903099, -0.008133863098919392, -0.10284913331270218, 0.02084256149828434, -0.08254268020391464, -0.0006743628764525056, 0.05875487998127937, -0.08880098909139633, 0.05735651031136513, -0.07250261306762695, 0.06697675585746765, -0.05066155642271042, 0.03243822231888771, 0.10025463998317719, -0.08459837734699249, 0.0968480259180069, 0.008979675360023975, 0.02098986506462097, -0.1243181973695755, -0.05547144636511803, -0.17532552778720856, -0.038950394839048386, 0.10809523612260818, 0.013272857293486595, -0.09310895949602127, 0.07877230644226074], metadata={'source': 'AAAMLP-569to.pdf', 'page': 37}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 38 In [X]: precision(l1, l2) Out[X]: 0.6666666666666666 ═════════════════════════════════════════════════════════════════════════  This seems fine.  Next, we come to recall. Recall is defined as:  Recall = TP / (TP + FN)  In the above case recall is 8 / (8 + 2) = 0.80. This means our model identified 80% of positive samples correctly.   ═════════════════════════════════════════════════════════════════════════ def recall(y_true, y_pred):     \"\"\"     Function to calculate recall     :param y_true: list of true values     :param y_pred: list of predicted values     :return: recall score     \"\"\"     tp = true_positive(y_true, y_pred)     fn = false_negative(y_true, y_pred)     recall = tp / (tp + fn)     return recall ═════════════════════════════════════════════════════════════════════════  In the case of our two small lists, we should have a recall of 0.5. Let’s check.  ═════════════════════════════════════════════════════════════════════════ In [X]: l1 = [0,1,1,1,0,0,0,1]    ...: l2 = [0,1,0,1,0,1,0,0]  In [X]: recall(l1, l2) Out[X]: 0.5 ═════════════════════════════════════════════════════════════════════════  And that matches our calculated value!  For a “good” model, our precision and recall values should be high. We see that in the above example, the recall value is quite high. However, precision is very low! Our model produces quite a lot of false positives but less false negatives. Fewer false negatives are good in this type of problem because you don’t want to say that'),\n",
       " VectorParams(vector=[-0.035610705614089966, -0.08126318454742432, -0.07736124098300934, 0.03764818608760834, 0.04271942749619484, -0.07672528177499771, 0.015435226261615753, 0.1355389952659607, 0.10389337688684464, 0.017039958387613297, 0.02113395929336548, -0.007506325840950012, 0.012300526723265648, 0.005371854640543461, -0.03984502702951431, -0.02570803463459015, -0.014099746942520142, -0.05528615042567253, -0.08592172712087631, -0.0033911564387381077, 0.08642041683197021, 0.043423108756542206, 0.08278099447488785, 0.050106726586818695, -0.06902472674846649, -0.09637337923049927, 0.08752003312110901, 0.04874410480260849, -0.10924805700778961, -0.027857840061187744, 0.051592402160167694, 0.011369198560714722, 0.037488289177417755, -0.02630368247628212, -0.07237286865711212, 0.018784213811159134, -0.06446538865566254, 0.03358911722898483, 0.05387876182794571, -0.00979865062981844, -0.010866420343518257, 0.02803104743361473, -0.023453034460544586, 0.036928318440914154, 0.09092502295970917, 0.034247249364852905, -0.09631772339344025, 0.023531828075647354, -0.09562896192073822, 0.01513090543448925, -0.10405533760786057, 0.028303243219852448, -0.09978117793798447, 0.008713694289326668, -0.03490017354488373, -0.018976060673594475, 0.07008960843086243, -0.09766372293233871, -0.03006020374596119, -0.044648606330156326, -0.1044197678565979, -0.08822803944349289, -0.04041207581758499, -0.04832115396857262, 0.05959390848875046, 0.028289716690778732, -0.006956491153687239, -0.024730827659368515, 0.07281678915023804, 0.07186351716518402, 0.003971097990870476, 0.048327915370464325, -0.036033470183610916, -0.01389554888010025, -0.014872454106807709, -0.0034635872580111027, 0.0011839838698506355, 0.004194623325020075, -0.053778570145368576, 0.008846662007272243, 0.03243090957403183, 0.02775605395436287, 0.05050884932279587, 0.02322450280189514, 0.08947821706533432, -0.1331152319908142, 0.047218285501003265, 0.031417254358530045, 0.08318231999874115, -0.00671768095344305, -0.01234481856226921, -0.06744196265935898, -0.08009258657693863, 0.035268429666757584, 0.0376860611140728, 0.13987010717391968, 0.02506573684513569, -0.07876931130886078, -0.008411400020122528, -0.0004920382052659988, -0.03281089663505554, -0.04049542546272278, -0.014828244224190712, -0.06610030680894852, 0.10364995896816254, -0.027700137346982956, 0.07063142955303192, -0.034198593348264694, 0.05596616491675377, -0.11511857807636261, 0.04680390655994415, -0.037317171692848206, 0.02409745380282402, 0.10542230308055878, 0.03948512673377991, 0.005777161568403244, -0.03141547739505768, 0.08767066895961761, -0.10799729079008102, 0.08450651913881302, -0.08105339109897614, 0.007857159711420536, 0.08146677166223526, 0.08821652829647064, -0.05753476917743683, -0.0513773113489151, -0.09778603166341782, 5.2673571252560534e-34, -0.02098369225859642, -0.07310876250267029, -0.04812471941113472, -0.2412301003932953, 0.022491320967674255, 0.002684107981622219, -0.10562214255332947, -0.050933629274368286, 0.051916345953941345, -0.03460562229156494, -0.05441685765981674, -0.058190830051898956, -0.0022002095356583595, 0.05143246054649353, 0.02267581783235073, -0.02319198101758957, -0.06934398412704468, 0.040694162249565125, -0.11539462953805923, -0.0014309047255665064, 0.025983579456806183, -0.042848579585552216, 0.04850452393293381, -0.04331245645880699, 0.010190106928348541, 0.1106431782245636, -0.0951843410730362, 0.13478681445121765, -0.10022596269845963, 0.003151191398501396, -0.06659907102584839, 0.20908847451210022, 0.015330912545323372, -0.16510358452796936, 0.05089261755347252, -0.022881649434566498, 0.05356402322649956, 0.016904965043067932, 0.06287520378828049, 0.01102827675640583, -0.025576479732990265, -0.01234443485736847, 0.08101840317249298, -0.04323916137218475, -0.03346039354801178, -0.12213507294654846, -0.0965518057346344, 0.06084020808339119, -0.11954560875892639, 0.013200975954532623, -0.01999334990978241, -0.1506386697292328, -0.07143904268741608, -0.02705841138958931, -0.08067597448825836, 0.07958902418613434, 0.029583154246211052, -0.010131727904081345, 0.0015885857865214348, 0.14166077971458435, 0.11782535910606384, -0.053832001984119415, -0.029705218970775604, 0.02300211600959301, 0.002757033333182335, 0.10563559830188751, 0.012936965562403202, 0.025062289088964462, 0.05421651154756546, 0.1027442142367363, -0.029938098043203354, 0.09087686985731125, 0.04401218891143799, -0.028624560683965683, -0.016443483531475067, 0.01645367406308651, 0.11798197031021118, 0.06971956044435501, -0.00972029659897089, -0.007927882485091686, -0.02837521769106388, 0.02759454771876335, -0.15666744112968445, -0.11061769723892212, 0.020610462874174118, 0.01101765502244234, 0.11330566555261612, -0.03412671387195587, -0.24339240789413452, -0.015921179205179214, -0.09528125077486038, 0.05975749343633652, -0.003505448345094919, 0.08124326169490814, -0.08734597265720367, -3.9552710655521854e-33, -0.08551494777202606, 0.17622242867946625, 0.07091139256954193, 0.08287191390991211, 0.06404805928468704, -0.026259876787662506, -0.021907296031713486, -0.0997597873210907, -0.022302702069282532, -0.01682625524699688, -0.06651727855205536, -0.07330428808927536, -0.030393213033676147, 0.04401741921901703, 0.054219283163547516, 0.05054207146167755, -0.0028681308031082153, -0.04584743082523346, -0.10615438967943192, -0.050209566950798035, 0.09310640394687653, 0.08904600143432617, -0.11674557626247406, 0.047912806272506714, -0.07275772839784622, 0.07824966311454773, 0.020242413505911827, 0.06363489478826523, -0.10538007318973541, -0.12019002437591553, -0.19142784178256989, -0.006901595275849104, -0.11055687069892883, -0.055648885667324066, 0.010048615746200085, 0.025075018405914307, 0.06973764300346375, -0.07803018391132355, -0.025852862745523453, -0.0028805534821003675, 0.07204107195138931, 0.046104203909635544, -0.2528526782989502, -0.04467475414276123, -0.023311330005526543, -0.0574137344956398, 0.08695296943187714, 0.14983899891376495, 0.0872117131948471, -0.07934695482254028, 0.010787772946059704, 0.08634833991527557, -0.029521316289901733, 0.1343514323234558, -0.06804700940847397, 0.011012928560376167, -0.12940528988838196, -0.12057242542505264, -0.030827943235635757, -0.014800911769270897, -0.09092649817466736, 0.028965074568986893, -0.004212664440274239, 0.08517415821552277, 0.08113831281661987, 0.08843803405761719, 0.02772998996078968, -0.0034485911019146442, 0.017780622467398643, 0.10778655856847763, 0.0021007286850363016, 0.08268081396818161, 0.0374644510447979, -0.1299617886543274, -0.017052272334694862, -0.09183558821678162, -0.13063399493694305, -0.015654519200325012, -0.03977786377072334, -0.004509712569415569, -0.06757277250289917, -0.06140094995498657, 0.051824480295181274, 0.11985114216804504, -0.05384748429059982, 0.02218833565711975, 0.052888352423906326, 0.09339205920696259, 0.07271096110343933, 0.003512316383421421, -0.05338826775550842, 0.04460760951042175, 0.024180710315704346, 0.02473689615726471, -0.10612139105796814, -9.999227756907203e-08, -0.051028698682785034, 0.0003255363553762436, 0.031694866716861725, 0.0299699567258358, 0.20619934797286987, 0.0605931282043457, -0.1296502947807312, 0.11771781742572784, -0.11402525752782822, -0.032345984131097794, 0.14702358841896057, 0.019080592319369316, -0.06437195837497711, -0.06298764050006866, 0.02025403268635273, 0.08256553113460541, 0.005350199528038502, 0.15960747003555298, -0.00806761160492897, 0.0001620459370315075, 0.0643264576792717, -0.07961951941251755, -0.005167751107364893, -0.010738453827798367, 0.03400785103440285, -0.03795945271849632, -0.02951023355126381, 0.13487982749938965, -0.056916043162345886, 0.13868749141693115, -0.03610828518867493, -0.11468373239040375, 0.09049536287784576, 0.0446702316403389, 0.11801667511463165, 0.01978025771677494, 0.1046854630112648, 0.03559960424900055, 0.03327102214097977, 0.06405803561210632, -0.00732494005933404, 0.05205845087766647, 0.03491590917110443, 0.10886794328689575, 0.03843217343091965, -0.026931846514344215, -0.005719962064176798, 0.023918790742754936, 0.12666012346744537, -0.06864096224308014, 0.02159486711025238, 0.04648814722895622, -0.02546371892094612, 0.08247926831245422, -0.0239737369120121, 0.045627299696207047, -0.06699502468109131, -0.04998699575662613, -0.18515422940254211, 0.023901525884866714, 0.11327388137578964, -0.006731441710144281, -0.023997271433472633, 0.03635132685303688], metadata={'source': 'AAAMLP-569to.pdf', 'page': 38}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 39 patients do not have pneumothorax when they do. That is going to be more harmful. But we do have a lot of false positives, and that’s not good either.  Most of the models predict a probability, and when we predict, we usually choose this threshold to be 0.5. This threshold is not always ideal, and depending on this threshold, your value of precision and recall can change drastically. If for every threshold we choose, we calculate the precision and recall values, we can create a plot between these sets of values. This plot or curve is known as the precision-recall curve.   Before looking into the precision-recall curve, let’s assume two lists.  ═════════════════════════════════════════════════════════════════════════ In [X]: y_true = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0,    ...:           1, 0, 0, 0, 0, 0, 0, 0, 1, 0]  In [X]: y_pred = [0.02638412, 0.11114267, 0.31620708,    ...:           0.0490937,  0.0191491,  0.17554844,    ...:           0.15952202, 0.03819563, 0.11639273,    ...:           0.079377,   0.08584789, 0.39095342,    ...:           0.27259048, 0.03447096, 0.04644807,    ...:           0.03543574, 0.18521942, 0.05934905,    ...:           0.61977213, 0.33056815] ═════════════════════════════════════════════════════════════════════════  So, y_true is our targets, and y_pred is the probability values for a sample being assigned a value of 1. So, now, we look at probabilities in prediction instead of the predicted value (which is most of the time calculated with a threshold at 0.5).  ═════════════════════════════════════════════════════════════════════════ precisions = [] recalls = [] # how we assumed these thresholds is a long story thresholds = [0.0490937 , 0.05934905, 0.079377,                0.08584789, 0.11114267, 0.11639273,                0.15952202, 0.17554844, 0.18521942,                0.27259048, 0.31620708, 0.33056815,                0.39095342, 0.61977213]  # for every threshold, calculate predictions in binary # and append calculated precisions and recalls # to their respective lists for i in thresholds:     temp_prediction = [1 if x >= i else 0 for x in y_pred]'),\n",
       " VectorParams(vector=[-0.08290651440620422, -0.14669087529182434, -0.12660495936870575, 0.05359135940670967, 0.04663480445742607, -0.027204295620322227, -0.09088843315839767, 0.24634408950805664, 0.022642832249403, -0.07167027145624161, 0.0991930440068245, 0.0194802675396204, -0.013233771547675133, -0.029100529849529266, 0.01614970713853836, -0.06419701129198074, -0.06879739463329315, -0.07823798060417175, -0.027673877775669098, -0.1145855188369751, 0.13934718072414398, -0.02773100510239601, 0.23293744027614594, 0.17175798118114471, 0.03341235592961311, -0.09167040884494781, 0.06674913316965103, 0.19488224387168884, -0.0165341068059206, -0.11125312000513077, -0.0006477367132902145, 0.10964939743280411, -0.08909095823764801, 0.0038404203951358795, -0.014409742318093777, 0.03765667602419853, -0.13061967492103577, 0.03179650753736496, 0.14099273085594177, -0.0439506359398365, 0.031183045357465744, -0.05081132799386978, 0.030235085636377335, 0.13735179603099823, 0.06236789748072624, 0.0407734178006649, -0.09265034645795822, -0.046895671635866165, -0.03157806396484375, 0.08048263192176819, -0.04154052585363388, 0.08913330733776093, -0.1482447385787964, -0.004051238764077425, -0.052580203860998154, 0.04163845628499985, 0.06049541011452675, -0.0814177393913269, -0.006648304406553507, -0.0723031759262085, -0.12476641684770584, -0.12832973897457123, -0.07843746244907379, -0.014752482064068317, -0.14937713742256165, -0.0010728435590863228, 0.06649196147918701, -0.05751009285449982, 0.07750916481018066, 0.08793814480304718, 0.002404603408649564, 0.11005668342113495, -0.041804078966379166, -0.03742991015315056, -0.06034882739186287, 0.005015874281525612, -0.0021543274633586407, 0.023257652297616005, -0.06028344854712486, 0.04259059205651283, -0.009878765791654587, -0.03702376410365105, 0.04970481991767883, 0.1486693173646927, 0.10431467741727829, -0.13973493874073029, 0.15524548292160034, -0.038200460374355316, 0.06684435158967972, -0.025362927466630936, 0.08377637714147568, -0.05389484390616417, -0.03983833268284798, 0.02254004031419754, -0.1060509979724884, 0.14587394893169403, 0.13808339834213257, 0.005857309326529503, -0.13774915039539337, -0.0019581846427172422, 0.09852800518274307, 0.007936360314488411, 0.032419316470623016, -0.03929422050714493, 0.029636166989803314, -0.048687148839235306, 0.07386596500873566, 0.03502326086163521, 0.22271692752838135, -0.07649998366832733, 0.03565109893679619, -0.12311623990535736, -0.06598386913537979, 0.18754073977470398, 0.15018603205680847, 0.10682685673236847, -0.22377073764801025, -0.03601151332259178, -0.16484332084655762, 0.1522735357284546, -0.14749372005462646, 0.05513719096779823, 0.07916227728128433, 0.06207087263464928, -0.035927753895521164, -0.02005564235150814, -0.14546042680740356, 7.108159972808647e-33, -0.05302603170275688, 0.09635265171527863, -0.02039152942597866, -0.18165123462677002, 0.020463349297642708, -0.019292326644062996, -0.34676069021224976, -0.015429824590682983, -0.06183648481965065, -0.03780197724699974, -0.025385776534676552, 0.03395680710673332, -0.014510267414152622, 0.06969106942415237, -0.010739315301179886, -0.05508536100387573, -0.09799950569868088, 0.1367930769920349, -0.10393135994672775, 0.09140235185623169, -0.027772778645157814, 0.027195651084184647, 0.14347995817661285, -0.10445736348628998, -0.05250196158885956, 0.10814842581748962, -0.02746170200407505, 0.24926796555519104, -0.06964769214391708, 0.03081681579351425, -0.1368539035320282, 0.11469592899084091, 0.04464154317975044, -0.060271717607975006, 0.12265164405107498, -0.07744929194450378, 0.1369892954826355, -0.09880136698484421, -0.009171375073492527, 0.0034000601153820753, 0.033830609172582626, 0.019226841628551483, 0.133584126830101, -0.08792579919099808, -0.01932191476225853, -0.10621640086174011, -0.03494713455438614, 0.10473545640707016, 0.021293316036462784, 0.11319679766893387, -0.07374246418476105, 0.0180829931050539, -0.08552690595388412, 0.0570250041782856, -0.0177366454154253, 0.07410036027431488, 0.017935331910848618, -0.03894893079996109, 0.03488544002175331, 0.03876008093357086, 0.20335960388183594, -0.022283917292952538, 0.022818023338913918, -0.023463193327188492, -0.06931934505701065, 0.17763683199882507, -0.00782505702227354, 0.11404173076152802, -0.004711287561804056, 0.19515611231327057, 0.00405733659863472, 0.03346683084964752, -0.0715537741780281, -0.00914163701236248, 0.05178183317184448, -0.024099046364426613, 0.15280750393867493, 0.06062626093626022, 0.002526054158806801, -0.05736146122217178, -0.03780301287770271, -0.12782835960388184, -0.052865590900182724, -0.22907207906246185, -0.12751978635787964, -0.09512188285589218, 0.2085927575826645, -0.035832349210977554, -0.06898114085197449, 0.001874278299510479, -0.06687178462743759, 0.008833231404423714, -0.008379284292459488, 0.08639281988143921, -0.24622493982315063, -9.977836291437526e-33, -0.13985151052474976, 0.17234928905963898, 0.03724804148077965, 0.1200004518032074, -0.0645064041018486, -0.01373401377350092, 0.032603830099105835, 0.05802106484770775, -0.009996402077376842, -0.18605998158454895, 0.03805312141776085, -0.10142779350280762, -0.09077072888612747, -0.059555888175964355, 0.11479880660772324, 0.05118873342871666, -0.08246399462223053, -0.026672180742025375, -0.15414707362651825, -0.14608308672904968, 0.07023494690656662, -0.04908664897084236, -0.0322885662317276, 0.025477634742856026, -0.09685772657394409, 0.1711149960756302, -0.10576104372739792, -0.12670904397964478, -0.14679649472236633, -0.16494043171405792, -0.12345600873231888, -0.008712352253496647, 0.006290845572948456, 0.026149284094572067, 0.025378001853823662, -0.01671203412115574, 0.16447563469409943, -0.13525280356407166, -0.016055943444371223, 0.03961406275629997, 0.22052380442619324, 0.07424980401992798, -0.15600737929344177, 0.024583546444773674, -0.06514056771993637, 0.01542944461107254, -0.06972622871398926, 0.11591678857803345, 0.18734392523765564, 0.03517850115895271, 0.011854581534862518, 0.08128892630338669, -0.02224535308778286, 0.009943927638232708, -0.09988393634557724, 0.019182242453098297, -0.1800450086593628, -0.07102943956851959, -0.115044005215168, -0.023695243522524834, -0.14193370938301086, -0.0026027208659797907, -0.10464436560869217, -0.04624910280108452, 0.08723676949739456, 0.006859146989881992, 0.015490071848034859, -0.0766717940568924, 0.020388076081871986, 0.15529373288154602, 0.1116219311952591, 0.07282604277133942, -0.1548275351524353, -0.1825994998216629, -0.00022531520517077297, -0.05230525881052017, -0.12989015877246857, 0.08771979063749313, -0.07953054457902908, -0.0396740548312664, 0.06013192981481552, 0.03909317031502724, 0.10834628343582153, 0.09878215193748474, -0.1230846419930458, -0.0015060437144711614, 0.039848003536462784, 0.12122759222984314, 0.017574016004800797, 0.03696320950984955, -0.04577961936593056, 0.161042258143425, -0.02084898203611374, 0.17132236063480377, 0.08563963323831558, -9.949992119118178e-08, -0.09178091585636139, 0.018912848085165024, -0.03412436693906784, 0.10578503459692001, 0.17581266164779663, -0.05148148909211159, -0.15979553759098053, 0.181911438703537, -0.11471565812826157, -0.0032357654999941587, 0.10161197930574417, -0.001618148759007454, -0.24352531135082245, -0.10614535957574844, 0.03453250601887703, 0.05021597817540169, 0.02301153540611267, 0.176914244890213, -0.010990547947585583, -0.06547512114048004, -0.08354528248310089, -0.12225364148616791, 0.12967121601104736, 0.04806506633758545, -0.09343066811561584, 0.031148001551628113, -0.10837774723768234, 0.31270864605903625, -0.0652274489402771, 0.1711241453886032, -0.007836014032363892, -0.1649114340543747, 0.14157672226428986, -0.015090445056557655, 0.07008399069309235, -0.03929002583026886, -0.0010620593093335629, 0.08862121403217316, 0.1943514496088028, 0.09118573367595673, -0.13930296897888184, -0.06640074402093887, -0.0718710795044899, 0.10215342044830322, 0.11259811371564865, -0.10387859493494034, 0.04088738188147545, -0.08743780106306076, 0.04429458826780319, 0.028618918731808662, -0.06435464322566986, 0.171883225440979, -0.051382001489400864, 0.08235275000333786, 0.0045632063411176205, 0.020111164078116417, -0.16249659657478333, -0.02394978143274784, -0.19066675007343292, 0.054518867284059525, 0.10387781262397766, -0.021065013483166695, -0.03809259459376335, -0.005771797150373459], metadata={'source': 'AAAMLP-569to.pdf', 'page': 39}, content=\"Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 40     p = precision(y_true, temp_prediction)     r = recall(y_true, temp_prediction)     precisions.append(p)     recalls.append(r) ═════════════════════════════════════════════════════════════════════════  Now, we can plot these values of precisions and recalls.  ═════════════════════════════════════════════════════════════════════════ plt.figure(figsize=(7, 7)) plt.plot(recalls, precisions) plt.xlabel('Recall', fontsize=15) plt.ylabel('Precision', fontsize=15) ═════════════════════════════════════════════════════════════════════════  Figure 2 shows the precision-recall curve we get this way. \\n Figure 2: precision-recall curve  This precision-recall curve looks very different from what you might have seen on the internet. It’s because we had only 20 samples, and only 3 of them were positive samples. But there’s nothing to worry. It’s the same old precision-recall curve.\"),\n",
       " VectorParams(vector=[-0.025112954899668694, -0.03409896418452263, -0.13545285165309906, 0.010767636820673943, 0.09250228852033615, -0.045746687799692154, -0.08509884774684906, 0.17777703702449799, -0.01364764105528593, -0.012437721714377403, -0.05496757850050926, -0.03959168493747711, 0.006316791754215956, 0.07972805947065353, 0.04504493623971939, -0.03797391057014465, 0.04001167416572571, 0.08243975788354874, 0.003993925638496876, -0.00722610205411911, 0.12295341491699219, -0.019194522872567177, 0.143633171916008, 0.10935280472040176, -0.024218598380684853, -0.1621115356683731, -0.019207237288355827, 0.06958229094743729, -0.13145491480827332, -0.06798668205738068, 0.07481647282838821, 0.07642266899347305, 0.0315418615937233, 0.012494605034589767, -0.1672925055027008, 0.04967128485441208, -0.06524499505758286, 0.05710333213210106, 0.05980798602104187, -0.059834711253643036, -0.1545886993408203, -0.018629824742674828, -0.011098246090114117, 0.01473078690469265, 0.14540374279022217, 0.044751204550266266, -0.03347349166870117, 0.008864208124577999, 0.03349807858467102, -0.019226182252168655, -0.06347807496786118, 0.27319902181625366, -0.14406435191631317, -0.012295955792069435, 0.010160897858440876, 0.03248848021030426, 0.12536028027534485, -0.09336132556200027, -0.08107497543096542, -0.09994540363550186, -0.04575837403535843, -0.19425925612449646, -0.032256729900836945, -0.08575496077537537, 0.022635111585259438, -0.015053539536893368, -0.05470890551805496, -0.049512237310409546, 0.07683826237916946, 0.13288892805576324, -8.172579691745341e-05, 0.1263720542192459, 0.01231289654970169, -0.005827599670737982, 0.01906256377696991, -0.05748128518462181, 0.04532499983906746, 0.0703553855419159, -0.045217644423246384, 0.15210771560668945, 0.08649565279483795, 0.020318705588579178, -0.03549228608608246, -0.03256489709019661, 0.1229495033621788, -0.1727956086397171, 0.06960484385490417, 0.033644065260887146, 0.05047663673758507, 0.07779546827077866, 0.13225030899047852, -0.044942326843738556, 0.01734279654920101, -0.040312089025974274, 0.02937162294983864, 0.06649516522884369, 0.0024708732962608337, -0.14237231016159058, -0.033468738198280334, 0.07612106949090958, -0.04105522111058235, 0.038248032331466675, -0.12607023119926453, -0.2093663513660431, 0.11664319038391113, -0.003116062842309475, 0.0099551472812891, 0.02285793423652649, 0.19463269412517548, -0.15792307257652283, 0.033935707062482834, -0.08378761261701584, -0.06545975804328918, 0.0407283678650856, 0.029005883261561394, 0.14387251436710358, 0.007987569086253643, 0.10844111442565918, -0.005173996090888977, 0.12463495135307312, -0.09382349997758865, 0.03219831362366676, 0.03804268315434456, 0.1388482302427292, 0.03107997588813305, -0.043777208775281906, -0.19335246086120605, 9.581555839940224e-33, -0.12590236961841583, 0.07427740097045898, -0.0011747876415029168, -0.11847247183322906, 0.004732151981443167, -0.02371951751410961, -0.06226282939314842, 0.025391314178705215, -0.06919363141059875, 0.048860859125852585, -0.047389205545186996, -0.021068332716822624, -0.04517313092947006, -0.016177328303456306, 0.11893170326948166, -0.11305789649486542, -0.13723571598529816, -0.04480591043829918, -0.050812479108572006, -0.036754265427589417, 0.05537046119570732, -0.051439665257930756, 0.1572263538837433, -0.06322479993104935, 0.042090289294719696, -0.007422757800668478, -0.04064950719475746, 0.012917213141918182, -0.10117806494235992, -0.00528178783133626, -0.15245597064495087, 0.012612750753760338, 0.05750366300344467, -0.013545542024075985, 0.10101114958524704, -0.11059844493865967, -0.015306568704545498, -0.06657686084508896, 0.0013399386079981923, -0.04863768443465233, -0.13032038509845734, 0.022094840183854103, 0.010145076550543308, -0.04857359081506729, -0.04442369565367699, -0.1426321268081665, -0.024573085829615593, 0.05947200581431389, -0.06760259717702866, 0.1783224195241928, -0.047565218061208725, -0.1068868637084961, -0.05804206803441048, 0.036296214908361435, -0.07096081227064133, 0.035627201199531555, 0.05657864734530449, -0.0101174246519804, 0.04327671602368355, 0.06517985463142395, 0.08341390639543533, -0.017237531021237373, 0.04264851659536362, -0.010662890039384365, -0.10586640983819962, 0.15119914710521698, 0.04833957552909851, 0.10538644343614578, 0.03995857015252113, 0.1102399155497551, 0.04799722880125046, 0.061163853853940964, -0.012090503238141537, -0.10232533514499664, 0.10196467489004135, 0.004016440361738205, 0.1863018125295639, -0.11449097841978073, -0.005020588170737028, -0.024353057146072388, 0.021357908844947815, 0.0406232587993145, -0.0740971639752388, -0.12884016335010529, -0.05236242339015007, 0.031152354553341866, 0.0674683228135109, -0.012320186011493206, -0.09665708988904953, -0.060442693531513214, -0.18325656652450562, 0.006734990049153566, 0.017460498958826065, 0.06242503970861435, -0.0689195990562439, -1.0366135136292744e-32, -0.08757907897233963, 0.04110429435968399, -0.011446037329733372, 0.11201085150241852, -0.03129128739237785, -0.028283828869462013, -0.039756275713443756, -0.0836341381072998, -0.03077719733119011, -0.05786287039518356, 0.005666911136358976, -0.02420399896800518, -8.719346806174144e-05, 0.04741077125072479, 0.014972180128097534, -0.005481555126607418, -0.07955099642276764, 0.07157748937606812, -0.12001875042915344, 0.08024270832538605, -0.0128405736759305, 0.11932465434074402, -0.03366396576166153, 0.032954562455415726, -0.132516011595726, 0.06500446796417236, 0.01790561154484749, 0.04452231898903847, -0.058925166726112366, -0.10976337641477585, -0.06787920743227005, 0.08414866030216217, -0.049976758658885956, 0.025772960856556892, 0.07925146073102951, -0.03727918118238449, 0.09498000144958496, -0.08820569515228271, -0.01675369217991829, 0.15113453567028046, 0.1464218944311142, 0.165452241897583, -0.1072922945022583, -0.04487202316522598, 0.003205591347068548, -0.0288622435182333, -0.03671326860785484, 0.07105059176683426, 0.149034783244133, 0.03719596192240715, 0.0021462575532495975, 0.020434314385056496, -0.07517822086811066, 0.15066727995872498, -0.09117093682289124, -0.028142254799604416, -0.16979952156543732, -0.0897863358259201, -0.08859913796186447, 0.10184671729803085, -0.13093653321266174, 0.024729179218411446, -0.04160881042480469, 0.11535654217004776, 0.031332604587078094, 0.02819870226085186, -0.04787806421518326, 0.10798373073339462, -0.01790863834321499, 0.17426666617393494, -0.011134874075651169, 0.08522014319896698, 0.049734048545360565, -0.05879497155547142, -0.04543650895357132, 0.010040742345154285, -0.056159164756536484, 0.10410993546247482, -0.07317005842924118, 0.02337506413459778, 0.0606531985104084, 0.05929642915725708, -0.027477938681840897, 0.08010407537221909, -0.07796596735715866, 0.018100226297974586, 0.059797365218400955, 0.13457772135734558, 0.022547269240021706, -0.040039658546447754, 0.00574761675670743, 0.17031970620155334, 0.08156664669513702, -0.03911653161048889, 0.003087585559114814, -9.988514193537412e-08, -0.043401408940553665, -0.07246196269989014, 0.09046870470046997, 0.0349808931350708, 0.15414927899837494, 0.013143965974450111, -0.10859683156013489, -0.05912251025438309, -0.16196493804454803, -0.044268783181905746, 0.07623185217380524, 0.04383544623851776, -0.1808711141347885, -0.13687942922115326, -0.04323593154549599, 0.08127985894680023, 0.09287140518426895, 0.13096459209918976, 0.0023885942064225674, -0.005397884640842676, 0.012334190309047699, -0.1165602058172226, 0.010219891555607319, -0.004328824579715729, -0.009004340507090092, -0.07112453877925873, -0.015957361087203026, 0.05389843508601189, 0.04562430456280708, 0.05105222761631012, -0.002832140540704131, -0.07683030515909195, 0.03995177149772644, 0.03217688575387001, 0.1012851819396019, 0.08579505234956741, 0.0029324907809495926, 0.0446615107357502, -0.0339319109916687, 0.035061314702034, -0.12224246561527252, 0.03473202884197235, -0.021868599578738213, -0.02799297496676445, 4.1236780816689134e-05, -0.026975568383932114, -0.022402483969926834, -0.040601808577775955, 0.02971229888498783, -0.08718244731426239, 0.05532767251133919, 0.14156918227672577, -0.13369430601596832, 0.06570129096508026, 0.03183923661708832, 0.08931057900190353, -0.20724791288375854, -0.051351018249988556, -0.21386313438415527, 0.05148773640394211, 0.08205568790435791, 0.03689304366707802, -0.012063436210155487, 0.022957121953368187], metadata={'source': 'AAAMLP-569to.pdf', 'page': 40}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 41 You will notice that it’s challenging to choose a value of threshold that gives both good precision and recall values. If the threshold is too high, you have a smaller number of true positives and a high number of false negatives. This decreases your recall; however, your precision score will be high. If you reduce the threshold too low, false positives will increase a lot, and precision will be less.  Both precision and recall range from 0 to 1 and a value closer to 1 is better.  F1 score is a metric that combines both precision and recall. It is defined as a simple weighted average (harmonic mean) of precision and recall. If we denote precision using P and recall using R, we can represent the F1 score as:  F1 = 2PR / (P + R)  A little bit of mathematics will lead you to the following equation of F1 based on TP, FP and FN  F1 = 2TP / (2TP + FP + FN)  A Python implementation is simple because we have already implemented these.  ═════════════════════════════════════════════════════════════════════════ def f1(y_true, y_pred):     \"\"\"     Function to calculate f1 score     :param y_true: list of true values     :param y_pred: list of predicted values     :return: f1 score     \"\"\"     p = precision(y_true, y_pred)     r = recall(y_true, y_pred)      score = 2 * p * r / (p + r)      return score ═════════════════════════════════════════════════════════════════════════  Let’s see the results of this and compare it with scikit-learn.  ═════════════════════════════════════════════════════════════════════════  In [X]: y_true = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0,    ...:           1, 0, 0, 0, 0, 0, 0, 0, 1, 0]'),\n",
       " VectorParams(vector=[-0.057016585022211075, -0.10242702066898346, -0.12548908591270447, 0.0002319566992809996, 0.09688399732112885, -0.03423326089978218, 0.005393857602030039, 0.1280549168586731, 0.02071157656610012, -0.0606357641518116, 0.07348150759935379, -0.06217372044920921, 0.020688001066446304, 0.03221679478883743, -0.027117498219013214, -0.08914298564195633, 0.01908964291214943, 0.016992144286632538, -0.0438041053712368, 0.020378941670060158, 0.07857339084148407, 0.08264750987291336, 0.07019194215536118, 0.15328192710876465, -0.03257759287953377, -0.18835675716400146, -0.016456834971904755, 0.0407395213842392, -0.18337920308113098, -0.027308054268360138, -0.03242760896682739, 0.11327682435512543, -0.047358669340610504, 0.0419108122587204, -0.059845201671123505, 0.05557048320770264, -0.04307239130139351, 0.049719661474227905, 0.061305005103349686, -0.02250121533870697, -0.06507181376218796, -0.08908451348543167, -0.024506328627467155, -0.020849887281656265, 0.11263109743595123, 0.05228200927376747, -0.017506755888462067, 0.008479050360620022, 0.003955637104809284, 0.034520551562309265, -0.08187831938266754, 0.20941542088985443, -0.11817910522222519, 0.0088801933452487, 0.04802507162094116, 0.05353063717484474, 0.07128506153821945, -0.09215933829545975, 0.023255547508597374, -0.04685366526246071, -0.05742213502526283, -0.1778123527765274, -0.05336831137537956, -0.08864224702119827, -0.02848517708480358, -0.03137849643826485, 0.0023417917545884848, -0.08043555915355682, 0.07407472282648087, 0.11590775102376938, -0.01073697954416275, 0.061830587685108185, 0.04453669860959053, 0.04205668345093727, 0.04469188675284386, -0.026476901024580002, 0.07386048883199692, 0.06153162568807602, -0.014358456246554852, 0.0520898699760437, 0.010102295316755772, 0.01770775206387043, -0.04724282771348953, 0.01186327449977398, 0.12044066935777664, -0.13670200109481812, 0.04664018005132675, 0.08416347205638885, 0.13224470615386963, 0.10309911519289017, 0.06595855951309204, -0.03159952908754349, -0.016290070489048958, -0.08426755666732788, 0.07069148123264313, 0.13509118556976318, 0.005326505750417709, -0.08985505998134613, -0.03610859811306, 0.036912672221660614, 0.02818181924521923, 0.03911159560084343, -0.036177411675453186, -0.045050330460071564, 0.09320656210184097, -0.01865123026072979, 0.037147749215364456, -0.0420246422290802, 0.13194817304611206, -0.08259480446577072, -0.002163294702768326, -0.04488656297326088, 0.006248088087886572, 0.05308028310537338, 0.04491795226931572, -0.037028707563877106, -0.06759655475616455, 0.06196649745106697, -0.02416592463850975, 0.06517253071069717, -0.0710543841123581, 0.030452260747551918, 0.0768023207783699, 0.12505558133125305, 0.03800027817487717, -0.018029389902949333, -0.13999995589256287, 1.3848814861144153e-32, -0.056171320378780365, 0.08147984743118286, -0.00870075449347496, -0.17142459750175476, -0.13353146612644196, -0.1279505491256714, -0.06955324113368988, 0.10508711636066437, -0.09738707542419434, 0.061092425137758255, -0.10061310231685638, 0.023048069328069687, -0.07759159058332443, -0.05308049917221069, 0.0074303108267486095, -0.027635561302304268, -0.14055582880973816, -0.00016336834232788533, -0.00873024482280016, 0.0353686586022377, 0.08001752942800522, 0.004543419927358627, 0.07130219042301178, -0.11631876975297928, 0.0074389055371284485, 0.03490446135401726, -0.10517745465040207, 0.018365871161222458, -0.1616850346326828, 0.027290213853120804, -0.10383661836385727, 0.04605228826403618, 0.04748356342315674, -0.04917727783322334, 0.08051957935094833, -0.10410481691360474, 0.004065398126840591, -0.02463327720761299, -0.04288511350750923, -0.03738981857895851, -0.054756760597229004, 0.12175677716732025, 0.009204812347888947, -0.06037763133645058, -0.04042875021696091, -0.07642480731010437, -0.006889851298183203, 0.05652540922164917, 0.02877444587647915, 0.13891710340976715, 0.012579498812556267, -0.1721739023923874, -0.09723813086748123, -0.0011557739926502109, -0.11510951071977615, 0.05014019459486008, 0.09325861185789108, -0.007804851047694683, 0.06626833230257034, 0.10245144367218018, -0.03905694931745529, -0.023981908336281776, 0.07161477953195572, -0.08919418603181839, -0.06338637322187424, 0.06974416971206665, -0.026039395481348038, 0.11313389986753464, 0.033675432205200195, 0.015168002806603909, 0.0011179250432178378, 0.03713309019804001, -0.03678832948207855, -0.040560245513916016, 0.10710085928440094, -0.06207624450325966, 0.13507232069969177, -0.119636669754982, -0.07664874941110611, 0.02806846797466278, 0.03598887845873833, 0.007470312993973494, -0.09440053999423981, -0.07804562151432037, -0.1329754739999771, -0.026844291016459465, 0.08386194705963135, -0.08117040991783142, -0.151293084025383, -0.11930253356695175, -0.14173570275306702, 0.01997469738125801, -0.03420396149158478, 0.02077113464474678, -0.1461562067270279, -1.3623823773028828e-32, -0.03233606368303299, 0.015456335619091988, 0.03315619379281998, 0.11075226217508316, -0.02859828807413578, 0.000733465189114213, -0.007598232943564653, -0.018393103033304214, 0.015224280767142773, -0.12115519493818283, -0.045793961733579636, -0.06201612949371338, -0.05097358301281929, 0.0016130099538713694, 0.007620340213179588, 0.02796236053109169, -0.09361781179904938, -0.018355490639805794, -0.1688670516014099, 0.039272382855415344, -0.0425904206931591, 0.09854670614004135, -0.1049775555729866, 0.01640184409916401, -0.08372261375188828, 0.09811562299728394, 0.005002750549465418, 0.10746604204177856, -0.07269401103258133, -0.05963091179728508, -0.005523386877030134, 0.03489072248339653, -0.009970015846192837, 0.03141818568110466, 0.10226023197174072, -0.07820173352956772, 0.05764658749103546, -0.052019309252500534, 0.034426767379045486, 0.0933615118265152, 0.16505110263824463, 0.25494474172592163, -0.15542641282081604, 0.020380154252052307, -0.012444722466170788, 0.04297628998756409, 0.0011895096395164728, 0.04946621134877205, 0.13392822444438934, 0.032092154026031494, 0.018494267016649246, 0.04946524277329445, -0.049856580793857574, 0.06313905119895935, -0.04969089478254318, 0.009671884588897228, -0.10905265808105469, -0.056579913944005966, -0.057719673961400986, 0.041405703872442245, -0.05877311900258064, 0.07554313540458679, 0.022869056090712547, 0.010137313045561314, 0.07817485183477402, 0.07275804132223129, -0.0602545291185379, 0.028641030192375183, -0.021321065723896027, 0.1286398470401764, -0.019987430423498154, 0.09281471371650696, -0.017660563811659813, -0.13599619269371033, -0.06863810122013092, -0.04869598522782326, -0.07105425000190735, 0.057959992438554764, -0.020759496837854385, 0.08337190002202988, 0.02818901091814041, 0.06904257833957672, 0.029168957844376564, 0.13607679307460785, -0.11325466632843018, 0.1275031715631485, 0.11479709297418594, 0.17370019853115082, 0.08804582804441452, -0.06404191255569458, -0.02160685881972313, 0.1221984401345253, 0.05366433039307594, 0.07291440665721893, -0.044037818908691406, -1.0013328477498362e-07, -0.07067462801933289, 0.032012589275836945, 0.05747897922992706, 0.12507733702659607, 0.045723963528871536, -0.009038638323545456, -0.1267654448747635, -0.020008059218525887, -0.06765595823526382, -0.06192522123456001, 0.05722903832793236, -0.01637963391840458, -0.23314394056797028, -0.11031105369329453, -0.003765718312934041, 0.03266015648841858, 0.06365340203046799, 0.11715629696846008, -0.06674037873744965, -0.0144781693816185, 0.0694030225276947, -0.02921678125858307, 0.003621214535087347, -0.0022558970376849174, -0.007080212235450745, -0.05227365344762802, -0.05863828584551811, 0.11515368521213531, 0.08651551604270935, 0.07711298018693924, -0.02065385691821575, -0.12143231183290482, 0.0801980122923851, 0.04627389460802078, 0.11737155169248581, 0.1030803769826889, -0.01212313212454319, 0.047053903341293335, 0.06617919355630875, 0.06981242448091507, -0.14479729533195496, -0.02455684170126915, -0.10205843299627304, -0.040418870747089386, -0.053023215383291245, 0.01704741083085537, -0.04494340717792511, -0.03561828285455704, 0.056295882910490036, -0.007396586239337921, 0.05326242372393608, 0.13472168147563934, -0.13467735052108765, 0.1311146318912506, 0.06438324600458145, 0.06297172605991364, -0.09328023344278336, -0.13173320889472961, -0.1394089013338089, 0.02375531941652298, 0.03949657082557678, 0.04814906790852547, -0.07488615065813065, 0.08502592146396637], metadata={'source': 'AAAMLP-569to.pdf', 'page': 41}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 42 In [X]: y_pred = [0, 0, 1, 0, 0, 0, 1, 0, 0, 0,    ...:           1, 0, 0, 0, 0, 0, 0, 0, 1, 0]  In [X]: f1(y_true, y_pred) Out[X]: 0.5714285714285715 ═════════════════════════════════════════════════════════════════════════  And from scikit learn for the same lists, we get:  ═════════════════════════════════════════════════════════════════════════ In [X]: from sklearn import metrics  In [X]: metrics.f1_score(y_true, y_pred) Out[X]: 0.5714285714285715 ═════════════════════════════════════════════════════════════════════════  Instead of looking at precision and recall individually, you can also just look at F1 score. Same as for precision, recall and accuracy, F1 score also ranges from 0 to 1, and a perfect prediction model has an F1 of 1. When dealing with datasets that have skewed targets, we should look at F1 (or precision and recall) instead of accuracy.  Then there are other crucial terms that we should know about.   The first one is TPR or True Positive Rate, which is the same as recall.  TPR = TP / (TP + FN)  Even though it is same as recall, we will make a python function for it for further use with this name.  ═════════════════════════════════════════════════════════════════════════ def tpr(y_true, y_pred):     \"\"\"     Function to calculate tpr     :param y_true: list of true values     :param y_pred: list of predicted values     :return: tpr/recall     \"\"\"     return recall(y_true, y_pred) ═════════════════════════════════════════════════════════════════════════  TPR or recall is also known as sensitivity.'),\n",
       " VectorParams(vector=[-0.020197605714201927, -0.04578357934951782, -0.08950302004814148, -0.003739879233762622, 0.1478617787361145, -0.06347543746232986, 0.05415403097867966, 0.12727034091949463, 0.11408223956823349, 0.11733907461166382, -0.03196519985795021, -0.19595013558864594, 0.025100618600845337, 0.07601334154605865, 0.008118253201246262, -0.06887070089578629, 0.005456314422190189, 0.016721505671739578, -0.06805308908224106, 0.01169147901237011, 0.020992282778024673, 0.0728086531162262, 0.019835317507386208, 0.023410575464367867, -0.03483553230762482, -0.19943159818649292, 0.00887834932655096, 0.08756415545940399, -0.09743484109640121, -0.0049441237933933735, -0.020083533599972725, 0.07646873593330383, 0.07586641609668732, -0.004979720339179039, -0.02795547805726528, 0.009816535748541355, -0.0808618888258934, -0.026675326749682426, 0.00388615601696074, 0.03642302751541138, -0.08856294304132462, -0.05601872131228447, -0.04260607808828354, -0.031922101974487305, 0.08808272331953049, 0.04076273739337921, 0.00047740270383656025, 0.04302232339978218, -0.047165751457214355, 0.0237116739153862, -0.038741227239370346, 0.23040100932121277, -0.13407476246356964, 0.033319294452667236, 0.013848772272467613, -0.06711377203464508, 0.05281075835227966, -0.18829098343849182, -0.07856537401676178, -0.06126595288515091, -0.08854599297046661, -0.14747753739356995, -0.13025982677936554, -0.0830935463309288, 0.09835810959339142, 0.0737057700753212, -0.11882031708955765, 0.013286078348755836, 0.06644655764102936, 0.12272609770298004, -0.07071200758218765, 0.049507204443216324, -0.015769436955451965, 0.07494517415761948, 0.0026653013192117214, 0.01959174871444702, 0.15283451974391937, 0.07389023154973984, 0.023108385503292084, 0.035438135266304016, 0.012629282660782337, 0.059516508132219315, 0.027171224355697632, -0.11435660719871521, 0.0839935839176178, -0.1277894526720047, -0.0024116449058055878, 0.0981525182723999, 0.18732701241970062, 0.070088230073452, -0.020714497193694115, -0.03414583578705788, -0.049817685037851334, -0.02825016714632511, 0.030808323994278908, 0.05594753101468086, -0.05614566057920456, -0.1714116632938385, 0.007259494159370661, 0.014941220171749592, -0.09406429529190063, -0.018254807218909264, 0.006901929620653391, -0.14799515902996063, 0.027884362265467644, -0.005678860004991293, 0.03308685123920441, 0.01205433253198862, 0.12189000844955444, -0.15367087721824646, -0.013203942216932774, 0.003211070317775011, 0.030835043638944626, -0.023400386795401573, 0.05571245029568672, 0.012441031634807587, -0.12930986285209656, 0.08097447454929352, -0.0033369441516697407, 0.033388689160346985, -0.11288165301084518, 0.029833108186721802, 0.06322924047708511, 0.09511183202266693, 0.05297581106424332, -0.08098777383565903, -0.16783718764781952, 8.919370484763259e-33, 0.02119920775294304, 0.008791053667664528, 0.014072462916374207, -0.16240759193897247, 0.025822745636105537, 0.0013833200791850686, -0.04486839473247528, 0.028222527354955673, 0.04281450808048248, 0.09846771508455276, -0.04132520407438278, 0.0521581694483757, -0.06658855825662613, -0.06077222526073456, 0.10250980406999588, 0.01326263602823019, -0.10991523414850235, 0.05763532966375351, -0.02123953402042389, -0.04147575795650482, 0.07926391810178757, 0.07011742144823074, 0.05158141255378723, -0.08300016820430756, 0.0931638702750206, 0.07476700097322464, -0.10777919739484787, 0.03065335564315319, -0.13731569051742554, 0.0162382572889328, -0.1328756958246231, 0.06076779216527939, 0.01780136302113533, -0.09813312441110611, 0.1182754710316658, -0.05162142217159271, -0.041844695806503296, 0.00620043883100152, -0.06837114691734314, -0.0629132017493248, -0.07524288445711136, 0.014589200727641582, -0.023272087797522545, -0.004707217216491699, 0.003494410077109933, -0.1399030238389969, -0.03789084777235985, -0.005374515894800425, -0.058383479714393616, 0.07914853096008301, 0.07391143590211868, -0.07709325104951859, -0.1012771874666214, -0.04356863349676132, -0.11310824006795883, 0.03571527451276779, -0.013153267093002796, 0.0505053773522377, 0.04846935346722603, 0.20204880833625793, -0.03486664593219757, 0.0028394421096891165, -0.038895606994628906, -0.12395604699850082, -0.05897696316242218, 0.1165347620844841, 0.0077889906242489815, 0.05205346643924713, 0.13429346680641174, 0.11670807003974915, 0.03277925029397011, 0.09940102696418762, 0.05362359806895256, -0.11087304353713989, 0.11261215806007385, 0.028096850961446762, 0.19054825603961945, -0.08911819756031036, -0.013277017511427402, 0.002430345630273223, -0.042930733412504196, 0.10173484683036804, -0.16959835588932037, -0.07308287173509598, -0.06523221731185913, 0.019515296444296837, 0.042167991399765015, -0.053143762052059174, -0.12803950905799866, -0.12190233170986176, -0.14701053500175476, -0.005857508629560471, -0.06733868271112442, -0.023451751098036766, -0.10250768810510635, -1.0465473225144859e-32, -0.08909737318754196, 0.050723444670438766, 0.03369564935564995, 0.058678120374679565, -0.06494089215993881, 0.013458391651511192, -0.009187884628772736, -0.11408749222755432, 0.010713273659348488, -0.09018434584140778, -0.036414988338947296, -0.07846051454544067, -0.0015208598924800754, -0.027195710688829422, -0.059135373681783676, 0.04904262721538544, -0.08883684128522873, 0.07097931951284409, -0.09232692420482635, 0.09658103436231613, 0.02555050142109394, 0.21325081586837769, -0.12861664593219757, 0.05563346669077873, -0.08588982373476028, 0.12799423933029175, 0.01206495612859726, 0.14423686265945435, -0.036030273884534836, -0.05023333430290222, 0.029645482078194618, 0.004674105439335108, -0.04360148310661316, -0.07148818671703339, 0.01523874793201685, -0.12901662290096283, 0.06160207837820053, -0.034384969621896744, 0.03602635860443115, 0.07130421698093414, 0.1591922789812088, 0.08895375579595566, -0.09249334782361984, -0.0477905236184597, -0.03188510239124298, -0.05090220645070076, -0.0004283106536604464, 0.0054542794823646545, 0.1247512549161911, -0.07505364716053009, 0.03653562813997269, 0.02479056641459465, -0.13891418278217316, 0.1468297243118286, -0.11758063733577728, 0.02137039043009281, -0.15938091278076172, -0.035883430391550064, 0.027030164375901222, 0.11538342386484146, -0.07549384236335754, 0.003361559472978115, 0.0676662027835846, 0.0618046410381794, 0.10451535880565643, 0.05830499529838562, 0.03326635807752609, 0.013473009690642357, 0.06345824897289276, 0.12613248825073242, -0.022202083840966225, 0.07813780754804611, 0.06006080284714699, -0.0980333536863327, -0.0012295667547732592, 0.05584608390927315, -0.0018754421034827828, -0.0053965006954967976, -0.025257892906665802, 0.06955856829881668, -0.05959901213645935, -0.005381387658417225, 0.01250381674617529, 0.09305306524038315, -0.07644572854042053, -0.002016660990193486, 0.0715012475848198, 0.06810882687568665, 0.13819405436515808, -0.013859725557267666, -0.012092788703739643, 0.13570542633533478, 0.10779087245464325, 0.10149975121021271, -0.030238671228289604, -1.0040324838200831e-07, -0.012981097213923931, -0.01288654562085867, 0.036834996193647385, 0.007764270529150963, 0.12360601127147675, 0.11911814659833908, -0.10434984415769577, -0.06815570592880249, -0.11421333253383636, -0.0634087398648262, 0.1038922518491745, 0.006965966429561377, -0.2153991013765335, -0.07701306790113449, 0.013945010490715504, -0.009424890391528606, 0.032569609582424164, 0.07424009591341019, -0.013159407302737236, -0.011119098402559757, 0.06925395131111145, 0.0013793612597510219, -0.0023834649473428726, -0.023732420057058334, -0.013387808576226234, -0.03692178800702095, -0.03453738987445831, 0.00015186598466243595, 0.055539801716804504, 0.10290752351284027, 0.02474556490778923, -0.03570794314146042, 0.12396878749132156, 0.0392492339015007, 0.13655179738998413, 0.07586407661437988, -0.002644859254360199, -0.009776437655091286, -0.07858950644731522, 0.08716975897550583, -0.07222768664360046, -0.018595874309539795, -0.06386902928352356, -0.003035700647160411, -0.04769706353545189, 0.015971511602401733, -0.015115567483007908, 0.01901855506002903, 0.03443275764584541, -0.04295191913843155, -0.033569756895303726, 0.07916224002838135, -0.09917111694812775, 0.08043357729911804, -0.03960713371634483, 0.04884921759366989, -0.10928229242563248, -0.11266256123781204, -0.13938865065574646, -0.019615797325968742, 0.14696064591407776, -0.0894651785492897, -0.05658227205276489, 0.005654856096953154], metadata={'source': 'AAAMLP-569to.pdf', 'page': 42}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 43 And FPR or False Positive Rate, which is defined as:  FPR = FP / (TN + FP)  ═════════════════════════════════════════════════════════════════════════ def fpr(y_true, y_pred):     \"\"\"     Function to calculate fpr     :param y_true: list of true values     :param y_pred: list of predicted values     :return: fpr     \"\"\"     fp = false_positive(y_true, y_pred)     tn = true_negative(y_true, y_pred)     return fp / (tn + fp) ═════════════════════════════════════════════════════════════════════════  And 1 - FPR is known as specificity or True Negative Rate or TNR.  These are a lot of terms, but the most important ones out of these are only TPR and FPR.   Let’s assume that we have only 15 samples and their target values are binary:  Actual targets : [0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1]   We train a model like the random forest, and we can get the probability of when a sample is positive.  Predicted probabilities for 1: [0.1, 0.3, 0.2, 0.6, 0.8, 0.05, 0.9, 0.5, 0.3, 0.66, 0.3, 0.2, 0.85, 0.15, 0.99]  For a typical threshold of  >= 0.5, we can evaluate all the above values of precision, recall/TPR, F1 and FPR. But we can do the same if we choose the value of the threshold to be 0.4 or 0.6. In fact, we can choose any value between 0 and 1 and calculate all the metrics described above.  Let’s calculate only two values, though: TPR and FPR.  ═════════════════════════════════════════════════════════════════════════ # empty lists to store tpr  # and fpr values'),\n",
       " VectorParams(vector=[-0.013449274003505707, -0.04918740317225456, -0.0648064911365509, 0.019380364567041397, 0.1510910838842392, -0.1334737241268158, 0.07634231448173523, 0.16112752258777618, -0.058830440044403076, 0.0974440798163414, -0.021285176277160645, -0.20006102323532104, 0.08366446942090988, -0.05880391597747803, -0.016057968139648438, 0.0456184558570385, -0.06649985909461975, 0.013465535826981068, -0.019208671525120735, -0.12193682789802551, 0.057708051055669785, 0.09172066301107407, -0.032708629965782166, 0.010553390718996525, 0.006365383975207806, -0.08431918174028397, 0.04591190442442894, 0.1456645131111145, -0.10226356238126755, -0.009060416370630264, -0.11536059528589249, 0.015138349495828152, 0.15964563190937042, -0.03394790366292, -0.03218325600028038, -0.07009854912757874, -0.0575718954205513, -0.011064106598496437, -0.021622370928525925, 0.024635303765535355, -0.0770278126001358, -0.04103626683354378, -0.011088736355304718, -0.009691882878541946, 0.12195251882076263, 0.10861381143331528, -0.04355816915631294, 0.026673024520277977, -0.118676096200943, 0.007608179003000259, -0.09120498597621918, 0.12988682091236115, -0.009509045630693436, -0.05556747689843178, 0.0029293587431311607, -0.07434336841106415, 0.1533685177564621, -0.1376938670873642, 0.02686573751270771, -0.08605507016181946, -0.11715271323919296, -0.07728668302297592, -0.024601509794592857, -0.11680638790130615, 0.05142144486308098, 0.04134924337267876, -0.07704752683639526, 0.06294407695531845, 0.03978361561894417, 0.11243695765733719, -0.07254090160131454, 0.17736613750457764, -0.018468787893652916, -0.024296483024954796, -0.017779795452952385, -0.019743427634239197, 0.14180755615234375, 0.029672468081116676, -0.039854250848293304, -0.005557261873036623, -0.07245603948831558, -0.0026240143924951553, 0.012920464389026165, -0.06710399687290192, -0.032676514238119125, -0.1666368544101715, 0.1178114265203476, 0.10168637335300446, 0.18337015807628632, 0.05775923654437065, 0.04201498255133629, 0.04876492917537689, -0.11941531300544739, -0.030729886144399643, -0.002066435758024454, 0.1594536155462265, -0.04195407032966614, -0.1237395703792572, -0.024327127262949944, 0.04934189096093178, -0.1408681869506836, -0.042642779648303986, -0.021217146888375282, -0.12125419825315475, 0.03936120122671127, 0.05673879012465477, 0.10336685180664062, 0.05951058864593506, 0.08533250540494919, -0.22727401554584503, -0.04231768101453781, -0.06544207036495209, 0.04712378606200218, -0.09275268763303757, 0.12166926264762878, 0.0021499672438949347, -0.05374302342534065, 0.06551790982484818, -0.029798926785588264, 0.07436764240264893, -0.07642482221126556, 0.04402931407094002, 0.018002478405833244, 0.1310536116361618, -0.01929645426571369, -0.06954865157604218, -0.2280905544757843, 6.827404902058252e-33, -0.0945272296667099, -0.04411086440086365, -0.054338593035936356, -0.1655992567539215, 0.04136449843645096, -0.02966265194118023, 0.042725395411252975, -0.006919322535395622, -0.01374213770031929, 0.055256400257349014, -0.034577373415231705, -0.03856564313173294, -0.07322266697883606, -0.03458249196410179, 0.1109597310423851, -0.034009791910648346, 0.03572667017579079, 0.03293982520699501, -0.08907434344291687, -0.01932647079229355, 0.03436095640063286, -0.018881939351558685, 0.04667692631483078, 0.0006136696902103722, -0.007881451398134232, 0.13918457925319672, -0.05367770045995712, 0.029300542548298836, -0.1125657707452774, 0.001030856859870255, 0.032391030341386795, 0.13861918449401855, -0.07327862828969955, -0.20682896673679352, 0.0422099344432354, -0.03612157702445984, 0.027237191796302795, 0.06353434920310974, 0.08154461532831192, 0.04011533781886101, -0.015543374232947826, -0.024079356342554092, 0.04848003014922142, 0.029950853437185287, -0.017840906977653503, -0.12987670302391052, -0.12447426468133926, 0.0753183662891388, -0.010567782446742058, 0.12119827419519424, 0.03503712639212608, -0.15759281814098358, -0.031164348125457764, -0.05217698588967323, -0.15569855272769928, 0.08778726309537888, -0.04359600320458412, 0.00186920037958771, 0.14911532402038574, 0.11375276744365692, -0.01754486747086048, -0.030084356665611267, -0.050067268311977386, -0.06300137937068939, -0.019739562645554543, 0.21868959069252014, -0.0009075541747733951, 0.00017463008407503366, 0.09311846643686295, 0.12146463990211487, -0.01623004488646984, 0.09515351057052612, 0.07806505262851715, -0.08514983206987381, 0.06763648241758347, 0.011960922740399837, 0.13661545515060425, -0.06863278895616531, -0.037075452506542206, -0.12214236706495285, -0.0031248917803168297, 0.17288097739219666, -0.15499477088451385, -0.16961568593978882, 0.0515126958489418, -0.06084584817290306, 0.02662641368806362, -0.03162601217627525, -0.18872305750846863, -0.09451266378164291, -0.1768171638250351, 0.034053985029459, 0.0364297479391098, 0.0030261166393756866, -0.11658675968647003, -7.743275162454113e-33, -0.034997954964637756, 0.2287307232618332, 0.08938267827033997, -0.00943063199520111, -0.00471761729568243, 0.07372765243053436, -0.08317815512418747, -0.11115865409374237, 0.027035027742385864, -0.02564748004078865, -0.10331495106220245, -0.11358071118593216, -0.056355103850364685, -0.004750420339405537, -0.04551679268479347, 0.06732648611068726, -0.03924725577235222, 0.047527238726615906, -0.09190875291824341, -0.01753021404147148, 0.03349028900265694, 0.18277764320373535, -0.11355535686016083, 0.06060674041509628, -0.1337009221315384, -0.005296861752867699, 0.019705183804035187, 0.15398657321929932, -0.025305241346359253, -0.0837920606136322, -0.11249598115682602, 0.0019959481433033943, 0.017293432727456093, 0.04010406509041786, 0.08216249197721481, -0.1043846607208252, 0.07179935276508331, -0.18463082611560822, 0.07570172101259232, 0.018617257475852966, 0.17011867463588715, 0.07487276196479797, -0.08518537133932114, -0.07967168837785721, -0.0159640870988369, 0.0674118772149086, 0.057847365736961365, 0.04792146012187004, 0.020076952874660492, -0.004317942075431347, 0.0837496668100357, 0.06625664234161377, -0.12625661492347717, 0.07125743478536606, -0.07269975543022156, 0.13541491329669952, -0.1702512949705124, -0.06816563755273819, -0.011397994123399258, 0.0344761423766613, -0.10466931760311127, 0.02671423740684986, 0.10744275152683258, 0.03103688731789589, 0.14721985161304474, 0.14385809004306793, -0.099594846367836, 0.02331884577870369, 0.06254921108484268, 0.13763730227947235, -0.09887339919805527, 0.13934016227722168, 0.05063458904623985, -0.12328418344259262, -0.004273919854313135, -0.012811622582376003, -0.10735685378313065, -0.029443878680467606, -0.06392344832420349, 0.02790498174726963, -0.12516532838344574, -0.07527425140142441, 0.07674684375524521, 0.07508894056081772, -0.0629679337143898, 0.036084532737731934, 0.11460240930318832, 0.09602124989032745, 0.14563985168933868, -0.058247849345207214, -0.06714262068271637, 0.10174843668937683, 0.15448139607906342, 0.14000041782855988, -0.014778508804738522, -1.0068969658050264e-07, -0.0027662180364131927, -0.06265204399824142, 0.04137493297457695, 0.11723523586988449, 0.19748426973819733, 0.16671936213970184, -0.1267457753419876, -0.04599165543913841, -0.09003448486328125, -0.166364386677742, 0.058173153549432755, 0.010408246889710426, -0.10751377791166306, -0.05353710055351257, -0.0008065140573307872, 0.008673319593071938, -0.010232877917587757, 0.04420488700270653, -0.006355057004839182, 0.0002962271682918072, 0.05886645242571831, 0.001291793305426836, -0.005360012408345938, 0.006841413211077452, 0.014965647831559181, -0.10707850009202957, -0.10056791454553604, -0.0058187320828437805, 0.03542184829711914, 0.06278450787067413, 0.04507128521800041, -0.09145133942365646, 0.08150589466094971, 1.1594914212764706e-05, 0.22536875307559967, 0.04301886633038521, 0.033299390226602554, -0.00898069143295288, -0.02724340371787548, 0.04953688010573387, -0.07384321093559265, 0.05582311376929283, -0.04564910754561424, 0.004355526529252529, 0.06826047599315643, -0.05926420912146568, -0.003324805060401559, -0.037377309054136276, 0.13636964559555054, -0.03637009486556053, 0.04106513410806656, 0.07095375657081604, -0.06153804436326027, 0.0784207358956337, -0.011401389725506306, 0.007626489270478487, -0.1250886619091034, -0.02857092395424843, -0.08648808300495148, 0.018469275906682014, 0.10775813460350037, -0.02949797920882702, -0.05730690062046051, 0.016288498416543007], metadata={'source': 'AAAMLP-569to.pdf', 'page': 43}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 44 tpr_list = [] fpr_list = []  # actual targets y_true = [0, 0, 0, 0, 1, 0, 1,            0, 0, 1, 0, 1, 0, 0, 1]  # predicted probabilities of a sample being 1 y_pred = [0.1, 0.3, 0.2, 0.6, 0.8, 0.05,            0.9, 0.5, 0.3, 0.66, 0.3, 0.2,            0.85, 0.15, 0.99]  # handmade thresholds thresholds = [0, 0.1, 0.2, 0.3, 0.4, 0.5,               0.6, 0.7, 0.8, 0.85, 0.9, 0.99, 1.0]  # loop over all thresholds for thresh in thresholds:      # calculate predictions for a given threshold     temp_pred = [1 if x >= thresh else 0 for x in y_pred]     # calculate tpr     temp_tpr = tpr(y_true, temp_pred)     # calculate fpr     temp_fpr = fpr(y_true, temp_pred)     # append tpr and fpr to lists     tpr_list.append(temp_tpr)     fpr_list.append(temp_fpr)  ═════════════════════════════════════════════════════════════════════════  We can thus get a tpr and fpr value for each threshold.  \\n Figure 3: Table for threshold, TPR and FPR values'),\n",
       " VectorParams(vector=[0.044243551790714264, -0.1012168899178505, -0.08685556799173355, -0.10881279408931732, 0.2390824556350708, -0.13683494925498962, 0.059144314378499985, 0.26440954208374023, -0.046653278172016144, 0.0048335399478673935, 0.05298199504613876, -0.1279333382844925, -0.020718585699796677, 0.0230146124958992, -0.023143749684095383, -0.03118846006691456, -0.07546639442443848, -0.09226370602846146, -0.03964800015091896, 0.07585710287094116, 0.16401734948158264, 0.08040868490934372, 0.07866695523262024, 0.11822954565286636, 0.08992384374141693, -0.11752072721719742, 0.0184322539716959, 0.14963771402835846, -0.05608076974749565, -0.01657695509493351, -0.007990242913365364, 0.08221952617168427, 0.07531335949897766, 0.02447310835123062, -0.02127978950738907, -0.07011063396930695, 0.06913269311189651, 0.1103639081120491, 0.016487155109643936, 0.04078035429120064, -0.0020489967428147793, -9.360374679090455e-05, 0.022769097238779068, 0.033672817051410675, 0.0711798146367073, 0.15109634399414062, -0.0513809509575367, -0.0026365204248577356, -0.024674192070961, 0.07973767817020416, 0.04051685705780983, 0.12089120596647263, -0.08559108525514603, 0.0788918286561966, -0.014216616749763489, -0.0563947893679142, 0.023007532581686974, -0.10026068240404129, 0.060600440949201584, -0.023146172985434532, -0.12404555827379227, -0.05654966086149216, -0.049871835857629776, 0.01910417154431343, -0.04986414313316345, 0.005863182246685028, 0.01206132024526596, -0.12522222101688385, -0.14021070301532745, 0.1561613827943802, 0.05655287578701973, -0.019407104700803757, -0.10174215584993362, 0.02525242231786251, -0.053625863045454025, -0.0024349407758563757, 0.07464460283517838, 0.05934559926390648, -0.04454434663057327, -0.0512077696621418, -0.01766459085047245, 0.16229000687599182, -0.020233336836099625, 0.018354149535298347, 0.05487632751464844, -0.12059234827756882, 0.055142514407634735, -0.02719305083155632, 0.08968205004930496, 0.07776517421007156, 0.08812723308801651, 0.06691540032625198, -0.18072809278964996, -0.04031189903616905, -0.033153779804706573, 0.02889277972280979, 0.10304605960845947, -0.06537295132875443, -0.0820285975933075, 0.14708025753498077, -0.06666242331266403, -0.1243835836648941, 0.0004730446089524776, -0.006186163518577814, 0.03964598849415779, 0.007800837513059378, 0.058345794677734375, 0.05421561002731323, 0.11479991674423218, -0.029008565470576286, 0.07117116451263428, -0.020779084414243698, -0.11389175057411194, 0.12186426669359207, 0.08522266894578934, 0.04907939210534096, -0.07288475334644318, 0.12363245338201523, -0.10739000886678696, 0.02324189618229866, -0.042315661907196045, 0.01736038736999035, -0.03063296340405941, 0.20353177189826965, -0.013942756690084934, -0.058223504573106766, -0.20464591681957245, 7.922275034093516e-33, -0.06103803589940071, -0.001793582458049059, -0.009300458244979382, -0.1651279479265213, -0.12162768840789795, -0.005914442241191864, -0.10653162002563477, 0.055226441472768784, 0.09031102061271667, 0.14300751686096191, -0.11822402477264404, 0.13463462889194489, -0.01549716480076313, -0.017748016864061356, 0.06696278601884842, 0.029192160815000534, 0.028314372524619102, 0.14294040203094482, -0.13669972121715546, -0.057483330368995667, 0.0788940042257309, 0.027852846309542656, 0.12725256383419037, -0.05801721662282944, -0.012383821420371532, 0.034278642386198044, -0.09646026045084, 0.012229951098561287, -0.1246202141046524, 0.0727541595697403, -0.14290408790111542, 0.11268982291221619, 0.02497062087059021, -0.11834768205881119, 0.040915850549936295, -0.22361361980438232, 0.01981733925640583, -0.021989094093441963, -0.014912357553839684, 0.09000059217214584, 0.051763467490673065, 0.05618158355355263, 0.051162004470825195, -0.21178489923477173, 0.015184419229626656, 0.03215707093477249, -0.0018396098166704178, 0.16483935713768005, 0.04331385716795921, 0.06844399869441986, 0.06731625646352768, -0.1501680314540863, 0.008121113292872906, 0.07750126719474792, -0.026910709217190742, 0.07442386448383331, -0.09873384237289429, -0.10533814877271652, 0.03580945357680321, 0.07367350906133652, 0.0831560343503952, -0.05968719720840454, 0.09778579324483871, -0.0829177275300026, -0.07275489717721939, 0.0487128347158432, 0.017861122265458107, -0.07443679124116898, -0.016152871772646904, 0.07753399014472961, -0.0848458781838417, 0.15394966304302216, -0.03589262813329697, 0.006144472397863865, 0.03596385195851326, -0.1841825395822525, 0.12965373694896698, 0.03658681735396385, -0.06504814326763153, -0.04236761853098869, -0.0957745835185051, 0.1098785400390625, -0.0961458832025528, -0.26319193840026855, -0.0932454839348793, -0.04501814767718315, 0.1552315056324005, -0.09103934466838837, -0.3016378879547119, -0.19606147706508636, -0.0714012011885643, -0.10658665001392365, -0.042809050530195236, 0.056240931153297424, -0.23382171988487244, -1.0755036422002759e-32, -0.0995946079492569, 0.03480943664908409, 0.1562354564666748, 0.013285048305988312, -0.06730881333351135, 0.10974752902984619, 0.06047893315553665, 0.04231370985507965, -0.028558755293488503, -0.08303394168615341, -0.0684981644153595, -0.10095073282718658, -0.0924047902226448, -0.08704368025064468, 0.17691539227962494, -5.5437667469959706e-05, -0.060222871601581573, 0.093775674700737, -0.19951927661895752, -0.036072738468647, 0.1605290025472641, 0.09651512652635574, -0.05875924974679947, -0.08394049108028412, -0.0519803985953331, 0.01177541445940733, -0.09449175000190735, 0.13249503076076508, -0.07544922083616257, -0.045580245554447174, -0.10716956853866577, 0.029827404767274857, -0.122182697057724, -0.05062563717365265, 0.01177884079515934, 0.00016515034076292068, -0.018362512812018394, 0.02246670052409172, -0.029766086488962173, 0.054314710199832916, 0.12318571656942368, 0.10477173328399658, -0.13318419456481934, -0.020069872960448265, -0.03917522355914116, 0.0761333480477333, -0.021155545487999916, 0.034967854619026184, 0.17770293354988098, -0.060610491782426834, 0.16228030622005463, 0.038710128515958786, 0.07581232488155365, 0.11624399572610855, -0.20522332191467285, 0.1612939089536667, -0.21490070223808289, -0.0013991502346470952, -0.11866607517004013, -0.028139309957623482, -0.06872536242008209, -0.04906702786684036, -0.026508398354053497, 0.025387512519955635, 0.07654969394207001, 0.049785565584897995, -0.051474954932928085, -0.09935253113508224, 0.055769823491573334, 0.16062504053115845, -0.06611534208059311, 0.055065546184778214, -0.02625715360045433, -0.11230781674385071, -0.07662604004144669, 0.14411213994026184, -0.05127266049385071, -0.14008377492427826, -0.1309950351715088, 0.06640525162220001, -0.017349863424897194, 0.004345601890236139, 0.12934258580207825, 0.1620870679616928, -0.10450544208288193, 0.11462695896625519, 0.1632646769285202, 0.11831748485565186, 0.11188188940286636, 0.030671004205942154, -0.050912369042634964, 0.08969362825155258, -0.026308072730898857, 0.1910126805305481, 0.06148785352706909, -1.0015615714564774e-07, -0.005393560044467449, -0.04746859520673752, -0.08352327346801758, 0.035970233380794525, 0.07370414584875107, 0.11300144344568253, -0.22659626603126526, 0.020412350073456764, -0.09017214179039001, -0.022178763523697853, 0.04053721949458122, 0.018269117921590805, -0.23711082339286804, -0.06082477420568466, -0.0848253145813942, -0.033025577664375305, -0.03551404923200607, 0.05071830749511719, -0.10372026264667511, -0.02094241976737976, -0.053054120391607285, -0.05458417162299156, 0.011440576985478401, -0.09491132199764252, -0.0905253142118454, -0.1432797908782959, -0.13991929590702057, 0.11935974657535553, 0.01688213087618351, 0.10667674988508224, 0.09069272875785828, -0.15596283972263336, 0.12298841029405594, 0.12653599679470062, 0.12576565146446228, 0.08333557844161987, -0.0592283271253109, 0.0742616355419159, 0.031753696501255035, 0.1994776874780655, -0.09051297605037689, 0.057098209857940674, -0.04381299018859863, -0.006432765629142523, 0.08273621648550034, 0.002282948000356555, -0.018004203215241432, 0.10764379799365997, -0.004206879995763302, 0.02377866581082344, 0.12241941690444946, 0.07591181248426437, -0.18149740993976593, 0.04847992584109306, -0.01954062096774578, -0.042999304831027985, -0.15397076308727264, -0.1260085552930832, -0.09921320527791977, 0.16435088217258453, -0.001708123367279768, -0.055517587810754776, -0.049065764993429184, 0.009437928907573223], metadata={'source': 'AAAMLP-569to.pdf', 'page': 44}, content=\"Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 45 If we plot the table as shown in figure 3, i.e. if we have TPR on the y-axis and FPR on the x-axis, we will get a curve as shown in figure 4.  ═════════════════════════════════════════════════════════════════════════ plt.figure(figsize=(7, 7)) plt.fill_between(fpr_list, tpr_list, alpha=0.4) plt.plot(fpr_list, tpr_list, lw=3) plt.xlim(0, 1.0) plt.ylim(0, 1.0) plt.xlabel('FPR', fontsize=15) plt.ylabel('TPR', fontsize=15) plt.show() ═════════════════════════════════════════════════════════════════════════ \\n Figure 4: Receiver operating characteristic (ROC) curve  This curve is also known as the Receiver Operating Characteristic (ROC). And if we calculate the area under this ROC curve, we are calculating another metric which is used very often when you have a dataset which has skewed binary targets.   This metric is known as the Area Under ROC Curve or Area Under Curve or just simply AUC. There are many ways to calculate the area under the ROC curve. For this particular purpose, we will stick to the fantastic implementation by scikit-learn.  ═════════════════════════════════════════════════════════════════════════ In [X]: from sklearn import metrics\"),\n",
       " VectorParams(vector=[0.028155267238616943, -0.13676413893699646, -0.0180150605738163, 0.09491733461618423, 0.14221633970737457, -0.19676163792610168, 0.015474782325327396, 0.097623810172081, 0.0007339715957641602, 0.08394293487071991, -0.0771600604057312, -0.17865991592407227, 0.06727363914251328, -0.00887332670390606, -0.13045360147953033, -0.008699319325387478, 0.027495382353663445, -0.08030117303133011, -0.18833136558532715, 0.17516380548477173, 0.024184785783290863, 0.055997855961322784, 0.016145829111337662, 0.11284182965755463, -0.09883317351341248, -0.08900266140699387, 0.06717658042907715, 0.016796013340353966, -0.11644092947244644, -0.031924642622470856, -0.12685967981815338, -0.04833560436964035, 0.14556345343589783, 0.005250154994428158, -0.058443207293748856, -0.04512060806155205, -0.01836106739938259, 0.035314083099365234, -0.06748456507921219, -0.09879211336374283, -0.012953379191458225, -0.009835009463131428, 0.019204646348953247, 0.018045205622911453, 0.05091600865125656, 0.08467668294906616, -0.06683099269866943, -0.05205318331718445, 0.070829838514328, 0.024847570806741714, -0.025921277701854706, 0.06732542812824249, -0.2290630340576172, -0.055412646383047104, -0.11147306859493256, 0.04911433905363083, -0.04054088145494461, -0.1630152463912964, 0.015663184225559235, -0.15678852796554565, 0.042373597621917725, -0.04874490946531296, -0.08383019268512726, 0.016258805990219116, 0.13339194655418396, -0.04612909257411957, -0.09833213686943054, -0.029003430157899857, 0.04871293902397156, 0.1512027084827423, 0.037575896829366684, -0.02446764148771763, 0.027060963213443756, 0.1563476324081421, 0.04396664723753929, 0.07813271880149841, 0.020963601768016815, -0.03305830433964729, 0.07305432856082916, 0.020197803154587746, -0.026916097849607468, -0.028917253017425537, 0.030851442366838455, -0.050782233476638794, 0.17711563408374786, -0.1277502030134201, 0.09608013182878494, 0.0006969338282942772, 0.0560292974114418, 0.02986694499850273, 0.09330181032419205, 0.024830235168337822, -0.031678974628448486, 0.0047132037580013275, 0.19182148575782776, 0.012978067621588707, 0.14597615599632263, -0.021377891302108765, -0.017620772123336792, 0.07288720458745956, -0.05962903052568436, 0.05206822603940964, -0.032906755805015564, -0.008230035193264484, 0.120982825756073, 0.0200743917375803, 0.025230497121810913, -0.05993440002202988, 0.08658099919557571, -0.04896623268723488, 0.0014597270637750626, -0.013286691159009933, -0.07574424147605896, -0.07724052667617798, 0.03165305405855179, 0.10742238163948059, -0.1044415533542633, 0.06981693208217621, -0.18081670999526978, 0.04189756512641907, -0.1752108335494995, 0.017086420208215714, 0.10218547284603119, 0.06759966909885406, 0.06388392299413681, -0.15343326330184937, -0.0946236401796341, 6.029553539800979e-33, -0.1048458069562912, -0.06012997031211853, -0.013268901035189629, -0.11251853406429291, -0.01988336443901062, 0.007334222085773945, -0.028225358575582504, 0.05553396791219711, 0.08288030326366425, 0.08341006934642792, -0.062408994883298874, 0.0389614962041378, 0.009231941774487495, 0.07219989597797394, 0.06504599004983902, 0.09527130424976349, -0.017291247844696045, -0.025804229080677032, -0.17029902338981628, 0.09247884154319763, 0.18104329705238342, -0.037684597074985504, -0.002936246804893017, -0.0402902327477932, -0.013599127531051636, 0.1774548888206482, -0.04803517460823059, 0.03804514557123184, -0.13779063522815704, 0.03954777121543884, -0.13857778906822205, 0.043592870235443115, 0.09373146295547485, -0.11761017888784409, -0.010672811418771744, 0.036582689732313156, 0.054579153656959534, 0.06239292025566101, -0.018357381224632263, -0.0630476176738739, -0.0755176693201065, -0.0010929543059319258, 0.05015592277050018, -0.10152017325162888, 0.03111526183784008, -0.07954724133014679, -0.048188354820013046, 0.08826126158237457, -0.14311960339546204, 0.07231287658214569, 0.08017931878566742, -0.14727401733398438, -0.14348691701889038, 0.06875904649496078, -0.17224404215812683, 0.05685066431760788, 0.12485340982675552, 0.03950178250670433, -0.02486570179462433, 0.10673904418945312, 0.11808237433433533, -0.054811038076877594, -0.07168999314308167, -0.05287090316414833, -0.05107135325670242, 0.1000252515077591, 0.0035345666110515594, -0.03567008674144745, 0.04794740676879883, 0.020130330696702003, -0.07860340178012848, 0.014409735798835754, -0.004601441323757172, -0.03791028633713722, 0.0921737402677536, 0.030706778168678284, 0.13251444697380066, 0.028777725994586945, -0.10228533297777176, 0.032606471329927444, -0.10383803397417068, 0.19634641706943512, -0.06349970400333405, -0.17909952998161316, -0.0656118094921112, -0.004877416882663965, 0.12209030985832214, -0.04785505682229996, -0.20627756416797638, 0.04024540260434151, 0.0145789235830307, 0.048831719905138016, 0.02138747088611126, 0.12528440356254578, -0.12579010426998138, -8.230036352870084e-33, -0.05813848599791527, 0.025705810636281967, 0.010181650519371033, 0.11462356150150299, -0.06236480921506882, 0.025613367557525635, 0.05185506120324135, 0.03380892798304558, -0.05142022296786308, -0.2078639715909958, 0.08057191967964172, -0.04579693824052811, 0.05107501894235611, 0.047079090029001236, 0.058748356997966766, 0.04685598611831665, -0.08289320021867752, 0.015260329470038414, -0.04175441712141037, 0.10093522071838379, 0.06861613690853119, 0.22931304574012756, -0.0661492794752121, -0.02314300462603569, -0.16796335577964783, 0.08694632351398468, -0.018032055348157883, 0.10119491070508957, 0.04379705712199211, -0.10887454450130463, -0.06489367038011551, 0.19421298801898956, -0.0978841707110405, -0.025617945939302444, -0.03570062294602394, -0.01697450503706932, -0.046301841735839844, -0.05599265545606613, -0.038474634289741516, 0.12734463810920715, 0.0926835834980011, 0.1034761592745781, -0.26348134875297546, -0.023534003645181656, -0.04688160866498947, -0.15985488891601562, 0.1048494428396225, 0.03813614696264267, 0.13259470462799072, -0.030591432005167007, 0.07756200432777405, -0.0938267707824707, -0.02483947016298771, 0.16929548978805542, -0.03244186192750931, 0.11676202714443207, -0.1498105823993683, -0.009892899543046951, 0.05065566301345825, 0.14674285054206848, -0.09017416834831238, 0.09984205663204193, 0.04881901293992996, 0.0007960237562656403, 0.030829982832074165, 0.09731599688529968, -0.0238400436937809, 0.06826760619878769, 0.07033372670412064, 0.15275506675243378, -0.10897758603096008, 0.13075703382492065, -0.01711103692650795, -0.023861100897192955, -0.0052630058489739895, 0.03872741386294365, -0.0292610265314579, 0.0493321567773819, 0.027739744633436203, -0.04085952043533325, -0.17423884570598602, 0.06908629089593887, 0.020608754828572273, 0.20638352632522583, -0.06582440435886383, 0.034087106585502625, 0.13858342170715332, -0.011587380431592464, 0.06576550006866455, -0.016889384016394615, -0.05746469646692276, 0.09863065183162689, 0.06286334991455078, 0.07225546985864639, -0.04935242235660553, -1.0067320488360565e-07, -0.06719904392957687, 0.01906352862715721, 0.05748463422060013, 0.03471345826983452, 0.022307468578219414, 0.06254715472459793, -0.19273459911346436, 0.029234042391180992, -0.13768073916435242, -0.07403907179832458, 0.09614519774913788, 0.008162503130733967, -0.23390117287635803, -0.1334303915500641, -0.049832843244075775, 0.06808922439813614, 0.002319816965609789, 0.11508759111166, -0.0387599803507328, -0.07734071463346481, -0.06273447722196579, -0.055416058748960495, -0.041473619639873505, -0.08393731713294983, -0.0007719041313976049, -0.04506957158446312, 0.03914516419172287, 0.06830896437168121, -0.10166682302951813, 0.0513947531580925, -0.007153789512813091, -0.07396590709686279, 0.03659084811806679, -0.0006670604925602674, 0.0640166699886322, 0.16166041791439056, 0.11884340643882751, -0.08297332376241684, -0.1057518869638443, 0.07151739299297333, -0.02645106054842472, 0.05674725025892258, -0.1290917545557022, -0.0991988256573677, -0.05506080389022827, 0.03971351683139801, 0.04258101060986519, -0.04140152782201767, 0.11492104083299637, -0.07229964435100555, 0.022345226258039474, 0.027906524017453194, -0.19901709258556366, -0.06221125274896622, -0.0024055507965385914, 0.015607273206114769, -0.06954649835824966, -0.07279815524816513, -0.13261403143405914, 0.1279400885105133, 0.04118967428803444, -0.10356560349464417, -0.1352023482322693, 0.0018695220351219177], metadata={'source': 'AAAMLP-569to.pdf', 'page': 45}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 46 In [X]: y_true = [0, 0, 0, 0, 1, 0, 1,    ...:           0, 0, 1, 0, 1, 0, 0, 1]  In [X]: y_pred = [0.1, 0.3, 0.2, 0.6, 0.8, 0.05,    ...:           0.9, 0.5, 0.3, 0.66, 0.3, 0.2,    ...:           0.85, 0.15, 0.99]  In [X]: metrics.roc_auc_score(y_true, y_pred) Out[X]: 0.8300000000000001 ═════════════════════════════════════════════════════════════════════════  AUC values range from 0 to 1.  - AUC = 1 implies you have a perfect model. Most of the time, it means that you made some mistake with validation and should revisit data processing and validation pipeline of yours. If you didn’t make any mistakes, then congratulations, you have the best model one can have for the dataset you built it on.  - AUC = 0 implies that your model is very bad (or very good!). Try inverting the probabilities for the predictions, for example, if your probability for the positive class is p, try substituting it with 1-p. This kind of AUC may also mean that there is some problem with your validation or data processing.  - AUC = 0.5 implies that your predictions are random. So, for any binary classification problem, if I predict all targets as 0.5, I will get an AUC of 0.5.  AUC values between 0 and 0.5 imply that your model is worse than random. Most of the time, it’s because you inverted the classes. If you try to invert your predictions, your AUC might become more than 0.5. AUC values closer to 1 are considered good.  But what does AUC say about our model?   Suppose you get an AUC of 0.85 when you build a model to detect pneumothorax from chest x-ray images. This means that if you select a random image from your dataset with pneumothorax (positive sample) and another random image without pneumothorax (negative sample), then the pneumothorax image will rank higher than a non-pneumothorax image with a probability of 0.85.'),\n",
       " VectorParams(vector=[-0.012418004684150219, -0.05097441375255585, -0.11830350756645203, -0.027943799272179604, 0.11591073125600815, -0.15234577655792236, 0.13657799363136292, 0.09137894958257675, -0.13340330123901367, 0.06565167754888535, -0.03635763004422188, -0.22994573414325714, 0.01958516426384449, -0.007265693508088589, -0.055672526359558105, 0.04744609445333481, 0.044842466711997986, -0.052367713302373886, -0.010880973190069199, 0.02567167952656746, 0.05932934209704399, 0.0638880506157875, -0.025925058871507645, 0.10053928196430206, -0.11875087022781372, -0.07851746678352356, 0.1471143364906311, 0.0288070160895586, -0.12622478604316711, -0.06382305175065994, -0.0894724652171135, -0.111466184258461, 0.1947309523820877, -0.014456639066338539, 0.006547267083078623, -0.05184849351644516, -0.01860477589070797, -0.008082191459834576, -0.04522321745753288, -0.04813236743211746, -0.05510673671960831, -0.02300521358847618, -0.026860209181904793, 0.0052141654305160046, 0.04993169754743576, 0.082308329641819, -0.0165051631629467, 0.018261579796671867, -0.01960078254342079, -0.04013517498970032, 0.005537375807762146, 0.04716638848185539, -0.0736970379948616, -0.0032209765631705523, -0.1015264093875885, -0.056779175996780396, 0.0624915212392807, -0.12023622542619705, 0.0005904163117520511, -0.09533531218767166, -0.025510910898447037, -0.1093396469950676, 0.02104087918996811, -0.06872622668743134, 0.10839232802391052, 0.08758289366960526, -0.11890958249568939, 0.06547950208187103, 0.09560636430978775, 0.1199076771736145, -0.024165593087673187, 0.04303845763206482, -0.04335326701402664, 0.11614327132701874, 0.03600016236305237, 0.02263898029923439, 0.08567342907190323, 0.00983037892729044, -0.047992102801799774, 0.07090619206428528, -0.08238215744495392, 0.014154566451907158, 0.04959246143698692, 0.004642199259251356, 0.04540417343378067, -0.15547938644886017, 0.09274718165397644, 0.09290902316570282, 0.09732099622488022, 0.0448409765958786, -0.0078737149015069, 0.05058442801237106, -0.019276902079582214, -0.0510404109954834, 0.048536282032728195, 0.0562402568757534, -0.02095111273229122, -0.10593205690383911, -0.006542083341628313, 0.06902983784675598, -0.13807553052902222, -0.05192519351840019, -0.04389885440468788, -0.08015420287847519, 0.12183961272239685, 0.08903984725475311, 0.06392320990562439, -0.009771705605089664, 0.062044598162174225, -0.1506654918193817, -0.007982704788446426, 0.024130860343575478, -0.032182153314352036, -0.11027273535728455, 0.08692707121372223, 0.029850240796804428, -0.04306778684258461, 0.12654492259025574, -0.09612886607646942, 0.06774863600730896, -0.07668551057577133, 0.003993480000644922, 0.036522939801216125, 0.07962896674871445, 0.039797816425561905, -0.05638973042368889, -0.15770240128040314, 4.7243367752097285e-33, -0.051415178924798965, -0.030846726149320602, -0.09947889298200607, -0.2134411782026291, 0.0707373395562172, -0.031992558389902115, 0.07186606526374817, 0.043086472898721695, 0.00896176602691412, 0.034999653697013855, 0.03529662638902664, -0.008244337514042854, -0.059716176241636276, 0.049935948103666306, 0.08027094602584839, -0.07372096180915833, 0.019583674147725105, -0.058270201086997986, -0.09552712738513947, -0.04049896448850632, 0.04433109983801842, -0.09010590612888336, 0.0007729769567959011, -0.022614842280745506, 0.08696196973323822, 0.06041017919778824, -0.06982225179672241, 0.008750754408538342, -0.07329348474740982, -0.0011572960065677762, -0.06285470724105835, 0.10290081799030304, 0.01584770530462265, -0.13902421295642853, 0.07420781254768372, 0.03515230491757393, -0.030969087034463882, 0.07482892274856567, 0.037925489246845245, -0.03357092663645744, -0.036769915372133255, -0.05277585610747337, 0.03482066094875336, -0.03328852728009224, 0.00411711260676384, -0.09835740178823471, -0.03951591998338699, 0.06901862472295761, -0.09942774474620819, 0.04808034375309944, 0.09569411724805832, -0.16904711723327637, -0.06207646429538727, 0.00871086586266756, -0.17451712489128113, -0.05752841383218765, -0.0016205497086048126, 0.029368959367275238, 0.07678168267011642, 0.08820843696594238, 0.08159591257572174, -0.09237589687108994, -0.02322319522500038, -0.032034192234277725, -0.030609874054789543, 0.09338141232728958, 0.009030846878886223, -0.060136549174785614, 0.04754871502518654, 0.04448236525058746, -0.0383707620203495, 0.08929264545440674, 0.06205808371305466, -0.08247917890548706, 0.0035903158131986856, 0.04820631816983223, 0.13501285016536713, 0.00898456946015358, -0.048411693423986435, -0.033851295709609985, -0.04605657234787941, 0.03853095695376396, -0.09039076417684555, -0.16367946565151215, 0.050179436802864075, 0.04647928848862648, 0.054988060146570206, -0.008457201533019543, -0.2270941436290741, -0.015638452023267746, -0.18188530206680298, 0.02489585056900978, 0.04240081459283829, 0.058069776743650436, -0.09072275459766388, -5.553132658910414e-33, -0.03068574331700802, 0.11401168256998062, 0.06888191401958466, 0.06507457047700882, -0.005709488410502672, 0.09735970199108124, -0.032900769263505936, 0.020298628136515617, -0.04743258282542229, -0.055741410702466965, 0.00376192107796669, -0.016734015196561813, 0.013324689120054245, 0.0008675253484398127, -0.07412289828062057, -0.006671059876680374, -0.09652479737997055, 0.10654869675636292, -0.01428777351975441, 0.040253251791000366, -0.00852864608168602, 0.24335543811321259, -0.1355913281440735, 0.02934463880956173, -0.11571419984102249, 0.08536367118358612, -0.0046095699071884155, 0.1808471977710724, -0.018682828173041344, -0.034850507974624634, -0.1551913172006607, 0.12148798257112503, -0.03532442823052406, -0.013608069159090519, 0.08555864542722702, -0.050753459334373474, 0.07904335111379623, -0.06903093308210373, 0.006292650476098061, 0.11056873947381973, 0.07621965557336807, 0.03265621140599251, -0.21457166969776154, -0.02919132262468338, -0.03886760026216507, -0.03508607670664787, 0.026612484827637672, 0.1865655928850174, 0.04005463048815727, -0.02932538464665413, 0.07437876611948013, 0.06494792550802231, -0.06192951649427414, 0.20211054384708405, -0.06592223048210144, 0.08968589454889297, -0.17796242237091064, -0.06084930896759033, -0.02227649837732315, 0.09597697854042053, -0.1362973302602768, 0.04077256843447685, 0.07739446312189102, 0.08296443521976471, 0.09378650039434433, 0.012620816007256508, -0.05298132076859474, 0.07910320162773132, 0.003334364853799343, 0.1536381095647812, -0.028044400736689568, 0.209075465798378, 0.09601271152496338, -0.12556946277618408, -0.015648212283849716, -0.07465143501758575, -0.03625171259045601, 0.003513482166454196, -0.01645340584218502, 0.05052429810166359, -0.11518404632806778, -0.014139060862362385, 0.04317591339349747, 0.1581364870071411, -0.013172115199267864, 0.12304925173521042, 0.08004051446914673, 0.004089880269020796, 0.1454620659351349, 0.0022605503909289837, -0.11128155142068863, 0.07232062518596649, 0.09393317997455597, 0.11114298552274704, -0.06666103005409241, -9.964008995666518e-08, 0.03049527108669281, -0.025840502232313156, 0.039981525391340256, 0.045689623802900314, 0.1640828549861908, 0.21278174221515656, -0.1728239208459854, -0.0032639168202877045, -0.17151430249214172, -0.09861496090888977, 0.08335421979427338, 0.044952649623155594, -0.1696241945028305, -0.04485137388110161, 0.023691972717642784, -4.3704207200789824e-05, 0.04755982756614685, 0.1489119827747345, -0.011761915870010853, 0.03396003693342209, 0.09134130924940109, -0.058126747608184814, 0.05067950114607811, 0.015239308588206768, -0.01097626518458128, -0.1094309389591217, 0.02121499739587307, -0.010661912150681019, -0.046375572681427, 0.07193223387002945, -0.016873648390173912, -0.07384615391492844, 0.05947485938668251, 0.02374923974275589, 0.20289194583892822, 0.13427181541919708, -0.06196670979261398, -0.004073709715157747, -0.09105246514081955, 0.05592027306556702, -0.02510962449014187, 0.0628429502248764, -0.08025722950696945, 0.003544751787558198, -0.03161264955997467, -0.06540670990943909, -0.04326941817998886, 0.01740252785384655, 0.07328692078590393, -0.0580582395195961, 0.02955656312406063, 0.046547796577215195, -0.10052584856748581, 0.03872529789805412, -0.04558383300900459, 0.026655063033103943, -0.05954960361123085, -0.06017894670367241, -0.15830576419830322, 0.07355503737926483, 0.1724216490983963, -0.09401028603315353, -0.04987216368317604, 0.02588094212114811], metadata={'source': 'AAAMLP-569to.pdf', 'page': 46}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 47 After calculating probabilities and AUC, you would want to make predictions on the test set. Depending on the problem and use-case, you might want to either have probabilities or actual classes. If you want to have probabilities, it’s effortless. You already have them. If you want to have classes, you need to select a threshold. In the case of binary classification, you can do something like the following.  Prediction = Probability >= Threshold  Which means, that prediction is a new list which contains only binary variables. An item in prediction is 1 if the probability is greater than or equal to a given threshold else the value is 0.  And guess what, you can use the ROC curve to choose this threshold! The ROC curve will tell you how the threshold impacts false positive rate and true positive rate and thus, in turn, false positives and true positives. You should choose the threshold that is best suited for your problem and datasets.   For example, if you don’t want to have too many false positives, you should have a high threshold value. This will, however, also give you a lot more false negatives. Observe the trade-off and select the best threshold. Let’s see how these thresholds impact true positive and false positive values.  ═════════════════════════════════════════════════════════════════════════ # empty lists to store true positive  # and false positive values tp_list = [] fp_list = []  # actual targets y_true = [0, 0, 0, 0, 1, 0, 1,            0, 0, 1, 0, 1, 0, 0, 1]  # predicted probabilities of a sample being 1 y_pred = [0.1, 0.3, 0.2, 0.6, 0.8, 0.05,            0.9, 0.5, 0.3, 0.66, 0.3, 0.2,            0.85, 0.15, 0.99]  # some handmade thresholds thresholds = [0, 0.1, 0.2, 0.3, 0.4, 0.5,               0.6, 0.7, 0.8, 0.85, 0.9, 0.99, 1.0]  # loop over all thresholds for thresh in thresholds:'),\n",
       " VectorParams(vector=[0.018130872398614883, -0.10786593705415726, -0.03977952152490616, 0.008665221743285656, 0.15057288110256195, -0.05786282569169998, 0.05791790410876274, 0.1678788661956787, -0.04332765191793442, 0.04561368376016617, -0.01006060466170311, -0.16684289276599884, -0.07452791929244995, 0.09691494703292847, -0.05229362100362778, -0.015897465869784355, 0.06568112969398499, -0.046043574810028076, 0.0010336828418076038, 0.030242113396525383, 0.0016626766882836819, -0.0008137400727719069, -0.06125398725271225, 0.12898308038711548, -0.16993696987628937, -0.1555207222700119, 0.030986223369836807, -0.05265919119119644, -0.043848808854818344, 0.06915631145238876, -0.14144869148731232, -0.021831590682268143, 0.16648069024085999, -0.01865389011800289, -0.07555188238620758, -0.012820826843380928, -0.006164136808365583, -0.04177051782608032, -0.05271385982632637, -0.053819023072719574, -0.09723348915576935, -0.11423436552286148, 0.022504957392811775, 0.026778392493724823, 0.09501619637012482, 0.14413152635097504, 0.01520190853625536, 0.02909448742866516, -0.13603754341602325, -0.026998216286301613, 0.010659612715244293, 0.1085682064294815, -0.06576959788799286, 0.03773581236600876, -0.10400165617465973, 0.0729963630437851, 0.007825829088687897, -0.10891257971525192, -0.019709715619683266, 0.014840852469205856, -0.06261944770812988, -0.11570921540260315, 0.05246623605489731, -0.07274038344621658, 0.1452375203371048, 0.11716139316558838, -0.07298999279737473, -0.008576943539083004, 0.016464946791529655, 0.18731731176376343, 0.009422912262380123, 0.11491364240646362, -0.01671551913022995, -0.020357083529233932, -0.017967602238059044, 0.0715879425406456, 0.11336217820644379, 0.0011954127112403512, -0.04370718076825142, 0.02880512736737728, 0.03196066617965698, 0.025154272094368935, 0.0023304657079279423, -0.03777826204895973, 0.1073913648724556, -0.2042180895805359, 0.06378644704818726, 0.02447730116546154, 0.08773146569728851, 0.09222161024808884, 0.09252811223268509, 0.0981111004948616, 0.009551333263516426, -0.05156352370977402, -0.0704054981470108, 0.018492672592401505, -0.03340902552008629, -0.03756120428442955, -0.05980461835861206, 0.016095610335469246, -0.217428058385849, -0.041775044053792953, -0.005860751494765282, -0.05859031528234482, 0.11791563779115677, 0.03843251243233681, 0.09748294204473495, 0.04575295001268387, 0.08364097774028778, -0.09393022209405899, 0.03146018832921982, 0.05438636988401413, 0.0549439936876297, -0.07139775156974792, 0.12139496207237244, 0.07703900337219238, -0.1044338196516037, 0.11356307566165924, 0.007605487480759621, 0.1039813980460167, -0.07498452067375183, 0.02053619921207428, 0.0333469957113266, 0.09572503715753555, 0.021236948668956757, -0.034987930208444595, -0.16736915707588196, 1.7815793850430528e-32, -0.021472766995429993, 0.08787494152784348, -0.025265751406550407, -0.106405109167099, 0.011469241231679916, -0.0614318810403347, -0.03255143389105797, -0.02620987594127655, 0.03452785313129425, 0.11918804049491882, 0.006855879910290241, -0.013992326334118843, -0.03650542348623276, 0.06965209543704987, 0.06211075186729431, -0.06098749861121178, -0.001984446542337537, -0.03416542336344719, -0.10614820569753647, -0.06330949813127518, 0.07257990539073944, -0.04327089712023735, 0.006106203887611628, -0.005616896320134401, 0.09842154383659363, 0.06384678184986115, -0.11285343021154404, -0.011176918633282185, -0.04999156296253204, 0.019262544810771942, -0.12331367284059525, 0.008990238420665264, 0.0002462912234477699, -0.11935533583164215, 0.10598117113113403, 0.032228223979473114, 0.03685811534523964, 0.05041481927037239, 0.05827629193663597, 0.021052472293376923, -0.029683122411370277, 0.003755186451599002, 0.07899995148181915, -0.05898630619049072, -0.00997594278305769, -0.07131541520357132, -0.03016994521021843, 0.061334557831287384, -0.10127686709165573, 0.028597360476851463, 0.045249562710523605, -0.1519956737756729, -0.022261779755353928, -0.011391826905310154, -0.09546773880720139, -0.03756774961948395, -0.09366948157548904, -0.006899444852024317, 0.05679589509963989, 0.10921970754861832, 0.10964576154947281, -0.13561691343784332, -0.09115243703126907, -0.11012919247150421, -0.13960249722003937, 0.061136119067668915, 0.0005461372202262282, -0.08991017937660217, 0.06040384992957115, 0.035396378487348557, 0.005968304816633463, 0.08317285776138306, 0.038165271282196045, -0.14689838886260986, 0.04457014426589012, 0.02783268317580223, 0.17988908290863037, -0.03878407925367355, 0.014493892900645733, -0.09575498104095459, -0.14009197056293488, 0.03229009732604027, -0.033652205020189285, -0.13421398401260376, 0.07374288141727448, -0.06571974605321884, 0.06451769918203354, 0.047060538083314896, -0.1940639764070511, 0.019608715549111366, -0.0895545557141304, -0.014653907157480717, 0.17831742763519287, 0.11473190039396286, -0.10918419063091278, -1.7107011899186967e-32, -0.06920146942138672, 0.011742329224944115, 0.08633352071046829, 0.024016236886382103, -0.08114193379878998, 0.09822343289852142, 0.020776931196451187, 0.016757287085056305, -0.04473847523331642, -0.08688616007566452, 0.05477612465620041, -0.05602698773145676, -0.037642497569322586, -0.08878284692764282, -0.028644578531384468, -0.05365742743015289, -0.03469067066907883, 0.0959753692150116, -0.05366338789463043, -0.04894474893808365, 0.04094782471656799, 0.12419324368238449, -0.14210517704486847, 0.0629875659942627, -0.1337004452943802, 0.13246043026447296, -0.11104702949523926, 0.08550339937210083, -0.048455554991960526, 0.02846420183777809, -0.2452608048915863, 0.10288894176483154, -0.0027820435352623463, 0.09436096996068954, 0.06807303428649902, 0.06775771826505661, 0.02857605367898941, -0.15871727466583252, 0.07646811753511429, 0.17109936475753784, 0.13287293910980225, 0.07598268985748291, -0.09981679171323776, -0.06790376454591751, -0.13078242540359497, 0.05397530645132065, 0.03675605356693268, 0.11886213719844818, 0.0949033573269844, -0.017473939806222916, 0.18866340816020966, 0.014065799303352833, -0.05482859164476395, 0.10414458066225052, -0.13511964678764343, 0.05132467672228813, -0.15047644078731537, -0.11911998689174652, -0.10786353796720505, 0.088814377784729, -0.05189596861600876, -0.02128324843943119, -0.0004780376038979739, 0.03761875256896019, 0.0030592228285968304, -0.0332215242087841, -0.008623260073363781, 0.0627896636724472, 0.06542786210775375, 0.04662536829710007, -0.07485120743513107, 0.057246770709753036, -0.021377695724368095, -0.09834151715040207, 0.009231417439877987, -0.021473251283168793, -0.026794616132974625, 0.027138011530041695, -0.0274767205119133, -0.08142686635255814, -0.13725750148296356, 0.03228096291422844, 0.005560928024351597, 0.07759145647287369, -0.06100424751639366, 0.018755683675408363, 0.06701125204563141, -0.07286304980516434, 0.15947751700878143, 0.012131540104746819, -0.09136027097702026, 0.05129661038517952, 0.019668571650981903, 0.05886726826429367, -0.005439437460154295, -1.0075843448476007e-07, 0.011592084541916847, -0.021724864840507507, 0.02515866607427597, 0.030949298292398453, 0.10202448815107346, 0.12195189297199249, -0.06410443782806396, 0.01374857872724533, -0.1513165533542633, -0.028577439486980438, 0.10114444047212601, 0.1049189418554306, -0.13878680765628815, -0.12737756967544556, -0.019494473934173584, -0.04729660227894783, -0.07325219362974167, 0.07956840842962265, 0.01995900832116604, -0.02103486843407154, -0.012853593565523624, -0.009184000082314014, 0.035672083497047424, -0.04844387248158455, -0.055373724550008774, -0.045972488820552826, -0.034108422696590424, 0.03529147058725357, -0.012190351262688637, 0.08070459216833115, -0.00581147987395525, -0.1181119829416275, -0.020759783685207367, 0.11692052334547043, 0.19661103188991547, 0.15741586685180664, -0.09102737158536911, -0.006612266413867474, -0.14496244490146637, 0.13346673548221588, -0.02892329730093479, 0.07217755913734436, -0.11124897748231888, 0.0151597298681736, -0.033054400235414505, -0.08028730005025864, -0.022189365699887276, 0.0645337849855423, 0.014704282395541668, -0.014110145159065723, 0.027039600536227226, 0.0944603681564331, -0.10601617395877838, 0.09130772948265076, -0.08687495440244675, 0.017303524538874626, -0.052658505737781525, 0.014747430570423603, -0.1680181920528412, 0.017000632360577583, 0.16738471388816833, -0.06353441625833511, -0.10121893137693405, -0.022900335490703583], metadata={'source': 'AAAMLP-569to.pdf', 'page': 47}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 48     # calculate predictions for a given threshold     temp_pred = [1 if x >= thresh else 0 for x in y_pred]     # calculate tp     temp_tp = true_positive(y_true, temp_pred)     # calculate fp     temp_fp = false_positive(y_true, temp_pred)     # append tp and fp to lists     tp_list.append(temp_tp)     fp_list.append(temp_fp) ═══════════════════════════════════════════════════════════════════════  Using this, we can create a table, as shown in Figure 5.  \\n Figure 5: TP and FP values for different thresholds  Most of the time, the top-left value on ROC curve should give you a quite good threshold, as shown in figure 6.  Comparing the table and the ROC curve, we see that a threshold of around 0.6 is quite good where we do not lose a lot of true positives and neither we have a lot of false positives.'),\n",
       " VectorParams(vector=[-0.0023048212751746178, -0.14543136954307556, -0.07406752556562424, 0.02332252450287342, 0.27044832706451416, -0.1370757818222046, 0.07779320329427719, 0.13213962316513062, -0.05770766735076904, 0.047384485602378845, -0.166270911693573, -0.09262292087078094, -0.05958282947540283, 0.020039139315485954, -0.10603989660739899, -0.026908989995718002, -0.08205495029687881, 0.03270770609378815, -0.09080418199300766, 0.11539637297391891, 0.12669938802719116, 0.028413569554686546, -0.0025374044198542833, 0.26656925678253174, -0.039866652339696884, -0.16903376579284668, 0.08700691908597946, -0.016726071015000343, -0.19775405526161194, -0.12362577021121979, -0.1199517473578453, -0.13421617448329926, 0.13313427567481995, 0.05720628425478935, -0.06310101598501205, -0.04586927965283394, -0.036843132227659225, -0.01621473766863346, 0.0077439709566533566, -0.09599614143371582, 0.00726839154958725, -0.02854372188448906, 0.007089208345860243, -0.03159515559673309, 0.027589399367570877, 0.07909781485795975, -0.017244966700673103, -0.01447276771068573, 0.09447167068719864, 0.08482127636671066, 0.06192837283015251, -0.007184644695371389, -0.1296558976173401, 0.02333036996424198, -0.19953837990760803, 0.03500021994113922, -0.039006877690553665, -0.12564022839069366, 0.06168922409415245, 0.03659063205122948, 0.06653701514005661, -0.16082486510276794, -0.07417873293161392, -0.11665555834770203, 0.1012917086482048, -0.13809742033481598, -0.0419088751077652, 0.046983469277620316, 0.03619002923369408, 0.2319834679365158, -0.015065417625010014, -0.15409889817237854, -0.02532198838889599, 0.11569923162460327, 0.049725133925676346, -0.035134851932525635, 0.14778874814510345, 0.07964152097702026, -0.05186186358332634, 0.0799660012125969, -0.00817705038934946, 0.08068200945854187, -0.016428105533123016, 0.03086000494658947, 0.13120560348033905, -0.224087655544281, 0.13074098527431488, 0.07338827103376389, 0.10645467787981033, 0.04110882058739662, -0.007393911946564913, 0.047047585248947144, 0.09460777789354324, -0.0550377182662487, 0.1449681967496872, 0.04726788401603699, -0.0027802791446447372, -0.03248737007379532, 0.05613327771425247, 0.0344042032957077, 0.02352880872786045, 0.049288369715213776, 0.051181964576244354, -0.10787650942802429, 0.1897590160369873, 0.017562013119459152, -0.012694916687905788, -0.02185736782848835, 0.12447475641965866, 0.027017628774046898, 0.03460060432553291, 0.08862077444791794, -0.172777459025383, -0.0028274478390812874, 0.16027531027793884, 0.12588119506835938, -0.04545295611023903, 0.07672615349292755, -0.19789130985736847, 0.16527922451496124, -0.2301510125398636, 0.06729990243911743, 0.10252918303012848, 0.02591150440275669, 0.11690708994865417, -0.09229037165641785, -0.08268467336893082, 1.1099945566317219e-32, -0.14217494428157806, 0.050006963312625885, -0.11285397410392761, -0.12679994106292725, -0.048547662794589996, 0.051393166184425354, -0.09372396767139435, 0.05583154410123825, 0.03639139607548714, 0.09926319122314453, -0.05172283947467804, 0.007458603009581566, 0.039277333766222, 0.11166498064994812, 0.08446874469518661, 0.05765732750296593, -0.008893818594515324, -0.11228302121162415, 0.0627150759100914, 0.02793380618095398, -0.03869238495826721, -0.04165038466453552, 0.0016891499981284142, 0.0376008078455925, -0.0543464720249176, 0.0458124577999115, -0.0025929948315024376, 0.006002417299896479, -0.09969174861907959, 0.058847468346357346, -0.021154150366783142, 0.07223723083734512, 0.01902131363749504, -0.17583569884300232, 0.13564267754554749, 0.05785989761352539, -0.04289901629090309, 0.06970825791358948, -0.029807860031723976, 0.05285724997520447, -0.12659506499767303, 0.0640096515417099, 0.08875647187232971, -0.055015064775943756, -0.057222336530685425, -0.028858082368969917, -0.03549012541770935, 0.18783889710903168, -0.1106380969285965, 0.05077624320983887, -0.04427197575569153, -0.25795602798461914, -0.01786736212670803, 0.07363355159759521, -0.040275197476148605, 0.04611688852310181, 0.04447617009282112, -0.10576806217432022, 0.045308880507946014, -0.020022109150886536, 0.1594056338071823, -0.16998979449272156, 0.0396474152803421, 0.03299741446971893, -0.09927567839622498, 0.031174736097455025, 0.15640954673290253, 0.050213366746902466, -0.07064686715602875, -0.0043444447219371796, -0.0875478982925415, -0.05804692953824997, 0.03544868528842926, -0.06794477254152298, 0.018048234283924103, 0.057363204658031464, 0.11548230797052383, -0.03904108703136444, 0.05504559352993965, 0.08593666553497314, -0.15557116270065308, 0.14079606533050537, 0.0074056293815374374, -0.18791702389717102, -0.03438472002744675, 0.05521225556731224, 0.08277392387390137, -0.07014477252960205, -0.22304803133010864, 0.0550302118062973, -0.14649605751037598, 0.009071857668459415, 0.00045929395128041506, 0.13761721551418304, -0.13634656369686127, -1.2791798585941243e-32, -0.06295567005872726, -0.004452437162399292, 0.01305125467479229, 0.10022009909152985, -0.09198180586099625, 0.05048729106783867, -0.04817381128668785, 0.03450906276702881, -0.07125624269247055, -0.08279194682836533, 0.0016414138954132795, 0.006923094857484102, 0.06375443935394287, 0.11186506599187851, 0.019161254167556763, 0.024991899728775024, -0.11783215403556824, 0.01053659152239561, 0.015727581456303596, -0.04570840671658516, 0.1114739254117012, 0.10257828235626221, -0.1420256346464157, -0.016279228031635284, -0.1329164355993271, -0.006765394471585751, -0.13469979166984558, 0.07342355698347092, -0.005859027616679668, -0.1265418529510498, -0.09977506846189499, 0.12244049459695816, -0.03618103638291359, 0.05883898586034775, 0.024684162810444832, 0.09617319703102112, 0.021169839426875114, -0.00900969561189413, 0.006081739440560341, 0.10386005789041519, 0.07638894766569138, 0.10056600719690323, -0.19384190440177917, -0.0691361278295517, -0.0709121897816658, -0.07853415608406067, -0.020466677844524384, 0.15689851343631744, 0.15429766476154327, 0.032907817512750626, 0.07134629786014557, -0.08059196174144745, 0.06954579800367355, 0.17656224966049194, -0.12795504927635193, 0.09313619136810303, -0.12669256329536438, 0.010369135066866875, -0.08792244642972946, 0.1403820663690567, -0.10630390048027039, 0.10439462959766388, 0.06572845578193665, 0.1150856465101242, -0.09490153193473816, -0.032219380140304565, -0.057913362979888916, 0.10403313487768173, -0.07848703861236572, 0.054284073412418365, 0.025973713025450706, 0.1244991347193718, -0.034900687634944916, -0.03726084157824516, -0.08759773522615433, -0.014520416036248207, -0.07448074966669083, -0.0841500461101532, -0.12861329317092896, 0.03578393533825874, -0.03243112564086914, 0.02457267977297306, -0.026407472789287567, 0.2293291538953781, -0.05715784430503845, 0.05550554767251015, 0.20290954411029816, 0.08614452928304672, 0.08499763906002045, -0.03328182175755501, -0.03541228175163269, 0.04340776056051254, -0.03978457301855087, 0.005020450800657272, -0.13945254683494568, -9.982079518522369e-08, -0.12598182260990143, 0.043078869581222534, 0.07018481194972992, -0.027293913066387177, 0.04801045358181, 0.16584472358226776, -0.16757933795452118, 0.1944943517446518, -0.1819966733455658, 0.07171736657619476, 0.020579829812049866, -0.011849360540509224, -0.21821671724319458, 0.03028452768921852, -0.04519518092274666, 0.11659182608127594, 0.05110800266265869, 0.13735412061214447, 0.011001755483448505, -0.002171108266338706, 0.03600810840725899, -0.06767377257347107, 0.08849164098501205, -0.072036013007164, -0.08318327367305756, -0.13811074197292328, 0.13479402661323547, 0.17155320942401886, -0.1311047375202179, 0.07200390845537186, -0.018777089193463326, -0.03769335523247719, 0.013899801298975945, 0.023142365738749504, -0.026924677193164825, 0.1462799459695816, 0.04243583232164383, -0.1987854540348053, -0.06423716992139816, 0.0777723416686058, -0.08656848967075348, 0.025397127494215965, -0.13815778493881226, -0.028596511110663414, -0.002891510259360075, -0.019275538623332977, 0.031433358788490295, 0.0011613874230533838, -0.023783691227436066, 0.025784721598029137, 0.05633498728275299, 0.012930898927152157, -0.07970724999904633, 0.05626266822218895, 0.089507557451725, -0.053827643394470215, -0.0999169796705246, -0.16014091670513153, -0.0229168888181448, 0.11021500825881958, 0.0175308957695961, -0.11925704032182693, -0.0933859720826149, -0.02078140713274479], metadata={'source': 'AAAMLP-569to.pdf', 'page': 48}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 49  Figure 6: Select the best threshold from the leftmost top point in the ROC curve  AUC is a widely used metric for skewed binary classification tasks in the industry, and a metric everyone should know about. Once you understand the idea behind AUC, as explained in the paragraphs above, it is also easy to explain it to non-technical people who would probably be assessing your models in the industry.  Another important metric you should learn after learning AUC is log loss. In case of a binary classification problem, we define log loss as:  Log Loss = - 1.0 * ( target * log(prediction) + (1 - target) * log(1 - prediction) )  Where target is either 0 or 1 and prediction is a probability of a sample belonging to class 1.  For multiple samples in the dataset, the log-loss over all samples is a mere average of all individual log losses. One thing to remember is that log loss penalizes quite high for an incorrect or a far-off prediction, i.e. log loss punishes you for being very sure and very wrong.  ═════════════════════════════════════════════════════════════════════════ import numpy as np  def log_loss(y_true, y_proba):'),\n",
       " VectorParams(vector=[-0.03922625631093979, -0.029341120272874832, -0.0035440672654658556, 0.020023124292492867, 0.20878498256206512, -0.26065927743911743, 0.12439912557601929, 0.0887937918305397, 0.027210768312215805, 0.10510801523923874, -0.10494149476289749, -0.08590258657932281, 0.059856995940208435, -0.05408499017357826, -0.05884228274226189, 0.022998202592134476, -0.1430070549249649, 0.04599873721599579, -0.06430930644273758, 0.022356241941452026, 0.11775215715169907, 0.16138388216495514, -0.04749847948551178, 0.13581763207912445, 0.152831569314003, -0.1668461263179779, 0.058476220816373825, 0.07973387092351913, -0.14149819314479828, -0.056758541613817215, -0.039605073630809784, 0.01873333379626274, 0.02963331528007984, -2.220891292381566e-05, 0.0033788757864385843, 0.000990800908766687, -0.022033175453543663, -0.04066222906112671, -0.041978660970926285, 0.03334091231226921, -0.05558793619275093, 0.05204351991415024, -0.017707422375679016, -0.055028900504112244, -0.02962833270430565, 0.018275484442710876, -0.13532108068466187, -0.08599343150854111, 0.06734143197536469, -0.00835128128528595, -0.05614783614873886, 0.1129736453294754, -0.15789873898029327, -0.014004608616232872, -0.07654481381177902, -0.013514994643628597, 0.06196440011262894, -0.047761186957359314, 0.024675318971276283, -0.018141495063900948, -0.03532237932085991, -0.0004333905235398561, -0.05281970649957657, -0.04134192317724228, 0.07033639401197433, -0.17656315863132477, 0.032025620341300964, 0.06566567718982697, -0.0019615390338003635, 0.053963784128427505, -0.09465695172548294, 0.023834895342588425, -0.12013580650091171, 0.08389796316623688, 0.03445158153772354, -0.06375855207443237, 0.2057916224002838, 0.013091127388179302, -0.06948918104171753, 0.09909037500619888, -0.058783747255802155, 0.0693783089518547, 0.0712151974439621, -0.07324929535388947, -0.026176029816269875, -0.15686675906181335, 0.05408572405576706, 0.12202992290258408, 0.15983574092388153, -0.02681095525622368, -0.05113344267010689, -0.02963506430387497, -0.05905696377158165, 0.07851655036211014, 0.1309218555688858, 0.16092011332511902, -0.045607127249240875, -0.06609916687011719, 0.026826368644833565, 0.06746607273817062, -0.060498323291540146, -0.001868172432295978, 0.0767219290137291, -0.17326824367046356, 0.13407766819000244, -0.02624317817389965, 0.16019271314144135, -0.14005903899669647, 0.14390890300273895, -0.1459675282239914, 0.055687643587589264, -0.049410540610551834, -0.02043922431766987, 0.0779506266117096, 0.09991747885942459, 0.1257888823747635, -0.11536718159914017, 0.14483895897865295, -0.1476781666278839, 0.11030171066522598, -0.18209248781204224, 0.1592704951763153, 0.06101933866739273, 0.18264128267765045, -0.03558044508099556, -0.04734518751502037, -0.05968447029590607, 7.310810790786594e-33, -0.10120653361082077, -0.06676137447357178, -0.04344717785716057, -0.21299023926258087, -0.028908541426062584, 0.15731848776340485, 0.02512441948056221, -0.04876226559281349, -0.10368163883686066, 0.005523270461708307, -0.11738056689500809, 3.5301511616125936e-06, -0.059950992465019226, -0.006415218580514193, 0.10205311328172684, -0.03705619275569916, -0.04054888337850571, 0.022577742114663124, 0.07355145364999771, 0.0024561192840337753, 0.020857572555541992, -0.04014839231967926, -0.01844169571995735, -0.15631680190563202, -0.07985342293977737, -0.0284944549202919, -0.038513872772455215, -0.017427051439881325, -0.1182924211025238, 0.04591889679431915, -0.13343007862567902, 0.17668884992599487, -0.049183331429958344, -0.1627449095249176, 0.12447738647460938, -0.1057850793004036, 0.13318246603012085, 0.07058954983949661, -0.019083509221673012, -0.07027612626552582, -0.10654927045106888, 0.05288932844996452, 0.0437336266040802, -0.03860253468155861, -0.023499269038438797, -0.1430686116218567, -0.021397219970822334, 0.10415998101234436, -0.019958728924393654, 0.09477124363183975, -0.042249634861946106, -0.125016450881958, -0.08034426718950272, -0.01131556835025549, -0.12537378072738647, 0.02369099110364914, 0.2323957085609436, 0.06864996999502182, 0.1250384896993637, 0.12337760627269745, -0.020328417420387268, 0.05772358179092407, 0.01988893933594227, -0.0897667333483696, -0.0032276217825710773, 0.2074374556541443, 0.1324828565120697, 0.06248869001865387, 0.021039821207523346, 0.13029499351978302, -0.09205363690853119, 0.0554947666823864, -0.0044941469095647335, -0.14421318471431732, 0.03898037225008011, -0.04476284608244896, 0.06585045158863068, -0.03786282241344452, 0.007575835566967726, -0.02509959600865841, -0.026571504771709442, 0.15983881056308746, -0.09606894105672836, -0.20790700614452362, -0.06899057328701019, -0.09924311190843582, 0.0196242518723011, -0.044951386749744415, -0.15589356422424316, -0.10500646382570267, -0.1293858289718628, -0.045355331152677536, -0.010256507433950901, 0.027044137939810753, -0.1675151139497757, -1.0650660605173402e-32, -0.1458911895751953, 0.14766159653663635, -0.008910956792533398, 0.10718605667352676, -0.005851811729371548, -0.018442822620272636, 0.07162292301654816, -0.07714343816041946, 0.017550045624375343, -0.10988619923591614, -0.042458564043045044, -0.1365402340888977, -0.022908207029104233, 0.06538660824298859, 0.14458155632019043, 0.1331220120191574, -0.16714538633823395, 0.09687912464141846, -0.09630884975194931, -0.1342715620994568, 0.08059772104024887, 0.219017893075943, -0.10848742723464966, 0.038795508444309235, -0.09310335665941238, -0.01879107393324375, -0.004850665107369423, 0.2111654281616211, 0.06809718906879425, -0.17277078330516815, -0.025727011263370514, -0.028663301840424538, -0.18885640799999237, 0.08548285067081451, 0.03227171674370766, -0.04256332665681839, 0.03119373507797718, 0.006894246209412813, 0.013840236701071262, -0.05218913033604622, 0.07364874333143234, 0.0626663938164711, -0.10040672868490219, -0.09356115013360977, 0.008289974182844162, 0.0810202956199646, -0.028985073789954185, -0.05714419111609459, 0.15678942203521729, -0.016295166686177254, -0.006026844959706068, 0.008693105541169643, -0.12478724867105484, 0.23969772458076477, -0.1368105709552765, 0.12778238952159882, -0.22943204641342163, 0.06050300970673561, -0.08063958585262299, -0.011319498531520367, -0.15065526962280273, -0.020716944709420204, 0.08170875161886215, 0.1527138352394104, 0.07772709429264069, 0.11898563802242279, -0.136572927236557, -0.07428339123725891, 0.05152267962694168, 0.07035189121961594, 0.08994574844837189, 0.08304821699857712, 0.03831084445118904, -0.12931136786937714, -0.06650740653276443, 0.019135823473334312, 0.0216826144605875, -0.11073915660381317, -0.06179467588663101, 0.07807986438274384, -0.07458087801933289, 0.05032624304294586, 0.06536675989627838, 0.13252873718738556, 0.02536598965525627, 0.0897742509841919, 0.08327966183423996, 0.09914916008710861, 0.06740248948335648, 0.00954805314540863, 0.017592312768101692, 0.13549688458442688, 0.04915904253721237, 0.04851065203547478, -0.04712507128715515, -1.0032422892436443e-07, -0.09747981280088425, -0.022964561358094215, 0.06328914314508438, 0.1352916657924652, 0.22088487446308136, 0.0425020232796669, -0.10833866149187088, -0.008849943988025188, -0.10320829600095749, -0.0460471510887146, 0.05400411784648895, -0.10219009220600128, -0.08567792922258377, 0.021659977734088898, 0.011652190238237381, 0.028596997261047363, -0.008501613512635231, 0.009394500404596329, 0.035678964108228683, 0.0560389868915081, 0.11213487386703491, -0.09629560261964798, -0.0071981861256062984, -0.04632265120744705, -0.133575439453125, -0.09331361204385757, -0.07190721482038498, 0.12493868172168732, 0.015213403850793839, 0.047906745225191116, 0.009390611201524734, -0.0266451183706522, 0.11633896827697754, 0.023402996361255646, 0.09087634086608887, 0.1360204964876175, 0.0072953952476382256, -0.006453957408666611, -0.018701761960983276, 0.05898778885602951, -0.17455026507377625, -0.07497934252023697, 0.017489470541477203, -0.001750693772919476, 0.10157930850982666, -0.06373162567615509, 0.07637885212898254, -0.0221524890512228, 0.0901947021484375, -0.10378202795982361, 0.09578874707221985, 0.003587022889405489, -0.0750928744673729, -0.01051932480186224, 0.2047835886478424, -0.1073288545012474, -0.22193656861782074, -0.0580945760011673, -0.0792962983250618, 0.09637243300676346, 0.021179059520363808, -0.09613750129938126, 0.007481532637029886, -0.022636739537119865], metadata={'source': 'AAAMLP-569to.pdf', 'page': 49}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 50     \"\"\"     Function to calculate log loss     :param y_true: list of true values     :param y_proba: list of probabilities for 1     :return: overall log loss     \"\"\"     # define an epsilon value     # this can also be an input     # this value is used to clip probabilities     epsilon = 1e-15     # initialize empty list to store     # individual losses     loss = []     # loop over all true and predicted probability values     for yt, yp in zip(y_true, y_proba):         # adjust probability         # 0 gets converted to 1e-15         # 1 gets converted to 1-1e-15         # Why? Think about it!         yp = np.clip(yp, epsilon, 1 - epsilon)         # calculate loss for one sample         temp_loss = - 1.0 * (             yt * np.log(yp)              + (1 - yt) * np.log(1 - yp)         )         # add to loss list         loss.append(temp_loss)     # return mean loss over all samples     return np.mean(loss) ═════════════════════════════════════════════════════════════════════════  Let’s test our implementation:  ═════════════════════════════════════════════════════════════════════════ In [X]: y_true = [0, 0, 0, 0, 1, 0, 1,    ...:           0, 0, 1, 0, 1, 0, 0, 1]  In [X]: y_proba = [0.1, 0.3, 0.2, 0.6, 0.8, 0.05,    ...:           0.9, 0.5, 0.3, 0.66, 0.3, 0.2,    ...:           0.85, 0.15, 0.99]  In [X]: log_loss(y_true, y_proba) Out[X]: 0.49882711861432294 ═════════════════════════════════════════════════════════════════════════  We can compare this with scikit-learn:'),\n",
       " VectorParams(vector=[-0.10460272431373596, -0.03727792575955391, -0.03849853202700615, -0.011483351700007915, 0.09281677007675171, -0.1483631432056427, 0.08365558832883835, 0.1284601390361786, 0.08150631934404373, 0.06155296042561531, -0.18822866678237915, -0.14657382667064667, 0.07288041710853577, 0.02403096668422222, -0.007585633546113968, -0.11336804181337357, -0.029855815693736076, 0.15798738598823547, -0.27989307045936584, 0.1263715922832489, 0.22099874913692474, 0.030326688662171364, 0.11015468090772629, 0.1941533088684082, -0.016976388171315193, -0.1747504472732544, 0.04353791102766991, -0.021339358761906624, -0.1859683394432068, -0.03498489037156105, -0.06865634024143219, 0.07831114530563354, -0.041995417326688766, 0.04317159578204155, -0.1107475757598877, -0.05085795372724533, -0.003397537162527442, -0.0007102422532625496, 0.02521125040948391, -0.032253991812467575, -0.07255184650421143, 0.07642418146133423, 0.0643356591463089, 0.014730987139046192, 0.0014264181954786181, -0.0013617026852443814, -0.08317162841558456, -0.10299601405858994, 0.04500720277428627, 0.03529755026102066, -0.0621144138276577, 0.06964471936225891, -0.09270980209112167, 0.03836929798126221, -0.13807979226112366, 0.04869749769568443, 0.09443493187427521, -0.06976087391376495, -0.02577258087694645, -0.008515243418514729, -0.03895703703165054, -0.10318416357040405, -0.04404960200190544, -0.11919239163398743, 0.04059245064854622, -0.14435333013534546, 0.03889771178364754, 0.025545384734869003, 0.07057972252368927, 0.2620254456996918, -0.09168177098035812, -0.0914222002029419, -0.07723537087440491, 0.04683049023151398, 0.0151683259755373, 0.014121407642960548, 0.1736825555562973, 0.11398959904909134, -0.0012472352245822549, 0.0314863845705986, 0.05219133198261261, 0.14384905993938446, 0.002193584805354476, 0.012015512213110924, 0.1252807229757309, -0.20576925575733185, 0.055432915687561035, 0.04532386362552643, 0.10506878793239594, -0.030368225648999214, -0.018836716189980507, 0.07701579481363297, 0.03606663644313812, -0.03807942941784859, 0.08093816041946411, 0.13179925084114075, -0.09353970736265182, 0.025008821859955788, 0.08027902990579605, 0.052069056779146194, -0.026173822581768036, 0.11467231065034866, 2.3152226276579313e-05, -0.24232631921768188, 0.10828894376754761, -0.02737666480243206, 0.07440879195928574, -0.02941102534532547, 0.13947038352489471, -0.07768677175045013, 0.14168979227542877, -0.018518922850489616, -0.1743607074022293, 0.08525905758142471, 0.08841879665851593, 0.1427888572216034, 0.03362277150154114, 0.010161980986595154, -0.08673374354839325, 0.20919525623321533, -0.15346787869930267, 0.028487952426075935, 0.09507083147764206, -0.0307893268764019, 0.1387128084897995, 0.07348132133483887, -0.12971511483192444, 1.0886505179566662e-32, -0.029883723706007004, 0.05274888500571251, -0.047713227570056915, -0.08619843423366547, -0.021505318582057953, 0.031969137489795685, -0.11955868452787399, 0.07638360559940338, -0.08156317472457886, 0.025884466245770454, -0.06760487705469131, 0.10270623117685318, -0.05666292458772659, 0.03192223608493805, 0.1548243761062622, 0.08940664678812027, -0.13338109850883484, -0.04333458095788956, 0.04464742913842201, 0.046291593462228775, 0.011529610492289066, -0.003630674909800291, 0.1061350405216217, -0.062630295753479, 0.07073114812374115, 0.06889386475086212, 0.05895966291427612, -0.07843552529811859, -0.1554143726825714, 0.03483976051211357, -0.07000324875116348, -0.05842078849673271, 0.0629512369632721, -0.11847170442342758, 0.12136313319206238, -0.05634375661611557, -0.06339982897043228, 0.1084057092666626, -0.047752223908901215, -0.03239995986223221, -0.17032872140407562, -0.02636628970503807, 0.02265128679573536, -0.04494783654808998, -0.04875532537698746, -0.005361017771065235, -0.09185826033353806, 0.06314995884895325, -0.02685382030904293, -0.01767769455909729, 0.0794713944196701, -0.15842299163341522, -0.057764600962400436, -0.005391268525272608, -0.08201069384813309, 0.0060751005075871944, 0.11555974930524826, 0.01868976280093193, 0.12435857951641083, 0.03098207898437977, 0.019990425556898117, 0.005013922695070505, 0.06927569955587387, -0.0030907003674656153, -0.06132619082927704, 0.017710436135530472, 0.04097243770956993, 0.12324877083301544, -0.05961635336279869, -0.04473953694105148, 0.030695907771587372, -0.09014029800891876, -0.02548830583691597, -0.059886567294597626, 0.11400226503610611, 0.062283970415592194, 0.18112485110759735, -0.011495120823383331, 0.015219252556562424, 0.08344867825508118, 0.022738056257367134, 0.07386981695890427, -0.04406993091106415, -0.08937616646289825, -0.16052699089050293, -0.024226268753409386, 0.11715779453516006, -0.024724820628762245, -0.1376129388809204, -0.026254860684275627, -0.13246668875217438, -0.0005262185004539788, -0.06127520650625229, -0.0024832328781485558, -0.16367530822753906, -1.3014275585513747e-32, -0.10432862490415573, 0.1584838330745697, -0.04024582356214523, 0.12212277203798294, -0.02698369324207306, 0.03578771650791168, 0.028745727613568306, -0.0461466908454895, -0.13555790483951569, -0.10911762714385986, -0.018276631832122803, -0.09482339024543762, -0.0377991683781147, 0.11812617629766464, -0.01166888140141964, 0.055356889963150024, -0.17106817662715912, 0.0024224596563726664, -0.06120200455188751, -0.021218888461589813, 0.22674235701560974, 0.1432456225156784, -0.13482213020324707, 0.07180014997720718, -0.049694810062646866, -0.050605837255716324, -0.0778437927365303, 0.13611778616905212, 0.0001648140896577388, -0.132160946726799, 0.060643769800662994, -0.10028315335512161, -0.057010337710380554, 0.007742981892079115, 0.012696665711700916, -0.04410243779420853, 0.08734264224767685, 0.005179308354854584, -0.05343905836343765, 0.10212744772434235, 0.04863297939300537, -0.012333666905760765, -0.12631215155124664, -0.040770165622234344, 0.012701288796961308, -0.06302137672901154, -0.003357755718752742, -0.012749076820909977, 0.14821378886699677, -0.00249108811840415, 0.009962943382561207, -0.11100355535745621, -0.0010624979622662067, 0.17699959874153137, -0.04373764619231224, 0.06712232530117035, -0.03930939361453056, -0.05535189062356949, -0.15448853373527527, 0.10816563665866852, -0.20373281836509705, -0.02289600484073162, 0.08898822218179703, 0.08846806734800339, 0.02669788897037506, 0.04844091460108757, 0.044627804309129715, 0.019052298739552498, -0.09955733269453049, 0.07619331777095795, -0.0015604919753968716, 0.05490834265947342, 0.024539664387702942, -0.07796358317136765, -0.021143779158592224, 0.14249412715435028, 0.023264598101377487, 0.0465741902589798, -0.06608688086271286, 0.01409341674298048, -0.05634652078151703, -0.07745060324668884, -0.001986815594136715, 0.1116190254688263, -0.007315181195735931, -0.04838458448648453, 0.11167897284030914, 0.07796084135770798, 0.06462251394987106, -0.04792821779847145, -0.042422205209732056, 0.09568481892347336, 0.025803115218877792, -0.030835194513201714, -0.1251695156097412, -1.0016994167472149e-07, -0.036238111555576324, 0.04827306419610977, 0.08715078979730606, 0.05760158225893974, 0.13059473037719727, 0.09276245534420013, -0.12980960309505463, 0.09119224548339844, -0.1081218346953392, 0.148724764585495, -0.004558484070003033, -0.11168437451124191, -0.11678741872310638, 0.009894519113004208, -0.04690594598650932, 0.07582255452871323, -0.008042541332542896, 0.07736163586378098, -0.011826789006590843, 0.03359529748558998, 0.05574730411171913, -0.10636153072118759, 0.018432332202792168, -0.007763197645545006, -0.16122066974639893, -0.14165405929088593, 0.10090222209692001, 0.11354883015155792, -0.03559894487261772, 0.045729923993349075, -0.053174201399087906, 0.0440649688243866, -0.02879244089126587, 0.024842241778969765, -0.012210240587592125, -0.004334606695920229, 0.037728406488895416, -0.04387228190898895, 0.02842174656689167, 0.049417831003665924, -0.0979362353682518, -0.11702436208724976, -0.03109750524163246, -0.06287872791290283, 0.0983806923031807, -0.04653805121779442, -0.021392283961176872, 0.040222372859716415, 0.015208128839731216, 0.12830890715122223, -0.00981453713029623, 0.09170358628034592, -0.18806475400924683, 0.11892950534820557, 0.029475724324584007, -0.04554399475455284, -0.0916031077504158, -0.18628910183906555, -0.006867152638733387, 0.0012131399707868695, 0.0858914777636528, -0.13455596566200256, -0.12342432141304016, 0.027404071763157845], metadata={'source': 'AAAMLP-569to.pdf', 'page': 50}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 51 ═════════════════════════════════════════════════════════════════════════ In [X]: from sklearn import metrics  In [X]: metrics.log_loss(y_true, y_proba) Out[X]: 0.49882711861432294 ═════════════════════════════════════════════════════════════════════════  Thus, our implementation is correct. Implementation of log loss is easy. Interpretation may seem a bit difficult. You must remember that log loss penalizes a lot more than other metrics.   For example, if you are 51% sure about a sample belonging to class 1, log loss would be:  - 1.0 * ( 1 * log(0.51) + (1 - 1) * log(1 – 0.51) ) = 0.67  And if you are 49% sure for a sample belonging to class 0, log loss would be:  - 1.0 * ( 0 * log(0.49) + (1 - 0) * log(1 – 0.49) ) = 0.67  So, even though we can choose a cut off at 0.5 and get perfect predictions, we will still have a very high log loss. So, when dealing with log loss, you need to be very careful; any non-confident prediction will have a very high log loss.  Most of the metrics that we discussed until now can be converted to a multi-class version. The idea is quite simple. Let’s take precision and recall. We can calculate precision and recall for each class in a multi-class classification problem.  There are three different ways to calculate this which might get confusing from time to time. Let’s assume we are interested in precision first. We know that precision depends on true positives and false positives.  - Macro averaged precision: calculate precision for all classes individually and then average them  - Micro averaged precision: calculate class wise true positive and false positive and then use that to calculate overall precision  - Weighted precision: same as macro but in this case, it is weighted average depending on the number of items in each class'),\n",
       " VectorParams(vector=[-0.07681126147508621, -0.05798936262726784, -0.004832413047552109, 0.002737022005021572, 0.00527396984398365, -0.1265501230955124, 0.021783795207738876, 0.13397446274757385, -0.16874313354492188, 0.022689035162329674, -0.07038141041994095, -0.06536760926246643, 0.09614291787147522, -0.046331655234098434, -0.11668747663497925, 0.029830951243638992, -0.04705743119120598, 0.08953947573900223, -0.011618615128099918, -0.01760648936033249, 0.062150415033102036, 0.15240633487701416, 0.022469215095043182, 0.14869000017642975, 0.03661230579018593, -0.23871831595897675, 0.0279606431722641, 0.09227313101291656, -0.07490307837724686, -0.008855458348989487, -0.08562779426574707, 0.05203096196055412, 0.03674374148249626, 0.10744407027959824, -0.04180740565061569, -0.023883569985628128, -0.051484402269124985, 0.012469267472624779, -0.01094961166381836, -0.03492913767695427, -0.051263608038425446, -0.052182991057634354, 0.09776101261377335, 0.005205038469284773, 0.12726478278636932, 0.21423055231571198, -0.08245662599802017, -0.08089809119701385, 0.06102580949664116, -0.13411684334278107, -0.08682238310575485, 0.12060437351465225, -0.14660711586475372, -0.06283479928970337, -0.09472524374723434, 8.321773930219933e-05, 0.14382585883140564, -0.09295690804719925, -0.0012336242944002151, -0.10215408354997635, -0.10641922801733017, -0.12323489785194397, 0.05627455189824104, -0.11665473878383636, -0.023378433659672737, 0.014296421781182289, -0.002865477465093136, 0.07015052437782288, 0.02567867375910282, 0.22975429892539978, -0.07044689357280731, 0.12281835079193115, 0.013566376641392708, 0.14949141442775726, 0.054942503571510315, -0.004396991804242134, 0.04620688408613205, 0.0892292708158493, -0.03724334388971329, 0.08256451040506363, -0.0774158239364624, -0.034179914742708206, 0.10642514377832413, -0.0927000418305397, 0.13732296228408813, -0.2493727207183838, 0.07671018689870834, 0.16823910176753998, 0.20630638301372528, 0.043656125664711, -0.06840621680021286, -0.07166808098554611, -0.07780038565397263, -0.08339757472276688, 0.05670710280537605, 0.1531813144683838, 0.06824891269207001, -0.09096987545490265, -0.028634412214159966, 0.013168711215257645, -0.08680203557014465, 0.0055766357108950615, 0.03138014301657677, -0.22164544463157654, 0.12297803163528442, 0.06274635344743729, 0.1471272110939026, -0.06534706801176071, 0.14887626469135284, -0.27785032987594604, -0.04311267286539078, -0.12463414669036865, -0.13103851675987244, -0.0015681878430768847, 0.14228448271751404, 0.0828617513179779, 0.0473429374396801, 0.12944234907627106, 0.04839419201016426, 0.10313207656145096, -0.08039182424545288, 0.077483631670475, 0.11830948293209076, 0.1746283620595932, 0.057619672268629074, -0.03936728462576866, -0.17394447326660156, 1.508634298759521e-32, -0.12233170866966248, 0.02898813784122467, 0.04611466825008392, -0.03950723260641098, -0.06857730448246002, 0.015362546779215336, 0.022908704355359077, 0.007317495532333851, -0.08312007784843445, 0.09166513383388519, -0.042593132704496384, 0.08755341917276382, -0.022718245163559914, 0.06215207651257515, 0.09651713818311691, -0.014195596799254417, -0.06356829404830933, -0.06843462586402893, 0.012039032764732838, -0.0613272488117218, 0.17115981876850128, -0.004259791225194931, 0.09061199426651001, -0.07721804082393646, -0.06900419294834137, 0.033614445477724075, -0.011107967235147953, -0.009701318107545376, -0.1527603417634964, 0.027961792424321175, -0.08435866981744766, 0.003299243748188019, 0.0998169481754303, -0.033661581575870514, 0.10584086924791336, -0.08130865544080734, 0.0800647884607315, 0.12219466269016266, 0.0644894391298294, -0.027999918907880783, 0.003914920147508383, -0.022258270531892776, 0.05534389615058899, -0.04378875344991684, -0.014357554726302624, -0.048730745911598206, -0.09757386147975922, 0.1170705184340477, 0.06923574209213257, 0.13708923757076263, -0.030851464718580246, -0.17056617140769958, -0.18170784413814545, -0.021866964176297188, -0.17411954700946808, -0.05448456108570099, 0.04333863407373428, 0.1734379380941391, 0.0010914580198004842, 0.0024223802611231804, 0.05889959633350372, 0.016277173534035683, -0.04147430136799812, -0.11189527064561844, -0.17249006032943726, 0.0941304937005043, -0.03513685613870621, 0.1494140625, 0.08887741714715958, 0.035629235208034515, 0.042786672711372375, 0.036031775176525116, -0.12050063908100128, -0.1095750629901886, 0.11897394061088562, -0.03828797861933708, 0.2276948094367981, -0.052756112068891525, 0.006891130469739437, -0.037322498857975006, 0.03047703579068184, 0.10983002185821533, -0.08658941090106964, -0.1297919899225235, -0.14261259138584137, -0.07849159836769104, 0.07363636046648026, 0.05486847832798958, -0.15484744310379028, -0.08656641095876694, -0.1467173546552658, -0.10050548613071442, 0.10776542127132416, 0.04983732849359512, -0.2389962524175644, -2.0822990518478137e-32, -0.026977036148309708, 0.19388149678707123, 0.05910997465252876, 0.1747986525297165, -0.04875023290514946, 0.04035631939768791, -0.09599006175994873, -0.02963992767035961, -0.06643181294202805, -0.144452765583992, -0.04617079719901085, -0.07895337790250778, -0.0012591546401381493, -0.0006568022654391825, 0.013407385908067226, 0.023235442116856575, -0.18040777742862701, -0.01633247546851635, -0.007988884113729, -0.0017086241859942675, 0.029064832255244255, 0.08809713274240494, -0.00019110976427327842, 0.029352547600865364, -0.10038378089666367, 0.10951372981071472, -0.12273936718702316, 0.13843342661857605, 0.03457816317677498, -0.03478386253118515, -0.08118228614330292, 0.025366676971316338, -0.0846167802810669, 0.007324054837226868, -0.0004563532129395753, -0.09659875184297562, 0.04381049424409866, -0.029391160234808922, 0.04949343204498291, 0.17150016129016876, 0.25579017400741577, -0.0304462518543005, -0.2317938655614853, -0.05235064774751663, 0.01521223597228527, 0.06733493506908417, -0.014035486616194248, 0.03189394623041153, 0.04958297312259674, -0.09542933106422424, 0.022093478590250015, 0.04472167417407036, -0.10851570963859558, 0.05098167061805725, -0.1133207157254219, 0.12870599329471588, -0.16249077022075653, -0.0077239032834768295, -0.1479077935218811, 0.06562290340662003, -0.13790898025035858, -0.07082381099462509, 0.04781213030219078, -0.01932518556714058, -0.0393940769135952, 0.1061527207493782, -0.07294023036956787, 0.03434555232524872, -0.044742047786712646, 0.09592535346746445, -0.03273383155465126, 0.16303415596485138, -0.11531638354063034, -0.1772414892911911, -0.11128368228673935, 0.05461825430393219, 0.02353527769446373, 0.0015780027024447918, -0.02718709409236908, 0.07491789013147354, -0.08732043951749802, -0.017228864133358, -0.01084155309945345, 0.008055565878748894, -0.15152759850025177, -0.017124049365520477, 0.20676714181900024, 0.07153883576393127, 0.09726604074239731, -0.04209335893392563, -0.0590948723256588, 0.17998184263706207, 0.08132332563400269, 0.011233650147914886, 0.010970556177198887, -1.014238932839362e-07, 0.07681108266115189, 0.015354720875620842, 0.014018360525369644, 0.14239585399627686, 0.1414872109889984, 0.050625648349523544, -0.13507984578609467, -0.0032281677704304457, -0.11488252133131027, -0.04287119582295418, 0.03541924059391022, -0.05871187523007393, -0.0349285751581192, -0.021785473451018333, -0.049225520342588425, 0.1222999170422554, -0.08450587838888168, 0.03585023060441017, -0.020194698125123978, 0.011374448426067829, -0.014921816997230053, -0.1462651938199997, 0.08039816468954086, -0.005202889908105135, -0.158870130777359, -0.08944066613912582, -0.05703303962945938, -0.0034602743107825518, 0.10387254506349564, 0.06382612884044647, -0.0719013661146164, -0.07248301804065704, -0.022055653855204582, -0.004293563775718212, 0.036061499267816544, 0.06748036295175552, 0.02127702906727791, -0.019534535706043243, -0.03777696192264557, -0.01854524575173855, -0.20876412093639374, -0.03975613787770271, -0.11398357897996902, -0.0007221906562335789, 0.10016262531280518, -0.07243907451629639, 0.0380953773856163, -0.019705941900610924, 0.029245750978589058, -0.03157107159495354, 0.04984690994024277, 0.19655336439609528, -0.16408787667751312, 0.029774710536003113, -0.040871210396289825, -0.01668720692396164, -0.18973486125469208, -0.10317249596118927, -0.09280618280172348, 0.01258767955005169, -0.05469226464629173, -0.032921504229307175, -0.11009819805622101, 0.007281903643161058], metadata={'source': 'AAAMLP-569to.pdf', 'page': 51}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 52 This seems complicated but is easy to understand by python implementations. Let’s see how macro-averaged precision is implemented.  ═════════════════════════════════════════════════════════════════════════ import numpy as np   def macro_precision(y_true, y_pred):     \"\"\"     Function to calculate macro averaged precision     :param y_true: list of true values     :param y_pred: list of predicted values     :return: macro precision score     \"\"\"          # find the number of classes by taking     # length of unique values in true list     num_classes = len(np.unique(y_true))          # initialize precision to 0     precision = 0          # loop over all classes     for class_ in range(num_classes):                  # all classes except current are considered negative         temp_true = [1 if p == class_ else 0 for p in y_true]         temp_pred = [1 if p == class_ else 0 for p in y_pred]                  # calculate true positive for current class         tp = true_positive(temp_true, temp_pred)                  # calculate false positive for current class         fp = false_positive(temp_true, temp_pred)                  # calculate precision for current class         temp_precision = tp / (tp + fp)                  # keep adding precision for all classes         precision += temp_precision      # calculate and return average precision over all classes     precision /= num_classes     return precision ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[-0.07873579114675522, -0.02468712441623211, 0.009198524989187717, 0.03754982724785805, -0.02235274389386177, -0.15094925463199615, -0.0036731965374201536, 0.059840403497219086, -0.06555666029453278, 0.051143255084753036, -0.07294512540102005, -0.04198015481233597, 0.05539604648947716, 0.005228765774518251, -0.11743798851966858, -0.0041059586219489574, -0.012231479398906231, 0.077907495200634, -0.03296743705868721, -0.012127232737839222, 0.07173705101013184, 0.07492583990097046, 0.0009531813557259738, 0.10201750695705414, 0.008974355645477772, -0.1614597737789154, -0.04000634700059891, 0.11751818656921387, -0.1198338195681572, -0.0065528168343007565, -0.06196864694356918, 0.04446527361869812, 0.050427988171577454, 0.006884511560201645, -0.09159842133522034, 0.014125006273388863, -0.005977424327284098, 0.0021965475752949715, 0.0049505471251904964, -0.02831236831843853, -0.019192125648260117, -0.05745670571923256, 0.06321516633033752, -0.01673569716513157, 0.102119579911232, 0.15358081459999084, -0.052857398986816406, -0.07938207685947418, -0.06191515177488327, -0.08357976377010345, -0.04695368930697441, 0.12851817905902863, -0.13773541152477264, 0.00334207178093493, -0.11344696581363678, -0.010965715162456036, 0.202890083193779, -0.0203785952180624, -0.08578287810087204, -0.024819402024149895, -0.09724833816289902, -0.13154278695583344, 0.06874839216470718, -0.07135583460330963, 0.056830424815416336, 0.0068329256027936935, -0.03751358389854431, -0.022356947883963585, 0.02171448804438114, 0.18410344421863556, 0.049007169902324677, 0.04008810967206955, -0.0522683747112751, 0.07774945348501205, 0.07806891202926636, -0.05728847160935402, 0.08665049821138382, 0.043668024241924286, 0.002434239722788334, 0.1584324836730957, -0.04269075766205788, -0.034495122730731964, -0.0008544017327949405, -0.06889887154102325, 0.12596745789051056, -0.2089012861251831, 0.010767812840640545, 0.11871123313903809, 0.12884294986724854, -0.0070210970006883144, -0.07048492133617401, 0.0009840962011367083, -0.09251944720745087, -0.05947975814342499, 0.07908280938863754, 0.10216082632541656, -0.0187545083463192, -0.09099849313497543, -0.07310070842504501, 0.01698724552989006, -0.08887497335672379, -0.01535448431968689, 0.04201636463403702, -0.16787263751029968, 0.10180302709341049, 0.036354538053274155, 0.09301634132862091, -0.018522311002016068, 0.13178296387195587, -0.22979682683944702, -0.02027890458703041, -0.07419441640377045, -0.05967125669121742, 0.06331643462181091, 0.060930415987968445, 0.06953183561563492, 0.029510676860809326, 0.0618315190076828, -0.011487925425171852, 0.1440688520669937, -0.09917239844799042, 0.04728245362639427, -0.027182791382074356, 0.12150363624095917, 0.07226718217134476, 0.030196361243724823, -0.1579790860414505, 1.7476055411891748e-32, -0.07614295929670334, 0.023557890206575394, 0.03729398176074028, -0.11468822509050369, -0.03897621110081673, -0.041849181056022644, 0.05874811112880707, -0.013355480507016182, -0.04011761024594307, 0.036847468465566635, -0.018325049430131912, 0.0686456486582756, -0.004072434734553099, 0.036993078887462616, 0.08503451943397522, -0.048732344061136246, -0.060267526656389236, -0.04724346101284027, 0.0864570140838623, -0.09582391381263733, 0.1349487006664276, 0.0096998056396842, 0.09634849429130554, -0.10614831745624542, -0.03394947946071625, 0.016862282529473305, -0.028548451140522957, 0.017938829958438873, -0.17882661521434784, 0.01474018208682537, -0.12223410606384277, -0.014814348891377449, 0.04012751951813698, -0.08732553571462631, 0.0935252457857132, -0.11922173202037811, 0.031861625611782074, 0.0637797862291336, -0.02641773782670498, -0.033259790390729904, -0.024724861606955528, 0.03645945340394974, 0.04667869210243225, 0.00892888754606247, -0.03505571931600571, 0.022258177399635315, -0.11051854491233826, 0.0797925740480423, -0.002515237545594573, 0.09997574239969254, -0.04506710171699524, -0.11052074283361435, -0.08166725188493729, -0.04895593971014023, -0.08034831285476685, -0.0035514486953616142, 0.06413786858320236, 0.11200951784849167, -0.019919773563742638, 0.00033385612186975777, 0.0834820345044136, -0.0032074269838631153, -0.0005108425975777209, -0.04509364441037178, -0.09055124223232269, 0.08573419600725174, 0.037830106914043427, 0.15990091860294342, 0.10119575262069702, 0.0204323660582304, 0.08433152735233307, 0.05824223533272743, -0.032808881253004074, -0.08620401471853256, 0.14017353951931, -0.01709606871008873, 0.2043943554162979, -0.12047097831964493, -0.04097331687808037, -0.030708251520991325, 0.060452450066804886, 0.09279539436101913, -0.07090099155902863, -0.13452209532260895, -0.16554978489875793, -0.02356564812362194, 0.04880128800868988, 0.04267590865492821, -0.10014349967241287, -0.058150459080934525, -0.17080748081207275, -0.013361609540879726, 0.026667499914765358, 0.05478324741125107, -0.18456022441387177, -2.0090246114893064e-32, -0.03847511112689972, 0.05393746495246887, 0.006845596246421337, 0.1625511646270752, -0.018819494172930717, 0.0736992359161377, -0.11003130674362183, -0.04488498345017433, -0.05706016346812248, -0.05113036185503006, -0.047799352556467056, -0.018846500664949417, -0.020910164341330528, -0.01624509133398533, 0.019692830741405487, 0.048496268689632416, -0.15544283390045166, 0.06408552825450897, 0.04734576866030693, 0.04315134510397911, 0.0895293578505516, 0.11496508121490479, -0.03241852670907974, 0.07743046432733536, -0.115480937063694, 0.006271933671087027, -0.13742876052856445, 0.11403647810220718, 0.010357803665101528, -0.053117796778678894, -0.07765600830316544, -0.05290893092751503, -0.07132699340581894, 0.009834915399551392, 0.050560105592012405, -0.04089193791151047, 0.03026347979903221, -0.03872883319854736, 0.039910607039928436, 0.12268449366092682, 0.16353915631771088, 0.031688790768384933, -0.1326756328344345, -0.06110447272658348, 0.028084101155400276, 0.011392263695597649, -0.011320737190544605, 0.008468558080494404, 0.028598668053746223, -0.05432824045419693, 0.0038796886801719666, -0.011105899699032307, -0.0695069283246994, 0.015061394311487675, -0.11528234928846359, 0.08382633328437805, -0.10124886780977249, -0.0013646023580804467, -0.09057668596506119, 0.06970496475696564, -0.14199046790599823, -0.024543369188904762, -0.00696942675858736, 0.03971792757511139, -0.05718725547194481, 0.15889008343219757, -0.03062065877020359, 0.049210160970687866, -0.020130779594182968, 0.11216418445110321, -0.048941243439912796, 0.08714030683040619, 0.018082229420542717, -0.10287056118249893, -0.09226077795028687, 0.05153501778841019, -0.03858383372426033, 0.05369168519973755, -0.06205526366829872, 0.013821260072290897, -0.041400425136089325, -0.012155014090240002, 0.0004933452000841498, 0.01700199395418167, -0.10349839180707932, -0.03370090201497078, 0.14965781569480896, 0.055956970900297165, 0.0965544730424881, -0.0553034283220768, -0.04588378593325615, 0.17011867463588715, 0.11260416358709335, -0.04509034380316734, -0.052342768758535385, -1.011918371318643e-07, 0.07957278192043304, -0.03214645758271217, 0.024700380861759186, 0.11957255750894547, 0.12031417340040207, 0.02296127751469612, -0.07112541049718857, -0.026919050142169, -0.07417157292366028, 0.01709102652966976, 0.029222415760159492, -0.011060429736971855, -0.06415586173534393, -0.02723771333694458, -0.07251416146755219, 0.16478095948696136, -0.02539338730275631, 0.0151682673022151, 0.004602820612490177, -0.019834741950035095, -0.008750366047024727, -0.08175817877054214, 0.10027577728033066, 0.022434279322624207, -0.06874635070562363, -0.05092849209904671, -0.0826864242553711, -0.01838442124426365, 0.0992787778377533, 0.1112310066819191, -0.11411651968955994, -0.06321029365062714, -0.0479809045791626, 0.07788223773241043, 0.09837190806865692, 0.07621299475431442, -0.03900311887264252, -0.011896554380655289, -0.0630204901099205, 0.007431275676935911, -0.1340099722146988, 0.023356616497039795, -0.05141494423151016, -0.018828757107257843, 0.12645286321640015, -0.032704245299100876, -0.025199485942721367, -0.05430944263935089, 0.03562307357788086, 0.030538715422153473, 0.046108365058898926, 0.1339489370584488, -0.17222507297992706, 0.0360882543027401, -0.04608302563428879, 0.008758261799812317, -0.10225376486778259, -0.17398549616336823, -0.12407194823026657, 0.014810138382017612, 0.03692685440182686, 0.03909742832183838, -0.01934373937547207, -0.0049739135429263115], metadata={'source': 'AAAMLP-569to.pdf', 'page': 52}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 53 You will notice that it wasn’t so difficult. Similarly, we have micro-averaged precision score.  ═════════════════════════════════════════════════════════════════════════ import numpy as np   def micro_precision(y_true, y_pred):     \"\"\"     Function to calculate micro averaged precision     :param y_true: list of true values     :param y_pred: list of predicted values     :return: micro precision score     \"\"\"          # find the number of classes by taking     # length of unique values in true list     num_classes = len(np.unique(y_true))          # initialize tp and fp to 0     tp = 0     fp = 0          # loop over all classes     for class_ in range(num_classes):         # all classes except current are considered negative         temp_true = [1 if p == class_ else 0 for p in y_true]         temp_pred = [1 if p == class_ else 0 for p in y_pred]                  # calculate true positive for current class         # and update overall tp         tp += true_positive(temp_true, temp_pred)                  # calculate false positive for current class         # and update overall tp         fp += false_positive(temp_true, temp_pred)              # calculate and return overall precision     precision = tp / (tp + fp)     return precision ═════════════════════════════════════════════════════════════════════════  This isn’t difficult, either. Then what is? Nothing. Machine learning is easy.   Now, let’s look at the implementation of weighted precision.'),\n",
       " VectorParams(vector=[-0.06660283356904984, -0.03380969166755676, -0.01933930814266205, 0.018332043662667274, -0.03216749429702759, -0.18223580718040466, 0.023060055449604988, 0.12669260799884796, -0.08293315768241882, 0.002361133461818099, -0.06200789287686348, -0.12373043596744537, 0.0818493664264679, -0.047311101108789444, -0.07645460963249207, -0.00477991346269846, -0.08664967864751816, 0.0440884493291378, -0.040117572993040085, -0.0938510075211525, 0.0894799456000328, 0.154310405254364, 0.046244487166404724, 0.12433181703090668, 0.02165145054459572, -0.16880349814891815, -0.023590844124555588, 0.16453178226947784, -0.1122780367732048, 0.0041245101019740105, -0.07844887673854828, 0.06209143251180649, 0.01508549228310585, 0.04069778695702553, -0.13155585527420044, -0.04791121929883957, -0.030074266716837883, -0.02875935658812523, 0.08126337826251984, -0.021753646433353424, -0.0789138600230217, -0.052484553307294846, 0.10591457039117813, 0.015842299908399582, 0.0753495991230011, 0.11884750425815582, -0.09342658519744873, -0.014782268553972244, -0.0033792168833315372, -0.045337602496147156, -0.07186626642942429, 0.18032729625701904, -0.11306338757276535, -0.03166145086288452, -0.13435913622379303, -0.036385614424943924, 0.26371774077415466, -0.16908349096775055, -0.019322894513607025, -0.03912702202796936, -0.11463582515716553, -0.10981598496437073, 0.05715208500623703, -0.13697607815265656, -0.06822705268859863, 0.006821127608418465, -0.024434473365545273, 0.06991055607795715, 0.028678027912974358, 0.22190256416797638, 0.0462651327252388, 0.12929554283618927, 0.006652541924268007, 0.13875813782215118, 0.01750250533223152, -0.02495584636926651, 0.028651118278503418, -0.011180808767676353, 0.005083742085844278, 0.08277636021375656, -0.09237393736839294, 0.031030243262648582, 0.09155834466218948, -0.015385699458420277, 0.15886464715003967, -0.25789573788642883, 0.12358546257019043, 0.1635970175266266, 0.14482925832271576, 0.009026597253978252, -0.03114970587193966, -0.008352940902113914, -0.09441567212343216, -0.022708145901560783, 0.05962245166301727, 0.1644425094127655, 0.02122167870402336, -0.06955242902040482, -0.03378049656748772, 0.004747290164232254, -0.08396749198436737, -0.04707728326320648, -0.0028142347000539303, -0.15689055621623993, 0.012575033120810986, 0.07097328454256058, 0.1393265426158905, 0.011338855139911175, 0.07705514878034592, -0.26566144824028015, 0.009576133452355862, -0.16793040931224823, -0.08131051808595657, 0.05438987538218498, 0.1675621122121811, 0.0909273698925972, 0.048048775643110275, 0.12141390144824982, -0.0771225318312645, 0.11633199453353882, -0.07414426654577255, 0.06584084779024124, 0.06153928115963936, 0.08746733516454697, 0.09382737427949905, -0.015305137261748314, -0.15411271154880524, 1.8055264090212106e-32, -0.17068199813365936, -0.021230041980743408, 0.024355502799153328, -0.09303484112024307, -0.029286831617355347, -0.06425303965806961, 0.05430574342608452, 0.03742360323667526, -0.14120888710021973, 0.05577787011861801, -0.017784325405955315, 0.07679528743028641, -0.0050892517901957035, -0.011583896353840828, 0.04690699651837349, -0.06322497129440308, -0.03315269201993942, -0.021297696977853775, 0.08056207746267319, -0.08151788264513016, 0.1759471893310547, -0.07344572246074677, 0.15305475890636444, -0.08371361345052719, -0.06399320811033249, 0.03206590563058853, -0.08022528141736984, 0.020505597814917564, -0.15426093339920044, 0.048137858510017395, -0.036706000566482544, -0.08107002079486847, 0.12383794039487839, -0.12409151345491409, 0.07822532951831818, -0.17567767202854156, 0.10101234912872314, 0.13474345207214355, 0.07235420495271683, -0.07777474075555801, 0.051717501133680344, 0.015237854793667793, 0.03813909366726875, 0.034077756106853485, -0.07053448259830475, 0.03742619603872299, -0.08544762432575226, 0.18645961582660675, 0.09568659961223602, 0.20715336501598358, -0.06958270817995071, -0.20920930802822113, -0.13493745028972626, 0.010919957421720028, -0.17138004302978516, 0.003494058270007372, 0.06369155645370483, 0.14586018025875092, 0.06744236499071121, -0.010106130503118038, 0.04607119783759117, 0.08701732009649277, -0.03453391045331955, -0.11437379568815231, -0.020878871902823448, 0.05409127101302147, 0.04164773225784302, 0.1175418347120285, 0.027772914618253708, 0.09013652056455612, 0.03244844079017639, 0.021732991561293602, -0.10948358476161957, -0.030579522252082825, 0.062470413744449615, -0.08528890460729599, 0.24398928880691528, -0.05718429759144783, -0.06986401230096817, -0.0011432694736868143, 0.061334278434515, 0.13372507691383362, -0.05120177939534187, -0.1670198142528534, -0.16266705095767975, -0.08261129260063171, 0.07270754128694534, 0.05961010977625847, -0.12335081398487091, -0.07429872453212738, -0.14943081140518188, -0.05142730847001076, -0.0253340695053339, -0.006626022048294544, -0.284250944852829, -2.122415147558326e-32, -0.052377134561538696, 0.1508287489414215, 0.11227454245090485, 0.1454489827156067, 0.03946128487586975, 0.037347372621297836, -0.12230543792247772, -0.05227372795343399, -0.019642017781734467, -0.06731805205345154, 0.018235450610518456, -0.1424262821674347, -0.055651187896728516, 0.010390539653599262, 0.07695553451776505, -0.019081220030784607, -0.18815334141254425, 0.04744608327746391, -0.06576619297266006, 0.02669673040509224, 0.07186494767665863, 0.07225369662046432, -0.05801227688789368, 0.024059105664491653, -0.16421237587928772, 0.04156114533543587, -0.1072869524359703, 0.05877862498164177, 0.036629632115364075, -0.06940903514623642, -0.06319697946310043, -0.05988215655088425, -0.016479749232530594, 0.011030709370970726, -0.003675099927932024, -0.13135968148708344, 0.11078650504350662, -0.08533376455307007, -0.02000311017036438, 0.12430369853973389, 0.214564248919487, 0.0355222187936306, -0.17790968716144562, -0.03439515084028244, 0.02187473140656948, 0.002467451384291053, -0.00034230336314067245, 0.041655752807855606, 0.012891620397567749, -0.0772712454199791, 0.033096298575401306, 0.05907930061221123, -0.10443354398012161, 0.1223263218998909, -0.04961618781089783, 0.11211943626403809, -0.10577582567930222, -0.05992446467280388, -0.14981107413768768, -0.012624927796423435, -0.12463979423046112, -0.03482478857040405, -0.01954999938607216, -0.032886311411857605, 0.049663837999105453, 0.09254723787307739, -0.07504775375127792, 0.03419434279203415, -0.06170237064361572, 0.16574066877365112, -0.15016499161720276, 0.16636091470718384, -0.036278314888477325, -0.19070759415626526, -0.11148962378501892, 0.0073029035702347755, -0.04838256537914276, 0.09654068946838379, -0.020519983023405075, 0.04508666321635246, -0.0330156534910202, -0.04918978735804558, 0.06141747161746025, -0.020661603659391403, -0.1328258216381073, 0.007912050932645798, 0.19883742928504944, 0.08595939725637436, 0.0842667743563652, -0.004245801363140345, -0.012358328327536583, 0.1233670562505722, 0.09829461574554443, 0.004905353765934706, 0.050609033554792404, -1.0172295361599026e-07, -0.00613178126513958, -0.03113158605992794, 0.06101753190159798, 0.11846635490655899, 0.10658112168312073, 0.11276277899742126, -0.0806024894118309, 0.013960257172584534, -0.09860620647668839, 0.001729654846712947, 0.04414037615060806, -0.05063239857554436, -0.05372556298971176, -0.02743309736251831, -0.1396452635526657, 0.12078854441642761, -0.05054320767521858, 0.07599012553691864, 0.0151223698630929, -0.09197631478309631, -0.01808987371623516, -0.11316954344511032, 0.16544756293296814, 0.023778170347213745, -0.16533543169498444, -0.027113167569041252, -0.07965642958879471, -0.09257934987545013, 0.12446561455726624, 0.09889382123947144, -0.05090492218732834, -0.1283808797597885, -0.07722175121307373, -0.06835375726222992, 0.1738305389881134, 0.03552970290184021, -0.06057123839855194, 0.017868656665086746, -0.02801493927836418, 0.040461961179971695, -0.1705498844385147, 0.03907481208443642, -0.12827599048614502, 0.07421454787254333, 0.2658986449241638, -0.07052706927061081, -0.09441675990819931, 0.015168300829827785, 0.09147633612155914, -0.026626884937286377, 0.05080902576446533, 0.08366937190294266, -0.17789393663406372, -0.006648439913988113, -0.11398856341838837, 0.06733281165361404, -0.1804405003786087, -0.1226842850446701, -0.13004036247730255, -0.014523935504257679, 0.07667238265275955, -0.00970740057528019, -0.04278522729873657, 0.007475302089005709], metadata={'source': 'AAAMLP-569to.pdf', 'page': 53}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 54 ═════════════════════════════════════════════════════════════════════════ from collections import Counter import numpy as np   def weighted_precision(y_true, y_pred):     \"\"\"     Function to calculate weighted averaged precision     :param y_true: list of true values     :param y_pred: list of predicted values     :return: weighted precision score     \"\"\"          # find the number of classes by taking     # length of unique values in true list     num_classes = len(np.unique(y_true))          # create class:sample count dictionary     # it looks something like this:     # {0: 20, 1:15, 2:21}     class_counts = Counter(y_true)          # initialize precision to 0     precision = 0          # loop over all classes     for class_ in range(num_classes):         # all classes except current are considered negative         temp_true = [1 if p == class_ else 0 for p in y_true]         temp_pred = [1 if p == class_ else 0 for p in y_pred]                  # calculate tp and fp for class         tp = true_positive(temp_true, temp_pred)         fp = false_positive(temp_true, temp_pred)                  # calculate precision of class         temp_precision = tp / (tp + fp)                  # multiply precision with count of samples in class         weighted_precision = class_counts[class_] * temp_precision                  # add to overall precision         precision += weighted_precision     # calculate overall precision by dividing by     # total number of samples     overall_precision = precision / len(y_true)'),\n",
       " VectorParams(vector=[-0.09265551716089249, -0.0919378474354744, -0.08818158507347107, -0.06153193116188049, -0.025502989068627357, -0.11206977069377899, -0.004715571645647287, 0.053678642958402634, -0.06662097573280334, -0.0058345128782093525, -0.06315913051366806, -0.10392801463603973, -0.004301233682781458, 0.012397697195410728, -0.057276494801044464, 0.012413166463375092, 0.05090836435556412, 0.09412532299757004, -0.07324626296758652, 0.01642591878771782, 0.14365239441394806, 0.09802396595478058, 0.0922926738858223, 0.09080996364355087, 0.04966682568192482, -0.1543559730052948, -0.0018776996294036508, 0.02966957353055477, -0.1667800396680832, -0.04774579405784607, 0.03096027672290802, 0.11583376675844193, 0.021325208246707916, -0.008164421655237675, -0.12654292583465576, 0.04981030151247978, 0.0527137815952301, -0.006420162506401539, 0.0008807036210782826, -0.014597317203879356, -0.14043807983398438, -0.034435536712408066, 0.1288430243730545, 0.010013137012720108, 0.08558320254087448, 0.04784099757671356, -0.13201221823692322, -0.10199861228466034, 0.07978519052267075, -0.05678575858473778, -0.021113282069563866, 0.18977314233779907, -0.15656809508800507, 0.13887172937393188, 0.05270185321569443, 0.0024434993974864483, 0.10477609932422638, -0.12995457649230957, 0.01774521730840206, -0.0326198972761631, -0.045469462871551514, -0.10549117624759674, -0.015429595485329628, -0.04279695078730583, -0.003722096560522914, 0.022569818422198296, -0.03148747608065605, -0.09862879663705826, 0.014670086093246937, 0.12217070907354355, -0.00647326186299324, -0.014423158951103687, -0.03204083442687988, 0.08199873566627502, -0.0016137372003868222, 0.06749243289232254, 0.10139628499746323, 0.016972312703728676, 0.01855500228703022, 0.06143861263990402, -0.031451303511857986, 0.13042661547660828, 0.0626961812376976, -0.010854732245206833, 0.1482510268688202, -0.18756163120269775, -0.02333644963800907, 0.07425612211227417, 0.09848961979150772, 0.08037286251783371, 0.09380324929952621, 0.04940398037433624, -0.03914199769496918, -0.09385950863361359, 0.031061289831995964, 0.04000862315297127, 0.06849463284015656, -0.049557410180568695, 0.025257453322410583, 0.06249809265136719, -0.025823654606938362, 0.004175350069999695, -0.023175425827503204, -0.10618717968463898, 0.12195908278226852, 0.0205261018127203, 0.13047240674495697, -0.029631905257701874, 0.12432055175304413, -0.1959667205810547, 0.022641044110059738, -0.14612194895744324, -0.13340824842453003, 0.07324349135160446, 0.04099857062101364, 0.09309900552034378, 0.045740991830825806, 0.13570494949817657, 0.03662745654582977, 0.12059430032968521, -0.1009666696190834, 0.015920329838991165, 0.08359796553850174, 0.1373993456363678, 0.05754724144935608, 0.016149114817380905, -0.16199944913387299, 9.083307865664812e-33, -0.16409236192703247, -0.002069560345262289, 0.01945166289806366, -0.1988786906003952, -0.09076208621263504, -0.04480484873056412, -0.013679235242307186, 0.023580998182296753, -0.0874050036072731, 0.046636682003736496, -0.04430495202541351, 0.15444554388523102, -0.08743958920240402, 0.01661885343492031, 0.08495067805051804, -0.0414545051753521, -0.08123736828565598, 0.009972944855690002, -0.01811649277806282, -0.05125768482685089, 0.17004361748695374, -0.06362492591142654, 0.13689740002155304, -0.05780095234513283, 0.0430053174495697, -0.016573000699281693, 0.02035144530236721, -0.04951095208525658, -0.13762159645557404, 0.07275336235761642, -0.1368132084608078, -0.0787743404507637, 0.09027010202407837, -0.0007240284467115998, 0.08334191143512726, -0.17287790775299072, -0.0059331925585865974, 0.06297976523637772, -0.013653885573148727, -0.09303014725446701, -0.0679713562130928, 0.002940431470051408, 0.03013879433274269, -0.13882744312286377, -0.08223452419042587, -0.0017833113670349121, -0.07342943549156189, 0.09321608394384384, 0.09443755447864532, 0.06141234189271927, -0.01697753742337227, -0.1860205978155136, -0.041027434170246124, 0.031445641070604324, -0.08272174745798111, 0.04560733959078789, 0.06780622154474258, 0.09801122546195984, 0.054341040551662445, 0.08941036462783813, -0.039322592318058014, 0.07481785118579865, 0.03547205403447151, -0.05472758039832115, -0.032257284969091415, 0.04005458950996399, -0.011149099096655846, 0.04872727021574974, -0.006649999413639307, 0.12763234972953796, -0.005290570203214884, 0.056512486189603806, -0.034986890852451324, -0.057622626423835754, 0.08149367570877075, -0.03265353664755821, 0.1774015575647354, -0.07039809972047806, -0.09064658731222153, -0.01660197414457798, 0.042479563504457474, 0.11640515923500061, -0.0694197341799736, -0.1283015012741089, -0.10320306569337845, 0.06814024597406387, 0.07744457572698593, -0.037551432847976685, -0.16654513776302338, -0.043573036789894104, -0.16106386482715607, -0.03212633356451988, -0.021787963807582855, 0.006741338409483433, -0.27002567052841187, -1.0361549238956599e-32, -0.01085595227777958, 0.056020986288785934, 0.02245965600013733, 0.18245647847652435, 0.0069451178424060345, 0.08651327341794968, -0.00671546021476388, -0.02641868405044079, -0.049962468445301056, -0.08251016587018967, -0.010485702194273472, -0.070963054895401, -0.07379480451345444, 0.014209426939487457, 0.10672416538000107, 0.0959339290857315, -0.1521289199590683, -0.012595975771546364, -0.09399344027042389, 0.06353438645601273, 0.11031324416399002, 0.1296112984418869, -0.034338682889938354, 0.0372382327914238, -0.09703546017408371, -0.026557207107543945, -0.012470095418393612, 0.12076424062252045, -0.08262719213962555, -0.08991775661706924, -0.03448330983519554, -0.012725256383419037, -0.07715484499931335, 0.057722341269254684, 0.0061548026278615, -0.1295856535434723, 0.1533123254776001, -0.044426191598176956, -0.05927151069045067, 0.09792279452085495, 0.12828591465950012, 0.13944821059703827, -0.24485258758068085, 0.04756670072674751, 0.032277874648571014, 0.04158243164420128, -0.06544730067253113, 0.06817951053380966, 0.0550910085439682, -0.04960574209690094, -0.04449152201414108, -0.06467901915311813, -0.12682485580444336, 0.16152936220169067, -0.08938032388687134, 0.07595328241586685, -0.05840536579489708, -0.01686236634850502, -0.12137599289417267, -0.012259338982403278, -0.11679427325725555, -0.05652787536382675, 0.02981499582529068, 0.004754288587719202, 0.11294969171285629, 0.12178384512662888, 0.045382022857666016, -0.018049798905849457, -0.13829462230205536, 0.1787843257188797, 0.020789610221982002, 0.06086694821715355, -0.009243139065802097, -0.16952580213546753, -0.0710749700665474, 0.06719629466533661, 0.07266566902399063, 0.0229573342949152, -0.03377149626612663, 0.05312224477529526, -0.021948590874671936, 0.04340559244155884, 0.1309441775083542, 0.1828220933675766, -0.0618881992995739, 0.07960271835327148, 0.15857234597206116, 0.17876605689525604, 0.031922996044158936, -0.00033859096583910286, -0.028117170557379723, 0.15593834221363068, 0.05961659178137779, -0.03188817575573921, -0.043850138783454895, -1.0001340911003354e-07, 0.0019371607340872288, -0.021053005009889603, 0.03721299767494202, 0.036687251180410385, 0.04992128536105156, 0.005389953963458538, -0.10728591680526733, 0.016235388815402985, -0.11464276909828186, -0.03382130712270737, 0.07412564754486084, -0.025561852380633354, -0.17581027746200562, -0.0311124287545681, -0.0780479684472084, -0.011415105313062668, 0.05081675201654434, 0.14552201330661774, -0.08047252893447876, -0.09172146767377853, 0.10063010454177856, -0.004690974485129118, 0.0716807171702385, -0.005593390669673681, -0.09779132157564163, -0.03287968039512634, -0.0742776095867157, -0.02176392264664173, 0.08621913194656372, 0.12966856360435486, -0.061534177511930466, -0.06577058881521225, 0.0007061530486680567, -0.04163017123937607, 0.1439971774816513, 0.06288139522075653, -0.055445704609155655, 0.05512155964970589, 0.005090585444122553, 0.029798123985528946, -0.1163736879825592, 0.015270506031811237, -0.09238841384649277, -0.029859552159905434, 0.16375669836997986, -0.027081415057182312, -0.10198938101530075, 0.02570493519306183, 0.07236622273921967, 0.015577455051243305, 0.09982388466596603, 0.050167325884103775, -0.14497777819633484, 0.11781125515699387, 0.00571378692984581, 0.020905906334519386, -0.15475572645664215, -0.19543671607971191, -0.11181692034006119, -0.0075261215679347515, 0.17137083411216736, -0.08816003054380417, -0.0726717934012413, 0.013177016749978065], metadata={'source': 'AAAMLP-569to.pdf', 'page': 54}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 55     return overall_precision ═════════════════════════════════════════════════════════════════════════  Let’s compare our implementations with scikit-learn to know if we implemented it right.  ═════════════════════════════════════════════════════════════════════════ In [X]: from sklearn import metrics  In [X]: y_true = [0, 1, 2, 0, 1, 2, 0, 2, 2]  In [X]: y_pred = [0, 2, 1, 0, 2, 1, 0, 0, 2]  In [X]: macro_precision(y_true, y_pred) Out[X]: 0.3611111111111111  In [X]: metrics.precision_score(y_true, y_pred, average=\"macro\") Out[X]: 0.3611111111111111  In [X]: micro_precision(y_true, y_pred) Out[X]: 0.4444444444444444  In [X]: metrics.precision_score(y_true, y_pred, average=\"micro\") Out[X]: 0.4444444444444444  In [X]: weighted_precision(y_true, y_pred) Out[X]: 0.39814814814814814  In [X]: metrics.precision_score(y_true, y_pred, average=\"weighted\") Out[X]: 0.39814814814814814 ═════════════════════════════════════════════════════════════════════════  It seems like we implemented everything correctly. Please note that the implementations shown here may not be the most efficient, but they are the easiest to understand.  Similarly, we can implement the recall metric for multi-class. Precision and recall depend on true positive, false positive and false negative while F1 depends on precision and recall.   Implementation for recall is left as an exercise for the reader and one version of F1 for multi-class, i.e., weighted average is implemented here.'),\n",
       " VectorParams(vector=[-0.05269201099872589, -0.006388186011463404, -0.06534270197153091, 0.04392482340335846, 0.04956436529755592, -0.08635934442281723, -0.030077176168560982, 0.06894004344940186, -0.07887385785579681, 0.017818519845604897, -0.06960294395685196, -0.12166108191013336, 0.059978071600198746, 0.00779274757951498, -0.021941469982266426, 0.0058919088914990425, -0.12229897081851959, 0.02545246295630932, -0.05229100584983826, -0.07405233383178711, 0.07966269552707672, 0.104083351790905, 0.051557254046201706, 0.1340285986661911, -0.008447195403277874, -0.08252529799938202, 0.008357240818440914, 0.17166031897068024, -0.12694421410560608, -0.025846103206276894, 0.0035140053369104862, 0.055365145206451416, 0.03184691444039345, 0.015192239545285702, -0.1296292096376419, -0.0023259047884494066, -0.1297357678413391, 0.010681083425879478, 0.055887266993522644, 0.0012428181944414973, -0.09717465192079544, -0.050719283521175385, 0.08032876253128052, 0.028628073632717133, 0.11148220300674438, 0.08834987878799438, -0.06816830486059189, 0.025360597297549248, 0.08569719642400742, -0.07032617181539536, -0.08100146055221558, 0.20681136846542358, -0.13683898746967316, -0.03202570974826813, -0.10714419931173325, -0.013107197359204292, 0.2815791070461273, -0.20440389215946198, -0.06477171182632446, -0.13232091069221497, -0.050888754427433014, -0.16707371175289154, 0.027416154742240906, -0.09822263568639755, -0.09619708359241486, -0.036633674055337906, -0.037024568766355515, 0.08999689668416977, 0.06108824163675308, 0.19573675096035004, 0.057980503886938095, 0.16827547550201416, 0.007281008642166853, 0.10252173244953156, 0.02669185772538185, 0.05076821893453598, 0.06223008781671524, -0.052459705621004105, -0.04123404249548912, 0.07830075919628143, -0.05226096510887146, -0.03761528059840202, 0.08558303117752075, -0.0160748939961195, 0.16343985497951508, -0.21132086217403412, 0.10742165148258209, 0.07310809195041656, 0.09183283150196075, 0.07074450701475143, -0.02254956215620041, 0.02129255421459675, -0.009314202703535557, -0.01683552749454975, -0.00352136860601604, 0.12316735833883286, 0.023225415498018265, -0.0984768196940422, 0.014560120180249214, 0.06334590911865234, -0.10310427844524384, 0.012991293333470821, -0.02749350666999817, -0.17067232728004456, -0.043018780648708344, 0.057044439017772675, 0.05994448810815811, 0.00721816997975111, 0.0943773165345192, -0.2525885999202728, 0.00958512257784605, -0.1838599145412445, -0.017849938943982124, 0.09712029248476028, 0.11298821121454239, 0.09003535658121109, 0.07575482875108719, 0.1397787630558014, -0.1271473467350006, 0.1684076339006424, -0.07179859280586243, 0.05975371599197388, 0.04192604869604111, 0.023517638444900513, 0.046616051346063614, -0.07552533596754074, -0.1982944905757904, 1.6997930431534475e-32, -0.1729617863893509, -0.05037899687886238, 0.006273424718528986, -0.08683475852012634, -0.02293357066810131, -0.08720679581165314, 0.028156619518995285, -0.008004045113921165, -0.10486710071563721, 0.00022312739747576416, 0.0022945492528378963, 0.03058694303035736, 0.004980369936674833, -0.05104076489806175, 0.05867202952504158, -0.06840670853853226, -0.02364342287182808, -0.027903564274311066, 0.046473100781440735, -0.06534702330827713, 0.07337735593318939, -0.040163978934288025, 0.17810311913490295, -0.09312770515680313, -0.07555988430976868, 0.06878074258565903, -0.03468271344900131, 0.00015529937809333205, -0.10371704399585724, 0.034886471927165985, -0.04093485698103905, -0.04517320916056633, 0.03714512288570404, -0.08490774035453796, 0.05361692234873772, -0.15589040517807007, 0.10430434346199036, 0.05823312699794769, 0.06325503438711166, -0.11696263402700424, 0.00915441382676363, -0.010169531218707561, 0.05483100935816765, 0.0388399139046669, -0.09840398281812668, 0.0018512664828449488, -0.033764880150556564, 0.17103958129882812, 0.050604429095983505, 0.28331151604652405, -0.07316987216472626, -0.20762839913368225, -0.11631488054990768, 0.029246242716908455, -0.15065711736679077, 0.01461055502295494, 0.009794408455491066, 0.19579745829105377, 0.10986868292093277, 0.03180815652012825, 0.06345805525779724, 0.07155408710241318, -0.024331487715244293, -0.027236592024564743, 0.007435827516019344, 0.0808335468173027, 0.006169338244944811, 0.0614100880920887, 0.039177991449832916, 0.10680389404296875, 0.08652711659669876, 0.024028852581977844, -0.08796985447406769, -0.036423295736312866, 0.057204969227313995, -0.03794192895293236, 0.1983223557472229, -0.09617166966199875, -0.052338819950819016, -0.030914081260561943, 0.02530875988304615, 0.13814203441143036, -0.06231886148452759, -0.1342698186635971, -0.14884531497955322, -0.061763521283864975, 0.08139180392026901, 0.006095129065215588, -0.09283910691738129, -0.022513866424560547, -0.14956799149513245, -0.06549260765314102, -0.02977662906050682, -0.010335071943700314, -0.20752733945846558, -1.9457960927897202e-32, -0.061128705739974976, 0.1327049285173416, 0.06961135566234589, 0.11064363270998001, 0.08986707776784897, 0.017180277034640312, -0.11632134020328522, -0.07303281873464584, -0.007401161827147007, -0.052695415914058685, 0.00744137167930603, -0.13181056082248688, -0.05357854813337326, 0.04878835752606392, 0.09549768269062042, -0.0365239717066288, -0.09938688576221466, 0.0479346364736557, -0.13542869687080383, 0.037373531609773636, 0.05745132640004158, 0.08015459775924683, -0.052665699273347855, 0.023656778037548065, -0.21812182664871216, 0.057798340916633606, -0.04244091734290123, 0.0046337624080479145, 0.01399906538426876, -0.04864780232310295, -0.04484039545059204, -0.0021982172038406134, -0.014692278578877449, 0.03466929495334625, 0.00156543985940516, -0.05633021146059036, 0.138898104429245, -0.08084452152252197, -0.06590836495161057, 0.14869602024555206, 0.17454734444618225, 0.08993949741125107, -0.15477025508880615, -0.05925634503364563, 0.01709229312837124, -0.06757432967424393, 0.009322342462837696, -0.0032000476494431496, 0.07697421312332153, -0.02421269752085209, -0.026687517762184143, 0.03624310716986656, -0.11822093278169632, 0.1133328229188919, -0.03600793704390526, 0.06075509637594223, -0.12673752009868622, -0.0721464455127716, -0.10482590645551682, 0.01691289246082306, -0.10968665778636932, -0.04596041515469551, -0.06751420348882675, 0.008594946004450321, 0.04091738164424896, 0.08429131656885147, -0.04061516374349594, 0.03304057940840721, -0.025287479162216187, 0.19707223773002625, -0.10323239862918854, 0.17595727741718292, -0.010990501381456852, -0.16756384074687958, -0.1050441637635231, -0.00018688570708036423, -0.06805025041103363, 0.11256631463766098, -0.01327164564281702, 0.0354347825050354, -0.058122746646404266, -0.05981706455349922, 0.06659402698278427, 0.025750063359737396, -0.11630911380052567, 0.01408213097602129, 0.18863049149513245, 0.05941697955131531, 0.07292336970567703, -0.017515169456601143, 0.041245732456445694, 0.15666741132736206, 0.16341865062713623, 0.06719030439853668, 0.06379592418670654, -1.0132380623417703e-07, 0.003048049286007881, -0.10478608310222626, 0.08050911128520966, 0.15528930723667145, 0.1607060581445694, 0.05773244798183441, -0.12547867000102997, -0.07109257578849792, -0.11300815641880035, 0.026895780116319656, 0.08265964686870575, -0.04455970600247383, -0.025959715247154236, -0.016405150294303894, -0.15739737451076508, 0.12259702384471893, 0.01604033261537552, 0.11733545362949371, -0.004432820715010166, -0.059940047562122345, 0.02328445389866829, -0.12524348497390747, 0.07906711101531982, 0.051239218562841415, -0.07356967031955719, -0.07322323322296143, -0.03137444704771042, -0.10085706412792206, 0.11862578243017197, 0.10294976085424423, -0.06565918773412704, -0.09477025270462036, -0.057120922952890396, -0.08103145658969879, 0.1514616161584854, 0.015286552719771862, -0.011418073438107967, 0.02650529332458973, -0.08800405263900757, 0.015169830992817879, -0.15851964056491852, 0.007111160550266504, -0.11913879215717316, 0.05838915705680847, 0.23778557777404785, -0.08127480745315552, -0.16403043270111084, 0.01057993620634079, 0.09533306956291199, -0.08965698629617691, -0.022033343091607094, 0.11354216933250427, -0.14927124977111816, 0.014879156835377216, -0.062385283410549164, 0.11071936041116714, -0.20904973149299622, -0.07476799935102463, -0.15767748653888702, -0.050441741943359375, 0.08372452110052109, -0.05077263340353966, -0.010711880400776863, -0.026508716866374016], metadata={'source': 'AAAMLP-569to.pdf', 'page': 55}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 56 ═════════════════════════════════════════════════════════════════════════ from collections import Counter import numpy as np   def weighted_f1(y_true, y_pred):     \"\"\"     Function to calculate weighted f1 score     :param y_true: list of true values     :param y_proba: list of predicted values     :return: weighted f1 score     \"\"\"          # find the number of classes by taking     # length of unique values in true list     num_classes = len(np.unique(y_true))          # create class:sample count dictionary     # it looks something like this:     # {0: 20, 1:15, 2:21}     class_counts = Counter(y_true)          # initialize f1 to 0     f1 = 0          # loop over all classes     for class_ in range(num_classes):         # all classes except current are considered negative         temp_true = [1 if p == class_ else 0 for p in y_true]         temp_pred = [1 if p == class_ else 0 for p in y_pred]                  # calculate precision and recall for class         p = precision(temp_true, temp_pred)         r = recall(temp_true, temp_pred)                  # calculate f1 of class         if p + r != 0:             temp_f1 = 2 * p * r / (p + r)         else:             temp_f1 = 0                  # multiply f1 with count of samples in class         weighted_f1 = class_counts[class_] * temp_f1                  # add to f1 precision         f1 += weighted_f1'),\n",
       " VectorParams(vector=[-0.013441508635878563, -0.0669342577457428, -0.11736491322517395, -0.06436135619878769, 0.04563092440366745, -0.0654139295220375, 0.0422808937728405, 0.13002616167068481, -0.03703303635120392, 0.10805875062942505, -0.08149147778749466, -0.12299952656030655, 0.00019507370598148555, -0.019718827679753304, -0.06003987416625023, -0.051648057997226715, -0.04901362210512161, 0.07198352366685867, -0.11803361028432846, 0.13338489830493927, 0.18149584531784058, 0.12434503436088562, 0.07329875975847244, 0.1387733519077301, -0.11595841497182846, -0.06902783364057541, -0.06502361595630646, 0.045024409890174866, -0.1974281370639801, -0.04997434467077255, -0.0490703321993351, 0.19045646488666534, -0.022727683186531067, 0.061113495379686356, -0.14011289179325104, -0.0012576580047607422, 0.01772640272974968, 0.04844807833433151, 0.031036367639899254, 0.0322294682264328, -0.10258083045482635, 0.008908950723707676, 0.05383099243044853, 0.05970989912748337, 0.06106053292751312, -0.0018516494892537594, -0.1368529200553894, -0.02845008671283722, 0.02817496843636036, 0.049311283975839615, -0.004043848719447851, 0.28071677684783936, -0.12446574866771698, 0.012497203424572945, -0.00024603898054920137, -0.06560151278972626, 0.09563418477773666, -0.11793259531259537, -0.07195053994655609, 0.029523087665438652, -0.06462201476097107, -0.10494502633810043, -0.010186917148530483, -0.1012439951300621, 0.11302366852760315, 0.007287424523383379, -0.16017450392246246, -0.10251802951097488, 0.05142105370759964, 0.1093529611825943, -0.04789092019200325, -0.05990675091743469, -0.02150999940931797, 0.042689573019742966, -0.060033559799194336, 0.04850688949227333, 0.1451459378004074, 0.15030524134635925, -0.01939968205988407, 0.15336865186691284, 0.005769698414951563, 0.1675499826669693, 0.03482561931014061, -0.05553610622882843, 0.16047005355358124, -0.17861495912075043, -0.005984301678836346, 0.08500129729509354, 0.08090072125196457, 0.10645454376935959, 0.03089854121208191, 0.03047017753124237, 0.0647025927901268, -0.052325353026390076, 0.14339679479599, 0.07026876509189606, -0.006804245989769697, 0.009276261553168297, 0.08870462328195572, 0.03480095416307449, 0.01204113382846117, 0.07454483956098557, -0.03586237505078316, -0.1533709615468979, -0.002882251748815179, 0.03545204550027847, 0.02820676378905773, 0.1070914939045906, 0.17271094024181366, -0.23402433097362518, 0.004396415315568447, -0.0840008556842804, -0.18246865272521973, 0.028025491163134575, -0.050229866057634354, 0.12135318666696548, 0.038124289363622665, 0.0648471936583519, 0.07907918095588684, 0.18224740028381348, -0.13723686337471008, 0.005550863686949015, 0.0996779054403305, 0.11151881515979767, 0.14426960051059723, -0.12941201031208038, -0.17920051515102386, 8.606725721642994e-33, -0.18183618783950806, 0.005708504468202591, -0.03385563939809799, -0.013070875778794289, -0.0423630066215992, -0.06727144867181778, -0.020460478961467743, 0.044407375156879425, -0.034911058843135834, 0.05351181700825691, 0.01372101716697216, 0.1230345070362091, -0.04003322497010231, 0.00504924263805151, 0.010182284750044346, 0.035197027027606964, -0.1200927123427391, -0.05819986015558243, -0.004480970092117786, -0.08643493801355362, 0.1664964258670807, 0.08674383163452148, 0.1922023743391037, -0.059755515307188034, 0.018068769946694374, 0.0579410120844841, -0.037293609231710434, -0.04948855936527252, -0.05650715529918671, 0.031171202659606934, -0.08780259639024734, -0.1275787502527237, 0.14584289491176605, -0.08126640319824219, 0.0668254941701889, -0.10080814361572266, 0.00941274594515562, 0.046643804758787155, -0.03173387423157692, -0.11354321241378784, -0.08459168672561646, -0.0033088945783674717, 0.04010613635182381, -0.07412438094615936, -0.05892537906765938, -0.021961674094200134, -0.010588269680738449, 0.1126253679394722, 0.04310160130262375, 0.14950409531593323, 0.007565077394247055, -0.18518979847431183, 0.011995282955467701, 0.057174693793058395, -0.0602760948240757, 0.049413103610277176, 0.07870703190565109, 0.04954954609274864, 0.05384090542793274, 0.14787667989730835, -0.0064901732839643955, 0.025552961975336075, -0.012584112584590912, -0.07582499831914902, -0.06601400673389435, 0.03804653510451317, -0.004408728331327438, 0.04490235075354576, 0.057807806879282, 0.04506160318851471, -0.028127487748861313, -0.021775994449853897, 0.005657688248902559, -0.04111321642994881, 0.06881480664014816, 0.005822410807013512, 0.1424008309841156, -0.11168764531612396, -0.1116660088300705, -0.024165263399481773, 0.07959459722042084, 0.08870772272348404, -0.08570152521133423, -0.06756559759378433, -0.27496570348739624, -0.03486431762576103, 0.1054641380906105, -0.05210964009165764, -0.11982197314500809, 0.00033394116326235235, -0.02565416693687439, 0.008436704985797405, -0.09842441231012344, 0.0023894591722637415, -0.10941533744335175, -9.307858143398578e-33, -0.08967699855566025, 0.00902180839329958, -0.05416705086827278, 0.11717929691076279, 0.015734294429421425, 0.007745756767690182, 0.036122728139162064, -0.08545995503664017, -0.030311686918139458, -0.06943012028932571, -0.037362948060035706, -0.10944938659667969, -0.10416125506162643, 0.053366050124168396, -0.030582666397094727, 0.06074395403265953, -0.11843375116586685, 0.04275253042578697, -0.0900987759232521, 0.07680043578147888, 0.09349246323108673, 0.18705500662326813, -0.03164463862776756, -0.027486229315400124, -0.11069082468748093, 0.11010952293872833, 0.004630228038877249, 0.08486232161521912, 0.053497713059186935, -0.044639382511377335, -0.04046419635415077, -0.059153009206056595, -0.015795744955539703, 0.10971923917531967, 0.09042847156524658, -0.12907849252223969, 0.08011043816804886, -0.05956007167696953, -0.006686629727482796, 0.10920868068933487, 0.07372598350048065, 0.15320107340812683, -0.14549677073955536, -0.05540831387042999, -0.0022309620399028063, 0.03268834203481674, -0.022782493382692337, 0.042319077998399734, 0.061305999755859375, -0.011813097633421421, 0.017311321571469307, -0.04146233946084976, -0.07414565235376358, 0.17656424641609192, -0.06778565794229507, 0.0942310318350792, -0.05887462571263313, -0.03605237230658531, -0.174343079328537, 0.11061706393957138, -0.0344485342502594, 0.05607646703720093, 0.038475316017866135, -0.0025454361457377672, 0.10527533292770386, -0.0266150813549757, -0.008051353506743908, 0.010155034251511097, -0.1344939023256302, 0.20785903930664062, -0.11211641877889633, 0.020401611924171448, -0.018215414136648178, -0.1491677314043045, 0.0841146782040596, 0.05046524479985237, -0.030365655198693275, 0.07177480310201645, -0.06547844409942627, 0.029427260160446167, -0.043297093361616135, -0.0009828058537095785, 0.04910250008106232, 0.24342739582061768, -0.10876300185918808, 0.08600068837404251, 0.22290171682834625, 0.10756633430719376, 0.012169457972049713, -0.07616692781448364, 0.0407942496240139, 0.1397591233253479, 0.12109772861003876, -0.003233662573620677, -0.10118547081947327, -9.936380962471958e-08, -0.053685255348682404, -0.018428895622491837, 0.033956751227378845, 0.017346298322081566, 0.06629450619220734, -0.011264120228588581, -0.10091991722583771, 0.026772771030664444, -0.09364213049411774, 0.1308651566505432, -0.0010528587736189365, -0.014027518220245838, -0.15843649208545685, -0.13738396763801575, -0.12107691168785095, 0.03836657851934433, 0.00889962911605835, 0.07587318122386932, -0.0008513894281350076, -0.051568403840065, 0.01858556643128395, -0.07132350653409958, 0.014864305034279823, -0.01880236528813839, -0.09255274385213852, -0.0987597182393074, -0.02774551324546337, 0.13256610929965973, 0.07814157754182816, 0.06153053417801857, -0.060687512159347534, -0.06649667769670486, -0.010818872600793839, -0.017608672380447388, 0.019234325736761093, 0.042036935687065125, 0.08168411254882812, -0.07134676724672318, -0.05705897882580757, 0.06262873113155365, -0.12022547423839569, -0.02663690783083439, -0.046914003789424896, -0.07039231806993484, 0.08927000313997269, 0.007117416709661484, -0.11860154569149017, 0.06816834956407547, -0.01010885275900364, -0.010750447399914265, 0.002718368312343955, 0.07897340506315231, -0.22689498960971832, 0.1104404404759407, 0.003988509066402912, -0.0788276344537735, -0.12261637300252914, -0.18954026699066162, -0.03764551132917404, 0.007927430793642998, 0.10009375214576721, 0.09748448431491852, -0.05037722364068031, 0.027635488659143448], metadata={'source': 'AAAMLP-569to.pdf', 'page': 56}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 57     # calculate overall F1 by dividing by     # total number of samples     overall_f1 = f1 / len(y_true)     return overall_f1 ═════════════════════════════════════════════════════════════════════════  Note that there are a few lines of code above which are new. And that’s why you should read the code carefully.  ═════════════════════════════════════════════════════════════════════════ In [X]: from sklearn import metrics  In [X]: y_true = [0, 1, 2, 0, 1, 2, 0, 2, 2]  In [X]: y_pred = [0, 2, 1, 0, 2, 1, 0, 0, 2]  In [X]: weighted_f1(y_true, y_pred) Out[X]: 0.41269841269841273  In [X]: metrics.f1_score(y_true, y_pred, average=\"weighted\") Out[X]: 0.41269841269841273 ═════════════════════════════════════════════════════════════════════════  Thus, we have precision, recall and F1 implemented for multi-class problems. You can similarly convert AUC and log loss to multi-class formats too. This format of conversion is known as one-vs-all. I’m not going to implement them here as the implementation is quite similar to what we have already discussed.  In binary or multi-class classification, it is also quite popular to take a look at confusion matrix. Don’t be confused; it’s quite easy. A confusion matrix is nothing but a table of TP, FP, TN and FN. Using the confusion matrix, you can quickly see how many samples were misclassified and how many were classified correctly.  One might argue that the confusion matrix should be covered quite early in this chapter, but I chose not to do it. If you understand TP, FP, TN, FN, precision, recall and AUC, it becomes quite easy to understand and interpret confusion matrix. Let’s see what confusion matrix looks like for a binary classification problem in figure 7.  We see that the confusion matrix is made up of TP, FP, FN and TN. These are the only values we need to calculate precision, recall, F1 score and AUC. Sometimes, people also prefer calling FP as Type-I error and FN as Type-II error.'),\n",
       " VectorParams(vector=[-0.0440586619079113, -0.07254879176616669, -0.07772261649370193, -0.03795816749334335, 0.18363197147846222, -0.050414472818374634, 0.03546174615621567, -0.08806148171424866, -0.0014533059438690543, -0.04643923416733742, -0.07184141874313354, -0.12226253747940063, 0.0653391107916832, -0.11098534613847733, -0.15176653861999512, 0.03077957034111023, -0.03370237350463867, -0.08822889626026154, -0.05963417887687683, 0.042333509773015976, 0.24105441570281982, 0.06555750221014023, 0.11621874570846558, 0.09908424317836761, -0.09086516499519348, 0.05092015862464905, 0.07239940762519836, 0.025940624997019768, 0.0014322418719530106, -0.07032179832458496, -0.10064283758401871, 0.13868966698646545, -0.018200073391199112, 0.058774299919605255, -0.042442645877599716, -0.05716817080974579, 0.029442576691508293, 0.1449010968208313, 0.055037565529346466, 0.23929786682128906, 0.06717809289693832, 0.13107261061668396, 0.09087521582841873, 0.10755975544452667, 0.06447885185480118, 0.12884536385536194, -0.049558237195014954, -0.08592283725738525, -0.056267037987709045, -0.12266072630882263, -0.1557636260986328, 0.026460280641913414, -0.07376863062381744, -0.002757251961156726, -0.15387877821922302, -0.14374645054340363, -0.023513231426477432, -0.012023022398352623, -0.05854790285229683, 0.10002860426902771, -0.013837597332894802, -0.14431414008140564, 0.08241529762744904, -0.11136145889759064, 0.09578423947095871, 0.06178956851363182, -0.14637230336666107, 0.016928542405366898, -0.06972922384738922, 0.12451047450304031, -0.08227942883968353, 0.05152465030550957, 0.027895284816622734, 0.040645938366651535, 0.019775325432419777, 0.027309993281960487, 0.14476986229419708, 0.18248724937438965, 0.031750813126564026, 0.12596285343170166, -0.05130426585674286, -0.01413346640765667, 0.021916065365076065, -0.08068029582500458, 0.09248987585306168, -0.10361341387033463, -0.06873265653848648, 0.004561297595500946, 0.12880262732505798, 0.09265794605016708, -0.1481553465127945, -0.09579269587993622, 0.014719762839376926, 0.009921638295054436, 0.10146505385637283, 0.21032366156578064, 0.03875809162855148, 0.024540020152926445, 0.0976671352982521, 0.11999787390232086, -0.04863908141851425, 0.024890711531043053, 0.06800981611013412, -0.06921268999576569, 0.017216328531503677, 0.07424460351467133, -0.027933932840824127, 0.03492428734898567, 0.14469416439533234, -0.26208004355430603, 0.07685872912406921, -0.12943889200687408, -0.16646228730678558, 0.052955616265535355, -0.06637141108512878, 0.10197100788354874, -0.0037380873691290617, 0.03990759700536728, -0.010764870792627335, 0.13660813868045807, -0.0678398609161377, -0.018098101019859314, 0.14397269487380981, 0.018915927037596703, -0.0011573761003091931, -0.025614894926548004, -0.25197866559028625, 4.263510663592744e-33, -0.056925415992736816, -0.030873965471982956, 0.015256756916642189, 0.06708959490060806, 0.04680829867720604, -0.13013365864753723, -0.07458405196666718, -0.0087581817060709, 0.05339771509170532, 0.06387478113174438, 0.10735773295164108, -0.012670180760324001, 0.0682462602853775, 0.1958710104227066, -0.07260798662900925, 0.011208689771592617, -0.03271464258432388, 0.07468276470899582, -0.1109008938074112, -0.11972003430128098, 0.05225749313831329, 0.17734523117542267, 0.06443625688552856, -0.18351799249649048, -0.06735639274120331, 0.06780500710010529, 0.010161669924855232, -0.04960956424474716, 0.016291078180074692, -0.046398743987083435, -0.05555928125977516, 0.022138342261314392, 0.06394321471452713, -0.006014294922351837, 0.03484140336513519, -0.04069347679615021, 0.07095687091350555, 0.053972017019987106, 0.055058564990758896, -0.14571018517017365, 0.04341545328497887, -0.013561345636844635, 0.10177788883447647, -0.07017094641923904, -0.043312184512615204, -0.05662739649415016, 0.040743373334407806, -0.03643226996064186, -0.09190592914819717, 0.07980497926473618, 0.03689480200409889, -0.12000863254070282, -0.09020666033029556, 0.05086741968989372, -0.053642936050891876, 0.00692642480134964, 0.0735425278544426, 0.03603160381317139, 0.025500182062387466, 0.10636622458696365, 0.007253220304846764, -0.012015079148113728, -0.02917962521314621, -0.03502553701400757, -0.07331696897745132, 0.08744724839925766, -0.03557826951146126, -0.04608713090419769, 0.21092195808887482, -0.018170392140746117, 0.009680029936134815, 0.037220556288957596, -0.10805941373109818, -0.08273959159851074, 0.08806154876947403, -0.01861153356730938, 0.0244163665920496, -0.046330731362104416, -0.09658953547477722, 0.12910696864128113, 0.1271904855966568, -0.002167494734749198, 0.004395447671413422, -0.06385330855846405, -0.3071131706237793, -0.0223096814006567, 0.09023512154817581, -0.1078047826886177, -0.08221087604761124, 0.019639596343040466, -0.04712013900279999, -0.06621576100587845, -0.0763988196849823, 0.05554545670747757, -0.0859077200293541, -6.806932198570743e-33, -0.05183252692222595, 0.05600009113550186, -0.03471525013446808, 0.09088414907455444, -0.010466381907463074, -0.028827505186200142, 0.0035400455817580223, 0.11110541224479675, -0.038519516587257385, -0.07593854516744614, 0.020189348608255386, 0.06896202266216278, 0.04240047559142113, 0.109611876308918, -0.09719771891832352, 0.04016115888953209, -0.015359723009169102, 0.018031449988484383, 0.020185858011245728, -0.0023838402703404427, 0.16243930160999298, 0.2007986605167389, -0.04149765893816948, 0.04940272495150566, -0.10120300203561783, 0.1714160144329071, -0.004612382967025042, 0.1833045929670334, 0.10616759955883026, 0.02175736427307129, 0.014533293433487415, -0.19761154055595398, -0.0030440313275903463, 0.04984671249985695, 0.11745675653219223, 0.02894732914865017, -0.029943998903036118, -0.060171548277139664, 0.0025154247414320707, 0.10062848776578903, 0.013631895184516907, -0.04903510957956314, -0.14394575357437134, 0.09211137890815735, -0.07264858484268188, -0.008377046324312687, 0.09868589788675308, 0.10157279670238495, -0.0020479094237089157, -0.05301927030086517, -0.05309063196182251, 0.10385849326848984, -0.13833899796009064, 0.12306752800941467, 0.024389715865254402, 0.06604232639074326, -0.2138376235961914, 0.03926672041416168, -0.00456797331571579, 0.15753746032714844, -0.1131809800863266, 0.04896801337599754, -0.0880136713385582, -0.04081697762012482, 0.02040492370724678, 0.027888720855116844, -0.19391050934791565, -0.024570174515247345, 0.001638743793591857, 0.1670621633529663, 0.030672041699290276, 0.12828192114830017, -0.12400659918785095, -0.2086755633354187, 0.009259500540792942, 0.08164621144533157, -0.03149402514100075, -0.04159120097756386, -0.06223160773515701, 0.026133237406611443, -0.21329478919506073, -0.11514294147491455, 0.04600623995065689, 0.18602600693702698, 0.011854341253638268, -0.028949178755283356, 0.2605341076850891, 0.04396139830350876, 0.06145106256008148, -0.05615663528442383, 0.08428515493869781, 0.05842391029000282, -0.012132693082094193, 0.12231922149658203, -0.1447247862815857, -9.93311601860114e-08, -0.10042180866003036, -0.006563900038599968, -0.002585165435448289, -0.032060135155916214, 0.18287526071071625, -0.11965515464544296, -0.016927162185311317, 0.1256365180015564, -0.11497880518436432, 0.055244795978069305, 0.025801757350564003, -0.10427512228488922, -0.08599475026130676, -0.0003039164002984762, -0.08734884113073349, 0.13559643924236298, -0.12430831044912338, 0.0894329696893692, 0.01474347710609436, 0.016384363174438477, 0.01402615662664175, -0.21427184343338013, 0.06084231287240982, 0.022075073793530464, -0.0838034376502037, -0.11937877535820007, -0.009763041511178017, 0.14437846839427948, 0.04490572214126587, 0.019137563183903694, -0.08922599256038666, -0.039616525173187256, -0.0021460172720253468, -0.01899338699877262, -0.07030648738145828, 0.08727281540632248, -0.14530381560325623, -0.04918796941637993, 0.05995628237724304, -0.07497485727071762, -0.12995830178260803, -0.16401363909244537, -0.001478506368584931, 0.03670986741781235, 0.06598196923732758, -0.047084227204322815, -0.07726352661848068, -0.19366765022277832, -0.051160965114831924, -0.14911894500255585, -0.033059537410736084, 0.07032037526369095, -0.11762616783380508, 0.12095322459936142, 0.04928746819496155, -0.07197178155183792, -0.17225858569145203, -0.0639818012714386, -0.036764346063137054, 0.16163022816181183, 0.009521059691905975, 0.16486868262290955, -0.13702410459518433, 0.05117802321910858], metadata={'source': 'AAAMLP-569to.pdf', 'page': 57}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 58  Figure 7: Confusion matrix for a binary classification task  We can also expand the binary confusion matrix to a multi-class confusion matrix. How would that look like? If we have N classes, it will be a matrix of size NxN. For every class, we calculate the total number of samples that went to the class in concern and other classes. This can be best understood by an example.  Suppose we have the following actual classes:  [0, 1, 2, 0, 1, 2, 0, 2, 2]  And our predictions are:  [0, 2, 1, 0, 2, 1, 0, 0, 2]  Then our confusion matrix will look as shown in figure 8.  What does figure 8 tell us?   Let’s look at class 0. We see that there are 3 instances of class 0 in the actual target. However, in prediction, we have 3 instances that belong to class 0 and 1 instance that belongs to class 1. Ideally, for class 0 in the actual label, predicted labels 1 and 2 shouldn’t have any instance. Let’s see class 2. In actual labels, this count adds up to 4 while in predicted it adds up to 3. Only 1 instance has a perfect prediction for class 2 and 2 instances go to class 1.   A perfect confusion matrix should only be filled diagonally from left to right.'),\n",
       " VectorParams(vector=[-0.027575446292757988, -0.1350681036710739, -0.03612537309527397, -0.06905562430620193, 0.10998900234699249, -0.12542705237865448, 0.021165069192647934, 0.0008480162941850722, -0.0449485145509243, -0.00975067913532257, -0.03866184502840042, -0.21582761406898499, -0.04349800944328308, -0.06730035692453384, -0.03734719008207321, 0.0257498137652874, -0.04495067149400711, -0.030242426320910454, -0.03879861161112785, 0.018171563744544983, 0.14734308421611786, 0.08138643950223923, -0.04376153647899628, 0.10838276892900467, -0.00038527516881003976, -0.022121254354715347, 0.16480955481529236, 0.10508192330598831, -0.16811136901378632, 0.04553095996379852, 0.055673155933618546, 0.03742440417408943, -0.103705495595932, 0.02677292749285698, -0.020454639568924904, 0.07703237980604172, 0.00014167696645017713, 0.09922832995653152, -0.06734872609376907, 0.19242647290229797, -0.046302009373903275, 0.06441238522529602, 0.13573776185512543, 0.07936979830265045, 0.04869096726179123, 0.05522308871150017, -0.22553206980228424, -0.06613284349441528, 0.02575322613120079, -0.06543044000864029, -0.14600640535354614, -0.003930593375116587, -0.11014605313539505, -0.1388247311115265, 0.05056285113096237, -0.03220613673329353, -0.009775413200259209, -0.11888383328914642, 0.13421161472797394, -0.23242957890033722, -0.06970644742250443, -0.1264132261276245, -0.007897505536675453, -0.09511341899633408, 0.12568826973438263, 0.03680200129747391, -0.11587858945131302, -0.051795970648527145, -0.05146298557519913, 0.17326804995536804, -0.09613929688930511, -0.001404674258083105, 0.08774086833000183, 0.04505957290530205, -0.05204840749502182, 0.09163882583379745, 0.18856237828731537, 0.11881810426712036, -0.03688163682818413, -0.03628892824053764, -0.020156659185886383, 0.10596358776092529, -0.03520345315337181, 0.0642428994178772, 0.06787867099046707, -0.13736367225646973, -0.0767587199807167, 0.14175786077976227, 0.060565825551748276, -0.008073699660599232, 0.10959311574697495, -0.027530401945114136, -0.027532707899808884, -0.07797861844301224, 0.029398368671536446, 0.1358584612607956, 0.14494863152503967, 0.016002777963876724, 0.03190058097243309, 0.03468012064695358, 0.025244135409593582, -0.15612933039665222, -0.08054550737142563, -0.02199314720928669, 0.07888349145650864, 0.03475889191031456, 0.08267723023891449, 0.07520950585603714, 0.12664805352687836, -0.17419566214084625, -0.01245346013456583, -0.10954183340072632, -0.16360627114772797, 0.08714842051267624, 0.08767694234848022, 0.1397872269153595, 0.00032963682315312326, 0.09938061237335205, 0.010620316490530968, 0.12132860720157623, -0.05771925672888756, 0.04533510282635689, 0.13290640711784363, 0.14794227480888367, -0.06945188343524933, -0.08692605048418045, -0.1734224557876587, 9.231557539770673e-33, -0.050124943256378174, -0.035762570798397064, -0.024150298908352852, 0.0055155628360807896, -0.0036018257960677147, -0.004242557566612959, -0.15741828083992004, 0.02572759799659252, -0.02840726636350155, 0.026109112426638603, -0.06640792638063431, 0.08863631635904312, -0.05404452607035637, -0.008828336372971535, -0.05173975229263306, -0.007079277187585831, 0.006187326740473509, -0.06883885711431503, -0.15042029321193695, -0.09449828416109085, 0.04990841820836067, 0.056847333908081055, 0.06413520127534866, -0.12237432599067688, -0.06688444316387177, -0.06167999282479286, -0.0122380331158638, -0.06599590182304382, -0.025035273283720016, 0.004790079779922962, -0.04974633455276489, 0.04575848951935768, 0.0432562455534935, 0.0290300864726305, 0.014393040910363197, -0.07016075402498245, -0.0104534812271595, 0.0842854306101799, -0.05846608057618141, -0.08892811089754105, 0.01595400460064411, 0.03161279857158661, 0.03976402059197426, -0.08810954540967941, 0.00744367903098464, 0.061467017978429794, -0.005509658250957727, 0.09880727529525757, 0.14365798234939575, 0.07494127750396729, -0.0048370822332799435, -0.09535234421491623, -0.09682893753051758, 0.039448078721761703, -0.049323953688144684, 0.05868491902947426, 0.11882132291793823, 0.006211602594703436, 0.10721268504858017, -0.06169106066226959, 0.013573190197348595, -0.029229069128632545, 0.12088790535926819, -0.10380847752094269, 0.04012717679142952, 0.16256724298000336, 0.03397085890173912, -0.0006690214504487813, 0.08136390894651413, 0.0770578384399414, -0.09642361849546432, 0.07552427053451538, -0.038630370050668716, -0.018994001671671867, 0.0436055064201355, -0.106198750436306, 0.07075799256563187, 0.0007262449944391847, -0.1459292620420456, 0.01859383098781109, 0.011222845874726772, 0.06779168546199799, -0.08484691381454468, -0.1671164482831955, -0.2218971848487854, -0.08341372758150101, 0.013006827794015408, 0.011107667349278927, -0.18645079433918, 0.0046805813908576965, -0.147001251578331, -0.07523974776268005, -0.03445926681160927, 0.028834667056798935, -0.17927978932857513, -1.1944588215892943e-32, -0.05465494468808174, 0.05957530066370964, -0.02157684974372387, 0.12209833413362503, 0.03861544653773308, 0.05490611121058464, 0.12443104386329651, 0.0631752535700798, -0.022895583882927895, -0.00853997003287077, 0.011816938407719135, -0.07920443266630173, -0.09274140745401382, -0.02780867926776409, 0.10094854235649109, 0.05106383189558983, -0.03093382529914379, 0.07114154100418091, -0.055448032915592194, -0.06748300790786743, 0.03655751422047615, 0.1360539346933365, -0.11453534662723541, -0.02551046758890152, -0.1570165604352951, 0.15580105781555176, 0.03143004700541496, 0.08123992383480072, -0.10176228731870651, -0.02893376350402832, -0.07152808457612991, 0.03405335918068886, -0.11462612450122833, 0.105906181037426, 0.030575888231396675, 0.07008422166109085, -0.026561733335256577, -0.11323289573192596, -0.09439592063426971, 0.12644720077514648, 0.03994176164269447, 0.038217540830373764, -0.220249205827713, 0.02368781715631485, -0.003625737503170967, 0.11811959743499756, 0.12543168663978577, 0.1260448396205902, 0.0567779466509819, -0.0002362821251153946, 0.04037363827228546, -0.09074579924345016, -0.07754634320735931, 0.12404081970453262, 0.013105075806379318, 0.09917367249727249, -0.06439314782619476, -0.028005434200167656, -0.02014750801026821, 0.05656154826283455, -0.0716925784945488, -0.043995071202516556, -0.050322026014328, -0.06934826076030731, 0.021991385146975517, 0.05374855548143387, -0.08251999318599701, -0.016527729108929634, 0.06387832015752792, 0.15067878365516663, 0.07296920567750931, 0.06725559383630753, -0.08478061854839325, -0.26461881399154663, 3.768980968743563e-05, 0.08116605132818222, -0.06708843261003494, 0.013212475925683975, -0.07279431074857712, 0.05251609906554222, -0.0208039078861475, -0.015423586592078209, 0.212715744972229, 0.331382691860199, -0.06436214596033096, 0.13272011280059814, 0.20475102961063385, 0.12519854307174683, 0.013747903518378735, -0.02979106269776821, 0.0038424201775342226, 0.0579502210021019, 0.07926521450281143, 0.11726745963096619, -0.024291839450597763, -9.918106513850944e-08, -0.03701629862189293, 0.04721766710281372, 0.023774566128849983, 0.08480694144964218, 0.007499882951378822, -0.024275703355669975, -0.039787501096725464, 0.06905511021614075, -0.0898444876074791, 0.048466756939888, 0.0044056568294763565, -0.16161416471004486, -0.1291976124048233, -0.023786436766386032, -0.095062755048275, 0.017316948622465134, -0.08651283383369446, 0.1046258881688118, 0.012092245742678642, -0.016853971406817436, 0.05809878930449486, -0.0715242549777031, 0.02797122485935688, 0.035991813987493515, -0.08720998466014862, 0.002336483681574464, -0.10797261446714401, 0.20089443027973175, 0.07994699478149414, 0.038885753601789474, -0.015288454480469227, -0.20801052451133728, 0.10479322820901871, 0.1272486448287964, 0.033245690166950226, 0.03524873033165932, -0.18680639564990997, 0.02498992718756199, 0.15956254303455353, 0.1329486221075058, -0.21292906999588013, 0.095257967710495, -0.10495518893003464, 0.016018517315387726, 0.08384853601455688, 0.06515569239854813, -0.07719346135854721, -0.07538061589002609, -0.016110433265566826, 0.001972115831449628, -0.0010669628391042352, 0.03463968634605408, -0.15467439591884613, 0.14219297468662262, 0.17146040499210358, -0.17671722173690796, -0.1520065814256668, -0.05712118372321129, -0.08318755030632019, 0.0725894570350647, 0.0219127144664526, 0.05791435018181801, -0.14620645344257355, 0.006263282615691423], metadata={'source': 'AAAMLP-569to.pdf', 'page': 58}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 59  Figure 8: Confusion matrix for a multi-class problem  Confusion matrix gives an easy way to calculate different metrics that we have discussed before. Scikit-learn offers an easy and straightforward way to generate a confusion matrix. Please note that the confusion matrix that I have shown in figure 8 is a transpose of scikit-learn’s confusion matrix and an original version can be plotted by the following code.  ═════════════════════════════════════════════════════════════════════════ import matplotlib.pyplot as plt import seaborn as sns from sklearn import metrics  # some targets y_true = [0, 1, 2, 0, 1, 2, 0, 2, 2]  #some predictions y_pred = [0, 2, 1, 0, 2, 1, 0, 0, 2]  # get confusion matrix from sklearn cm = metrics.confusion_matrix(y_true, y_pred)  # plot using matplotlib and seaborn plt.figure(figsize=(10, 10)) cmap = sns.cubehelix_palette(50, hue=0.05, rot=0, light=0.9, dark=0, as_cmap=True) sns.set(font_scale=2.5) sns.heatmap(cm, annot=True, cmap=cmap, cbar=False)'),\n",
       " VectorParams(vector=[-0.024295039474964142, 0.006401711143553257, -0.0569695308804512, -0.12876024842262268, 0.09634091705083847, 0.07082704454660416, 0.10238821804523468, -0.018952224403619766, 0.049325551837682724, -0.08047778159379959, -0.05492889881134033, -0.19640089571475983, 0.14515148103237152, 0.08790846168994904, 0.017420507967472076, 0.033663809299468994, 0.04322709143161774, 0.06769619137048721, -0.17677274346351624, -0.013665655627846718, 0.08667387813329697, -0.08180706948041916, 0.19511185586452484, 0.0336151123046875, -0.05533263832330704, 0.039153244346380234, -0.015534649603068829, 0.018631231039762497, -0.08576851338148117, -0.11380469799041748, -0.0038282517343759537, 0.11463410407304764, -0.07046420127153397, 0.08862032741308212, -0.05779328942298889, 0.1092301607131958, -0.12218751013278961, 0.08310572057962418, 0.08241664618253708, 0.036070432513952255, 0.051311373710632324, 0.07888731360435486, -0.0016336161643266678, -0.02828819304704666, 0.09193696081638336, 0.20412148535251617, -0.07601376622915268, -0.1414700597524643, -0.015241442248225212, -0.08333221077919006, -0.12425639480352402, -0.10091317445039749, -0.18193483352661133, 0.061510227620601654, -0.02612403593957424, -0.08245215564966202, -0.0045096734538674355, -0.10974405705928802, 0.09625444561243057, 0.027084659785032272, 0.04927186295390129, -0.11943040043115616, 0.001353057799860835, 0.008179222233593464, 0.05091084539890289, 0.048146672546863556, 0.0077608381398022175, -0.06686829775571823, -0.13126766681671143, -0.002600207692012191, 0.07027547061443329, 0.021616116166114807, 0.03278142213821411, -0.005745613481849432, 0.013026915490627289, -0.011243791319429874, 0.05115858092904091, -0.0019015729194507003, 0.03180710971355438, -0.06432760506868362, 0.026866300031542778, 0.10781832039356232, -0.04124477878212929, -0.09655860811471939, 0.1989583671092987, -0.13007000088691711, -0.08068942278623581, 0.02518622577190399, -0.02852611243724823, -0.05591096356511116, -0.04961823672056198, -0.06383878737688065, -0.02897248975932598, -0.026448609307408333, -0.025744469836354256, -0.021779652684926987, 0.049999725073575974, -0.012044290080666542, 0.04762427136301994, 0.076173797249794, -0.05322754383087158, -0.011445137672126293, 0.036380521953105927, -0.031507015228271484, 0.1798965185880661, -0.033862899988889694, 0.045557424426078796, -0.08828015625476837, 0.15563389658927917, -0.23406539857387543, -0.02663453482091427, -0.0847105085849762, -0.28254836797714233, 0.1085081696510315, -0.03767262399196625, 0.018720120191574097, -0.050013042986392975, -0.07630893588066101, 0.016429420560598373, 0.0381571501493454, -0.2079944610595703, -0.13708746433258057, 0.12921079993247986, -0.019427837803959846, 0.05364927276968956, -0.02632114291191101, -0.09905160218477249, 8.704437220187158e-33, -0.023372391238808632, -0.13249489665031433, 0.06510797888040543, -0.16995421051979065, 0.1406627893447876, -0.1141374260187149, -0.13705120980739594, 0.053778570145368576, 0.05245671421289444, -0.007016782183200121, 0.011948768049478531, -0.006659431848675013, 0.016087405383586884, 0.09281276911497116, 0.10446655750274658, 0.006948424503207207, -0.03286347538232803, 0.0995342805981636, -0.06387121975421906, 0.030927352607250214, 0.11452824622392654, 0.03367787227034569, 0.053513091057538986, -0.05291130393743515, -0.04966333881020546, 0.05190064013004303, 0.006659696344286203, -0.03497897833585739, -0.028017334640026093, 0.04133914038538933, -0.09396553039550781, 0.0581120140850544, 0.13259753584861755, 0.15812230110168457, -0.05526351183652878, -0.19455227255821228, -0.14666901528835297, 0.12979388236999512, -0.01472864206880331, 0.04151821881532669, -0.049210865050554276, 0.06325170397758484, 0.06607163697481155, -0.11403664201498032, 0.06881146132946014, 0.1108861044049263, -0.0825800895690918, 0.0855882316827774, -0.11840938031673431, 0.030681956559419632, -0.01109270192682743, -0.08403576910495758, -0.08699071407318115, 0.023121671751141548, -0.08283254504203796, 0.021547332406044006, -0.05649273470044136, -0.0480128638446331, -0.0053929719142615795, -0.08009586483240128, 0.029216883704066277, 0.040749743580818176, -0.01425966527312994, 0.06353559345006943, 0.08227398991584778, 0.11934862285852432, 0.04945347458124161, -0.04860220476984978, 0.15956242382526398, 0.13050034642219543, 0.025030454620718956, 0.024243490770459175, -0.04121268913149834, -0.10646925866603851, 0.12778159976005554, 0.009818586520850658, 0.06811446696519852, 0.005706951953470707, -0.14326266944408417, 0.21699151396751404, -0.015156286768615246, 0.12318535894155502, 0.04027479514479637, -0.1565648466348648, -0.1671147346496582, 0.009518176317214966, 0.09651900082826614, -0.10567683726549149, -0.10593242198228836, 0.05894845351576805, -0.16110572218894958, 0.12086690217256546, -0.15225286781787872, 0.028793994337320328, -0.08702321350574493, -1.026463046441527e-32, 0.06823018193244934, 0.12585823237895966, 0.07994616776704788, 0.06207947060465813, 0.043860793113708496, 0.10818944126367569, -0.024164395406842232, 0.021784832701086998, -0.033112432807683945, -0.05108876898884773, -0.049970656633377075, -0.02523212693631649, 0.058322519063949585, -0.06298869848251343, -0.11651548743247986, 0.04594426229596138, -0.0854959562420845, 0.0043036178685724735, -0.04735328629612923, 0.09552809596061707, 0.10945790261030197, 0.14745193719863892, -0.062258392572402954, 0.05554526671767235, -0.0797901526093483, 0.08105242997407913, -0.021251389756798744, 0.0014036275679245591, -0.07634513080120087, -0.05852692946791649, -0.07121214270591736, -0.16801320016384125, -0.003171031828969717, 0.015136804431676865, -0.02106660231947899, -0.041764914989471436, -0.023289278149604797, -0.007310986518859863, -0.1269337236881256, 0.18632872402668, 0.1489740014076233, 0.0037420520093292, -0.15614038705825806, 0.08363871276378632, -0.058437835425138474, -0.11647170037031174, -0.06826929748058319, -0.00830786395817995, 0.08504829555749893, -0.02188272774219513, -0.03145354986190796, -0.03225833922624588, -0.1307784467935562, -0.004223193507641554, 0.0011888745939359069, -0.006298392079770565, -0.1503133475780487, -0.00799962691962719, -0.020536303520202637, 0.048965878784656525, -0.045658234506845474, -0.11512330174446106, 0.012940394692122936, 0.11204887926578522, 0.12472058832645416, 0.06728655844926834, -0.05937257781624794, -0.0928952693939209, 0.0014184231404215097, 0.1566203534603119, 0.09035379439592361, 0.060366660356521606, -0.010418093763291836, -0.012705717235803604, -0.09492380172014236, 0.049699410796165466, -0.03591284155845642, -0.012658803723752499, 0.011261416599154472, 0.07056528329849243, -0.013060981407761574, -0.12615342438220978, -0.03560701385140419, 0.15159352123737335, -0.03216852247714996, 0.02404922991991043, 0.19139844179153442, 0.039513181895017624, 0.15912456810474396, -0.08897033333778381, 0.008076044730842113, 0.10785681009292603, -0.006073415745049715, 0.15558649599552155, 0.014097128063440323, -9.973179970756973e-08, 0.07058130204677582, -0.04126071184873581, -0.01850311830639839, 0.007284391671419144, 0.037092551589012146, -0.053724419325590134, -0.13375526666641235, 0.1448913812637329, -0.04719941318035126, 0.02012181095778942, 0.12759461998939514, 0.05696820467710495, -0.09621119499206543, 0.060418110340833664, -0.09011567384004593, -0.09668195247650146, -0.08562430739402771, 0.04870009794831276, 0.00989789143204689, 0.08493047952651978, 0.022367069497704506, -0.13845594227313995, 0.19628405570983887, -0.08265797793865204, -0.04377272352576256, -0.07027439773082733, -0.00035622090217657387, 0.09631914645433426, 0.06502991169691086, 0.05717608332633972, 0.003330560401082039, -0.04178714007139206, -0.05700685828924179, 0.0015462754527106881, 0.0808136835694313, -0.07005464285612106, -0.12186726182699203, -0.04849376901984215, -0.015278387814760208, 0.14165835082530975, -0.014822968281805515, -0.07372216880321503, -0.10998231172561646, 0.014621462672948837, 0.2149527221918106, 0.06666349619626999, 0.06071896478533745, -0.09561379253864288, 0.06087552756071091, 0.12431398779153824, -0.029408395290374756, 0.0879165306687355, -0.10328038781881332, 0.12233804911375046, 0.06157563626766205, -0.11640170961618423, -0.0063355425372719765, -0.1648983657360077, 0.08769429475069046, 0.11612057685852051, 0.11373324692249298, -0.09515862166881561, -0.11146552115678787, 0.061289988458156586], metadata={'source': 'AAAMLP-569to.pdf', 'page': 59}, content=\"Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 60 plt.ylabel('Actual Labels', fontsize=20) plt.xlabel('Predicted Labels', fontsize=20) ═════════════════════════════════════════════════════════════════════════  So, until now, we have tackled metrics for binary and multi-class classification. Then comes another type of classification problem called multi-label classification. In multi-label classification, each sample can have one or more classes associated with it. One simple example of this type of problem would be a task in which you are asked to predict different objects in a given image.  \\n Figure 9: Different objects in an image4  Figure 9 shows an example image from a well-known dataset. Note that this dataset’s objective is something different but let’s not go there. Let’s assume that the aim is only to predict if an object is present in an image or not. For figure 9, we have a chair, flower-pot, window, but we don’t have other objects such as computer, bed, tv, etc. So, one image can have multiple targets associated with it. This type of problem is the multi-label classification problem.  The metrics for this type of classification problem are a bit different. Some suitable and most common metrics are:  - Precision at k (P@k) - Average precision at k (AP@k)  4 https://www.flickr.com/photos/krakluski/2950388100 License: CC BY 2.0\"),\n",
       " VectorParams(vector=[-0.06478922069072723, 0.010420284233987331, -0.035035766661167145, -0.032500091940164566, 0.03665940836071968, -0.11423546075820923, 0.05818098038434982, 0.09010522812604904, 0.01006642822176218, 0.09626537561416626, -0.11381787061691284, -0.04261402040719986, 0.114411860704422, -0.06391626596450806, -0.06745276600122452, 0.06636898964643478, -0.06696014851331711, 0.1182851493358612, -0.04530063271522522, -0.012275292538106441, 0.1112910658121109, 0.05926208570599556, 0.08996279537677765, 0.1347821205854416, 0.11636192351579666, -0.14557021856307983, -0.014127995818853378, 0.1299625188112259, -0.13318485021591187, -0.0548105351626873, -0.12020332366228104, 0.10177917778491974, 0.14954598248004913, 0.005267275497317314, -0.09063537418842316, -0.02411348558962345, -0.0901808813214302, -0.033773813396692276, 0.0644386038184166, 0.014137888327240944, -0.06454691290855408, -0.01985079236328602, 0.10369205474853516, 0.031855806708335876, 0.07017768174409866, 0.2054569274187088, -0.06706732511520386, -0.041179489344358444, 0.002578719286248088, -0.10914702713489532, -0.050794776529073715, 0.14637491106987, -0.14214447140693665, -0.02228393964469433, -0.11745741218328476, -0.07665098458528519, -0.0203876830637455, -0.07333017140626907, 0.0728054866194725, -0.0662946105003357, -0.13575203716754913, -0.11122652888298035, 0.00794062577188015, -0.07478046417236328, 0.07455561310052872, -0.10804911702871323, 0.01184253953397274, 0.058401789516210556, 0.011640144512057304, 0.08704134076833725, -0.0037963807117193937, 0.13425341248512268, 0.042212799191474915, -0.0015232193982228637, 0.08089537918567657, -0.03243880718946457, 0.05442078039050102, 0.08567211776971817, -0.04504850506782532, 0.05400088429450989, -0.02359178103506565, 0.039189986884593964, -0.018950369209051132, -0.0795464813709259, 0.06369273364543915, -0.21997752785682678, 0.08617667108774185, 0.09762781113386154, 0.20114777982234955, -0.04310597479343414, -0.03823709115386009, -0.1491202563047409, -0.0420992411673069, -0.036186739802360535, 0.07638497650623322, 0.17257608473300934, 0.0060198926366865635, -0.07589921355247498, -0.06095428392291069, 0.06964138895273209, -0.03021792322397232, 0.07378407567739487, 0.0250020083039999, -0.26665860414505005, 0.04313873127102852, -0.031243562698364258, 0.07101062685251236, -0.03911595046520233, 0.10825494676828384, -0.1946684718132019, -0.04089799523353577, -0.11515550315380096, -0.1409730315208435, 0.08194956183433533, 0.09558181464672089, 0.08371241390705109, 0.051706038415431976, 0.046691589057445526, 0.050929807126522064, 0.018898088485002518, -0.0661066472530365, 0.04574103280901909, 0.1068209633231163, 0.06723277270793915, 0.09860081970691681, -0.042515531182289124, -0.08595990389585495, 1.1313536563281475e-32, -0.1222127228975296, 0.016693515703082085, 0.02033303678035736, -0.09210310131311417, -0.0497250072658062, -0.04525984451174736, -0.02929559536278248, -0.0894256979227066, -0.09095389395952225, 0.0038853383157402277, -0.06884301453828812, 0.019213734194636345, 0.07453019171953201, -0.04373406991362572, 0.08288149535655975, 0.07747992873191833, -0.054544687271118164, 0.048085831105709076, -0.0670374408364296, -0.026671800762414932, 0.20350635051727295, 0.030865631997585297, 0.03494948893785477, -0.044812873005867004, -0.09511120617389679, 0.1273067444562912, -0.051441919058561325, 0.019024118781089783, -0.13888731598854065, 0.04460471495985985, -0.06989356875419617, 0.07399199157953262, 0.026972245424985886, -0.036160968244075775, 0.05919141694903374, -0.08811318129301071, -0.0038392385467886925, 0.027149509638547897, 0.030685672536492348, 0.03141334652900696, -0.11006072908639908, -0.002777204615995288, 0.009784582071006298, 0.02001410908997059, -0.05580859258770943, -0.12054818868637085, -0.07511258125305176, 0.19270667433738708, 0.046080902218818665, 0.16725532710552216, -0.03949172794818878, -0.18452179431915283, -0.052981577813625336, 0.04162925109267235, -0.10996200889348984, 0.09430358558893204, 0.15479861199855804, 0.07518772035837173, 0.10244335234165192, 0.026764176785945892, 0.004113315138965845, 0.004034888930618763, 0.005381712689995766, -0.001959805376827717, -0.09884008765220642, 0.09918318688869476, -0.0031092690769582987, 0.1454189121723175, 0.12270589917898178, 0.11629237979650497, -0.04383618384599686, 0.010588047094643116, -0.09851857274770737, 0.0406944565474987, 0.09387543052434921, -0.02168971486389637, 0.17474806308746338, -0.0501818023622036, -0.04615102708339691, 0.07108868658542633, 0.08811841160058975, 0.15487869083881378, -0.10841154307126999, -0.07272506505250931, -0.10360559821128845, -0.11847721040248871, 0.10461878776550293, 0.018316268920898438, -0.10729524493217468, -0.04819713160395622, -0.21951784193515778, 0.0653923824429512, 0.05337328091263771, 0.028170498088002205, -0.1724766343832016, -1.3376950857572947e-32, -0.04443230479955673, 0.18505142629146576, 0.11944036185741425, 0.10149672627449036, -0.01650518923997879, 0.004987997002899647, 0.029889795929193497, -0.06222929432988167, 0.011718690395355225, -0.09534449875354767, -0.0855768695473671, -0.11927100270986557, -0.013833519071340561, -0.011044233106076717, 0.10250244289636612, 0.056866902858018875, -0.19782139360904694, 0.030197281390428543, -0.07715078443288803, -0.009342759847640991, 0.04998740181326866, 0.041102081537246704, -0.06750879436731339, 0.03882237896323204, -0.13612155616283417, 0.001002322998829186, -0.025750506669282913, 0.11376959830522537, -0.021866220980882645, -0.1016644835472107, -0.051942549645900726, -0.1918710172176361, -0.09238336235284805, -0.0029734387062489986, -0.015368634834885597, -0.16163575649261475, 0.05564795061945915, -0.05247088521718979, -0.03377528116106987, 0.07100024819374084, 0.1493007093667984, 0.04160858690738678, -0.08794887363910675, -0.035011377185583115, 0.0683557391166687, 0.019596382975578308, 0.05142871290445328, 0.015923216938972473, 0.09152896702289581, -0.1404166966676712, 0.09059520065784454, 0.05140705406665802, -0.07898876816034317, 0.0715259239077568, -0.04600358009338379, 0.07840682566165924, -0.1900898814201355, 0.026501793414354324, -0.07772940397262573, -0.042441509664058685, -0.1980186253786087, -0.12351638823747635, 0.07467598468065262, 0.10907585173845291, 0.07976759225130081, 0.09353340417146683, -0.07136254012584686, -0.038286466151475906, -0.07682701200246811, 0.11023247987031937, -0.10071864724159241, 0.1011461615562439, 0.02339044027030468, -0.09871593117713928, -0.0003601598727982491, -0.030640525743365288, -0.048639073967933655, 0.050627537071704865, -0.04158845916390419, 0.09072725474834442, -0.05976785719394684, -0.059921570122241974, -0.04979109391570091, 0.02135961689054966, -0.07892818748950958, 0.014610831625759602, 0.17164486646652222, 0.09276033192873001, 0.06938831508159637, -0.13492442667484283, -0.011084233410656452, 0.16009914875030518, 0.008486917242407799, 0.10026765614748001, -0.05601053312420845, -1.0066729316804413e-07, -0.006525165867060423, -0.022900618612766266, 0.011187821626663208, 0.12462636828422546, 0.1728230118751526, 0.11577842384576797, -0.06032729148864746, 0.028095636516809464, -0.06174211576581001, -0.0793282613158226, 0.07478369027376175, -0.009433002211153507, -0.03813508152961731, -0.0483601950109005, -0.042106933891773224, 0.05335788428783417, -0.04122868552803993, 0.05056682229042053, -0.04875606670975685, 0.01718519628047943, 0.07016506046056747, -0.11837219446897507, 0.10898508131504059, -0.0032674067188054323, -0.04401500150561333, 0.008010800927877426, -0.03759871795773506, 0.06602063030004501, -0.033965110778808594, -0.027949171140789986, 0.08306663483381271, -0.09522981941699982, 0.046982813626527786, 0.0061270748265087605, 0.01965971663594246, 0.06999484449625015, 0.014615758322179317, 0.03632068261504173, 0.023189406841993332, 0.037502653896808624, -0.1361745297908783, -0.06071660667657852, -0.029102148488163948, -0.01692448928952217, 0.08719763159751892, -0.03489620238542557, 0.00036506890319287777, -0.0093077989295125, 0.020530004054307938, -0.09974537044763565, 0.010216780938208103, 0.08345695585012436, -0.18423719704151154, -0.03475836664438248, 0.0856015756726265, -0.0024292052257806063, -0.1286982297897339, -0.2591319978237152, -0.08915518969297409, -0.04401642829179764, 0.11474663019180298, -0.05232112854719162, -0.044254645705223083, 0.13175249099731445], metadata={'source': 'AAAMLP-569to.pdf', 'page': 60}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 61 - Mean average precision at k (MAP@k) - Log loss  Let’s start with precision at k or P@k. One must not confuse this precision with the precision discussed earlier. If you have a list of original classes for a given sample and list of predicted classes for the same, precision is defined as the number of hits in the predicted list considering only top-k predictions, divided by k.  If that’s confusing, it will become apparent with python code.  ═════════════════════════════════════════════════════════════════════════ def pk(y_true, y_pred, k):     \"\"\"     This function calculates precision at k      for a single sample     :param y_true: list of values, actual classes     :param y_pred: list of values, predicted classes     :param k: the value for k     :return: precision at a given value k     \"\"\"     # if k is 0, return 0. we should never have this     # as k is always >= 1     if k == 0:         return 0     # we are interested only in top-k predictions     y_pred = y_pred[:k]     # convert predictions to set     pred_set = set(y_pred)     # convert actual values to set     true_set = set(y_true)     # find common values     common_values = pred_set.intersection(true_set)     # return length of common values over k     return len(common_values) / len(y_pred[:k]) ═════════════════════════════════════════════════════════════════════════  With code, everything becomes much easier to understand.  Now, we have average precision at k or AP@k. AP@k is calculated using P@k. For example, if we have to calculate AP@3, we calculate P@1, P@2 and P@3 and then divide the sum by 3.   Let’s see its implementation.'),\n",
       " VectorParams(vector=[0.01514640636742115, -0.025583768263459206, -0.040175702422857285, -0.07945095747709274, 0.005383816547691822, -0.1350485384464264, 0.07595016807317734, 0.017859844490885735, -0.018694592639803886, -0.009922982193529606, -0.0654282420873642, -0.010472964495420456, 0.06095288693904877, -0.018771277740597725, -0.12990617752075195, 0.08981970697641373, -0.04661793261766434, 0.0675509050488472, 0.04839426651597023, -0.128781259059906, 0.08482135087251663, 0.09289128333330154, 0.05597692355513573, 0.04548021778464317, 0.11770324409008026, -0.10298974066972733, 0.005326941143721342, 0.10238101333379745, -0.15476970374584198, -0.04615539312362671, -0.11656396836042404, 0.028677091002464294, 0.12604428827762604, -0.003617150243371725, -0.03373773396015167, -0.031504590064287186, -0.0005797161138616502, 0.010774235241115093, 0.07243720442056656, -0.0021621279884129763, -0.04854179546236992, 0.008075264282524586, 0.07230767607688904, 0.029597723856568336, 0.09825541824102402, 0.1774940937757492, -0.07211385667324066, -0.08287672698497772, 0.015101210214197636, -0.11162326484918594, -0.08053547143936157, 0.19407959282398224, -0.20833942294120789, -0.08537683635950089, -0.06869471818208694, -0.12303008139133453, 0.025574399158358574, -0.06985819339752197, 0.06430797278881073, -0.061247099190950394, -0.07991642504930496, -0.04941684007644653, 0.013066387735307217, -0.04414108395576477, -0.013405588455498219, -0.04712783917784691, 0.03915415704250336, 0.07905758172273636, -0.006271222606301308, 0.057442985475063324, 0.015953442081809044, 0.1727333664894104, -0.028648432344198227, 0.05286850035190582, 0.08765359222888947, -0.021800903603434563, 0.025652442127466202, -0.04541829600930214, -0.03101080097258091, 0.07702068984508514, -0.024478383362293243, 0.008576401509344578, -0.0143330879509449, -0.056849393993616104, 0.04593711718916893, -0.18583102524280548, 0.11965269595384598, 0.1713891625404358, 0.19974763691425323, -0.021226542070508003, -0.05804828181862831, -0.05479850992560387, -0.10097640752792358, -0.06649374216794968, 0.0667518675327301, 0.18119637668132782, 0.09556017071008682, -0.10721537470817566, -0.05324742943048477, 0.11899613589048386, -0.11336908489465714, -0.012645753100514412, 0.01569627970457077, -0.23151637613773346, 0.16423138976097107, 0.015121949836611748, 0.09995178878307343, -0.12712179124355316, 0.06286634504795074, -0.25483831763267517, -0.0574243925511837, -0.09541649371385574, -0.10729146003723145, 0.10539886355400085, 0.10658956319093704, 0.0009635924361646175, -0.021919380873441696, 0.09555748850107193, 0.04985584691166878, -0.0074126203544437885, 0.01621648482978344, 0.08476375043392181, 0.1713709682226181, 0.18496426939964294, 0.04186868667602539, -0.11012261360883713, -0.11354997009038925, 3.6620032247792716e-33, -0.1976986527442932, -0.04362958297133446, 0.1001017764210701, -0.14497454464435577, -0.02816559001803398, -0.07316969335079193, 0.09832198172807693, -0.16178233921527863, 0.047599032521247864, 0.026826007291674614, -0.11671122908592224, 0.060875069350004196, 0.012822611257433891, -0.028615443035960197, 0.12078449130058289, -0.04384623467922211, -0.0045366124249994755, 0.03840787708759308, -0.010826464742422104, -0.016360795125365257, 0.17419542372226715, -0.1315689980983734, 0.10546941310167313, -0.041167113929986954, -0.08561781793832779, -0.024241216480731964, -0.010146694257855415, 0.03551158308982849, -0.10269308090209961, 0.0420144647359848, -0.09325183928012848, 0.10447853803634644, 0.0128517160192132, -0.04100385308265686, 0.024301491677761078, -0.16145631670951843, 0.02765705995261669, 0.020917007699608803, 0.08581174910068512, 0.022991368547081947, -0.041402921080589294, 0.015155595727264881, 0.040702853351831436, -0.02081177942454815, -0.05948636308312416, -0.08244699239730835, -0.03293626010417938, 0.1317247599363327, 0.036217909306287766, 0.1548433154821396, -0.11109861731529236, -0.21574237942695618, -0.12610644102096558, 0.11289459466934204, -0.17118880152702332, 0.0634550154209137, 0.12137920409440994, 0.10189478099346161, 0.017864638939499855, 0.034573402255773544, -0.010763507336378098, 0.041544631123542786, -0.02642880007624626, 0.0016704287845641375, -0.10765626281499863, 0.07842456549406052, 0.02280411124229431, 0.11298961937427521, 0.12751850485801697, 0.14852501451969147, 0.01213124766945839, -0.003578537842258811, 0.018106546252965927, -0.05623576045036316, 0.07919459044933319, -0.048910416662693024, 0.1202690452337265, -0.042239196598529816, -0.1286865472793579, 0.004246225114911795, 0.10474328696727753, 0.12506242096424103, -0.0786372721195221, -0.12474650889635086, -0.014969345182180405, -0.0685919001698494, 0.06316447257995605, 0.04794088006019592, -0.09747125953435898, -0.031972065567970276, -0.2575899064540863, 0.08647138625383377, -0.0007950413855724037, -0.015472237952053547, -0.12449122220277786, -6.0757376108188326e-33, -0.010287710465490818, 0.12214498966932297, 0.13752764463424683, 0.128718301653862, 0.039208829402923584, 0.05524427816271782, 0.005508219823241234, -0.027072271332144737, 0.07374650985002518, -0.05492579564452171, -0.15216320753097534, -0.08693323284387589, 0.08233210444450378, -0.03638053312897682, 0.1331654042005539, 0.07414654642343521, -0.11766933649778366, 0.12282055616378784, -0.0020626753102988005, 0.032739363610744476, 0.07515762746334076, 0.0655687004327774, 0.02420777827501297, 0.02282383292913437, -0.13637293875217438, 0.05925477668642998, 0.019809633493423462, 0.06977569311857224, -0.10694123804569244, -0.1021881103515625, 0.0055991834960877895, -0.12398707121610641, -0.08143056929111481, -0.027709459885954857, -0.030077558010816574, -0.14238199591636658, 0.11389905959367752, -0.006004781927913427, -0.07675490528345108, 0.09494902193546295, 0.18389065563678741, 0.06352150440216064, -0.08936969935894012, -0.048374660313129425, 0.09370805323123932, 0.03884226456284523, 0.01495567336678505, 0.011251457966864109, 0.03231611102819443, -0.11339370161294937, 0.03619201108813286, 0.133282870054245, -0.20938944816589355, 0.06012547388672829, -0.0734282061457634, 0.08463459461927414, -0.2576223909854889, -0.024760274216532707, -0.03197158873081207, -0.06671519577503204, -0.18704107403755188, -0.16702231764793396, 0.00908229686319828, 0.14260374009609222, 0.12082011997699738, 0.09257175773382187, 0.012975850142538548, -0.08291826397180557, -0.10076460987329483, 0.20446144044399261, -0.0136422049254179, 0.12985897064208984, -0.042547114193439484, -0.12051423639059067, -0.07415899634361267, -0.00635733176022768, -0.06678358465433121, -0.036880552768707275, -0.04178229719400406, 0.14077255129814148, -0.06052904948592186, -0.030081255361437798, -0.01548711583018303, 0.021280860528349876, -0.050398871302604675, -0.0006058199796825647, 0.2063092738389969, 0.13926450908184052, 0.07991956919431686, -0.10541891306638718, 0.0208940077573061, 0.15791930258274078, 0.08623798191547394, 0.05008386820554733, 0.019913626834750175, -9.941835088511652e-08, -0.01659623347222805, -0.02646445855498314, 0.0008384663378819823, 0.11678071320056915, 0.1802748441696167, 0.025835156440734863, -0.11040934920310974, 0.06522142142057419, -0.015033435076475143, -0.146514892578125, 0.1090843677520752, -0.047273989766836166, -0.002958267694339156, 0.07182293385267258, -0.02000574767589569, 0.06877002120018005, -0.08328115195035934, 0.059889066964387894, -0.01982705667614937, 0.029960764572024345, 0.04751482605934143, -0.05143333598971367, 0.043691106140613556, -0.05126422271132469, -0.08479822427034378, -0.0056739081628620625, -0.0605488047003746, -0.02738363854587078, 0.05111226066946983, 0.07240111380815506, 0.07785247266292572, -0.07662907987833023, 0.06734051555395126, -0.07349853217601776, 0.0795578584074974, 0.08235853165388107, -0.054022062569856644, 0.05421719327569008, -0.03787536174058914, 0.03322916105389595, -0.1652345359325409, 0.028134740889072418, 0.013721764087677002, 0.03186944127082825, 0.20497530698776245, -0.054721180349588394, -0.061879660934209824, -0.04785458371043205, 0.06972075253725052, -0.11025531589984894, 0.12841211259365082, 0.09204781800508499, -0.13805508613586426, -0.10302427411079407, 0.08437599986791611, 0.033169399946928024, -0.15159159898757935, -0.19379174709320068, -0.04476087912917137, 0.020221073180437088, 0.046123992651700974, -0.14301902055740356, -0.05527709424495697, 0.041514165699481964], metadata={'source': 'AAAMLP-569to.pdf', 'page': 61}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 62 ═════════════════════════════════════════════════════════════════════════ def apk(y_true, y_pred, k):     \"\"\"     This function calculates average precision at k      for a single sample     :param y_true: list of values, actual classes     :param y_pred: list of values, predicted classes     :return: average precision at a given value k     \"\"\"     # initialize p@k list of values     pk_values = []     # loop over all k. from 1 to k + 1     for i in range(1, k + 1):         # calculate p@i and append to list         pk_values.append(pk(y_true, y_pred, i))      # if we have no values in the list, return 0     if len(pk_values) == 0:         return 0     # else, we return the sum of list over length of list     return sum(pk_values) / len(pk_values) ═════════════════════════════════════════════════════════════════════════  These two functions can be used to calculate average precision at k (AP@k) for two given lists; let’s see how.  In [X]: y_true = [    ...:     [1, 2, 3],    ...:     [0, 2],    ...:     [1],    ...:     [2, 3],    ...:     [1, 0],    ...:     []    ...: ]  In [X]: y_pred = [    ...:     [0, 1, 2],    ...:     [1],    ...:     [0, 2, 3],    ...:     [2, 3, 4, 0],    ...:     [0, 1, 2],    ...:     [0]    ...: ]  In [X]: for i in range(len(y_true)):    ...:     for j in range(1, 4):    ...:         print('),\n",
       " VectorParams(vector=[0.025312406942248344, -0.030592458322644234, -0.05499438941478729, -0.07098250091075897, -0.05176788195967674, -0.0867779552936554, 0.08868838846683502, 0.03173873573541641, 0.012265253812074661, 0.11473982781171799, -0.02540140226483345, -0.055552247911691666, 0.0827055275440216, -0.10743271559476852, -0.04583229124546051, 0.14688855409622192, -0.030406078323721886, 0.08280864357948303, -0.0126781752333045, -0.08454267680644989, 0.10286959260702133, 0.11313168704509735, 0.06234225258231163, 0.08452863991260529, 0.07447302341461182, -0.042647283524274826, 0.0016675597289577127, 0.1234491840004921, -0.15741127729415894, -0.04648705571889877, -0.11724483221769333, 0.0027176043950021267, 0.091523177921772, -0.0037950107362121344, -0.05049996078014374, -0.02011142112314701, 0.009822869673371315, -0.054783716797828674, 0.07304862141609192, 0.028419669717550278, -0.0595424510538578, 0.02709401771426201, 0.08537279069423676, 0.006946008186787367, 0.14139483869075775, 0.12936851382255554, -0.05098257586359978, -0.03105742298066616, 0.05670939385890961, -0.00756643433123827, -0.007833232171833515, 0.15304124355316162, -0.17767541110515594, -0.050554607063531876, -0.07182685285806656, -0.06425540894269943, -0.02259179577231407, -0.12689560651779175, 0.0849163830280304, -0.05182168260216713, -0.09822610765695572, -0.06983452290296555, 0.13793836534023285, -0.023228276520967484, 0.02547004632651806, -0.0949459969997406, 0.0074799275025725365, -0.01605374366044998, -0.022814495489001274, 0.06443760544061661, 0.006451111286878586, 0.09122034907341003, 0.11402697116136551, -0.0696028620004654, 0.047686778008937836, -0.017096789553761482, -0.01592523418366909, -0.024862103164196014, 0.005902854260057211, 0.06110058352351189, -0.011209692806005478, -0.012903960421681404, 0.05554626137018204, -0.0037463700864464045, -0.041339315474033356, -0.2157394289970398, 0.1105455532670021, 0.05056917667388916, 0.21157385408878326, -0.006160230375826359, -0.019914202392101288, -0.06931671500205994, -0.10405685752630234, -0.018100734800100327, 0.06291452795267105, 0.15690739452838898, -0.010190790519118309, -0.09765002876520157, -0.08695781230926514, 0.07908378541469574, -0.047289855778217316, 0.03389602527022362, 0.057946424931287766, -0.22237035632133484, 0.09562712907791138, -0.013040658086538315, 0.06444743275642395, -0.1054530218243599, 0.07782328128814697, -0.1422336846590042, -0.11921045184135437, -0.1716509461402893, -0.10549760609865189, 0.06704483926296234, 0.0787668526172638, 0.060836512595415115, 0.030354730784893036, 0.05946006253361702, 0.03423772752285004, 0.04974982887506485, -0.06903649866580963, 0.06719498336315155, 0.09490247815847397, 0.112686388194561, 0.023103609681129456, -0.07784391939640045, -0.06753075122833252, 9.539155024022095e-33, -0.11387915164232254, 0.0018539422890171409, 0.07689029723405838, -0.09014040231704712, -0.016544107347726822, -0.07541971653699875, 0.03834516182541847, -0.11843674629926682, -0.04957780987024307, -0.015888085588812828, -0.07345957309007645, 0.03022731840610504, 0.023134976625442505, -0.01792052388191223, 0.024696502834558487, 0.024351395666599274, -0.05990996211767197, -0.03031635656952858, -0.021944748237729073, 0.023811621591448784, 0.1573781669139862, -0.05843455344438553, 0.004770385101437569, -0.00519385514780879, -0.0883152186870575, 0.0697929784655571, -0.0345308892428875, 0.07930606603622437, -0.15193194150924683, 0.038342755287885666, -0.017842862755060196, 0.06131475046277046, -0.020485155284404755, -0.0957876592874527, 0.04711717367172241, -0.17407645285129547, 0.06394099444150925, 0.06571316719055176, -0.016200393438339233, 0.027728047221899033, -0.0584489181637764, 0.01005458366125822, 0.008425776846706867, 0.00309488526545465, -0.03603852912783623, -0.13198068737983704, -0.04440506175160408, 0.16779358685016632, 0.08187295496463776, 0.17489086091518402, -0.021213915199041367, -0.17063504457473755, -0.016357602551579475, 0.10247247666120529, -0.13675883412361145, 0.09995987266302109, 0.07887910306453705, 0.0922669917345047, 0.10900607705116272, 0.019202284514904022, -0.07755669951438904, -0.011812811717391014, 0.0381135419011116, 0.011962838470935822, -0.11064449697732925, 0.017016461119055748, 0.04078131914138794, 0.12946341931819916, 0.09028688818216324, 0.1838265359401703, 0.00992446206510067, -0.028029276058077812, -0.08859740942716599, -0.05874760076403618, 0.026129523292183876, -0.017322836443781853, 0.12893134355545044, -0.05533314123749733, -0.1469532698392868, 0.020187808200716972, -0.04201974347233772, 0.11448688805103302, -0.0645066350698471, -0.14135484397411346, -0.02447187714278698, -0.0892174169421196, 0.0645134449005127, -0.006196319125592709, -0.050069183111190796, -0.09209989756345749, -0.16494370996952057, 0.2023487240076065, -0.04501244053244591, 0.0025740708224475384, -0.1236698105931282, -1.0168303845153169e-32, 0.03089284524321556, 0.08599812537431717, 0.12397304177284241, 0.12697570025920868, 0.02394220232963562, 0.022826019674539566, 0.08182968944311142, -0.04082745313644409, 0.12792682647705078, -0.02136106975376606, -0.21020500361919403, -0.10379838198423386, 0.07070758938789368, 0.0012244004756212234, 0.15921767055988312, 0.12855927646160126, -0.09261229634284973, 0.11130977421998978, 0.0219928827136755, 0.05984679237008095, -0.0432787649333477, 0.09435011446475983, 0.029593901708722115, 0.012588092125952244, -0.11372576653957367, -0.018863443285226822, 0.0016998115461319685, 0.05630889907479286, -0.07403429597616196, -0.16381943225860596, 0.005708599463105202, -0.12422788888216019, -0.04961121454834938, 0.033688586205244064, 0.024127067998051643, -0.13816992938518524, 0.053236812353134155, -0.09787414222955704, -0.12910595536231995, 0.05289454013109207, 0.12737056612968445, 0.06614299863576889, -0.14667978882789612, -0.11523458361625671, 0.07774979621171951, 0.1345217376947403, 0.11358103901147842, -0.01961398497223854, -0.034307584166526794, -0.08786697685718536, 0.01442556083202362, 0.003795612370595336, -0.06859235465526581, 0.05915200710296631, -0.100039541721344, 0.06691758334636688, -0.24128827452659607, 0.009843203239142895, -0.06587090343236923, -0.019919317215681076, -0.06460773199796677, -0.12778085470199585, 0.1004943698644638, 0.10777623951435089, 0.11809603869915009, 0.10061108320951462, 0.06160343065857887, -0.0473061203956604, -0.08875549584627151, 0.1076909527182579, -0.08184025436639786, 0.053915347903966904, 0.0088705625385046, -0.021923961117863655, -0.006808401085436344, 0.005852404050529003, -0.05340639129281044, -0.03045026957988739, -0.025184400379657745, -0.040432512760162354, -0.07304395735263824, 0.0011979276314377785, -0.1115894466638565, 0.12023179978132248, -0.06543263792991638, 0.005648618098348379, 0.1943032443523407, 0.08917897194623947, 0.03745151311159134, -0.09068342298269272, 0.03014904074370861, 0.20240584015846252, -0.05577744543552399, 0.09184663742780685, -0.03724374622106552, -1.0070614564483549e-07, 0.020612943917512894, 0.0554482527077198, 0.01870107650756836, 0.1403193324804306, 0.14351390302181244, 0.08634112030267715, -0.05372022092342377, 0.03443310037255287, -0.013868062756955624, -0.1831343173980713, 0.1018330529332161, -0.025331588461995125, -0.051600947976112366, 0.0005727087846025825, -0.033503975719213486, 0.0430976003408432, -0.02242550067603588, 0.07542034238576889, -0.013642397709190845, 0.011848017573356628, 0.01781868189573288, -0.023619839921593666, 0.10500682890415192, -0.00900944136083126, -0.04281379282474518, 0.05085939168930054, -0.010874608531594276, -0.08952231705188751, 0.029849311336874962, -0.04547008499503136, 0.04374489188194275, -0.17804479598999023, 0.08438080549240112, -0.03488759323954582, 0.05692337453365326, 0.06939275562763214, 0.0007362201577052474, 0.0018589419778436422, 0.016232218593358994, 0.0943874716758728, -0.1748271882534027, 0.027256261557340622, 0.01610328070819378, -0.12647999823093414, 0.04700485244393349, -0.006154679227620363, -0.0072666858322918415, -0.025920316576957703, 0.06568699330091476, -0.07705871015787125, 0.03726739436388016, 0.07561106979846954, -0.1750328242778778, -0.03215677663683891, 0.05075166001915932, -0.04678168147802353, -0.07007971405982971, -0.20691610872745514, -0.09819258749485016, -0.04984382167458534, 0.05475698411464691, -0.04614385589957237, -0.07650958001613617, 0.003545435145497322], metadata={'source': 'AAAMLP-569to.pdf', 'page': 62}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 63    ...:             f\"\"\"    ...:             y_true={y_true[i]},    ...:             y_pred={y_pred[i]},    ...:             AP@{j}={apk(y_true[i], y_pred[i], k=j)}    ...:             \"\"\"    ...:         )    ...:              y_true=[1, 2, 3],             y_pred=[0, 1, 2],             AP@1=0.0               y_true=[1, 2, 3],             y_pred=[0, 1, 2],             AP@2=0.25               y_true=[1, 2, 3],             y_pred=[0, 1, 2],             AP@3=0.38888888888888884      .      . ═════════════════════════════════════════════════════════════════════════  Please note that I have omitted many values from the output, but you get the point. So, this is how we can calculate AP@k which is per sample. In machine learning, we are interested in all samples, and that’s why we have mean average precision at k or MAP@k. MAP@k is just an average of AP@k and can be calculated easily by the following python code.  ═════════════════════════════════════════════════════════════════════════ def mapk(y_true, y_pred, k):     \"\"\"     This function calculates mean avg precision at k      for a single sample     :param y_true: list of values, actual classes     :param y_pred: list of values, predicted classes     :return: mean avg precision at a given value k     \"\"\"     # initialize empty list for apk values     apk_values = []     # loop over all samples     for i in range(len(y_true)):         # store apk values for every sample         apk_values.append('),\n",
       " VectorParams(vector=[0.11263822019100189, 0.026815293356776237, 0.009808549657464027, -0.2256685197353363, -0.036033689975738525, -0.09297889471054077, 0.07598584145307541, -0.14081038534641266, -0.10803483426570892, 0.08519099652767181, -0.038241636008024216, 0.06232896447181702, 0.15944217145442963, -0.04416567459702492, -0.13834737241268158, 0.19305367767810822, 0.058150555938482285, 0.10275787860155106, 0.08504310250282288, -0.1508595496416092, -0.005151484161615372, 0.08236122876405716, -0.01286587119102478, 0.026588192209601402, 0.1522635966539383, 0.00223202514462173, 0.08619477599859238, 0.13828998804092407, -0.15479212999343872, -0.1453470140695572, -0.06853444129228592, 0.028937090188264847, 0.18521445989608765, -0.13938184082508087, 0.007464576978236437, 0.04949456825852394, -0.0695190280675888, -0.03554684296250343, 0.037567004561424255, 0.10609909892082214, -0.011696971021592617, 0.00621062982827425, 0.1225552037358284, -0.0026168336626142263, 0.06837586313486099, 0.20185187458992004, -0.04318338260054588, -0.057054027915000916, -0.00965182390064001, -0.11858709901571274, -0.04854150116443634, 0.16018174588680267, -0.24654699862003326, 0.05681523680686951, -0.014582199975848198, -0.19527356326580048, -0.12742356956005096, -0.15974926948547363, 0.09449711441993713, -0.004989375825971365, -0.06100836768746376, -0.012442125007510185, 0.101849764585495, -0.035595640540122986, 0.08103839308023453, -0.00022694050858262926, 0.04789145290851593, 0.00919901393353939, 0.06344813108444214, 0.006769224535673857, 0.016023263335227966, 0.10047853738069534, 0.050857409834861755, -0.017997238785028458, 0.056204985827207565, 0.02087847702205181, 0.12548093497753143, -0.14653737843036652, -0.06895843148231506, -0.0535958856344223, -0.07360120117664337, 0.05255627632141113, -0.055994950234889984, -0.026206757873296738, -0.10799500346183777, -0.17381756007671356, -0.028210986405611038, 0.08806110918521881, 0.3012063503265381, -0.07320404052734375, 0.008140233345329762, -0.05607471242547035, -0.13486377894878387, 0.02454160898923874, 0.05546806380152702, 0.08268649876117706, 0.05077617987990379, -0.05602365732192993, 0.008782642893493176, 0.1445402055978775, -0.06359326094388962, -0.05446361005306244, 0.02032073214650154, -0.19458283483982086, 0.13991643488407135, 0.01983608677983284, 0.08875854313373566, -0.1757780760526657, 0.017983004450798035, -0.15395882725715637, -0.14798425137996674, -0.2452712059020996, -0.0354316271841526, 0.09123633056879044, 0.014021340757608414, -0.10440760850906372, 0.06585176289081573, 0.16765636205673218, 0.07270924001932144, 0.019881684333086014, -0.035783715546131134, -0.021742993965744972, 0.12594954669475555, 0.1962427794933319, -0.0534709095954895, -0.08067825436592102, -0.07421445101499557, 2.853593902870699e-33, -0.10520634800195694, -0.003016918431967497, 0.13949847221374512, -0.17939478158950806, 0.04301372542977333, -0.06924556195735931, 0.09944312274456024, -0.2530670464038849, 0.033671192824840546, 0.02773422934114933, -0.11030284315347672, 0.0447714664041996, 0.008778443560004234, -0.04277201369404793, 0.06686587631702423, -0.14799249172210693, 0.045942313969135284, 0.10593602806329727, -0.19511102139949799, -0.05018417909741402, 0.03477386012673378, -0.1139226108789444, 0.03149466589093208, -0.03274741396307945, -0.059694886207580566, -0.05700313299894333, -0.04795527085661888, -0.02832687646150589, -0.031632937490940094, 0.0066458904184401035, -0.03773978725075722, 0.20618624985218048, -0.07486635446548462, 0.002337123965844512, 0.03630559518933296, -0.16645941138267517, -0.048957690596580505, 0.01693904958665371, 0.06450249254703522, -0.004270505625754595, -0.18615125119686127, -0.05044076219201088, 0.04830362647771835, -0.03410693630576134, 0.05611172318458557, -0.19467733800411224, -0.034339871257543564, 0.1698884516954422, -0.07469151169061661, 0.18037182092666626, -0.04431845247745514, -0.18566733598709106, -0.11906300485134125, 0.1110132485628128, -0.13773714005947113, -0.0015309688169509172, 0.09672779589891434, 0.1025233343243599, 0.16983970999717712, 0.22064612805843353, -0.035207103937864304, -0.023833148181438446, -0.017481915652751923, 0.11938486993312836, -0.027146879583597183, 0.008096178062260151, 0.006761159747838974, 0.011206015944480896, 0.1250513195991516, 0.20833587646484375, 0.02753262035548687, 0.02595188096165657, 0.06450777500867844, -0.0548788458108902, 0.0009810595074668527, -0.021932503208518028, 0.16410601139068604, 0.031156044453382492, -0.11334603279829025, -0.08069761097431183, -0.12996749579906464, 0.11195249110460281, -0.10237999260425568, -0.13783976435661316, 0.0029700028244405985, -0.004232419189065695, -0.023076675832271576, -0.0625663548707962, -0.08800273388624191, -0.015947449952363968, -0.2772059440612793, 0.19428633153438568, -0.038552772253751755, 0.03676874190568924, -0.09928920865058899, -3.461001404970338e-33, 0.021864112466573715, 0.10416550189256668, 0.17407895624637604, 0.03325314447283745, 0.012686360627412796, -0.04430275410413742, 0.2223978489637375, -0.036575108766555786, 0.16504019498825073, 0.08614299446344376, -0.15645436942577362, -0.02803824283182621, 0.1192951574921608, -0.041783656924963, 0.1514366865158081, 0.08432535827159882, 0.03951724246144295, 0.14843130111694336, 0.022295717149972916, 0.009274297393858433, 0.018017122521996498, 0.18097884953022003, -0.04501195624470711, 0.1268257349729538, -0.17321021854877472, 0.033332984894514084, 0.013284525834023952, 0.08935911953449249, -0.13425248861312866, -0.04948420077562332, -0.07735180854797363, -0.1738339215517044, -0.14435935020446777, 0.07971189171075821, 0.022978458553552628, -0.1262904852628708, 0.04535787180066109, 0.07358519732952118, -0.13693402707576752, 0.16630491614341736, 0.11052767187356949, 0.0609937384724617, -0.09692415595054626, -0.06340153515338898, 0.0693683922290802, 0.09271517395973206, 0.12838585674762726, -0.002324855187907815, 0.0043213507160544395, -0.042441606521606445, -0.007943465374410152, 0.06545187532901764, -0.09668097645044327, 0.0517934150993824, -0.0251185093075037, 0.06736187636852264, -0.3035062849521637, 0.012972427532076836, -0.03920383006334305, -0.17202994227409363, -0.12404876202344894, -0.19189287722110748, 0.10583057999610901, 0.31522518396377563, 0.19446955621242523, 0.10813146084547043, 0.0009332641493529081, -0.1848110407590866, -0.13080741465091705, 0.21892833709716797, 0.07815942913293839, 0.08572470396757126, -0.008519869297742844, -0.12989181280136108, -0.03980612754821777, -0.05678469315171242, -0.062076386064291, -0.021555732935667038, -0.06402997672557831, 0.007394724525511265, -0.18514689803123474, 0.0033756126649677753, -0.007422931492328644, 0.1556248664855957, -0.03012879751622677, 0.11428041011095047, 0.20272067189216614, -0.003076329594478011, 0.18455055356025696, -0.127821147441864, 0.0985269621014595, 0.15417557954788208, -0.010798080824315548, 0.037979960441589355, 0.01111666951328516, -9.935401124039345e-08, -0.13490863144397736, -0.04093204438686371, -0.020001661032438278, 0.0914650484919548, 0.3040083944797516, -0.013512665405869484, 0.037595003843307495, 0.13683339953422546, -0.010267156176269054, -0.1950707584619522, 0.13200195133686066, -0.01602015644311905, -0.0001955059269675985, 0.04141433164477348, 0.08672454953193665, 0.0014402054948732257, -0.02784890867769718, 0.008233902975916862, -0.054892510175704956, -0.04075144976377487, -0.012039504013955593, 0.06512559950351715, 0.07111455500125885, 0.03281138464808464, -0.04772600159049034, 0.03826945275068283, -0.08096875995397568, -0.1556721329689026, 0.0512494295835495, -0.02307087928056717, 0.0861855074763298, -0.12221124768257141, 0.14934290945529938, -0.09402838349342346, 0.1231771931052208, 0.164903461933136, -0.11471859365701675, 0.04685703292489052, -0.18728208541870117, 0.10433904826641083, -0.18692125380039215, 0.015528448857367039, 0.12123215198516846, -0.043619319796562195, 0.14580556750297546, 0.05440201982855797, -0.05026581883430481, -0.05202985554933548, 0.03501695767045021, -0.20273970067501068, 0.04688553512096405, 0.07805746048688889, -0.066168412566185, -0.13312628865242004, 0.14763008058071136, -0.06979113072156906, -0.0024543271865695715, -0.20231126248836517, -0.0025558427441865206, -0.06127310171723366, 0.12149282544851303, -0.11969924718141556, 0.020430821925401688, -0.0004653542418964207], metadata={'source': 'AAAMLP-569to.pdf', 'page': 63}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 64             apk(y_true[i], y_pred[i], k=k)         )     # return mean of apk values list     return sum(apk_values) / len(apk_values) ═════════════════════════════════════════════════════════════════════════  Now, we can calculate MAP@k for k=1, 2, 3 and 4 for the same list of lists.  ═════════════════════════════════════════════════════════════════════════ In [X]: y_true = [    ...:     [1, 2, 3],    ...:     [0, 2],    ...:     [1],    ...:     [2, 3],    ...:     [1, 0],    ...:     []    ...: ]  In [X]: y_pred = [    ...:     [0, 1, 2],    ...:     [1],    ...:     [0, 2, 3],    ...:     [2, 3, 4, 0],    ...:     [0, 1, 2],    ...:     [0]    ...: ]  In [X]: mapk(y_true, y_pred, k=1) Out[X]: 0.3333333333333333  In [X]: mapk(y_true, y_pred, k=2) Out[X]: 0.375  In [X]: mapk(y_true, y_pred, k=3) Out[X]: 0.3611111111111111  In [X]: mapk(y_true, y_pred, k=4) Out[X]: 0.34722222222222215  ═════════════════════════════════════════════════════════════════════════  P@k, AP@k and MAP@k all range from 0 to 1 with 1 being the best.  Please note that sometimes you might see different implementations of P@k and AP@k on the internet. For example, let’s take a look at one of these implementations.'),\n",
       " VectorParams(vector=[-0.0834997221827507, -0.04127663001418114, -0.017130447551608086, -0.0003907522768713534, 0.03276455029845238, -0.11560346186161041, 0.011040402576327324, 0.03564970940351486, 0.017200352624058723, 0.03173030540347099, -0.10273578763008118, -0.004604434594511986, 0.1435125470161438, 0.04774526134133339, -0.15857172012329102, 0.06584005057811737, 0.05372397601604462, 0.0333399698138237, 0.028909122571349144, -0.12325283139944077, 0.055184826254844666, 0.1279255598783493, 0.10619958490133286, 0.02517026849091053, 0.07334551960229874, -0.06400855630636215, -0.005190413445234299, 0.17815198004245758, -0.15298281610012054, -0.08780460059642792, -0.01716754585504532, -0.03310420736670494, 0.15075811743736267, 0.02990623563528061, -0.1485745906829834, 0.000589318631682545, -0.09410839527845383, -0.07156087458133698, -0.038198135793209076, -0.07483620941638947, -0.010550342500209808, 0.06324690580368042, 0.08539246767759323, -0.01412585936486721, 0.05266928672790527, 0.12807688117027283, -0.08894464373588562, -0.07247056066989899, -0.06401918828487396, -0.04236596077680588, -0.05891870707273483, 0.1257655769586563, -0.09451055526733398, 0.006905036047101021, -0.13836508989334106, -0.04398861527442932, 0.029502009972929955, -0.08769377321004868, 0.005545998923480511, -0.15047580003738403, -0.04330207407474518, -0.14980024099349976, -0.024742409586906433, -0.06811992079019547, 0.01241119671612978, -0.08653122186660767, 0.07552704215049744, -0.03149910271167755, -0.13453811407089233, 0.13860981166362762, 0.11450158059597015, 0.11649653315544128, -0.021968483924865723, 0.018956581130623817, 0.10034432262182236, -0.010191923007369041, 0.03209170326590538, 0.04599497467279434, -0.1087615117430687, 0.08037160336971283, -0.011265343055129051, 0.003590245498344302, -0.09624148160219193, -0.12524519860744476, 0.03698187693953514, -0.19590921700000763, 0.10125116258859634, 0.1306188702583313, 0.1722731590270996, -0.027525730431079865, -0.028368322178721428, -0.11559450626373291, -0.036660950630903244, -0.04462484270334244, 0.1582225263118744, 0.1759578287601471, 0.11329369992017746, -0.09039167314767838, -0.11902574449777603, 0.039124079048633575, -0.05663241073489189, 0.08258736878633499, -0.06475499272346497, -0.2083883434534073, 0.2589884400367737, 0.06252212822437286, 0.03070802614092827, -0.09239066392183304, 0.13360810279846191, -0.17306220531463623, 0.08438649028539658, -0.08228522539138794, -0.10093936324119568, 0.05228293687105179, 0.13221830129623413, 0.051109738647937775, 0.04627777636051178, 0.12955443561077118, 0.017818741500377655, 0.1802329272031784, -0.051969218999147415, 0.02245226688683033, 0.06442340463399887, 0.13059674203395844, 0.09914437681436539, 0.018701620399951935, -0.07991039752960205, 1.0431241360280975e-32, -0.0649772584438324, -0.0575653612613678, 0.08169326931238174, -0.08787179738283157, -0.0022593389730900526, -0.029335176572203636, -0.0041133081540465355, -0.13073402643203735, 0.002100941725075245, -0.09990372508764267, -0.1381634771823883, 0.08258610218763351, 0.06627791374921799, 0.048384182155132294, 0.13593125343322754, 0.01754770427942276, 0.013581092469394207, 0.059106845408678055, -0.032308172434568405, -0.005749198142439127, 0.05535093694925308, -0.0997607484459877, -0.01196296326816082, -0.1444212943315506, -0.10993179678916931, 0.028368666768074036, -0.047488290816545486, -0.002567940391600132, -0.16535817086696625, -0.05236012116074562, -0.1766805648803711, 0.0489979088306427, 0.0659315437078476, 0.0006255480693653226, 0.05939154326915741, -0.10270486027002335, -0.03706871345639229, 0.01953343115746975, 0.04098144546151161, -0.0965232253074646, -0.11037911474704742, 0.0027379642706364393, -0.04438968002796173, 0.06672555208206177, -0.036572836339473724, -0.06665894389152527, -0.149451345205307, 0.11315927654504776, 0.03288077935576439, 0.11168289184570312, -0.05253246799111366, -0.10460717231035233, 0.03355034068226814, 0.04086962714791298, -0.14446771144866943, 0.0013873946154490113, 0.15838363766670227, -0.017995476722717285, 0.059340398758649826, -0.06481976062059402, 0.12558799982070923, 0.03959004953503609, 0.048111945390701294, -0.051112327724695206, -0.055774301290512085, 0.10254225879907608, 0.07784271240234375, 0.15566803514957428, 0.15597131848335266, 0.1259017437696457, 0.02357788383960724, 0.007716732565313578, -0.02750733681023121, 0.02061675861477852, 0.09842543303966522, 0.0068433890119194984, 0.20138221979141235, -0.20529848337173462, -0.07279684394598007, -0.025934096425771713, 0.11453435570001602, 0.1287589818239212, 0.013797033578157425, -0.1309160441160202, -0.0747334286570549, -0.042044658213853836, 0.05680008605122566, 0.019560571759939194, -0.11292034387588501, -0.13096892833709717, -0.21488042175769806, 0.17395634949207306, 0.05786893889307976, 0.014082170091569424, -0.12797732651233673, -1.1721627794268664e-32, -0.014808334410190582, 0.08928711712360382, 0.17838093638420105, 0.08369787037372589, 0.06711519509553909, -0.0345759317278862, -0.12726543843746185, -0.04134384170174599, 0.08126433938741684, -0.06669380515813828, -0.08318766951560974, -0.07426440715789795, 0.10251831263303757, -0.05703481286764145, 0.1606835424900055, 0.10275859385728836, -0.08658484369516373, 0.03802676498889923, 0.04592194780707359, -0.052956096827983856, 0.05767048895359039, 0.08798858523368835, -0.06873659044504166, 0.046168647706508636, -0.17176109552383423, -0.027464324608445168, 0.038826022297143936, -0.03849196061491966, -0.04803885519504547, -0.1861230731010437, -0.01585487462580204, -0.0720762237906456, -0.02214067615568638, 0.01285677682608366, 0.037455979734659195, -0.007932583801448345, 0.08194118738174438, -0.08065751194953918, -0.08995306491851807, 0.095317542552948, 0.13155221939086914, 0.11921637505292892, -0.09772899746894836, -0.0449940524995327, 0.060763634741306305, 0.0014363568043336272, -0.04545750096440315, 0.013139807619154453, -0.029834922403097153, -0.06187864765524864, 0.01869119144976139, 0.18292014300823212, -0.20907659828662872, 0.04345868527889252, -0.06938893347978592, 0.02540910430252552, -0.2553827464580536, 0.01781526207923889, 0.03368811681866646, -0.007886306382715702, -0.11997423321008682, -0.06738369911909103, 0.03383221849799156, 0.10854489356279373, 0.018796734511852264, 0.1840837299823761, -0.0010470655979588628, -0.10224433243274689, -0.12121739238500595, 0.15173019468784332, -0.06633078306913376, 0.03290245309472084, 0.049958258867263794, -0.03928976505994797, -0.0411878265440464, 0.011250566691160202, 0.06028534099459648, 0.00833493284881115, -0.06876625865697861, 0.042202480137348175, -0.0999072939157486, 0.012684387154877186, -0.026206843554973602, 0.050153955817222595, -0.0794338658452034, -0.009655279107391834, 0.1967972069978714, 0.04656771570444107, 0.0868997871875763, 0.025990499183535576, -0.010349521413445473, 0.1055954098701477, 0.07415107637643814, 0.03291485831141472, -0.06731819361448288, -9.99799993905981e-08, 0.0017835370963439345, -0.034400686621665955, -0.0348421111702919, 0.12988068163394928, 0.08344178646802902, 0.08877042680978775, -0.04206886142492294, 0.007315870374441147, -0.012857926078140736, -0.07951469719409943, 0.1487043797969818, -0.09574040025472641, -0.08827384561300278, 0.07598786801099777, -0.012138736434280872, 0.17680984735488892, 0.01225990243256092, -0.011288300156593323, -0.06871160864830017, -0.005949134007096291, -0.014551226980984211, 0.025221122428774834, 0.15129360556602478, -0.008828972466289997, -0.0695791020989418, 0.020957592874765396, -0.031411975622177124, 0.03527311980724335, -0.04535451531410217, 0.07453694194555283, 0.00011463684495538473, -0.0686393529176712, 0.01959763467311859, -0.04252832010388374, 0.02858199179172516, 0.1115257516503334, -0.0430011972784996, 0.08298274874687195, 0.0020929647143930197, 0.07810544222593307, -0.15553487837314606, -0.027155715972185135, -0.02833811193704605, 0.05007579177618027, 0.16260531544685364, -0.039104897528886795, -0.03150167316198349, -0.07873541116714478, 0.05112655833363533, -0.06639711558818817, 0.07506409287452698, 0.04257630929350853, -0.13599787652492523, -0.1344556361436844, 0.11789248138666153, -0.00029688881477341056, -0.13547542691230774, -0.19503314793109894, 0.040616970509290695, -0.08808659017086029, 0.13383999466896057, -0.037108659744262695, -0.04136493429541588, 0.09377364814281464], metadata={'source': 'AAAMLP-569to.pdf', 'page': 64}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 65 ═════════════════════════════════════════════════════════════════════════ # taken from: # https://github.com/benhamner/Metrics/blob/ # master/Python/ml_metrics/average_precision.py import numpy as np  def apk(actual, predicted, k=10):     \"\"\"     Computes the average precision at k.     This function computes the AP at k between two lists of     items.     Parameters     ----------     actual : list              A list of elements to be predicted (order doesn\\'t matter)     predicted : list              A list of predicted elements (order does matter)     k : int, optional              The maximum number of predicted elements     Returns     -------     score : double              The average precision at k over the input lists     \"\"\"     if len(predicted)>k:         predicted = predicted[:k]      score = 0.0     num_hits = 0.0      for i,p in enumerate(predicted):         if p in actual and p not in predicted[:i]:             num_hits += 1.0             score += num_hits / (i+1.0)      if not actual:         return 0.0      return score / min(len(actual), k) ═════════════════════════════════════════════════════════════════════════  This implementation is another version of AP@k where order matters and we weigh the predictions. This implementation will have slightly different results from what I have presented.'),\n",
       " VectorParams(vector=[-0.014963925816118717, -0.08757214993238449, -0.14793281257152557, -0.022351518273353577, 0.1487855315208435, -0.050191834568977356, 0.005761638283729553, 0.09862873703241348, -0.060704682022333145, -0.05993406102061272, -0.07219576835632324, -0.10251089930534363, 0.08800479769706726, 0.008352200500667095, -0.05791710689663887, 0.02311992458999157, -0.056716978549957275, 0.09817478805780411, -0.07433227449655533, -0.030842488631606102, 0.16168197989463806, 0.15443511307239532, -0.02160773053765297, 0.16743914783000946, 0.005905723664909601, -0.07583646476268768, -0.0045699733309447765, 0.08450289070606232, -0.21724244952201843, -0.051176827400922775, -0.09733739495277405, -0.005213969852775335, -0.012268810532987118, 0.05125834792852402, -0.07174026221036911, 0.015379423275589943, -0.017164435237646103, 0.03523945063352585, -0.016630956903100014, -0.016558712348341942, -0.06583902984857559, -0.05201836675405502, 0.06789101660251617, -0.011470462195575237, 0.015044678002595901, 0.029955852776765823, -0.0752255842089653, -0.09659760445356369, 0.09614239633083344, -0.00030037903343327343, -0.05757827311754227, -0.013707691803574562, -0.07533562928438187, 0.05763851851224899, -0.07661990076303482, -0.034900106489658356, 0.06668616086244583, -0.09992925077676773, 0.045089635998010635, -0.0253987405449152, 0.017904797568917274, -0.008715405128896236, 0.09935356676578522, -0.09862146526575089, 0.05149312689900398, -0.02658640220761299, -0.06648843735456467, 0.11625414341688156, -0.09013688564300537, 0.13611730933189392, -0.031405769288539886, -0.07341577112674713, -0.05423411726951599, 0.0016334509709849954, -0.021189650520682335, -0.06173257529735565, 0.24455255270004272, 0.1186542809009552, -0.03161069005727768, 0.078377366065979, -0.10476600378751755, 0.08248468488454819, 0.10624949634075165, 0.006359599996358156, 0.05712028220295906, -0.16315416991710663, 0.04566163569688797, 0.17620033025741577, 0.08161033689975739, -0.03282459080219269, 0.011203141883015633, -0.05204637721180916, -0.02816852368414402, 0.007704001385718584, 0.10932736843824387, 0.0536656379699707, -0.06362620741128922, -0.09797299653291702, 0.09688503295183182, -0.019291596487164497, -0.012436171062290668, 0.035648465156555176, 0.0017637416021898389, -0.14753925800323486, 0.17917320132255554, 0.00487856101244688, 0.20570312440395355, -0.08392345905303955, 0.13776123523712158, -0.13477350771427155, -0.027014805004000664, -0.13421332836151123, -0.1667890101671219, 0.06113354489207268, 0.1586807817220688, 0.1083877831697464, -0.07918470352888107, -0.0025313205551356077, -0.12484317272901535, 0.08781403303146362, -0.17580848932266235, 0.07163845002651215, 0.13462677597999573, 0.0941053181886673, 0.10563988238573074, 0.01571398414671421, -0.13081124424934387, 1.1706189880022521e-32, -0.08177583664655685, 0.05386533588171005, -0.05756185203790665, -0.05158460512757301, 0.021714266389608383, -0.010607784613966942, -0.08954676240682602, 0.012168738059699535, 0.0567018985748291, 0.06598127633333206, 0.07780931890010834, 0.07209812104701996, -0.021244974806904793, 0.006502972915768623, 0.11170309036970139, -0.009001610800623894, 0.014621556736528873, -0.1137394905090332, 0.10398680716753006, 0.0908445417881012, 0.02216961979866028, -0.012997849844396114, 0.03265977278351784, -0.10944915562868118, 0.0005550803034566343, 0.00969342514872551, -0.06459632515907288, 0.038312878459692, -0.09015602618455887, -0.011506199836730957, -0.04422715678811073, 0.025003617629408836, 0.011306505650281906, -0.08008135855197906, 0.0856110081076622, -0.12527203559875488, -0.09939730912446976, 0.18967193365097046, -0.11793191730976105, -0.03722095862030983, -0.144775390625, 0.058678824454545975, -0.03819651156663895, -0.05018824711441994, -0.016389546915888786, 0.07842780649662018, -0.042049963027238846, 0.07213710993528366, 0.13080570101737976, 0.016738878563046455, -0.11939352750778198, -0.19051726162433624, -0.02545262686908245, -0.025527138262987137, -0.1591533124446869, 0.04372577741742134, -0.03363847732543945, -0.0004409946850501001, 0.01366295013576746, -0.1287185251712799, 0.02598465420305729, -0.1754734367132187, 0.08751605451107025, -0.09202476590871811, 0.005809348076581955, 0.09352720528841019, 0.15596182644367218, 0.14417438209056854, 0.06506789475679398, 0.09422530233860016, -0.08891008049249649, -0.1247330829501152, 0.019706154242157936, -0.0675174742937088, 0.1018482893705368, -0.04988554120063782, 0.09934090822935104, -0.13901206851005554, -0.04939759522676468, 0.05930858477950096, 0.012412271462380886, 0.13124318420886993, 0.00992839690297842, -0.218850776553154, -0.05719662085175514, -0.052661068737506866, 0.06881283968687057, -0.08720312267541885, -0.1689995676279068, -0.022881191223859787, -0.21293294429779053, 0.11524726450443268, -0.03321266174316406, 0.042971204966306686, -0.1563359647989273, -1.5307838449384776e-32, -0.030933044850826263, 0.1498642861843109, 0.012049945071339607, 0.08846114575862885, 0.021070431917905807, 0.01523023284971714, -0.041528936475515366, 0.1086866557598114, 0.059986427426338196, -0.0702134296298027, -0.09536832571029663, -0.07061909884214401, 0.033561866730451584, 0.14951151609420776, 0.0063400473445653915, 0.09519435465335846, -0.1431659311056137, -0.0015684862155467272, 0.031013939529657364, -0.05060073360800743, 0.005650854669511318, 0.10113132745027542, -0.052056703716516495, -0.040983784943819046, -0.22126661241054535, 0.05340597406029701, -0.03645503520965576, 0.07122485339641571, -0.10943887382745743, -0.17746567726135254, -0.011366029269993305, 0.03487203270196915, -0.045315638184547424, 0.05319800600409508, -0.018981903791427612, -0.008998957462608814, 0.04436521977186203, -0.06939566135406494, -0.06849087029695511, 0.02445685677230358, 0.13502050936222076, 0.11468736827373505, -0.17117224633693695, -0.06815023720264435, -0.023295454680919647, 0.04718870297074318, -0.053705036640167236, 0.015679530799388885, -0.028698952868580818, 0.0021792585030198097, 0.009423702023923397, -0.06748464703559875, -0.11405918747186661, 0.028722666203975677, -0.06761032342910767, -0.0315156951546669, -0.16133467853069305, 0.035492848604917526, -0.0817565843462944, 0.05697987228631973, -0.12357466667890549, -0.04039812088012695, 0.01596464030444622, 0.10106414556503296, -0.005717561114579439, 0.012052265927195549, -0.05315258726477623, -0.020889004692435265, -0.07824140042066574, 0.15610964596271515, 0.01917126029729843, 0.10173524171113968, -0.07421381026506424, 0.01118637528270483, -0.05093763768672943, -0.007401785347610712, -0.13896287977695465, -0.12451460212469101, -0.12554070353507996, 0.08396098762750626, 0.08406396210193634, -0.0013163407566025853, 0.013170531019568443, 0.16152940690517426, -0.09098625928163528, -0.012416444718837738, 0.23798465728759766, 0.18764442205429077, 0.06078170984983444, -0.1605999916791916, -0.01614333875477314, 0.07428066432476044, 0.002670955378562212, 0.084539033472538, -0.06155342608690262, -1.0040228204388768e-07, -0.023042164742946625, 0.039568595588207245, 0.10211560875177383, 0.029903974384069443, -0.017429936677217484, 0.08456579595804214, -0.12357424199581146, 0.10299061238765717, -0.05105149373412132, 0.16829842329025269, -0.028499403968453407, -0.01611398346722126, -0.16441534459590912, 0.009562299586832523, -0.14290519058704376, 0.10347109287977219, 0.013191291131079197, 0.04873764142394066, 0.06365150958299637, 0.06503715366125107, 0.11517854034900665, -0.04888284206390381, 0.10625423491001129, -0.0030286170076578856, 0.016670530661940575, -0.14017203450202942, 0.007113668601959944, 0.05491733178496361, -0.005724858492612839, 0.08967474102973938, 0.04362266883254051, -0.06184469163417816, 0.08065293729305267, -0.025006430223584175, -0.006419016979634762, 0.09240550547838211, 0.015486841090023518, -0.10498818755149841, 0.05559880658984184, 0.13466060161590576, -0.1590004563331604, 0.04222540929913521, -0.10225003957748413, -0.0829630047082901, 0.0894642174243927, 0.05951661616563797, 0.06062832474708557, -0.0003771417250391096, 0.07679105550050735, 0.0007703294395469129, 0.062061816453933716, -0.0027179494500160217, -0.05259290710091591, 0.07503429055213928, 0.13089925050735474, -0.1653572916984558, -0.14561879634857178, -0.0064405896700918674, 0.11309382319450378, 0.06372465193271637, 0.041789256036281586, 0.023203056305646896, 0.0316399447619915, -0.052847541868686676], metadata={'source': 'AAAMLP-569to.pdf', 'page': 65}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 66 Now, we come to log loss for multi-label classification. This is quite easy. You can convert the targets to binary format and then use a log loss for each column. In the end, you can take the average of log loss in each column. This is also known as mean column-wise log loss. Of course, there are other ways you can implement this, and you should explore it as you come across it.  We have now reached a stage where we can say that we now know all binary, multi-class and multi-label classification metrics, and now we can move to regression metrics.  The most common metric in regression is error. Error is simple and very easy to understand.  Error = True Value – Predicted Value  Absolute error is just absolute of the above.  Absolute Error = Abs ( True Value – Predicted Value )  Then we have mean absolute error (MAE). It’s just mean of all absolute errors.  ═════════════════════════════════════════════════════════════════════════ import numpy as np   def mean_absolute_error(y_true, y_pred):     \"\"\"     This function calculates mae     :param y_true: list of real numbers, true values     :param y_pred: list of real numbers, predicted values     :return: mean absolute error     \"\"\"     # initialize error at 0     error = 0     # loop over all samples in the true and predicted list     for yt, yp in zip(y_true, y_pred):         # calculate absolute error          # and add to error         error += np.abs(yt - yp)     # return mean error     return error / len(y_true) ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[-0.17251981794834137, -0.09487269073724747, -0.08289875090122223, 0.11338447034358978, 0.0025865458883345127, -0.13568782806396484, -0.05340568721294403, 0.20520104467868805, -0.03458043560385704, 0.004893701057881117, -0.08272486180067062, 0.07299082726240158, 0.10341013222932816, 0.04370931535959244, -0.04219839349389076, -0.055359967052936554, -0.10687335580587387, 0.0710609033703804, -0.02726869471371174, -0.056410860270261765, 0.3583833873271942, 0.15273278951644897, -0.1782338172197342, 0.17035123705863953, 0.17380163073539734, -0.22439995408058167, -0.058538611978292465, 0.12111441045999527, -0.2049003541469574, 0.03843455761671066, 0.0761730745434761, 0.0020501494873315096, 0.01145477406680584, 0.08659081161022186, -0.09386766701936722, 0.044176820665597916, 0.0936637669801712, -0.040227342396974564, -0.0195742417126894, 0.0029921778477728367, -0.09402786195278168, -0.05491071939468384, 0.07078804075717926, -0.006936913821846247, 0.062411319464445114, 0.020699582993984222, -0.033671341836452484, -0.09753037244081497, 0.038095325231552124, -0.04953032359480858, -0.12536679208278656, 0.06662804633378983, -0.19069543480873108, -0.08782995492219925, 0.06256917864084244, 0.0015610057162120938, 0.07065176218748093, -0.06175759807229042, 0.10506188869476318, -0.14739836752414703, -0.011555315926671028, -0.07436218857765198, 0.06932925432920456, -0.018458915874361992, -0.03269202634692192, -0.1192924976348877, 0.04033759981393814, 0.007970689795911312, -0.025294825434684753, 0.09386667609214783, -0.0766642615199089, 0.0797140896320343, -0.19148285686969757, 0.115939199924469, 0.01366723608225584, -0.004692540038377047, 0.1194615364074707, 0.1325564831495285, -0.0555184930562973, 0.04127408564090729, -0.05283541604876518, 0.1144205629825592, 0.10953769832849503, -0.05519517511129379, 0.03237180411815643, -0.11103055626153946, 0.05379793047904968, 0.10677994042634964, 0.11280118674039841, -0.03590550273656845, 0.053804174065589905, -0.04073091968894005, -0.13369058072566986, 0.10584813356399536, 0.09968309849500656, 0.044171884655952454, 0.034009601920843124, -0.06376677751541138, -0.010029195807874203, -0.03099827840924263, -0.039735712110996246, 0.05698184296488762, 0.07498136162757874, -0.13086657226085663, 0.2582307457923889, -0.04406052455306053, 0.24634720385074615, -0.25197312235832214, 0.10366543382406235, -0.16672880947589874, -0.06700792908668518, -0.07030888646841049, -0.16823507845401764, 0.08029922097921371, 0.1373002976179123, 0.1120898500084877, -0.028989413753151894, 0.10099909454584122, -0.16468584537506104, 0.04167953133583069, -0.13337330520153046, 0.1691245585680008, 0.1553598791360855, 0.104457788169384, 0.14684294164180756, -0.04229894280433655, -0.18239659070968628, 1.2144235645804538e-32, -0.18947015702724457, 0.02550707384943962, 0.0961243286728859, -0.03034713678061962, -0.04737253114581108, -0.020914671942591667, -0.0800916999578476, -0.06337782740592957, 0.08466703444719315, 0.07800701260566711, -0.09424811601638794, 0.01754695177078247, 0.005056636407971382, 0.005873228423297405, 0.15322335064411163, 0.13298211991786957, 0.03705708310008049, -0.08096037805080414, 0.04087694361805916, -0.05843183770775795, 0.13569612801074982, -0.07958196103572845, 0.11671385169029236, -0.038855019956827164, -0.07875347882509232, 0.017405355349183083, 0.03368431702256203, -0.019436141476035118, -0.001278518931940198, 0.04601452499628067, -0.11829222738742828, 0.019042737782001495, 0.10630329698324203, -0.04324515536427498, 0.14859330654144287, -0.1595703363418579, 0.0532584972679615, -0.03479154035449028, -0.07350650429725647, -0.00310591422021389, -0.08861061930656433, 0.06654421985149384, 0.05234348401427269, 0.01929611526429653, -0.027402514591813087, -0.09557372331619263, -0.05364219844341278, 0.10137679427862167, 0.16452401876449585, 0.10714946687221527, -0.19003355503082275, -0.053677868098020554, -0.08874606341123581, 0.07503800094127655, -0.12913130223751068, 0.0802813172340393, 0.12976936995983124, 0.0953914150595665, 0.022937124595046043, -0.0508650578558445, -0.04656499624252319, -0.0976518839597702, 0.09620988368988037, -0.19478121399879456, 0.02899934910237789, 0.14830626547336578, 0.13833624124526978, 0.143185093998909, 0.010014623403549194, 0.12537725269794464, 0.002954537747427821, -0.1417308747768402, -0.013528713025152683, 0.01610327512025833, 0.04075578600168228, -0.15098051726818085, 0.2054288387298584, -0.046537626534700394, -0.014105725102126598, -0.08151643723249435, -0.05189952626824379, 0.13109812140464783, -0.24087925255298615, -0.2742420434951782, -0.08552520722150803, -0.18655182421207428, 0.03581467270851135, -0.0649179220199585, -0.22035720944404602, -0.07747851312160492, -0.3083345293998718, 0.12733419239521027, -0.049519672989845276, -0.0070579685270786285, -0.24368777871131897, -1.801502691858346e-32, 0.04033803939819336, 0.12748803198337555, 0.011240219697356224, 0.13233254849910736, -0.012849943712353706, -0.028228284791111946, 0.044608063995838165, -0.043058931827545166, 0.03886621817946434, -0.1579008847475052, -0.08135277777910233, -0.19825854897499084, 0.08789463341236115, 0.14664609730243683, 0.1512877643108368, 0.132534921169281, -0.1132577657699585, -0.06579235196113586, -0.0656556561589241, -0.017695454880595207, 0.0024757119826972485, 0.10080122202634811, -0.0027745203115046024, -0.04694584757089615, -0.10977130383253098, -0.025645198300480843, -0.09080569446086884, 0.11048950999975204, -0.07874012738466263, -0.12536229193210602, 0.01152307540178299, 0.11307850480079651, -0.22463534772396088, -0.001594509114511311, -0.010358581319451332, 0.01514500379562378, 0.16716592013835907, -0.12363183498382568, -0.04874708503484726, -0.004931674804538488, 0.15857601165771484, 0.1813211739063263, -0.01593245565891266, -0.038679737597703934, 0.07630707323551178, 0.06845419108867645, -0.03445958346128464, -0.10586217790842056, -0.010043379850685596, -0.04835112392902374, -0.032954487949609756, -0.03690265491604805, -0.1457700878381729, 0.12749484181404114, -0.16079795360565186, 0.05954284220933914, -0.2696973979473114, 0.08631673455238342, -0.11365263909101486, -0.029399588704109192, -0.042165812104940414, -0.042080286890268326, -0.10697111487388611, 0.010121412575244904, -0.09614595025777817, 0.10303635895252228, -0.10189623385667801, -0.029451284557580948, 0.031383950263261795, 0.07490880787372589, -0.07208419591188431, -0.020674992352724075, -0.02790260501205921, -0.024215752258896828, -0.15818923711776733, -0.0006420519202947617, -0.12417636811733246, -0.08465462177991867, -0.01999390870332718, 0.09208483248949051, 0.05394107848405838, 0.14419175684452057, 0.10383595526218414, 0.04633648693561554, -0.07078899443149567, -0.0714997947216034, 0.16020619869232178, 0.27565011382102966, -0.005991068668663502, -0.14827249944210052, -0.04899395629763603, 0.08587510138750076, -0.007536404766142368, 0.17510126531124115, 0.040307626128196716, -1.009330361512184e-07, -0.11127182096242905, 0.051744233816862106, 0.16985389590263367, -0.016147799789905548, 0.04851715266704559, -0.04781276732683182, -0.22252313792705536, 0.016730941832065582, -0.08939830213785172, -0.043205928057432175, -0.01479831337928772, -0.0807773768901825, -0.21943984925746918, -0.061901774257421494, -0.016712423413991928, 0.1554768681526184, -0.10963369905948639, 0.0014551924541592598, 0.026203593239188194, 0.002671909751370549, 0.11557987332344055, -0.11775533854961395, -0.010556013323366642, 0.09081803262233734, -0.010920415632426739, -0.09717829525470734, -0.023792482912540436, 0.08036863803863525, -0.07423080503940582, 0.07437942177057266, 0.08382485806941986, -0.030119339004158974, 0.10635125637054443, -0.022181393578648567, 0.023641182109713554, 0.06374915689229965, 0.11828692257404327, 0.0065626525320112705, 0.1425778865814209, 0.0872054472565651, -0.1588805466890335, 0.02766922488808632, -0.10401307791471481, -0.031097564846277237, 0.13687847554683685, 0.09458507597446442, 0.06773212552070618, 0.06796833872795105, 0.05476295202970505, -0.09983716905117035, 0.07231120020151138, -0.014912054874002934, -0.13324466347694397, 0.06386050581932068, 0.10053325444459915, -0.09946764260530472, -0.15425269305706024, -0.09872446954250336, -0.0013700370909646153, 0.008478481322526932, 0.027899842709302902, 0.015131337568163872, 0.0439237505197525, 0.01914113387465477], metadata={'source': 'AAAMLP-569to.pdf', 'page': 66}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 67 Similarly, we have squared error and mean squared error (MSE).  Squared Error = ( True Value – Predicted Value )2  And mean squared error (MSE) can be implemented as follows.  ═════════════════════════════════════════════════════════════════════════ def mean_squared_error(y_true, y_pred):     \"\"\"     This function calculates mse     :param y_true: list of real numbers, true values     :param y_pred: list of real numbers, predicted values     :return: mean squared error     \"\"\"     # initialize error at 0     error = 0     # loop over all samples in the true and predicted list     for yt, yp in zip(y_true, y_pred):         # calculate squared error          # and add to error         error += (yt - yp) ** 2     # return mean error     return error / len(y_true) ═════════════════════════════════════════════════════════════════════════  MSE and RMSE (root mean squared error) are the most popular metrics used in evaluating regression models.  RMSE = SQRT ( MSE )  Another type of error in same class is squared logarithmic error. Some people call it SLE, and when we take mean of this error across all samples, it is known as MSLE (mean squared logarithmic error) and implemented as follows.  ═════════════════════════════════════════════════════════════════════════ import numpy as np   def mean_squared_log_error(y_true, y_pred):     \"\"\"     This function calculates msle     :param y_true: list of real numbers, true values     :param y_pred: list of real numbers, predicted values     :return: mean squared logarithmic error'),\n",
       " VectorParams(vector=[-0.04445189610123634, -0.08680403232574463, -0.08920522779226303, 0.05958306044340134, 0.08033203333616257, -0.18770724534988403, -0.051257580518722534, 0.22085340321063995, -0.07569465786218643, 0.07306773960590363, -0.049199428409338, -0.036648523062467575, 0.12738484144210815, 0.03298085182905197, -0.00836483109742403, 0.00246394332498312, -0.11780346930027008, 0.07796263694763184, -0.04816461354494095, -0.03354686126112938, 0.17975297570228577, 0.18750472366809845, 0.03040090948343277, 0.1059935986995697, 0.17033757269382477, -0.1269303262233734, -0.056688472628593445, 0.10196007043123245, -0.11418130993843079, 0.012448820285499096, 0.0009123022900894284, 0.04345277324318886, 0.04287727177143097, 0.03237603232264519, -0.07559014856815338, 0.0376117043197155, 0.016312357038259506, -0.05555088818073273, 0.006749726831912994, 0.015046360902488232, -0.034721098840236664, 0.011317761614918709, 0.032157886773347855, -0.014643109403550625, 0.027766073122620583, 0.04599623754620552, -0.07519923895597458, 0.012911416590213776, 0.0751282200217247, 0.070682592689991, -0.08083201944828033, 0.0357246957719326, -0.14690132439136505, -0.04747619852423668, -0.018812989816069603, -0.01888565719127655, 0.08967864513397217, -0.05639449879527092, 0.0932265892624855, -0.152030810713768, 0.009853069670498371, -0.05109914764761925, 0.1054428368806839, -0.0628773495554924, 0.014360310509800911, -0.08197471499443054, 0.009565495885908604, 0.04183191433548927, -0.07853803038597107, 0.08563277870416641, -0.010972334071993828, 0.03222581744194031, -0.126886785030365, -0.01567186787724495, -0.022041916847229004, 0.02516554668545723, 0.10787831246852875, 0.15488047897815704, 0.0075674899853765965, -0.0008716583251953125, -0.024364858865737915, -0.03862630948424339, 0.050096575170755386, -0.10889408737421036, -0.015989037230610847, -0.10282313078641891, 0.13470891118049622, 0.13828276097774506, 0.0797727108001709, -0.09758966416120529, 0.024226799607276917, 0.01955617405474186, -0.12748241424560547, 0.020150598138570786, 0.1522187739610672, 0.14107315242290497, -0.007333484012633562, -0.050500765442848206, -0.011370431631803513, -0.05606190860271454, -0.08315964788198471, 0.00468491343781352, 0.07831395417451859, -0.15049618482589722, 0.11407183855772018, -0.0892656147480011, 0.18966807425022125, -0.11442859470844269, 0.06612002849578857, -0.14198967814445496, -0.1311543583869934, -0.11683477461338043, -0.07546454668045044, 0.06058065965771675, 0.13627272844314575, 0.03727000206708908, 0.05905226245522499, 0.11765074729919434, -0.12588223814964294, 0.08172435313463211, -0.09982509911060333, 0.10376111418008804, 0.16652117669582367, 0.12481744587421417, 0.09227276593446732, -0.1476275771856308, -0.18183597922325134, 1.4625314103202708e-32, -0.11729531735181808, 0.05549301952123642, 0.014369666576385498, -0.06914039701223373, 0.013321011327207088, 0.011221609078347683, -0.06769511848688126, -0.003945787437260151, 0.027386853471398354, 0.0037352959625422955, -0.08651421964168549, -0.027644624933600426, -0.02862061746418476, -0.02237972430884838, 0.05758335068821907, 0.1313343048095703, -0.02480173483490944, -0.0855807438492775, -0.02041693590581417, -0.10163626074790955, 0.04873555526137352, 0.0007435561856254935, 0.02264905348420143, -0.026925209909677505, -0.09761516004800797, 0.038383517414331436, 0.09439824521541595, 0.026904525235295296, -0.08417738229036331, -0.03238033875823021, 0.015576086938381195, 0.07683145999908447, 0.007629770785570145, -0.09232735633850098, 0.03925527259707451, -0.13404589891433716, 0.10196471214294434, 0.06312323361635208, -0.13746197521686554, 0.019756648689508438, -0.1630861759185791, 0.041523247957229614, -0.020163923501968384, -0.06595566868782043, -0.06086479127407074, -0.1581065058708191, -0.05199640244245529, 0.12122439593076706, 0.14285945892333984, 0.15981139242649078, -0.17262697219848633, -0.07509680837392807, -0.029696030542254448, 0.04867704585194588, -0.15542186796665192, 0.013898701407015324, 0.030979450792074203, 0.1086338609457016, 0.057036589831113815, -0.09649904817342758, 0.0739460363984108, -0.09579446911811829, 0.09317787736654282, -0.20161308348178864, -0.06920559704303741, 0.07589941471815109, 0.12857219576835632, 0.13106563687324524, -0.006373752374202013, 0.12334237992763519, -0.02034442313015461, -0.06393586844205856, -0.045533712953329086, 0.0059840199537575245, 0.0514204166829586, -0.09194536507129669, 0.12383005023002625, 0.0047134216874837875, -0.09754457324743271, -0.03649061173200607, -0.10847822576761246, 0.08106043934822083, -0.15161405503749847, -0.237019345164299, -0.06566287577152252, -0.05144323781132698, 0.055389631539583206, -0.014579792506992817, -0.18922771513462067, -0.1015859842300415, -0.1305340975522995, 0.06592228263616562, -0.016314882785081863, 0.032984018325805664, -0.14318899810314178, -1.7905547252219625e-32, -0.1184341311454773, 0.18635855615139008, 0.035759516060352325, 0.13767898082733154, -0.011327399872243404, -0.01775922253727913, 0.08309125155210495, -0.04574005305767059, 0.048304568976163864, -0.1312253773212433, -0.1261996179819107, -0.16148164868354797, -0.03989594429731369, 0.0570792481303215, 0.06179692968726158, 0.08834189176559448, -0.13693581521511078, 0.05998203530907631, -0.00821713637560606, 0.07978271692991257, 0.025680584833025932, 0.09837710112333298, -0.0319075770676136, 0.03210916370153427, -0.14793533086776733, 0.04422859475016594, -0.06527609378099442, 0.09540741890668869, -0.08715900033712387, -0.202811598777771, 0.04342997074127197, 0.060925014317035675, -0.153574600815773, 0.055425163358449936, -0.04853710159659386, -0.05272159352898598, 0.10154242068529129, -0.09790171682834625, -0.025301247835159302, 0.041163742542266846, 0.13698478043079376, 0.08488594740629196, -0.10222896188497543, -0.1190546452999115, 0.04286227375268936, 0.022609148174524307, 0.09759882092475891, -0.14070281386375427, 0.026779165491461754, -0.10023127496242523, 0.08347480744123459, 0.04721119627356529, -0.06921472400426865, 0.11433142423629761, -0.07111570984125137, 0.10647904127836227, -0.2176113724708557, 0.10877218842506409, -0.0576217956840992, -0.038190919905900955, -0.07453978806734085, -0.019927071407437325, -0.001954245613887906, 0.02755153737962246, -0.0904785692691803, 0.06000789627432823, -0.10372497886419296, 0.004305741749703884, 0.06957124173641205, 0.1287483423948288, -0.029996324330568314, 0.08740117400884628, 0.04331110790371895, 0.036802805960178375, -0.03705816715955734, 0.032024722546339035, -0.07506576925516129, -0.09275997430086136, -0.047538917511701584, 0.06875606626272202, 0.045908860862255096, 0.10890164971351624, -0.02183232270181179, 0.03786824643611908, -0.15285001695156097, -0.04715820029377937, 0.1836615651845932, 0.18887390196323395, -0.027636848390102386, -0.12643738090991974, -0.026502400636672974, 0.13691328465938568, -0.0035855299793183804, 0.18751072883605957, 0.0478917732834816, -1.0140011852399766e-07, -0.028334736824035645, -0.018002435564994812, 0.063409723341465, 0.05706139653921127, 0.05935845896601677, 0.03970087692141533, -0.16159504652023315, -0.012477039359509945, -0.11168556660413742, -0.06841164082288742, 0.017606329172849655, -0.020152205601334572, -0.20204894244670868, -0.0918399766087532, -0.11432868987321854, 0.08865053206682205, -0.08117570728063583, 0.08563224226236343, 0.06255804002285004, 0.056626349687576294, 0.07416782528162003, -0.07629955559968948, 0.04789692163467407, 0.02343190275132656, 0.04933830723166466, -0.04861947149038315, -0.055648770183324814, 0.07209806144237518, -0.07072048634290695, -0.008522736839950085, 0.07759590446949005, -0.15856890380382538, 0.12211521714925766, -0.0225767083466053, 0.014359286054968834, 0.10338706523180008, 0.12709958851337433, -0.007711015176028013, 0.03868694603443146, 0.11207509785890579, -0.11234607547521591, 0.06108863651752472, -0.062261659651994705, -0.050691548734903336, 0.09858532249927521, -0.026967626065015793, 0.05154027044773102, -0.019155798479914665, 0.04308735951781273, -0.11375993490219116, 0.1054161861538887, 0.00025127921253442764, -0.12830419838428497, 0.06210469454526901, 0.04132353141903877, -0.11132647842168808, -0.14013038575649261, -0.07500632852315903, -0.046463821083307266, 0.0593593493103981, 0.0897374302148819, 0.04160170629620552, 0.04093863442540169, 0.0122795719653368], metadata={'source': 'AAAMLP-569to.pdf', 'page': 67}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 68     \"\"\"     # initialize error at 0     error = 0     # loop over all samples in true and predicted list     for yt, yp in zip(y_true, y_pred):         # calculate squared log error          # and add to error         error += (np.log(1 + yt) - np.log(1 + yp)) ** 2     # return mean error     return error / len(y_true) ═════════════════════════════════════════════════════════════════════════  Root mean squared logarithmic error is just a square root of this. It is also known as RMSLE.   Then we have the percentage error:  Percentage Error = ( ( True Value – Predicted Value ) / True Value ) * 100  Same can be converted to mean percentage error for all samples.  ═════════════════════════════════════════════════════════════════════════ def mean_percentage_error(y_true, y_pred):     \"\"\"     This function calculates mpe     :param y_true: list of real numbers, true values     :param y_pred: list of real numbers, predicted values     :return: mean percentage error     \"\"\"     # initialize error at 0     error = 0      # loop over all samples in true and predicted list     for yt, yp in zip(y_true, y_pred):         # calculate percentage error          # and add to error         error += (yt - yp) / yt      # return mean percentage error     return error / len(y_true) ═════════════════════════════════════════════════════════════════════════  And an absolute version of the same (and more common version) is known as mean absolute percentage error or MAPE.'),\n",
       " VectorParams(vector=[-0.12984777987003326, -0.08141794800758362, -0.06676023453474045, 0.09423178434371948, 0.1644216626882553, -0.1397513896226883, -0.06714806705713272, 0.2075376808643341, -0.016815168783068657, 0.009077968075871468, -0.06341837346553802, -0.011736336164176464, 0.05860605090856552, 0.13688869774341583, -0.03909720107913017, -0.05218874663114548, 0.14158861339092255, 0.046203114092350006, -0.030061088502407074, -0.07503193616867065, 0.09193181246519089, 0.10338230431079865, 0.025705687701702118, 0.08827313035726547, 0.15352275967597961, -0.08231048285961151, -0.052375875413417816, 0.13370497524738312, -0.17907582223415375, 0.0029822050128132105, -0.06038924306631088, 0.019239434972405434, 0.008748513646423817, -0.05659221485257149, -0.0941069945693016, 0.04244711995124817, 0.05314655974507332, 0.018468519672751427, 0.020119689404964447, -0.0413556843996048, -0.021705882623791695, 0.0016876307781785727, 0.06434330344200134, 0.08171771466732025, 0.05936248227953911, 0.0383879579603672, -0.048406537622213364, -0.024174902588129044, 0.0006198650225996971, -0.04788068309426308, -0.14862027764320374, 0.08533399552106857, -0.158577099442482, 0.04828421026468277, 0.02269645407795906, 0.017128922045230865, -0.008908628486096859, -0.05016182363033295, -0.009143560193479061, -0.13884463906288147, 0.09079140424728394, -0.1210431307554245, 0.012596306391060352, 0.02689548023045063, 0.0034478562884032726, -0.09657490253448486, -0.023306850343942642, -0.01242295652627945, -0.03139154985547066, 0.16891342401504517, 0.023687472566962242, 0.11734776198863983, -0.1423817276954651, 0.032466545701026917, 0.011172931641340256, -0.00783573929220438, 0.18562856316566467, 0.17766889929771423, -0.076473169028759, 0.06410332024097443, 0.004571148660033941, 0.06588853895664215, 0.058912426233291626, -0.09210310131311417, 0.0017065278952941298, -0.058534421026706696, 0.10487217456102371, 0.048770226538181305, 0.029107362031936646, -0.040977947413921356, 0.08114039152860641, 0.01092606782913208, -0.059117622673511505, -0.04459661245346069, 0.04942552372813225, 0.13878916203975677, 0.006213394924998283, -0.0783596858382225, -0.03834785148501396, -0.022859647870063782, -0.05038692057132721, 0.07649797201156616, -0.003982704598456621, -0.1873728185892105, 0.19447661936283112, -0.023759406059980392, 0.0751640647649765, -0.1718844622373581, 0.16266603767871857, -0.07289926707744598, -0.0605815090239048, -0.14463473856449127, -0.14790908992290497, 0.13122625648975372, 0.0832875445485115, 0.050966065376996994, -0.04089021310210228, 0.1292065978050232, -0.06860450655221939, 0.08021519333124161, -0.11688287556171417, 0.10534274578094482, 0.1193622276186943, 0.06304339319467545, 0.07688325643539429, -0.0850740596652031, -0.2756165564060211, 1.265444060167972e-32, -0.10630888491868973, 0.01524159125983715, 0.01636672019958496, 0.0026494937483221292, 0.007603000849485397, -0.12627147138118744, -0.1373787671327591, 0.03899582847952843, 0.11194994300603867, 0.12428338080644608, -0.07504834234714508, 0.008776208385825157, 0.003058833070099354, 0.05832746624946594, 0.17709897458553314, 0.1365177035331726, -0.05458532273769379, -0.022045467048883438, -0.04018025100231171, 0.01609274186193943, 0.035399992018938065, -0.050338264554739, 0.02656383253633976, -0.032971370965242386, -0.023091202601790428, 0.007294552866369486, 0.016796443611383438, 0.051454808562994, -0.1470896452665329, 0.010973968543112278, -0.05869574099779129, 0.06950583308935165, 0.08733757585287094, -0.051745668053627014, 0.03859907388687134, -0.16707392036914825, 0.004370677284896374, 0.013511964119970798, -0.1239205077290535, -0.013451999984681606, -0.15661674737930298, 0.07748475670814514, -0.107845239341259, -0.02809765562415123, 0.03888710215687752, -0.09927459806203842, 0.02099236287176609, 0.06184577941894531, 0.05651802197098732, 0.19088390469551086, -0.10265876352787018, -0.025938307866454124, -0.017737049609422684, 0.05263892561197281, -0.17295008897781372, 0.015086192637681961, 0.022311896085739136, 0.0247482992708683, 0.055061206221580505, 0.01208560448139906, 0.01389721967279911, -0.1178554892539978, 0.10710974037647247, -0.20448826253414154, -0.07238242775201797, 0.07931434363126755, 0.09928422421216965, 0.06122707203030586, -0.023302720859646797, 0.17604966461658478, -0.006026871502399445, -0.05612760782241821, -0.009847656823694706, -0.03243865445256233, 0.1786266416311264, -0.08427437394857407, 0.22517850995063782, -0.15500900149345398, 0.055063992738723755, -0.10621674358844757, -0.0539427325129509, 0.13120613992214203, -0.05181855708360672, -0.2582966983318329, -0.11310867220163345, -0.13494722545146942, 0.06444666534662247, -0.03342573717236519, -0.1334400773048401, -0.030522450804710388, -0.17606495320796967, 0.045319873839616776, -0.08584727346897125, 0.024262040853500366, -0.2066066563129425, -1.5760956256796243e-32, -0.058292996138334274, 0.06907626241445541, -0.029093438759446144, 0.2005949765443802, -0.1052069365978241, -0.02053683064877987, 0.031104790046811104, -0.01077154092490673, 0.11666694283485413, -0.19706860184669495, -0.0625067725777626, -0.021047279238700867, 0.05924493446946144, 0.19372643530368805, 0.11970292031764984, 0.040947165340185165, -0.12461327016353607, -0.053742263466119766, -0.07610730081796646, 0.0746091902256012, 0.051725514233112335, 0.10545938462018967, -0.015285803936421871, -0.0281109269708395, -0.25056082010269165, 0.07529336214065552, -0.0862114205956459, 0.034436121582984924, -0.09232325851917267, -0.18168266117572784, 0.011834424920380116, 0.09402637928724289, -0.193053737282753, -0.040063805878162384, -0.059875816106796265, 0.03533850237727165, 0.030876703560352325, -0.0553826205432415, -0.060069967061281204, 0.058125708252191544, 0.16473506391048431, 0.12716393172740936, -0.22494493424892426, -0.10876676440238953, -0.006187574937939644, -0.06028705835342407, 0.033946648240089417, -0.08804003149271011, 0.024511102586984634, -0.0932726263999939, 0.041435323655605316, 0.06723988801240921, -0.00779790710657835, 0.14268459379673004, -0.07838064432144165, 0.07166814059019089, -0.33668190240859985, 0.060415130108594894, -0.02270343154668808, 0.09108906239271164, -0.0951375812292099, -0.0845583826303482, -0.024534184485673904, 0.10042083263397217, -0.11827271431684494, 0.10711701959371567, -0.044729601591825485, 0.06963980942964554, 0.06046172231435776, 0.10875412076711655, -0.020345406606793404, 0.03541017696261406, 0.07235082983970642, -0.00898129865527153, -0.119232177734375, 0.019861992448568344, -0.03419182449579239, -0.12604470551013947, -0.011948478408157825, 0.10299800336360931, -0.004130650777369738, 0.10214203596115112, -0.0035938567016273737, 0.03618179261684418, -0.13408106565475464, 0.021710941568017006, 0.1139378547668457, 0.1914890557527542, 0.014632293954491615, -0.08847957849502563, 0.041109006851911545, 0.06883140653371811, -0.05512527748942375, 0.14576944708824158, 0.13581998646259308, -1.0069040001781104e-07, 0.0017075017094612122, 0.028499793261289597, 0.17607559263706207, 0.0013357162242755294, 0.003511392744258046, 0.04681708663702011, -0.14094358682632446, 0.03995590656995773, -0.13867069780826569, 0.08501207828521729, 0.0324040949344635, -0.008912651799619198, -0.23411902785301208, -0.06051717698574066, -0.14801762998104095, 0.1872415989637375, 0.019349349662661552, 0.10349422693252563, -0.002317279577255249, 0.12079368531703949, 0.008292143233120441, -0.00020849163411185145, 0.04604681581258774, -0.06644425541162491, 0.08501400798559189, -0.053704239428043365, -0.053177036345005035, 0.118709497153759, -0.07079767435789108, 0.07524076849222183, 0.00985045451670885, -0.1351003646850586, 0.14729304611682892, 0.04239121824502945, -0.0042912582866847515, 0.01863359659910202, 0.06497496366500854, -0.027817558497190475, -0.021579470485448837, 0.03623219206929207, -0.12259489297866821, 0.049426350742578506, -0.04158341512084007, 0.0014886249555274844, 0.04083605110645294, 0.0028783553279936314, 0.06954887509346008, 0.013853581622242928, -0.053744979202747345, -0.15516792237758636, 0.05132605880498886, 0.04418345168232918, -0.1937926709651947, 0.050498735159635544, 0.03346148505806923, -0.07398571074008942, -0.243662029504776, -0.052967436611652374, -0.1367100179195404, 0.07581281661987305, 0.03900676593184471, 0.0932730957865715, 0.050109997391700745, -0.0437629334628582], metadata={'source': 'AAAMLP-569to.pdf', 'page': 68}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 69 ═════════════════════════════════════════════════════════════════════════ import numpy as np   def mean_abs_percentage_error(y_true, y_pred):     \"\"\"     This function calculates MAPE     :param y_true: list of real numbers, true values     :param y_pred: list of real numbers, predicted values     :return: mean absolute percentage error     \"\"\"     # initialize error at 0     error = 0     # loop over all samples in true and predicted list     for yt, yp in zip(y_true, y_pred):         # calculate percentage error          # and add to error         error += np.abs(yt - yp) / yt     # return mean percentage error     return error / len(y_true) ═════════════════════════════════════════════════════════════════════════  The best thing about regression is that there are only a few most popular metrics that can be applied to almost every regression problem. And it is much easier to understand when we compare it to classification metrics.   Let’s talk about another regression metric known as R2 (R-squared), also known as the coefficient of determination.   In simple words, R-squared says how good your model fits the data. R-squared closer to 1.0 says that the model fits the data quite well, whereas closer 0 means that model isn’t that good. R-squared can also be negative when the model just makes absurd predictions.   The formula for R-squared is shown in figure 10, but as always a python implementation makes things more clear.     Figure 10: Formula for R-squared'),\n",
       " VectorParams(vector=[-0.10910172760486603, -0.05574583262205124, -0.10694926977157593, 0.09766406565904617, 0.06432735919952393, -0.1665402501821518, -0.17160890996456146, 0.04696064442396164, -0.04702453315258026, 0.01468456257134676, -0.047155141830444336, -0.060123953968286514, 0.04345421865582466, 0.13376979529857635, -0.015575793571770191, 0.02122633345425129, 0.016676828265190125, 0.11026551574468613, 0.015217903070151806, -0.056173160672187805, 0.05596042051911354, 0.15601873397827148, -0.004835096187889576, 0.10409779846668243, 0.1310250610113144, -0.13213595747947693, -0.04789286106824875, 0.05765322223305702, -0.21356460452079773, -0.022256482392549515, 0.04147953912615776, -0.048887938261032104, 0.07571427524089813, -0.09241338074207306, -0.10159685462713242, 0.014374659396708012, 0.05790781229734421, -0.007788293529301882, -0.04320868104696274, 0.009311561472713947, -0.11980456113815308, 0.039045535027980804, 0.02812453731894493, 0.03399055451154709, 0.047363873571157455, 0.021314693614840508, -0.05129089578986168, -0.06905533373355865, 0.038022711873054504, 0.0063364566303789616, -0.07489984482526779, 0.11706598848104477, -0.16965197026729584, -0.045131005346775055, 0.07057427614927292, 0.00019825440540444106, 0.0589984767138958, -0.09223446995019913, -0.0001602208794793114, -0.1469395011663437, -0.031171483919024467, -0.075330950319767, 0.08383715152740479, -0.0921076238155365, 0.01400266494601965, -0.05998309701681137, 0.08626352995634079, 0.06899428367614746, 0.010739967226982117, 0.1628742516040802, -0.0183729100972414, 0.019308149814605713, -0.054685451090335846, -0.0029701837338507175, -0.028805382549762726, 0.06713162362575531, 0.09561718255281448, 0.10966018587350845, -0.0330585278570652, 0.07734636962413788, 0.019024118781089783, 0.04051380231976509, 0.07877428084611893, -0.11089450865983963, -0.0055945017375051975, -0.13888023793697357, 0.10542870312929153, 0.09290295839309692, 0.21991059184074402, -0.019183043390512466, 0.10277125984430313, -0.001323623233474791, -0.1034817099571228, -0.13534393906593323, 0.14675095677375793, 0.11052302271127701, -0.038636092096567154, -0.10733581334352493, 0.009491696022450924, -0.011363927274942398, 0.06517161428928375, 0.027207372710108757, 0.018572118133306503, -0.2907623052597046, 0.17336037755012512, 0.0367300920188427, 0.23679673671722412, -0.038488682359457016, 0.10365086048841476, -0.14873118698596954, -0.04261060804128647, -0.13127359747886658, -0.06966886669397354, 0.11092393845319748, 0.11975325644016266, 0.057918399572372437, 0.07000395655632019, 0.07249106466770172, -0.04177374765276909, 0.08462445437908173, -0.04936476796865463, 0.09330882132053375, 0.19136668741703033, 0.142898827791214, 0.11663763225078583, -0.03809339925646782, -0.19045528769493103, 1.630167925007068e-32, -0.1830359399318695, 0.05822298675775528, 0.040246836841106415, -0.006844914983958006, -0.04136955738067627, 0.0038039772771298885, 0.01929202489554882, 0.039311494678258896, 0.02714577317237854, 0.08964728564023972, -0.10215117037296295, 0.04988076165318489, -0.05295867472887039, -0.1058829128742218, 0.21098431944847107, -0.025968190282583237, -0.045052412897348404, -0.08281473070383072, 0.05021705478429794, -0.04646316170692444, 0.04737236723303795, -0.1018608883023262, 0.02634650655090809, -0.04070539399981499, -0.0033393343910574913, -0.06824073940515518, 0.0049966247752308846, 0.046731818467378616, -0.09676971286535263, -0.03584882616996765, 0.002883616602048278, 0.06290774047374725, -0.009593535214662552, -0.04944067448377609, -0.0031728395260870457, -0.12239839881658554, 0.015524000860750675, 0.09630274027585983, -0.06226198002696037, -0.023670343682169914, -0.12838484346866608, 0.03667246177792549, -0.056105829775333405, -0.007401091977953911, -0.014289969578385353, -0.07398512214422226, 0.057322487235069275, 0.13680948317050934, 0.04286711663007736, 0.08376432955265045, -0.14173370599746704, -0.06850537657737732, -0.05656631663441658, -0.03930766507983208, -0.09577085077762604, 0.03947394713759422, 0.05634113773703575, 0.045516323298215866, -0.03938116505742073, 0.0209285169839859, -0.041932784020900726, -0.10515682399272919, 0.024039847776293755, -0.16989587247371674, -0.08442456275224686, 0.059913258999586105, 0.03880402445793152, 0.13263648748397827, 0.04295329004526138, 0.13717831671237946, 0.02173415757715702, -0.048385199159383774, -0.033467184752225876, -0.12482315301895142, 0.10603338479995728, -0.1055009737610817, 0.1889554113149643, -0.07483334839344025, -0.06568305194377899, -0.1324588656425476, -0.01872086524963379, 0.18272751569747925, 0.0067410822957754135, -0.1793195754289627, 0.0387575700879097, -0.1194053366780281, 0.06204666569828987, 0.04794759303331375, -0.22424867749214172, -0.07099322229623795, -0.18835465610027313, 0.03000194951891899, 0.022334415465593338, 0.046041395515203476, -0.16580872237682343, -1.789987402260897e-32, -0.016992369666695595, 0.07995416224002838, -0.0026820667553693056, 0.12016663700342178, 0.04965045675635338, 0.010219771414995193, -0.06484778970479965, -0.09421451389789581, 0.07001343369483948, -0.1848936676979065, -0.12316377460956573, -0.12179438769817352, 0.10119972378015518, 0.15537486970424652, 0.10580957680940628, 0.08129251003265381, -0.16332130134105682, 0.05400727689266205, -0.03297760710120201, 0.06250012665987015, 0.0328429751098156, 0.06927240639925003, 0.022185921669006348, -0.03932750225067139, -0.209017813205719, 0.10533825308084488, -0.048983167856931686, 0.09144110232591629, -0.06683897227048874, -0.05564356595277786, -0.08974021673202515, -0.005597004666924477, -0.0875139907002449, 0.0005182920140214264, 0.0007784710032865405, -0.09321630001068115, 0.056844450533390045, -0.09800165146589279, -0.04458685964345932, 0.10366688668727875, 0.1792314350605011, 0.15865743160247803, -0.2207680493593216, -0.07455131411552429, 0.09606152772903442, -0.007743822876363993, 0.030547795817255974, -0.055776216089725494, -0.015390642918646336, 0.008195186965167522, -0.015683433040976524, -0.03586750477552414, -0.1423942595720291, 0.08867134153842926, -0.1340087503194809, 0.025634771212935448, -0.23426243662834167, 0.06345182657241821, -0.032601989805698395, 0.048243388533592224, -0.08972567319869995, -0.045493390411138535, -0.05406281352043152, 0.0832122191786766, -0.04380810260772705, 0.06177133694291115, -0.0028594620525836945, 0.09627722948789597, -0.029118333011865616, 0.2009057253599167, -0.012670380063354969, 0.0712432935833931, 0.006886344403028488, -0.028366820886731148, -0.03159875422716141, -0.01069890521466732, -8.141557918861508e-05, -0.07568340748548508, -0.054371654987335205, -0.018866125494241714, 0.032284948974847794, 0.12026234716176987, 0.06630280613899231, -0.0500304140150547, -0.11495517194271088, 0.011390377767384052, 0.20805415511131287, 0.1105712279677391, 0.14106722176074982, -0.07262628525495529, 0.00473613990470767, 0.05942321568727493, 0.07613108307123184, 0.08648001402616501, 0.05231976509094238, -1.0099719816025754e-07, 0.012109247036278248, -0.010145824402570724, 0.05768762528896332, 0.06913520395755768, 0.027937274426221848, 0.0843166634440422, -0.23721130192279816, -0.0040446678176522255, -0.043658506125211716, -0.017689291387796402, 0.024466222152113914, -0.016791583970189095, -0.13611671328544617, -0.020333651453256607, -0.11483655124902725, 0.10960208624601364, -0.0061170849949121475, 0.02287203073501587, -0.02277303673326969, -0.043081387877464294, 0.07739757746458054, 0.019237179309129715, 0.009815491735935211, 0.05274417996406555, 0.03527563437819481, -0.08764181286096573, -0.07713307440280914, -0.03488384559750557, -0.0084278155118227, 0.01232355646789074, 0.0006284507689997554, -0.08259765058755875, 0.11902406066656113, -0.03333370015025139, 0.11317341774702072, -0.03489036485552788, 0.06807948648929596, 0.04503367841243744, 0.024019485339522362, 0.10866943001747131, -0.1603788286447525, 0.09945878386497498, -0.053144775331020355, -0.0847020298242569, 0.08193150162696838, -0.04359371215105057, 0.020265044644474983, 0.050283290445804596, 0.043790169060230255, -0.10445208102464676, 0.06091327220201492, 0.06729727238416672, -0.1455467939376831, 0.03187300264835358, 0.11466382443904877, -0.183357834815979, -0.17860329151153564, -0.025360586121678352, -0.12838415801525116, 0.09326274693012238, 0.05665799602866173, 0.003292905166745186, -0.004085963126271963, -0.097020722925663], metadata={'source': 'AAAMLP-569to.pdf', 'page': 69}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 70 ═════════════════════════════════════════════════════════════════════════ import numpy as np   def r2(y_true, y_pred):     \"\"\"     This function calculates r-squared score     :param y_true: list of real numbers, true values     :param y_pred: list of real numbers, predicted values     :return: r2 score     \"\"\"          # calculate the mean value of true values     mean_true_value = np.mean(y_true)          # initialize numerator with 0     numerator = 0     # initialize denominator with 0     denominator = 0          # loop over all true and predicted values     for yt, yp in zip(y_true, y_pred):         # update numerator         numerator += (yt - yp) ** 2         # update denominator         denominator += (yt - mean_true_value) ** 2     # calculate the ratio     ratio = numerator / denominator     # return 1 - ratio     return 1 – ratio ═════════════════════════════════════════════════════════════════════════  There are many more evaluation metrics, and this list is never-ending. I can write a book which is only about different evaluation metrics. Maybe I will. For now, these evaluations metrics will fit almost every problem you want to attempt. Please note that I have implemented these metrics in the most straightforward manner, and that means they are not efficient enough. You can make most of them in a very efficient way by properly using numpy. For example, take a look at the implementation of mean absolute error without any loops.  ═════════════════════════════════════════════════════════════════════════ import numpy as np  def mae_np(y_true, y_pred):     return np.mean(np.abs(y_true - y_pred)) ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[-0.09448472410440445, -0.08354827016592026, -0.11115994304418564, -0.037851475179195404, -0.02309715375304222, -0.0740320160984993, -0.028373725712299347, 0.05881599709391594, 0.09097771346569061, 0.004378451965749264, -0.10387454926967621, -0.11203163862228394, 0.053551286458969116, 0.06369839608669281, -0.03202962502837181, -0.024558596312999725, 0.1438504457473755, 0.0926240012049675, -0.006117217242717743, -0.034408293664455414, 0.0005776137113571167, 0.1198330745100975, 0.08276490867137909, 0.022150695323944092, 0.011582966893911362, -0.16099712252616882, 0.08141928911209106, 0.09628888964653015, -0.20870357751846313, -0.024146810173988342, -0.04049946367740631, 0.06676720082759857, 0.06344209611415863, -0.03151603415608406, -0.15532925724983215, 0.06455355137586594, 0.07156173884868622, -0.005797818303108215, -0.002874116413295269, 0.010450631380081177, -0.08769665658473969, 0.05987630411982536, 0.12400428205728531, 0.03855306655168533, 0.013148756697773933, 0.08916402608156204, -0.1435692012310028, -0.012738323770463467, -0.039158277213573456, -0.06334658712148666, -0.07144919782876968, 0.12089715898036957, -0.12059231102466583, 0.06385111808776855, 0.08485526591539383, 0.03641027584671974, -0.030432546511292458, -0.0719652846455574, 0.010000149719417095, -0.033861588686704636, 0.0014527235180139542, -0.06723376363515854, -0.09494435787200928, -0.037116244435310364, 0.10749761015176773, 0.019046610221266747, -0.07035581767559052, -0.027534930035471916, -0.008862381801009178, 0.1257004290819168, -0.08112604171037674, -0.0009876945987343788, -0.05980343744158745, 0.059443991631269455, 0.010279080830514431, 0.0067096296697855, 0.15568377077579498, 0.06698974967002869, 0.04673989117145538, -0.010245410725474358, -0.01492974441498518, 0.0981387048959732, 0.059179678559303284, -0.0592678040266037, 0.10309933125972748, -0.1929900050163269, -0.044078126549720764, 0.09126757085323334, 0.022104207426309586, -0.015518913976848125, 0.11157327890396118, 0.03548533469438553, -0.003118399530649185, -0.10351206362247467, 0.04878361150622368, 0.05045543238520622, 0.07976964116096497, -0.0630929172039032, 0.004671698901802301, 0.11842711269855499, 0.00222276384010911, 0.007382987067103386, -0.13994255661964417, -0.1439090073108673, 0.1697167009115219, 0.04679930955171585, 0.13087183237075806, -0.04010744392871857, 0.13971766829490662, -0.10231068730354309, -0.07350693643093109, -0.05175165832042694, -0.08712863177061081, 0.018602890893816948, 0.05880938470363617, 0.07167002558708191, 0.03832443803548813, 0.151597797870636, 0.02156546711921692, 0.09772178530693054, -0.07855477929115295, -0.01076417975127697, 0.019268495962023735, 0.004505862481892109, 0.03430134803056717, 0.061521898955106735, -0.12912075221538544, 1.0514362035195558e-32, -0.03769438713788986, 0.032739147543907166, 0.06567445397377014, -0.11546695977449417, -0.011583482846617699, -0.018310818821191788, -0.0023530772887170315, -0.04732661694288254, -0.09113603830337524, 0.04227740317583084, -0.06404402107000351, 0.17992697656154633, -0.06143802031874657, -0.0005687321536242962, 0.14883331954479218, -0.04649505019187927, -0.13887037336826324, -0.02180144563317299, -0.03433642536401749, -0.0762982964515686, 0.07868611067533493, -0.08028873801231384, 0.04939828813076019, -0.0383090078830719, 0.09518887847661972, -0.08521781116724014, 0.002274409867823124, -0.056344449520111084, -0.04825394228100777, 0.015608455054461956, -0.21505090594291687, 0.009925968013703823, 0.06791644543409348, -0.11851194500923157, 0.013685859739780426, -0.09984637796878815, -0.036050036549568176, 0.04629717767238617, -0.02827639877796173, -0.13189272582530975, -0.07819259166717529, 0.042421549558639526, -0.0033303797245025635, -0.12580028176307678, -0.04887077957391739, 0.05904427543282509, -0.0021177316084504128, 0.006923941895365715, 0.04070379585027695, 0.017177455127239227, -0.005080684088170528, -0.13532754778862, -0.029271472245454788, 0.034719064831733704, -0.06269443035125732, 0.055382851511240005, 0.10892258584499359, -0.03060119040310383, -0.051893580704927444, -0.004227320663630962, 0.024973466992378235, -0.010234775952994823, 0.056262481957674026, -0.10934368520975113, 0.03531111031770706, 0.1211845725774765, -0.03720725327730179, -0.02086532488465309, 0.09303677082061768, 0.040261149406433105, -0.020285002887248993, 0.07806684076786041, 0.05897894501686096, -0.19209177792072296, 0.08316822350025177, -0.03172067925333977, 0.11242647469043732, -0.07410520315170288, -0.0186987966299057, -0.012606605887413025, -0.05541592836380005, 0.06390642374753952, -0.015540307387709618, -0.19800686836242676, -0.06254620850086212, -0.03999797999858856, 0.05236562341451645, -0.022268397733569145, -0.15262934565544128, -0.00029924139380455017, -0.14362311363220215, -0.0033483649604022503, -0.02817607671022415, 0.060966119170188904, -0.11065875738859177, -9.668727562261328e-33, -0.03207908570766449, -0.0049518197774887085, -0.016888543963432312, 0.17790356278419495, 0.004088489804416895, -0.007667746860533953, -0.033668357878923416, -0.050252657383680344, 0.02445005439221859, -0.0681028738617897, -0.01165185496211052, -0.07706442475318909, 0.044408977031707764, -0.003924889024347067, 0.15837916731834412, 0.035488054156303406, -0.12645168602466583, 0.13962553441524506, 0.004280561581254005, 0.0450613908469677, 0.15184982120990753, 0.12467904388904572, -0.13593222200870514, 0.008592620491981506, -0.059915103018283844, 0.01507234014570713, -0.05731683224439621, 0.08320508897304535, -0.05022308602929115, -0.08148138225078583, -0.05635453015565872, -0.09822098910808563, -0.12078174948692322, -0.004771633073687553, -0.022261623293161392, -0.05306622385978699, -0.004523123614490032, -0.08671903610229492, -0.04493657872080803, 0.06817905604839325, 0.16482238471508026, 0.08434627205133438, -0.2002912312746048, -0.021902162581682205, 0.07410195469856262, -0.03394624590873718, 0.03294604271650314, -0.0024050851352512836, 0.0007677273824810982, -0.037455640733242035, 0.05130774900317192, -0.02630290575325489, -0.0749756246805191, 0.16781264543533325, -0.12434321641921997, 0.06834333389997482, -0.1513923704624176, 0.035384900867938995, 0.02795671671628952, 0.03321037441492081, -0.048080988228321075, 0.021918589249253273, 0.0076224422082304955, 0.1267222762107849, 0.12365438789129257, 0.10173116624355316, -0.005411926656961441, 0.12442711740732193, 0.031998030841350555, 0.14421500265598297, -0.02657431736588478, 0.06522490084171295, 0.028141427785158157, -0.05429346114397049, 0.013877278193831444, 0.027491677552461624, 0.007687469013035297, 0.011283963918685913, -0.13509605824947357, 0.012889119796454906, -0.021532289683818817, 0.09459908306598663, 0.060637399554252625, 0.16947363317012787, 0.008504321798682213, 0.04754894599318504, 0.20137304067611694, 0.10527549684047699, 0.10032256692647934, 0.014517899602651596, -0.010441046208143234, 0.08048900216817856, 0.06909628212451935, -0.028384964913129807, -0.06751719117164612, -9.987260796151531e-08, -0.05042896419763565, -0.022445376962423325, -0.03529205918312073, 0.003457467071712017, 0.06661567836999893, 0.11986412853002548, -0.06514526903629303, 0.026479050517082214, -0.1144426167011261, 0.10233557224273682, 0.08792795240879059, 0.02414066717028618, -0.19609937071800232, -0.004152084235101938, -0.12580640614032745, 0.0709805116057396, 0.007776098325848579, 0.06340986490249634, -0.04419594258069992, 0.016250895336270332, 0.08507665246725082, 0.053549639880657196, 0.021522443741559982, -0.04267321154475212, -0.08466464281082153, -0.009642346762120724, 0.015900233760476112, 0.016145814210176468, -0.014347333461046219, 0.09226451814174652, -0.09396401792764664, -0.03641248494386673, 0.021900629624724388, -0.028432782739400864, 0.09940573573112488, 0.11331747472286224, -0.0814022570848465, 0.04105609655380249, -0.0026528658345341682, 0.12952926754951477, -0.1265794336795807, 0.05821550637483597, -0.10544946044683456, -0.005218638107180595, 0.08436770737171173, 0.020891735330224037, -0.0835823267698288, 0.04542325437068939, 0.027751276269555092, -0.04078235477209091, 0.0614258274435997, 0.045849524438381195, -0.141559436917305, -0.04389217868447304, 0.026828916743397713, 0.02652200125157833, -0.11647273600101471, -0.0691976472735405, -0.10644714534282684, 0.02025255188345909, 0.1336742639541626, 0.0063612088561058044, 0.01266787201166153, 0.044468749314546585], metadata={'source': 'AAAMLP-569to.pdf', 'page': 70}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 71 I could have implemented all the metrics this way but to learn it’s better to look at low-level implementation. Once you learn the low-level implementation in pure python, and without using a lot of numpy, you can easily convert it to numpy and make it much faster.  Then, there are some advanced metrics.  One of them which is quite widely used is quadratic weighted kappa, also known as QWK. It is also known as Cohen’s kappa. QWK measures the “agreement” between two “ratings”. The ratings can be any real numbers in 0 to N. And predictions are also in the same range. An agreement can be defined as how close these ratings are to each other. So, it’s suitable for a classification problem with N different categories/classes. If the agreement is high, the score is closer towards 1.0. In the case of low agreement, the score is close to 0. Cohen’s kappa has a good implementation in scikit-learn, and detailed discussion of this metric is beyond the scope of this book.  ═════════════════════════════════════════════════════════════════════════ In [X]: from sklearn import metrics  In [X]: y_true = [1, 2, 3, 1, 2, 3, 1, 2, 3]  In [X]: y_pred = [2, 1, 3, 1, 2, 3, 3, 1, 2]  In [X]: metrics.cohen_kappa_score(y_true, y_pred, weights=\"quadratic\") Out[X]: 0.33333333333333337  In [X]: metrics.accuracy_score(y_true, y_pred) Out[X]: 0.4444444444444444 ═════════════════════════════════════════════════════════════════════════  You can see that even though accuracy is high, QWK is less. A QWK greater than 0.85 is considered to be very good!  An important metric is Matthew’s Correlation Coefficient (MCC). MCC ranges from -1 to 1. 1 is perfect prediction, -1 is imperfect prediction, and 0 is random prediction. The formula for MCC is quite simple.                TP * TN - FP * FN MCC = ─────────────────────────────────────           [ (TP + FP) * (FN + TN) * (FP + TN) * (TP + FN) ] ^ (0.5)'),\n",
       " VectorParams(vector=[-0.06933778524398804, -0.09024534374475479, -0.02178918570280075, 0.09992563724517822, 0.10618386417627335, -0.042275868356227875, -0.049646079540252686, -0.0035108099691569805, -0.07050740718841553, 0.041277021169662476, -0.039412472397089005, -0.08848027884960175, 0.060347434133291245, 0.06462860107421875, -0.0012508241925388575, -0.07518678158521652, 0.12827084958553314, 0.02230650559067726, -0.045502498745918274, 0.006119809579104185, 0.007239304482936859, 0.017839301377534866, -0.0013634084025397897, 0.16087639331817627, -0.016858840361237526, -0.08165717124938965, 0.02035483717918396, 0.02935127168893814, -0.1714719831943512, 0.005266914609819651, -0.029855435714125633, 0.08910634368658066, -0.027706962078809738, -0.013320374302566051, -0.008701995015144348, 0.051713403314352036, 0.011712177656590939, 0.01393892988562584, -0.007471712306141853, -0.035161107778549194, -0.08640508353710175, -0.06594821810722351, 0.06860137730836868, -0.04026544466614723, 0.052393049001693726, 0.025016793981194496, -0.05910734087228775, 0.04826866835355759, -0.08747182786464691, -0.08320995420217514, -0.008411021903157234, 0.09996141493320465, -0.18600952625274658, -0.03113633766770363, 0.00956216175109148, 0.031129512935876846, 0.1414841115474701, -0.101814866065979, 0.038307346403598785, -0.07215022295713425, 0.002080988371744752, -0.1369352489709854, 0.004794826731085777, -0.018185509368777275, -0.03730092570185661, 0.045219480991363525, -0.018921740353107452, -0.01746883988380432, 0.058550119400024414, 0.10832886397838593, 0.0501633957028389, 0.0006838437984697521, 0.028567854315042496, 0.0005061157280579209, 0.09105189889669418, 0.0781438797712326, 0.17767728865146637, 0.05848048999905586, -0.0028808265924453735, 0.06996423006057739, 0.037596601992845535, 0.07915008068084717, 0.00045676599256694317, -0.028792569413781166, 0.1297045350074768, -0.08476784825325012, 0.02521902322769165, 0.011366261169314384, 0.02469698339700699, 0.03895358741283417, 0.051277223974466324, 0.062470365315675735, -0.07391009479761124, -0.11434709280729294, 0.027606280520558357, 0.0031041097827255726, -0.06427642703056335, -0.07624752074480057, 0.06593514233827591, 0.03805319219827652, -0.056705836206674576, 0.07021353393793106, 0.04373011738061905, -0.19910810887813568, 0.06286769360303879, 0.05008827522397041, 0.0504387728869915, -0.05611726641654968, 0.10675548017024994, -0.1719520092010498, -0.0286872498691082, 0.02430323325097561, -0.149861678481102, 8.285231160698459e-05, -0.005862122401595116, 0.12318701297044754, 0.10716166347265244, 0.013188968412578106, -0.03571198508143425, 0.13095194101333618, -0.05780420079827309, -0.035328060388565063, 0.05252324417233467, 0.09216902405023575, 0.07200206816196442, -0.05227918177843094, -0.22542378306388855, 1.275200663279797e-32, -0.10053494572639465, -0.08124026656150818, 0.08720135688781738, -0.14170677959918976, 0.0099629582837224, -0.08568112552165985, 0.007517336402088404, 0.07278895378112793, 0.003333816770464182, -0.03092890791594982, -0.030535347759723663, 0.08877154439687729, -0.00423605740070343, -0.048543594777584076, 0.06408881396055222, -0.029327385127544403, -0.08083697408437729, -0.02867872081696987, -0.017307374626398087, -0.11145109683275223, 0.09504839777946472, -0.03503027185797691, 0.04403574764728546, -0.045384060591459274, -0.008613702841103077, -0.08099520206451416, 0.012011157348752022, 0.010260381735861301, -0.08992522209882736, 0.023353546857833862, -0.10200148820877075, -0.05024164915084839, 0.1006331667304039, 0.023415949195623398, 0.03744250908493996, -0.03193647786974907, -0.006940175779163837, 0.00461906474083662, -0.052107952535152435, 0.015272424556314945, -0.13114970922470093, 0.02563168667256832, 0.020379990339279175, -0.13217543065547943, -0.006887379102408886, -0.017070233821868896, -0.03635641187429428, -0.023663798347115517, 0.010672331787645817, 0.053197361528873444, 0.08708003163337708, -0.1547422558069229, 0.00512930192053318, 0.011636699549853802, -0.19234313070774078, 0.08336855471134186, 0.14252549409866333, -0.040087562054395676, 0.03778259456157684, 0.017017876729369164, -0.040984105318784714, -0.14844584465026855, -0.006761070340871811, -0.17584042251110077, -0.07176405936479568, 0.030766917392611504, 0.007845859974622726, 0.0457594133913517, 0.08837448060512543, 0.016697166487574577, -0.0024676381144672632, 0.04633111506700516, -0.0033548218198120594, -0.040341705083847046, 0.17813505232334137, 0.01602283865213394, 0.053872741758823395, -0.024019042029976845, -0.07611384242773056, 0.03085937909781933, 0.009472411125898361, 0.13332165777683258, -0.11206384748220444, -0.09313153475522995, -0.005493703298270702, -0.04758238419890404, 0.0005646468489430845, -0.024065010249614716, -0.1346159279346466, -0.07084250450134277, -0.08019247651100159, 0.02077176235616207, -0.025471581146121025, 0.028347929939627647, -0.01638066954910755, -1.467234269344323e-32, -0.02526397444307804, 0.00613043736666441, -0.017732804641127586, 0.082462377846241, -0.07908781617879868, 0.004262002184987068, -0.010631600394845009, -0.036036353558301926, 0.02006666734814644, -0.134171724319458, -0.06511110067367554, -0.15213707089424133, 0.013185392133891582, 0.018772678449749947, -0.05245251581072807, 0.06346206367015839, -0.10558945685625076, 0.04317556321620941, 0.06583710759878159, 0.1511831283569336, -0.013793831691145897, 0.09347522258758545, 0.012916738167405128, -0.09923380613327026, -0.13268475234508514, 0.038100291043519974, -0.05154843255877495, 0.06827672570943832, 0.024828221648931503, 0.02987702563405037, -0.08809834718704224, 0.05263276770710945, -0.07849229127168655, 0.06035889685153961, 0.050632450729608536, -0.06479354202747345, -0.019866561517119408, -0.04070044308900833, 0.08481301367282867, -0.02001299150288105, 0.08247694373130798, 0.1683395653963089, -0.12948110699653625, 0.019418423995375633, 0.09915769845247269, -0.03899822384119034, 0.013799802400171757, -0.019557731226086617, 0.006107120309025049, 0.0781548023223877, -0.048315901309251785, -0.01475577987730503, -0.05770128220319748, 0.03878163918852806, -0.1757822334766388, 0.01611185260117054, -0.06655748188495636, -0.002475156681612134, -0.0798247903585434, 0.08337313681840897, -0.07063882797956467, -0.016738485544919968, 0.004753754008561373, 0.08085054159164429, 0.05493858456611633, 0.062117937952280045, 0.01985914632678032, 0.03737768158316612, -0.009771635755896568, 0.12130391597747803, -0.17677989602088928, 0.1053633838891983, -0.04186014458537102, -0.05573587119579315, -0.04251239076256752, 0.012534220702946186, -0.024342715740203857, 0.051870737224817276, -0.01946689747273922, 0.08044444024562836, -0.00398086616769433, 0.017165984958410263, -0.10253473371267319, 0.05433506891131401, -0.04202921316027641, 0.01751340553164482, 0.14917431771755219, 0.125832200050354, 0.19074711203575134, -0.06275305151939392, -0.03203016147017479, 0.05931884050369263, 0.07960044592618942, -0.0014161872677505016, -0.00976601243019104, -1.0101095426762186e-07, -0.03973488137125969, -0.0533042810857296, 0.017687704414129257, 0.061729609966278076, 0.09244474768638611, 0.0773698017001152, -0.10503347963094711, 0.05534307286143303, -0.06689050793647766, 0.01935265213251114, 0.0692184790968895, 0.0362042598426342, -0.17755448818206787, -0.04078719764947891, -0.10417266935110092, 0.06053071841597557, 0.049056872725486755, 0.03206201642751694, 0.01847406104207039, -0.024667968973517418, 0.03755638748407364, -0.07747700810432434, 0.020529381930828094, 0.12739385664463043, -0.025325827300548553, -0.06920310854911804, 0.0261030625551939, 0.02114787884056568, 0.0028304161969572306, -0.0010345797054469585, -0.10029378533363342, -0.1177101731300354, -0.059376999735832214, 0.0667622908949852, 0.07981814444065094, 0.12864236533641815, -0.02900003083050251, 0.054896991699934006, -0.04959934204816818, 0.17306368052959442, -0.04579135403037071, 0.09430599957704544, -0.07134819030761719, -0.09903036803007126, 0.05247412621974945, 0.049313902854919434, -0.035692911595106125, 0.09108040481805801, 0.020298589020967484, -0.004508985206484795, -0.010134503245353699, 0.008882109075784683, -0.20690537989139557, 0.02504962682723999, -0.049982454627752304, 0.04572264850139618, 0.026247533038258553, -0.10962234437465668, -0.04508030787110329, 0.04887193813920021, -0.007164277136325836, 0.012075655162334442, 0.001868122024461627, -0.011323985643684864], metadata={'source': 'AAAMLP-569to.pdf', 'page': 71}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 72 We see that MCC takes into consideration TP, FP, TN and FN and thus can be used for problems where classes are skewed. You can quickly implement it in python by using what we have already implemented.  ═════════════════════════════════════════════════════════════════════════ def mcc(y_true, y_pred):     \"\"\"     This function calculates Matthew\\'s Correlation Coefficient     for binary classification.     :param y_true: list of true values     :param y_pred: list of predicted values     :return: mcc score     \"\"\"     tp = true_positive(y_true, y_pred)     tn = true_negative(y_true, y_pred)     fp = false_positive(y_true, y_pred)     fn = false_negative(y_true, y_pred)      numerator = (tp * tn) - (fp * fn)      denominator = (         (tp + fp) *         (fn + tn) *         (fp + tn) *         (tp + fn)     )      denominator = denominator ** 0.5      return numerator/denominator ═════════════════════════════════════════════════════════════════════════  These are the metrics that can help you get started and will apply to almost every machine learning problem.  One thing to keep in mind is that to evaluate un-supervised methods, for example, some kind of clustering, it’s better to create or manually label the test set and keep it separate from everything that is going on in your modelling part. When you are done with clustering, you can evaluate the performance on the test set simply by using any of the supervised learning metrics.  Once we understand what metric to use for a given problem, we can start looking more deeply into our models for improvements.'),\n",
       " VectorParams(vector=[-0.14844565093517303, -0.13468563556671143, -0.012535148300230503, 0.020764192566275597, 0.06151563674211502, -0.017246736213564873, -0.061108894646167755, 0.07901544868946075, -0.084482342004776, 0.06336163729429245, -0.0459345206618309, 0.013607766479253769, 0.09875456243753433, -0.005373762920498848, -0.007057772949337959, 0.008739959448575974, -0.009837809950113297, 0.0017396145267412066, 0.03633201867341995, -0.11778663843870163, -0.08417405188083649, -0.022778382524847984, 0.04823392257094383, 0.024294881150126457, -0.09839742630720139, -0.002890767762437463, 0.07816560566425323, -0.006140551064163446, -0.1683882623910904, -0.03949765861034393, -0.028005138039588928, -0.019228573888540268, -0.05054863542318344, 0.05900682136416435, 0.07175243645906448, 0.15436981618404388, 0.049982134252786636, -0.060442522168159485, -0.0077458331361413, -0.007769747171550989, 0.07081425935029984, 0.07610137015581131, -0.05539749190211296, -0.13884437084197998, 0.17634941637516022, -0.13348302245140076, 0.036951128393411636, -0.18909810483455658, 0.0841124877333641, -0.06026574969291687, -0.19737420976161957, -0.14211159944534302, -0.06880884617567062, -0.05049692466855049, -0.03867185115814209, -0.12313730269670486, 0.1800464689731598, -0.07650507241487503, 0.029572492465376854, -0.11285807937383652, 0.01938048005104065, -0.04722701385617256, -0.07583548873662949, -0.10004755109548569, -0.03753123804926872, -0.07139041274785995, -0.0288509801030159, 0.29825496673583984, 0.12326940149068832, 7.339414150919765e-05, -0.01727542094886303, 0.08826632797718048, -0.14457976818084717, -0.01896815001964569, -0.023369936272501945, 0.005615626461803913, 0.08151069283485413, 0.062192801386117935, 0.06345004588365555, -0.19694438576698303, -0.17157377302646637, -0.07550454139709473, 0.07713162899017334, 0.08491718024015427, -0.017145629972219467, -0.06739228218793869, 0.05781769007444382, 0.19459322094917297, 0.09126581996679306, -0.11298401653766632, 0.1038057953119278, -0.020311422646045685, -0.005634606815874577, 0.07313136011362076, 0.14273695647716522, 0.09609371423721313, 0.15486398339271545, 0.054760538041591644, 0.015485525131225586, 0.1494467854499817, -0.07178949564695358, -0.012155360542237759, 0.1610366404056549, 0.010901221074163914, 0.09568749368190765, 0.09653685241937637, 0.08719917386770248, -0.05684472247958183, 0.038389164954423904, -0.1841389387845993, 0.016804393380880356, -0.05380694940686226, -0.12766426801681519, 0.01620502769947052, 0.06548357754945755, 0.16613858938217163, -0.06534039229154587, 0.018720386549830437, -0.14736267924308777, 0.1853933483362198, -0.06918159127235413, 0.04905659332871437, 0.025212233886122704, 0.03871970996260643, 0.07936397939920425, 0.0654124990105629, -0.23376409709453583, 3.800437521055766e-33, 0.056797292083501816, -0.03585786744952202, 0.032057374715805054, 0.015053206123411655, 0.1979077309370041, -0.04971713200211525, 0.0398225374519825, 0.03175269439816475, -0.04841330647468567, 0.06487225741147995, -0.07449806481599808, 0.045349642634391785, -0.1126888245344162, 0.04355549439787865, 0.019923096522688866, -0.13516196608543396, -0.170878604054451, -0.010297193191945553, -0.044020045548677444, -0.04010234773159027, 0.07690389454364777, -0.145419642329216, -0.06011964753270149, 0.015242110006511211, 0.06007767841219902, -0.00228415266610682, 0.09907879680395126, -0.02082173340022564, -0.09400437027215958, 0.04571833834052086, -0.04926838353276253, -0.034140605479478836, 0.008062032051384449, -0.013188009150326252, -0.12729790806770325, -0.06571043282747269, -0.09578628093004227, -0.015858137980103493, 0.04777504876255989, -0.04302435368299484, -0.06252054125070572, -0.07907462120056152, -0.001504983869381249, -0.0566624291241169, -0.12260282784700394, 0.032322902232408524, 0.01943185366690159, -0.00603596493601799, 0.0811496153473854, 0.018481841310858727, -0.047520458698272705, -0.06529836356639862, -0.043765679001808167, -0.0029035184998065233, -0.1076577752828598, 0.08153288811445236, 0.02303539402782917, -0.08913492411375046, 0.15775087475776672, -0.021332327276468277, 0.15377584099769592, -0.06542322039604187, -0.05447658896446228, 0.15411674976348877, 0.09340686351060867, 0.12144570052623749, 0.03762323409318924, 0.043841976672410965, 0.22021684050559998, 0.019532207399606705, -0.18569070100784302, -0.0008622669847682118, 0.04694393277168274, -0.11230473220348358, 0.2651781141757965, -0.10123462229967117, 0.007051714230328798, 0.009300041012465954, -0.18814565241336823, -0.014008954167366028, -0.04139126464724541, 0.028044717386364937, -0.04822435602545738, -0.0693027526140213, -0.003986329305917025, 0.016127120703458786, 0.03943668678402901, 0.051587287336587906, -0.13900995254516602, -0.001525198109447956, -0.005951766390353441, 0.08232875913381577, -0.06546783447265625, -0.010782051831483841, -0.05207386985421181, -4.3052285907614425e-33, 0.11223417520523071, 0.049546536058187485, 0.0541195347905159, 0.02801658771932125, 0.0841880813241005, -0.01790534518659115, -0.07499005645513535, -0.057873278856277466, 0.008088834583759308, -0.040386028587818146, -0.15290534496307373, -0.1259845644235611, 0.10088009387254715, 0.02183687314391136, -0.00539070600643754, 0.0742868036031723, -0.09251412004232407, -0.06652204692363739, 0.08328285813331604, 0.03454761207103729, -0.16311869025230408, 0.14953450858592987, -0.11281880736351013, -0.03371360898017883, -0.06021052226424217, 0.03558541089296341, -0.15282128751277924, 0.008648079819977283, 0.047141533344984055, 0.004343708045780659, -0.11113991588354111, 0.04141128063201904, -0.17682339251041412, -0.11314769834280014, -0.061592284590005875, 0.04777606204152107, 0.027141163125634193, -0.008263355121016502, -0.041319604963064194, 0.21547134220600128, 0.10610056668519974, 0.048334479331970215, -0.2519921660423279, 0.050935905426740646, 0.009707276709377766, 0.010715014301240444, -0.02900855429470539, 0.11125252395868301, -0.1419866383075714, -0.07273349910974503, -0.07856818288564682, 0.07575453817844391, -0.04572339728474617, -0.18239350616931915, 0.011933392845094204, 0.06512432545423508, 0.0767689123749733, 0.07239358872175217, -0.0922124907374382, 0.053842198103666306, -0.1400938779115677, -0.09707920998334885, 0.015471347607672215, -0.12161918729543686, -0.14188365638256073, -0.017970092594623566, -0.17922334372997284, 0.008411256596446037, 0.10919005423784256, -0.01860630512237549, -0.061842963099479675, 0.05654652789235115, -0.07332222908735275, -0.04333403706550598, -0.0004350794479250908, -0.01191365160048008, -0.07443999499082565, 0.05930229648947716, 0.03203124925494194, 0.05145150050520897, 0.009573069401085377, 0.032355114817619324, 0.07315734773874283, 0.07276706397533417, 0.033128898590803146, 0.17882601916790009, 0.0892799124121666, 0.11503943800926208, 0.09329289197921753, -0.07699696719646454, -0.05167818069458008, -0.028378766030073166, 0.1385291963815689, 0.2556796371936798, -0.052308421581983566, -1.0011614648419709e-07, -0.05422855168581009, 0.13642971217632294, 0.04918671399354935, 0.09261751919984818, 0.0033027995377779007, 0.00022734934464097023, -0.04247494414448738, 0.31587186455726624, 0.008689013309776783, 0.0795450285077095, 0.13448864221572876, 0.015916869044303894, -0.09860558062791824, 0.11694009602069855, -0.1426699459552765, 0.15140970051288605, 0.10552086681127548, 0.0485156774520874, -0.08882948756217957, 0.08118154108524323, 0.1640077531337738, 0.05380083620548248, 0.11560320854187012, 0.14109990000724792, 0.06855317950248718, -0.1476093828678131, -0.03660336136817932, -0.04111059010028839, -0.047140300273895264, 0.03999897092580795, 0.03349623084068298, -0.036171361804008484, -0.026483148336410522, 0.01409133616834879, 0.1144462525844574, -0.03986164554953575, 0.05570478364825249, -0.05181167647242546, 0.151114821434021, 0.0875941663980484, -0.049897223711013794, -0.014654748141765594, -0.09508758783340454, -0.041021861135959625, 0.023748304694890976, -0.034739311784505844, -0.09289558976888657, -0.18516382575035095, -0.0030002191197127104, -0.058222781866788864, -0.06877540796995163, 0.042572829872369766, -0.059740182012319565, 0.07341883331537247, 0.16942156851291656, 0.15348078310489655, 0.01570296660065651, 0.010081377811729908, 0.0036365606356412172, 0.030045097693800926, -0.044701382517814636, -0.04114784672856331, 0.02048412710428238, -0.062487054616212845], metadata={'source': 'AAAMLP-569to.pdf', 'page': 72}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 73 Arranging machine learning projects  Finally, we are at a stage where we can start building our very first machine learning models.  Or are we?  Before we start, we must take care of a few things. Please remember that we will work in an IDE/text editor rather than jupyter notebooks. You can also work in jupyter notebooks, and it’s totally up to you. However, I will be using jupyter only for things like data exploration and for plotting charts and graphs. We will build the classification framework in such a way that most problems will become plug n’ play. You will be able to train a model without making too many changes to the code, and when you improve your models, you will be able to track them using git.  Let’s look at the structure of the files first of all. For any project that you are doing, create a new folder. For this example, I am calling the project “project”.  The inside of the project folder should look something like the following.  . ├── input │       ├── train.csv │       └── test.csv ├── src │       ├── create_folds.py │       ├── train.py │       ├── inference.py │       ├── models.py │       ├── config.py │       └── model_dispatcher.py ├── models │       ├── model_rf.bin │       └── model_et.bin ├── notebooks │       ├── exploration.ipynb │       └── check_data.ipynb ├── README.md └── LICENSE'),\n",
       " VectorParams(vector=[-0.11559556424617767, -0.023624569177627563, -0.0849759429693222, -0.053119782358407974, 0.16226057708263397, -0.024149123579263687, -0.04832836240530014, 0.028266843408346176, -0.02131257951259613, 0.00671419408172369, 0.03285469487309456, -0.009054215624928474, 0.17135396599769592, -0.0073629384860396385, -0.07053638994693756, 0.0014261547476053238, -0.03510333225131035, 0.06924252957105637, -0.15462753176689148, 0.003238087985664606, -0.006047642324119806, 0.09837938100099564, 0.05772329866886139, -0.05724456533789635, -0.08790652453899384, 0.05374591052532196, 0.031958140432834625, 0.025267889723181725, -0.1144566461443901, -0.07089795172214508, 0.019913118332624435, 0.016374636441469193, -0.0033139828592538834, 0.029772941023111343, 0.12552222609519958, 0.13685549795627594, 0.053999416530132294, 0.020284151658415794, -0.010014789178967476, 0.07153840363025665, 0.08037076890468597, 0.0658435970544815, -0.015786267817020416, -0.06321842223405838, 0.07356379181146622, 0.009184160269796848, 0.007803791202604771, -0.1718350648880005, 0.05484496057033539, -0.028099922463297844, -0.1586398184299469, 0.05967557430267334, -0.20002487301826477, 0.11841752380132675, -0.07368536293506622, -0.16835927963256836, 0.06402751058340073, -0.07726027071475983, -0.056136760860681534, 0.04864238575100899, -0.008218449540436268, -0.019563034176826477, -0.05198926478624344, 0.03732174634933472, 0.06264142692089081, -0.0044390433467924595, -0.06620459258556366, 0.05001504346728325, 0.11306912451982498, -0.14932100474834442, -0.13638891279697418, 0.0312788262963295, -0.08129480481147766, 0.09311888366937637, -0.12799455225467682, -0.005249590612947941, 0.11989574134349823, 0.03743007779121399, 0.1845463067293167, -0.27295413613319397, -0.0983065813779831, -0.010565954260528088, 0.15066389739513397, 0.0006563063361681998, 0.04186207056045532, -0.05081070959568024, 0.04667756333947182, 0.20768137276172638, 0.08752284198999405, -0.03797819837927818, 0.07308956980705261, -0.0888877734541893, -0.013682304881513119, 0.06374531984329224, 0.027556950226426125, 0.15724198520183563, 0.0655578151345253, 0.06029616668820381, 0.06362074613571167, 0.14516490697860718, -0.029426926746964455, -0.09993026405572891, 0.05846138671040535, 0.0071530649438500404, 0.06338164955377579, 0.018667059019207954, 0.09709280729293823, 0.03828134760260582, 0.0823938399553299, -0.10692734271287918, -0.026224376633763313, 0.010235280729830265, -0.21990278363227844, -0.04634148254990578, 0.05135196074843407, -0.03812992200255394, -0.0490928590297699, -0.012418911792337894, -0.08447001874446869, 0.07294677942991257, -0.13486458361148834, 0.036053139716386795, 0.13066935539245605, -0.06729307025671005, 0.015618948265910149, -0.10106948763132095, -0.20140761137008667, 6.710964105085642e-33, -0.02491908147931099, -0.07429531961679459, 0.09387371689081192, -0.03488065302371979, 0.13240459561347961, -0.09468769282102585, 0.05881136283278465, 0.06507130712270737, -0.09544139355421066, 0.03663060441613197, -0.13732627034187317, 0.07028525322675705, -0.05252023786306381, 0.11255144327878952, -0.032473932951688766, -0.025666987523436546, -0.08664767444133759, -0.02548520639538765, -0.009712433442473412, -0.004775634966790676, 0.16920742392539978, -0.003832033835351467, 0.033416613936424255, 0.07538370788097382, -0.042003147304058075, 0.002111974637955427, -0.02083483897149563, -0.024709830060601234, -0.0833306610584259, 0.06742516160011292, -0.10252585262060165, -0.009991006925702095, -0.0051310984417796135, -0.10070588439702988, -0.0281608197838068, -0.020878488197922707, -0.04852404072880745, -0.009954793378710747, 0.04695165902376175, 0.021487362682819366, -0.04674629122018814, -0.024953844025731087, 0.04374650493264198, -0.052117325365543365, -0.15614831447601318, 0.049784041941165924, 0.06483753025531769, 0.11563748866319656, -0.01623489335179329, 0.05513555929064751, 0.01170041412115097, -0.09644918888807297, 0.009186746552586555, -0.09055468440055847, -0.11291898787021637, 0.06111463904380798, -0.013032954186201096, -0.053873658180236816, 0.09981133788824081, -0.037136346101760864, 0.017162512987852097, 0.021083809435367584, -0.04454512149095535, 0.1685817390680313, 0.02050529047846794, -0.01487954892218113, 0.014960765838623047, -0.05008288472890854, 0.0796005129814148, -0.08244987577199936, -0.08652918040752411, 0.0054846759885549545, 0.03568968549370766, -0.1260753870010376, 0.1047225147485733, -0.05783384293317795, -0.001193222706206143, 0.027172761037945747, -0.11361485719680786, 0.09822840243577957, 0.012188303284347057, 0.0864606499671936, -0.0721818283200264, -0.1856815665960312, -0.1462852507829666, -0.019024323672056198, 0.0755193904042244, -0.10979180037975311, -0.030288366600871086, -0.055135127156972885, 0.02214818261563778, -0.0033921028953045607, -0.11073906719684601, -0.09464424848556519, -0.040464647114276886, -7.091666317698672e-33, 0.12139976769685745, 0.0854373425245285, -0.007557188626378775, -0.023733774200081825, -0.0072225360199809074, 0.12496397644281387, 0.025037856772542, 0.07156495004892349, -0.05828399956226349, -0.11554499715566635, 0.011633236892521381, -0.022958433255553246, 0.028426116332411766, -0.1036883145570755, -0.09280639886856079, 0.035298511385917664, -0.04804867506027222, 0.020348213613033295, -0.00483627337962389, 0.03375748544931412, -0.10015154629945755, 0.18075409531593323, -0.05618159845471382, 0.0739014521241188, -0.03696180135011673, 0.06965360045433044, -0.11167392134666443, 0.08678168803453445, 0.036903221160173416, -0.020366841927170753, -0.0694694072008133, 0.008285603486001492, -0.1718667596578598, -0.057713475078344345, -0.05623048543930054, -0.05463816598057747, 0.038566846400499344, -0.06472817063331604, -0.0058693550527095795, 0.06520507484674454, 0.19690412282943726, 0.1517353653907776, -0.21674944460391998, 0.0858943983912468, 0.006245489697903395, -0.0999700203537941, -0.12793311476707458, 0.026760971173644066, 0.05920733883976936, -0.0774349719285965, -0.01934051513671875, -0.08101633191108704, -0.03188192844390869, -0.05412726476788521, 0.008560139685869217, 0.07170376181602478, 0.012206166982650757, 0.09697772562503815, -0.021610161289572716, 0.0026740524917840958, -0.07523331046104431, -0.12878568470478058, -0.11040162295103073, 0.020141474902629852, -0.047170598059892654, 0.010390539653599262, -0.12006581574678421, -0.006832315120846033, -0.0027790768072009087, -0.0029659259598702192, -0.07140517979860306, -0.0711425244808197, 0.11001525074243546, -0.09390194714069366, -0.02771761268377304, -0.014630301855504513, -0.02141999453306198, 0.010129059664905071, -0.03791473060846329, 0.004996947944164276, 0.07035624235868454, -0.01955309510231018, 0.048162274062633514, 0.1455717384815216, 0.10087783634662628, 0.08136522769927979, 0.04550475627183914, 0.00846894271671772, 0.14315463602542877, -0.048575449734926224, -0.08053163439035416, 0.009043632075190544, 0.06701403856277466, 0.22789297997951508, 0.1082044392824173, -9.975268255857372e-08, -0.05770567059516907, 0.1261884719133377, 0.06877218931913376, 0.002308543538674712, -0.016595790162682533, 0.10026726126670837, -0.03776267543435097, 0.10468777269124985, 0.07391245663166046, 0.11839491873979568, 0.2294239103794098, -0.06386647373437881, -0.10667532682418823, 0.020629340782761574, -0.15125496685504913, 0.231986865401268, 0.07898331433534622, 0.03116299770772457, -0.020154820755124092, 0.08434949815273285, 0.054694388061761856, -0.0362284891307354, 0.05629231780767441, 0.12453486025333405, 0.08706066012382507, -0.03709964081645012, -0.04853370413184166, 0.01432873960584402, -0.0661768838763237, -0.009068836458027363, -0.03854978084564209, -0.06143493950366974, 0.03945806622505188, -0.025172976776957512, 0.08134540915489197, 0.008043980225920677, 0.042410433292388916, -0.044932376593351364, 0.06873992830514908, 0.12520547211170197, -0.09235839545726776, -0.05407213047146797, -0.06954899430274963, -0.05611059069633484, 0.13632650673389435, -0.00899097416549921, -0.1059957817196846, 0.02427779883146286, -0.08512304723262787, 0.03814975917339325, -0.008468606509268284, 0.03601779416203499, -0.07095108926296234, 0.09913036972284317, 0.07326808571815491, -0.02368517592549324, -0.007685994263738394, 0.03229261562228203, 0.04057127237319946, 0.025888673961162567, 0.028039205819368362, 0.0029479919467121363, 0.040196847170591354, -0.09159862995147705], metadata={'source': 'AAAMLP-569to.pdf', 'page': 73}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 74 Let’s see what these folders and file are about.  input/: This folder consists of all the input files and data for your machine learning project. If you are working on NLP projects, you can keep your embeddings here. If you are working on image projects, all images go to a subfolder inside this folder.  src/: We will keep all the python scripts associated with the project here. If I talk about a python script, i.e. any *.py file, it is stored in the src folder.  models/: This folder keeps all the trained models.  notebooks/: All jupyter notebooks (i.e. any *.ipynb file) are stored in the notebooks folder.  README.md: This is a markdown file where you can describe your project and write instructions on how to train the model or to serve this in a production environment.  LICENSE: This is a simple text file that consists of a license for the project, such as MIT, Apache, etc. Going into details of the licenses is beyond the scope of this book.  Let’s assume you are building a model to classify MNIST dataset (a dataset that has been used in almost every machine learning book). If you remember, we touched MNIST dataset in cross-validation chapter too. So, I am not going to explain how this dataset looks like. There are many different formats of MNIST dataset available online, but we will be using the CSV format of the dataset.  In this format of the dataset, each row of the CSV consists of the label of the image and 784 pixel values ranging from 0 to 255. The dataset consists of 60000 images in this format.  We can use pandas to read this data format easily.  Please note that even though Figure 1 shows all pixel values as zeros, it is not the case.'),\n",
       " VectorParams(vector=[-0.18804620206356049, -0.11145127564668655, -0.20679916441440582, 0.055144183337688446, 0.05528658255934715, 0.05812828987836838, 0.02625286392867565, 0.13017690181732178, -0.05616307258605957, -0.11682185530662537, 0.08295970410108566, -0.15710929036140442, 0.12401078641414642, 0.05960078909993172, -0.13933038711547852, 0.06499378383159637, -0.04124351218342781, -0.013213876634836197, 0.014115636236965656, -0.0542520172894001, 0.006993504706770182, 0.0476035550236702, 0.2258097231388092, -0.05353187024593353, 0.05702727660536766, 0.023188484832644463, 0.08653903752565384, 0.0019720306154340506, -0.10291485488414764, 0.04151725396513939, 0.057856056839227676, 0.15853449702262878, 0.13248975574970245, 0.025392673909664154, 0.2033464014530182, 0.21604062616825104, 0.08108548074960709, 0.0852179080247879, -0.04919636622071266, 0.033800024539232254, -0.03385363519191742, 0.012809053994715214, 0.17276376485824585, -0.06313487142324448, -0.03387032076716423, 0.11895827203989029, 0.02201060950756073, -0.20652265846729279, -0.03804105147719383, 0.12389916181564331, -0.148803249001503, 0.018531402572989464, -0.1594904363155365, -0.021950723603367805, -0.0986800342798233, -0.03331727907061577, 0.006990489084273577, -0.1627422422170639, -0.0735696405172348, 0.05102016404271126, 0.07291354984045029, -0.08829774707555771, -0.08081600069999695, -0.06924770772457123, 0.1533745974302292, -0.002725588157773018, -0.03290266916155815, 0.09719128906726837, 0.12638986110687256, -0.06334482133388519, -0.05452751740813255, 0.17958837747573853, -0.09639910608530045, 0.054751940071582794, -0.1517261117696762, -0.057802483439445496, 0.07494724541902542, 0.02528640627861023, 0.09057685732841492, -0.2832069993019104, -0.05602375417947769, 0.015396889299154282, 0.13823215663433075, 0.12065096944570541, 0.10758421570062637, 0.006169477943331003, 0.13817381858825684, 0.1944790631532669, -0.013535772450268269, -0.065733402967453, -0.0010948904091492295, -0.01792268268764019, -0.002772754058241844, 0.00024603764177300036, -0.02892329730093479, 0.27404773235321045, -0.011624947190284729, 0.11786048114299774, 0.10737526416778564, 0.11019571125507355, -0.1156451627612114, -0.08170904964208603, 0.003360781352967024, -0.04307295382022858, 0.08983472734689713, 0.0873100683093071, 0.10080871731042862, 0.07255140691995621, 0.1859167069196701, -0.08843018859624863, 0.13424700498580933, -0.035891152918338776, -0.2661283612251282, 0.02672809548676014, 0.14974600076675415, -0.006047409027814865, 0.027077725157141685, 0.016540974378585815, -0.08056353777647018, 0.14581426978111267, -0.12668296694755554, 0.006000628229230642, 0.03304189816117287, -0.06587430089712143, -0.021597469225525856, -0.027468333020806313, -0.15622536838054657, 7.352808265205597e-33, 0.023098619654774666, -0.02313694730401039, 0.07772549986839294, -0.07511644810438156, 0.14629176259040833, -0.12467379122972488, 0.024583488702774048, 0.08695744723081589, 0.00809659343212843, 0.048631761223077774, -0.04402736946940422, 0.11565286666154861, -0.0740780383348465, 0.08728190511465073, 0.0003583456564228982, -0.16115021705627441, -0.009331750683486462, 0.038975901901721954, -0.02876162715256214, -0.1987880915403366, 0.0510115772485733, -0.02134692296385765, 0.15334326028823853, 0.03192822262644768, 0.005189097486436367, -0.07222557812929153, -0.007374799344688654, 0.11725256592035294, -0.04396014288067818, -0.03249134495854378, -0.11564289778470993, -0.0538349375128746, 0.04977267235517502, -0.01631375215947628, -0.006263583432883024, -0.055287234485149384, -0.0829429104924202, 0.011539509519934654, -0.003664945950731635, 0.0529082715511322, -0.04206445813179016, 0.04637062922120094, 0.03821416199207306, -0.1113584116101265, -0.1686156988143921, 0.13068096339702606, 0.02980463020503521, -0.003414441365748644, 0.06319268047809601, 0.010293165221810341, 0.0449184775352478, -0.047870028764009476, 0.08791489899158478, -0.0026030386798083782, -0.08640875667333603, 0.04123961552977562, -0.006666278466582298, -0.04822097718715668, 0.09358613193035126, -0.031779348850250244, 0.10105940699577332, 0.05557607114315033, 0.08989845216274261, 0.13880646228790283, 0.02277923934161663, 0.06159036234021187, 0.17433129251003265, 0.009864778257906437, 0.16467152535915375, 0.06200696527957916, -0.04870043322443962, 0.03913647308945656, -0.08534508943557739, -0.08222931623458862, 0.165778249502182, 0.019995708018541336, -0.009945439174771309, -0.06741203367710114, -0.19445593655109406, 0.06169024482369423, -0.021230259910225868, 0.04375641793012619, -0.037398193031549454, -0.17818665504455566, -0.05109546706080437, 0.0816621482372284, 0.04839775338768959, -0.14394377171993256, -0.0635852962732315, -0.0785357654094696, -0.07621300965547562, -0.015843072906136513, -0.1811901479959488, -0.10863715410232544, -0.14649896323680878, -8.22582734841017e-33, 0.035976383835077286, 0.15835675597190857, 0.10993633419275284, 0.0641169473528862, 0.003024498699232936, 0.05717732384800911, -0.07941175997257233, 0.053150713443756104, 0.01069454662501812, 0.04837612807750702, -0.05099748075008392, -0.10816408693790436, -0.0029885489493608475, -0.10190068185329437, -0.09165465086698532, -0.025213802233338356, -0.0605899915099144, 0.061173468828201294, -0.008016391657292843, 0.016013288870453835, -0.06404392421245575, 0.26608672738075256, -0.10701755434274673, 0.06387991458177567, -0.1079411432147026, 0.019083095714449883, -0.10654474794864655, -0.055867914110422134, -0.025021284818649292, -0.05849521979689598, -0.06963152438402176, -0.11433173716068268, -0.05171923711895943, -0.1576164960861206, -0.0516701266169548, -0.018576765432953835, 0.05820421874523163, -0.09374940395355225, -0.0045557282865047455, 0.12132202833890915, 0.11401406675577164, 0.07009636610746384, -0.4037608802318573, 0.059918422251939774, -0.04121923819184303, -0.08951785415410995, -0.01337036956101656, 0.09299904108047485, -0.055197108536958694, -0.1228085532784462, -0.038455523550510406, -0.006279913708567619, -0.11719344556331635, -0.11326338350772858, 0.04198678955435753, -0.01624506711959839, -0.0473770871758461, -0.004673758056014776, -0.02941056899726391, 0.02018701657652855, -0.23746857047080994, -0.19154039025306702, -0.07650388777256012, -0.03856801986694336, -0.07599649578332901, 0.00795736163854599, -0.13120892643928528, -0.014116126112639904, -0.02305033802986145, 0.06357506662607193, 0.05987036973237991, -0.03464438393712044, 0.03724455460906029, 0.021365797147154808, -0.19127118587493896, -0.0765240490436554, 0.07002976536750793, -0.0508107915520668, 0.004195013083517551, 0.09292399138212204, 0.11065104603767395, -0.06513571739196777, 0.10142350941896439, 0.18052862584590912, 0.0089989909902215, 0.1757456362247467, 0.21261578798294067, -0.0553542785346508, 0.15101197361946106, 0.04331623390316963, -0.035917896777391434, 0.026240117847919464, 0.09981995820999146, 0.20469443500041962, -0.032290659844875336, -9.946977286290348e-08, -0.02171928621828556, 0.048157479614019394, 0.030658140778541565, 0.01341767143458128, -0.02071322500705719, 0.18809829652309418, -0.1639423370361328, 0.1592818945646286, -0.06076480448246002, 0.17876875400543213, 0.18467947840690613, -0.10638101398944855, -0.22515974938869476, 0.14513561129570007, -0.3800499737262726, 0.11676900833845139, 0.11999356746673584, 0.29674622416496277, -0.03819386288523674, 0.13761313259601593, 0.11219040304422379, 0.09844069182872772, 0.18875929713249207, 0.10380692780017853, 0.008243586868047714, -0.14404770731925964, -0.09251945465803146, 0.06239166855812073, -0.00030753298779018223, -0.006389535963535309, 0.02713736891746521, -0.031831204891204834, 0.08015436679124832, 0.06900469958782196, 0.062447186559438705, -0.015436350367963314, -0.15890833735466003, -0.05883270874619484, 0.0501200295984745, 0.057445868849754333, -0.14648087322711945, 0.07430557906627655, -0.15876424312591553, 0.047128062695264816, 0.08538038283586502, -0.03307525813579559, -0.14670227468013763, -0.03278806805610657, -0.19812867045402527, -0.10718310624361038, -0.04034188389778137, -0.06214349716901779, -0.09411114454269409, 0.07978565990924835, 0.19077321887016296, 0.08608544617891312, -0.10370751470327377, 0.0021217826288193464, -0.005218252073973417, 0.041631247848272324, -0.10111536830663681, 0.02447744645178318, -0.09368125349283218, -0.21480681002140045], metadata={'source': 'AAAMLP-569to.pdf', 'page': 74}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 75  Figure 1: MNIST dataset in CSV format  Let’s take a look at the counts of the label column in this dataset.  \\n Figure 2: Counts of label in MNIST dataset  We don’t need much more exploration for this dataset. We already know what we have, and there is no need to make plots on different pixel values. From figure 2, it is quite clear that the distribution of labels is quite good and even. We can thus use accuracy/F1 as metrics. This is the first step when approaching a machine learning problem: decide the metric!  Now, we can code a little bit. We need to create the src/ folder and some python scripts.  Please note that the training CSV file is located in the input/ folder and is called mnist_train.csv.  How should these files look like for such a project?  The first script that one should create is create_folds.py.'),\n",
       " VectorParams(vector=[-0.11465198546648026, -0.10291961580514908, -0.04520206153392792, -0.000506737909745425, 0.09530173242092133, -0.06380177289247513, 0.016300486400723457, 0.060774996876716614, -0.1007685735821724, -0.016180146485567093, -0.017441341653466225, -0.08673065900802612, 0.01747480034828186, -0.05029471963644028, -0.06156128644943237, 0.05290773883461952, -0.08064437657594681, 0.12093400210142136, -0.08296403288841248, -0.08733595162630081, 0.04052286595106125, 0.07940448075532913, 0.012008890509605408, 0.05604259669780731, -0.11071740835905075, -0.0007679582922719419, 0.039400748908519745, 0.06829172372817993, -0.15006615221500397, -0.005984706804156303, -0.014409751631319523, 0.03963248059153557, 0.014458849094808102, -0.02021918073296547, 0.007836753502488136, 0.08183620870113373, -0.05340160056948662, 0.051505621522665024, -0.011430284008383751, 0.1570732444524765, -0.05152546241879463, 0.04382632300257683, 0.06694303452968597, -0.011822488158941269, -0.023073360323905945, 0.052822988480329514, -0.09784283488988876, -0.12319229543209076, 0.019803714007139206, 0.04210899397730827, -0.0652981624007225, 0.028036698698997498, -0.12694567441940308, -0.09137886762619019, -0.0636214017868042, -0.07017279416322708, 0.050775930285453796, -0.06661926209926605, 0.0402836799621582, -0.01345210149884224, 0.051778215914964676, -0.1056012511253357, -0.0396043062210083, -0.07305656373500824, -0.01702728681266308, -0.08138395100831985, -0.05193129554390907, -0.027742424979805946, -0.0024689517449587584, -0.035015612840652466, -0.07347051799297333, 0.13157671689987183, -0.1258804202079773, 0.07887307554483414, -0.09398876130580902, -0.05315098166465759, 0.25721949338912964, 0.013552501797676086, 0.10383065044879913, -0.07006463408470154, -0.18527697026729584, 0.051922090351581573, 0.038252148777246475, -0.02735101617872715, 0.0055034286342561245, -0.12704505026340485, 0.03767829388380051, 0.10021064430475235, 0.05638956278562546, -0.05950257554650307, 0.16432207822799683, 0.02416149713099003, -0.05603612959384918, -0.026425369083881378, -0.012313778512179852, 0.16434040665626526, 0.008785873651504517, 0.06925974786281586, -0.012499234639108181, 0.10680031031370163, -0.11472782492637634, -0.04767211526632309, -0.036770597100257874, -0.023156948387622833, 0.0681365355849266, -0.04412515088915825, 0.10335982590913773, -0.06546185910701752, 0.06134532019495964, -0.017411304637789726, 0.04763682559132576, -0.10518145561218262, -0.11813142895698547, 0.07289993762969971, 0.07308481633663177, 0.08664746582508087, -0.0440649650990963, 0.013027750886976719, -0.22179654240608215, 0.17572399973869324, -0.08989530056715012, 0.022844206541776657, 0.06752394139766693, -0.004450605716556311, -0.024549737572669983, -0.1026265099644661, -0.037432704120874405, 1.3259266240640374e-32, -0.10374104231595993, -0.0066154832020401955, 0.1281927078962326, -0.10429879277944565, -0.0019963779486715794, -0.13546213507652283, -0.012750758789479733, 0.0026572414208203554, -0.026044748723506927, 0.059956811368465424, -0.1818695366382599, 0.07063589245080948, -0.020355066284537315, -0.05409179627895355, -0.012193665839731693, -0.020839212462306023, -0.10373029857873917, -0.0018365624127909541, -0.01265458483248949, 0.002772014122456312, 0.2943081855773926, -0.016197923570871353, 0.004256659187376499, -0.051530420780181885, 0.0017979171825572848, -0.09284712374210358, -0.054006174206733704, 0.07569443434476852, -0.022766536101698875, -0.023356948047876358, -0.2178926318883896, -0.0636184886097908, 0.01553381234407425, -0.06910385191440582, -0.024327605962753296, -0.05349920690059662, -0.010309776291251183, 0.10856922715902328, -0.1023288369178772, -0.041105903685092926, -0.03506917133927345, 0.014372133649885654, 0.033597681671381, -0.0044242460280656815, -0.012969071045517921, 0.0025670353788882494, 0.04668474569916725, 0.06886123865842819, 0.06603754311800003, 0.04468370974063873, 0.005469892174005508, -0.06966323405504227, 0.04649443179368973, 0.03046703152358532, -0.19204400479793549, 0.19908414781093597, 0.12567885220050812, 0.06167534738779068, 0.13800960779190063, -0.025076624006032944, 0.07477422058582306, -0.026648739352822304, -0.00839429721236229, 0.06386136263608932, 0.03491779789328575, -0.005026603117585182, 0.14820949733257294, -0.05124451592564583, 0.0892624631524086, -0.08055966347455978, -0.09151262789964676, 0.03844693303108215, -0.056190863251686096, -0.12354962527751923, 0.08970119804143906, -0.09565594047307968, 0.028771838173270226, -0.028090259060263634, -0.19565510749816895, -0.04971585422754288, -0.00967339240014553, 0.08811267465353012, -0.052307214587926865, -0.18632780015468597, 0.11244615167379379, -0.03152700886130333, 0.03813999891281128, 0.002051211893558502, -0.17370055615901947, -0.08199898153543472, -0.17555809020996094, 0.008033807389438152, -0.038654204457998276, -0.11010286957025528, 0.12745358049869537, -1.5144397714846445e-32, 0.09183625876903534, 0.008812953718006611, 0.15720710158348083, 0.08012038469314575, 0.0825420692563057, 0.11036942899227142, -0.012930236756801605, 0.05792272090911865, -0.1539095938205719, -0.1228051483631134, -0.09469904005527496, -0.06764005869626999, 0.08433949202299118, 0.033131130039691925, -0.0041709961369633675, 0.05820846185088158, -0.19387036561965942, 0.20985029637813568, -0.06057208776473999, 0.055525775998830795, 0.036648012697696686, 0.1740344911813736, -0.18740388751029968, -0.013973657041788101, -0.16205954551696777, -0.007108110468834639, 0.043787334114313126, 0.14380216598510742, 0.04331713914871216, -0.012548999860882759, -0.07839729636907578, -0.01657814532518387, -0.11698753386735916, 0.030873239040374756, 0.0490771122276783, -0.08000487834215164, 0.0501045361161232, -0.1276831477880478, -0.09271637350320816, 0.2623429000377655, 0.06643590331077576, 0.16771939396858215, -0.26994961500167847, 0.06291894614696503, -0.006151709705591202, -0.05519469827413559, -0.046680450439453125, -0.01528017409145832, -0.09824667125940323, -0.13958929479122162, 0.034483566880226135, 0.013358335942029953, -0.14511853456497192, 0.01885104924440384, 0.003198782214894891, 0.11759387701749802, -0.07877147942781448, 0.0029232611414045095, -0.031626347452402115, 0.02786194533109665, -0.14249403774738312, -0.06411794573068619, -0.06614939123392105, -0.017580924555659294, 0.12186746299266815, 0.03572137653827667, -0.10359875857830048, -0.013177519664168358, -0.0051610697992146015, 0.06154366582632065, -0.13139431178569794, 0.04655694589018822, 0.024240897968411446, -0.08889102935791016, 0.027011431753635406, 0.026554543524980545, 0.03391166776418686, 0.028350958600640297, 0.040556199848651886, 0.1288459300994873, 0.018322153016924858, -0.041789013892412186, 0.03088059090077877, 0.20302870869636536, 0.001398476422764361, 0.12050840258598328, 0.18349364399909973, 0.11971749365329742, 0.041619207710027695, -0.08290212601423264, 0.00024394541105721146, -0.08389522135257721, 0.11436551809310913, 0.18009263277053833, -0.08702955394983292, -1.0060843891324112e-07, -0.025506483390927315, 0.08172066509723663, 0.08462399244308472, 0.16377310454845428, -0.013054345734417439, 0.05422366410493851, -0.05813940614461899, 0.011383894830942154, -0.05545661598443985, 0.06669134646654129, 0.07011234015226364, -0.0039018052630126476, -0.15278373658657074, 0.15089274942874908, 0.0063938251696527, 0.10670012980699539, 0.0006292234756983817, 0.11793049424886703, -0.014529675245285034, 0.22706939280033112, 0.17723293602466583, -0.0525352843105793, 0.11830301582813263, 0.12726636230945587, 0.033096861094236374, -0.14825963973999023, -0.06445226073265076, 0.06775780022144318, -0.00327629828825593, 0.04838377237319946, 0.012495830655097961, -0.11106650531291962, 0.06169482693076134, 0.044846177101135254, 0.025863047689199448, 0.010882859118282795, -0.023886334151029587, -0.028904061764478683, 0.094272181391716, 0.1592649519443512, -0.07310325652360916, 0.06373398751020432, -0.18862931430339813, -0.04406651109457016, -0.018689319491386414, 0.02800031751394272, -0.047375380992889404, 0.00013972805754747242, 0.047994405031204224, -0.004368223249912262, -0.108559250831604, -0.0604512058198452, -0.1101297065615654, -0.019963009282946587, 0.13519006967544556, 0.029899772256612778, -0.1110355481505394, 0.01767468824982643, 0.0033606071956455708, 0.0361737422645092, 0.014438959769904613, -0.024185972288250923, 0.03380030393600464, -0.052165865898132324], metadata={'source': 'AAAMLP-569to.pdf', 'page': 75}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 76 This will create a new file in the input/ folder called mnist_train_folds.csv, and it’s the same as mnist_train.csv. The only differences are that this CSV is shuffled and has a new column called kfold.   Once we have decided what kind of evaluation metric we want to use and have created the folds, we are good to go with creating a basic model. This is done in train.py.  ═════════════════════════════════════════════════════════════════════════ # src/train.py import joblib import pandas as pd from sklearn import metrics from sklearn import tree   def run(fold):     # read the training data with folds     df = pd.read_csv(\"../input/mnist_train_folds.csv\")      # training data is where kfold is not equal to provided fold     # also, note that we reset the index     df_train = df[df.kfold != fold].reset_index(drop=True)      # validation data is where kfold is equal to provided fold     df_valid = df[df.kfold == fold].reset_index(drop=True)      # drop the label column from dataframe and convert it to     # a numpy array by using .values.     # target is label column in the dataframe     x_train = df_train.drop(\"label\", axis=1).values     y_train = df_train.label.values      # similarly, for validation, we have     x_valid = df_valid.drop(\"label\", axis=1).values     y_valid = df_valid.label.values      # initialize simple decision tree classifier from sklearn     clf = tree.DecisionTreeClassifier()      # fit the model on training data     clf.fit(x_train, y_train)      # create predictions for validation samples     preds = clf.predict(x_valid)'),\n",
       " VectorParams(vector=[-0.14818744361400604, -0.048937682062387466, -0.14356771111488342, 0.07562922686338425, 0.071504607796669, -0.07235068082809448, -0.03030329942703247, 0.1744370311498642, -0.1697680801153183, -0.0688282698392868, 0.019002681598067284, -0.016662608832120895, 0.031184330582618713, -0.10641568899154663, -0.0376947745680809, -0.016205284744501114, -0.1296481192111969, 0.0712967962026596, -0.1274704486131668, -0.07282061129808426, 0.12348015606403351, 0.03086170367896557, 0.05444328859448433, 0.1105070561170578, -0.06406696885824203, -0.10710620880126953, 0.03374394029378891, 0.09253758937120438, -0.1576777994632721, -0.06535587459802628, 0.0028526887763291597, 0.11253926903009415, 0.01820334605872631, 0.02871623821556568, 0.08265864104032516, 0.14990606904029846, 0.041256245225667953, -0.07506003230810165, -0.013402573764324188, 0.0004939731443300843, 0.02316756546497345, 0.016716765239834785, 0.011030838824808598, -0.014257418923079967, -0.0007522145169787109, 0.03623495250940323, -0.1412811130285263, -0.08272294700145721, 0.012865887023508549, 0.022688129916787148, -0.07814551144838333, 0.054113078862428665, -0.05682055279612541, -0.09114012867212296, 0.019985828548669815, -0.013780971057713032, 0.065266914665699, 0.022534117102622986, -0.0770948976278305, -0.0675296038389206, -0.017056284472346306, 0.02425156906247139, -0.09784354269504547, -0.06489327549934387, -0.02916543185710907, -0.04324062913656235, -0.04653097689151764, -0.03909509629011154, 0.07934486120939255, -0.08813109248876572, -0.10459321737289429, 0.13999691605567932, -0.08178766071796417, -0.04980691522359848, -0.03727122023701668, -0.15352031588554382, 0.1023944765329361, 0.06428300589323044, -0.0010812062537297606, -0.12346018850803375, -0.09848261624574661, -0.06950706243515015, 0.047568418085575104, 0.011930767446756363, 0.027294199913740158, -0.07567410171031952, 0.09315743297338486, 0.06646686792373657, 0.12092887610197067, -0.07791134715080261, 0.07989934831857681, -0.07730677723884583, -0.12044614553451538, 0.059382956475019455, 0.04080783948302269, 0.28549888730049133, 0.04221353307366371, 0.1327105015516281, -0.044713933020830154, 0.10305916517972946, -0.08858026564121246, -0.043795522302389145, 0.06295833736658096, 0.10866223275661469, 0.1628786325454712, -0.02404460683465004, 0.13040520250797272, -0.021552758291363716, 0.06903799623250961, -0.08243651688098907, 0.12388931959867477, -0.025093117728829384, -0.007956058718264103, 0.03249707818031311, 0.11379731446504593, 0.2069607973098755, -0.12673766911029816, 0.09412795305252075, -0.16517473757266998, 0.22908459603786469, -0.10412377864122391, 0.14559486508369446, 0.0680893287062645, 0.05859706550836563, 0.0013843269553035498, -0.13416630029678345, -0.051376063376665115, 1.1259048726701016e-32, -0.038216348737478256, -0.11329503357410431, 0.06460043787956238, -0.0018457848345860839, 0.12087921798229218, -0.053042441606521606, -0.0017211579252034426, 0.07712966203689575, -0.02816878631711006, 0.09320452064275742, -0.2410287857055664, 0.0561092384159565, -0.04750944301486015, -0.01135213952511549, 0.02044611983001232, -0.09510154277086258, -0.05756079778075218, 0.04488307982683182, -0.019504453986883163, 0.032573629170656204, 0.2928770184516907, 0.09196994453668594, -0.05305005609989166, -0.05007929354906082, -0.008198341354727745, 0.12070363759994507, -0.04274601861834526, 0.12393281608819962, -0.18434157967567444, 0.025956913828849792, -0.09809821844100952, -0.0292026586830616, 0.010474505834281445, -0.059451986104249954, -0.07606428861618042, -0.16884683072566986, 0.025920972228050232, 0.007308344356715679, -0.09101448953151703, -0.012047267518937588, -0.01403977070003748, 0.016373489052057266, 0.009611533023416996, -0.031144382432103157, -0.07153908908367157, -0.06828571110963821, 0.05141088366508484, 0.11505473405122757, -0.03352944180369377, 0.08651632070541382, 0.03514443337917328, -0.011343046091496944, 0.01957349292933941, -0.11121171712875366, -0.1346949338912964, 0.0260362159460783, 0.1074259877204895, -0.05720192566514015, 0.12649330496788025, -0.06468023359775543, 0.06652093678712845, 0.017447618767619133, -0.032404255121946335, 0.07048898935317993, 0.05984318256378174, -0.031517185270786285, 0.14136922359466553, -0.032358478754758835, 0.12607334554195404, 0.015295114368200302, -0.24554118514060974, -0.000620442908257246, -0.10537189245223999, -0.0512097105383873, 0.14762581884860992, -0.07773410528898239, 0.10001744329929352, -0.03283977881073952, -0.16993331909179688, -0.027900882065296173, 0.16297225654125214, 0.16866859793663025, -0.06494133919477463, -0.25312280654907227, 0.06273959577083588, -0.025832297280430794, 0.05584156513214111, -0.04153250530362129, -0.05412163957953453, -0.09807687252759933, -0.13079167902469635, -0.019781775772571564, -0.05276624113321304, -0.1124362125992775, -0.029587117955088615, -1.2447516861736535e-32, 0.09306600689888, 0.0406523235142231, 0.0027621209155768156, 0.0556151457130909, 0.04136675223708153, 0.01322563923895359, 0.09066888689994812, -0.02680318057537079, -0.11703242361545563, -0.13811194896697998, -0.0054468875750899315, -0.17284905910491943, 0.04452868178486824, -0.04062139615416527, 0.034352198243141174, 0.07370134443044662, -0.20530842244625092, 0.10588839650154114, -0.10338833928108215, -0.0037726580630987883, -0.09517690539360046, 0.1243734359741211, -0.06172417104244232, 0.032096199691295624, -0.036601342260837555, -0.021318446844816208, -0.03299926593899727, 0.19839249551296234, 0.0668468326330185, -0.06497127562761307, -0.07418937981128693, -0.006027372553944588, -0.21015019714832306, 0.05654667690396309, -0.08102721720933914, -0.1019030213356018, -0.011638784781098366, -0.060585007071495056, 0.056356918066740036, 0.19635556638240814, 0.15026214718818665, 0.12193043529987335, -0.309611976146698, 0.05667184665799141, -9.277333447244018e-05, 0.028117068111896515, 0.0011392106534913182, -0.059971291571855545, -0.13204078376293182, -0.20915186405181885, 0.05587487667798996, -0.047211404889822006, -0.111277736723423, -0.027276325970888138, 0.007193308789283037, 0.09954848140478134, 0.043128885328769684, 0.003546433988958597, -0.10745197534561157, 0.03706635162234306, -0.003307017032057047, -0.040941666811704636, 0.03972291573882103, -0.00997419748455286, 0.01302993856370449, 0.10838516801595688, -0.21573960781097412, 0.04664289951324463, 0.10105054080486298, 0.06005902215838432, -0.1662845015525818, -0.00506408978253603, 0.08634750545024872, -0.015742335468530655, -0.04652886837720871, 0.07539240270853043, -0.0801965743303299, -0.013039826415479183, 0.00387042504735291, 0.16006645560264587, -0.020969217643141747, -0.04830258712172508, 0.03479433432221413, 0.18665271997451782, -0.0582788810133934, 0.07399410754442215, 0.08112812042236328, 0.1584865152835846, 0.12503837049007416, -0.08821796625852585, -0.025495825335383415, 0.0682852640748024, 0.10879073292016983, 0.18911471962928772, -0.08456634730100632, -1.0069118872024774e-07, -0.04035593941807747, 0.039671652019023895, 0.03187946230173111, 0.1932981163263321, 0.00246735499240458, 0.08779988437891006, -0.057168375700712204, 0.0034869469236582518, -0.0592244490981102, 0.0018882129807025194, 0.046362414956092834, -0.04109570384025574, -0.2283506840467453, 0.09263589978218079, -0.02354946918785572, 0.07129297405481339, 0.06982890516519547, 0.12998194992542267, -0.051641423255205154, 0.01723386161029339, 0.13418976962566376, 0.047574687749147415, 0.05281112343072891, 0.09693276137113571, 0.07534193247556686, -0.06481170654296875, -0.12479064613580704, 0.11536513268947601, -0.1159784272313118, 0.0635136142373085, 0.03004629537463188, -0.13234736025333405, 0.05856555327773094, 0.03105917014181614, -0.003887125989422202, 0.07502463459968567, 0.016895530745387077, -0.008893382735550404, 0.0905061587691307, 0.1415603905916214, 0.03294544294476509, 0.10617941617965698, -0.1983189731836319, 0.0030541575979441404, -0.002454663161188364, -0.13799826800823212, 0.04717268794775009, -0.06224922463297844, 0.04926976561546326, -0.010048183612525463, -0.022340210154652596, 0.04671259596943855, -0.08672916889190674, 0.04871353879570961, 0.0658026859164238, 0.036664340645074844, -0.09409109503030777, -0.08502544462680817, -0.13711825013160706, 0.02697974257171154, -0.13459469377994537, -0.05371131747961044, 0.08334033191204071, -0.025394514203071594], metadata={'source': 'AAAMLP-569to.pdf', 'page': 76}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 77     # calculate & print accuracy     accuracy = metrics.accuracy_score(y_valid, preds)     print(f\"Fold={fold}, Accuracy={accuracy}\")      # save the model     joblib.dump(clf, f\"../models/dt_{fold}.bin\")   if __name__ == \"__main__\":     run(fold=0)     run(fold=1)     run(fold=2)     run(fold=3)     run(fold=4) ═════════════════════════════════════════════════════════════════════════  You can run this script by calling python train.py in the console.  ═════════════════════════════════════════════════════════════════════════ ❯ python train.py Fold=0, Accuracy=0.8680833333333333 Fold=1, Accuracy=0.8685 Fold=2, Accuracy=0.8674166666666666 Fold=3, Accuracy=0.8703333333333333 Fold=4, Accuracy=0.8699166666666667 ═════════════════════════════════════════════════════════════════════════  When you look at the training script, you will see that there are still a few more things that are hardcoded, for example, the fold numbers, the training file and the output folder.  We can thus create a config file with all this information: config.py.  ═════════════════════════════════════════════════════════════════════════ # config.py  TRAINING_FILE = \"../input/mnist_train_folds.csv\"  MODEL_OUTPUT = \"../models/\" ═════════════════════════════════════════════════════════════════════════  And we make some changes to our training script too. The training file utilizes the config file now. Thus making it easier to change data or the model output.'),\n",
       " VectorParams(vector=[-0.06427037715911865, -0.08646785467863083, -0.031011413782835007, -0.010157577693462372, 0.11256548017263412, -0.09640149027109146, 0.009523037821054459, 0.042413391172885895, -0.1140088364481926, -0.002302097389474511, 0.003520459635183215, -0.10820118337869644, -0.03404505178332329, -0.08141100406646729, -0.06171566992998123, 0.048604048788547516, -0.09901778399944305, 0.05108948051929474, -0.07345573604106903, -0.1237860769033432, 0.028053827583789825, 0.10108904540538788, 0.004265042021870613, 0.11055464297533035, -0.08624154329299927, -0.03053312748670578, -0.0027980280574411154, 0.05801894888281822, -0.11756979674100876, -0.007130773272365332, -0.011928639374673367, 0.03238007798790932, 0.0002697940217331052, 0.0062506054528057575, -0.0010740478755906224, 0.05946870148181915, -0.07388415187597275, 0.028292929753661156, 0.039395976811647415, 0.1371789276599884, -0.01970309391617775, 0.005890344735234976, 0.053773198276758194, -0.008240101858973503, -0.008071927353739738, 0.10799438506364822, -0.15012332797050476, -0.08552560210227966, 0.057895395904779434, 0.02511535957455635, -0.08937118202447891, 0.027278173714876175, -0.11737857013940811, -0.1095256432890892, -0.06621969491243362, -0.040061287581920624, 0.02038947492837906, -0.03112201578915119, 0.06030617654323578, 0.025935344398021698, 0.037521541118621826, -0.09362021833658218, -0.06524403393268585, -0.1061151847243309, -0.0040510669350624084, -0.016975553706288338, -0.04871238395571709, -0.046060264110565186, -0.07740350812673569, 0.046354882419109344, -5.130592398927547e-05, 0.12178393453359604, -0.09632255136966705, 0.08337811380624771, -0.05628320574760437, -0.08009304106235504, 0.20770999789237976, 0.0025611568707972765, 0.1385771632194519, -0.046548206359148026, -0.1630844622850418, 0.061605777591466904, 0.015522826462984085, -0.02076943963766098, 0.022912055253982544, -0.17250880599021912, 0.03181802108883858, 0.06443653255701065, 0.05634104833006859, -0.07738424837589264, 0.15861348807811737, -0.057972997426986694, -0.056534331291913986, 0.012531346641480923, -0.009797973558306694, 0.15732242166996002, 0.016260074451565742, 0.09319009631872177, -0.03957014158368111, 0.07794935256242752, -0.11577150970697403, -0.017521753907203674, -0.04264073818922043, 0.014177415519952774, 0.02343187853693962, -0.02009795792400837, 0.1191040575504303, -0.035305336117744446, 0.07360856980085373, -0.0031327176839113235, 0.05384817719459534, -0.11449059844017029, -0.08127613365650177, 0.08336025476455688, 0.0826619565486908, 0.11336879432201385, -0.05439303442835808, 0.05401967093348503, -0.24158522486686707, 0.14891259372234344, -0.13863292336463928, 0.08905425667762756, 0.08459427207708359, 0.059986662119627, -0.049308355897665024, -0.09261336177587509, -0.04263078048825264, 1.8212676008098657e-32, -0.13713514804840088, -0.0299635361880064, 0.10522361099720001, -0.11392608284950256, 0.000310905888909474, -0.15852193534374237, -0.0756448432803154, 0.021147623658180237, 0.015604281798005104, 0.12431513518095016, -0.17641356587409973, -0.004199808929115534, -0.027165744453668594, -0.09872764348983765, 0.026767371222376823, 0.002106093568727374, -0.04137450084090233, -6.202677468536422e-05, -0.04810841754078865, 0.009151225909590721, 0.3269011080265045, -0.030358130112290382, 0.014362203888595104, -0.0474420003592968, -0.024246089160442352, -0.02135171741247177, -0.07224369049072266, 0.08969321846961975, -0.04859983175992966, 0.017346391454339027, -0.21231046319007874, -0.05529603362083435, 0.08212124556303024, -0.06204192340373993, -0.008609095588326454, -0.10303501039743423, 0.03734251856803894, 0.11291849613189697, -0.12182445079088211, -0.019256195053458214, -0.036209799349308014, 0.06606610119342804, 0.08778161555528641, -0.014912615530192852, -0.022547410801053047, -0.04087655246257782, 0.04921342432498932, 0.07765857130289078, 0.06499690562486649, 0.12093328684568405, -0.03180934116244316, -0.09454277902841568, 0.032549384981393814, 0.02863246016204357, -0.20314495265483856, 0.21856701374053955, 0.14191934466362, 0.04558437690138817, 0.1164633259177208, -0.03471696376800537, 0.06968970596790314, -0.04081631824374199, 0.016673285514116287, -0.009496768936514854, 0.001724422094412148, 0.03154405578970909, 0.1362747848033905, -0.008305135183036327, 0.0651065781712532, -0.029987668618559837, -0.13267545402050018, 0.06480511277914047, -0.0991847887635231, -0.10090761631727219, 0.08126282691955566, -0.12246303260326385, 0.07067026942968369, -0.014613225124776363, -0.17679329216480255, -0.015294386073946953, 0.008847343735396862, 0.09832125902175903, -0.039922066032886505, -0.20759420096874237, 0.11570310592651367, -0.0982537493109703, 0.08420941233634949, 0.03647754713892937, -0.13756181299686432, -0.07135910540819168, -0.19238846004009247, -0.013549729250371456, -0.020896587520837784, -0.10680519789457321, 0.06694565713405609, -1.9013986997167194e-32, 0.0440472811460495, 0.017322398722171783, 0.11085126549005508, 0.04194297268986702, 0.08654199540615082, 0.09865114837884903, 0.03237459436058998, 0.06914790719747543, -0.1204228475689888, -0.1384359449148178, -0.08194553852081299, -0.052398767322301865, 0.0954766795039177, 0.04464101046323776, 0.022533997893333435, 0.058620862662792206, -0.22464217245578766, 0.1949286162853241, -0.10100273787975311, 0.023193243891000748, -0.047255806624889374, 0.13828429579734802, -0.12437742203474045, 0.01447047758847475, -0.14808769524097443, 0.019223036244511604, -0.025626853108406067, 0.12945905327796936, 0.06495843827724457, -0.018233370035886765, -0.05810609459877014, -0.006803127005696297, -0.12256715446710587, 0.05668399855494499, 0.03813614696264267, -0.10629996657371521, 0.026552753522992134, -0.13705004751682281, -0.09211033582687378, 0.18476003408432007, 0.09997519105672836, 0.19185982644557953, -0.26970362663269043, 0.06175041198730469, -0.0075248051434755325, -0.01593600958585739, 0.004521137103438377, -0.021585730835795403, -0.0984080582857132, -0.14396798610687256, 0.052805762737989426, 0.005646313540637493, -0.12064976990222931, 0.057385675609111786, -0.0068644871935248375, 0.14271891117095947, -0.08627236634492874, 0.02643073908984661, -0.06584057956933975, 0.016087844967842102, -0.11731240153312683, -0.028586430475115776, -0.07274951785802841, -0.016031723469495773, 0.150732159614563, 0.01427946425974369, -0.1242731511592865, 0.08202124387025833, 0.04311585798859596, 0.014782018959522247, -0.12666374444961548, 0.08803592622280121, -0.01941045932471752, -0.09195199608802795, -0.012753752060234547, 0.06884807348251343, -0.07184108346700668, 0.04355936124920845, 0.019400063902139664, 0.13532549142837524, 0.04994060844182968, -0.032445818185806274, -0.009584344923496246, 0.2496711015701294, 0.014357336796820164, 0.08282085508108139, 0.18951691687107086, 0.1093851774930954, 0.0044264839962124825, -0.0745721161365509, 0.04243256896734238, -0.039342980831861496, 0.08207476884126663, 0.22864708304405212, -0.07505191117525101, -1.0044486487004178e-07, -0.06399697065353394, 0.08206725865602493, 0.05564906820654869, 0.11794434487819672, 0.03444407135248184, 0.022100716829299927, -0.036069195717573166, 0.03333064913749695, -0.09799904376268387, 0.04955626279115677, 0.05648818239569664, -0.04214503988623619, -0.22640980780124664, 0.11513114720582962, -0.020504215732216835, 0.06768651306629181, -0.024641098454594612, 0.11097482591867447, -0.015304451808333397, 0.1542380005121231, 0.14565251767635345, -0.09737275540828705, 0.1297464668750763, 0.05739935114979744, 0.01811438426375389, -0.14084245264530182, -0.07136956602334976, 0.10093826800584793, -0.0001228823239216581, 0.07861494272947311, -0.009404855780303478, -0.130430668592453, 0.0436784066259861, 0.062716543674469, 0.0267600379884243, 0.02907921001315117, 0.027569860219955444, -0.03555424138903618, 0.08783955872058868, 0.17672300338745117, -0.07203688472509384, 0.09094379097223282, -0.20143872499465942, -0.02074361965060234, -0.007470682263374329, 0.04306028410792351, 0.021522365510463715, 0.013777073472738266, 0.08419699966907501, 0.007705455645918846, -0.0867978185415268, -0.0608455128967762, -0.11992068588733673, 0.01231779158115387, 0.11986273527145386, -0.03246020898222923, -0.1348336637020111, 0.012373186647891998, -0.0028552331496030092, 0.02967577986419201, 0.012205074541270733, -0.04255026578903198, 0.03644347935914993, -0.026151414960622787], metadata={'source': 'AAAMLP-569to.pdf', 'page': 77}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 78 ═════════════════════════════════════════════════════════════════════════ # train.py import os  import config  import joblib import pandas as pd from sklearn import metrics from sklearn import tree   def run(fold):     # read the training data with folds     df = pd.read_csv(config.TRAINING_FILE)      # training data is where kfold is not equal to provided fold     # also, note that we reset the index     df_train = df[df.kfold != fold].reset_index(drop=True)      # validation data is where kfold is equal to provided fold     df_valid = df[df.kfold == fold].reset_index(drop=True)      # drop the label column from dataframe and convert it to     # a numpy array by using .values.     # target is label column in the dataframe     x_train = df_train.drop(\"label\", axis=1).values     y_train = df_train.label.values      # similarly, for validation, we have     x_valid = df_valid.drop(\"label\", axis=1).values     y_valid = df_valid.label.values      # initialize simple decision tree classifier from sklearn     clf = tree.DecisionTreeClassifier()      # fir the model on training data     clf.fit(x_train, y_train)      # create predictions for validation samples     preds = clf.predict(x_valid)      # calculate & print accuracy     accuracy = metrics.accuracy_score(y_valid, preds)     print(f\"Fold={fold}, Accuracy={accuracy}\")      # save the model'),\n",
       " VectorParams(vector=[-0.1617521494626999, -0.09523327648639679, -0.08764870464801788, 0.0901336669921875, -0.023707864806056023, -0.1037617102265358, -0.018955055624246597, 0.15623164176940918, -0.25927385687828064, -0.04923192784190178, -0.09350869804620743, 0.02516491524875164, -0.07696019858121872, -0.05422450229525566, -0.004979589022696018, 0.08459027111530304, -0.15804465115070343, 0.0772608146071434, -0.06022883579134941, -0.1634707897901535, 0.10730220377445221, 0.026066334918141365, 0.07707573473453522, 0.029059335589408875, -0.10544335842132568, -0.04708077013492584, 0.04344155266880989, -0.029606366530060768, -0.05547187477350235, -0.05408947169780731, 0.20479892194271088, 0.07940001040697098, 0.011678327806293964, -0.02091015875339508, 0.15864406526088715, 0.25736239552497864, -0.11795277893543243, -0.03833542391657829, -0.07471019774675369, 0.08428679406642914, 0.05805564671754837, 0.047222036868333817, -0.034836091101169586, -0.027767661958932877, 0.024833904579281807, -0.02129518799483776, -0.05093245208263397, -0.04090387746691704, 0.03788187727332115, -0.0198019091039896, 0.05089011788368225, 0.03548996523022652, -0.01221431978046894, -0.03394844010472298, -0.030053438618779182, -0.15986375510692596, 0.02944573573768139, -0.012825369834899902, -0.14157147705554962, 0.049834854900836945, -0.12158883363008499, -0.007941818796098232, -0.11787382513284683, -0.08084508776664734, -0.06661995500326157, 0.012410224415361881, 0.08327140659093857, 0.028256691992282867, -0.010719602927565575, 0.07944431155920029, -0.11862820386886597, 0.1275942027568817, -0.18329757452011108, -0.0662355050444603, -0.07030433416366577, -0.04940548539161682, 0.22576963901519775, -0.12730351090431213, -0.05692406743764877, -0.11926514655351639, -0.06317079812288284, -0.042065899819135666, 0.05029385909438133, -0.04442345350980759, 0.03200710564851761, -0.08474946767091751, 0.013578714802861214, 0.06879637390375137, 0.11663612723350525, -0.050088316202163696, 0.15976592898368835, 0.0331113375723362, 0.016144799068570137, 0.05330468714237213, 0.045113544911146164, 0.272219181060791, 0.04581785202026367, -0.0062880790792405605, -0.13310779631137848, 0.18242572247982025, -0.10044687241315842, 0.03262997046113014, 0.1571396291255951, 0.031101873144507408, 0.08786913752555847, 0.051106225699186325, 0.06614652276039124, -0.030078409239649773, 0.050059035420417786, -0.1230403482913971, 0.06391768902540207, 0.029441682621836662, 0.03101787529885769, 0.0679132416844368, 0.10904455929994583, 0.18792270123958588, -0.039223287254571915, -0.00805819034576416, -0.08116898685693741, 0.25019571185112, -0.08129993826150894, 0.1296393871307373, -0.016566919162869453, 0.11653237044811249, 0.031766626983881, -0.1604539006948471, -0.09541160613298416, 1.1032468517160173e-32, -0.06975451856851578, -0.04948199540376663, 0.030345212668180466, -0.04065278172492981, 0.06175606697797775, -0.10094612091779709, 0.026674693450331688, 0.035543426871299744, -0.14148232340812683, 0.1275089681148529, -0.1913638561964035, 0.027711596339941025, -0.014422636479139328, -0.026571625843644142, 0.0801224634051323, -0.07314535975456238, 9.447078627999872e-05, 0.12284726649522781, -0.05229858681559563, -0.042611610144376755, 0.11823609471321106, 0.008881673216819763, -0.04671359434723854, 0.03812340274453163, -0.010001521557569504, -0.029091112315654755, 0.01995723880827427, 0.016613511368632317, 0.002825636649504304, 0.04914657399058342, -0.22068704664707184, 0.04515201598405838, -0.11465326696634293, -0.019557783380150795, 0.012968473136425018, -0.12840645015239716, -0.05940365791320801, 0.07909251749515533, -0.07931546866893768, -0.019045738503336906, -0.10609263181686401, -0.05088629201054573, 0.10399028658866882, -0.09872689098119736, -0.04229259490966797, -0.1528424173593521, 0.022812601178884506, 0.09390846639871597, -0.14569377899169922, 0.1766922026872635, 0.06359389424324036, -0.02467191219329834, 0.010442126542329788, -0.006356231868267059, -0.07703319191932678, 0.04713776335120201, 0.11364449560642242, 0.07578594982624054, 0.24232102930545807, 0.07937078922986984, 0.13436664640903473, 0.0013987248530611396, -0.009363864548504353, 0.05670791119337082, 0.0406167134642601, 0.006487180013209581, 0.14453886449337006, 0.05003132298588753, 0.04914305731654167, 0.12151717394590378, -0.1143738254904747, 0.0840357318520546, -0.08535853773355484, -0.1021207869052887, 0.2159215211868286, -0.12059634178876877, 0.1629144847393036, -0.04456884413957596, -0.1324424296617508, 0.015635723248124123, 0.12875531613826752, 0.113894984126091, 0.1758102923631668, -0.29813534021377563, 0.003206525230780244, -0.05917806550860405, 0.07270757108926773, -0.10152848809957504, -0.11679162830114365, -0.03200880065560341, -0.2179017961025238, -0.020593203604221344, -0.011232730932533741, -0.13671326637268066, 0.034016530960798264, -9.913270060166704e-33, 0.12814006209373474, -0.002667865250259638, -0.026778586208820343, 0.04501406103372574, -0.043379757553339005, -0.03524284437298775, 0.04452832043170929, 0.0770380049943924, -0.1766664832830429, -0.13203810155391693, -0.11900867521762848, -0.11291033029556274, 0.09233408421278, -0.015839295461773872, 0.09922251105308533, 0.026917921379208565, -0.02127140387892723, 0.1181902289390564, -0.020106805488467216, 0.07463536411523819, -0.1933363378047943, 0.08664833009243011, -0.04463062435388565, -0.08770512044429779, -0.15543070435523987, -0.000460168463177979, -0.035448718816041946, 0.15584489703178406, 0.11813196539878845, 0.04815376549959183, -0.10838130861520767, 0.013614735566079617, -0.11352565139532089, 0.0852343887090683, -0.05907399579882622, 0.06432498246431351, 0.08383990079164505, -0.033165790140628815, 0.046020522713661194, 0.1287878453731537, 0.21782924234867096, 0.08577848970890045, -0.10212857276201248, 0.03567908704280853, -0.005468222312629223, -0.050397783517837524, -0.17313478887081146, 0.03143736347556114, -0.19264869391918182, -0.13993877172470093, -0.04971681162714958, -0.003917400725185871, -0.07935871183872223, -0.009359041228890419, -0.08659206330776215, -0.0582212395966053, 0.06696213036775589, -0.12171377241611481, -0.1439850628376007, -0.05274447798728943, -0.07066254317760468, -0.012041640467941761, -0.04669506102800369, -0.09309666603803635, 0.06749479472637177, 0.02740478329360485, -0.17214208841323853, -0.09886486083269119, 0.048930488526821136, 0.07412682473659515, -0.03607798367738724, -0.017095141112804413, -0.027526041492819786, 0.037657108157873154, -0.09470688551664352, 0.1974818855524063, -0.022106273099780083, -0.012365300208330154, -0.032993655651807785, 0.043894410133361816, -0.0329035259783268, -0.05725821480154991, 0.03801647201180458, 0.15722818672657013, -0.12972553074359894, 0.09694947302341461, 0.058553870767354965, 0.13132496178150177, 0.1013547033071518, -0.0828479677438736, 0.004986538551747799, 0.020954670384526253, 0.14338134229183197, 0.3002455234527588, -0.023188242688775063, -9.954268165301983e-08, 0.08287268131971359, 0.10947196185588837, 0.05521459877490997, 0.1946239471435547, 0.05440979078412056, 0.023855682462453842, -0.03474178537726402, 0.07759188860654831, -0.0249018594622612, 0.10108979791402817, 0.059604063630104065, -0.05603950843214989, -0.13861991465091705, 0.10724037140607834, 0.03587879613041878, 0.17182962596416473, -0.031169841066002846, 0.048669423907995224, -0.07911995053291321, 0.022777777165174484, 0.11448759585618973, -0.016836930066347122, 0.06969262659549713, 0.0967460423707962, -0.014032279141247272, -0.0799420028924942, -0.00682473462074995, 0.0576341338455677, -0.04149314761161804, -0.05392630770802498, -0.010547609068453312, -0.020653365179896355, -0.08895915001630783, 0.022479234263300896, 0.05667981132864952, 0.06989137828350067, -0.011750984005630016, -0.07898040115833282, 0.0666060522198677, 0.12194676697254181, -0.027192000299692154, 0.1402563899755478, -0.09645968675613403, -0.032285306602716446, 0.025715690106153488, 0.03332636505365372, 0.0001938593777595088, -0.06423389166593552, 0.09909556806087494, 0.008058554492890835, -0.060136206448078156, 0.06727041304111481, -0.05313330888748169, 0.007414556574076414, 0.05787711963057518, 0.06734161078929901, 0.008208203129470348, -0.11913500726222992, -0.06013955920934677, 0.020424768328666687, -0.13000570237636566, -0.06602668017148972, -0.036805160343647, 0.025990011170506477], metadata={'source': 'AAAMLP-569to.pdf', 'page': 78}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 79     joblib.dump(         clf,          os.path.join(config.MODEL_OUTPUT, f\"dt_{fold}.bin\")     )   if __name__ == \"__main__\":     run(fold=0)     run(fold=1)     run(fold=2)     run(fold=3)     run(fold=4) ═════════════════════════════════════════════════════════════════════════  Please note that I am not showing the difference between this training script and the one before. Please take a careful look at both of them and find the differences yourself. There aren’t many of them.  There is still one more thing related to the training script that can be improved. As you can see, we call the run function multiple times for every fold. Sometimes it’s not advisable to run multiple folds in the same script as the memory consumption may keep increasing, and your program may crash. To take care of this problem, we can pass arguments to the training script. I like doing it using argparse.  ═════════════════════════════════════════════════════════════════════════ # train.py import argparse . . .  if __name__ == \"__main__\":     # initialize ArgumentParser class of argparse     parser = argparse.ArgumentParser()      # add the different arguments you need and their type     # currently, we only need fold     parser.add_argument(         \"--fold\",         type=int     )     # read the arguments from the command line     args = parser.parse_args()      # run the fold specified by command line arguments'),\n",
       " VectorParams(vector=[-0.18788954615592957, -0.11919283866882324, -0.059226129204034805, 0.1489247977733612, 0.041385799646377563, -0.07259659469127655, -0.08813711255788803, 0.1201406866312027, -0.10741432011127472, -0.009673097170889378, -0.01801837980747223, 0.035988084971904755, 0.01793854869902134, 0.021889427676796913, 0.023617533966898918, -0.024492919445037842, -0.1028265506029129, 0.07727894186973572, -0.11514895409345627, -0.045705944299697876, 0.16794005036354065, 0.015101965516805649, 0.14554762840270996, 0.04563121497631073, -0.15916220843791962, -0.15015660226345062, 0.05432514473795891, -0.03857303783297539, -0.05875375494360924, -0.1233549565076828, 0.11896451562643051, 0.04327014088630676, 0.0022444718051701784, -0.1337643563747406, 0.10970771312713623, 0.1415378898382187, -0.07517726719379425, -0.063125379383564, -0.00869569182395935, 0.04445332661271095, 0.10200957953929901, 0.037237852811813354, -0.08733097463846207, -0.058174896985292435, 0.01139876525849104, -0.016772275790572166, -0.16372160613536835, -0.11019475013017654, -0.013648033142089844, 0.003704128321260214, -0.006776438560336828, 0.005286538507789373, -0.05887909606099129, -0.08408548682928085, -0.058817747980356216, -0.03201739117503166, 0.07173824310302734, 0.0291301142424345, -0.1047472134232521, -0.06224192678928375, -0.11433461308479309, 0.012527761049568653, -0.13480144739151, -0.09422703832387924, 0.030193358659744263, -0.03841237351298332, 0.00047749836812727153, -0.03797344118356705, 0.05341736227273941, -0.003883974626660347, -0.1005372628569603, 0.0533440038561821, -0.022141367197036743, -0.08707401901483536, -0.04371887072920799, -0.12532314658164978, 0.15644848346710205, -0.050902724266052246, -0.07633073627948761, -0.06425655633211136, -0.14997924864292145, -0.16244439780712128, 0.04427922144532204, -0.0769575983285904, 0.016748081892728806, -0.007914643734693527, 0.09964445233345032, 0.0541304387152195, 0.12711340188980103, -0.06760213524103165, 0.06256724894046783, -0.02845470979809761, -0.0036049678456038237, 0.15371356904506683, 0.04050912708044052, 0.2765490710735321, 0.1082802340388298, 0.012072776444256306, -0.05256938561797142, 0.14099177718162537, -0.023010706529021263, 0.017891723662614822, 0.09800474345684052, 0.028597140684723854, 0.16992226243019104, 0.07229410111904144, 0.021099552512168884, -0.1784944385290146, 0.07214178144931793, -0.08871523290872574, 0.10541726648807526, 0.02077811397612095, 0.05316677689552307, 0.026959285140037537, 0.07902693003416061, 0.20891694724559784, -0.04070407524704933, 0.09329012036323547, -0.11207418143749237, 0.29293227195739746, -0.07404059171676636, 0.15940307080745697, 0.17953097820281982, 0.05928726866841316, 0.05302330479025841, -0.06576160341501236, -0.07478544861078262, 5.7307987118036174e-33, -0.020966075360774994, -0.0845479667186737, 0.0035215048119425774, -0.09542397409677505, 0.1547328680753708, -0.04845215007662773, 0.028623411431908607, 0.09232071042060852, -0.11973170936107635, 0.10501419007778168, -0.16792871057987213, 0.06607869267463684, -0.02542564459145069, -0.02823680080473423, 0.10573667287826538, -0.03818894177675247, -0.09111619740724564, 0.05198928713798523, -0.011607320047914982, 0.012436961755156517, 0.2504858672618866, 0.029051538556814194, -0.01303940825164318, -0.06075509637594223, 0.012145566754043102, 0.019558077678084373, -0.02558625303208828, 0.08313107490539551, -0.15095479786396027, 0.051051411777734756, -0.1480957567691803, 0.03799932450056076, -0.12373878806829453, -0.048230722546577454, -0.1046099066734314, -0.10004235804080963, -0.03198397159576416, 0.04062502831220627, -0.023920413106679916, -0.07261824607849121, -0.03213925287127495, -0.10531498491764069, 0.06681352853775024, -0.10868280380964279, -0.04031677916646004, -0.08837372809648514, 0.02732759341597557, 0.14231768250465393, -0.1390955150127411, 0.11084046214818954, 0.1145089715719223, -0.030670300126075745, 0.021365320309996605, -0.08889041841030121, -0.09756552428007126, 0.0002707673702389002, 0.0919780284166336, -0.03096708096563816, 0.21768462657928467, 0.028260312974452972, 0.12352891266345978, -0.019376439973711967, -0.0646442249417305, 0.08587832748889923, 0.03718210756778717, 0.04994902387261391, 0.09262407571077347, -0.031266313046216965, 0.033491142094135284, 0.062212493270635605, -0.20633849501609802, 0.060094475746154785, -0.14751388132572174, -0.0383269339799881, 0.07691571116447449, -0.1249198168516159, 0.17116829752922058, -0.02535220794379711, -0.02599942497909069, 0.01740855909883976, 0.18323259055614471, 0.145337775349617, -0.02691923826932907, -0.2648985981941223, 0.02804357185959816, 0.010792617686092854, 0.05232146754860878, -0.06009881943464279, -0.12900295853614807, -0.1016257256269455, -0.0815693661570549, -0.1108226329088211, 0.0162827055901289, -0.07154849916696548, 0.036050938069820404, -7.773619814436621e-33, 0.0437270812690258, 0.07208750396966934, -0.06860116869211197, 0.04467693716287613, 0.026043904945254326, -0.11398904770612717, 0.07287542521953583, -0.005910193547606468, -0.22821606695652008, -0.15885566174983978, -0.15202246606349945, -0.11264322698116302, 0.05156092345714569, 0.026684539392590523, 0.11583984643220901, 0.022963913157582283, -0.13005799055099487, 0.10576280951499939, 0.04875343292951584, 0.06836456060409546, -0.04093537852168083, 0.12233051657676697, -0.23994344472885132, 0.040629010647535324, -0.04523854702711105, 0.001606821664609015, -0.027296481654047966, 0.18054740130901337, 0.19304490089416504, -0.009783114306628704, -0.14112426340579987, -0.06714159995317459, -0.13522882759571075, 0.07218585163354874, -0.08538748323917389, 0.035068873316049576, -0.022563716396689415, -0.07257161289453506, 0.08584818243980408, 0.18113024532794952, 0.08698549121618271, 0.003136793849989772, -0.2199522703886032, 0.0673041045665741, -0.003954476676881313, -0.003380583366379142, -0.10500739514827728, -0.0032714500557631254, -0.14052170515060425, -0.22266605496406555, 0.026240374892950058, -0.0017632751259952784, -0.0775134265422821, 0.016689838841557503, -0.10967444628477097, -0.0032291465904563665, -0.021347498521208763, -0.025902830064296722, -0.07334153354167938, 0.08063482493162155, -0.016275255009531975, 0.005665082484483719, 0.026267146691679955, -0.015229610726237297, -0.03742588683962822, 0.09290068596601486, -0.2128554731607437, -0.13266858458518982, 0.0802001878619194, 0.0657387375831604, -0.0702066421508789, -0.007564463187009096, 0.061959899961948395, -0.08416473120450974, 0.025126755237579346, 0.1388964205980301, -0.09381050616502762, -0.017567601054906845, -0.08416373282670975, 0.010689673013985157, -0.03096475638449192, -0.07722008973360062, 0.03646872937679291, 0.12438277155160904, -0.08109231293201447, 0.07022669911384583, 0.09016460180282593, 0.14708486199378967, 0.18202514946460724, -0.08683612197637558, 0.06218218430876732, 0.11417923867702484, 0.21594518423080444, 0.26818299293518066, -0.03789186477661133, -1.0032862718389879e-07, 0.07890423387289047, 0.13548211753368378, 0.126304030418396, 0.26724401116371155, -0.022809190675616264, 0.10313302278518677, -0.04084227606654167, -0.08742523193359375, -0.08535799384117126, -0.05630018189549446, 0.04536416754126549, -0.025167427957057953, -0.12211553752422333, 0.12474914640188217, 0.08486443758010864, 0.17056024074554443, -0.04923679679632187, 0.17027868330478668, -0.0012594222789630294, 0.06083327904343605, 0.05493339151144028, 0.019207872450351715, 0.08761098235845566, 0.05493432655930519, -0.0636635422706604, 0.010047917254269123, -0.11467665433883667, 0.039592195302248, -0.09893658757209778, 0.0354212187230587, 0.03638795018196106, -0.08957520872354507, 0.04095294326543808, 0.07397205382585526, -0.009392600506544113, 0.09206343442201614, -0.008527913130819798, -0.061866872012615204, 0.05645988881587982, 0.07222450524568558, 0.06715957075357437, 0.04655616357922554, -0.12275885790586472, 0.03390691801905632, -0.010165980085730553, -0.08497551828622818, -0.05597842484712601, -0.2129705846309662, 0.16201592981815338, -0.03912443667650223, -0.029235804453492165, 0.01883823052048683, -0.13846297562122345, -0.02252477966248989, 0.05982707813382149, 0.19289527833461761, -0.07098273932933807, -0.06510958820581436, -0.12232495099306107, 0.002376115880906582, -0.08975119888782501, -0.09305018931627274, 0.013478678651154041, 0.025369927287101746], metadata={'source': 'AAAMLP-569to.pdf', 'page': 79}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 80     run(fold=args.fold) ═════════════════════════════════════════════════════════════════════════  Now, we can run the python script again, but only for a given fold.  ═════════════════════════════════════════════════════════════════════════ ❯ python train.py --fold 0 Fold=0, Accuracy=0.8656666666666667 ═════════════════════════════════════════════════════════════════════════  If you see carefully, our fold 0 score was a bit different before. This is because of the randomness in the model. We will come to handling randomness in later chapters.  Now, if you want, you can create a shell script with different commands for different folds and run them all together, as shown below.  ═════════════════════════════════════════════════════════════════════════ #!/bin/sh  python train.py --fold 0 python train.py --fold 1 python train.py --fold 2 python train.py --fold 3 python train.py --fold 4 ═════════════════════════════════════════════════════════════════════════  And you can run this by the following command.  ═════════════════════════════════════════════════════════════════════════ ❯ sh run.sh Fold=0, Accuracy=0.8675 Fold=1, Accuracy=0.8693333333333333 Fold=2, Accuracy=0.8683333333333333 Fold=3, Accuracy=0.8704166666666666 Fold=4, Accuracy=0.8685 ═════════════════════════════════════════════════════════════════════════  We have made quite some progress now, but if we look at our training script, we still are limited by a few things, for example, the model. The model is hardcoded in the training script, and the only way to change it is to modify the script. So, we will create a new python script called model_dispatcher.py. model_dispatcher.py, as the name suggests, will dispatch our models to our training script.'),\n",
       " VectorParams(vector=[-0.11202502250671387, -0.05216819420456886, 0.024151364341378212, 0.03468380495905876, 0.06691668927669525, -0.09506448358297348, 0.02780865877866745, -0.005215742625296116, -0.03301718831062317, 0.004254775587469339, -0.0694214478135109, -0.12466568499803543, -0.020704012364149094, 0.013772943057119846, -0.06913240253925323, 0.05132094398140907, -0.056786518543958664, 0.07985125482082367, -0.06444545090198517, -0.11259561032056808, 0.09181395173072815, 0.11115162819623947, -0.005649483297020197, 0.1309063881635666, -0.044866226613521576, -0.10506727546453476, -0.02444099821150303, 0.11679358780384064, -0.1593763381242752, 0.04543566331267357, -0.023194070905447006, 0.05668746680021286, -0.0002715424925554544, -0.011243131943047047, -0.012694364413619041, 0.08873334527015686, -0.09002210944890976, -0.02133248560130596, 0.05115382373332977, 0.1414596289396286, 0.0010914859594777226, 0.031679946929216385, 0.013889236375689507, -0.03413182497024536, -0.03814937546849251, 0.08222387731075287, -0.11187709867954254, -0.04903906583786011, 0.047220222651958466, -0.05008748918771744, -0.07448413968086243, 0.04433732479810715, -0.03328884392976761, -0.09233657270669937, -0.0023604142479598522, -0.04171816632151604, 0.06719809025526047, -0.12777873873710632, 0.030845191329717636, -0.029130319133400917, -0.0058327713049948215, -0.09543025493621826, -0.16158424317836761, -0.01381912175565958, -0.05272183194756508, -0.0430198609828949, 0.0009743586997501552, 0.0025641678366810083, 0.002828632714226842, -0.01181047223508358, -0.03673355281352997, 0.04449119791388512, -0.11617960780858994, 0.02444293349981308, -0.009396144188940525, -0.04903501272201538, 0.252437561750412, 0.05235147476196289, 0.07547269016504288, -0.13146166503429413, -0.1255483627319336, 0.05914922431111336, 0.08538277447223663, -0.018149452283978462, 0.053655195981264114, -0.18928855657577515, 0.013306881301105022, 0.08416052162647247, 0.15909695625305176, -0.0344490185379982, 0.036824144423007965, -0.04220321401953697, 0.035904690623283386, -0.004446526989340782, 0.0713123008608818, 0.11865945160388947, 0.07017003744840622, 0.054827671498060226, -0.05069730430841446, 0.09135376662015915, -0.11653543263673782, -0.10819192230701447, -0.06920287758111954, -0.10178355127573013, 0.06389717757701874, 0.06150173395872116, 0.0066117760725319386, -0.09730686992406845, 0.121003657579422, -0.008555546402931213, 0.06294777989387512, 0.016743121668696404, -0.11392135918140411, 0.10589388757944107, 0.06428990513086319, 0.13774916529655457, -0.04134928807616234, 0.023106712847948074, -0.19694066047668457, 0.14370529353618622, -0.15146450698375702, -0.02136342041194439, 0.00904927309602499, -0.026320800185203552, -0.03723185136914253, -0.17969544231891632, -0.03568620979785919, 1.167819401268975e-32, -0.08432355523109436, -0.1137104332447052, 0.08831093460321426, -0.16397647559642792, 0.05499856173992157, 0.028043311089277267, -0.03507550060749054, -0.023975905030965805, -0.005319635849446058, 0.12492222338914871, -0.22021009027957916, 0.11057394742965698, -0.0877043828368187, -0.11371904611587524, 0.08589998632669449, -0.005595075432211161, -0.13408318161964417, 0.053151875734329224, -0.015261701308190823, -0.015724631026387215, 0.2798139452934265, 0.0306338332593441, -0.0914098247885704, -0.07433486729860306, -0.0012611083220690489, -0.06099722534418106, -0.062565378844738, -0.03181447461247444, -0.0430896133184433, 0.005009577609598637, -0.2433418482542038, -0.046490378677845, 0.0711565837264061, -0.09768244624137878, -0.08642619103193283, -0.09999120980501175, -0.030200624838471413, 0.092495396733284, -0.08803663402795792, -0.14554695785045624, -0.03946906328201294, 0.08359429985284805, 0.04420718550682068, -0.047307152301073074, -0.10293420404195786, 0.07224880158901215, 0.004345898982137442, 0.07196615636348724, 0.040007367730140686, 0.0790676549077034, 0.0019160839729011059, -0.08084253966808319, 0.05114932358264923, 0.0616510808467865, -0.19494882225990295, 0.15844352543354034, 0.11257768422365189, 0.0910990908741951, 0.16044995188713074, -0.039591118693351746, 0.02052360028028488, -0.04558071494102478, 0.08759098500013351, -0.032146453857421875, 0.07869156450033188, 0.07391215860843658, 0.014081898145377636, 0.014317142777144909, 0.12357956171035767, -0.04612349718809128, -0.11105730384588242, 0.058248113840818405, -0.11506487429141998, -0.09342880547046661, 0.1286059021949768, -0.1247306615114212, 0.13906730711460114, -0.03423542529344559, -0.23510850965976715, 0.0625724196434021, -0.036298856139183044, 0.03759047016501427, 0.029429025948047638, -0.16153068840503693, 0.11233563721179962, -0.09493037313222885, -0.022196248173713684, 0.042464468628168106, -0.22379137575626373, -0.06268519908189774, -0.16151675581932068, -0.029194869101047516, 0.04974319785833359, -0.0288300309330225, 0.12098221480846405, -1.6924097631359327e-32, 0.044647783041000366, -0.04364892467856407, 0.18223607540130615, 0.0288176778703928, 0.021646050736308098, 0.08822716772556305, -0.03219342604279518, 0.028025120496749878, -0.14039933681488037, -0.15620669722557068, -0.07608643174171448, 0.025809872895479202, 0.08984583616256714, 0.04588093236088753, 0.015344551764428616, 0.040518682450056076, -0.180990070104599, 0.21084198355674744, -0.13534028828144073, 0.12298431247472763, 0.025127699598670006, 0.2065606266260147, -0.25918370485305786, -0.01761084422469139, -0.16202332079410553, 0.0017772297142073512, 0.008805164135992527, 0.12469983845949173, 0.04470743611454964, 0.06187286227941513, -0.05272650346159935, 0.029566755518317223, -0.17506836354732513, 0.00431619631126523, 0.05878845974802971, -0.039390679448843, 0.05550467222929001, -0.11810646951198578, -0.15219955146312714, 0.26144856214523315, 0.05318306013941765, 0.18188054859638214, -0.22680041193962097, 0.11024614423513412, 0.04795139655470848, 0.02344321273267269, -0.04379500076174736, -0.04534788057208061, -0.06733644753694534, -0.08723212033510208, 0.11122830957174301, -0.024281011894345284, -0.12498447299003601, 0.10121270269155502, -0.08740931749343872, 0.008738760836422443, -0.034425973892211914, -0.0464489609003067, -0.054736316204071045, 0.014023739844560623, -0.16805128753185272, -0.07662671059370041, -0.00024200697953347117, -0.014301232062280178, -0.0009930947562679648, -0.03623396158218384, -0.1352548748254776, 0.034956324845552444, 0.0625232383608818, -0.026005815714597702, -0.06983789056539536, 0.0645676702260971, 0.07599961012601852, 0.03160153329372406, 0.04989184811711311, 0.09292177855968475, 0.012084105983376503, -0.012509163469076157, -0.015590786933898926, 0.14785999059677124, -0.038156066089868546, 0.06611200422048569, 0.04767564311623573, 0.20294667780399323, -0.014256143011152744, 0.08952216058969498, 0.2438606172800064, 0.13121342658996582, 0.12265236675739288, -0.10488361865282059, 0.03311358019709587, 0.005723722744733095, 0.14224238693714142, 0.20460431277751923, -0.044045235961675644, -1.0030153418938426e-07, 0.03409631922841072, 0.08414231985807419, 0.07891079038381577, 0.09364452213048935, -0.04339298605918884, 0.04167387634515762, -0.1397942751646042, 0.07842915505170822, -0.12277735769748688, -0.014873712323606014, 0.14939674735069275, 0.072771817445755, -0.13126346468925476, 0.05348731949925423, 0.007512932177633047, 0.10620007663965225, -0.008762625977396965, 0.10869748145341873, -0.0011109216138720512, 0.13516733050346375, 0.1768919676542282, -0.14836068451404572, 0.13845983147621155, 0.14630073308944702, -0.0028406225610524416, -0.14553651213645935, -0.053270645439624786, -0.0035909530706703663, 0.016681229695677757, 0.06652616709470749, 0.029671424999833107, -0.03497955575585365, 0.03178544342517853, 0.12761665880680084, -0.03581098094582558, 0.029375310987234116, -0.043998878449201584, -0.032645322382450104, 0.025851937010884285, 0.08244118094444275, -0.15283776819705963, -0.06892825663089752, -0.17350468039512634, -0.02267812378704548, -0.05537844076752663, 0.07426014542579651, -0.07433294504880905, 0.018628647550940514, 0.14587734639644623, 0.0726233497262001, -0.07706144452095032, 0.011021760292351246, -0.08618263155221939, -0.013336900621652603, 0.11695048958063126, -0.09807628393173218, -0.1648697406053543, -0.0010561844101175666, 0.054478615522384644, -0.06838741153478622, 0.05255286395549774, -0.14614948630332947, -0.06010037288069725, 0.007084772922098637], metadata={'source': 'AAAMLP-569to.pdf', 'page': 80}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 81 ═════════════════════════════════════════════════════════════════════════ # model_dispatcher.py from sklearn import tree   models = {     \"decision_tree_gini\": tree.DecisionTreeClassifier(         criterion=\"gini\"     ),     \"decision_tree_entropy\": tree.DecisionTreeClassifier(         criterion=\"entropy\"     ), } ═════════════════════════════════════════════════════════════════════════  model_dispatcher.py imports tree from scikit-learn and defines a dictionary with keys that are names of the models and values are the models themselves. Here, we define two different decision trees, one with gini criterion and one with entropy. To use model_dispatcher.py, we need to make a few changes to our training script.  ═════════════════════════════════════════════════════════════════════════ # train.py import argparse import os  import joblib import pandas as pd from sklearn import metrics  import config import model_dispatcher   def run(fold, model):     # read the training data with folds     df = pd.read_csv(config.TRAINING_FILE)      # training data is where kfold is not equal to provided fold     # also, note that we reset the index     df_train = df[df.kfold != fold].reset_index(drop=True)      # validation data is where kfold is equal to provided fold     df_valid = df[df.kfold == fold].reset_index(drop=True)      # drop the label column from dataframe and convert it to     # a numpy array by using .values.'),\n",
       " VectorParams(vector=[-0.05401626229286194, -0.05847207456827164, -0.12118557840585709, 0.03405872732400894, 0.12697423994541168, -0.040013689547777176, 0.03509501367807388, 0.10857684165239334, -0.1866401880979538, -0.1105600968003273, 0.0064870878122746944, -0.14075875282287598, -0.06996782124042511, -0.07730448991060257, -0.04419395700097084, 0.005528350360691547, 0.040265146642923355, 0.00018330659077037126, -0.020315993577241898, -0.1916016936302185, -0.0013839186867699027, 0.13707225024700165, 0.07651492953300476, 0.205535426735878, -0.006618020124733448, -0.009118771180510521, -0.05289921164512634, 0.08956277370452881, -0.05706632137298584, -0.02137145958840847, 0.06990810483694077, 0.048569198697805405, -0.033117495477199554, 0.05154766887426376, 0.09970779716968536, 0.08350173383951187, -0.02675716206431389, -0.007062837015837431, 0.09707760810852051, 0.06122364103794098, -0.006101234816014767, -0.06437397003173828, 0.09059856832027435, 0.0507100485265255, -0.0739682987332344, 0.07613690197467804, -0.020757658407092094, -0.08710161596536636, 0.03597581014037132, 0.008562753908336163, -0.10095579922199249, 0.06466052681207657, -0.020178746432065964, -0.09728020429611206, -0.09630030393600464, -0.1146761029958725, 0.0923566147685051, -0.11237039417028427, 0.03499986231327057, -0.03661071136593819, -0.11863789707422256, -0.05180579796433449, -0.07738923281431198, -0.06687698513269424, -0.11043892055749893, -0.04184528440237045, -0.06438963115215302, -0.06924796104431152, -0.10923540592193604, 0.058803074061870575, 0.027176711708307266, 0.13279694318771362, -0.06528403609991074, 0.05441543832421303, -0.1169470027089119, -0.055722564458847046, 0.1642015129327774, 0.02171909622848034, 0.07429488748311996, -0.05114303529262543, -0.1395183652639389, -0.0331495925784111, 0.06515702605247498, 0.038385938853025436, 0.0225613284856081, -0.13119055330753326, 0.09411488473415375, 0.01574711874127388, 0.06365927308797836, -0.08988077193498611, 0.1333543062210083, -0.020733818411827087, -0.039750948548316956, 0.11328818649053574, -0.003708783071488142, 0.15324728190898895, 0.07925212383270264, 0.057167764753103256, -0.1083206981420517, 0.14368067681789398, -0.12303809076547623, -0.06111987680196762, -0.03349786251783371, 0.012410163879394531, 0.05787809565663338, 0.018691932782530785, 0.04103770852088928, 0.055406779050827026, 0.0680793896317482, -0.09077513962984085, 0.08206482231616974, -0.02598673850297928, -0.07700071483850479, 0.13354837894439697, 0.13308608531951904, 0.0954531654715538, -0.10308056324720383, 0.002711057895794511, -0.2086997777223587, 0.06497510522603989, -0.1889743059873581, 0.12308637797832489, 0.04126787930727005, 0.02433781512081623, -0.10099207609891891, -0.07750999927520752, -0.06050994619727135, 1.2759626774927176e-32, -0.07410316914319992, -0.04037940129637718, 0.06284482032060623, -0.15852399170398712, -0.022830460220575333, -0.07003259658813477, -0.10708042234182358, 0.03167511895298958, 0.09802373498678207, 0.07992833107709885, -0.13368532061576843, -0.043504830449819565, 0.017140978947281837, -0.0457010380923748, 0.030674448236823082, -0.07104336470365524, -0.01558847539126873, 0.020472165197134018, -0.004849572665989399, 0.05339282006025314, 0.253635972738266, -0.04879484325647354, -0.08721674978733063, -0.06949198246002197, -0.07507605105638504, 0.03404463082551956, -0.06778953224420547, 0.05678240582346916, -0.12171871215105057, 0.06332071125507355, -0.2402881234884262, -0.04659411683678627, 0.13696521520614624, 0.003977040760219097, -0.06032180041074753, -0.15916664898395538, 0.08809680491685867, 0.11722912639379501, -0.07128678262233734, -0.09706127643585205, -0.011099052615463734, 0.05330904200673103, 0.03258237615227699, -0.06605228781700134, -0.027177652344107628, -0.08216487616300583, -0.029081806540489197, 0.07639569044113159, 0.03220779076218605, 0.105026476085186, -0.006901092827320099, -0.12914998829364777, 0.013446715660393238, 0.007920891977846622, -0.17750369012355804, 0.11186809092760086, 0.055452775210142136, 0.07934500277042389, 0.18640995025634766, -0.08754110336303711, 0.028398247435688972, -0.015651004388928413, 0.052553996443748474, -0.08883903175592422, 0.08743251115083694, 0.06796932220458984, 0.13202308118343353, -0.056133728474378586, 0.09855258464813232, 0.04468446224927902, -0.10850057005882263, 0.003509277245029807, -0.10159251093864441, -0.06684648990631104, 0.18689334392547607, -0.204097718000412, 0.03314802050590515, -0.07103344798088074, -0.10822493582963943, 0.08773110061883926, 0.053152766078710556, 0.13574399054050446, -0.0025404510088264942, -0.16122348606586456, 0.09304357320070267, -0.047916922718286514, 0.07241322845220566, 0.004123684950172901, -0.14680522680282593, -0.08227750658988953, -0.13552363216876984, -0.09862339496612549, -0.007737107574939728, -0.044569093734025955, -0.0035701997112482786, -1.3892102440613183e-32, 0.07160376012325287, 0.07502684742212296, 0.03936534747481346, 0.036864545196294785, 0.040130864828825, 0.009304843842983246, 0.09535530209541321, 0.15214474499225616, -0.07705746591091156, -0.09365292638540268, -0.012119235470890999, -0.16110435128211975, 0.04453916475176811, 0.06299532949924469, 0.011323460377752781, -0.029644347727298737, -0.15711554884910583, 0.09025406837463379, -0.07308303564786911, 0.04726119339466095, -0.05969156324863434, 0.08310074359178543, -0.13432537019252777, 0.03768516331911087, -0.12978951632976532, 0.01648964360356331, 0.03658819943666458, 0.10589926689863205, -0.0034711549524217844, -0.06301873177289963, -0.06228787824511528, 0.047166965901851654, -0.08683112263679504, 0.06815525144338608, 0.010752956382930279, -0.005971678998321295, 0.054854825139045715, -0.049254659563302994, -0.12417204678058624, 0.1852758675813675, 0.0787045881152153, 0.11847902089357376, -0.23768870532512665, 0.08571866154670715, -0.02375328540802002, 0.07356838136911392, -0.019323714077472687, -0.005021941848099232, -0.11617543548345566, -0.11192546039819717, 0.026813779026269913, -0.013309366069734097, -0.09368598461151123, 0.02236470952630043, -0.005847857799381018, -0.02765517309308052, -0.013110799714922905, -0.02978852391242981, -0.14301429688930511, 0.04272738844156265, -0.06925978511571884, 0.06610525399446487, -0.027955804020166397, -0.025627953931689262, 0.14452065527439117, 0.06517071276903152, -0.19693465530872345, 0.04823833703994751, 0.12303270399570465, 0.0360572412610054, -0.028887523338198662, 0.026205813512206078, -0.023709405213594437, 0.023747924715280533, -0.04040895774960518, 0.10531119257211685, -0.07861902564764023, 0.028133763000369072, 0.02037123590707779, 0.1576463133096695, 0.05431293323636055, -0.0040346961468458176, 0.021245084702968597, 0.17442362010478973, -0.05661918222904205, 0.009966585785150528, 0.162100687623024, 0.17147618532180786, -0.09584091603755951, -0.06320800632238388, 0.08519773930311203, -0.03190457448363304, 0.07396336644887924, 0.268252968788147, -0.022445470094680786, -1.0060453092819444e-07, -0.058956775814294815, 0.09724317491054535, 0.0699501782655716, 0.14121632277965546, -0.05367166921496391, 0.11925521492958069, 0.013691535219550133, -0.02721896953880787, -0.036939043551683426, 0.022363033145666122, 0.013868882320821285, -0.059814706444740295, -0.19137582182884216, 0.09271588176488876, -0.07785076647996902, 0.05431182309985161, 0.03241756930947304, 0.08815570920705795, 0.020553074777126312, 0.0786648690700531, 0.12631678581237793, -0.14316551387310028, 0.14369775354862213, -0.07536853849887848, 0.019018813967704773, -0.1110922247171402, -0.08552844822406769, 0.12465839087963104, 0.023440347984433174, 0.0935634970664978, 0.01788967102766037, -0.10182713717222214, 0.053103286772966385, 0.037867914885282516, 0.05021245405077934, 0.09623183310031891, 0.02413812093436718, -0.09749028831720352, 0.16760112345218658, 0.16293545067310333, -0.1323869675397873, 0.1428801268339157, -0.2367161214351654, -0.08680945634841919, 0.04821508750319481, 0.06383071839809418, 0.022665008902549744, -0.03270724043250084, 0.09403670579195023, 0.010381699539721012, -0.020092513412237167, -0.013049112632870674, -0.11094510555267334, 0.034958627074956894, 0.10408609360456467, -0.09952015429735184, -0.1294843852519989, -0.07326478511095047, -0.05701552331447601, -0.026631653308868408, 0.02652989886701107, -0.015322263352572918, -0.002688767621293664, -0.01740119233727455], metadata={'source': 'AAAMLP-569to.pdf', 'page': 81}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 82     # target is label column in the dataframe     x_train = df_train.drop(\"label\", axis=1).values     y_train = df_train.label.values      # similarly, for validation, we have     x_valid = df_valid.drop(\"label\", axis=1).values     y_valid = df_valid.label.values      # fetch the model from model_dispatcher     clf = model_dispatcher.models[model]      # fir the model on training data     clf.fit(x_train, y_train)      # create predictions for validation samples     preds = clf.predict(x_valid)      # calculate & print accuracy     accuracy = metrics.accuracy_score(y_valid, preds)     print(f\"Fold={fold}, Accuracy={accuracy}\")      # save the model     joblib.dump(         clf,          os.path.join(config.MODEL_OUTPUT, f\"dt_{fold}.bin\")     )   if __name__ == \"__main__\":     parser = argparse.ArgumentParser()      parser.add_argument(         \"--fold\",         type=int     )     parser.add_argument(         \"--model\",         type=str     )      args = parser.parse_args()      run(         fold=args.fold,         model=args.model     ) ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[-0.09471742063760757, -0.12038195133209229, 0.018487771973013878, 0.1463516354560852, 0.05675475299358368, -0.1373431384563446, -0.041177548468112946, 0.05416644364595413, -0.08157011866569519, 0.028285812586545944, -0.06163641810417175, -0.14101789891719818, -0.05129869282245636, -0.019905922934412956, -0.0544915609061718, 0.019501954317092896, 0.02706185355782509, -0.008886177092790604, -0.05640097334980965, -0.05054142326116562, 0.08169463276863098, 0.005464555695652962, 0.011257440783083439, 0.09681197255849838, -0.06621123850345612, -0.217027485370636, -0.037474680691957474, 0.03158019483089447, -0.12810999155044556, -0.0028665405698120594, 0.010665311478078365, 0.005931123625487089, 0.020694008097052574, -0.04412602633237839, -0.05337122455239296, 0.043830085545778275, -0.029634878039360046, -0.07206971198320389, 0.023271771147847176, 0.06758344173431396, -0.00923539511859417, -0.00018075529078487307, -0.07098271697759628, -0.0066208080388605595, 0.012265223078429699, 0.03807618096470833, -0.11609670519828796, -0.02707534469664097, 0.06942225247621536, -0.07270660996437073, -0.06805405020713806, -0.016957737505435944, -0.004859148524701595, -0.1459771692752838, -0.01885603927075863, -0.01331297680735588, -0.006990217138081789, -0.037124183028936386, -0.0025892695412039757, -0.05657133832573891, 0.05123500898480415, -0.02140715718269348, -0.11934442818164825, -0.04570811986923218, 0.020582547411322594, -0.05655849725008011, -0.02363543212413788, 0.005969544872641563, 0.08397792279720306, -0.027619607746601105, 0.009069276042282581, 0.0833107978105545, -0.04631835222244263, 0.043496161699295044, 0.0600610114634037, -0.1641526073217392, 0.15781241655349731, 0.1130649670958519, 0.12032509595155716, -0.01567729003727436, -0.14750805497169495, 0.0018982706824317575, -0.0039057706017047167, -0.05751977488398552, 0.11803413927555084, -0.05142965912818909, 0.055292632430791855, 0.08464328199625015, 0.11719246953725815, -0.022246524691581726, -0.00010684409062378109, -0.07458417862653732, -0.015232043340802193, 0.10283485800027847, 0.050071775913238525, 0.23614174127578735, 0.09716259688138962, -0.018784472718834877, -0.09727655351161957, 0.0964607521891594, -0.11294010281562805, 0.009684511460363865, -0.05892275273799896, -0.04679277911782265, 0.10098375380039215, 0.08374723792076111, -0.03466785326600075, -0.11013305187225342, 0.1128043606877327, -0.05148879811167717, 0.1465320587158203, 0.002808977384120226, -0.09823359549045563, 0.07170930504798889, 0.08438500016927719, 0.1811407208442688, -0.0950596034526825, 0.04273134842514992, -0.15161876380443573, 0.17029516398906708, -0.09389588981866837, 0.07432899624109268, -0.019742850214242935, 0.007893656380474567, -0.007009807508438826, -0.061337847262620926, -0.08519230037927628, 5.387841255453507e-33, -0.0407286137342453, -0.05503663048148155, 0.07003618031740189, -0.061054766178131104, 0.0722297728061676, -0.01714976876974106, 0.015055231750011444, 0.016049830242991447, -0.0397820845246315, 0.10840027779340744, -0.2043016254901886, -0.007262184750288725, -0.048575423657894135, -0.07708852738142014, 0.14839115738868713, -0.009627566672861576, -0.15805445611476898, -0.038265831768512726, 0.02196420356631279, -0.012039637193083763, 0.2578312158584595, 0.04803299158811569, -0.060159262269735336, -0.05594528838992119, -0.04201130568981171, 0.07835358381271362, 0.007241768296808004, -0.04125964269042015, -0.09076570719480515, 0.07751387357711792, -0.16104070842266083, -0.0873328372836113, -0.01857045851647854, -0.06184789538383484, -0.05450902134180069, -0.11110235005617142, -0.013111050240695477, 0.06881681084632874, -0.11935710906982422, -0.19147217273712158, -0.029827842488884926, 0.011286389082670212, -0.015531384386122227, -0.025967396795749664, -0.0628470629453659, 0.04363409802317619, -0.01163571048527956, 0.04725959524512291, 0.03347776457667351, 0.1647772490978241, -0.015296333469450474, -0.027524534612894058, 0.006987484637647867, 0.08253823965787888, -0.19557559490203857, 0.13565975427627563, 0.12190238386392593, 0.0365302711725235, 0.20392967760562897, -0.04350296035408974, 0.05747046694159508, -0.0296343807131052, 0.10770387202501297, -0.032195594161748886, 0.15392734110355377, 0.07133698463439941, 0.04556950926780701, -0.05717967823147774, 0.044168420135974884, 0.014402599073946476, -0.11889921128749847, 0.008767444640398026, -0.15607954561710358, -0.024298664182424545, 0.12876226007938385, -0.11518040299415588, 0.13101375102996826, -0.031241627410054207, -0.1338725984096527, 0.0732438787817955, 0.05754027143120766, 0.12133520096540451, 0.05376199632883072, -0.21200501918792725, 0.1366156041622162, -0.08684255182743073, -0.03186877816915512, 0.042782410979270935, -0.1280011683702469, 0.006630690768361092, -0.08891107887029648, -0.04954378679394722, 0.10224074125289917, 0.019165564328432083, 0.04104827344417572, -1.039682141632096e-32, 0.030390113592147827, -0.06433108448982239, 0.0935724750161171, 0.0533432699739933, -0.13104435801506042, -0.015005655586719513, -0.09745822101831436, 0.017500951886177063, -0.16416244208812714, -0.12681809067726135, -0.034846022725105286, 0.06084556132555008, 0.08415780961513519, 0.11872632801532745, 0.1071612536907196, 0.054857559502124786, -0.14186441898345947, 0.09953686594963074, -0.11726643145084381, 0.1438162922859192, -0.005501071456819773, 0.14266514778137207, -0.2612283229827881, -0.016179239377379417, -0.07271065562963486, -0.0007281664875335991, 0.002123920014128089, 0.13840308785438538, 0.09850988537073135, -0.03702859953045845, -0.07614921033382416, 0.05371209606528282, -0.15508483350276947, -0.012467472814023495, 0.015354398638010025, -0.00894264504313469, 0.015970874577760696, -0.11246474832296371, 0.03347889333963394, 0.20135512948036194, 0.01262894831597805, 0.09874594956636429, -0.22635482251644135, 0.09332743287086487, 0.056878507137298584, -0.0006154939765110612, -0.08718086034059525, 0.025254016742110252, -0.00855974294245243, -0.04997498542070389, 0.11375580728054047, -0.05649328604340553, -0.05917518958449364, 0.1380583494901657, 0.0069614192470908165, 0.06332966685295105, 0.0051974160596728325, -0.011468281969428062, -0.0034821347799152136, 0.06695559620857239, -0.15406543016433716, -0.04078356549143791, 0.06898309290409088, -0.09322575479745865, -0.08273553848266602, -0.021909132599830627, -0.19077159464359283, 0.03189673647284508, 0.10166312009096146, 0.0360998660326004, -0.06011437997221947, 0.07089564204216003, 0.014744570478796959, 0.03925514221191406, -0.0013782541500404477, 0.06896919012069702, 0.027514178305864334, 0.04437170922756195, 0.02345830202102661, 0.10064693540334702, -0.09980271756649017, 0.08829275518655777, 0.07279965281486511, 0.0629042237997055, 0.07849758118391037, -0.0026147521566599607, 0.20122845470905304, 0.14409089088439941, 0.12284316122531891, -0.10478546470403671, 0.07955050468444824, 0.1209615170955658, 0.11750584840774536, 0.15877079963684082, -0.0645793005824089, -9.95398536929315e-08, -0.006746169179677963, 0.08011755347251892, 0.10837539285421371, 0.13774867355823517, 0.011072739027440548, 0.005990968085825443, -0.08991594612598419, 0.025482766330242157, -0.1312040537595749, -0.12226251512765884, 0.16146279871463776, 0.026910852640867233, -0.11845416575670242, 0.06243990361690521, 0.06340765208005905, 0.03191622346639633, -0.06512363255023956, 0.11098107695579529, -0.03993828222155571, 0.05291461572051048, 0.09847618639469147, -0.14763830602169037, 0.06515113264322281, 0.08031993359327316, 0.04130689427256584, -0.0953507274389267, -0.08090216666460037, 0.0327024906873703, -0.12243127822875977, 0.011224046349525452, 0.016253503039479256, 0.04419020190834999, 0.04282551631331444, 0.11256754398345947, -0.11028629541397095, 0.13296359777450562, -0.005620800890028477, -0.019203174859285355, -0.00857347622513771, -0.007324917707592249, -0.04512058198451996, -0.041466016322374344, -0.08606527745723724, -0.028255101293325424, -0.10053303092718124, 0.006245043594390154, -0.03432949259877205, -0.09260120242834091, 0.1283360868692398, 0.04883171245455742, -0.0213472917675972, -0.0009031689260154963, -0.11609850078821182, -0.0040634856559336185, 0.07623394578695297, 0.02181534841656685, -0.11992988735437393, -0.0741669163107872, -0.0430690199136734, -0.026738738641142845, 0.002618505386635661, -0.17738191783428192, -0.10098829865455627, 0.03508397564291954], metadata={'source': 'AAAMLP-569to.pdf', 'page': 82}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 83 There are a few major changes to train.py: • import model_dispatcher • add --model argument to ArgumentParser • add model argument to run() function • use the dispatcher to fetch the model given the name  Now, we can run the script using the following command:  ═════════════════════════════════════════════════════════════════════════ ❯ python train.py --fold 0 --model decision_tree_gini Fold=0, Accuracy=0.8665833333333334 ═════════════════════════════════════════════════════════════════════════  Or the following command  ═════════════════════════════════════════════════════════════════════════ ❯ python train.py --fold 0 --model decision_tree_entropy Fold=0, Accuracy=0.8705833333333334 ═════════════════════════════════════════════════════════════════════════  Now, if you add a new model, all you have to do is make changes to model_dispatcher.py. Let’s try adding random forest and see what happens to our accuracy.  ═════════════════════════════════════════════════════════════════════════ # model_dispatcher.py from sklearn import ensemble from sklearn import tree   models = {     \"decision_tree_gini\": tree.DecisionTreeClassifier(         criterion=\"gini\"     ),     \"decision_tree_entropy\": tree.DecisionTreeClassifier(         criterion=\"entropy\"     ),     \"rf\": ensemble.RandomForestClassifier(), } ═════════════════════════════════════════════════════════════════════════  Let’s run this code.'),\n",
       " VectorParams(vector=[-0.15553267300128937, -0.05778083577752113, -0.05763569101691246, 0.08184939622879028, 0.11093808710575104, -0.10689297318458557, -0.0782661885023117, 0.14927928149700165, -0.1413455754518509, 0.05378524214029312, -0.03879685327410698, 0.04267813265323639, 0.055540405213832855, 0.018792642280459404, -0.030898582190275192, 0.03919731080532074, -0.03717009723186493, 0.00728398934006691, -0.14204266667366028, -0.026797931641340256, 0.06253423541784286, 0.029812706634402275, 0.07284627109766006, 0.030036630108952522, -0.030285116285085678, -0.026064077392220497, -0.007135577499866486, 0.0038541157264262438, -0.12650121748447418, -0.02741144597530365, -0.010675218887627125, 0.14401821792125702, 0.017288323491811752, -0.05250493809580803, 0.07130692899227142, 0.13590645790100098, 0.0849580466747284, -0.051240645349025726, -0.0368485152721405, 0.0415278859436512, 0.005894246976822615, -0.01304352656006813, 0.026855425909161568, -0.017389457672834396, 0.042772531509399414, 0.0140299703925848, -0.1198122650384903, -0.1529361605644226, -0.023542610928416252, -0.029056115075945854, -0.15049318969249725, 0.029176773503422737, -0.12941084802150726, -0.016149038448929787, 0.03732246905565262, -0.05257536470890045, 0.025021333247423172, -0.009243016131222248, -0.1180185079574585, -0.12249428033828735, -0.0029895214829593897, -0.058895282447338104, -0.10492230206727982, -0.05497400462627411, 0.04949298873543739, -0.03880533203482628, -0.05826891213655472, -0.07871943712234497, 0.07419025152921677, 0.006255481392145157, -0.10508248209953308, 0.023673830553889275, 0.02376229502260685, -0.05740523338317871, 0.025437399744987488, -0.10196253657341003, 0.24733182787895203, 0.01719014346599579, 0.030385160818696022, -0.020222751423716545, -0.1061011552810669, 0.01677531749010086, -0.05282806232571602, -0.06673119217157364, 0.06889338046312332, -0.060184840112924576, 0.07763823866844177, 0.037284255027770996, 0.12091397494077682, -0.014222254045307636, 0.06805243343114853, -0.06093546748161316, -0.08313699811697006, 0.0955725908279419, 0.025402052327990532, 0.20284122228622437, 0.12816430628299713, -0.006658199243247509, -0.06898747384548187, 0.15297885239124298, -0.029386920854449272, 0.02773747220635414, 0.04780281335115433, -0.01703888364136219, 0.09752640873193741, -0.011082804761826992, 0.07721561938524246, -0.02008717507123947, 0.047202542424201965, -0.1278928518295288, 0.06440053880214691, -0.06855520606040955, -0.0800413265824318, -0.012173506431281567, 0.10833931714296341, 0.16131237149238586, -0.04702378064393997, 0.14295898377895355, -0.019746292382478714, 0.23508383333683014, -0.07965195178985596, 0.09432295709848404, 0.13241158425807953, 0.036289941519498825, 0.018216954544186592, -0.040053099393844604, -0.14040301740169525, 5.769788390052454e-33, -0.02905626967549324, 0.05696107819676399, 0.029304299503564835, -0.07618795335292816, 0.0932711735367775, -0.09804130345582962, -0.023099711164832115, 0.07380513101816177, -0.009235040284693241, 0.10682861506938934, -0.12110789120197296, 0.08449561893939972, -0.05603206902742386, -0.029489345848560333, 0.12711884081363678, -0.11675955355167389, -0.13299758732318878, 0.04964086040854454, -0.04332512989640236, 0.09324336796998978, 0.23968631029129028, -0.02221027761697769, -0.01714564673602581, -0.10280933231115341, 0.08382413536310196, 0.0672355443239212, 0.0010698242112994194, 0.0011469352757558227, -0.16074535250663757, 0.061773598194122314, -0.0968482717871666, -0.02507399022579193, -0.1162104532122612, -0.05843161419034004, -0.07539767771959305, -0.13749702274799347, -0.0076970565132796764, -0.07569621503353119, -0.008762135170400143, -0.1505502164363861, -0.09551967680454254, -0.026904704049229622, -0.01477066706866026, -0.045153744518756866, -0.05490661785006523, -0.06909254938364029, 0.07067491114139557, 0.011500135995447636, -0.05859006941318512, 0.058328162878751755, 0.03667664900422096, -0.024883534759283066, -0.03307648003101349, -0.06063002347946167, -0.08010129630565643, 0.04037433862686157, 0.16859763860702515, -0.005564571358263493, 0.15582862496376038, 0.06492466479539871, 0.03530929610133171, -0.027394790202379227, 0.04890938848257065, -0.008132766000926495, 0.1523137390613556, 0.02313326671719551, -0.0032563304994255304, 0.006520414259284735, 0.11365267634391785, 0.057331815361976624, -0.14748704433441162, 0.03817795589566231, -0.06126929447054863, -0.09150443226099014, 0.12103672325611115, -0.13914886116981506, 0.15934200584888458, -0.04738727584481239, -0.01921592280268669, -0.04366350546479225, 0.07948359847068787, 0.18812410533428192, -0.11178670823574066, -0.2740561068058014, -0.03779713436961174, 0.004078897647559643, 0.09131762385368347, -0.09760133922100067, -0.07935646176338196, -0.08926862478256226, -0.11068375408649445, -0.01599965989589691, -0.04855499416589737, -0.13396300375461578, -0.0761011615395546, -6.326090356895132e-33, 0.03635194152593613, 0.019508177414536476, -0.030294282361865044, 0.05524201691150665, -0.0074335490353405476, -0.135129913687706, 0.00676883477717638, -0.044383544474840164, -0.09703202545642853, -0.11985979229211807, -0.01853693649172783, -0.12139950692653656, -0.006430421955883503, 0.0026097793597728014, 0.08741037547588348, 0.0064765894785523415, -0.06560222804546356, 0.0016464813379570842, 0.06994511932134628, 0.05735103785991669, 0.011262224055826664, 0.17061321437358856, -0.19588075578212738, -0.008195716887712479, -0.17065514624118805, 0.04410763084888458, -0.10698618739843369, 0.06254778057336807, 0.12271611392498016, -0.05530308559536934, -0.09194067120552063, -0.041987672448158264, -0.10540124773979187, 0.02110913023352623, -0.02726239524781704, 0.050400376319885254, -0.04869428649544716, -0.08225090056657791, 0.07069061696529388, 0.11456689983606339, 0.13605426251888275, 0.1298481971025467, -0.22463229298591614, 0.048639070242643356, -0.016720065847039223, -0.041380997747182846, -0.09823431819677353, -0.0015368408057838678, -0.015324697829782963, -0.13562095165252686, 0.05515362694859505, -0.007776983547955751, -0.07752738147974014, -0.027269216254353523, -0.11384524405002594, 0.12157011777162552, 0.0037436794955283403, -0.030765535309910774, 0.01139890681952238, 0.043743543326854706, -0.03333067148923874, -0.03151128068566322, 0.007513880264014006, 0.03560827299952507, 0.05059113726019859, 0.1129601001739502, -0.16832754015922546, -0.036372601985931396, 0.06523436307907104, 0.09526731073856354, -0.146449014544487, 0.003258803393691778, 0.0661785826086998, -0.03610013425350189, -0.04655303806066513, 0.018621128052473068, -0.022799372673034668, 0.07889780402183533, -0.013394187204539776, 0.02192273736000061, -0.03695746138691902, -0.036539576947689056, 0.04922926425933838, 0.1009271964430809, -0.06655417382717133, 0.011286593042314053, 0.17621369659900665, 0.14373250305652618, 0.06929630041122437, -0.0939483642578125, -0.01595139689743519, 0.127355694770813, 0.08332235366106033, 0.20644444227218628, -0.04222659021615982, -1.0023077834375727e-07, -0.02414052002131939, 0.03342481702566147, 0.05883428081870079, 0.15278245508670807, 0.05403340235352516, 0.025833940133452415, -0.059425584971904755, -0.037872105836868286, -0.04150858148932457, 0.019764935597777367, 0.1381584256887436, 0.02803790755569935, -0.19100245833396912, 0.06309619545936584, 0.0581953302025795, 0.11884620040655136, -0.023895690217614174, 0.14075610041618347, -0.052626900374889374, 0.12357410788536072, 0.15533748269081116, 0.07445278763771057, 0.013642430305480957, 0.022126656025648117, 0.0278693325817585, 0.06548160314559937, -0.07490316778421402, 0.10133533924818039, -0.04972583428025246, 0.07487764954566956, -0.02099696546792984, -0.05592914670705795, 0.11056719720363617, 0.01722603105008602, 0.005932968109846115, 0.08752883225679398, 0.029202157631516457, -0.0758199617266655, -0.01117750909179449, 0.14120204746723175, -0.011089316569268703, 0.13711458444595337, -0.134216770529747, 0.056820597499608994, 0.03605557978153229, -0.10189565271139145, -0.04522467032074928, -0.11187668889760971, 0.01823727786540985, -0.062464866787195206, -0.009570415131747723, 0.0987747311592102, -0.15809279680252075, -0.004113502334803343, 0.04571763798594475, 0.16760076582431793, -0.06131872534751892, -0.09397567063570023, -0.15016748011112213, 0.03636297583580017, -0.12097706645727158, -0.0022637401707470417, 0.04639921337366104, 0.03654012456536293], metadata={'source': 'AAAMLP-569to.pdf', 'page': 83}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 84 ═════════════════════════════════════════════════════════════════════════ ❯ python train.py --fold 0 --model rf Fold=0, Accuracy=0.9670833333333333 ═════════════════════════════════════════════════════════════════════════  Wow, a simple change gave such a massive improvement in the score! Let’s run all 5 folds using our run.sh script now!  ═════════════════════════════════════════════════════════════════════════ #!/bin/sh  python train.py --fold 0 --model rf python train.py --fold 1 --model rf python train.py --fold 2 --model rf python train.py --fold 3 --model rf python train.py --fold 4 --model rf ═════════════════════════════════════════════════════════════════════════  And the scores look like the following.  ═════════════════════════════════════════════════════════════════════════ ❯ sh run.sh Fold=0, Accuracy=0.9674166666666667 Fold=1, Accuracy=0.9698333333333333 Fold=2, Accuracy=0.96575 Fold=3, Accuracy=0.9684166666666667 Fold=4, Accuracy=0.9666666666666667 ═════════════════════════════════════════════════════════════════════════  MNIST is a problem that is discussed in almost every book and every blog. But I tried to convert this problem to more fun and show you how to write a basic framework for almost any machine learning project you are doing, or you plan to do in the near future. There are many different ways to improve on this MNIST model and also this framework, and we will see that in future chapters.  I used some scripts like model_dispatcher.py and config.py and imported them in my training script. Please note that I did not import * and neither should you. If I had imported *, you would have never known where the models dictionary came from. Writing good, understandable code is an essential quality one can have, and many data scientists ignore it. If you work on a project that others can understand and use without consulting you, you save their time and your own time and can invest that time to improve your project or work on a new one.'),\n",
       " VectorParams(vector=[0.024875180795788765, -0.04627787321805954, 0.06779097020626068, 0.050623901188373566, -0.04515145719051361, 0.04494990035891533, -0.07915566116571426, -0.09873786568641663, -0.08126683533191681, 0.0018029006896540523, -0.026117708534002304, -0.07265264540910721, -0.004744528792798519, 0.06082653999328613, 0.18907156586647034, 0.014775942079722881, 0.02843542769551277, 0.09999307990074158, -0.010865774005651474, 0.08365841209888458, 0.0886249840259552, -0.010855690576136112, 0.047349993139505386, 0.06620834767818451, -0.10046827793121338, -0.035573408007621765, -0.0517498180270195, 0.06192760542035103, -0.053417980670928955, -0.029261447489261627, -0.09117566049098969, 0.15863068401813507, -0.043747659772634506, 0.042962316423654556, -0.08701768517494202, 0.057242728769779205, -0.010165650397539139, 0.044411156326532364, -0.07881812751293182, -0.007479365915060043, -0.06522919237613678, 0.013995621353387833, -0.003564675571396947, -0.007528230082243681, 0.10213673114776611, 0.06967365741729736, -0.007742057554423809, -0.019513949751853943, -0.20686811208724976, -0.056549910455942154, -0.035924773663282394, 0.01547615323215723, 0.00704423151910305, 0.16160550713539124, -0.014613678678870201, -0.02996307797729969, 0.01852402836084366, -0.08476868271827698, -0.023906735703349113, 0.015429489314556122, -0.16321693360805511, -0.024332726374268532, -0.06526406854391098, -0.05003568157553673, -0.03792237490415573, -0.043868087232112885, -0.08265383541584015, 0.06875148415565491, 0.08717542886734009, 0.08266555517911911, -0.05527777969837189, 0.02218301221728325, -0.11443771421909332, 0.13224725425243378, 0.04883630946278572, 0.009869269095361233, 0.15482129156589508, -0.05972340703010559, 0.036502815783023834, -0.035832446068525314, -0.08469867706298828, 0.10174235701560974, 0.04118375480175018, 0.0678912028670311, 0.055434562265872955, -0.15628090500831604, -0.005429692566394806, 0.09768722206354141, -0.207951620221138, 0.12909017503261566, -0.00800988357514143, 0.011566217057406902, 0.2542927861213684, -0.04149211570620537, 0.1459929347038269, 0.050320666283369064, 0.18790844082832336, -0.06187128275632858, 0.12553559243679047, 0.0018018318805843592, 0.006976718548685312, 0.07368142157793045, -0.06615107506513596, -0.04011160135269165, 0.006790624000132084, -0.010650627315044403, 0.06369233131408691, -0.03339614346623421, -0.043052420020103455, -0.1252089887857437, -0.031103914603590965, -0.029306422919034958, -0.12866653501987457, -0.18425512313842773, -0.046203240752220154, 0.002673457143828273, -0.055399902164936066, 0.0817897617816925, 0.1576421856880188, -0.010661718435585499, -0.008828142657876015, -0.0800391435623169, 0.049634139984846115, 0.043627649545669556, 0.14919467270374298, 0.061113957315683365, -0.011130628176033497, 1.345529020921556e-32, -0.023302655667066574, -0.05025654286146164, -0.07947690784931183, -0.04598724842071533, 0.01771119423210621, -0.0226559080183506, -0.02766323648393154, 0.008327754214406013, 0.11023091524839401, 0.05895595625042915, -0.03893475607037544, 0.08832864463329315, -0.155753031373024, 0.06824934482574463, 0.05991530418395996, -0.053155772387981415, -0.0004963777028024197, 0.04071091488003731, -0.1627681851387024, 0.0032485811971127987, 0.056230079382658005, 0.04535076022148132, 0.035317085683345795, 0.06686747819185257, 0.02312677726149559, -0.03617066890001297, -0.006795558612793684, -0.17315086722373962, -0.09502861648797989, -0.0032671266235411167, -0.001467504887841642, -0.023996714502573013, 0.0005170161020942032, 0.10244059562683105, -0.07912033796310425, -0.1705126017332077, 0.042223259806632996, 0.02430359274148941, 0.06346997618675232, 0.05720464512705803, -0.006790042854845524, -0.05538802221417427, -0.02268349751830101, 0.03952491655945778, 0.04000800475478172, 0.03724655136466026, 0.13292168080806732, 0.07138381153345108, -0.14025767147541046, 0.12851980328559875, 0.004710276611149311, 0.01704331301152706, 0.013011645525693893, -0.08756580203771591, -0.046671342104673386, 0.10639743506908417, -0.027622710913419724, -0.16760580241680145, -0.1901472955942154, 0.0983538031578064, -0.0063199312426149845, 0.05537942051887512, 0.20494745671749115, -0.07377205789089203, -0.04755038395524025, -0.10661385953426361, -0.04567897692322731, -0.014303531497716904, 0.07970814406871796, 0.04718019440770149, -0.060514338314533234, 0.043998099863529205, 0.001124427653849125, -0.1087988018989563, 0.0791395828127861, 0.093808114528656, 0.05786103010177612, -0.0716477483510971, -0.06022246927022934, -0.017799977213144302, 0.03988318145275116, 0.030478982254862785, 0.08635164052248001, -0.03704028204083443, -0.03916371613740921, 0.03573547303676605, 0.07208523154258728, -0.09559807181358337, 0.01021540816873312, -0.06424957513809204, -0.1722080558538437, 0.0711384117603302, 0.06291051208972931, 0.012589489109814167, 0.15260203182697296, -1.3020643826159326e-32, -0.03645198792219162, -0.051681023091077805, -0.03212093561887741, -0.01903386227786541, -0.0003227242559660226, 0.04696781188249588, -0.026654385030269623, -0.06690721958875656, 0.0192364864051342, -0.08505751937627792, -0.11623802781105042, 0.06338271498680115, -0.03560594096779823, 0.04595673456788063, 0.03233632072806358, 0.0038657155819237232, -0.21015939116477966, 0.0197017602622509, -0.008721082471311092, 0.1776324361562729, -0.0917968899011612, 0.09790315479040146, -0.198227658867836, 0.04139835014939308, -0.03319070488214493, 0.056444935500621796, -0.06176433712244034, 0.038470666855573654, 0.0882652997970581, 0.0785258412361145, -0.027943480759859085, -0.07637767493724823, -0.06658706068992615, -0.032964061945676804, 0.05289461836218834, -0.08114448189735413, -0.012756354175508022, -0.13915973901748657, -0.11097267270088196, 0.09853639453649521, 0.041098784655332565, 0.037043213844299316, -0.03916332870721817, -0.04918298125267029, 0.04719031974673271, 0.005393530707806349, -0.01619068719446659, -0.0027130732778459787, 0.032734114676713943, 0.02606789954006672, 0.04649649187922478, -0.05333776772022247, -0.025980066508054733, -0.043786339461803436, 0.03468821570277214, -0.008848292753100395, -0.006908170413225889, -0.1351568102836609, 0.02981603518128395, 0.14156177639961243, 0.009839150123298168, -0.058794885873794556, 0.13204094767570496, 0.04583686962723732, -0.036189425736665726, -0.1290581226348877, 0.015119137242436409, -0.13408182561397552, -0.0697711929678917, -0.044855400919914246, -0.05984634533524513, -0.00599287822842598, -0.01994958706200123, -0.005069132428616285, -0.03116103634238243, 0.032417427748441696, -0.04159216582775116, 0.05787048116326332, -0.12528710067272186, 0.06629469990730286, 0.05827794596552849, -0.07380805164575577, 0.0044098058715462685, 0.09720095247030258, -0.08443819731473923, 0.05449840798974037, 0.08563468605279922, 0.11103662848472595, 0.03960436210036278, 0.038560084998607635, -0.02576126530766487, 0.08353415131568909, -0.05150729417800903, 0.21369822323322296, 0.017475303262472153, -1.0006066020196158e-07, 0.006374534219503403, 0.03654169663786888, -0.03863726183772087, -0.025359556078910828, 0.06914834678173065, 0.020793408155441284, 0.05305216833949089, 0.033527303487062454, -0.03639224171638489, 0.15885111689567566, 0.07323412597179413, 0.12520989775657654, 0.03373709321022034, 0.004860483575612307, 0.02203754335641861, 0.046928633004426956, 0.07291742414236069, -0.10773660242557526, -0.01684817671775818, 0.09337182343006134, 0.12269232422113419, -0.04275636002421379, -0.1006709635257721, -0.056606557220220566, 0.017017990350723267, -0.12215812504291534, 0.016962656751275063, 0.1966903656721115, 0.1032550260424614, 0.0029941725078970194, -0.07604999840259552, 0.01692602038383484, -0.0502101369202137, -0.021646104753017426, 0.04041507467627525, 0.04819588363170624, 0.00995125062763691, -0.092367984354496, -0.05485765263438225, -0.07594000548124313, -0.028894096612930298, -0.0924425721168518, -0.0014373424928635359, -0.07302238047122955, -0.04886782169342041, -0.008641369640827179, -0.021953977644443512, -0.008047794923186302, 0.007935257628560066, 0.16132760047912598, -0.15028345584869385, 0.07568535953760147, -0.043347787111997604, 0.06117366626858711, 0.08434053510427475, 0.0663556158542633, -0.06783449649810791, -0.07102807611227036, -0.010674817487597466, -0.025467952713370323, 0.0023927243892103434, -0.03468802943825722, -0.01274978555738926, -0.025791099295020103], metadata={'source': 'AAAMLP-569to.pdf', 'page': 84}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 85 Approaching categorical variables  Many people struggle a lot with the handling of categorical variables, and thus this deserves a full chapter. In this chapter, I will talk about different types of categorical data and how to approach a problem with categorical variables.  What are categorical variables?  Categorical variables/features are any feature type  can be classified into two major types: • Nominal • Ordinal  Nominal variables are variables that have two or more categories which do not have any kind of order associated with them. For example, if gender is classified into two groups, i.e. male and female, it can be considered as a nominal variable.  Ordinal variables, on the other hand, have “levels” or categories with a particular order associated with them. For example, an ordinal categorical variable can be a feature with three different levels: low, medium and high. Order is important.  As far as definitions are concerned, we can also categorize categorical variables as binary, i.e., a categorical variable with only two categories. Some even talk about a type called “cyclic” for categorical variables. Cyclic variables are present in “cycles” for example, days in a week: Sunday, Monday, Tuesday, Wednesday, Thursday, Friday and Saturday. After Saturday, we have Sunday again. This is a cycle. Another example would be hours in a day if we consider them to be categories.  There are many different definitions of categorical variables, and many people talk about handling categorical variables differently depending on the type of categorical variable. However, I do not see any need for it. All problems with categorical variables can be approached in the same way.  Before we start, we need a dataset to work with (as always). One of the best free datasets to understand categorical variables is cat-in-the-dat from Categorical Features Encoding Challenge from Kaggle. There were two challenges, and we will be using the data from the second challenge as it had more variables and was more difficult than its previous version.'),\n",
       " VectorParams(vector=[-0.028628209605813026, -0.02805643528699875, -0.0428309328854084, -0.0415973924100399, 0.13145701587200165, 0.030113233253359795, -0.003994989208877087, 0.03407803922891617, -0.11639998853206635, -0.027687976136803627, 0.00044133677147328854, -0.15513302385807037, -0.016354283317923546, 0.021010741591453552, -0.004589518532156944, -0.024057537317276, 0.04639899358153343, -0.01996891386806965, -0.01626151241362095, 0.13157325983047485, 0.06878267973661423, 0.04074254631996155, 0.05204048752784729, 0.09692659974098206, -0.06184693053364754, -0.024922823533415794, 0.0039147259667515755, 0.020034953951835632, -0.12478788942098618, -0.10354787856340408, 0.00531134195625782, 0.009100467897951603, -0.08938080817461014, 0.02603609301149845, -0.06957275420427322, 0.012679158709943295, 0.02822115458548069, 0.057332709431648254, 0.04338547959923744, -0.08801804482936859, 0.010745871812105179, -0.0198956448584795, 0.05662064626812935, -0.010464344173669815, 0.10075702518224716, 0.0973953902721405, -0.00704193115234375, 0.021420445293188095, -0.08083420246839523, -0.01727914996445179, -0.10005665570497513, -0.040821708738803864, -0.028869058936834335, 0.09115582704544067, -0.11087549477815628, 0.003280964447185397, -0.03564296290278435, -0.1159694641828537, 0.0718199834227562, -0.022989826276898384, -0.03844332695007324, -0.10776735842227936, -0.07146532088518143, 0.015325827524065971, 0.05530005320906639, -0.12071946263313293, -0.04207229241728783, 0.00048574956599622965, -0.011570033617317677, 0.05346078798174858, 0.06205941364169121, 0.00679636187851429, -0.11700307577848434, 0.05516715720295906, 0.07402945309877396, 0.008867012336850166, 0.028725452721118927, -0.009837653487920761, 0.04274662584066391, -0.09105344861745834, 0.005392496939748526, 0.056627433747053146, -0.009619740769267082, 0.0338386595249176, 0.14690856635570526, -0.03153103217482567, 0.05465688183903694, 0.02161332778632641, -0.11535196751356125, 0.05019014701247215, 0.0735129714012146, -0.0027510663494467735, 0.20804241299629211, -0.034584082663059235, 0.09055069088935852, 0.07827702909708023, 0.09348747134208679, -0.05994213744997978, 0.0547141470015049, 0.13812214136123657, 0.005168781150132418, 0.07785720378160477, -0.061959151178598404, -0.09169614315032959, 0.0550859309732914, -0.08217661082744598, 0.04925817623734474, 0.041546523571014404, 0.09236616641283035, -0.09579001367092133, 0.07356356829404831, -0.03163821995258331, -0.16356226801872253, -0.043490368872880936, 0.02047356590628624, 0.003523861290886998, -0.0015962754841893911, 0.1306135654449463, -0.03466123715043068, 0.012970075011253357, -0.11123014986515045, 0.011562822386622429, 0.028705401346087456, 0.09431798756122589, 0.05370061844587326, -0.056655071675777435, -0.11119277030229568, 5.2631569370037716e-33, -0.03762566298246384, -0.06388116627931595, -0.05969728156924248, -0.11988220363855362, 0.02755521796643734, -0.06821434199810028, -0.09807681292295456, 0.0794122964143753, 0.09590532630681992, 0.08249425888061523, -0.028392978012561798, 0.03632901981472969, -0.08461464196443558, 0.10542003065347672, 0.07244853675365448, -0.0009513262193650007, -0.028622109442949295, 0.06780529767274857, -0.16088330745697021, 0.0004555378982331604, 0.04628030210733414, 0.02106734737753868, 0.11351407319307327, -0.014507518149912357, 0.07947282493114471, -0.040814682841300964, 0.02088215760886669, -0.02086763083934784, -0.10760114341974258, 0.0630788803100586, -0.0068575674667954445, -0.021304525434970856, -0.03230561316013336, 0.03476151451468468, 0.0026700147427618504, -0.17068998515605927, 0.04677198827266693, 0.03764379397034645, -0.038093358278274536, 0.06020614877343178, -0.01836496964097023, 0.07512234896421432, 0.0988871306180954, -0.00430050166323781, -0.01150017511099577, -0.007598555646836758, 0.11223714053630829, 0.09644854068756104, -0.055672530084848404, 0.029077408835291862, 0.07126915454864502, -0.12650039792060852, -0.09563712030649185, -0.008585563860833645, -0.061689455062150955, 0.029798220843076706, -0.07526989281177521, -0.16117917001247406, -0.07560735940933228, 0.11882411688566208, 0.15313270688056946, -0.044692862778902054, 0.10551481693983078, 0.026993142440915108, 0.009152148850262165, -0.06804042309522629, -0.047486770898103714, -0.040854040533304214, 0.057618241757154465, 0.07774930447340012, -0.0029331673868000507, 0.0163122471421957, 0.05418919771909714, 0.0009064747719094157, 0.12309329956769943, 0.0461261160671711, 0.15856164693832397, -0.019433356821537018, -0.045357201248407364, 0.02883203700184822, 0.029314246028661728, 0.04684290289878845, 0.03364892676472664, -0.09973835200071335, -0.08884972333908081, 0.05401674285531044, 0.031789131462574005, -0.16512024402618408, -0.19389548897743225, 0.03925254940986633, -0.11842722445726395, 0.09240446239709854, -0.07454468309879303, 0.034875962883234024, 0.0037735896185040474, -5.8208647216216364e-33, -0.09289194643497467, 0.039096005260944366, 0.07219622284173965, 0.052657321095466614, -0.020761331543326378, 0.09156560152769089, -0.008007422089576721, 0.0035725655034184456, 0.032456401735544205, -0.02549760602414608, -0.06809432804584503, 0.0659417137503624, 0.04038823023438454, 0.04770832881331444, -0.015258600935339928, -0.011599996127188206, -0.05790599435567856, -0.01918005384504795, -0.026878198608756065, 0.0828867256641388, 0.030980130657553673, 0.12610921263694763, -0.1383730173110962, 0.0704837366938591, -0.075019970536232, 0.11763383448123932, -0.06977042555809021, 0.013792531564831734, 0.016463441774249077, -0.024023719131946564, -0.06481481343507767, 0.019724223762750626, -0.06298793852329254, -0.030151214450597763, 0.0059281932190060616, 0.03600822761654854, 0.007699584122747183, -0.05920511856675148, -0.09084894508123398, 0.11700813472270966, 0.019937340170145035, 0.09005610644817352, -0.27741891145706177, 0.03775770962238312, 0.04872816801071167, -0.0391991063952446, 0.0427829809486866, 0.10752861946821213, 0.13194237649440765, -0.014939386397600174, 0.0194509606808424, -0.02828841283917427, -0.0031223478727042675, 0.09380542486906052, -0.011516006663441658, -0.0053900256752967834, -0.07449965924024582, -0.07614730298519135, 0.015910431742668152, 0.08816021680831909, -0.05567337945103645, 0.03961881250143051, 0.07061862200498581, -0.04006613790988922, 0.01125568151473999, -0.08293676376342773, -0.007969518192112446, -0.00635593943297863, -0.08643849194049835, 0.06216241791844368, -0.020772650837898254, 0.04712938889861107, -0.015627749264240265, -0.09231194853782654, -0.11353634297847748, 0.02976239286363125, 0.03270700201392174, 0.013982166536152363, -0.044034719467163086, 0.01683915965259075, 0.020213868468999863, -0.05229554325342178, -0.050839100033044815, 0.11931474506855011, 0.019644230604171753, 0.15280969440937042, 0.17423021793365479, 0.021060600876808167, 0.07615020126104355, 0.08518937230110168, -0.0734669417142868, 0.11008227616548538, -0.0038886198308318853, 0.11837121099233627, -0.017544882372021675, -9.847499882198463e-08, 0.016413284465670586, 0.026424972340464592, -0.07216490060091019, -0.041744332760572433, 0.021466204896569252, 0.15982438623905182, -0.1872882843017578, 0.10359480232000351, -0.07837000489234924, -0.01654735393822193, 0.030613834038376808, 0.07996317744255066, -0.11268303543329239, 0.04658566415309906, -0.0924520194530487, 0.06983134150505066, 0.04887784272432327, 0.06086798384785652, -0.06839291751384735, 0.04719242826104164, 0.08482611924409866, -0.0009638909832574427, 0.00023742752091493458, -0.11915645003318787, -0.050217561423778534, -0.1418382227420807, -0.006914667319506407, 0.17449070513248444, 0.03394492715597153, 0.046412430703639984, -0.029402023181319237, -0.05652724951505661, -0.03169757500290871, 0.02795700915157795, 0.0467674657702446, 0.04428369551897049, -0.07099027186632156, -0.01262180507183075, -0.055155497044324875, 0.005995581857860088, -0.017184101045131683, 0.012325241230428219, -0.06605441123247147, 0.013453710824251175, -0.07642380893230438, -0.07561615109443665, -0.0077003492042422295, -0.025782855227589607, 0.01401405781507492, 0.06563161313533783, 0.019498305395245552, -0.009056303650140762, -0.09846046566963196, 0.14358173310756683, 0.03877270966768265, 0.059371620416641235, -0.0516815260052681, -0.14773286879062653, -0.06830394268035889, 0.0954204648733139, 0.10225988179445267, -0.13024210929870605, -0.1629224419593811, 0.07859878987073898], metadata={'source': 'AAAMLP-569to.pdf', 'page': 85}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 86 Let’s take a look at the data.  \\n Figure 1: Viewing a subset of the data. Cat-in-the-dat-ii challenge5  The dataset consists of all kinds of categorical variables:  • Nominal • Ordinal • Cyclical • Binary  In Figure 1, we see only a subset of all the variables that are present and the target variable.   It is a binary classification problem.   The target is not very important for us to learn categorical variables, but in the end, we will be building an end-to-end model so let’s take a look at the target distribution in figure 2. We see that the target is skewed and thus the best metric for this binary classification problem would be Area Under the ROC Curve (AUC). We can use precision and recall too, but AUC combines these two metrics. Thus, we will be using AUC to evaluate the model that we build on this dataset.  5 https://www.kaggle.com/c/cat-in-the-dat-ii'),\n",
       " VectorParams(vector=[0.16677077114582062, 0.0035372059792280197, 0.01713406667113304, -0.03213087096810341, -0.01847194693982601, 0.08977537602186203, -0.0073190610855817795, -0.12794989347457886, -0.08877969533205032, -0.05862802639603615, 0.03481456637382507, -0.14057905972003937, 0.09028974175453186, -0.0040778410620987415, 0.15208739042282104, 0.15864990651607513, -0.03554316237568855, 0.11783640086650848, 0.019970493391156197, -0.1477426141500473, 0.12658528983592987, 0.12242372334003448, 0.03986119106411934, 0.06215757504105568, -0.03102380782365799, 0.053405243903398514, -0.027097446843981743, 0.07460018992424011, -0.03580237179994583, 0.032892562448978424, -0.07173993438482285, 0.05555258318781853, -0.05877784267067909, -0.0061556268483400345, 0.06973086297512054, -0.056448794901371, -0.04673678055405617, 0.08942262083292007, -0.09777361154556274, 0.15351419150829315, 0.02883516252040863, -0.01065239030867815, 0.041362352669239044, -0.06712528318166733, 0.16168256103992462, 0.22870329022407532, -0.18820814788341522, 0.0666479840874672, -0.06159928813576698, -0.025571350008249283, -0.014733940362930298, 0.010585972107946873, -0.0741298645734787, 0.0976671352982521, 0.004284744616597891, -0.08751986920833588, -0.11616460978984833, -0.18002164363861084, -0.01071057841181755, -0.034500233829021454, -0.06424131989479065, -0.053549498319625854, 0.06129707396030426, -0.11744073778390884, -0.008406275883316994, -0.013102268800139427, -0.08657781034708023, 0.0797116830945015, 0.013575265184044838, 0.1241772398352623, -0.03255286067724228, 0.11259517818689346, 0.12681953608989716, -0.03418276831507683, 0.04451584070920944, -0.04474630206823349, 0.04276273399591446, -0.09096881747245789, 0.12151225656270981, -0.013182240538299084, -0.0727045014500618, 0.04877055808901787, 0.07066510617733002, 0.17033345997333527, -0.10225953161716461, -0.11533790826797485, 0.05519486218690872, 0.08602875471115112, -0.06414078921079636, 0.09404242038726807, -0.12360532581806183, -0.10752276331186295, 0.3087628185749054, -0.04214001074433327, -0.06505272537469864, 0.12032493203878403, 0.13447682559490204, -0.004118176642805338, 0.14156043529510498, 0.03530585765838623, -0.1069791242480278, -0.06118984892964363, -0.06767483055591583, -0.18463096022605896, -0.1373860388994217, -0.007706340402364731, 0.1630433052778244, 0.0521225742995739, 0.19204646348953247, -0.11759664863348007, 0.039583150297403336, -0.18050436675548553, -0.11714714020490646, -0.06000427529215813, -0.026560984551906586, -0.13336877524852753, -0.10420650988817215, 0.10501102358102798, 0.19997398555278778, -0.10365726053714752, -0.010723453015089035, -0.04649364948272705, 0.03285032883286476, 0.22460484504699707, -0.06689281016588211, 0.13744549453258514, -0.09127490967512131, 6.0637802618770775e-33, 0.006672888528555632, -0.12278556823730469, -0.04251766577363014, 0.04717433080077171, 0.04083682596683502, -0.15620334446430206, -0.03187701478600502, 0.0546250119805336, 0.09365825355052948, 0.13201457262039185, 0.017999213188886642, 0.07921762764453888, -0.13509541749954224, 0.1997208148241043, 0.11915533244609833, -0.19652564823627472, 0.126124307513237, 0.140546053647995, -0.12053146213293076, -0.11499392241239548, -0.042647816240787506, -0.008982032537460327, 0.012331368401646614, -0.01599849946796894, 0.06055150926113129, 0.011286316439509392, -0.15208841860294342, -0.1406383216381073, -0.010600117966532707, -0.04424753040075302, 0.08330991119146347, 0.0021879456471651793, 0.003953482024371624, -0.009786495007574558, 0.07117798179388046, -0.18759602308273315, 0.052282776683568954, 0.1782456785440445, 0.13083437085151672, 0.008690926246345043, 0.02743825688958168, -0.006661950144916773, -0.0035576405934989452, -0.037252966314554214, 0.0018580282339826226, 0.15510138869285583, 0.06437938660383224, 0.06773057579994202, -0.09085910022258759, 0.044401731342077255, -0.05699900537729263, -0.07103009521961212, -0.07411227375268936, 0.11255022883415222, -0.12182497978210449, 0.015121834352612495, -0.033942319452762604, -0.0982249528169632, -0.06649697571992874, 0.06113583222031593, -0.009771294891834259, 0.13743843138217926, 0.230088472366333, -0.017323294654488564, 0.06968545913696289, -0.03908608853816986, 0.06830070167779922, -0.05920690670609474, 0.0918884202837944, 0.06327613443136215, -0.10861024260520935, 0.07219631969928741, -0.11349782347679138, -0.09191378951072693, 0.030780453234910965, -0.009599865414202213, 0.1612839698791504, -0.1293540596961975, -0.2134937345981598, 0.010265166871249676, -0.011684306897222996, -0.0077934241853654385, 0.13865944743156433, -0.15949465334415436, 0.06618897616863251, 0.05489185452461243, -0.1199456974864006, -0.18747632205486298, -0.07063545286655426, -0.043355152010917664, -0.101826973259449, 0.008591140620410442, -0.088233582675457, -0.018457230180501938, -0.009764050133526325, -1.0261486017026821e-32, -0.14160825312137604, 0.03697402402758598, 0.1338355541229248, 0.0022568628191947937, -0.04402121528983116, 0.022485360503196716, -0.051216889172792435, 0.11705946177244186, 0.10256496071815491, -0.00648640189319849, -0.10249786078929901, 0.06955692917108536, 0.009094364941120148, -0.01835218071937561, -0.051942892372608185, 0.007993682287633419, -0.18494831025600433, 0.19166666269302368, 0.023358387872576714, 0.13408517837524414, -0.10308369249105453, 0.1275704950094223, -0.23990888893604279, 0.08870389312505722, -0.0505666509270668, 0.13322879374027252, 0.10051489621400833, -0.12829923629760742, 0.0843580886721611, 0.00031333111110143363, -0.009988340549170971, -0.06299454718828201, 0.0546804703772068, -0.021463317796587944, -0.044933971017599106, -0.07145091891288757, 0.11909722536802292, -0.1732511967420578, -0.2756975591182709, 0.07937775552272797, 0.11749368906021118, -0.024966992437839508, -0.11852661520242691, -0.026169797405600548, 0.0034190001897513866, -0.057309381663799286, 0.040082596242427826, 0.0329660028219223, 0.045157626271247864, -0.010755863972008228, 0.10654959082603455, -0.047038983553647995, -0.09108926355838776, 0.015815917402505875, -0.013893801718950272, -0.031722329556941986, -0.09849583357572556, -0.11480382084846497, 0.09774911403656006, -0.12231001257896423, -0.0809512510895729, -0.15841300785541534, 0.13944219052791595, 0.02924300730228424, -0.02877430059015751, 0.010181548073887825, -0.10502628237009048, -0.03502163663506508, -0.19317670166492462, -0.021804697811603546, 0.054335951805114746, 0.08778979629278183, -0.03131082281470299, -0.06143730878829956, -0.2069815844297409, -0.1500450074672699, -0.07093674689531326, -0.03699089214205742, -0.11782333254814148, 0.08564458787441254, -0.001975467661395669, -0.059219956398010254, -0.012266736477613449, 0.2037530094385147, -0.04273991286754608, 0.05000041052699089, 0.3435457646846771, 0.045060135424137115, -0.0403389111161232, 0.16810643672943115, -0.006243811454623938, -0.03759780153632164, 0.054852455854415894, 0.25293827056884766, -0.05492188408970833, -1.0027244456978224e-07, -0.0892362892627716, -0.09598342329263687, -0.0911330059170723, -0.017063982784748077, 0.08454994857311249, 0.06530828028917313, -0.08407887071371078, 0.13040325045585632, -0.1376020312309265, 0.019589506089687347, 0.0014763380168005824, 0.10836885869503021, -0.06236575171351433, 0.08789002150297165, -0.06343488395214081, 0.09838712215423584, 0.17312785983085632, 0.061550382524728775, 0.028966236859560013, 0.025081103667616844, 0.10039260238409042, -0.031085524708032608, 0.001950820442289114, 0.014341606758534908, 0.04645664617419243, -0.16554316878318787, 0.008703340776264668, 0.11108925938606262, 0.23034019768238068, 0.019724348559975624, -0.07062818855047226, -0.08344394713640213, -0.1366700828075409, -0.03422822803258896, 0.12428449839353561, 0.0614057220518589, -0.1882762610912323, -0.12075889855623245, -0.0625639259815216, -0.13861072063446045, -0.15618805587291718, 0.018426325172185898, -0.04395256191492081, 0.05510454624891281, -0.018972888588905334, -0.11219073832035065, -0.04573961719870567, -0.08051704615354538, 0.027655087411403656, -0.0010280823335051537, -0.057729676365852356, 0.012759127654135227, 0.039697322994470596, -0.06309984624385834, -0.02608036994934082, 0.06280571222305298, -0.08230473846197128, -0.03386218845844269, -0.005721915513277054, 0.03533156216144562, 0.07816869765520096, -0.002699953271076083, 0.022557063028216362, -0.0630606934428215], metadata={'source': 'AAAMLP-569to.pdf', 'page': 86}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 87  Figure 2: Count of targets. the x-axis shows the label, and the y-axis shows the count of the label  Overall, there are: • Five binary variables • Ten nominal variables • Six ordinal variables • Two cyclic variables • And a target variable  Let’s look at ord_2 feature in the dataset. It consists of six different categories: • Freezing • Warm • Cold • Boiling Hot • Hot • Lava Hot  We have to know that computers do not understand text data and thus, we need to convert these categories to numbers. A simple way of doing this would be to create a dictionary that maps these values to numbers starting from 0 to N-1, where N is the total number of categories in a given feature.'),\n",
       " VectorParams(vector=[0.06790909916162491, -0.059713371098041534, 0.05704528093338013, 0.07055409252643585, 0.002648119581863284, -0.03589089214801788, -0.05645604431629181, -0.1088499128818512, -0.028783563524484634, -0.05511746555566788, 0.09739355742931366, -0.19819346070289612, 0.015032459981739521, -0.13051985204219818, 0.07731451094150543, 0.032685622572898865, -0.09989671409130096, 0.010848878882825375, 0.0134274922311306, -0.18706832826137543, -0.012320414185523987, 0.1351231336593628, -0.03265133872628212, -0.004962810315191746, -0.018102070316672325, 0.06458793580532074, -0.03564955294132233, 0.16781122982501984, -0.12004561722278595, 0.03164731338620186, -0.12083961814641953, -0.030694765970110893, -0.0825381800532341, -0.017157353460788727, 0.0072386497631669044, -0.07588538527488708, -0.0777939185500145, 0.004768318496644497, -0.11075318604707718, 0.18234865367412567, 0.04693242534995079, -0.10794299840927124, 0.1444946825504303, -0.007641952950507402, 0.0636405497789383, 0.09736502915620804, -0.06171666458249092, -0.02424638904631138, -0.05283495783805847, -0.10892532765865326, 0.017077643424272537, 0.19509975612163544, -0.18350553512573242, 0.14009298384189606, -0.06491918861865997, -0.17835338413715363, 0.0032242550514638424, -0.2375318855047226, 0.055126164108514786, -0.013513577170670033, -0.1901133507490158, 0.06662952899932861, 0.10364381968975067, -0.07095734030008316, 0.018006855621933937, 0.00011033314513042569, -0.05934794247150421, 0.12456464767456055, 0.00699436804279685, 0.09427487105131149, 0.09597260504961014, 0.16780498623847961, 0.007168719545006752, -0.07019748538732529, 0.014238651841878891, -0.07319454848766327, 0.04436027258634567, -0.09373972564935684, 0.039841800928115845, -0.08925417810678482, -0.09924253076314926, -0.06147850677371025, -0.01803833246231079, 0.06069300323724747, -0.15699902176856995, -0.1324637532234192, 0.10895189642906189, 0.07662420719861984, 0.0317557118833065, -0.0629018247127533, 0.09970579296350479, -0.04407179728150368, 0.12635983526706696, 0.017239529639482498, 0.027752133086323738, 0.16232597827911377, 0.13606417179107666, 0.02277621254324913, 0.0028586036060005426, -0.02870350144803524, -0.07868470996618271, -0.11712583154439926, -0.15579615533351898, -0.10745664685964584, -0.02695600688457489, -0.014005335979163647, 0.19849984347820282, 0.06352721899747849, 0.18143771588802338, 0.0055420841090381145, -0.00034496778971515596, -0.15439070761203766, 0.0007173074991442263, 0.01966078020632267, -0.08038438856601715, -0.05380246415734291, -0.006652818992733955, 0.024180827662348747, 0.036514777690172195, 0.040490396320819855, -0.04675290733575821, 0.002479411428794265, 0.06805307418107986, 0.15119415521621704, -0.0910462737083435, -0.04506446421146393, -0.08905027061700821, 8.906206417401988e-33, -0.07847148180007935, -0.08145752549171448, 0.04124708101153374, -0.03299548104405403, 0.08381468802690506, -0.1128019392490387, -0.09066136181354523, -0.03644010052084923, 0.061354417353868484, 0.14576378464698792, -0.12803404033184052, 0.09421217441558838, -0.16189609467983246, 0.06229280307888985, 0.02187843807041645, -0.12804485857486725, 0.061689283698797226, -0.10451910644769669, -0.19323638081550598, -0.019937388598918915, 0.06777919083833694, 0.017257921397686005, 0.08556438237428665, 0.019089223816990852, -0.011471295729279518, 0.06312490254640579, -0.07907715439796448, -0.0011297590099275112, -0.12238729000091553, -0.018875690177083015, 0.05164668709039688, -0.06339096277952194, -0.05669984593987465, -0.026399556547403336, 0.0475287064909935, -0.1279088854789734, 0.1566048562526703, 0.11218268424272537, -0.004630676470696926, -0.017306851223111153, -0.0406138151884079, -0.0452667661011219, 0.009568982757627964, 0.08009808510541916, 0.016060682013630867, 0.09774833917617798, 0.05718406289815903, 0.16454501450061798, -0.10886027663946152, 0.05978064239025116, -0.02399762161076069, -0.06779365241527557, 0.017993666231632233, 0.1649644374847412, -0.13972845673561096, -0.012614907696843147, 0.008076208643615246, -0.08036243170499802, -0.023593317717313766, 0.040684569627046585, -0.0361192487180233, 0.04499449580907822, 0.15118151903152466, -0.027624458074569702, -0.006101038306951523, -0.033609408885240555, 0.12278507649898529, 0.08986014127731323, 0.01967284083366394, -0.01742522604763508, 0.007622824050486088, -0.019266903400421143, -0.005058225244283676, -0.10604286193847656, 0.04991276562213898, -0.026736078783869743, 0.08556748926639557, -0.08295807242393494, -0.1919272243976593, 0.09275348484516144, 0.016813237220048904, -0.08811493963003159, 0.05998542159795761, -0.11163236200809479, -0.04449227452278137, -0.02192206121981144, -0.05826716125011444, 0.022054573521018028, -0.1079690232872963, -0.025240669026970863, -0.1954946517944336, 0.10875032097101212, 0.037469178438186646, -0.09349893033504486, 0.018557535484433174, -1.3000281325267207e-32, -0.17600207030773163, -0.07760190218687057, 0.05265737324953079, 0.058389004319906235, 0.0727744773030281, -0.05842731148004532, 0.0036636081058532, 0.12305514514446259, 0.15488804876804352, 0.040039319545030594, -0.055643316358327866, -0.04346423223614693, 0.020096780732274055, -0.17316238582134247, 0.07571210712194443, 0.0834508016705513, -0.15565718710422516, 0.23434633016586304, 0.013160908594727516, 0.1103358194231987, -0.14498011767864227, 0.2127762883901596, -0.2590743899345398, 0.12866835296154022, -0.129975363612175, 0.12414100766181946, 0.06524007022380829, -0.09335433691740036, -0.04362449049949646, -0.03042025677859783, -0.04707440733909607, 0.03408198803663254, 0.013402479700744152, 0.08012634515762329, -0.08698780089616776, -0.0031087808310985565, 0.20694488286972046, -0.12558910250663757, -0.3034411072731018, 0.06444106251001358, 0.12230123579502106, 0.09617362171411514, -0.1679634153842926, 0.03761241212487221, 0.031919632107019424, 0.08268178999423981, 0.11061333864927292, -0.0026988997124135494, 0.047617241740226746, 0.03688088059425354, 0.13522709906101227, -0.00900152325630188, -0.11794788390398026, 0.18415461480617523, 0.055251967161893845, 0.0070105865597724915, -0.11056969314813614, -0.07665973901748657, -0.2137698084115982, -0.14094436168670654, -0.03582870587706566, -0.1067647784948349, 0.034269966185092926, 0.08785370737314224, -0.014786414802074432, 0.049205292016267776, -0.0937504768371582, -0.09936069697141647, 0.007948984391987324, -0.10912350565195084, 0.0021963573526591063, -0.04877116158604622, 0.00035131932236254215, -0.15353183448314667, -0.10976783186197281, -0.03598823770880699, -0.09673430770635605, 0.022883890196681023, -0.02829248644411564, 0.07654765248298645, -0.11067499965429306, -0.0734655112028122, 0.0192287415266037, 0.2309771478176117, -0.06053374707698822, -0.009106988087296486, 0.21811749041080475, -0.010307651944458485, -0.03792668879032135, 0.02477828785777092, 0.05032551288604736, -0.03390789031982422, 0.002159117255359888, 0.16822440922260284, -0.0727890133857727, -1.004942333793224e-07, 0.05235699936747551, -0.08574140816926956, -0.0032547293230891228, 0.018404116854071617, 0.015391174703836441, 0.009995358064770699, -0.1447608917951584, 0.1357043981552124, -0.04106280580163002, 0.1426495909690857, 0.01988677680492401, 0.13559091091156006, 0.014397562481462955, 0.02680368535220623, 0.0016047541284933686, 0.11193466186523438, 0.21869082748889923, 0.07687906175851822, 0.008932284079492092, 0.004071403760462999, 0.11656787246465683, 0.003744871588423848, 0.05221330374479294, -0.011169028468430042, 0.043621357530355453, -0.05448504164814949, 0.015308183617889881, -0.02243100106716156, 0.09782218933105469, 0.02433099038898945, -0.07875298708677292, -0.20992200076580048, -0.07012493163347244, 0.017562178894877434, 0.166399285197258, 0.052078038454055786, -0.0462370328605175, -0.07385549694299698, 0.03205077722668648, -0.05970609188079834, -0.1532260775566101, 0.1211879700422287, -0.08202137798070908, 0.020203527063131332, 0.0620492585003376, -0.04885195195674896, -0.0657930001616478, 0.025663437321782112, 0.21398049592971802, 0.1041334792971611, -0.06905774772167206, 0.042955223470926285, 0.036203596740961075, -0.04066359996795654, 0.042443789541721344, -0.017892397940158844, -0.05008668452501297, 0.12652157247066498, -0.06270095705986023, -0.02707536704838276, 0.20146746933460236, -0.07439731806516647, -0.006559011992067099, -0.11058183759450912], metadata={'source': 'AAAMLP-569to.pdf', 'page': 87}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 88 ═════════════════════════════════════════════════════════════════════════ mapping = {     \"Freezing\": 0,     \"Warm\": 1,     \"Cold\": 2,     \"Boiling Hot\": 3,     \"Hot\": 4,     \"Lava Hot\": 5   } ═════════════════════════════════════════════════════════════════════════  Now, we can read the dataset and convert these categories to numbers easily.   ═════════════════════════════════════════════════════════════════════════ import pandas as pd  df = pd.read_csv(\"../input/cat_train.csv\")  df.loc[:, \"ord_2\"] = df.ord_2.map(mapping) ═════════════════════════════════════════════════════════════════════════  Value counts before mapping:  ═════════════════════════════════════════════════════════════════════════ df.ord_2.value_counts()  Freezing       142726 Warm           124239 Cold            97822 Boiling Hot     84790 Hot             67508 Lava Hot        64840 Name: ord_2, dtype: int64 ═════════════════════════════════════════════════════════════════════════  Value counts after mapping:  ═════════════════════════════════════════════════════════════════════════ 0.0    142726 1.0    124239 2.0     97822 3.0     84790 4.0     67508 5.0     64840 Name: ord_2, dtype: int64 ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[-0.1030101627111435, -0.08275070786476135, -0.04665715619921684, -0.026609182357788086, 0.16698522865772247, -0.09218208491802216, -0.01298494078218937, -0.10603022575378418, -0.005295862443745136, -0.01767275668680668, 0.10162175446748734, -0.14025478065013885, -0.02059587463736534, -0.12486125528812408, 0.14226990938186646, 0.13228055834770203, -0.04841029271483421, 0.18819676339626312, -0.14969299733638763, -0.09105926752090454, 0.14782777428627014, 0.1298830658197403, -0.05107554420828819, 0.169869065284729, -0.09246055036783218, 0.029255354776978493, 0.027144206687808037, 0.16020911931991577, -0.045204684138298035, -0.05416799336671829, -0.05318385362625122, 0.1090676337480545, -0.07679429650306702, 0.0892164558172226, -0.14184163510799408, -0.008639223873615265, 0.009156782180070877, 0.01857094094157219, -0.17932559549808502, 0.07958181947469711, -0.04687604308128357, 0.040576621890068054, 0.025570150464773178, -0.06139719486236572, 0.028913965448737144, 0.09664814919233322, -0.04645455256104469, -0.1526065468788147, -0.01957671158015728, -0.15280094742774963, 0.06638796627521515, 0.09829869866371155, -0.14646373689174652, 0.06893311440944672, -0.015012598596513271, -0.13264590501785278, 0.028888937085866928, -0.14804275333881378, 0.04210280999541283, 0.1548856496810913, -0.1787717193365097, 0.05012936890125275, 0.08283581584692001, -0.023503074422478676, -0.03255826607346535, -0.009576364420354366, -0.10041532665491104, -0.045075200498104095, -0.12112690508365631, 0.01874895766377449, 0.003123000031337142, -0.0342554971575737, -0.15706096589565277, 0.04842839762568474, -0.07129909098148346, -0.012843533419072628, 0.346711128950119, 0.06148276478052139, 0.23031273484230042, -0.026190102100372314, -0.23914532363414764, 0.10568313300609589, 0.05542007088661194, 0.04380737617611885, 0.03510589525103569, -0.113933265209198, -0.04415455833077431, 0.14926347136497498, -0.018517401069402695, 0.0864875465631485, 0.007491040509194136, -0.050425104796886444, 0.0726315900683403, -0.0013653006171807647, 0.024110544472932816, 0.06690894812345505, 0.09864812344312668, 0.04961959645152092, 0.10115478187799454, 0.056224286556243896, -0.07221109420061111, -0.02017880789935589, -0.03202527388930321, -0.15943457186222076, -0.016736185178160667, -0.023604702204465866, 0.13744567334651947, 0.08693405985832214, 0.21367256343364716, -0.027865849435329437, 0.06654759496450424, -0.13053129613399506, -0.09402558207511902, 0.03483293205499649, -0.10321520268917084, 0.020540766417980194, -0.08388707041740417, -0.021551698446273804, -0.0047231679782271385, 0.04744211211800575, -0.1435530185699463, -0.017805837094783783, -0.09415988624095917, 0.08707694709300995, -0.017818259075284004, -0.10987700521945953, -0.10964945703744888, 1.2162104629304976e-32, -0.07645829021930695, -0.06384114176034927, -0.029616758227348328, -0.09326813369989395, 0.027877474203705788, 0.043334778398275375, -0.06518189609050751, 0.01958887092769146, 0.10430032759904861, 0.020481469109654427, -0.17382074892520905, 0.07747825980186462, -0.20046377182006836, 0.02626706287264824, 0.006414782255887985, -0.07099892944097519, -0.046500857919454575, -0.08925475180149078, -0.1177988052368164, 0.014402545057237148, 0.26892223954200745, 0.09776987880468369, 0.017441842705011368, -0.01625775545835495, 0.1265065222978592, -0.07939647883176804, -0.1073090061545372, -0.16116386651992798, -0.012226352468132973, -0.011774837039411068, -0.14353957772254944, -0.16377480328083038, 0.12361013889312744, -0.12148965895175934, -0.003357047913596034, -0.1833823323249817, 0.20975248515605927, 0.09364455193281174, -0.08888523280620575, -0.11578056961297989, 0.011621478945016861, 0.11757022887468338, 0.015821538865566254, -0.02896737866103649, -0.0022221801336854696, 0.1014331504702568, 0.18206487596035004, 0.1456705629825592, -0.08707502484321594, 0.09227828681468964, -0.003813195275142789, -0.09573253244161606, -0.020363343879580498, 0.04207577556371689, -0.16635166108608246, 0.09112583845853806, 0.083106629550457, -0.20586630702018738, -0.03737220540642738, 0.06335928291082382, -0.03202996775507927, 0.0030664149671792984, 0.219981849193573, -0.030555812641978264, 0.07181660830974579, -0.09154658764600754, 0.17431078851222992, 0.014079584740102291, 0.07045933604240417, -0.09333410114049911, -0.09880051016807556, 0.005272906273603439, -0.04945128411054611, -0.14659175276756287, 0.056494735181331635, -0.13678526878356934, 0.012919822707772255, -0.10927855968475342, -0.11405995488166809, 0.041851673275232315, 0.00559191545471549, 0.07241885364055634, 0.03712800145149231, -0.08401685953140259, -0.028024079278111458, 0.012303457595407963, 0.0032098949886858463, -0.06709295511245728, -0.18469107151031494, -0.040249451994895935, -0.05296428129076958, 0.01978984847664833, 0.013106618076562881, -0.16694779694080353, 0.07829512655735016, -1.4232716622443326e-32, -0.16907022893428802, -0.08778730779886246, 0.017686733976006508, 0.05287313461303711, 0.027346530929207802, 0.0769575983285904, 0.05492782220244408, -0.02145848236978054, 0.031601086258888245, -0.20077697932720184, -0.058705467730760574, -0.023596176877617836, 0.08458344638347626, -0.07084792852401733, 0.07382261753082275, 0.007965832017362118, -0.2631304860115051, 0.2779120206832886, -0.09636659175157547, 0.16143293678760529, -0.02641146630048752, 0.27690285444259644, -0.21458961069583893, 0.04234214872121811, 0.05758298933506012, 0.05739084631204605, 0.010895744897425175, 0.15166471898555756, 0.03619100898504257, 0.04836299270391464, -0.12563294172286987, -0.008576104417443275, -0.1144006997346878, -0.0026853338349610567, -0.003673114348202944, -0.10895717144012451, 0.15308110415935516, -0.1339857280254364, -0.23750513792037964, 0.06272701919078827, 0.029520362615585327, 0.2162991315126419, -0.2614443600177765, 0.13290676474571228, -0.11106611788272858, 0.12720587849617004, -0.0708814263343811, -0.01396108791232109, 0.04765491187572479, -0.03549615666270256, 0.1134694293141365, -0.02570149675011635, -0.07045688480138779, 0.1519438475370407, -0.07842527329921722, 0.03084045834839344, -0.1977490782737732, -0.009154703468084335, -0.11886772513389587, -0.01413773838430643, -0.10422562807798386, -0.05077508091926575, 0.08219156414270401, -0.0885625034570694, 0.035197366029024124, -0.015606550499796867, -0.042586833238601685, -0.04030909389257431, 0.008612202480435371, -0.184855118393898, 0.0006875082035548985, -0.03138188272714615, 0.01202165987342596, 0.07750479131937027, -0.08321698009967804, 0.07003231346607208, 0.020401034504175186, -0.06344540417194366, -0.12135615199804306, 0.14728249609470367, -0.05067139118909836, -0.0352962464094162, 0.06478312611579895, 0.31211161613464355, 0.004467890132218599, 0.10742734372615814, 0.19602441787719727, 0.16560502350330353, -0.004990673623979092, -0.07923422008752823, 0.04869111627340317, 0.11323992908000946, 0.040210675448179245, 0.31675446033477783, -0.07166532427072525, -9.96281883658412e-08, -0.12710040807724, -0.05756844952702522, -0.0387200191617012, -0.08288092911243439, -0.010250234045088291, -0.023259088397026062, -0.006438310723751783, 0.11336494237184525, -0.007127593737095594, 0.04671492800116539, 0.11835795640945435, 0.13749872148036957, -0.17872972786426544, -0.023388678207993507, 0.08471465855836868, 0.17981615662574768, 0.16718845069408417, 0.01608407124876976, 0.07608593255281448, 0.18189823627471924, 0.06907709687948227, -0.10372085124254227, -0.14882640540599823, 0.0029341974295675755, -0.03779517486691475, -0.2074568122625351, -0.05608025938272476, 0.18922482430934906, 0.20155766606330872, 0.08767342567443848, -0.003256838768720627, -0.09959874302148819, 0.08068238943815231, 0.03181935474276543, 0.15209676325321198, 0.014673927798867226, 0.04211971163749695, -0.07002221047878265, -0.01936432160437107, 0.07841140776872635, -0.04753204807639122, -0.0045434474013745785, -0.08249008655548096, -0.08462110906839371, 0.05424194782972336, 0.04778926447033882, 0.04099462926387787, 0.049199678003787994, 0.10767441242933273, 0.09577018767595291, -0.003181753447279334, -0.011533861048519611, -0.0403725765645504, -0.03484873101115227, 0.05728819966316223, -0.07127656787633896, -0.08822643011808395, -0.02170620672404766, 0.009543199092149734, 0.0409068763256073, 0.12460943311452866, 0.0005155974067747593, 0.0663112998008728, 0.053859610110521317], metadata={'source': 'AAAMLP-569to.pdf', 'page': 88}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 89 This type of encoding of categorical variables is known as Label Encoding, i.e., we are encoding every category as a numerical label. We can do the same by using LabelEncoder from scikit-learn. ═════════════════════════════════════════════════════════════════════════ import pandas as pd from sklearn import preprocessing  # read the data df = pd.read_csv(\"../input/cat_train.csv\")  # fill NaN values in ord_2 column df.loc[:, \"ord_2\"] = df.ord_2.fillna(\"NONE\")  # initialize LabelEncoder lbl_enc = preprocessing.LabelEncoder()  # fit label encoder and transform values on ord_2 column # P.S: do not use this directly. fit first, then transform df.loc[:, \"ord_2\"] = lbl_enc.fit_transform(df.ord_2.values) ═════════════════════════════════════════════════════════════════════════  You will see that I use fillna from pandas. The reason is LabelEncoder from scikit-learn does not handle NaN values, and ord_2 column has NaN values in it.  We can use this directly in many tree-based models: • Decision trees • Random forest • Extra Trees • Or any kind of boosted trees model o XGBoost o GBM o LightGBM This type of encoding cannot be used in linear models, support vector machines or neural networks as they expect data to be normalized (or standardized).  For these types of models, we can binarize the data.'),\n",
       " VectorParams(vector=[0.06212889775633812, -0.018495716154575348, -0.03227574750781059, 0.06614542007446289, 0.09271273016929626, -0.012084366753697395, -0.036010827869176865, -0.1373274028301239, -0.0646105408668518, -0.0067847189493477345, -0.04947800561785698, -0.13273778557777405, 0.08893238008022308, 0.014763256534934044, 0.0952264815568924, 0.11563257873058319, 0.0057975491508841515, 0.04215748608112335, -0.054731011390686035, -0.06043943762779236, 0.1209828108549118, 0.012875479646027088, -0.12671083211898804, 0.04084204137325287, 0.026761146262288094, 0.07825013250112534, 0.07954871654510498, 0.0408891998231411, -0.034452710300683975, -0.005616381298750639, -0.000659325101878494, 0.05691343918442726, -0.04217015951871872, -0.10440070927143097, 0.10268857330083847, 0.08155981451272964, -0.09115805476903915, 0.04607051610946655, -0.19930388033390045, 0.08355255424976349, 0.014792242087423801, -0.03455235809087753, -0.0077803656458854675, 0.014446820132434368, 0.1180998906493187, 0.12052924931049347, 0.03948357701301575, 0.011135619133710861, 0.04267902299761772, -0.1677575409412384, 0.025403663516044617, 0.11664973944425583, -0.09152743220329285, 0.13627290725708008, -0.01144163217395544, -0.21412205696105957, -0.07318633794784546, -0.08096123486757278, -0.04148472100496292, -0.012059668079018593, -0.06998659670352936, 0.03296079859137535, 0.04209926724433899, -0.029683807864785194, 0.09879538416862488, 0.02095988765358925, -0.057865310460329056, 0.027027972042560577, 0.03652412071824074, 0.06305350363254547, -0.0320875383913517, 0.0426863394677639, -0.10436466336250305, 0.004496110137552023, 0.01989520713686943, 0.0059487055987119675, 0.21463723480701447, -0.07348128408193588, 0.032630596309900284, 0.0639612227678299, -0.06276960670948029, 0.006360858678817749, 0.07117778807878494, -0.010411999188363552, -0.08647037297487259, -0.1748507171869278, 0.022531133145093918, 0.006115900818258524, -0.016066426411271095, 0.055745527148246765, -0.00685890531167388, 0.001819426310248673, 0.1385728120803833, -0.07108480483293533, 0.0655592530965805, 0.07834001630544662, 0.15036725997924805, 0.029719358310103416, 0.06645654141902924, 0.09237873554229736, -0.03672396391630173, -0.08017323911190033, -0.03320565074682236, 0.06882280111312866, -0.0016360657755285501, -0.06302964687347412, 0.11110978573560715, 0.07540101557970047, 0.049967698752880096, -0.029436370357871056, -0.013469603843986988, -0.06890198588371277, -0.14614754915237427, -0.021479547023773193, -0.037200234830379486, -0.08084562420845032, -0.07869605720043182, 0.04616864398121834, 0.08565232157707214, 0.0930624008178711, -0.00685116508975625, -0.016689470037817955, 0.045850738883018494, 0.12018511444330215, 0.044043198227882385, -0.05948975309729576, -0.05729132518172264, 6.662330230372278e-33, 0.04721520096063614, -0.0015996081056073308, -0.10066919028759003, -0.04920436814427376, 0.04547740891575813, 0.0031504437793046236, -0.03429178148508072, 0.032232578843832016, 0.03462227061390877, 0.1709512621164322, -0.08561637252569199, 0.1239701583981514, -0.02304375357925892, 0.10137888044118881, -0.0170348659157753, -0.07360868155956268, -0.05711454153060913, 0.09872754663228989, -0.05948882922530174, -0.04375658184289932, -0.06266331672668457, 0.06569346785545349, 0.03770015761256218, 0.035312410444021225, -0.054071418941020966, -0.09940662235021591, -0.02121886983513832, -0.09696409106254578, -0.10426481813192368, 0.022769520059227943, -0.10787308216094971, -0.0006898883730173111, 0.017266366630792618, -0.01794266328215599, 0.026092706248164177, -0.030036697164177895, 0.01805516518652439, 0.023840822279453278, 0.05741240084171295, 0.017967965453863144, 0.003923088312149048, -0.029493728652596474, 0.10793031752109528, -0.027020491659641266, -0.021858036518096924, 0.08838701993227005, 0.08416564017534256, 0.11867845803499222, -0.20424018800258636, 0.0279550738632679, 0.04243246093392372, 0.03343484550714493, 0.05522534251213074, 0.08625492453575134, -0.03155037760734558, 0.012704374268651009, 0.04510599747300148, -0.1320476084947586, -0.02832920476794243, 0.03992091491818428, -0.0933353379368782, 0.07930067181587219, 0.061598047614097595, -0.08188477903604507, -0.040628522634506226, 0.012362516485154629, 0.06962781399488449, -0.008996187709271908, 0.12261821329593658, -0.045682553201913834, -0.10510076582431793, 0.13493011891841888, -0.04319817200303078, -0.16102157533168793, 0.03684249147772789, -0.1007877066731453, 0.24847151339054108, -0.1316482126712799, -0.12385746836662292, -0.06928383558988571, -0.057952504605054855, -0.05718611925840378, 0.09702804684638977, -0.0868295207619667, -0.13123109936714172, 0.03661339730024338, -0.007993011735379696, -0.06391782313585281, -0.15847937762737274, -0.1054215207695961, -0.1570146232843399, 0.037703175097703934, 0.033443380147218704, -0.07730550318956375, 0.06277716904878616, -6.594534328372572e-33, -0.07623136788606644, -0.07046357542276382, 0.041867729276418686, 0.0005130809149704874, -0.02592809684574604, 0.018431469798088074, 0.020857224240899086, -0.029780050739645958, 0.022324586287140846, -0.11043942719697952, -0.05708099901676178, -0.00854960735887289, -0.029729723930358887, -0.10824087262153625, -0.08258506655693054, 0.1000271663069725, -0.14596451818943024, 0.010270143859088421, 0.06368092447519302, 0.20198684930801392, -0.07892776280641556, 0.17413941025733948, -0.1759558618068695, 0.038508180528879166, -0.1307300180196762, 0.01997719332575798, -0.010143747553229332, 0.0005529405898414552, 0.09604141116142273, 0.06301192939281464, -0.04334495961666107, -0.06428801268339157, -0.08079484105110168, -0.12221385538578033, 0.01403714157640934, 0.0029489549342542887, 0.05086219683289528, -0.14031822979450226, -0.023446783423423767, 0.03242345154285431, 0.14325746893882751, 0.059378545731306076, -0.18600328266620636, 0.08521206676959991, 0.09082242101430893, 0.07164622098207474, -0.006070976611226797, 0.066435307264328, 0.09119514375925064, 0.05461789295077324, 0.04226640611886978, 0.0029661396984010935, -0.04581483453512192, 0.13773317635059357, 0.03704829141497612, -0.04981590807437897, -0.14609618484973907, -0.06815444678068161, -0.003652517916634679, -0.060838598757982254, -0.09369217604398727, -0.07225615531206131, 0.05215974524617195, 0.06363856792449951, 0.04942747950553894, 0.00805167481303215, 0.00900727603584528, -0.11966049671173096, -0.07310637831687927, 0.04365823417901993, 0.0531373992562294, -0.04609159380197525, -0.006648040376603603, -0.10417390614748001, -0.013009888119995594, -0.036340463906526566, -0.09008520841598511, -0.048539403825998306, -0.044897451996803284, 0.14226408302783966, -0.09253587573766708, 0.12617211043834686, 0.023278046399354935, 0.08690952509641647, 0.04133596271276474, 0.006371015217155218, 0.14393696188926697, 0.08261407166719437, 0.02542048878967762, 0.01895778253674507, 0.022519895806908607, 0.08865082263946533, 0.05941549688577652, 0.15304046869277954, -0.06277576088905334, -9.899393660361966e-08, 0.03335630148649216, 0.0038139410316944122, -0.011918028816580772, -0.019868332892656326, 0.10994099825620651, -0.045938264578580856, -0.053543586283922195, 0.049560341984033585, 0.014124911278486252, 0.04050322249531746, 0.08964427560567856, 0.07395606487989426, -0.09183360636234283, -0.0756416916847229, 0.12414438277482986, 0.20144906640052795, 0.10204282402992249, -0.0867348462343216, -0.04916023090481758, 0.054404981434345245, 0.08457633852958679, -0.005489104427397251, -0.04813298583030701, -0.032134514302015305, 0.08500653505325317, -0.0174050722271204, 0.07996596395969391, 0.07190031558275223, 0.20974649488925934, 0.04823971167206764, -0.12912148237228394, -0.036737002432346344, -0.00042816379573196173, 0.014126489870250225, 0.08426164835691452, 0.08937565237283707, -0.012518199160695076, 0.03134239464998245, -0.03290510177612305, -0.14785443246364594, -0.11881835013628006, -0.022224782034754753, 0.01905035972595215, -0.037328168749809265, -0.0632941871881485, -0.045481421053409576, -0.06525436043739319, 0.054774004966020584, 0.03188636153936386, 0.052628207951784134, -0.09312425553798676, 0.03396071121096611, -0.04801235720515251, 0.08632979542016983, 0.02637770026922226, -0.013781768269836903, -0.07331246137619019, -0.006470899097621441, 0.07261853665113449, 0.008753100410103798, 0.06206103414297104, -0.020458215847611427, -0.12431525439023972, -0.07062584906816483], metadata={'source': 'AAAMLP-569to.pdf', 'page': 89}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 90 ═════════════════════════════════════════════════════════════════════════ Freezing    --> 0 --> 0 0 0 Warm        --> 1 --> 0 0 1 Cold        --> 2 --> 0 1 0 Boiling Hot --> 3 --> 0 1 1 Hot         --> 4 --> 1 0 0 Lava Hot    --> 5 --> 1 0 1 ═════════════════════════════════════════════════════════════════════════  This is just converting the categories to numbers and then converting them to their binary representation. We are thus splitting one feature into three (in this case) features (or columns). If we have more categories, we might end up splitting into a lot more columns.  It becomes easy to store lots of binarized variables like this if we store them in a sparse format. A sparse format is nothing but a representation or way of storing data in memory in which you do not store all the values but only the values that matter. In the case of binary variables described above, all that matters is where we have ones (1s).   It’s difficult to imagine a format like this but should become clear with an example.  Let’s assume that we are provided with only one feature in the dataframe above: ord_2.   Index Feature 0 Warm 1 Hot 2 Lava hot  Currently, we are looking at only three samples in the dataset. Let’s convert this to binary representation where we have three items for each sample.   These three items are the three features.'),\n",
       " VectorParams(vector=[0.08511687815189362, 0.0267249196767807, -0.18494419753551483, 0.020469430834054947, 0.08684197068214417, -0.07168630510568619, -0.0022401721216738224, -0.09813220798969269, -0.1298210322856903, -0.004280484281480312, -0.03762536123394966, -0.00909875612705946, 0.05821238085627556, 0.042048390954732895, -0.12653230130672455, 0.14784008264541626, -0.06222095713019371, 0.017538536339998245, 0.015869878232479095, 0.06749553233385086, 0.07696148008108139, -0.012700694613158703, -0.025564473122358322, 0.011867610737681389, -0.04490775987505913, 0.06957802176475525, 0.1486460417509079, 0.09081482887268066, 0.04009299725294113, -0.06709490716457367, 0.04421579837799072, 0.0919075533747673, 0.06178434193134308, -0.07317671924829483, 0.08706606924533844, 0.08054372668266296, -0.09315796941518784, -0.0252640750259161, -0.1471811681985855, 0.08953792601823807, 0.1172497421503067, 0.03563548997044563, 0.002852980513125658, 0.0474596805870533, 0.11959902197122574, 0.11334524303674698, -0.04324619099497795, 0.004250792320817709, 0.09490129351615906, -0.1611793041229248, -0.06329278647899628, 0.21023447811603546, -0.10121795535087585, 0.11238137632608414, -0.001466963323764503, -0.29132938385009766, -0.06443841010332108, -0.0552491620182991, -0.10605055838823318, 0.008293436840176582, 0.013368617743253708, -0.11748902499675751, 0.12655988335609436, -0.09113644063472748, 0.04692763835191727, 0.03452689200639725, -0.08640353381633759, -0.11745990067720413, -0.030039796605706215, 0.05805547535419464, -0.1073746532201767, 0.12255777418613434, -0.037657350301742554, 0.098953016102314, -0.07020904123783112, -0.04571156948804855, 0.19157783687114716, 0.025700777769088745, 0.14230819046497345, 0.14413174986839294, -0.10336390137672424, -0.01892472244799137, 0.12680839002132416, 0.024148212745785713, -0.020905615761876106, -0.08241499215364456, -0.07573505491018295, 0.0683433786034584, -0.005307635758072138, -0.008337953127920628, -0.028673306107521057, -0.05494523420929909, 0.08620758354663849, -0.1943322718143463, 0.09026063978672028, 0.07874689251184464, 0.09226872771978378, 0.02565637044608593, -0.07424653321504593, 0.06851054728031158, 0.01137511059641838, -0.03898466005921364, 0.08325868844985962, 0.14314931631088257, 0.05458173528313637, 0.1246340423822403, -0.007933305576443672, 0.006319691892713308, 0.04167691245675087, -0.10212336480617523, 0.11233635246753693, -0.03293878212571144, -0.0944136530160904, -0.029207199811935425, 0.10436106473207474, -0.04171711206436157, -0.17193584144115448, 0.08728703111410141, 0.07530461251735687, 0.13935597240924835, 0.04778007045388222, -0.10701930522918701, 0.11173173785209656, 0.11332336068153381, -0.06038269028067589, 0.06090303137898445, -0.13507802784442902, 1.1781553026905645e-32, -0.12326715886592865, 0.04916686564683914, -0.09094931185245514, -0.009574942290782928, -0.03803880885243416, 0.03836863487958908, 0.12465256452560425, 0.06685635447502136, 0.0409451462328434, 0.02648594230413437, -0.09841509163379669, 0.12114225327968597, 0.019788295030593872, 0.13129396736621857, 0.026936570182442665, -0.0037932954728603363, -0.005617580842226744, 0.07048562914133072, 0.0695895403623581, -0.18136955797672272, 0.039332326501607895, -0.016395321115851402, 0.03787033632397652, -0.04052126035094261, -0.0845148116350174, -0.15749257802963257, -0.0686446875333786, -0.19448548555374146, -0.1885434240102768, -0.03331959992647171, -0.13325956463813782, 0.10317421704530716, -0.05520588159561157, -0.05384591221809387, 0.07256954908370972, -0.1552661508321762, 0.019675638526678085, -0.06878092885017395, 0.1265341192483902, -0.14547879993915558, 0.03598600625991821, 0.0532175712287426, 0.0821782723069191, -0.1505277454853058, -0.11540979892015457, -0.021522631868720055, 0.09463601559400558, 0.01954774372279644, -0.10753528028726578, 0.0479782409965992, 0.021449660882353783, -0.019237719476222992, -0.08149095624685287, 0.06266573071479797, -0.026191864162683487, -0.12118475139141083, 0.0379851795732975, -0.08753656595945358, 0.09863727539777756, 0.05880803242325783, -0.0626344382762909, -0.05523184686899185, 0.09178825467824936, 0.04834979400038719, -0.05665380135178566, 0.02686181850731373, 0.12694671750068665, 0.10854426771402359, 0.018835319206118584, -0.04597670957446098, -0.00011212431127205491, 0.05629327893257141, 0.01857059635221958, -0.17990738153457642, -0.0904117152094841, -0.07746325433254242, 0.19715315103530884, -0.1657228320837021, -0.1356407254934311, -0.01334358099848032, 0.15173375606536865, 0.08423016965389252, 0.007568218279629946, -0.06292781978845596, -0.013963384553790092, 0.004221369046717882, 0.09980865567922592, -0.16066238284111023, -0.07615209370851517, -0.15218405425548553, -0.1134532168507576, 0.06653055548667908, 0.03921544551849365, -0.1599808931350708, -0.09802273660898209, -1.2815671406838506e-32, -0.04492662474513054, 0.013802211731672287, -0.054139573127031326, -0.06219245865941048, -0.03721986338496208, -0.09334611892700195, 0.05839960277080536, -0.011484834365546703, 0.02043607085943222, -0.08429646492004395, 0.03713298588991165, -0.016584796831011772, -0.005536350421607494, -0.09028179943561554, 0.04126933962106705, 0.06292513757944107, -0.22990041971206665, 0.06533029675483704, 0.03247674182057381, -0.017370659857988358, -0.17857761681079865, 0.07248753309249878, 0.00425392622128129, 0.12699879705905914, -0.13040386140346527, -0.03281605243682861, -0.0027598903980106115, -0.04251772165298462, 0.0621388740837574, -0.007824109867215157, -0.04908343404531479, -0.09413658827543259, -0.06561249494552612, 0.05169571191072464, 0.12399972975254059, -0.03969210013747215, 0.00893506221473217, -0.1448679268360138, 0.14692777395248413, 0.08062165230512619, 0.11468490958213806, 0.08479166030883789, -0.10246142745018005, 0.1180892363190651, 0.08364053815603256, -0.037370432168245316, 0.001824773964472115, 0.09145690500736237, 0.025165285915136337, -0.06462662667036057, 0.02534431591629982, 0.12698444724082947, -0.0262403916567564, 0.026157893240451813, -0.02799251489341259, 0.11113113909959793, -0.1429987996816635, 0.04133297875523567, 0.09966498613357544, -0.08123333007097244, -0.059793874621391296, -0.09237340092658997, 0.0031056778971105814, 0.007673839572817087, 0.018820013850927353, 0.058171406388282776, -0.0832049772143364, 0.03910505026578903, -0.21735799312591553, 0.12025287747383118, -0.045231517404317856, -0.05253082141280174, -0.040949366986751556, -0.13039667904376984, -0.12194022536277771, 0.0026979041285812855, -0.08942767232656479, -0.08503399044275284, -0.025226963683962822, 0.06216101720929146, -0.13556323945522308, 0.10371831059455872, 0.04068426787853241, 0.036381520330905914, 0.07722026854753494, 0.001993576530367136, 0.18988212943077087, 0.001545793958939612, -0.0037509924732148647, -0.07522455602884293, 0.06899762153625488, 0.16589201986789703, -0.019000353291630745, 0.1493370085954666, -0.009242929518222809, -1.0005543060742639e-07, -0.09998741000890732, -0.006269567180424929, 0.06417515128850937, -0.06156069040298462, 0.09556500613689423, -0.13153019547462463, 0.03048090450465679, 0.062448885291814804, 0.019206225872039795, 0.031240375712513924, 0.1729859560728073, -0.05049194023013115, -0.2086762636899948, -0.003307174891233444, 0.11066557466983795, 0.164779931306839, 0.0252681877464056, -0.11086591333150864, -0.007806079462170601, -0.03008720837533474, 0.1034080907702446, -0.029613841325044632, -0.007624675519764423, -0.007760089822113514, -0.12280706316232681, -0.18967372179031372, -0.011404895223677158, 0.055323276668787, 0.20933283865451813, 0.041934967041015625, -0.02777385339140892, -0.05229482427239418, 0.11852642148733139, 0.013097604736685753, 0.20886072516441345, 0.024057362228631973, 0.031561579555273056, -0.007070228457450867, 0.03980367258191109, -0.09192615002393723, -0.12016796320676804, 0.03987988457083702, 0.09930752217769623, 0.02743520960211754, 0.0008964001317508519, 0.024627381935715675, -0.051868218928575516, -0.09729927778244019, -0.018709421157836914, -0.0026075944770127535, 0.03278551250696182, 0.019987791776657104, -0.0679226890206337, 0.1313694566488266, 0.09356611222028732, -0.04111716151237488, -0.22247271239757538, 0.03761001303792, 0.1473941057920456, 0.03236487880349159, -0.08278266340494156, 0.13152049481868744, -0.027192510664463043, -0.07874083518981934], metadata={'source': 'AAAMLP-569to.pdf', 'page': 90}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 91 Index Feature_0 Feature_1 Feature_2 0 0 0 1 1 1 0 0 2 1 0 1  So, our features are stored in a matrix which has 3 rows and 3 columns - 3x3. Each element of this matrix occupies 8 bytes. So, our total memory requirement for this array is 8x3x3 = 72 bytes.  We can also check this using a simple python snippet.  ═════════════════════════════════════════════════════════════════════════ import numpy as np  # create our example feature matrix example = np.array(     [         [0, 0, 1],         [1, 0, 0],         [1, 0, 1]     ] )  # print size in bytes print(example.nbytes) ═════════════════════════════════════════════════════════════════════════  This code will print 72 as we calculated before. But do we need to store all the elements of this matrix? No. As mentioned before we are only interested in 1s. 0s are not that important because anything multiplied with 0 will be zero and 0 added/subtracted to/from anything doesn’t make any difference. One way to represent this matrix only with ones would be some kind of dictionary method in which keys are indices of rows and columns and value is 1:    ═════════════════════════════════════════════════════════════════════════   (0, 2) 1   (1, 0) 1   (2, 0) 1   (2, 2) 1 ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[0.08910781890153885, 0.005394516047090292, -0.23046718537807465, 0.09811197221279144, 0.06525204330682755, -0.14214226603507996, -0.07970090955495834, -0.035696640610694885, -0.034469231963157654, -0.009906641207635403, -0.06785744428634644, 0.030401619151234627, 0.11109493672847748, 0.015922175720334053, 0.027864377945661545, 0.06415711343288422, -0.0008603648748248816, -0.031037084758281708, -0.035081975162029266, 0.03538069874048233, 0.10787411779165268, -0.06879774481058121, -0.08010634034872055, 0.08662226051092148, -0.007429364137351513, -0.030362986028194427, 0.060756977647542953, -0.006699781399220228, -0.04819241166114807, 0.02965155988931656, 0.028796199709177017, 0.19226938486099243, 0.05437446013092995, -0.042975250631570816, 0.08772094547748566, 0.12722034752368927, -0.07695025205612183, 0.11379808187484741, -0.1153864935040474, 0.10849638283252716, 0.1159377321600914, 0.1232517659664154, -0.04436277598142624, 0.08417106419801712, 0.13603702187538147, 0.05391134321689606, -0.020524192601442337, -0.13903911411762238, 0.09893590211868286, -0.12987379729747772, -0.04931202530860901, 0.1962154507637024, -0.1584506779909134, 0.027082344517111778, -0.02347486838698387, -0.31533119082450867, -0.03923023119568825, -0.08043920993804932, -0.10606168955564499, 0.03800632432103157, -0.03630724176764488, -0.2322806864976883, 0.11453374475240707, -0.0690411925315857, 0.06012053042650223, 0.019280901178717613, 0.1311478465795517, 0.052244462072849274, 0.009990346617996693, 0.040700387209653854, -0.06427943706512451, 0.1250196397304535, -0.015391943976283073, 0.14018601179122925, -0.04417659714818001, -0.1225975826382637, 0.16637834906578064, -0.02623266912996769, 0.1764662265777588, 0.09847612679004669, -0.07444311678409576, 0.048906389623880386, -0.08144591003656387, -0.040173016488552094, -0.024270489811897278, -0.11218786984682083, -0.02047879248857498, 0.011676551774144173, -0.05546547472476959, 0.029807331040501595, 0.07903988659381866, -0.022929511964321136, -0.11317404359579086, -0.0699196457862854, 0.05527995526790619, 0.0663428083062172, 0.11539439111948013, -0.029818054288625717, -0.008019175380468369, 0.0767233818769455, 0.16483186185359955, -0.0638740137219429, 0.13032861053943634, 0.15866446495056152, -0.03419484198093414, 0.10812168568372726, 0.11698877066373825, 0.09682570397853851, 0.03434725105762482, 0.017072103917598724, 0.10751640051603317, -0.056990161538124084, -0.14789775013923645, 0.14268958568572998, 0.12538860738277435, 0.028846940025687218, 0.009253141470253468, 0.047201164066791534, 0.06960878521203995, 0.1728190779685974, -0.08154214918613434, -0.15484365820884705, 0.15516813099384308, -0.01612480729818344, 9.011637303046882e-06, 0.10405002534389496, -0.19312834739685059, 1.1602352586542634e-32, -0.009119648486375809, 0.11325497925281525, -0.040631312876939774, -0.0025170405860990286, 0.06648284941911697, -0.01115440484136343, 0.0917624831199646, 0.13393546640872955, -0.02545333281159401, 0.12042278796434402, -0.10087686032056808, 0.15486116707324982, 0.07466301321983337, 0.10493085533380508, 0.026662427932024002, -0.10855866968631744, 0.0026833820156753063, 0.07074163854122162, -0.03246012330055237, -0.25091254711151123, 0.05226108431816101, 0.07941360771656036, 0.04648678004741669, -0.029668422415852547, -0.1180892065167427, -0.2324845790863037, -0.06484772264957428, -0.17942441999912262, -0.18193534016609192, -0.03308875486254692, -0.19633328914642334, 0.0950288474559784, 0.14397601783275604, -0.02102760039269924, 0.2607530355453491, -0.16338033974170685, 0.02055339142680168, -0.113532654941082, 0.100984126329422, -0.16969427466392517, -0.02499520033597946, 0.017199618741869926, 0.14258773624897003, -0.11840201169252396, -0.12198091298341751, 0.010358287021517754, 0.105070561170578, -0.009065051563084126, -0.09630583226680756, 0.07589495927095413, 0.10576672852039337, -0.025105411186814308, -0.024347534403204918, 0.13007798790931702, 0.019365718588232994, -0.07299423217773438, 0.05077986791729927, -0.17108957469463348, 0.07676205039024353, 0.12649224698543549, -0.039104413241147995, -0.03835346922278404, 0.0757775604724884, 0.06445276737213135, 0.11664140969514847, 0.005264740902930498, 0.030573153868317604, 0.17934951186180115, 0.0626411959528923, 0.0015328822191804647, -0.029035164043307304, 0.12966711819171906, -0.0265647042542696, -0.13721998035907745, 0.049736350774765015, -0.07238491624593735, 0.23748114705085754, -0.07626648247241974, -0.19979000091552734, -0.06906578689813614, 0.06690237671136856, 0.09068233519792557, 0.08262213319540024, -0.15366704761981964, -0.14288966357707977, 0.12427186965942383, 0.11854202300310135, -0.1410369873046875, 0.011231105774641037, -0.23763571679592133, -0.04859509319067001, -0.0027160767931491137, 0.01748661696910858, -0.24237139523029327, -0.16460104286670685, -1.242446541751691e-32, -0.03518587723374367, -0.012637579813599586, -0.019422998651862144, 0.043693020939826965, 0.05273693799972534, -0.1261877566576004, 0.011814584955573082, -0.03527864068746567, 0.00025964094675146043, -0.22898106276988983, -0.012067173607647419, 0.020704735070466995, 0.1536879688501358, -0.04708664119243622, 0.07093917578458786, 0.12885864078998566, -0.18049189448356628, 0.030557779595255852, -0.02252632938325405, 0.00985683687031269, -0.15077021718025208, 0.03356604278087616, 0.05973236635327339, -0.0220626387745142, -0.20028837025165558, -0.078499436378479, -0.13941866159439087, -0.01851523667573929, 0.14945703744888306, -0.06302031129598618, -0.04882232844829559, 0.016862263903021812, -0.1308092474937439, -0.016723858192563057, 0.06633227318525314, -0.038886163383722305, 0.021686410531401634, -0.037515535950660706, -0.03307550773024559, -0.026116956025362015, 0.13157975673675537, 0.1406499147415161, -0.0812867134809494, 0.012540738098323345, 0.042384322732686996, 0.043639540672302246, -0.034578919410705566, -0.0303808581084013, 0.05476188659667969, 0.06879859417676926, 0.10622522979974747, 0.01981094852089882, -0.042027439922094345, 0.12218692153692245, -0.04539177939295769, -0.04192117229104042, -0.12077317386865616, 0.03970184177160263, 0.04350382462143898, -0.07525858283042908, -0.1659126579761505, -0.16899292171001434, -0.11506060510873795, -0.02569303847849369, 0.04778120294213295, 0.007839297875761986, -0.1482963263988495, 0.02721598744392395, -0.16564644873142242, 0.21452565491199493, -0.03204232081770897, -0.03574947640299797, -0.1147218570113182, -0.06436550617218018, -0.18446986377239227, 0.046986933797597885, 0.01373833417892456, -0.11957231909036636, -0.1654619574546814, 0.1483154594898224, 0.014645230956375599, 0.10669747740030289, 0.05116831883788109, -0.013139113783836365, -0.07750307768583298, 0.24668079614639282, 0.08821281790733337, -0.012625196948647499, -0.09141060709953308, 0.021198371425271034, 0.052251726388931274, 0.041612643748521805, 0.09728451818227768, 0.08624807000160217, -0.01857818104326725, -9.96312721213144e-08, -0.04036879166960716, -0.010718711651861668, -0.015904022380709648, -0.1271163821220398, 0.19024117290973663, -0.1435507833957672, -0.030222740024328232, 0.07457409054040909, 0.03695647045969963, -0.03382880985736847, 0.04812674596905708, -0.09290733933448792, -0.12065433710813522, -0.07489248365163803, 0.05300981551408768, 0.24164310097694397, -0.002103423699736595, -0.1909865438938141, 0.02576100453734398, -0.026180770248174667, -0.05580895021557808, -0.028526004403829575, -0.005228049587458372, 0.047073740512132645, -0.043973371386528015, -0.109693244099617, -0.002060524420812726, 0.15556733310222626, 0.14661896228790283, 0.016511285677552223, -0.04485929384827614, -0.08499936759471893, 0.07083155959844589, -0.047152530401945114, 0.2337576001882553, 0.05718177556991577, 0.031205780804157257, -0.030282896012067795, -0.06852090358734131, -0.020213307812809944, -0.13825830817222595, -0.01805994100868702, 0.06284065544605255, 0.027774086222052574, 0.07433360069990158, -0.02858489193022251, -0.16684657335281372, -0.0786685049533844, 0.0745258629322052, -0.06541825085878372, 0.020501023158431053, 0.01779802516102791, -0.0727153941988945, 0.133341982960701, 0.14552396535873413, -0.04488779231905937, -0.26385143399238586, 0.015280536375939846, 0.12823240458965302, 0.042923226952552795, 0.01271038968116045, 0.0516776405274868, -0.02287634089589119, -0.03944995254278183], metadata={'source': 'AAAMLP-569to.pdf', 'page': 91}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 92 A notation like this will occupy much less memory because it has to store only four values (in this case). The total memory used will be 8x4 = 32 bytes. Any numpy array can be converted to a sparse matrix by simple python code.  ═════════════════════════════════════════════════════════════════════════ import numpy as np from scipy import sparse  # create our example feature matrix example = np.array(     [         [0, 0, 1],         [1, 0, 0],         [1, 0, 1]     ] )  # convert numpy array to sparse CSR matrix sparse_example = sparse.csr_matrix(example)  # print size of this sparse matrix print(sparse_example.data.nbytes) ═════════════════════════════════════════════════════════════════════════  This will print 32, which is so less than our dense array! The total size of the sparse csr matrix is the sum of three values.  ═════════════════════════════════════════════════════════════════════════ print(     sparse_example.data.nbytes +      sparse_example.indptr.nbytes +      sparse_example.indices.nbytes ) ═════════════════════════════════════════════════════════════════════════  This will print 64, which is still less than our dense array. Unfortunately, I will not go into the details of these elements. You can read more about them in scipy docs. The difference in size becomes vast when we have much larger arrays, let’s say with thousands of samples and tens of thousands of features. For example, a text dataset where we are using count-based features.  ═════════════════════════════════════════════════════════════════════════ import numpy as np from scipy import sparse'),\n",
       " VectorParams(vector=[0.0011111217318102717, 0.004586245398968458, -0.1830025613307953, 0.08911538124084473, 0.1425836980342865, -0.1537207067012787, -0.01628722995519638, -0.040876101702451706, -0.01169476006180048, 0.04237045347690582, -0.13576970994472504, 0.04849481210112572, 0.01607147790491581, 0.007181667722761631, 0.012046467512845993, 0.003011527704074979, 0.09540461748838425, -0.06967570632696152, -0.04436740279197693, 0.10857615619897842, 0.08053962886333466, -0.0728989839553833, 0.0035190966445952654, -0.008518373593688011, -0.023207493126392365, -0.05432979017496109, 0.07878401130437851, 0.027490202337503433, -0.0734754130244255, -0.05467462167143822, 0.05927981063723564, 0.2283223271369934, 0.058510296046733856, -0.023923423141241074, 0.04346432536840439, 0.19978603720664978, 0.005041647236794233, 0.11076780408620834, -0.048357728868722916, 0.028375593945384026, 0.07412413507699966, 0.10327618569135666, -0.08528322726488113, 0.10171133279800415, 0.12769855558872223, -0.021500416100025177, -0.012865126132965088, -0.036347854882478714, 0.0379527248442173, -0.1502228081226349, -0.13516241312026978, 0.12777768075466156, -0.10432475805282593, 0.04796776548027992, -0.016410093754529953, -0.2968851327896118, -0.03436620533466339, -0.09229891747236252, -0.11686450242996216, 0.0619119256734848, -0.08208472281694412, -0.16180451214313507, 0.028682395815849304, 0.0011590139474719763, 0.09398724883794785, 0.09685348719358444, 0.09114111214876175, 0.04179738089442253, -0.06526601314544678, 0.062485430389642715, 0.011257899925112724, 0.061189860105514526, -0.10032996535301208, 0.11365289986133575, -0.03698217123746872, -0.1276223361492157, 0.10776010900735855, 0.018073391169309616, 0.15014566481113434, 0.16518136858940125, -0.060189951211214066, 0.053912125527858734, -0.06808651238679886, -0.10070466250181198, -0.00085069565102458, -0.09804169833660126, -0.03176556155085564, 0.07826793938875198, -0.10708259791135788, -0.08334052562713623, 0.056856248527765274, 0.005392169579863548, -0.13780906796455383, -0.025281252339482307, -0.028054146096110344, 0.028825489804148674, 0.09870672971010208, -0.023027639836072922, -0.048698540776968, 0.049107782542705536, 0.1148797869682312, -0.08325400948524475, 0.14281783998012543, 0.14782002568244934, -0.030849281698465347, 0.07213036715984344, 0.17483165860176086, 0.16424356400966644, 0.04748522490262985, 0.0217266995459795, 0.07330330461263657, 0.014275829307734966, -0.12409233301877975, 0.18086253106594086, 0.07776838541030884, -0.0627020001411438, -0.039178404957056046, 0.05312176048755646, 0.03940286114811897, 0.16367118060588837, -0.08592379093170166, -0.06784292310476303, 0.021945510059595108, -0.029399681836366653, -0.028065597638487816, 0.0805368572473526, -0.15141797065734863, 1.9195603813105114e-32, 0.06318849325180054, 0.1413322538137436, 0.06195540353655815, -0.08867203444242477, 0.0860641598701477, -0.01444348506629467, 0.12391600757837296, 0.09996704757213593, -0.026894086971879005, 0.10333000868558884, -0.14031414687633514, 0.11270111054182053, 0.04318222030997276, 0.11970117688179016, -0.06280865520238876, -0.10378892719745636, -0.07950717210769653, 0.09514131397008896, -0.05648086592555046, -0.23573459684848785, 0.10128381848335266, 0.15904170274734497, 0.0069425986148417, -0.03111620433628559, -0.04646074026823044, -0.21288561820983887, 0.04131823033094406, -0.2088545560836792, -0.1418216973543167, 0.022611655294895172, -0.24741217494010925, 0.07228334248065948, 0.12913858890533447, 0.02507735788822174, 0.13135956227779388, -0.11731801182031631, -0.008936157450079918, -0.07194506376981735, -0.03305957093834877, -0.19242770969867706, -0.041365236043930054, 0.04757123440504074, 0.10533301532268524, -0.07527437806129456, -0.13266606628894806, -0.014554191380739212, 0.10113251954317093, 0.06513338536024094, -0.03271159529685974, 0.046261321753263474, 0.12707394361495972, -0.008876778185367584, -0.05994008108973503, 0.10264407098293304, 0.011185677722096443, -0.05348747596144676, 0.11566796898841858, -0.11948198080062866, 0.049823928624391556, 0.13365894556045532, 0.009614190086722374, -0.0810636579990387, 0.018297066912055016, 0.01600622572004795, 0.04719356447458267, -0.015436704270541668, -0.018619433045387268, 0.10998064279556274, 0.1263953298330307, -0.03829624503850937, 0.028370963409543037, 0.15872959792613983, 0.10442712157964706, -0.10502930730581284, 0.008685257285833359, -0.008874606341123581, 0.27478793263435364, -0.09017925709486008, -0.14542505145072937, -0.06126837432384491, 0.05675186961889267, 0.04115502908825874, -0.00138665153644979, -0.16759604215621948, -0.28128719329833984, 0.11511094868183136, 0.16637243330478668, -0.14597493410110474, -0.09405887871980667, -0.23837129771709442, 0.006085405126214027, -0.036329854279756546, 0.0034800944849848747, -0.2368132621049881, -0.15583878755569458, -1.6381549683105239e-32, 0.0324120968580246, -0.07418164610862732, 0.0016472444403916597, 0.0645129606127739, 0.02984214946627617, -0.0704844668507576, 0.04167556017637253, -0.08862819522619247, 0.001564705977216363, -0.20405280590057373, -0.027814354747533798, -0.013424438424408436, 0.14928580820560455, -0.009789733216166496, 0.036687761545181274, 0.05495651811361313, -0.12614499032497406, 0.08737536519765854, 0.008815859444439411, 0.03259405493736267, -0.14190495014190674, 0.11941005289554596, 0.06864117085933685, -0.0870329737663269, -0.07827112078666687, -0.027125045657157898, -0.10610233247280121, 0.1133725717663765, 0.1472366899251938, -0.015746600925922394, -0.06661488860845566, 0.005010233726352453, -0.22038348019123077, -0.10832536220550537, 0.05586223304271698, 0.009680512361228466, -0.009929447434842587, 0.03579859435558319, -0.03854091838002205, -0.06555096805095673, 0.00427689915522933, 0.1262604296207428, -0.13066622614860535, 0.026258235797286034, 0.06402866542339325, -0.03658603876829147, -0.06828688830137253, -0.04396095871925354, 0.06498555839061737, 0.043545641005039215, 0.10057546943426132, 0.033248171210289, -0.028268208727240562, 0.08543022722005844, -0.03729797899723053, -0.008121320977807045, -0.07056320458650589, 0.053460247814655304, 0.08201438188552856, -0.07348018139600754, -0.14108198881149292, -0.07420728355646133, -0.16284716129302979, -0.07200595736503601, 0.09536745399236679, -0.04072733595967293, -0.1537618786096573, 0.006807454861700535, -0.07362569868564606, 0.20328475534915924, -0.18033787608146667, 0.0141175901517272, -0.048774708062410355, -0.02125815860927105, -0.14617286622524261, 0.15531983971595764, 0.033710822463035583, -0.10886555910110474, -0.1166868805885315, 0.12403114140033722, -0.055835604667663574, 0.1245800256729126, -0.026189908385276794, -0.008466268889605999, -0.05615685507655144, 0.21592508256435394, 0.07908166944980621, -0.11966388672590256, -0.04061200097203255, -0.023508230224251747, 0.03813577815890312, -0.02196364663541317, 0.032036419957876205, 0.06499762833118439, -0.041147295385599136, -9.995662964001895e-08, 0.02996664308011532, 0.028346821665763855, -0.006346709560602903, -0.09004233032464981, 0.30325648188591003, -0.12378577888011932, 0.06853216141462326, 0.049725309014320374, 0.06957969069480896, -0.049059487879276276, 0.10754305124282837, -0.04268885403871536, -0.15102997422218323, -0.047929439693689346, 0.03525873273611069, 0.16461603343486786, -0.050822533667087555, -0.15497297048568726, -0.0017269764794036746, 0.01175296027213335, -0.03961653262376785, -0.030301343649625778, -0.046166807413101196, 0.01749761588871479, 0.004107110667973757, -0.07010827958583832, -0.023225191980600357, 0.05882054194808006, 0.18702881038188934, 0.041942939162254333, -0.10395113378763199, -0.051145605742931366, 0.13217775523662567, -0.11260150372982025, 0.18107375502586365, 0.11607609689235687, 0.04639405757188797, 0.05192543566226959, -0.11184985190629959, -0.002446974627673626, -0.03469845652580261, -0.0953897163271904, 0.1419367492198944, -0.020812777802348137, 0.0017620761645957828, -0.03074459359049797, -0.14030927419662476, -0.0023763752542436123, 0.06529231369495392, -0.025267045944929123, 0.04940398782491684, -0.07796476036310196, -0.08153415471315384, 0.11608588695526123, 0.12167614698410034, -0.01579880341887474, -0.2094915807247162, -0.0175947118550539, 0.10917086899280548, 0.1198536604642868, 0.12661276757717133, 0.11466198414564133, -0.07621714472770691, 0.07480792701244354], metadata={'source': 'AAAMLP-569to.pdf', 'page': 92}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 93 # number of rows n_rows = 10000  # number of columns n_cols = 100000  # create random binary matrix with only 5% values as 1s example = np.random.binomial(1, p=0.05, size=(n_rows, n_cols))  # print size in bytes print(f\"Size of dense array: {example.nbytes}\")  # convert numpy array to sparse CSR matrix sparse_example = sparse.csr_matrix(example)  # print size of this sparse matrix print(f\"Size of sparse array: {sparse_example.data.nbytes}\")  full_size = (     sparse_example.data.nbytes +      sparse_example.indptr.nbytes +      sparse_example.indices.nbytes )  # print full size of this sparse matrix print(f\"Full size of sparse array: {full_size}\") ═════════════════════════════════════════════════════════════════════════  This prints:  Size of dense array: 8000000000 Size of sparse array: 399932496 Full size of sparse array: 599938748  So, dense array takes ~8000MB or approximately 8GB of memory. The sparse array, on the other hand, takes only 399MB of memory.  And, that’s why we prefer sparse arrays over dense whenever we have a lot of zeros in our features.   Please note that there are many different ways of representing a sparse matrix. Here I have shown only one such (and probably the most popular) way. Going deep into these is beyond the scope of this book and is left as an exercise to the reader.'),\n",
       " VectorParams(vector=[0.10280875861644745, -0.050546322017908096, -0.11763762682676315, 0.10492494702339172, 0.08146060258150101, 0.07009725272655487, -0.017759254202246666, -0.1452905684709549, 0.04954255744814873, -0.025528481230139732, -0.050265099853277206, -0.04958314076066017, 0.05423897132277489, -0.06891941279172897, -0.025096219033002853, 0.08956669270992279, -0.04906560480594635, 0.03781166300177574, -0.11032546311616898, -0.02532312646508217, 0.13205797970294952, -0.04371177405118942, -0.13213026523590088, 0.017345862463116646, 0.041330691426992416, 0.08476880192756653, 0.047704633325338364, 0.09202645719051361, -0.03339490666985512, -0.08010212332010269, 0.04278360307216644, 0.15401916205883026, -0.042091842740774155, 0.01859096810221672, -0.04738537594676018, 0.09061072766780853, -0.02736690081655979, 0.027668993920087814, -0.1495809555053711, 0.0402211956679821, 0.010485251434147358, 0.05356385558843613, 0.0028849239461123943, 0.04240932688117027, 0.14178429543972015, 0.16070489585399628, 0.0018721221713349223, 0.0389133021235466, -0.03276321664452553, -0.2291373610496521, 0.014743009582161903, 0.1522216945886612, -0.05819186195731163, 0.17018672823905945, -0.03334294632077217, -0.18099677562713623, -0.10099977254867554, -0.07911490648984909, -0.07227332890033722, 0.006333767436444759, -0.1902935653924942, 0.030862614512443542, 0.09653874486684799, 0.013624497689306736, 0.09942068159580231, -0.05848662182688713, 0.007016434334218502, -0.04686992987990379, 0.013309400528669357, 0.004319526720792055, -0.03443317487835884, -0.02483864314854145, -0.11994767189025879, -0.035946983844041824, 0.0704832449555397, -0.05139494314789772, 0.22302527725696564, -0.005553797353059053, 0.12696154415607452, 0.05863722786307335, -0.045449528843164444, 0.0032356323208659887, 0.07210994511842728, -0.03138846904039383, -0.053482796996831894, -0.0652613714337349, 0.06051483750343323, -0.007166468072682619, -0.011230935342609882, 0.03863023594021797, -0.012568719685077667, -0.006996642332524061, 0.1198430135846138, -0.039272528141736984, 0.1050773486495018, -0.039520252496004105, 0.10447952896356583, 0.1636318415403366, 0.07123711705207825, 0.03467549756169319, 0.042272359132766724, -0.09589827805757523, -0.09148705750703812, 0.03288499638438225, 0.039778463542461395, -0.03992335498332977, 0.12776313722133636, 0.07387401908636093, 0.11032845824956894, -0.07668910920619965, -0.0011890021851286292, -0.005058569367974997, -0.09389148652553558, -0.027929039672017097, -0.0689752995967865, -0.022033143788576126, -0.1408245712518692, 0.06456948816776276, 0.06223994493484497, 0.03966625779867172, -0.03094426542520523, -0.017101524397730827, -0.004342995118349791, 0.1684848815202713, -0.0710039734840393, -0.07538846880197525, -0.10519333928823471, 1.1458655748994302e-32, -0.03960925713181496, 0.034786488860845566, -0.10094840824604034, -0.06500571966171265, 0.0639386922121048, -0.04595264792442322, -0.010324613191187382, 0.04334888234734535, -0.0005634804838337004, 0.11668498814105988, -0.13387376070022583, 0.10362346470355988, -0.022369233891367912, 0.2088003009557724, 0.019783658906817436, -0.07566080242395401, -0.024553881958127022, 0.037507735192775726, -0.11669715493917465, -0.09653417021036148, -0.03368160501122475, 0.13859987258911133, 0.04370719566941261, 0.006008401978760958, -0.07605700194835663, 0.004322119057178497, 0.039505038410425186, -0.16903847455978394, -0.1479531079530716, 0.03812115266919136, -0.2103963941335678, -0.011940217576920986, -0.004538784734904766, -0.050770267844200134, 0.05563988536596298, -0.09090032428503036, 0.06168172135949135, -0.008518315851688385, 0.004051260184496641, -0.08436039835214615, 0.10911380499601364, 0.027318673208355904, -0.016801968216896057, -0.05663251876831055, 0.03208518773317337, -0.0007028220570646226, 0.11315058171749115, 0.07302001863718033, -0.15719851851463318, 0.04353806748986244, 0.06004135683178902, 0.0011324664810672402, 0.001643783994950354, 0.09256052225828171, -0.0065246764570474625, -0.032768625766038895, 0.051328837871551514, -0.13337492942810059, -0.020064694806933403, 0.15608666837215424, -0.11817210167646408, 0.04154646024107933, 0.13687098026275635, -0.04672159627079964, -0.00020909142040181905, -0.04007662832736969, 0.0565803088247776, -0.007096126675605774, 0.12859350442886353, 0.05777749791741371, -0.12404022365808487, 0.15002554655075073, 0.026093700900673866, -0.14970222115516663, -0.021213142201304436, -0.03633962944149971, 0.18302349746227264, -0.15666528046131134, -0.14144395291805267, 0.05584229528903961, -0.02259749360382557, -0.017059236764907837, 0.04538944363594055, -0.13300853967666626, -0.17176558077335358, -0.06665286421775818, -0.0450848713517189, -0.12736347317695618, -0.12165295332670212, -0.01397037785500288, -0.017205942422151566, -0.025190303102135658, 0.021108241751790047, -0.12766902148723602, 0.03231847286224365, -1.292739626741241e-32, -0.14867611229419708, -0.05348820239305496, -0.056516245007514954, -0.008697780780494213, -0.1313161700963974, -0.06277553737163544, 0.052772823721170425, -0.02125370129942894, -0.027206020429730415, -0.08516969531774521, -0.03530140221118927, -0.08339275419712067, 0.020766543224453926, -0.057190097868442535, -0.021437538787722588, 0.07827100902795792, -0.14152659475803375, 0.07785120606422424, -0.024737156927585602, 0.17429454624652863, -0.05397607386112213, 0.2383817434310913, -0.16673403978347778, 0.031150950118899345, -0.07801400870084763, 0.08041977137327194, 0.0555119588971138, 0.06741141527891159, 0.1623355597257614, 0.0259794183075428, -0.017959846183657646, -0.13542650640010834, -0.1115746721625328, -0.004034288693219423, 0.05418342351913452, -0.0021457108668982983, 0.005728777498006821, -0.08814357221126556, -0.00032280111918225884, 0.03962292522192001, 0.11076735705137253, 0.03439212590456009, -0.14778023958206177, 0.06116363778710365, 0.09109894931316376, 0.07658140361309052, -0.041970085352659225, 0.031260497868061066, 0.10910438001155853, 0.000611211231444031, 0.14316023886203766, -0.01807725615799427, -0.0262130256742239, 0.12388855963945389, 0.060420021414756775, -0.0766541138291359, -0.18884548544883728, -0.06219032034277916, 0.06766683608293533, -0.08751071989536285, -0.022143572568893433, -0.08016595989465714, 0.10632938891649246, -0.013403333723545074, 0.0654459148645401, 0.025186387822031975, -0.009347302839159966, -0.09280519187450409, -0.0842459425330162, 0.013646918348968029, 0.02997242473065853, 0.013517913408577442, -0.0595107339322567, -0.058964334428310394, -0.023397918790578842, -0.000422792712925002, -0.058216530829668045, -0.03605577349662781, -0.0905207023024559, 0.04530941694974899, -0.18374468386173248, 0.08344756811857224, 0.04154117777943611, 0.1239527091383934, 0.05537847429513931, 0.041762322187423706, 0.12679345905780792, 0.04957115650177002, 0.0192527174949646, 0.02034800685942173, 0.06322129815816879, 0.13181626796722412, -0.01681388169527054, 0.1367093324661255, -0.06230238825082779, -1.0005368267229642e-07, -0.0493677482008934, -0.10286238044500351, -0.026998713612556458, -0.04931747913360596, 0.14327971637248993, -0.13663576543331146, -0.04737222567200661, 0.05697077512741089, -0.08270563185214996, 0.02956303581595421, 0.10265614837408066, 0.1289793848991394, -0.07123881578445435, -0.08091277629137039, 0.13979849219322205, 0.12391762435436249, 0.014932212419807911, -0.08429630100727081, 0.0015120828757062554, 0.02989340014755726, 0.04990120604634285, -0.006102954037487507, -0.08318046480417252, -0.045555002987384796, -0.008153725415468216, -0.10949398577213287, 0.028808843344449997, 0.16063787043094635, 0.2586100101470947, -0.03035474754869938, -0.07126688212156296, 0.0011223980691283941, 0.018334347754716873, -0.014388415031135082, 0.11397737264633179, 0.03580537810921669, 0.029573973268270493, -0.00893213227391243, -0.0007055215537548065, -0.10950873047113419, -0.10677677392959595, -0.04344860836863518, 0.06100626289844513, -0.008096610195934772, -0.05262172222137451, -0.01860605925321579, -0.10987886041402817, -0.021079566329717636, -0.002224003430455923, 0.0666133463382721, -0.020001042634248734, 0.11782678216695786, -0.06467609107494354, 0.1401059627532959, -0.014582988806068897, -0.035947103053331375, -0.14484426379203796, -0.11489586532115936, 0.09436208009719849, 0.006742909085005522, 0.031222760677337646, 0.02599276416003704, -0.09573870152235031, -0.037348248064517975], metadata={'source': 'AAAMLP-569to.pdf', 'page': 93}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 94 Even though the sparse representation of binarized features takes much less memory than its dense representation, there is another transformation for categorical variables that takes even less memory. This is known as One Hot Encoding.  One hot encoding is a binary encoding too in the sense that there are only two values, 0s and 1s. However, it must be noted that it’s not a binary representation. Its representation can be understood by looking at the following example.  Suppose we represent each category of the ord_2 variable by a vector. This vector is of the same size as the number of categories in the ord_2 variable. In this specific case, each vector is of size six and has all zeros except at one position. Let’s look at this particular table of vectors.  Freezing 0 0 0 0 0 1 Warm 0 0 0 0 1 0 Cold 0 0 0 1 0 0 Boiling Hot 0 0 1 0 0 0 Hot 0 1 0 0 0 0 Lava Hot 1 0 0 0 0 0  We see that the size of vectors is 1x6, i.e. there are six elements in the vector. Where does this number come from? If you look carefully, you will see that there are six categories, as mentioned before. When one-hot encoding, the vector size has to be same as the number of categories we are looking at. Each vector has a 1 and rest all other values are 0s. Now, let’s use these features instead of the binarized feature as before and see how much memory can we save.  If you remember the old data, it looked as follows:  Index Feature 0 Warm 1 Hot 2 Lava hot'),\n",
       " VectorParams(vector=[0.09581197053194046, 0.02090834081172943, -0.12945646047592163, 0.011141522787511349, 0.10481593012809753, -0.1689271330833435, -0.05656791478395462, -0.09926530718803406, -0.21824301779270172, 0.0858466699719429, -0.09924358129501343, -0.046181127429008484, 0.03609335049986839, -0.06367660313844681, -0.030351588502526283, 0.028514010831713676, -0.1534978151321411, 0.004946655128151178, -0.03590115159749985, 0.00953631941229105, 0.05435054004192352, 0.008395174518227577, -0.07845941185951233, -0.07636420428752899, 0.07630834728479385, -0.04798772931098938, 0.12089281529188156, 0.08767585456371307, -0.10817977786064148, -0.0509478822350502, 0.11890134960412979, 0.22099828720092773, 0.10113899409770966, -0.03178922086954117, 0.10352058708667755, 0.12550075352191925, -0.07403796911239624, 0.04915842041373253, -0.07405143231153488, 0.10391368716955185, 0.030900467187166214, 0.007205126341432333, -0.052717600017786026, -0.04516703262925148, 0.09156715869903564, 0.03267066553235054, -0.016542533412575722, 0.030500805005431175, 0.16653850674629211, -0.18905241787433624, 0.005115236155688763, 0.08553710579872131, -0.05493835732340813, 0.08384792506694794, -0.05267221853137016, -0.31632861495018005, -0.03435130789875984, -0.12129312753677368, -0.06977937370538712, -0.022067967802286148, -0.014523418620228767, -0.09106603264808655, 0.08886326104402542, -0.04745592549443245, 0.13375356793403625, 0.0881270244717598, 0.02858640067279339, -0.04995499551296234, -0.061908550560474396, 0.0691443458199501, -0.0535404272377491, 0.09417077898979187, 0.006291354540735483, 0.04971057549118996, -0.031175225973129272, -0.06378950923681259, 0.184798464179039, 0.07347770780324936, 0.11678007245063782, 0.09103352576494217, -0.19799654185771942, 0.0032550226897001266, 0.04464562237262726, -0.06860867142677307, -0.06766363978385925, -0.10722864419221878, -0.08152557909488678, 0.008325708098709583, -0.02847503311932087, 0.019981440156698227, 0.02662612684071064, 0.03867645934224129, -0.15162736177444458, -0.11843891441822052, 0.04095051810145378, -0.011117184534668922, 0.00721140718087554, 0.005882823374122381, -0.003655283944681287, 0.10584081709384918, 0.0490635521709919, -0.10675711929798126, 0.030459310859441757, 0.12059804052114487, 0.06451351195573807, 0.21678347885608673, 0.10179140418767929, 0.06391698867082596, 0.09462285786867142, -0.06820296496152878, -0.007183749228715897, 0.04582628980278969, -0.059145279228687286, 0.08634402602910995, 0.1437627077102661, 0.09913509339094162, -0.03042697161436081, 0.0928514152765274, 0.019166745245456696, 0.12532098591327667, -0.044050268828868866, -0.05238759145140648, 0.08711063116788864, 0.07824743539094925, -0.0424930639564991, 0.022991258651018143, -0.13332250714302063, 1.6485364936066047e-32, -0.07440412044525146, 0.09129036962985992, 0.009456264786422253, -0.062096260488033295, 0.01622041128575802, 0.029282787814736366, 0.11337819695472717, 0.08634860813617706, -0.032884225249290466, 0.06195829063653946, -0.1249222457408905, 0.17997103929519653, 0.04139222949743271, 0.05439720302820206, -0.012480963952839375, -0.023847457021474838, 0.022243870422244072, 0.07821216434240341, -0.01158133801072836, -0.1909901350736618, 0.06051792576909065, 0.017493290826678276, 0.02054576948285103, -0.0230422280728817, -0.13648588955402374, -0.13329605758190155, 0.005182095803320408, -0.1871524453163147, -0.14884284138679504, -0.0019526146352291107, -0.2021038681268692, 0.026583895087242126, 0.09243692457675934, -0.0019742066506296396, 0.12149010598659515, -0.17843025922775269, -0.00824589654803276, 0.017057670280337334, 0.016378676518797874, -0.10921882092952728, 0.09799854457378387, -0.0027177396696060896, 0.05757646635174751, -0.1492045521736145, -0.0746973529458046, 0.09586501866579056, -0.003286964725703001, 0.040533311665058136, -0.06298529356718063, 0.09520082920789719, 0.06405525654554367, 0.025850502774119377, 0.018429279327392578, 0.05521318316459656, 0.01877281814813614, -0.043117258697748184, 0.03808089345693588, -0.04480237513780594, 0.12404119223356247, 0.06561333686113358, 0.04786377027630806, -0.027484752237796783, 0.0012879450805485249, 0.05268622562289238, -0.015450587496161461, 0.04174191132187843, 0.08190655708312988, 0.08014348149299622, 0.05850764364004135, 0.1161409392952919, -0.060232263058423996, 0.21813839673995972, 0.03699299693107605, -0.058830466121435165, 0.05624596029520035, -0.12278120964765549, 0.23535864055156708, -0.14482074975967407, -0.13749326765537262, -0.11182265728712082, 0.052327051758766174, 0.10772843658924103, 0.06806228309869766, -0.20317505300045013, -0.1419254094362259, -0.01176859624683857, 0.042541537433862686, -0.1347026526927948, -0.125754252076149, -0.19516141712665558, 0.011481042020022869, 0.00852777436375618, -0.07983332872390747, -0.14237916469573975, -0.10196918994188309, -1.2988924580470326e-32, 0.005817211698740721, -0.028760692104697227, 0.053580839186906815, 0.05897269397974014, -0.02905447967350483, -0.016137944534420967, 0.04879704490303993, -0.05975334718823433, 0.004175975918769836, -0.14107725024223328, 0.03073824569582939, -0.08053441345691681, 0.03309984132647514, -0.1846834421157837, 0.05638711899518967, 0.10469675064086914, -0.16302897036075592, 0.03131226450204849, 0.016563275828957558, 0.13265272974967957, -0.16833364963531494, 0.08135878294706345, 0.001931088394485414, -0.09143127501010895, -0.18207675218582153, -0.02958429977297783, -0.045435160398483276, 0.059547241777181625, 0.08049473166465759, -0.03967085853219032, -0.09368675947189331, 0.058569468557834625, -0.24301882088184357, 0.029370907694101334, 0.15175308287143707, -0.07445834577083588, -0.0052800364792346954, -0.0042036063969135284, 0.04380445182323456, 0.0048468830063939095, 0.08196868002414703, 0.1518353521823883, -0.15492147207260132, -0.03751366212964058, 0.03927900269627571, 0.06919354945421219, -0.0029869689606130123, 0.03864041343331337, 0.054232727736234665, 0.032775409519672394, 0.1335018277168274, -0.007727744057774544, -0.0261260773986578, 0.14164480566978455, -0.007116893772035837, 0.10019341111183167, -0.06344819068908691, 0.07302942126989365, 0.03586490824818611, -0.016339872032403946, -0.18578702211380005, -0.1630214899778366, -0.02412310801446438, -0.011170893907546997, 0.10661840438842773, 0.044494882225990295, -0.1249145045876503, 0.07550782710313797, -0.08087713271379471, 0.20919929444789886, -0.025251805782318115, 0.05830945447087288, -0.007676565088331699, -0.0872245505452156, -0.20457157492637634, 0.13162259757518768, 0.041455917060375214, -0.119017094373703, -0.10109788179397583, 0.12692154943943024, -0.09738776087760925, 0.09473633021116257, -0.01888047717511654, 0.09894423186779022, -0.03755035623908043, 0.1643107682466507, 0.1600988358259201, -8.972328942036256e-05, 0.002808474935591221, -0.031830236315727234, 0.019032757729291916, 0.09875090420246124, 0.06558944284915924, 0.07126065343618393, 0.01535392552614212, -9.90401503031535e-08, 0.0377102866768837, -0.05809500813484192, -0.047150131314992905, 0.0028951053973287344, 0.24277271330356598, -0.01968637853860855, -0.0254592914134264, 0.061595965176820755, -0.014727377332746983, -0.05660398304462433, 0.10859213769435883, -0.009487391449511051, 0.00031854939879849553, -0.029222456738352776, -0.003388867015019059, 0.06814110279083252, -0.030338920652866364, -0.13412459194660187, -0.01585748791694641, -0.0010577405337244272, -0.02392934076488018, 0.016722822561860085, 0.025360798463225365, 0.06916158646345139, -0.03696107491850853, -0.08546348661184311, -0.00804154947400093, 0.02884628437459469, 0.2294400930404663, 0.0651683360338211, -0.04380824789404869, -0.03466973826289177, 0.1254923790693283, -0.04748276248574257, 0.15321926772594452, 0.06490882486104965, -0.0023186791222542524, 0.08385223895311356, -0.07809432595968246, 0.02934488095343113, -0.15800215303897858, 0.07272220402956009, 0.03411509469151497, -0.06620095670223236, 0.02248230203986168, -0.04068103805184364, -0.08396080136299133, -0.05124923214316368, 0.049647942185401917, -0.031730856746435165, 0.09789644926786423, 0.09354227781295776, -0.08018866181373596, 0.14724023640155792, 0.044503353536129, -0.06303281337022781, -0.260185182094574, -0.017197519540786743, 0.10665953904390335, 0.0718853697180748, -0.003725792048498988, -0.03551178425550461, -0.09151307493448257, -0.05555683746933937], metadata={'source': 'AAAMLP-569to.pdf', 'page': 94}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 95 And we had three features for each sample. But one-hot vectors, in this case, are of size 6. Thus, we have six features instead of 3.  Index F_0 F_1 F_2 F_3 F_4 F_5 0 0 0 0 0 1 0 1 0 1 0 0 0 0 2 1 0 0 0 0 0  So, we have six features, and in this 3x6 array, there are only 3 ones. Finding size using numpy is very similar to the binarization size calculation script. All you need to change is the array. Let’s take a look at this code.  ═════════════════════════════════════════════════════════════════════════ import numpy as np from scipy import sparse # create binary matrix example = np.array(     [         [0, 0, 0, 0, 1, 0],         [0, 1, 0, 0, 0, 0],         [1, 0, 0, 0, 0, 0]     ] )  # print size in bytes print(f\"Size of dense array: {example.nbytes}\")  # convert numpy array to sparse CSR matrix sparse_example = sparse.csr_matrix(example)  # print size of this sparse matrix print(f\"Size of sparse array: {sparse_example.data.nbytes}\")  full_size = (     sparse_example.data.nbytes +      sparse_example.indptr.nbytes +      sparse_example.indices.nbytes )  # print full size of this sparse matrix print(f\"Full size of sparse array: {full_size}\") ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[0.04847950115799904, 0.028052465990185738, -0.09219980239868164, 0.03308743238449097, 0.10590946674346924, -0.23088927567005157, -0.06862011551856995, -0.1553865522146225, -0.17378324270248413, -0.0024496044497936964, -0.044617362320423126, -0.05284646525979042, -0.021149709820747375, -0.09288709610700607, -0.036412499845027924, 0.06185648590326309, -0.035092007368803024, 0.08449777960777283, -0.13685008883476257, -0.014880724251270294, 0.060403116047382355, 0.027851566672325134, -0.042998459190130234, 0.017679985612630844, 0.08581729233264923, -0.018950683996081352, 0.10042516887187958, 0.09152812510728836, -0.1287434697151184, -0.09533679485321045, 0.09286660701036453, 0.11111710220575333, 0.05249873176217079, 0.044589996337890625, 0.011413661763072014, 0.09562893211841583, -0.026911688968539238, 0.06767864525318146, 0.020622489973902702, 0.035937875509262085, 0.013572284020483494, 0.14094804227352142, -0.046461280435323715, -0.005744301248341799, 0.044166676700115204, -0.04171709343791008, -0.07416418939828873, -0.09559216350317001, 0.10298227518796921, -0.1688787192106247, -0.03990718722343445, 0.05161653086543083, 0.0009125726646743715, 0.04297846928238869, -0.03976311534643173, -0.2718956172466278, -0.0655934065580368, -0.11788470298051834, -0.038874994963407516, -0.008729780092835426, -0.10374102741479874, -0.06254541128873825, 0.09221962094306946, 0.010319376364350319, 0.059339579194784164, 0.003774844342842698, 0.061482448130846024, 0.01005848590284586, -0.061369720846414566, 0.037644509226083755, 0.007826993241906166, 0.03922441229224205, -0.04123081639409065, 0.12610386312007904, 0.0367162711918354, -0.10879884660243988, 0.16245967149734497, 0.05756281316280365, 0.12410581111907959, 0.1458137482404709, -0.11983134597539902, 0.06584235280752182, -0.029557965695858, -0.05655830353498459, -0.01384289376437664, -0.1177469789981842, -0.06317286938428879, 0.10700592398643494, -0.07872627675533295, -0.09657258540391922, 0.021462151780724525, -0.03155980259180069, -0.08287271857261658, -0.033270031213760376, 0.06884653121232986, -0.05606920272111893, 0.09855513274669647, -0.012677821330726147, -0.08882029354572296, 0.12982460856437683, 0.08300501108169556, -0.06305163353681564, 0.06949056684970856, 0.10052817314863205, -0.004994906485080719, 0.13736283779144287, 0.17096473276615143, 0.08568252623081207, 0.12189078330993652, 0.001055801403708756, 0.055195342749357224, -0.024124033749103546, -0.03622903674840927, 0.09696870297193527, 0.12427890300750732, 0.020716754719614983, -0.05008632317185402, 0.11322569102048874, -0.024050641804933548, 0.11791103333234787, -0.10464518517255783, -0.07188370078802109, 0.020680202171206474, 0.11087985336780548, 0.0020641623996198177, 0.0234367772936821, -0.1197834461927414, 2.087198365365247e-32, 0.022764628753066063, 0.053600843995809555, -0.02807394415140152, -0.08601056784391403, 0.04576952010393143, -0.01161629892885685, 0.06878397613763809, 0.0566447414457798, 0.01987256295979023, 0.022957054898142815, -0.1895463615655899, 0.16609790921211243, -0.029124990105628967, 0.09194781631231308, -0.08282757550477982, -0.08518130332231522, 0.006929080002009869, 0.15315787494182587, -0.08785008639097214, -0.13769739866256714, -0.005606997758150101, 0.011384040117263794, -0.0543953999876976, -0.0064620282500982285, -0.17799215018749237, -0.1440337598323822, 0.035084303468465805, -0.1415741741657257, -0.1202172115445137, 0.03331632539629936, -0.17901480197906494, 0.01404515653848648, 0.09241494536399841, -0.006587844807654619, 0.07169714570045471, -0.16247710585594177, 0.037320371717214584, 0.09516796469688416, 0.018886571750044823, -0.21490031480789185, 0.034778546541929245, 0.09880407154560089, 0.09582051634788513, -0.16717997193336487, -0.006242041010409594, 0.022890904918313026, 0.0462762787938118, 0.11514844000339508, -0.01644359529018402, 0.11193116754293442, 0.09384261816740036, -0.09238073229789734, -0.0641966313123703, 0.08067698776721954, -0.02965943142771721, -0.015136747620999813, 0.182997465133667, -0.09873158484697342, 0.15654203295707703, 0.11742009967565536, -0.06418746709823608, -0.02121806889772415, 0.06887786090373993, 0.08027483522891998, 0.06527285277843475, -0.016892490908503532, 0.03826993703842163, 0.012953252531588078, 0.05230746045708656, 0.07802165299654007, -0.06734158843755722, 0.12193094938993454, 0.023368490859866142, -0.10366211086511612, 0.04066460579633713, -0.10559700429439545, 0.23623615503311157, -0.09123371541500092, -0.18299253284931183, -0.06047564744949341, 0.0004826119402423501, 0.09823635965585709, 0.031004175543785095, -0.21228866279125214, -0.16096344590187073, 0.023001695051789284, 0.05823193117976189, -0.13137023150920868, -0.1285899430513382, -0.12029729783535004, -0.10130053758621216, -0.006730660796165466, -0.05403479188680649, -0.25728192925453186, -0.019949128851294518, -1.7907184128103145e-32, 0.055887795984745026, 0.021412111818790436, -0.03079565428197384, 0.05802590772509575, -0.016249457374215126, -0.004076840355992317, 0.002021633554250002, 0.05320936068892479, 7.161599205574021e-05, -0.18773223459720612, -0.009458024054765701, -0.08772696554660797, 0.026680832728743553, -0.17498715221881866, 0.11766248941421509, -0.011755689978599548, -0.08581634610891342, 0.06571129709482193, 0.028991203755140305, 0.12198403477668762, -0.09243051707744598, 0.05659199133515358, 0.06538734585046768, -0.010334175080060959, -0.15470048785209656, -0.027079541236162186, -0.04202543571591377, 0.158422589302063, 0.13662312924861908, -0.046147577464580536, -0.0799097940325737, 0.008111351169645786, -0.20280876755714417, -0.020322730764746666, 0.09428715705871582, -0.0171644426882267, 0.0019496402237564325, -0.021636219695210457, -0.06075681373476982, -0.0032175760716199875, 0.051625847816467285, 0.08339875936508179, -0.22203513979911804, 0.011428272351622581, 0.028787672519683838, 0.012296999804675579, -0.03505585715174675, -0.016022944822907448, 0.09168584644794464, 0.030816784128546715, 0.12631027400493622, 0.048147983849048615, -0.005526476074010134, 0.15085136890411377, 0.013134723529219627, 0.050409186631441116, -0.03420817852020264, 0.04899359866976738, -0.022958021610975266, -0.06330358982086182, -0.20966437458992004, -0.14008691906929016, -0.02737429365515709, -0.11295617371797562, 0.06201157346367836, -0.05193701013922691, -0.1163170263171196, 0.04212867096066475, -0.03991873934864998, 0.19602704048156738, -0.05345500260591507, 0.014923273585736752, 0.0003534714342094958, -0.042543716728687286, -0.09805957973003387, 0.021000972017645836, 0.028675992041826248, -0.12508442997932434, -0.0232332032173872, 0.08470677584409714, -0.09790357947349548, 0.0974140390753746, -0.028398392722010612, 0.09943214058876038, 0.06331002712249756, 0.23905101418495178, 0.10542773455381393, 0.011006535030901432, 0.005906411446630955, 0.0464913509786129, 0.06206144019961357, 0.09050487726926804, 0.11505872756242752, -0.004257882479578257, -0.04712478443980217, -9.983343574049286e-08, 0.02289687655866146, 0.01708521880209446, 0.0014387802220880985, 0.04608992114663124, 0.1934504508972168, -0.06736038625240326, -0.005029874388128519, 0.10270634293556213, 0.0014827331760898232, -0.05770862475037575, 0.12175644189119339, 0.07576844841241837, -0.12353238463401794, -0.021598665043711662, 0.03696941211819649, 0.1418299376964569, -0.06857113540172577, -0.10455222427845001, -0.01342235691845417, 0.06986461579799652, 0.0001471715368097648, -0.024616636335849762, -0.04502881318330765, -0.035954900085926056, -0.05962030962109566, -0.09377846866846085, -0.037430521100759506, 0.06400592625141144, 0.17743150889873505, 0.03491906449198723, -0.030817721039056778, -0.08549635857343674, 0.12576733529567719, -0.02984621375799179, 0.16044862568378448, 0.01958591304719448, -0.02229270152747631, 0.058123793452978134, -0.09041981399059296, -0.020816568285226822, -0.13643516600131989, 0.04780913144350052, 0.017606087028980255, -0.0647280365228653, -0.03113682195544243, -0.024111833423376083, -0.02166084200143814, 0.006623445078730583, 0.09324076771736145, 0.0013430581893771887, 0.02983407862484455, 0.047332823276519775, -0.08314326405525208, 0.05334904417395592, 0.029072798788547516, -0.043314505368471146, -0.14865170419216156, -0.013270501047372818, 0.12198571860790253, 0.0957566425204277, 0.11867661029100418, 0.0027492200024425983, -0.07842082530260086, 0.044867467135190964], metadata={'source': 'AAAMLP-569to.pdf', 'page': 95}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 96 This will print the sizes as:  Size of dense array: 144 Size of sparse array: 24 Full size of sparse array: 52  We see that the dense array size is much larger than the one with binarization. However, the size of the sparse array is much less. Let’s try this with a much larger array. In this example, we will use OneHotEncoder from scikit-learn to transform our feature array with 1001 categories into dense and sparse matrices.  ═════════════════════════════════════════════════════════════════════════ import numpy as np from sklearn import preprocessing  # create random 1-d array with 1001 different categories (int) example = np.random.randint(1000, size=1000000)  # initialize OneHotEncoder from scikit-learn # keep sparse = False to get dense array ohe = preprocessing.OneHotEncoder(sparse=False)  # fit and transform data with dense one hot encoder ohe_example = ohe.fit_transform(example.reshape(-1, 1))  # print size in bytes for dense array print(f\"Size of dense array: {ohe_example.nbytes}\")  # initialize OneHotEncoder from scikit-learn # keep sparse = True to get sparse array ohe = preprocessing.OneHotEncoder(sparse=True)  # fit and transform data with sparse one-hot encoder ohe_example = ohe.fit_transform(example.reshape(-1, 1))  # print size of this sparse matrix print(f\"Size of sparse array: {ohe_example.data.nbytes}\")  full_size = (     ohe_example.data.nbytes +      ohe_example.indptr.nbytes + ohe_example.indices.nbytes )  # print full size of this sparse matrix print(f\"Full size of sparse array: {full_size}\") ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[0.10252263396978378, 0.00011954427463933825, -0.0430975966155529, 0.05294995754957199, 0.05272626504302025, -0.08852698653936386, 0.051998648792505264, -0.09726296365261078, -0.08467759937047958, -0.02799043245613575, -0.0004377524892333895, -0.028495164588093758, -0.04318602755665779, -0.0482146292924881, 0.06882104277610779, 0.02203708328306675, 0.016232050955295563, -0.03055754117667675, -0.06461986899375916, -0.12354923039674759, -0.04804624989628792, 0.013802234083414078, -0.1308945268392563, 0.07258948683738708, 0.033685386180877686, 0.1150016263127327, 0.05170254036784172, 0.05018383264541626, -0.10041018575429916, 0.04344310611486435, -0.035910382866859436, 0.08944334834814072, -0.14270558953285217, -0.06805764138698578, -0.03342689573764801, 0.04768557474017143, -0.022751498967409134, 0.036980971693992615, -0.09371896088123322, 0.03412109613418579, 0.052947998046875, 0.0071508027613162994, 0.08516882359981537, 0.05949007719755173, 0.15705259144306183, 0.05115174874663353, -0.04486778378486633, -0.06828869134187698, -0.051003891974687576, -0.18063895404338837, 0.007646334823220968, 0.12175456434488297, -0.046731553971767426, 0.11277451366186142, 0.011605233885347843, -0.30880701541900635, -0.026886364445090294, -0.1422697752714157, -0.08412352204322815, 0.09898453205823898, -0.1454956978559494, 0.07380494475364685, 0.08007639646530151, 0.06538385897874832, 0.02419021539390087, -0.032116204500198364, -0.008020119741559029, 0.07723932713270187, 0.006816921290010214, 0.029325371608138084, 0.06933656334877014, 0.1978214681148529, -0.078895203769207, 0.014754918403923512, 0.04726259037852287, -0.042003776878118515, 0.2079121470451355, -0.1126817986369133, 0.07654160261154175, 0.016642507165670395, -0.05485018342733383, 0.0868818461894989, -0.014830904081463814, -0.034939300268888474, -0.03215409815311432, -0.1172824501991272, 0.057393431663513184, 0.10350151360034943, -0.02740354649722576, -0.020937444642186165, 0.12927769124507904, 0.002590673277154565, 0.15069478750228882, -0.04329881817102432, 0.03633224591612816, 0.12527412176132202, 0.12417220324277878, -0.05969247967004776, 0.0003968573873862624, 0.050383009016513824, -0.043170250952243805, -0.1252613216638565, -0.13452716171741486, 0.0007145191775634885, 0.03418808430433273, -0.012853686697781086, 0.2040826380252838, 0.09609214216470718, 0.024944880977272987, -0.02651749737560749, -0.043411239981651306, -0.06990647315979004, -0.06096050143241882, 0.06757017970085144, 0.024234937503933907, -0.053355809301137924, 0.05618252977728844, 0.06525116413831711, 0.095282644033432, 0.043625153601169586, -0.08141452819108963, -0.04306235536932945, 0.10902328789234161, 0.0910077840089798, -0.017382487654685974, 0.04728441312909126, -0.1373489797115326, 1.3373897510996686e-32, -0.01958749257028103, 0.06583606451749802, -0.046044088900089264, -0.0492519736289978, 0.030953424051404, -0.0781063660979271, -0.021910730749368668, 0.025188786908984184, 0.14266501367092133, 0.15624555945396423, -0.1401880830526352, 0.14988304674625397, -0.09504665434360504, 0.08014027029275894, 0.10295486450195312, -0.1359260231256485, 0.018174083903431892, 0.13096758723258972, -0.1664334386587143, -0.03520473092794418, 0.002645515138283372, -0.003569949185475707, 0.056978873908519745, 0.06747491657733917, -0.04502898082137108, -0.12451167404651642, 0.040481965988874435, -0.07178130745887756, -0.2151310294866562, 0.015674877911806107, -0.09376503527164459, -0.08713984489440918, -0.033934611827135086, 0.01120753027498722, 0.0008493445347994566, -0.12303777784109116, 0.06850335001945496, -0.01832660660147667, 0.09189417213201523, 0.05800078809261322, -0.02011224441230297, 0.002461391733959317, 0.056944962590932846, 0.06701444834470749, -0.022765254601836205, 0.12153796851634979, -0.01597021147608757, 0.07705073803663254, -0.14088428020477295, 0.09930221736431122, -0.007842404767870903, -0.08456966280937195, 0.06463036686182022, 0.11572743207216263, -0.0762779638171196, -0.06854422390460968, -0.051111187785863876, -0.19012227654457092, 0.009091786108911037, 0.03353509679436684, -0.1149851530790329, -0.03166075795888901, 0.05867678299546242, -0.06829258799552917, 0.02821345068514347, -0.0067266072146594524, 0.08553137630224228, 0.008387891575694084, 0.10102032124996185, -0.1080598384141922, -0.03186139091849327, 0.038665179163217545, -0.006931327749043703, -0.17987170815467834, 0.07555635273456573, -0.1015469878911972, 0.20247764885425568, -0.006029350217431784, -0.17526449263095856, 0.00590664055198431, -0.02108779363334179, 0.049638256430625916, 0.06124160811305046, -0.06350784003734589, -0.06932717561721802, 0.060659654438495636, -0.039178770035505295, 0.04436164349317551, -0.1270773708820343, -0.05904132127761841, -0.2081700563430786, 0.13959212601184845, 0.08846571296453476, -0.23507080972194672, 0.053187571465969086, -1.3107304208437822e-32, -0.1049124225974083, -0.08634717762470245, 0.02886725217103958, -0.019366977736353874, 0.0013260308187454939, -0.047963615506887436, 0.00024504069006070495, -0.023402290418744087, 0.0894005075097084, -0.17843540012836456, -0.08103714138269424, 0.0057556177489459515, 0.06126309558749199, -0.03398189693689346, -0.034733232110738754, 0.05590908229351044, -0.2160508930683136, 0.09480102360248566, 0.06121679022908211, 0.14060461521148682, -0.1583273857831955, 0.10507675260305405, -0.051365166902542114, 0.012298788875341415, -0.09547784179449081, 0.017637260258197784, -0.009575232863426208, -0.05164352059364319, 0.0027488828636705875, -0.05772624909877777, 0.00991642102599144, -0.06354730576276779, -0.13247373700141907, -0.007962852716445923, 0.0024606981314718723, 0.022316711023449898, 0.0803716778755188, -0.027184203267097473, -0.13865618407726288, 0.015674276277422905, 0.09290239214897156, 0.08848731964826584, -0.14993055164813995, 0.06981641054153442, -0.03245525807142258, 0.11413915455341339, -0.021766725927591324, -0.09175962209701538, 0.09451880306005478, 0.08975264430046082, 0.0862293392419815, -0.09603388607501984, 0.022553343325853348, 0.18810148537158966, 0.05202491208910942, -0.027857035398483276, 0.0009854119271039963, -0.08676832914352417, -0.15489250421524048, 0.00022664482821710408, 0.006983248051255941, -0.039296962320804596, 0.05375269800424576, 0.03544028848409653, -0.06393954157829285, 0.0004595524806063622, -0.001741240150295198, -0.07823909819126129, -0.0842159241437912, -0.07190370559692383, -0.04228172451257706, -0.0473405085504055, 0.004734172020107508, 0.007018700707703829, -0.12846790254116058, 0.06480735540390015, 0.014581509865820408, -0.03169490396976471, -0.00989584531635046, 0.14177395403385162, 0.06998808681964874, 0.01627647504210472, -0.003825488733127713, 0.028678078204393387, -0.0597926527261734, 0.027298901230096817, 0.16375434398651123, -0.018418975174427032, -0.024793777614831924, 0.008823469281196594, 0.06273230165243149, 0.04710908234119415, 0.048957500606775284, 0.06359394639730453, -0.010525689460337162, -1.0037374664761956e-07, 0.05484563857316971, 0.018714098259806633, 0.03716081380844116, -0.09600171446800232, 0.0038584470748901367, 0.00502815842628479, -0.1197197362780571, 0.01078832894563675, 0.058118388056755066, 0.04942888766527176, 0.05619756132364273, 0.09157484769821167, 0.059951744973659515, 0.03280054032802582, 0.006822839844971895, 0.05712269991636276, 0.08169754594564438, -0.1123274564743042, -0.038299866020679474, 0.1256505250930786, 0.11129093915224075, -0.04273802042007446, -0.08277907967567444, -0.14775504171848297, 0.11887902766466141, -0.10756423324346542, 0.0544680580496788, 0.0889844074845314, 0.16404621303081512, -0.006189462263137102, -0.12129639834165573, -0.06594540923833847, -0.09649565815925598, 0.061932336539030075, 0.2406332790851593, 0.03528885543346405, 0.029561443254351616, -0.0706782341003418, -0.06334741413593292, -0.07362063229084015, -0.1378006786108017, -0.022876206785440445, 0.0924484133720398, -0.06946469098329544, 0.004261439666152, -0.07345695793628693, -0.043336451053619385, 0.04899660125374794, 0.13641920685768127, 0.13685183227062225, -0.026211323216557503, 0.06274738162755966, 0.026434285566210747, 0.07132560759782791, 0.018709633499383926, -0.020385395735502243, -0.13478265702724457, 0.0054821656085550785, 0.012778772041201591, -0.060041461139917374, 0.1359654664993286, 0.007005246821790934, -0.10416513681411743, -0.030954204499721527], metadata={'source': 'AAAMLP-569to.pdf', 'page': 96}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 97 And this code prints:  Size of dense array: 8000000000 Size of sparse array: 8000000 Full size of sparse array: 16000004  Dense array size here is approximately 8GB and sparse array is 8MB. If you had a choice, which one would you choose? Seems like a quite simple choice to me, isn’t it?  These three methods are the most important ways to handle categorical variables. There are, however, many other different methods you can use to handle categorical variables. An example of one such method is about converting categorical variables to numerical variables.  Suppose we go back to the categorical features dataframe (original cat-in-the-dat-ii) that we had. How many ids do we have in the dataframe where the value of ord_2 is Boiling Hot ?   We can easily calculate this value by calculating the shape of the dataframe where ord_2 column has the value Boiling Hot.  ═════════════════════════════════════════════════════════════════════════ In [X]: df[df.ord_2 == \"Boiling Hot\"].shape Out[X]: (84790, 25) ═════════════════════════════════════════════════════════════════════════  We see that there are 84790 rows with this value. We can also calculate this value for all the categories using groupby in pandas.  ═════════════════════════════════════════════════════════════════════════ In [X]: df.groupby([\"ord_2\"])[\"id\"].count() Out[X]: ord_2 Boiling Hot     84790 Cold            97822 Freezing       142726 Hot             67508 Lava Hot        64840 Warm           124239 Name: id, dtype: int64 ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[-0.027164602652192116, -0.0771140605211258, 0.1370009034872055, 0.03083115816116333, 0.07410578429698944, 0.01697455905377865, 0.060602083802223206, -0.08467184752225876, -0.04387060925364494, 0.05230046436190605, 0.1430041640996933, -0.05220295861363411, 0.02081143483519554, -0.122465580701828, 0.08427634090185165, 0.1039290502667427, -0.12960496544837952, 0.0041826823726296425, -0.04917218163609505, -0.19860872626304626, -0.05127323418855667, 0.131719172000885, -0.016110114753246307, -0.022467615082859993, 0.056468360126018524, 0.0827668085694313, 0.029475845396518707, 0.05731404200196266, -0.06248278170824051, -0.04599978029727936, -0.09063529223203659, 0.1005886048078537, -0.055608998984098434, -0.034526191651821136, -0.12003330886363983, 0.035173483192920685, -0.056055132299661636, -0.033653825521469116, 0.004890467040240765, 0.09118077158927917, 0.050064411014318466, -0.06274992972612381, 0.08251360803842545, -0.07192423194646835, 0.11617618054151535, 0.14164388179779053, -0.004578904248774052, -0.017219409346580505, -0.04360167682170868, -0.06309673190116882, 0.1566038578748703, 0.20289194583892822, -0.0861070454120636, 0.15390300750732422, 0.028575291857123375, -0.2886629104614258, 0.04916475713253021, -0.21036727726459503, 0.04298669099807739, 0.02666369453072548, -0.05475402623414993, 0.007040755823254585, 0.1303904950618744, -0.06577053666114807, -0.10731445252895355, 0.02648552507162094, -0.042513158172369, 0.06714648753404617, -0.02309805154800415, -0.01415444165468216, 0.02594289369881153, 0.10466267913579941, -0.006372817326337099, 0.03616849705576897, -0.0025962362997233868, -0.02107950486242771, 0.10924486070871353, -0.07584039121866226, 0.0825745165348053, -0.03465599566698074, -0.057921748608350754, 0.07356797158718109, 0.02832401916384697, 0.04658438265323639, -0.058059222996234894, -0.20800025761127472, 0.023425275459885597, 0.03283163160085678, -0.009989132173359394, -0.07175499200820923, -0.00669373944401741, 0.11450112611055374, 0.0878843441605568, -0.12807223200798035, 0.07209926843643188, -0.02027277462184429, 0.0745471715927124, 0.06279443204402924, 0.002908912720158696, 0.09041374176740646, -0.07334867119789124, -0.01943831518292427, -0.16308584809303284, -0.15976408123970032, -0.056316524744033813, 0.06809370964765549, 0.09549275785684586, 0.09903448075056076, 0.04410024732351303, -0.008884892798960209, -0.03347577527165413, -0.1185777336359024, 0.09169121086597443, 0.010510222055017948, -0.05048445984721184, -0.11002185195684433, 0.07808143645524979, 0.059955962002277374, 0.08788111805915833, -0.004314872436225414, 0.02074379101395607, -0.016294948756694794, 0.08445747196674347, 0.15788522362709045, 0.05439510568976402, 0.14217165112495422, 0.004000210668891668, 1.4244146835637135e-32, -0.1377263218164444, 0.04981224983930588, 0.01373455673456192, -0.09639501571655273, 0.0973709300160408, -0.1295395940542221, -0.010785172693431377, 0.03508082032203674, 0.05562569573521614, 0.012933049350976944, -0.0623386986553669, 0.10959625244140625, -0.034572307020425797, 0.04778052121400833, -0.023094991222023964, -0.15381309390068054, 0.041289862245321274, -0.04820273816585541, -0.06568840891122818, -0.0053420281037688255, 0.009334275498986244, -0.025645673274993896, 0.055805351585149765, 0.029385551810264587, -0.06736833602190018, -0.10027631372213364, -0.06081435829401016, -0.10755034536123276, -0.06880232691764832, -0.05619945749640465, -0.0805286392569542, -0.022282155230641365, -0.07459452748298645, -0.06215217337012291, -0.08420982211828232, -0.16913911700248718, 0.13977710902690887, -0.02537052519619465, 0.06741493940353394, 0.08073799312114716, -0.04243868961930275, 0.048521142452955246, -0.08714131265878677, -0.058955129235982895, -0.026541728526353836, 0.1450243443250656, 0.123763807117939, 0.02226201817393303, -0.14658544957637787, 0.10936501622200012, -0.05529910698533058, -0.21142596006393433, 0.011429653503000736, 0.15842336416244507, -0.09746948629617691, -0.04206835851073265, -0.07657163590192795, -0.140578493475914, 0.025496134534478188, 0.0438913069665432, -0.04317495971918106, 0.06515491753816605, -0.02896411530673504, -0.027363376691937447, 0.14974834024906158, -0.04269467294216156, 0.17674480378627777, 0.18076886236667633, -0.017053283751010895, -0.045664217323064804, -0.0027989642694592476, 0.00480674346908927, -0.01734091155230999, -0.09630323946475983, -0.0818924605846405, -0.08821025490760803, 0.06863231956958771, 0.07229422777891159, -0.178297221660614, 0.02649393491446972, -0.042261525988578796, 0.018757015466690063, 0.07748232036828995, -0.15895767509937286, 0.06386169046163559, 0.07955832779407501, -0.026834802702069283, -0.02049381472170353, -0.23571522533893585, -0.13484437763690948, -0.10762227326631546, 0.06422839313745499, 0.07956305146217346, -0.0627487450838089, 0.013161160983145237, -1.4731418631411743e-32, -0.12954047322273254, -0.07217473536729813, 0.08698874711990356, 0.004214477725327015, 0.19764597713947296, -0.05692898854613304, 0.004030950367450714, -0.002751951804384589, 0.11859211325645447, -0.03602888435125351, -0.04927384853363037, -0.09525580704212189, 0.14184589684009552, -0.10635783523321152, 0.03867673501372337, 0.05115077272057533, -0.18588872253894806, 0.2112157791852951, -0.07639720290899277, 0.13759557902812958, -0.015305208042263985, 0.19488172233104706, -0.03676484897732735, 0.15005742013454437, -0.11867818236351013, 0.07040906697511673, 0.05014855042099953, -0.06258067488670349, -0.020994164049625397, -0.018813524395227432, 0.03328069671988487, 0.022652022540569305, -0.06314779072999954, 0.06015360727906227, 0.04915435239672661, -0.019258152693510056, 0.10684894025325775, -0.0362834706902504, -0.2788025438785553, 0.032309383153915405, 0.05180421099066734, 0.13643097877502441, -0.03498200699687004, 0.10796097666025162, 0.006890755612403154, 0.06598705053329468, 0.030116677284240723, -0.06935802847146988, -0.115460105240345, 0.04273994639515877, -0.03709731251001358, 0.04431276023387909, 0.042585160583257675, 0.14929679036140442, -0.06669697165489197, 0.015605396591126919, -0.01795750856399536, -0.11360741406679153, -0.15116769075393677, -0.15506167709827423, 0.030124731361865997, -0.07936641573905945, 0.011193317361176014, 0.06969773769378662, 0.1179979145526886, 0.04940631985664368, -0.10644955188035965, -0.02448073774576187, -0.08273225277662277, 0.053325068205595016, -0.15754562616348267, -0.20975074172019958, -0.038784559816122055, -0.10343553870916367, -0.056734781712293625, 0.06380595266819, -0.026722967624664307, -0.03152012452483177, -0.13465477526187897, 0.13729432225227356, -0.09800048917531967, -0.1687733232975006, 0.07159022986888885, 0.05596457049250603, -0.1820010095834732, 0.03697558119893074, 0.10586095601320267, 0.05807378515601158, -0.03475842997431755, 0.010991091839969158, -0.02017173543572426, 0.0010888768592849374, 0.07132727652788162, 0.05929846316576004, 0.031292010098695755, -1.0059966371045448e-07, -0.07948818802833557, -0.03759559988975525, 0.033317480236291885, -0.15865878760814667, 0.08877506107091904, -0.033826738595962524, -0.12937574088573456, 0.02976991981267929, -0.057236649096012115, 0.09675394743680954, 0.07361200451850891, 0.077560655772686, 0.046043045818805695, 0.04224882647395134, -0.024328937754034996, 0.08828528225421906, 0.030859755352139473, 0.1110587939620018, -0.011786235496401787, -0.06544989347457886, 0.0711216926574707, -0.05605458468198776, 0.018411774188280106, -0.1425207555294037, -0.03177653253078461, -0.07940245419740677, 0.03012547455728054, -0.0565987192094326, 0.07452327013015747, 0.09203138202428818, -0.12289369106292725, -0.18092414736747742, -0.157337948679924, 0.058456551283597946, 0.27876317501068115, -0.03532222658395767, 0.11810482293367386, -0.08431407809257507, -0.010950686410069466, -0.04111581668257713, -0.15759439766407013, 0.16298380494117737, 0.024706948548555374, 0.10073459893465042, 0.07225499302148819, -0.03747883439064026, 0.004052010830491781, -0.018330002203583717, 0.15231142938137054, 0.05267847701907158, 0.10371218621730804, -0.09005334973335266, 0.04123480245471001, -0.08053646981716156, 0.003447874914854765, 0.1397704929113388, -0.11500943452119827, 0.09732692688703537, 0.11072506010532379, -0.08280928432941437, 0.09079677611589432, 0.012622319161891937, 0.058161672204732895, -0.00954594835639], metadata={'source': 'AAAMLP-569to.pdf', 'page': 97}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 98 If we just replace ord_2 column with its count values, we have converted it to a feature which is kind of numerical now. We can create a new column or replace this column by using the transform function of pandas along with groupby.  ═════════════════════════════════════════════════════════════════════════ In [X]: df.groupby([\"ord_2\"])[\"id\"].transform(\"count\") Out[X]: 0          67508.0 1         124239.0 2         142726.0 3          64840.0 4          97822.0             ... 599995    142726.0 599996     84790.0 599997    142726.0 599998    124239.0 599999     84790.0 Name: id, Length: 600000, dtype: float64 ═════════════════════════════════════════════════════════════════════════  You can add counts of all the features or can also replace them or maybe group by multiple columns and their counts. For example, the following code counts by grouping on ord_1 and ord_2 columns.  ═════════════════════════════════════════════════════════════════════════ In [X]: df.groupby(    ...:     [    ...:         \"ord_1\",    ...:         \"ord_2\"    ...:     ]    ...: )[\"id\"].count().reset_index(name=\"count\") Out[X]:           ord_1        ord_2  count 0   Contributor  Boiling Hot  15634 1   Contributor         Cold  17734 2   Contributor     Freezing  26082 3   Contributor          Hot  12428 4   Contributor     Lava Hot  11919 5   Contributor         Warm  22774 6        Expert  Boiling Hot  19477 7        Expert         Cold  22956 8        Expert     Freezing  33249 9        Expert          Hot  15792 10       Expert     Lava Hot  15078 11       Expert         Warm  28900'),\n",
       " VectorParams(vector=[0.09718579053878784, -0.07264623045921326, 0.07073303312063217, -0.010448266752064228, 0.05828418210148811, 0.13638082146644592, 0.017127297818660736, -0.07586830854415894, -0.17525503039360046, -0.00011426174023654312, 0.07121580839157104, -0.14241725206375122, 0.06781364232301712, -0.06688396632671356, 0.03377983719110489, 0.03948549926280975, -0.041686054319143295, 0.0234404094517231, -0.026123294606804848, -0.20473983883857727, -0.017630567774176598, -0.05829363688826561, -0.023729488253593445, 0.008909217081964016, 0.0037620088551193476, 0.07156357914209366, 0.04193264618515968, 0.14454017579555511, -0.03871312364935875, -0.016637403517961502, -0.026934046298265457, 0.0390087366104126, -0.005601661745458841, -0.009341154247522354, 0.0013554897159337997, 0.012765533290803432, -0.1886167824268341, 0.009116129018366337, -0.056241411715745926, -0.016122106462717056, 0.03166310861706734, -0.1073104590177536, 0.10467971116304398, 0.029051121324300766, 0.1906770020723343, 0.0925765335559845, -0.09842945635318756, 0.033146537840366364, -0.03991016000509262, -0.049278583377599716, -0.04083479940891266, 0.09946120530366898, 0.011542418971657753, 0.09377315640449524, 0.015575301833450794, -0.20004352927207947, -0.07664760947227478, -0.16419799625873566, -0.042253412306308746, -0.019589079543948174, -0.07356788963079453, 0.03161177039146423, 0.03359304368495941, -0.09041324257850647, 0.008658706210553646, -0.018425291404128075, -0.12164683640003204, 0.17857135832309723, -0.03812452778220177, 0.17749010026454926, 0.03679912909865379, 0.11306760460138321, -0.056655172258615494, -0.034725505858659744, -0.04538717493414879, 0.03915498033165932, 0.03712276741862297, -0.04535125195980072, 0.09604743123054504, 0.027907729148864746, -0.08428214490413666, 0.027979448437690735, 0.015761837363243103, 0.018340080976486206, -0.055953286588191986, -0.13336220383644104, 0.08427848666906357, -0.012814238667488098, -0.04173962399363518, 0.019235391169786453, -0.047015249729156494, 0.09556692093610764, 0.1639954149723053, -0.08486011624336243, 0.03652803972363472, 0.12528946995735168, 0.06621592491865158, -0.01334818359464407, 0.0019532146397978067, 0.10643789172172546, -0.05132914334535599, -0.0011216673301532865, -0.08533397316932678, -0.05915149301290512, -0.022198928520083427, 0.0745912715792656, 0.06639381498098373, 0.09078451246023178, 0.017589082941412926, -0.0947747528553009, -0.04749741777777672, -0.05395781621336937, 0.009812535718083382, -0.05257764458656311, -0.04495006799697876, -0.03818443790078163, -0.026735380291938782, 0.04381448030471802, 0.052255403250455856, 0.07606909424066544, 0.08491574227809906, 0.05567098781466484, 0.023028964176774025, 0.14585864543914795, 0.0013396393042057753, 0.061110854148864746, -0.08947700262069702, 1.177282498135079e-32, -0.024385347962379456, -0.04930031672120094, -0.051493871957063675, 0.0631326287984848, 0.063228078186512, -0.06997636705636978, 0.023769307881593704, 0.02742096036672592, 0.007582112681120634, 0.08454900979995728, -0.054435502737760544, 0.08480960875749588, -0.09515974670648575, 0.09413351118564606, 0.10313253849744797, -0.11553499847650528, 0.04714800789952278, -0.013630696572363377, -0.12204021215438843, -0.026987897232174873, -0.028397653251886368, -0.01348225586116314, 0.07199417799711227, 0.026828179135918617, 0.001189200091175735, 0.0034835392143577337, -0.14433401823043823, -0.12423060834407806, -0.10950842499732971, -0.002012190641835332, -0.034618280827999115, -0.02883392758667469, -0.1269591599702835, 0.028578191995620728, -0.002829853445291519, -0.1593851000070572, 0.10430566966533661, -0.06849826872348785, 0.11554610729217529, 0.0719505101442337, -0.057060953229665756, -0.10239516943693161, -0.073221355676651, 0.01376939658075571, -0.0677672028541565, 0.12712661921977997, 0.03979296237230301, -0.05109299346804619, -0.1664946973323822, 0.11972106993198395, 0.006907118950039148, -0.046418726444244385, 0.04340943694114685, 0.040102243423461914, -0.06530973315238953, -0.020477090030908585, -0.09431859850883484, -0.055751074105501175, 0.0023111088667064905, 0.05669597163796425, -0.03091399185359478, 0.08568393439054489, 0.0013609149027615786, -0.041164495050907135, 0.07161033153533936, -0.021041221916675568, 0.09351377934217453, 0.0806165486574173, 0.08562405407428741, -0.05974412336945534, -0.0324893593788147, 0.04096098244190216, -0.02989392727613449, -0.1421879678964615, -0.027841396629810333, -0.041640572249889374, 0.06708964705467224, -0.03643199801445007, -0.08107562363147736, 0.004744808655232191, -0.007356904447078705, -0.013347801752388477, 0.005094330292195082, -0.14039891958236694, -0.04219300299882889, 0.02971351519227028, 0.009943893179297447, -0.06337698549032211, -0.07783950865268707, 0.010353759862482548, -0.23709215223789215, -0.03185074403882027, 0.10393922030925751, 0.016772814095020294, 0.00245412765070796, -1.3175784101212913e-32, -0.13144129514694214, -0.07942872494459152, 0.12707515060901642, -0.030781084671616554, 0.17276810109615326, 0.023718714714050293, -0.02057131938636303, -0.02375231869518757, 0.059404175728559494, -0.02517099678516388, -0.045159485191106796, 0.0026725567877292633, 0.04758787900209427, -0.06031109020113945, 0.009970621205866337, 0.0472661554813385, -0.128448948264122, 0.18780836462974548, -0.054580796509981155, 0.22721540927886963, -0.013646501116454601, 0.22397442162036896, -0.11345582455396652, 0.1475304365158081, -0.05007798224687576, 0.052443914115428925, 0.12445678561925888, -0.07231639325618744, -0.013787730596959591, 0.0847446545958519, -0.008712892420589924, 0.021212702617049217, -0.06979577243328094, 0.04435119777917862, 0.03928796947002411, -0.011567133478820324, 0.022982317954301834, -0.10428769886493683, -0.13740435242652893, 0.12470639497041702, 0.1673642098903656, -0.016331331804394722, -0.07738924771547318, 0.10346197336912155, 0.02368091605603695, 0.06458257138729095, -0.01923496089875698, -0.06709437072277069, 0.015854645520448685, 0.013755491003394127, -0.012512098997831345, -0.016273563727736473, -0.06688887625932693, 0.0590742863714695, -0.06123610958456993, -0.038186050951480865, 0.03385770320892334, -0.14690102636814117, -0.030326802283525467, 0.02878206968307495, -0.021159615367650986, -0.05105205252766609, 0.05458663031458855, 0.027129022404551506, 0.13568152487277985, -0.040035828948020935, -0.13085827231407166, -0.014065208844840527, -0.11858399212360382, 0.02710273116827011, -0.054601095616817474, -0.0435125008225441, -0.07630407810211182, -0.04774719476699829, -0.05126142129302025, 0.031273309141397476, -0.15512537956237793, 0.01606876403093338, -0.050913263112306595, 0.04675186052918434, -0.09480997920036316, -0.059100255370140076, 0.09339676052331924, 0.08630196750164032, -0.024494580924510956, 0.02618212066590786, 0.16108538210391998, 0.013519449159502983, 0.010839954018592834, -0.021224457770586014, 0.01705787517130375, 0.020897282287478447, -0.0016448909882456064, 0.16330435872077942, -0.02934766188263893, -9.941149414771644e-08, -0.055027980357408524, -0.05176600068807602, -0.06773406267166138, 0.015741826966404915, 0.09797943383455276, -0.01600588858127594, -0.1285625547170639, -0.02972729504108429, -0.014116436243057251, 0.10508620738983154, 0.13414299488067627, 0.046649038791656494, 0.06912810355424881, 0.041396159678697586, 0.06524033099412918, 0.023260656744241714, -0.031995560973882675, 0.0921856164932251, -0.055766019970178604, -0.06751419603824615, 0.19108209013938904, 0.033125098794698715, 0.049490999430418015, -0.052768152207136154, 0.011931940913200378, -0.17999698221683502, 0.005081141367554665, 9.821292042033747e-05, 0.08693907409906387, 0.11520297825336456, -0.022171996533870697, -0.13084076344966888, -0.11230755597352982, 0.028688037768006325, 0.2715687155723572, 0.0712033286690712, 0.07575097680091858, -0.10299468785524368, 0.005712403450161219, -0.06993036717176437, -0.184547558426857, 0.05407388135790825, -0.062096837908029556, 0.038401562720537186, 0.00650753965601325, -0.03069247119128704, -0.055119387805461884, -0.12662184238433838, 0.10412588715553284, 0.013131052255630493, -0.013529185205698013, -0.012882796116173267, 0.04516804590821266, -0.027660254389047623, 0.08038108795881271, 0.10107090324163437, -0.009937716647982597, 0.12056560814380646, 0.08431121706962585, -0.09296915680170059, 0.10232504457235336, -0.028795892372727394, 0.0018288410501554608, -0.024009699001908302], metadata={'source': 'AAAMLP-569to.pdf', 'page': 98}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 99 12  Grandmaster  Boiling Hot  13623 13  Grandmaster         Cold  15464 14  Grandmaster     Freezing  22818 15  Grandmaster          Hot  10805 16  Grandmaster     Lava Hot  10363 17  Grandmaster         Warm  19899 18       Master  Boiling Hot  10800 . . . . ═════════════════════════════════════════════════════════════════════════  Please note that I have eliminated some rows from the output to fit them in one page. This is another kind of count that you can add as a feature. You must have noted by now that I am using the id column for counts. You can, however, also count other columns by grouping by on combinations of the columns.  One more trick is to create new features from these categorical variables. You can create new categorical features from existing features, and this can be done in an effortless manner.  ═════════════════════════════════════════════════════════════════════════ In [X]: df[\"new_feature\"] = (    ...:     df.ord_1.astype(str)    ...:     + \"_\"    ...:     + df.ord_2.astype(str)    ...: )  In [X]: df.new_feature  Out[X]: 0                 Contributor_Hot 1                Grandmaster_Warm 2                    nan_Freezing 3                 Novice_Lava Hot 4                Grandmaster_Cold                    ... 599995            Novice_Freezing 599996         Novice_Boiling Hot 599997       Contributor_Freezing 599998                Master_Warm 599999    Contributor_Boiling Hot Name: new_feature, Length: 600000, dtype: object ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[0.10536088794469833, -0.0582021102309227, -0.05032101646065712, -0.052213288843631744, 0.0068488093093037605, 0.02362353540956974, 0.06264230608940125, -0.049674712121486664, -0.18398979306221008, -0.011794226244091988, 0.10698432475328445, -0.0767696350812912, 0.03148902580142021, -0.043842099606990814, 0.12446726858615875, 0.11274852603673935, -0.025538785383105278, 0.12697596848011017, -0.11390302330255508, -0.13272406160831451, 0.031415652483701706, 0.02700556442141533, -0.048750296235084534, 0.0686584934592247, -0.026674844324588776, 0.12627677619457245, 0.001312741544097662, 0.11246630549430847, -0.10192526876926422, 0.0031442500185221434, -0.020800797268748283, 0.04713056609034538, -0.004191361367702484, 0.0006112555856816471, -0.07536955922842026, -0.00655931793153286, -0.11032684892416, 0.09639684855937958, -0.1426037847995758, -0.021335149183869362, -0.058000512421131134, 0.03077903762459755, 0.1219923347234726, -0.020975463092327118, 0.10973183810710907, 0.06948154419660568, -0.06268007308244705, -0.06397870928049088, 0.06744419038295746, -0.11125867068767548, 0.03202029690146446, 0.1420825868844986, -0.03597955033183098, 0.1191522479057312, 0.054439742118120193, -0.12280985713005066, -0.12305564433336258, -0.21173067390918732, -0.04839030280709267, 0.03816575929522514, -0.13210512697696686, 0.04514487087726593, 0.11327110975980759, -0.1136847585439682, 0.11074524372816086, -0.007196546532213688, -0.09404562413692474, 0.07477755099534988, -0.06321382522583008, 0.09077494591474533, 0.00031796633265912533, 0.02801799401640892, -0.05869186297059059, -0.012109781615436077, -0.07290253043174744, 0.0876777246594429, 0.1649089902639389, -0.0655810609459877, 0.13626240193843842, 0.02498905546963215, -0.10069770365953445, 0.08927826583385468, -9.35638090595603e-05, -0.023677589371800423, -0.005571370013058186, -0.10695942491292953, 0.05405259132385254, 0.07785897701978683, -0.0017733839340507984, 0.008967560715973377, -0.051237206906080246, 0.05311255529522896, 0.2265540063381195, -0.14707757532596588, 0.044605664908885956, 0.030697697773575783, 0.02430306375026703, -0.011898597702383995, 0.07160428911447525, 0.06987651437520981, -0.011905177496373653, -0.0111722806468606, -0.025168590247631073, -0.10694973170757294, -0.019443165510892868, 0.037137847393751144, 0.13932539522647858, 0.11741244792938232, 0.09069747477769852, -0.06269676983356476, -0.011368043720722198, -0.08402328193187714, -0.08195815980434418, -0.08307532966136932, -0.05068212375044823, 0.03383820503950119, -0.08095679432153702, 0.04539863020181656, 0.14717987179756165, 0.09275111556053162, 0.04256267845630646, 0.037577755749225616, 0.04538041725754738, 0.07731256633996964, 0.0504315085709095, -0.03700513020157814, -0.11024453490972519, 6.841423406875777e-33, -0.15948575735092163, 0.0022984249517321587, -0.10573671013116837, 0.03597593680024147, 0.0395105741918087, 0.031221071258187294, 0.02209666185081005, 0.04368104040622711, 0.07175909727811813, 0.015883227810263634, -0.11113688349723816, 0.1464204490184784, -0.1782439798116684, 0.08336546272039413, 0.0332525335252285, -0.1574360579252243, 0.08060328662395477, -0.016626883298158646, -0.1033077985048294, -0.026014506816864014, 0.02692173235118389, 0.09061998128890991, 0.035418551415205, 0.05067284405231476, 0.07374437153339386, -0.22187569737434387, -0.10328016430139542, -0.10892102867364883, -0.06450881063938141, -0.04386448115110397, -0.1078927144408226, -0.10429640114307404, -0.04980593919754028, -0.05279543250799179, 0.034180041402578354, -0.1398986130952835, 0.13769197463989258, -0.0019027377711609006, 0.12379730492830276, 0.029853152111172676, -0.09540235251188278, -0.027638547122478485, -0.10093598067760468, 0.028564956039190292, -0.027984563261270523, 0.08606212586164474, 0.06288488209247589, 0.05197255313396454, -0.11863765120506287, 0.052748799324035645, 0.013584819622337818, -0.15228891372680664, 0.009239941835403442, 0.05882639437913895, -0.14117075502872467, 0.022617820650339127, -0.06721507757902145, -0.18517300486564636, -0.052701473236083984, 0.07119156420230865, -0.19496981799602509, 0.08682817965745926, -0.007279915269464254, 0.020084748044610023, 0.06967204809188843, 0.03911637142300606, 0.13451938331127167, 0.09349384158849716, 0.11448974907398224, -0.061720699071884155, -0.1191139742732048, -0.04437626153230667, -0.008209523744881153, -0.12267430871725082, -0.010049466975033283, -0.0769481211900711, 0.06275711953639984, -0.09337510913610458, -0.12141966074705124, -0.017490169033408165, -0.06402614712715149, 0.013338799588382244, 0.06442777812480927, -0.03680336847901344, -0.08202274143695831, 0.07531426846981049, 0.004123022314161062, -0.10083597153425217, -0.11245277523994446, -0.03335744887590408, -0.23681001365184784, 0.021248478442430496, 0.0337684229016304, -0.054213132709264755, 0.11508676409721375, -9.817672247402112e-33, -0.08997790515422821, -0.07272356003522873, 0.10643807798624039, -0.04288855567574501, 0.1058148592710495, 0.023038329556584358, 0.016369953751564026, -0.13559025526046753, -0.015734924003481865, -0.14368192851543427, -0.13203532993793488, -0.08119595050811768, 0.0502304881811142, -0.1783926784992218, 0.016254784539341927, 0.10961510986089706, -0.22625732421875, 0.25257954001426697, 0.020339148119091988, 0.23320035636425018, -0.03345109894871712, 0.21987636387348175, -0.12227203696966171, 0.08117365837097168, -0.006174413952976465, 0.047035202383995056, 0.08149480074644089, 0.0029118333477526903, 0.07438197731971741, 0.03115377575159073, -0.13612166047096252, -0.08782058954238892, -0.06165990233421326, 0.006790043320506811, -0.041461601853370667, -0.07619521021842957, 0.04793711006641388, -0.12071795761585236, -0.14994093775749207, -0.013247624970972538, 0.12296609580516815, 0.1332685351371765, -0.061309609562158585, 0.11311427503824234, 0.012082317844033241, 0.08291461318731308, -0.07055598497390747, 0.02078668586909771, 0.006648928392678499, 0.023570353165268898, 0.07644732296466827, -0.025399792939424515, -0.08866104483604431, 0.029770556837320328, -0.07206764072179794, -0.04229219630360603, 0.013133779168128967, -0.1258409023284912, -0.05603070929646492, 0.0006152664427645504, -0.01781802624464035, -0.06791766732931137, 0.1343095302581787, 0.05103740096092224, 0.1613493412733078, -0.0500609464943409, -0.08271405845880508, -0.038586363196372986, -0.08625675737857819, -0.011935212649405003, -0.019726881757378578, 0.021847659721970558, 0.023463565856218338, -0.036969251930713654, -0.0945400819182396, 0.009968645870685577, -0.034234099090099335, -0.035483941435813904, -0.009844685904681683, 0.0747511237859726, -0.0747072696685791, 0.024271203204989433, 0.12028537690639496, 0.1687856763601303, -0.0797140970826149, 0.10536280274391174, 0.1719958484172821, 0.08603834360837936, 0.03886070474982262, -0.017986871302127838, 0.03984424099326134, 0.05530305579304695, 0.10254452377557755, 0.08710608631372452, -0.08090908080339432, -9.973594217171922e-08, 0.0671766921877861, 0.016532601788640022, -0.07455438375473022, -0.08839548379182816, 0.030136536806821823, -0.01747884973883629, -0.14122550189495087, -0.03943049907684326, 0.08058551698923111, 0.1004985049366951, 0.11608725786209106, 0.1284245401620865, -0.04328553006052971, -0.05650850757956505, 0.0562119223177433, 0.05289801210165024, 0.03468289598822594, 0.0021362246479839087, -0.02636054717004299, -0.05073992535471916, 0.18557798862457275, -0.058657851070165634, -0.06454502046108246, 0.0031693261116743088, 0.013953992165625095, -0.08053841441869736, 0.039612144231796265, 0.07050752639770508, 0.15018993616104126, 0.16825349628925323, -0.004455716349184513, -0.15569014847278595, -0.10870655626058578, -0.002995293354615569, 0.36280837655067444, 0.00672588124871254, 0.0918579250574112, -0.11506833881139755, -0.04398488998413086, -0.015387659892439842, -0.07586207985877991, 0.06844735890626907, 0.02217334695160389, -0.010592973791062832, 0.07835175842046738, -0.12801042199134827, -0.07284074276685715, -0.03732570260763168, 0.1679460108280182, 0.11027424782514572, -0.01983909122645855, 0.02239704504609108, -0.019498230889439583, 0.017194613814353943, -0.021714376285672188, 0.06125043332576752, -0.06248651072382927, 0.03399045765399933, -0.0052663725800812244, -0.07418112456798553, 0.11557251960039139, -0.05107933655381203, 0.004396955482661724, 0.05888769403100014], metadata={'source': 'AAAMLP-569to.pdf', 'page': 99}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 100 Here, we have combined ord_1 and ord_2 by an underscore, and before that, we convert these columns to string types. Note that NaN will also convert to string. But it’s okay. We can also treat NaN as a new category. Thus, we have a new feature which is a combination of these two features. You can also combine more than three columns or four or even more.  ═════════════════════════════════════════════════════════════════════════ In [X]: df[\"new_feature\"] = (     ...:     df.ord_1.astype(str)     ...:     + \"_\"     ...:     + df.ord_2.astype(str)     ...:     + \"_\"     ...:     + df.ord_3.astype(str)     ...: )  In [X]: df.new_feature Out[X]: 0                 Contributor_Hot_c 1                Grandmaster_Warm_e 2                    nan_Freezing_n 3                 Novice_Lava Hot_a 4                Grandmaster_Cold_h                     ... 599995            Novice_Freezing_a 599996         Novice_Boiling Hot_n 599997       Contributor_Freezing_n 599998                Master_Warm_m 599999    Contributor_Boiling Hot_b Name: new_feature, Length: 600000, dtype: object ═════════════════════════════════════════════════════════════════════════  So which categories should we combine? Well, there isn\\'t an easy answer to that. It depends on your data and the types of features. Some domain knowledge might be useful for creating features like this. But if you don’t have concerns about memory and CPU usage, you can go for a greedy approach where you can create many such combinations and then use a model to decide which features are useful and keep them. We will read about it later in this book.  Whenever you get categorical variables, follow these simple steps: • fill the NaN values (this is very important!) • convert them to integers by applying label encoding using LabelEncoder of scikit-learn or by using a mapping dictionary. If you didn’t fill up NaN values with something, you might have to take care of them in this step'),\n",
       " VectorParams(vector=[-0.028894104063510895, -0.0678737536072731, -0.017227603122591972, 0.021666940301656723, 0.0599072203040123, -0.05498684197664261, 0.031211264431476593, -0.10781412571668625, -0.06347213685512543, -0.030619438737630844, 0.09408560395240784, -0.0998900756239891, -0.0318516306579113, -0.09831470996141434, 0.08248749375343323, -0.007494000252336264, -0.09833333641290665, 0.05005485936999321, -0.06989641487598419, -0.12067694216966629, 0.0013256180100142956, 0.06917078047990799, -0.07190608233213425, 0.16483363509178162, -0.029796786606311798, 0.055337365716695786, 0.05179140716791153, 0.1142890602350235, -0.02722184732556343, -0.04304610565304756, -0.048956822603940964, 0.13326963782310486, -0.13611756265163422, -0.03961166739463806, -0.002330153714865446, 0.010367103852331638, -0.004112785682082176, 0.08470877259969711, -0.11391506344079971, 0.024337390437722206, -0.003958537243306637, -0.08839230239391327, 0.16340604424476624, -0.019387641921639442, 0.101287841796875, 0.053797647356987, 0.05971112102270126, -0.18332268297672272, 0.05285234749317169, -0.16505324840545654, 0.12762901186943054, 0.15674659609794617, -0.09762967377901077, 0.16092319786548615, -0.038449183106422424, -0.19522853195667267, 0.05595644935965538, -0.18965913355350494, 0.022013412788510323, 0.06820128858089447, -0.21125608682632446, 0.08750558644533157, 0.06999246776103973, -0.05984506756067276, 0.045343682169914246, 0.02263319492340088, -0.09123505651950836, 0.024889366701245308, -0.00021217341418378055, 0.05972183868288994, 0.08167654275894165, -0.014135967940092087, -0.025689763948321342, 0.026188651099801064, -0.06186378747224808, -0.042113546282052994, 0.2603975236415863, -0.12417690455913544, 0.1454775482416153, 0.032667502760887146, -0.16865216195583344, 0.004066566005349159, 0.04156089201569557, 0.029020071029663086, -0.08832185715436935, -0.050271447747945786, 0.03979911282658577, 0.050489578396081924, 0.09817322343587875, 0.02633143588900566, 0.11289974302053452, 0.036225274205207825, 0.08846670389175415, 0.03421216085553169, 0.1016363874077797, 0.073284812271595, 0.09306133538484573, 0.010303637012839317, 0.006502489559352398, 0.0846230611205101, -0.002472600433975458, -0.022656865417957306, -0.14939852058887482, 0.0028402728494256735, 0.015332079492509365, -0.02194991335272789, 0.23071610927581787, -0.03747114911675453, 0.07793348282575607, 0.048468951135873795, -0.04570871964097023, 0.007751420605927706, -0.08651602268218994, -0.003991558216512203, -0.069525346159935, -0.020679708570241928, -0.012157848104834557, -0.003562706056982279, -0.13233761489391327, 0.04381391033530235, -0.1395779252052307, 0.10226402431726456, 0.021142370998859406, 0.1781930923461914, 0.03549056127667427, -0.11967281997203827, -0.05147121846675873, 1.1464936562247539e-32, -0.09513280540704727, -0.04378361627459526, -0.04509951174259186, -0.13060146570205688, 0.11983318626880646, -0.02463953197002411, -0.010308469645678997, 0.019007984548807144, 0.11595156043767929, 0.09940695762634277, -0.0691523626446724, 0.06781036406755447, -0.1988442838191986, -0.03828047215938568, 0.0014553184155374765, -0.14814670383930206, 0.02554943598806858, -0.11459150165319443, -0.0780782550573349, -0.0024852966889739037, 0.0536830872297287, -0.05406412109732628, 0.013326358050107956, 0.0028237614315003157, -0.034510377794504166, -0.025075387209653854, -0.06607189029455185, -0.028814779594540596, -0.07229876518249512, 0.038074593991041183, -0.174178346991539, -0.15282538533210754, 0.022479303181171417, -0.05280592665076256, 0.03804530203342438, -0.14638395607471466, 0.09763284772634506, 0.13530993461608887, 0.0012485383776947856, 0.01183561235666275, -0.03083963133394718, 0.05581820383667946, -0.0029105183202773333, 0.03367092087864876, 0.034443631768226624, 0.08876251429319382, 0.13924355804920197, 0.11769165098667145, -0.12666259706020355, 0.07354244589805603, -0.0588018000125885, -0.11672210693359375, -0.0558556392788887, -0.017209641635417938, -0.15400779247283936, -0.044062331318855286, 0.01450671162456274, -0.25066131353378296, -0.052910663187503815, 0.04832366108894348, -0.08996298909187317, -0.024287929758429527, 0.01220001932233572, -0.01182392705231905, 0.02106572687625885, -0.015772365033626556, 0.021913748234510422, 0.0017801463836804032, 0.09617570787668228, -0.10770142078399658, -0.11217512935400009, -0.029959997162222862, -0.0108235077932477, -0.12639327347278595, 0.07070670276880264, -0.09705706685781479, 0.06692780554294586, -0.048656441271305084, -0.07464447617530823, -0.006979479920119047, 0.10839109122753143, -0.04348302632570267, 0.0026603511068969965, -0.054806750267744064, 0.0163411907851696, 0.015396775677800179, 0.03857044130563736, -0.053513433784246445, -0.12556080520153046, -0.007029354106634855, -0.08478090912103653, -0.013716415502130985, 0.03627194091677666, -0.16244859993457794, 0.012774916365742683, -1.2214133478640309e-32, -0.07469704002141953, 0.012223492376506329, 0.024317076429724693, 0.009130577556788921, -0.004106607753783464, -0.021168110892176628, 0.1219790056347847, 0.05587116628885269, 0.10922612249851227, -0.15614202618598938, -0.012094700708985329, -0.1295442283153534, -0.006628061644732952, -0.1475260704755783, -0.0445198118686676, 0.06272850185632706, -0.18761517107486725, 0.12341758608818054, -0.023600611835718155, 0.15764807164669037, -0.13140158355236053, 0.16066287457942963, -0.24078434705734253, -0.006658999715000391, -0.15834632515907288, 0.12433182448148727, -0.012292020954191685, 0.15814939141273499, 0.07008298486471176, 0.014644085429608822, -0.10242610424757004, -0.06041537970304489, -0.06467469781637192, -0.07632958143949509, 0.023458795621991158, -0.0440545380115509, 0.19741159677505493, -0.05104454234242439, -0.15851466357707977, 0.013989107683300972, 0.17212116718292236, 0.0786033570766449, -0.2104097455739975, 0.13301990926265717, -0.031808577477931976, 0.13255609571933746, -0.08253598213195801, 0.11456706374883652, 0.032520320266485214, 0.012868933379650116, 0.13416169583797455, -0.02847076579928398, -0.08210103958845139, 0.13420583307743073, -0.002677180105820298, -0.03569238632917404, -0.042050790041685104, 0.0016230180626735091, -0.1263856589794159, 0.02567947283387184, -0.032944049686193466, -0.06976255029439926, 0.02685784175992012, -0.030090127140283585, 0.04319214075803757, -0.020268352702260017, -0.012734000571072102, 0.027108464390039444, 0.0355001762509346, -0.010427949018776417, -0.038094256073236465, 0.0029827465768903494, 0.03918703645467758, -0.1613648235797882, -0.02266191691160202, -0.04814126342535019, -0.03996540606021881, -0.09167375415563583, 0.02277733013033867, 0.06222929805517197, -0.023206397891044617, 0.03827753663063049, 0.0004773331165779382, 0.14431355893611908, 0.017374509945511818, 0.07725174725055695, 0.16151171922683716, 0.028506861999630928, 0.00171344680711627, -0.07348529249429703, 0.03731425851583481, 0.023086385801434517, 0.000855958613101393, 0.21481114625930786, -0.13609729707241058, -9.96579174739054e-08, -0.05308208987116814, -0.061230242252349854, 0.0546545647084713, 0.03813467174768448, 0.03493097424507141, 0.0029564793221652508, -0.08615174144506454, 0.06831910461187363, 0.038569699972867966, 0.053217630833387375, 0.16474704444408417, 0.17695920169353485, -0.0172346793115139, 0.01515974197536707, 0.016127077862620354, 0.06658793985843658, 0.14863523840904236, 0.05231127887964249, 0.02318459376692772, -0.017016520723700523, 0.0464632473886013, 0.014260774478316307, -0.0683966726064682, -0.14170444011688232, 0.023267900571227074, -0.058654818683862686, 0.05396198108792305, 0.12868525087833405, 0.18026326596736908, 0.0822722390294075, -0.04722439497709274, -0.13326144218444824, 0.0338328517973423, 0.04626644402742386, 0.1799946278333664, 0.06422040611505508, 0.022790132090449333, -0.05150025710463524, 0.03208751603960991, 0.021294619888067245, -0.0911833867430687, 0.11183419823646545, -0.06348839402198792, -0.047033295035362244, -0.004784590099006891, -0.055625684559345245, -0.03978676721453667, 0.05069481208920479, 0.1807687133550644, 0.1027020737528801, 0.05569103732705116, 0.046157535165548325, -0.004514469765126705, 0.06727902591228485, 0.0631905198097229, -0.08661288022994995, -0.07368773221969604, -0.028169406577944756, -0.1120791882276535, 0.08720263093709946, 0.14947332441806793, -0.05309310927987099, -0.09379250556230545, -0.0049841818399727345], metadata={'source': 'AAAMLP-569to.pdf', 'page': 100}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 101 • create one-hot encoding. Yes, you can skip binarization! • go for modelling! I mean the machine learning one. Not on the ramp.  Handling NaN data in categorical features is quite essential else you can get the infamous error from scikit-learn’s LabelEncoder:  ValueError: y contains previously unseen labels: [nan, nan, nan, nan, nan, nan, nan, nan]  This simply means that when you are transforming the test data, you have NaN values in it. It’s because you forgot to handle them during training. One simple way to handle NaN values would be to drop them. Well, it’s simple but not ideal. NaN values may have a lot of information in them, and you will lose it if you just drop these values. There might also be many situations where most of your data has NaN values, and thus, you cannot drop rows/samples with NaN values. Another way of handling NaN values is to treat them as a completely new category. This is the most preferred way of handling NaN values. And can be achieved in a very simple manner if you are using pandas.  Check this out on ord_2 column of the data we have been looking at till now.  ═════════════════════════════════════════════════════════════════════════ In [X]: df.ord_2.value_counts() Out[X]: Freezing       142726 Warm           124239 Cold            97822 Boiling Hot     84790 Hot             67508 Lava Hot        64840 Name: ord_2, dtype: int64 ═════════════════════════════════════════════════════════════════════════  And after filling the NaN values, it becomes:  ═════════════════════════════════════════════════════════════════════════ In [X]: df.ord_2.fillna(\"NONE\").value_counts() Out[X]: Freezing       142726 Warm           124239 Cold            97822 Boiling Hot     84790 Hot             67508'),\n",
       " VectorParams(vector=[-0.06233812868595123, -0.11809276789426804, 0.03530903905630112, 0.02828630805015564, 0.06630008667707443, -0.09572049230337143, -0.13467778265476227, -0.034672513604164124, 0.01223874744027853, 0.0035445289686322212, 0.0623660683631897, -0.1723361760377884, -0.037349633872509, -0.08996488898992538, 0.0013056423049420118, 0.025171805173158646, -0.041067030280828476, 0.02639380842447281, -0.18415479362010956, -0.08052702993154526, 0.025810351595282555, 0.09090538322925568, 0.009165042079985142, 0.10159873962402344, -0.04588939622044563, 0.007757449522614479, 0.04479898139834404, 0.07128798961639404, -0.0320446640253067, -0.12229813635349274, -0.1544336974620819, 0.16554519534111023, -0.11973206698894501, 0.0022587431594729424, 0.04325536638498306, -0.016617929562926292, -0.018234748393297195, 0.11425654590129852, -0.07403252273797989, 0.024581294506788254, -0.03538946807384491, -0.02580953575670719, 0.04151974990963936, -0.08724424988031387, 0.0878523737192154, -0.04449361562728882, -0.0789140909910202, -0.19312730431556702, 0.05890995264053345, -0.07053956389427185, -0.040538884699344635, 0.031152281910181046, -0.08364682644605637, 0.07766709476709366, -0.028653033077716827, -0.09536386281251907, -0.050614211708307266, -0.18621791899204254, -0.05861987546086311, 0.005272629205137491, -0.07230972498655319, 0.0076887174509465694, 0.10253589600324631, -0.0725354552268982, 0.08576246351003647, -0.0017915101489052176, -0.10231314599514008, 0.04410363361239433, 0.04165065661072731, 0.06426810473203659, 0.10447844862937927, 0.08448828756809235, -0.12714584171772003, 0.04718645662069321, -0.025644192472100258, 0.051397617906332016, 0.17590302228927612, -0.004125749226659536, 0.15283282101154327, -0.03152727708220482, -0.026184750720858574, 0.028626341372728348, -0.018926233053207397, -0.07033874839544296, 0.03002719208598137, -0.016443859785795212, 0.011869336478412151, 0.042229294776916504, 0.004668725188821554, 0.022325633093714714, 0.028153257444500923, 0.011567667126655579, 0.09086527675390244, 0.07843147218227386, 0.09377717971801758, 0.06154957041144371, 0.02767271175980568, 0.025908714160323143, 0.0583193339407444, 0.08460237830877304, -0.05652922764420509, 0.08063392341136932, 0.011056636460125446, -0.01453772746026516, 0.023237384855747223, 0.04896027594804764, 0.10800781846046448, 0.09497421234846115, 0.0866907611489296, -0.04282791540026665, 0.0668378546833992, -0.0004371499817352742, -0.07988808304071426, -0.029652701690793037, -0.07645682245492935, -0.006124344188719988, -0.05098656937479973, -0.048374369740486145, -0.10223211348056793, 0.10467266291379929, -0.09614875167608261, 0.055817894637584686, 0.06495009362697601, 0.10448563098907471, -0.014532596804201603, -0.05567048490047455, -0.09996259957551956, 6.56702776056333e-33, 0.021236488595604897, -0.13783814013004303, -0.07823865115642548, -0.057472240179777145, 0.10631149262189865, -0.042650263756513596, 0.006506228819489479, 0.0823458656668663, 0.04555602744221687, 0.024573123082518578, -0.11285992711782455, 0.026002204045653343, -0.09365294873714447, -0.017661254853010178, 0.0219707190990448, -0.07328469306230545, 0.04739280417561531, 0.0033903857693076134, -0.1431206464767456, 0.009876178577542305, 0.05371427163481712, 0.03376585990190506, -0.054288510233163834, -0.044838838279247284, 0.03934255614876747, 0.11799442768096924, 0.0029439092613756657, -0.003344425465911627, -0.10328896343708038, 0.06268849968910217, -0.03604690730571747, -0.02939232811331749, 0.07393384724855423, -0.03263654187321663, 0.062234118580818176, -0.056663259863853455, 0.06177882105112076, 0.07795049250125885, 0.04573294520378113, 0.015329897403717041, -0.04544183984398842, 0.045383624732494354, -0.05259188264608383, -0.0007544985273852944, 0.044996850192546844, 0.01791110634803772, 0.2016366571187973, 0.07645577937364578, -0.13964299857616425, 0.07140300422906876, -0.012990663759410381, -0.049964480102062225, -0.02696196921169758, 0.07870020717382431, -0.15318994224071503, -0.05041702091693878, -0.0025566888507455587, -0.19902192056179047, 0.07677910476922989, 0.13884559273719788, -0.0008810859872028232, 0.06883415579795837, 0.0066405534744262695, 0.10410045832395554, 0.04323161393404007, 0.016056561842560768, 0.066615030169487, 0.06593471765518188, 0.08587632328271866, 0.030440503731369972, -0.0214619692414999, -0.08267472684383392, -0.03306505084037781, -0.07479451596736908, 0.09269501268863678, -0.15419553220272064, 0.09884727001190186, -0.05656513199210167, -0.13703706860542297, 0.005892305169254541, 0.00494891544803977, -0.049330540001392365, -0.054787129163742065, -0.06080372631549835, -0.0389784537255764, 0.12132959067821503, 0.013096329756081104, -0.05902133136987686, -0.08917510509490967, 0.05332312732934952, 0.0052659776993095875, 0.010189064778387547, -0.05863518267869949, -0.05534207448363304, 0.10720648616552353, -6.529086476338633e-33, -0.059643592685461044, 0.06916340440511703, 0.018583456054329872, -0.024453304708003998, 0.009668332524597645, -0.05160191282629967, 0.04164111986756325, 0.009634388610720634, -0.015311668626964092, -0.1496472805738449, -0.053821057081222534, 0.003142977599054575, 0.015688536688685417, -0.09760339558124542, -0.01915261521935463, 0.019973108544945717, -0.1060914620757103, 0.005575197748839855, -0.0008621750166639686, 0.16762547194957733, 0.0021075711119920015, 0.15961070358753204, -0.2243996113538742, 0.0989687591791153, -0.07005482167005539, 0.15621885657310486, -0.10035644471645355, 0.016646523028612137, 0.048994120210409164, -0.08129365742206573, -0.015558368526399136, -0.050369054079055786, -0.06112818047404289, -0.05758298188447952, -0.003763781161978841, -0.06333938241004944, 0.12735499441623688, -0.11497700214385986, -0.044043250381946564, 0.04085875675082207, 0.028592227026820183, 0.04622010141611099, -0.16003842651844025, 0.06341706961393356, -0.0713294968008995, 0.012866118922829628, 0.05100766569375992, 0.025367114692926407, 0.0784267783164978, -0.06113184243440628, 0.0768248662352562, -0.011297954246401787, 0.0018343513365834951, 0.08928577601909637, 0.027176786214113235, 0.03214748948812485, -0.006621206179261208, -0.011385303921997547, -0.0673166960477829, 0.11290185153484344, 0.04911656677722931, -0.02091713808476925, -0.015144068747758865, -0.062460411339998245, 0.04667544737458229, 0.025388753041625023, -0.037102147936820984, 2.5569758577148605e-07, 0.009343915618956089, 0.0030648093670606613, -0.07671502977609634, 0.09578050673007965, -0.061908915638923645, -0.09520089626312256, -0.05205703154206276, -0.07178530097007751, -0.09311855584383011, -0.07534398138523102, 0.06564052402973175, 0.08947942405939102, -0.14853939414024353, -0.012714813463389874, 0.06260237097740173, 0.06696804612874985, 0.02961118333041668, 0.06382637470960617, 0.1926945596933365, 0.04938153922557831, -0.06425100564956665, 0.03999854624271393, -0.05017796903848648, -0.01204744540154934, -0.06912495195865631, 0.09250526130199432, -0.09913945943117142, -9.937489409139744e-08, -0.0074830614030361176, 0.023708079010248184, -0.034553904086351395, 0.01430661790072918, 0.11537320911884308, -0.08860057592391968, -0.09049572050571442, 0.20286157727241516, -0.02369740977883339, 0.05201449245214462, 0.07298494875431061, 0.12649594247341156, -0.10913071781396866, 0.0647667944431305, 0.09584737569093704, 0.03795938193798065, 0.05203358829021454, -0.019153708592057228, -0.05938589200377464, -0.033019792288541794, 0.06275216490030289, 0.02500307373702526, 0.016285356134176254, -0.03179651498794556, 0.015075287781655788, -0.08533494919538498, 0.11269108951091766, 0.15929003059864044, 0.07218169420957565, 0.0075736199505627155, -0.04296264797449112, -0.15999989211559296, -0.039560455828905106, -0.010130174458026886, 0.17383234202861786, 0.09789282083511353, -0.0010012616403400898, -0.127942755818367, -0.040331799536943436, -0.030484801158308983, -0.019495923072099686, 0.04142417386174202, 0.043430399149656296, 0.02635628916323185, 0.0004335312114562839, -0.06668082624673843, -0.08576516807079315, -0.041583385318517685, 0.06094669923186302, 0.015002163127064705, -0.043612442910671234, -0.004913039039820433, -0.08322781324386597, 0.14106331765651703, 0.09730181843042374, 0.004387169145047665, 0.009415571577847004, -0.06653276085853577, -0.03717047721147537, 0.09233734756708145, 0.24608445167541504, -0.11016770452260971, -0.06666971743106842, 0.006909637246280909], metadata={'source': 'AAAMLP-569to.pdf', 'page': 101}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 102 Lava Hot        64840 NONE            18075 Name: ord_2, dtype: int64 ═════════════════════════════════════════════════════════════════════════  Wow! There were 18075 NaN values in this column that we didn’t even consider using previously. With the addition of this new category, the total number of categories have now increased from 6 to 7. This is okay because now when we build our models, we will also consider NaN. The more relevant information we have, the better the model is.  Let’s assume that ord_2 did not have any NaN values. We see that all categories in this column have a significant count. There are no “rare” categories; i.e. the categories which appear only a small percentage of the total number of samples. Now, let’s assume that you have deployed this model which uses this column in production and when the model or the project is live, you get a category in ord_2 column that is not present in train. You model pipeline, in this case, will throw an error and there is nothing that you can do about it. If this happens, then probably something is wrong with your pipeline in production. If this is expected, then you must modify your model pipeline and include a new category to these six categories.   This new category is known as the “rare” category. A rare category is a category which is not seen very often and can include many different categories. You can also try to “predict” the unknown category by using a nearest neighbour model. Remember, if you predict this category, it will become one of the categories from the training data. \\n Figure 3: An illustration of a data set with different features and no targets where one feature might assume a new value when it’s seen in the test set or live data'),\n",
       " VectorParams(vector=[-0.022496435791254044, -0.03980620577931404, -0.04974821209907532, 0.09841664135456085, 0.11513171344995499, 0.020486371591687202, -0.06580869853496552, -0.04767715930938721, -0.050200920552015305, -0.10003454238176346, -0.029545703902840614, -0.1717175543308258, 0.018619442358613014, -0.09055377542972565, 0.03978496044874191, -0.053026363253593445, 0.05529879033565521, 0.08763962239027023, -0.1446485072374344, 0.011649048887193203, 0.04154209792613983, -0.03173144534230232, 0.041399188339710236, 0.1178068071603775, -0.12140294164419174, -0.0236352626234293, -0.022463573142886162, 0.07997854053974152, -0.06308160722255707, -0.03501797094941139, 0.0756908655166626, 0.005632112734019756, -0.09712056815624237, 0.023941241204738617, 0.02416914328932762, -0.026083720847964287, -0.0540420226752758, 0.09520398080348969, 0.03304448351264, 0.06417632848024368, -0.08841981738805771, -0.008950837887823582, 0.06654510647058487, -0.011278213001787663, 0.14288212358951569, 0.09415067732334137, -0.06416858732700348, -0.0689203143119812, -0.008518305607140064, -0.02433967962861061, 0.007463305722922087, -0.028264930471777916, -0.039938852190971375, 0.09870611876249313, -0.03998319059610367, -0.07420245558023453, 0.00859813392162323, -0.09494099020957947, -0.07783187180757523, 0.008377267979085445, -0.017539961263537407, -0.08044404536485672, 0.05675430968403816, -0.029192769899964333, 0.015834016725420952, 0.00132195302285254, -0.10491319000720978, 0.058564670383930206, 0.08343727886676788, 0.07671324163675308, -0.011917185969650745, 0.1361664980649948, -0.0829075500369072, 0.010519116185605526, 0.036083921790122986, 0.11545167863368988, 0.11581289768218994, 0.01718657650053501, 0.0005280783516354859, 0.025272000581026077, -0.018581578508019447, 0.04252208396792412, 0.017081117257475853, -0.022473784163594246, 0.03665906935930252, -0.019066721200942993, -0.031751248985528946, -0.05851557105779648, -0.10016103088855743, 0.006143528502434492, 0.05511310696601868, -0.07736890763044357, 0.012975174933671951, 0.011292582377791405, 0.10864095389842987, 0.09303346276283264, 0.14125847816467285, -0.0579940564930439, 0.05032094568014145, 0.03037058748304844, -0.03056391514837742, 0.014565551653504372, 0.09775320440530777, 0.017984772101044655, 0.04694516956806183, 0.0456276498734951, 0.00594194745644927, 0.0022256909869611263, 0.08669726550579071, -0.1190573200583458, 0.09845758229494095, -0.029708411544561386, -0.060849808156490326, -0.11762119084596634, -0.01819816417992115, 0.11358467489480972, -0.09345602244138718, -0.09224522113800049, -0.015318627469241619, 0.15018264949321747, -0.05920666828751564, 0.05238765478134155, 0.1160469725728035, 0.0010967835551127791, 0.10129993408918381, -0.02426997758448124, -0.125592440366745, 9.468058186948486e-33, -0.0045209601521492004, -0.10768672078847885, -0.029881803318858147, -0.03616277500987053, -0.044155098497867584, -0.13106200098991394, 0.03298003971576691, 0.02077815681695938, 0.03592503443360329, 0.02252407744526863, -0.06528369337320328, 0.03594137355685234, -0.08443192392587662, 0.007382113020867109, 0.02179553173482418, 0.03941115364432335, 0.037143755704164505, -0.12901920080184937, -0.09474875777959824, 0.047221001237630844, 0.16655129194259644, -0.05960638448596001, 0.054878462105989456, -0.04760245978832245, -0.026891225948929787, 0.01585802063345909, -0.003957522101700306, 0.005622873082756996, -0.05276310443878174, 0.05186491087079048, -0.08212693780660629, 0.06389786303043365, 0.05075756460428238, 0.10735013335943222, -0.0021361904218792915, 0.007955209352076054, 0.010498611256480217, -0.013258430175483227, 0.018101360648870468, 0.13736730813980103, 0.03832658380270004, -0.04316016286611557, 0.03115701861679554, -0.04782651737332344, 0.10331540554761887, -0.06806595623493195, 0.09717974811792374, -0.041459836065769196, -0.06310845166444778, 0.14855587482452393, 0.04878857731819153, -0.009269500151276588, -0.08935485780239105, -0.10992111265659332, -0.14805284142494202, 0.0647890567779541, -0.012300994247198105, -0.15293793380260468, -0.03938566520810127, 0.11675456911325455, -0.09798050671815872, -0.10057368874549866, -0.042469270527362823, 0.0736260861158371, -0.10970023274421692, -0.030490832403302193, 0.0465669184923172, -0.043681997805833817, 0.05187097564339638, -0.0472794771194458, -0.05883998051285744, -0.05647766590118408, -0.055502936244010925, -0.0015457251574844122, 0.12946175038814545, -0.009005839936435223, 0.08013661205768585, 0.04664740338921547, -0.08954346179962158, 0.010575457476079464, 0.1462584286928177, 0.044853080064058304, -0.031836237758398056, -0.03877780959010124, 0.0034990401472896338, -0.05209687352180481, 0.039559803903102875, -0.1886308789253235, -0.07577650994062424, -0.042499493807554245, -0.1557820737361908, 0.09507182985544205, -0.007095460779964924, -0.08886796981096268, 0.08375134319067001, -1.0874776684681333e-32, 0.020492713898420334, 0.03516215831041336, 0.012011205777525902, 0.04422346130013466, -0.034796781837940216, 0.021684305742383003, -0.007421089336276054, -0.005403259303420782, -0.13537220656871796, -0.09598098695278168, -0.05205371975898743, -0.11769066005945206, -0.01529050711542368, -0.0874684751033783, -0.15458711981773376, 0.030917616561055183, -0.1418035924434662, -0.008077832870185375, 0.04120013862848282, 0.10881507396697998, 0.041793808341026306, 0.13549324870109558, -0.09864916652441025, 0.08081486076116562, -0.1313176155090332, 0.0009840007405728102, -0.10492534190416336, 0.02135610207915306, 0.12875379621982574, -0.014866659417748451, -0.003908639773726463, -0.03010089509189129, -0.004701967351138592, -0.03304150328040123, 0.05381237715482712, -0.003186132526025176, 0.13170260190963745, -0.06852193921804428, 0.011192915961146355, 0.12776470184326172, 0.03457694128155708, 0.10902465134859085, -0.18163108825683594, -0.00450139120221138, -0.030910329893231392, -0.019291486591100693, -0.11830779910087585, 0.021080786362290382, 0.0592641718685627, -0.019342731684446335, 0.026336723938584328, -0.06056753173470497, -0.058013588190078735, 0.013802522793412209, 0.023972032591700554, 0.007774266414344311, 0.016249701380729675, 0.003554900409653783, -0.03577980399131775, 0.10244255512952805, -0.04601852223277092, 0.02848600596189499, 0.03285355120897293, 0.020463380962610245, 0.12371647357940674, 0.019916128367185593, -0.03391329571604729, 0.0035334662534296513, 0.08893933147192001, 0.034725405275821686, -0.13544109463691711, 0.005650781560689211, -0.08593852818012238, -0.09417706727981567, 0.05801038816571236, -0.0049092769622802734, -0.04368839040398598, -0.06792931258678436, 0.04502103850245476, 0.03359232097864151, -0.07018572092056274, -0.1307237148284912, -0.03941364958882332, 0.16222603619098663, 0.06669734418392181, 0.09904801100492477, 0.04385705664753914, 0.0887632891535759, -0.0265140850096941, -0.11238423734903336, -0.04229467362165451, 0.027683885768055916, 0.00788853783160448, 0.14760248363018036, -0.026650605723261833, -1.0013110340878484e-07, 0.012018362991511822, 0.06110461801290512, -0.03840316832065582, 0.02503926120698452, -0.024497007951140404, -0.108476422727108, -0.01794379949569702, -0.005860783159732819, -0.09993262588977814, 0.018826400861144066, -0.011167082004249096, 0.03186595067381859, -0.07707365602254868, 0.07125931233167648, 0.04715913534164429, 0.042521119117736816, 0.03708850219845772, 0.068129763007164, -0.050638895481824875, 0.1506735384464264, 0.07680445909500122, 0.019850799813866615, 0.02851906232535839, 0.023045213893055916, 0.11778898537158966, -0.05498317629098892, 0.021004490554332733, 0.07515261322259903, -0.004670746624469757, 0.06371909379959106, -0.03681327775120735, -0.1104826107621193, -0.006804500240832567, 0.02711145579814911, 0.0488898903131485, 0.0984545424580574, 0.06438643485307693, -0.11791766434907913, -0.12216170877218246, 0.09449978172779083, 0.04708698391914368, 0.011590915732085705, 0.02108711376786232, -0.07164615392684937, -0.006878765765577555, -0.08532168716192245, 0.028870703652501106, 0.04181452468037605, -0.07145564258098602, -0.04565750062465668, -0.1332448422908783, 0.04561144858598709, -0.0773647278547287, 0.11352675408124924, 0.039046578109264374, 0.06382008641958237, 0.01613422855734825, 0.03251025825738907, 0.001779816928319633, -0.014882134273648262, 0.09512762725353241, -0.12148583680391312, -0.028998292982578278, 0.03282897546887398], metadata={'source': 'AAAMLP-569to.pdf', 'page': 102}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 103 When we have a dataset like as shown in figure 3, we can build a simple model that’s trained on all features except “f3”. Thus, you will be creating a model that predicts “f3” when it’s not known or not available in training. I can’t say if this kind of model is going to give you an excellent performance but might be able to handle those missing values in test set or live data and one can’t say without trying just like everything else when it comes to machine learning.  If you have a fixed test set, you can add your test data to training to know about the categories in a given feature. This is very similar to semi-supervised learning in which you use data which is not available for training to improve your model. This will also take care of rare values that appear very less number of times in training data but are in abundance in test data. Your model will be more robust.   Many people think that this idea overfits. It may or may not overfit. There is a simple fix for that. If you design your cross-validation in such a way that it replicates the prediction process when you run your model on test data, then it’s never going to overfit. It means that the first step should be the separation of folds, and in each fold, you should apply the same pre-processing that you want to apply to test data. Suppose you want to concatenate training and test data, then in each fold you must concatenate training and validation data and also make sure that your validation dataset replicates the test set. In this specific case, you must design your validation sets in such a way that it has categories which are “unseen” in the training set.  \\n Figure 4: A simple concatenation of training and test sets to learn about the categories present in the test set but not in the training set or rare categories in the training set.'),\n",
       " VectorParams(vector=[-0.050815150141716, -0.019934525713324547, -0.005375276319682598, 0.007085699588060379, 0.1520811915397644, -0.04154638946056366, 0.062499020248651505, -0.034229155629873276, -0.1878504455089569, -0.11607412993907928, 0.07392361760139465, -0.09061288833618164, 0.022906193509697914, -0.1536540389060974, -0.00016595254419371486, 0.08003585785627365, -0.09768209606409073, 0.08229565620422363, -0.11796025186777115, -0.07941553741693497, -0.017628835514187813, 0.07567273825407028, -0.060136061161756516, 0.17169538140296936, -0.08603966981172562, -0.015305210836231709, 0.0770803689956665, 0.06728743761777878, -0.20123709738254547, -0.06072423607110977, 0.000542635447345674, 0.07300955057144165, -0.10989922285079956, 0.0401497520506382, 0.06908827275037766, 0.04355403035879135, -0.08775336295366287, 0.06843926012516022, 0.008411976508796215, 0.0978604406118393, 0.021228423342108727, -0.06374143809080124, 0.060140736401081085, -0.05558748543262482, 0.07894949615001678, 0.04702147841453552, -0.10416599363088608, -0.024453381076455116, -0.05791488662362099, -0.023025354370474815, -0.039430487900972366, 0.1246919110417366, -0.09409971535205841, 0.06518671661615372, -0.0777992382645607, -0.21202115714550018, 0.06647808104753494, -0.11535556614398956, 0.15309202671051025, 0.004786026664078236, -0.03819431737065315, -0.017218738794326782, 0.02302466332912445, -0.07631093263626099, -0.00977418851107359, -0.09688738733530045, -0.03436844423413277, 0.03492388129234314, 0.013225429691374302, 0.006825326010584831, -0.0062958975322544575, 0.07545900344848633, -0.06658381223678589, 0.11576487123966217, 0.006067750509828329, -0.024791724979877472, 0.1535070687532425, -0.02439231611788273, 0.10436222702264786, 0.008066206239163876, -0.17688320577144623, -0.06034979596734047, 0.051679350435733795, 0.0008993451483547688, 0.005866366904228926, -0.18937891721725464, -0.009494111873209476, 0.09174522757530212, -0.0006176858441904187, -0.013175912201404572, 0.05282185599207878, -0.018438002094626427, 0.06577730178833008, -0.011165155097842216, 0.10956665873527527, 0.16638454794883728, 0.08838126808404922, -0.0010028224205598235, 0.03191541135311127, 0.09180855751037598, -0.06393568217754364, -0.06361297518014908, 0.0053739408031105995, -0.032517220824956894, -0.04531300067901611, -0.05393560975790024, 0.21238455176353455, 0.019513094797730446, 0.18098527193069458, -0.13961952924728394, 0.040140241384506226, -0.16441316902637482, -0.05930311232805252, -0.02592746913433075, 0.0634843185544014, 0.043773356825113297, -0.10868271440267563, 0.07178909331560135, -0.11482932418584824, 0.07704503834247589, -0.07027813047170639, 0.015398160554468632, 0.009431804530322552, 0.09075559675693512, 0.03810354322195053, -0.04241364449262619, -0.08979063481092453, 1.513920202981581e-32, -0.09428679198026657, -0.07828743010759354, -0.018411530181765556, -0.1042475551366806, -0.010403811931610107, -0.11351537704467773, 0.01636761799454689, 0.08599348366260529, -0.035856135189533234, 0.10603045672178268, -0.12840059399604797, 0.12270588427782059, -0.09574342519044876, 0.0673602968454361, -0.038445621728897095, -0.011580869555473328, 0.008557059802114964, -0.0047975522466003895, -0.04082465171813965, 0.030025117099285126, 0.24461370706558228, 0.041527800261974335, -0.020353302359580994, -0.06883477419614792, -0.060486916452646255, -0.10368211567401886, -0.20188650488853455, -0.03050103783607483, -0.09889142215251923, -0.002184055047109723, -0.18695282936096191, 0.03148781135678291, -0.015964271500706673, -0.016417725011706352, -0.027587343007326126, -0.16437070071697235, 0.08807538449764252, 0.02036643587052822, -0.03232080489397049, -0.006167728919535875, 0.01929834671318531, 0.06452164798974991, 0.029018547385931015, -0.042902108281850815, 0.03802927955985069, 0.06375289708375931, 0.01326474454253912, 0.03406796231865883, -0.028625017032027245, 0.018394339829683304, 0.02059539593756199, -0.08043409883975983, 0.00675773061811924, -0.004154067486524582, -0.1460774689912796, 0.07417235523462296, 0.04043162986636162, -0.023359427228569984, 0.0745537132024765, 0.0504487045109272, 0.014319390058517456, -0.02939477004110813, 0.01778586581349373, 0.061061516404151917, 0.04342366382479668, -0.10022885352373123, 0.1598777025938034, 0.03836414963006973, 0.11159788817167282, -0.03608556464314461, -0.12833040952682495, -0.021658066660165787, -0.07198270410299301, -0.12916669249534607, 0.08687631040811539, -0.10384276509284973, 0.02964628115296364, -0.06972391158342361, -0.17944569885730743, 0.0026250015944242477, 0.08473198860883713, 0.19074763357639313, 0.025822358205914497, -0.11634662747383118, -0.03407762944698334, -0.015296528115868568, 0.01702658273279667, -0.13633787631988525, -0.13000118732452393, -0.1708226352930069, -0.17281097173690796, 0.008397461846470833, -0.08636714518070221, -0.0948944240808487, 0.1164538562297821, -1.5741488600978687e-32, 0.043303459882736206, 0.06253910064697266, 0.0825132355093956, 0.013760685920715332, 0.0962313860654831, 0.05889943987131119, 0.10626152157783508, 0.013980303891003132, 0.09867659211158752, -0.14109954237937927, 0.0006260370719246566, -0.18818093836307526, 0.011183383874595165, -0.02944135293364525, 0.004000901710242033, 0.08970851451158524, -0.2578383982181549, 0.15984992682933807, -0.1202663853764534, 0.09172241389751434, -0.07152828574180603, 0.156707301735878, -0.049150023609399796, 0.04700972139835358, -0.14450086653232574, 0.029731420800089836, 0.08651150017976761, 0.08515513688325882, 0.08099028468132019, -0.01038369257003069, -0.08586001396179199, 0.08849304914474487, -0.09883392602205276, 0.11613064259290695, -0.036252666264772415, -0.04340983182191849, 0.1373417228460312, -0.034164804965257645, -0.12969008088111877, 0.10714824497699738, 0.18471115827560425, 0.2324008345603943, -0.14831966161727905, 0.12184349447488785, 0.016850585117936134, 0.06507273018360138, 0.05880456790328026, 0.005936088506132364, -0.03974054753780365, 0.014384694397449493, 0.02985159493982792, -0.055961642414331436, -0.04644692316651344, -0.02714649960398674, -0.030002202838659286, 0.016424424946308136, -0.03824211284518242, -0.04977642372250557, -0.16385142505168915, -0.06665289402008057, -0.16647493839263916, 0.0076158177107572556, 0.10747458785772324, -0.009008289314806461, 0.13948196172714233, 0.06410825252532959, -0.09827127307653427, 0.02573683112859726, -0.05491873249411583, 0.005971513222903013, -0.10936952382326126, -0.05908996984362602, -0.008767854422330856, -0.05606285110116005, -0.036158859729766846, 0.014188267290592194, -0.06954018026590347, -0.06885716319084167, -0.10773129761219025, 0.06226874887943268, -0.040990445762872696, -0.10773152858018875, 0.019833536818623543, 0.14842967689037323, 0.03523228317499161, 0.1643235683441162, 0.08181273937225342, 0.1233937069773674, 0.01748233661055565, 0.010924811474978924, 0.013048944063484669, 0.0017359303310513496, 0.20587818324565887, 0.1676601618528366, -0.04648969694972038, -1.00769440791737e-07, -0.03565776348114014, 0.0755930170416832, -0.09194151312112808, 0.045925941318273544, -0.00409280601888895, 0.1039922758936882, -0.12075161933898926, -0.011063368059694767, -0.023600313812494278, 0.027178626507520676, 0.0043188342824578285, 0.05773760750889778, -0.059878185391426086, 0.07614956796169281, -0.0545150563120842, 0.11384450644254684, 0.008102774620056152, -0.043907929211854935, 0.0225406214594841, 0.1090421974658966, 0.07666769623756409, -0.04489326849579811, -0.026464242488145828, -0.017144199460744858, -0.028485102578997612, -0.09767362475395203, -0.12304744124412537, 0.10356032848358154, 0.10990551859140396, 0.10606028139591217, 0.03596626594662666, -0.16519425809383392, 0.0628693550825119, 0.04502655938267708, 0.19831068813800812, -0.022086238488554955, 0.1260850876569748, -0.07569754123687744, -0.0139027563855052, 0.05049319192767143, -0.06815901398658752, 0.15980471670627594, -0.09469930827617645, -0.09706035256385803, -0.03969009965658188, -0.08451364934444427, -0.017658594995737076, -0.025781389325857162, 0.19186517596244812, 0.0669015422463417, -0.08100499957799911, -0.021127739921212196, -0.09721626341342926, 0.008576851338148117, 0.16073650121688843, -0.03584175184369087, -0.0633501335978508, 0.022714857012033463, 0.016737766563892365, -0.0070629240944981575, 0.06609763205051422, 0.008372535929083824, 0.06076318398118019, -0.045964036136865616], metadata={'source': 'AAAMLP-569to.pdf', 'page': 103}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 104 How this works is can be understood easily by looking at figure 4 and the following code.  ═════════════════════════════════════════════════════════════════════════ import pandas as pd from sklearn import preprocessing  # read training data train = pd.read_csv(\"../input/cat_train.csv\")  #read test data test = pd.read_csv(\"../input/cat_test.csv\")  # create a fake target column for test data # since this column doesn\\'t exist test.loc[:, \"target\"] = -1  # concatenate both training and test data data = pd.concat([train, test]).reset_index(drop=True)  # make a list of features we are interested in # id and target is something we should not encode features = [x for x in train.columns if x not in [\"id\", \"target\"]]  # loop over the features list for feat in features:     # create a new instance of LabelEncoder for each feature     lbl_enc = preprocessing.LabelEncoder()          # note the trick here     # since its categorical data, we fillna with a string     # and we convert all the data to string type     # so, no matter its int or float, its converted to string     # int/float but categorical!!!     temp_col = data[feat].fillna(\"NONE\").astype(str).values      # we can use fit_transform here as we do not     # have any extra test data that we need to     # transform on separately     data.loc[:, feat] = lbl_enc.fit_transform(temp_col)       # split the training and test data again     train = data[data.target != -1].reset_index(drop=True) test = data[data.target == -1].reset_index(drop=True) ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[-0.1256989985704422, -0.05436647683382034, -0.06391067802906036, 0.14139215648174286, 0.054601993411779404, -0.05445835366845131, -0.04319334402680397, -0.05837554112076759, -0.009297551587224007, 0.03483669459819794, 0.09500037133693695, -0.08995045721530914, 0.04573975130915642, -0.07560139894485474, 0.04318094626069069, -0.006701902952045202, -0.001068856450729072, 0.004044987726956606, -0.15609237551689148, -0.09157436341047287, 0.039158280938863754, 0.08194872736930847, -0.04018315672874451, 0.05567632615566254, -0.0230731014162302, 0.0013248096220195293, 0.0007205517613328993, 0.006031435448676348, -0.06644118577241898, 0.013535968959331512, 0.04255041480064392, 0.12187784165143967, -0.143718883395195, 0.052441731095314026, 0.06960313767194748, -0.025136960670351982, -0.14906632900238037, 0.05772734805941582, -0.0271777156740427, 0.016182737424969673, -0.03008640930056572, -0.030385948717594147, -0.0005945151206105947, 0.028553826734423637, 0.07316675782203674, 0.07932551950216293, -0.06858693063259125, 0.03209567815065384, 0.007465217262506485, -0.08509629219770432, -0.05389009043574333, 0.05196681618690491, -0.06595397740602493, 0.12427787482738495, -0.09681681543588638, -0.11742258816957474, 0.0031590217258781195, -0.09714513272047043, -0.0914241150021553, 0.033255644142627716, -0.12292490154504776, -0.06816648691892624, 0.05231665447354317, 0.007109110243618488, -0.02440534345805645, 0.07550842314958572, -0.1531938910484314, 0.05726303905248642, 0.031110526993870735, 0.06096776947379112, -0.013148975558578968, 0.1621304154396057, -0.10444465279579163, 0.04226287081837654, 0.06076080724596977, -0.061588793992996216, 0.17221878468990326, -0.04159366711974144, 0.11921615898609161, 0.021245576441287994, -0.055134788155555725, -0.040082741528749466, -0.05399155989289284, -0.007769546937197447, 0.037695325911045074, -0.08539009094238281, 0.07272498309612274, 0.005497308447957039, 0.03995217755436897, -0.059988491237163544, 0.0547645166516304, -0.07838688790798187, 0.05103866755962372, 0.031750597059726715, 0.061376944184303284, 0.022991584613919258, 0.12351387739181519, 0.07375653833150864, 0.01641845516860485, 0.07990870624780655, -0.02387511357665062, -0.008543538860976696, -0.03719070926308632, -0.02064279280602932, -0.01480866689234972, 0.013318362645804882, 0.04767680913209915, 0.0023802726063877344, 0.13028189539909363, -0.03278101608157158, 0.009036637842655182, -0.01992270164191723, 0.04813183844089508, -0.059177495539188385, -0.0826941430568695, -0.02165888249874115, -0.02390577830374241, -0.040492016822099686, -0.032297659665346146, 0.07054510712623596, 0.01059324573725462, 0.10371211171150208, 0.10916325449943542, 0.0021469297353178263, 0.055487677454948425, 0.04318464547395706, -0.08856407552957535, 8.024961077793566e-33, -0.0004046123940497637, -0.09182320535182953, -0.06871756166219711, -0.06480897963047028, 0.013779291883111, 0.023124027997255325, 0.027240177616477013, 0.12754258513450623, 0.06980293989181519, 0.00811499822884798, -0.045887839049100876, 0.11962621659040451, -0.08712206035852432, -0.007203687913715839, 0.046941012144088745, 0.05420588701963425, -0.01999141089618206, 0.017998656257987022, -0.05464969947934151, 0.0419112928211689, 0.1662820428609848, -0.013396121561527252, 0.01427113264799118, -0.10510583966970444, -0.10199951380491257, -0.0159495510160923, 0.002023665700107813, -0.050331901758909225, -0.151844784617424, 0.02620578184723854, -0.20158323645591736, -0.0010058050975203514, 0.003310879459604621, 0.04357413575053215, 0.020244916900992393, -0.11765971034765244, 0.05727614462375641, -0.0295160673558712, 0.017168845981359482, -0.05884489044547081, -0.05881660059094429, -0.007646525278687477, -0.04038256034255028, -0.017441732808947563, -0.0347282737493515, 0.03560524806380272, 0.10343403369188309, 0.0578606054186821, -0.11436183750629425, 0.09788357466459274, 0.03155532851815224, -0.018525967374444008, -0.0325886532664299, 0.07879829406738281, -0.1316218376159668, 0.05434799939393997, -0.013873252086341381, -0.2180130034685135, 0.07350856810808182, 0.04811324179172516, -0.04721708595752716, -0.01987786591053009, 0.06750401854515076, 0.1258159577846527, -0.03158503770828247, 0.020408937707543373, 0.130506232380867, -0.04787838086485863, 0.08365979045629501, -0.0662412941455841, 0.01589874178171158, -0.12142708897590637, -0.05384676530957222, -0.07899988442659378, 0.04136916995048523, -0.11114057153463364, 0.12246786057949066, 0.0627463236451149, -0.128464475274086, 0.04397224634885788, 0.13525547087192535, -0.058976784348487854, 0.014132709242403507, 0.008309236727654934, 0.012747242115437984, -0.028092902153730392, 0.0975058525800705, -0.14871203899383545, -0.1613500714302063, -0.08388179540634155, -0.07630015909671783, 0.028755025938153267, -0.09622785449028015, -0.05566319823265076, 0.1882891058921814, -9.004421909149067e-33, -0.07603093236684799, -0.03890714794397354, -0.04621750861406326, 0.03561478853225708, -0.043406032025814056, -0.0658717229962349, 0.03528635576367378, -0.0016953437589108944, 0.0530112199485302, -0.12421467900276184, -0.04108458757400513, -0.023977093398571014, -0.025125030428171158, -0.05246688053011894, 0.03171618655323982, 0.06344743818044662, -0.10072752833366394, 0.0385701060295105, -0.018061187118291855, 0.19663763046264648, -0.020888498052954674, 0.1606164425611496, -0.26265013217926025, 0.04612484946846962, -0.06493134051561356, 0.018547585234045982, -0.014453655108809471, 0.06907173246145248, -0.04538663104176521, -0.0810481458902359, -0.014808641746640205, -0.006350063253194094, -0.09235972166061401, 0.013337942771613598, -0.017920689657330513, 0.043136902153491974, 0.11682351678609848, -0.11306215077638626, -0.06017504632472992, 0.18235616385936737, 0.09761100262403488, 0.0845416784286499, -0.22279882431030273, 0.03946080431342125, -0.09892025589942932, 0.01205863244831562, -0.04422091320157051, 0.005737459287047386, 0.07456497848033905, -0.033501509577035904, 0.1285596638917923, 0.008954533375799656, -0.016760800033807755, 0.06000897288322449, -0.04152009263634682, 0.0402643121778965, -0.021747319027781487, -0.08004707843065262, -0.06693974882364273, 0.08754049241542816, 0.04696119949221611, -0.005981833208352327, 0.010794281959533691, 0.03419085964560509, -0.012418079189956188, -0.03868125379085541, -0.05276519060134888, 0.008982331492006779, 0.043375786393880844, 0.006733040791004896, -0.07634978741407394, 0.04210929572582245, -0.017931237816810608, -0.12808412313461304, -0.020965198054909706, 0.07935907691717148, -0.07641374319791794, -0.0864388644695282, 0.029352109879255295, 0.03247042000293732, -0.1697326898574829, -0.0458008274435997, 0.09021633118391037, 0.0838707834482193, -0.02539578266441822, 0.06944110244512558, 0.1008603572845459, 0.08390454947948456, -0.025347625836730003, -0.026309385895729065, -0.032104212790727615, -0.05982914939522743, -0.08696331828832626, 0.17911529541015625, -0.08621396869421005, -9.957362578916218e-08, -0.10941490530967712, 0.09976188838481903, 0.003433982143178582, 0.039767708629369736, 0.04311249777674675, -0.07876870036125183, -0.03274378553032875, 0.06705781072378159, -0.09867934137582779, 0.09465942531824112, 0.11031283438205719, 0.10761483013629913, -0.057289768010377884, 0.14388543367385864, 0.017130309715867043, 0.13780251145362854, 0.044212356209754944, -0.03252296894788742, -0.09621694684028625, 0.06386017799377441, 0.1180720403790474, 0.026792949065566063, 0.016564128920435905, -0.05998549610376358, 0.07331922650337219, -0.0828852504491806, 0.09274817258119583, 0.13231562077999115, 0.11436382681131363, 0.1069718599319458, -0.06549973785877228, -0.10990217328071594, -0.0822913646697998, 0.017886511981487274, 0.20346742868423462, 0.10509953647851944, 0.02914818748831749, -0.12183859944343567, -0.07219818979501724, 0.014878838323056698, -0.09608380496501923, 0.059271927922964096, -0.03332842141389847, -0.004173032008111477, 0.02400725521147251, -0.07470957189798355, -0.09123837202787399, -0.06291253119707108, 0.07978065311908722, -0.02936038188636303, 0.0037289962638169527, 0.11149720102548599, -0.10656431317329407, 0.09475453943014145, 0.15278516709804535, -0.016990970820188522, -0.022501571103930473, 0.04849758744239807, -0.019233794882893562, 0.032946813851594925, 0.10882331430912018, -0.035815827548503876, -0.061311181634664536, 0.09615256637334824], metadata={'source': 'AAAMLP-569to.pdf', 'page': 104}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 105 This trick works when you have a problem where you already have the test dataset. It must be noted that this trick will not work in a live setting. For example, let’s say you are in a company that builds a real-time bidding solution (RTB). RTB systems bid on every user they see online to buy ad space. The features that can be used for such a model may include pages viewed in a website. Let’s assume that features are the last five categories/pages visited by the user. In this case, if the website introduces new categories, we will no longer be able to predict accurately. Our model, in this case, will fail. A situation like this can be avoided by using an “unknown” category.   In our cat-in-the-dat dataset, we already have unknowns in ord_2 column.  ═════════════════════════════════════════════════════════════════════════ In [X]: df.ord_2.fillna(\"NONE\").value_counts() Out[X]: Freezing       142726 Warm           124239 Cold            97822 Boiling Hot     84790 Hot             67508 Lava Hot        64840 NONE            18075 Name: ord_2, dtype: int64 ═════════════════════════════════════════════════════════════════════════ We can treat “NONE” as unknown. So, if during live testing, we get new categories that we have not seen before, we will mark them as “NONE”.  This is very similar to natural language processing problems. We always build a model based on a fixed vocabulary. Increasing the size of the vocabulary increases the size of the model. Transformer models like BERT are trained on ~30000 words (for English). So, when we have a new word coming in, we mark it as UNK (unknown).  So, you can either assume that your test data will have the same categories as training or you can introduce a rare or unknown category to training to take care of new categories in test data.  Let’s see the value counts in ord_4 column after filling NaN values:  ═════════════════════════════════════════════════════════════════════════ In [X]: df.ord_4.fillna(\"NONE\").value_counts()'),\n",
       " VectorParams(vector=[-0.01912367157638073, -0.032750632613897324, 0.025164691731333733, -0.07462534308433533, 0.07626114040613174, 0.020340627059340477, 0.05913593992590904, 0.007240422535687685, 0.05147585645318031, -0.02368626743555069, 0.08069523423910141, -0.0767860934138298, -0.021227726712822914, -0.09528666734695435, 0.0751735270023346, 0.03437970578670502, 0.021153755486011505, -0.032797325402498245, -0.10470875352621078, -0.12404236942529678, -0.038322340697050095, 0.1519903838634491, -0.002937061246484518, 0.05426016077399254, -0.03897944837808609, -0.06381441652774811, 0.03108796291053295, 0.047208599746227264, -0.03475626930594444, 0.0004128608270548284, -0.09127135574817657, 0.16301329433918, -0.017265839502215385, 0.007882121950387955, 0.003972159698605537, 0.018252545967698097, -0.06015383452177048, 0.047491248697042465, -0.03287378326058388, 0.011426975019276142, -0.050868213176727295, -0.08155383169651031, 0.09790452569723129, -0.08435584604740143, 0.012119738385081291, 0.08609505742788315, -0.05357612296938896, -0.05222409963607788, -0.0007258992409333587, -0.08827649801969528, 0.06419235467910767, 0.17462138831615448, -0.0994151160120964, 0.0811924859881401, -0.10017024725675583, -0.20376940071582794, -0.0390864834189415, -0.20304641127586365, 0.013048985041677952, 0.05440567806363106, -0.17007268965244293, -0.021121585741639137, 0.17961357533931732, -0.10272230952978134, 0.04643822833895683, 0.07079044729471207, -0.06243326887488365, -0.027295267209410667, 0.004825787153095007, 0.10206474363803864, 0.06145583465695381, 0.16635054349899292, -0.1136714518070221, 0.10559914261102676, -0.06999246031045914, -0.06512604653835297, 0.11683289706707001, -0.09658677130937576, 0.11357255280017853, 0.0007381128380075097, -0.060497257858514786, -0.004566470626741648, -0.002326836809515953, -0.018285641446709633, 0.07956646382808685, -0.16599930822849274, -0.007505211513489485, 0.03011566959321499, 0.10580622404813766, -0.018506109714508057, 0.09015065431594849, 0.030763790011405945, 0.05595959722995758, 0.0031450751703232527, 0.036583781242370605, 0.07780227065086365, 0.0359797328710556, 0.003889022395014763, 0.06369619071483612, 0.13734053075313568, -0.05025642365217209, -0.01998179592192173, -0.010667398571968079, -0.11094101518392563, -0.05799267068505287, 0.07019277662038803, 0.09358745813369751, 0.15198983252048492, 0.02140873670578003, -0.02997004985809326, -0.032989371567964554, -0.05617313086986542, 0.08479335904121399, 0.032781124114990234, -0.07000928372144699, -0.09292950481176376, 0.07873669266700745, -0.03851904347538948, -0.09164244681596756, 0.0370062030851841, -0.11616956442594528, 0.04209813103079796, 0.03534397855401039, 0.10767097026109695, 0.005198027938604355, 0.052386026829481125, -0.07511992752552032, 1.314179174332301e-32, -0.08536957204341888, -0.02498723194003105, 0.022400474175810814, -0.18443331122398376, -0.008499194867908955, -0.05699371173977852, 0.0027049730997532606, -0.06634779274463654, 0.10829836875200272, 0.04153675585985184, -0.020212316885590553, 0.05949835479259491, -0.01397851761430502, -0.0838332548737526, -0.029651761054992676, -0.07682233303785324, 0.09352549910545349, -0.13594919443130493, -0.0608324371278286, -0.0073655033484101295, -0.0021711059380322695, -0.04129519686102867, 0.08092775195837021, 0.011628756299614906, -0.039586760103702545, -0.05242631956934929, -0.03907935693860054, -0.09172573685646057, -0.0017641105223447084, -0.008339017629623413, -0.042177554219961166, 0.029575582593679428, 0.05395430326461792, -0.10891234129667282, 0.05745659023523331, -0.0842389389872551, 0.10828280448913574, 0.04427309334278107, 0.07833705842494965, 0.04765819013118744, -0.14520034193992615, 0.04952053725719452, -0.05370189994573593, 0.040455836802721024, 0.015727441757917404, 0.1433744877576828, 0.17950205504894257, 0.14588886499404907, -0.1930818408727646, 0.08945929259061813, -0.025923676788806915, -0.14049695432186127, 0.01406086329370737, 0.09918082505464554, -0.16868093609809875, -0.07881219685077667, -0.0262380912899971, -0.14417524635791779, 0.010047570802271366, 0.048080407083034515, 0.10690079629421234, 0.03805176168680191, 0.01584983617067337, 0.0667136162519455, 0.06662251800298691, -0.037000831216573715, 0.14355309307575226, 0.14608578383922577, 0.003915437962859869, 0.004423260223120451, 0.0912550538778305, -0.03761725127696991, 0.05755011364817619, -0.1823146641254425, 0.017606521025300026, -0.09177663177251816, 0.18839281797409058, 0.09179545193910599, -0.004269166849553585, -0.09414607286453247, 0.007983979769051075, 0.025544319301843643, 0.07534344494342804, -0.019950686022639275, 0.06868688762187958, -0.01569192297756672, 0.06287313252687454, -0.10292655974626541, -0.07477407157421112, -0.05475408583879471, -0.008487170562148094, -0.009134864434599876, -0.055254362523555756, -0.1363261640071869, 0.02521338500082493, -1.1865268061151362e-32, -0.06581828743219376, 0.04031378775835037, 0.08967150002717972, 0.05102180689573288, 0.07316944748163223, -0.038528185337781906, 0.005531666334718466, 0.09186984598636627, 0.05326956510543823, -0.13996292650699615, 0.04169312119483948, -0.02147582545876503, 0.10368288308382034, -0.1530560851097107, -0.03666121885180473, 0.07040020078420639, -0.11134058982133865, 0.16781562566757202, -0.12952981889247894, 0.04765010625123978, -0.013596085831522942, 0.20907501876354218, -0.07907485216856003, 0.13112933933734894, -0.14062008261680603, 0.05043964833021164, -0.024124978110194206, -0.04397760331630707, -0.048334259539842606, -0.13353101909160614, -0.09344706684350967, 0.03230510279536247, -0.013736408203840256, 0.0005630486411973834, 0.04635867848992348, -0.10007794946432114, 0.1972619593143463, -0.08367380499839783, -0.2114492654800415, 0.01117398589849472, 0.008977080695331097, 0.1274752914905548, -0.12332740426063538, 0.048655591905117035, -0.09346421808004379, 0.040510375052690506, -0.025359444320201874, 0.02696520835161209, 0.0952259972691536, -0.06105954945087433, 0.026637904345989227, 0.005538750905543566, 0.05605190247297287, 0.21166351437568665, -0.05991073325276375, 0.09843554347753525, -0.09429963678121567, -0.07622677087783813, -0.13606712222099304, 0.01786734350025654, -0.02401951514184475, -0.06754833459854126, -0.06059104949235916, 0.021688474342226982, 0.0829998105764389, -0.012349373660981655, -0.004543404560536146, 0.00392128573730588, -0.027300836518406868, -0.00839596800506115, -0.05103692784905434, -0.10623932629823685, 0.017633147537708282, -0.15423670411109924, -0.07450719177722931, 0.034453194588422775, -0.05660844221711159, -0.08994654566049576, -0.0788910761475563, 0.12245719879865646, -0.06775509566068649, -0.08736071735620499, 0.08285921812057495, 0.08964361995458603, -0.12141577899456024, 0.1272042840719223, 0.12245475500822067, 0.011857704259455204, -0.017238816246390343, -0.06589478254318237, 0.025434603914618492, -0.035429947078228, 0.0671725943684578, 0.05465378612279892, 0.0016322931041941047, -9.949085466587348e-08, -0.013410545885562897, 0.03070284053683281, -0.059613507241010666, -0.12791916728019714, 0.12335163354873657, 0.034815795719623566, -0.07233235985040665, 0.04624529182910919, -0.035487622022628784, 0.04247002676129341, 0.1096283420920372, 0.04010176286101341, -0.07530280947685242, 0.003261360339820385, -0.04610835760831833, 0.06698847562074661, -0.007697199936956167, 0.06696875393390656, -0.02667052485048771, 0.0797167643904686, 0.024298211559653282, 0.032534535974264145, 0.10528390109539032, -0.06961570680141449, -0.06074493005871773, -0.04487764835357666, 0.040778107941150665, 0.005644810851663351, 0.11488185077905655, 0.08305688947439194, -0.05933530628681183, -0.1587185561656952, -0.021707285195589066, -0.010086114518344402, 0.16965138912200928, 0.04381164535880089, -0.10664939135313034, -0.09911062568426132, -0.1375611573457718, 0.0018729777075350285, -0.04297527298331261, -0.03473164513707161, -0.0063448077999055386, 0.04485388472676277, 0.05353602021932602, -0.030817927792668343, -0.028055403381586075, 0.07483573257923126, 0.1290653795003891, 0.005036409944295883, 0.005038314498960972, -0.006228040438145399, -0.057748619467020035, 0.07050161063671112, 0.07549180090427399, 0.027991676703095436, -0.05018904432654381, 0.07255345582962036, -0.034439943730831146, -0.08490924537181854, 0.26634907722473145, -0.1009388342499733, 0.020996032282710075, 0.036882009357213974], metadata={'source': 'AAAMLP-569to.pdf', 'page': 105}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 106 Out[X]: N       39978 P       37890 Y       36657 A       36633 R       33045 U       32897 . . . K       21676 I       19805 NONE    17930 D       17284 F       16721 W        8268 Z        5790 S        4595 G        3404 V        3107 J        1950 L        1657 Name: ord_4, dtype: int64 ═════════════════════════════════════════════════════════════════════════  We see that some values appear only a couple thousand times, and some appear almost 40000 times. NaNs are also seen a lot. Please note that I have removed some values from the output.   We can now define our criteria for calling a value “rare”. Let’s say the requirement for a value being rare in this column is a count of less than 2000. So, it seems, J and L can be marked as rare values. With pandas, it is quite easy to replace categories based on count threshold. Let’s take a look at how it’s done.  ═════════════════════════════════════════════════════════════════════════ In [X]: df.ord_4 = df.ord_4.fillna(\"NONE\")  In [X]: df.loc[    ...:     df[\"ord_4\"].value_counts()[df[\"ord_4\"]].values < 2000,    ...:     \"ord_4\"    ...: ] = \"RARE\"  In [X]: df.ord_4.value_counts() Out[X]: N       39978'),\n",
       " VectorParams(vector=[0.00295959017239511, -0.02092580869793892, -0.03950124979019165, 0.026764938607811928, 0.05711347982287407, 0.07125193625688553, -0.07701163738965988, -0.04262995719909668, -0.077027328312397, -0.11145521700382233, 0.047979265451431274, -0.13307920098304749, 0.029502898454666138, -0.05193667858839035, 0.09183591604232788, 0.04403521865606308, 0.06764594465494156, 0.06725628674030304, -0.14952151477336884, -0.004785547964274883, -0.057764727622270584, 0.05930700898170471, -0.034745313227176666, 0.07538910955190659, -0.07828379422426224, -0.028888655826449394, -0.0015175369335338473, 0.052637238055467606, -0.0328606553375721, -0.07705099880695343, 0.03329787403345108, 0.07746714353561401, -0.10485442727804184, 0.07434085011482239, 0.12165432423353195, 0.02271905168890953, -0.0686420276761055, 0.06569206714630127, 0.0017933228518813848, 0.07665494084358215, -0.038575902581214905, -0.020166875794529915, 0.011883619241416454, 0.010082113556563854, 0.04367754980921745, 0.04314842447638512, -0.05176863074302673, -0.012940650805830956, -0.0389941930770874, -0.06835202127695084, -0.03367982804775238, -0.05518524348735809, -0.012478473596274853, 0.09641079604625702, -0.05778248608112335, -0.1438395380973816, -0.06309396028518677, -0.22423473000526428, -0.102900430560112, -0.029264653101563454, -0.06479454040527344, -0.0394960381090641, 0.10467948019504547, -0.07267899811267853, 0.05325000733137131, -0.00580013869330287, -0.029078969731926918, 0.015257717110216618, 0.13808973133563995, 0.15898242592811584, 0.049143511801958084, 0.08963122218847275, -0.11333756893873215, 0.1364290416240692, -0.006209428887814283, 0.005225646775215864, 0.16073499619960785, -0.018862685188651085, 0.07524489611387253, 0.010760005563497543, 0.004375664051622152, -0.011869422160089016, -0.07151052355766296, 0.006996024399995804, 0.07693849503993988, -0.04367610067129135, -0.04867936670780182, 0.09578306972980499, -0.07052148133516312, 0.04639683663845062, 0.0010695761302486062, 0.013748908415436745, 0.08816629648208618, 0.03936262056231499, 0.11517549306154251, 0.08318515121936798, 0.09903872758150101, -0.06610678881406784, 0.10021641105413437, 0.10073767602443695, -0.01536264643073082, 0.00889945775270462, 0.05293227732181549, 0.02111241966485977, -0.027902081608772278, -0.02188568376004696, 0.09548555314540863, 0.058922771364450455, 0.02163105085492134, -0.066336490213871, 0.03474719822406769, -0.045133065432310104, -0.042427245527505875, -0.009901721030473709, -0.07610733807086945, -0.008303150534629822, -0.03632820397615433, -0.027465976774692535, -0.03535499423742294, 0.07001972198486328, -0.0809837281703949, 0.03430343419313431, 0.1162450909614563, 0.10950598865747452, -0.037978075444698334, -0.007416666019707918, -0.10590799897909164, 1.286951492557792e-32, 0.04785449057817459, -0.044712767004966736, 0.0036668293178081512, -0.08263364434242249, -0.05022914335131645, -0.040674444288015366, -0.0001852202694863081, 0.030152682214975357, 0.043642494827508926, 0.045840103179216385, -0.12667176127433777, 0.03978503495454788, -0.06107673421502113, 0.020554639399051666, 0.0012236281763762236, -0.011214020662009716, -0.025315726175904274, 0.041092902421951294, -0.15990130603313446, -0.012125090695917606, 0.0686265379190445, 0.0333695150911808, -0.006695091724395752, -0.018954070284962654, -0.046638503670692444, 0.044616326689720154, 0.0021796147339046, -0.09110739082098007, -0.03486229479312897, 0.049845755100250244, -0.09475111216306686, 0.002718244679272175, 0.003893268294632435, 0.059573519974946976, -0.0045415000058710575, -0.05173027887940407, -0.05544028803706169, 0.012970593757927418, 0.039175957441329956, 0.1691877543926239, -0.04514289274811745, 0.024814559146761894, -0.007655620574951172, -0.043879132717847824, 0.05806140974164009, 0.02947673201560974, 0.11175964772701263, 0.09165431559085846, -0.12491445988416672, 0.09715141355991364, 0.08524275571107864, -0.009182215668261051, -0.06970324367284775, -0.007797519210726023, -0.22459645569324493, -0.021371446549892426, -0.049972523003816605, -0.13623149693012238, -0.0232987217605114, 0.0752679705619812, -0.0064869895577430725, -0.006256758701056242, 0.033161710947752, 0.0682004764676094, 0.03194562345743179, -0.0075256251730024815, 0.07148860394954681, -0.019828658550977707, 0.02699160948395729, -0.01838575303554535, 0.008432336151599884, -0.04880314692854881, -0.04539548605680466, -0.07388467341661453, 0.08401934802532196, -0.03568455949425697, 0.1239299327135086, 0.04777596890926361, -0.0016014312859624624, -0.04464052617549896, 0.06523171067237854, 0.09812932461500168, -0.016391659155488014, -0.08964332193136215, -0.025907527655363083, 0.0020894045010209084, 0.03010699898004532, -0.14526401460170746, -0.11148329824209213, 0.015871290117502213, -0.03714831918478012, 0.05779649317264557, -0.10419090837240219, -0.08414237946271896, 0.1405431479215622, -1.286511269923409e-32, -0.007369982544332743, -0.03637481480836868, 0.06010991707444191, 0.029206037521362305, -0.08221958577632904, -0.006484615616500378, -0.002173064509406686, -0.0003778816608246416, -0.02112327702343464, -0.06205720454454422, -0.010219437070190907, -0.02726295031607151, 0.020474901422858238, -0.034517280757427216, -0.06988681852817535, 0.004339432809501886, -0.0933455303311348, 0.07886011898517609, -0.01779680699110031, 0.13046234846115112, 0.02836555987596512, 0.1912951022386551, -0.23538701236248016, 0.1304914802312851, -0.10183621942996979, 0.07399711012840271, -0.0791291818022728, -0.0012097590370103717, 0.06708763539791107, -0.046828534454107285, 0.007511494215577841, -0.016405103728175163, -0.01815837249159813, -0.00987786054611206, 0.023067979142069817, 0.02354392036795616, 0.061489515006542206, -0.0644788146018982, -0.053047120571136475, 0.09086047112941742, -0.055054545402526855, 0.1013125628232956, -0.26679864525794983, 0.037610363215208054, -0.01675782911479473, 0.05417598411440849, -0.042131900787353516, 0.030780483037233353, 0.11089543253183365, -0.012774084694683552, 0.07777596265077591, -0.04113907366991043, 0.02959110215306282, 0.026250723749399185, 0.031789615750312805, 0.012543294578790665, -0.07600930333137512, -0.1091223806142807, -0.0985480397939682, 0.07980655133724213, -0.06191124767065048, -0.003559149568900466, 0.026624780148267746, -0.023894071578979492, 0.024464597925543785, -0.0963783785700798, 0.014576510526239872, -0.05427094176411629, -0.0323924757540226, -0.02820545993745327, -0.014543966390192509, 0.07226921617984772, -0.08172477781772614, -0.09162449836730957, 0.04368919879198074, 0.004681249614804983, -0.03546644002199173, 0.033186789602041245, -0.015587063506245613, 0.03245602175593376, -0.03131343424320221, -0.050219904631376266, 0.02990458719432354, 0.10069125890731812, 0.03346700966358185, 0.1009741872549057, 0.14159895479679108, 0.025597212836146355, 0.003929758444428444, -0.025140123441815376, -0.04331769794225693, 0.06846270710229874, 0.057241931557655334, 0.16040495038032532, 0.01141854003071785, -9.957466318155639e-08, 0.06350228190422058, 0.15122276544570923, -0.1625058799982071, 0.0400199331343174, 0.027613498270511627, -0.05505083128809929, -0.11775723844766617, 0.011010185815393925, -0.025180786848068237, 0.026930801570415497, 0.03535739704966545, -0.010489500127732754, -0.08681333065032959, 0.05239773169159889, 0.04688224941492081, -0.009451228193938732, 0.03372310847043991, -0.03816461190581322, -0.06560569256544113, 0.16154175996780396, 0.031048744916915894, 0.060494836419820786, 0.0657670646905899, -0.056083399802446365, 0.049156829714775085, -0.08239846676588058, 0.10312299430370331, 0.11312639713287354, 0.13002242147922516, 0.004158483352512121, -0.05875108391046524, -0.0984414666891098, -0.09456513822078705, 0.057020947337150574, 0.011144865304231644, 0.13139092922210693, 0.004744152072817087, -0.023278968408703804, -0.07548670470714569, 0.019162293523550034, -0.0011789259733632207, -0.03796065226197243, -0.01696784980595112, -0.062143344432115555, -0.10591953247785568, -0.12231116741895676, -0.06308841705322266, -0.0011182193411514163, -0.012967253103852272, -0.012004511430859566, -0.09150741994380951, -0.000894107564818114, -0.11557570099830627, 0.14639857411384583, 0.05371755361557007, 0.05782793089747429, -0.01715599186718464, 0.024131178855895996, 0.00017367739928886294, -0.017481015995144844, 0.1718611717224121, -0.21792863309383392, -0.1282980591058731, 0.03621998429298401], metadata={'source': 'AAAMLP-569to.pdf', 'page': 106}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 107 P       37890 Y       36657 A       36633 R       33045 U       32897 M       32504 . . . B       25212 E       21871 K       21676 I       19805 NONE    17930 D       17284 F       16721 W        8268 Z        5790 S        4595 RARE     3607 G        3404 V        3107 Name: ord_4, dtype: int64  ═════════════════════════════════════════════════════════════════════════  We say that wherever the value count for a certain category is less than 2000, replace it with rare. So, now, when it comes to test data, all the new, unseen categories will be mapped to “RARE”, and all missing values will be mapped to “NONE”.  This approach will also ensure that the model works in a live setting, even if you have new categories.  Now we have everything we need to approach any kind of problem with categorical variables in it. Let’s try building our first model and try to improve its performance in a step-wise manner.  Before going to any kind of model building, it’s essential to take care of cross-validation. We have already seen the label/target distribution, and we know that it is a binary classification problem with skewed targets. Thus, we will be using StratifiedKFold to split the data here.'),\n",
       " VectorParams(vector=[-0.07301720976829529, -0.12710979580879211, -0.004672329872846603, -0.0063058785162866116, 0.15317824482917786, -0.005407365504652262, 0.039180126041173935, -0.02231673151254654, -0.04625978320837021, 0.025416281074285507, 0.07058525830507278, -0.07786738872528076, -0.04701812192797661, -0.1893721967935562, -0.022323481738567352, 0.024755310267210007, -0.15247322618961334, 0.077132448554039, -0.1208745688199997, -0.10853330045938492, -0.03765173256397247, 0.019944986328482628, 0.057076696306467056, 0.023692702874541283, -0.07449483126401901, -0.03989953547716141, 0.0943019911646843, 0.05827666074037552, -0.11948030441999435, -0.0943712517619133, 0.009566327556967735, 0.14082327485084534, 0.012713896110653877, -0.032397713512182236, 0.035923462361097336, 0.021171724423766136, -0.17242366075515747, 0.07002133131027222, -0.008943098597228527, 0.22624415159225464, -0.019768860191106796, -0.04918591305613518, 0.003135975217446685, 0.0404849611222744, 0.05661872774362564, 0.0787895917892456, -0.04605282098054886, -0.07058755308389664, 0.0828888788819313, 0.05045226216316223, -0.02958868071436882, 0.13367052376270294, -0.14718730747699738, 0.016749819740653038, -0.13428936898708344, -0.24278368055820465, 0.06989801675081253, -0.16191445291042328, 0.019245294854044914, 0.10674350708723068, 0.021132024005055428, -0.15061752498149872, 0.013591025024652481, -0.14199963212013245, -0.043659672141075134, -0.030763540416955948, -0.014500660821795464, 0.0826253890991211, 0.039016060531139374, -0.008986592292785645, -0.03373101353645325, 0.2380024790763855, -0.03977309539914131, 0.0651065781712532, -0.11138085275888443, -0.06640257686376572, 0.1493740677833557, -0.09168221056461334, 0.12364322692155838, -0.03624558448791504, -0.16332118213176727, -0.007656078319996595, 0.016858816146850586, -0.012574884109199047, -0.041991643607616425, -0.13235697150230408, 0.07476473599672318, 0.051675137132406235, 0.02920663356781006, -0.08310514688491821, 0.13052326440811157, 0.04929100349545479, -0.0687713548541069, -0.0014278213493525982, -0.05512524023652077, 0.17429518699645996, 0.11467137932777405, 0.08019241690635681, 0.1539965718984604, 0.1369733065366745, -0.053449492901563644, -0.0406624972820282, 0.04608684033155441, 0.06619683653116226, -0.09209969639778137, -0.1497740000486374, 0.1556670367717743, 0.04750670865178108, 0.07370337098836899, -0.09413662552833557, 0.05579065531492233, -0.06308659166097641, -0.06747658550739288, 0.11290052533149719, 0.09796161949634552, 0.03654485568404198, 0.03212942183017731, 0.02864607237279415, -0.14020363986492157, 0.10137077420949936, -0.09452016651630402, 0.06484537571668625, 0.0461714081466198, -0.009206901304423809, -0.07751228660345078, -0.051223013550043106, -0.01695418357849121, 1.0380935344853566e-32, -0.08009249716997147, 0.010039067827165127, 0.1187676265835762, -0.0755176842212677, 0.047693729400634766, -0.19736674427986145, 0.04720710217952728, 0.002708268351852894, 0.02549571543931961, 0.12017770856618881, -0.19950483739376068, 0.05853019654750824, 0.04915211722254753, -0.0938129872083664, -0.08082265406847, -0.14265510439872742, -0.0520610436797142, 0.04207030311226845, -0.05268631875514984, -0.04173648729920387, 0.3889656662940979, 0.03764592856168747, 0.11379215866327286, -0.06699489057064056, -0.030988002195954323, -0.10335423797369003, -0.16176627576351166, 0.04046882688999176, -0.07706286013126373, 0.009411985985934734, -0.19476363062858582, 0.008087437599897385, -0.02409486100077629, -0.0773489847779274, -0.02557351067662239, -0.11394764482975006, 0.07875841110944748, 0.12071673572063446, -0.020973166450858116, 0.018501266837120056, 0.03998946398496628, 0.020171470940113068, 0.1457802653312683, -0.04794730246067047, -0.11816968768835068, 0.020117685198783875, 0.11877916753292084, 0.06763097643852234, -0.10729886591434479, 0.0919739156961441, 0.026303790509700775, -0.18425123393535614, 0.06148744001984596, 0.09357479214668274, -0.10780085623264313, 0.19730447232723236, 0.10390239208936691, -0.10112856328487396, 0.09491503983736038, 0.095192089676857, -0.009389231912791729, 0.002054222160950303, -0.042578112334012985, 0.14248698949813843, 0.07368158549070358, 0.045526374131441116, 0.24043606221675873, 0.03382470831274986, 0.1539730578660965, -0.08303896337747574, -0.12074512988328934, 0.08270008116960526, -0.129124715924263, -0.21087786555290222, 0.05713670328259468, -0.07364282757043839, 0.013751106336712837, 0.09470692276954651, -0.12156376987695694, -0.0013148802099749446, 0.01206203829497099, 0.07595925033092499, -0.04773939773440361, -0.23574385046958923, 0.06956717371940613, 0.030251486226916313, 0.023133710026741028, -0.07517924904823303, -0.2059973031282425, -0.27618512511253357, -0.15986113250255585, 0.027414336800575256, 0.024291209876537323, -0.20264558494091034, 0.1102542132139206, -1.0894899678599472e-32, 0.0837235227227211, -0.03758604824542999, 0.11069981008768082, 0.11252178251743317, 0.15021781623363495, 0.15829303860664368, 0.0218192171305418, 0.09728780388832092, -0.09362120926380157, -0.14458636939525604, -0.12258096784353256, -0.06476899236440659, 0.149633526802063, -0.023014666512608528, 0.021242639049887657, 0.11480773985385895, -0.1253591626882553, 0.21170444786548615, -0.08582095801830292, 0.047113947570323944, -0.09380685538053513, 0.08409279584884644, -0.07088467478752136, -0.049569133669137955, -0.0678921714425087, 0.007275912445038557, 0.02545071393251419, 0.08946298807859421, 0.11655759066343307, -0.10900626331567764, -0.05751027166843414, -0.06478172540664673, -0.1407637894153595, 0.14208635687828064, -0.004336727317422628, -0.032068315893411636, 0.07641036808490753, 0.0038116539362818003, -0.10901912301778793, 0.20404857397079468, 0.10145486891269684, 0.1450178176164627, -0.1645604372024536, 0.12623955309391022, -0.02587353251874447, 0.039631299674510956, -0.04410841315984726, 0.055600591003894806, -0.0569399818778038, -0.0512043796479702, 0.015792138874530792, 0.04084198549389839, -0.16685719788074493, 0.046029720455408096, 0.03589596971869469, 0.14778867363929749, -0.10945796966552734, 0.017946237698197365, -0.2321254163980484, 0.05931272357702255, -0.09847669303417206, -0.06273657083511353, -0.1602877825498581, 0.01473099272698164, 0.17686928808689117, -0.008199608884751797, -0.14925706386566162, -0.0643443763256073, 0.01655074767768383, 0.04485724866390228, -0.05992085486650467, -0.0031648059375584126, 0.02153506875038147, -0.1949409693479538, -0.0654301866889, 0.07283315807580948, -0.07929882407188416, 0.03448731452226639, -0.008429761976003647, 0.15432389080524445, 0.018873434513807297, -0.18327756226062775, 0.10594930499792099, 0.16370505094528198, -0.043328795582056046, 0.11297928541898727, 0.1659938246011734, 0.018790509551763535, 0.12463068962097168, -0.04981017857789993, -0.04017876088619232, -0.08194375038146973, 0.1952110230922699, 0.26839253306388855, -0.040820199996232986, -9.972257686285957e-08, 0.047340698540210724, 0.07911348342895508, -0.002846274059265852, 0.062420282512903214, 0.11668598651885986, 0.10303927212953568, -0.17559145390987396, 0.03853526711463928, -0.06769699603319168, 0.015498566441237926, 0.12027522176504135, -0.03842915967106819, -0.10111662745475769, 0.14145702123641968, -0.05543350800871849, 0.05811286345124245, 0.03333670645952225, 0.1155032217502594, 0.009497160091996193, 0.0961938127875328, 0.06891190260648727, -0.042671944946050644, 0.11040057241916656, -0.03020028956234455, 0.019361255690455437, -0.10442332178354263, -0.06277904659509659, 0.02539462223649025, 0.08363896608352661, -0.012100298888981342, -0.018273429945111275, -0.19806919991970062, -0.07628283649682999, -0.011895779520273209, 0.16761179268360138, -0.03968852758407593, -0.04109615087509155, -0.07525745034217834, 0.10043346136808395, 0.14446596801280975, -0.10425324738025665, 0.012564958073198795, -0.11070321500301361, 0.0014663286274299026, -0.02777637168765068, 0.052568286657333374, -0.049123793840408325, -0.04119906201958656, 0.16842231154441833, -0.022026941180229187, -0.08141472190618515, -0.16316628456115723, -0.0740186870098114, -0.03442266583442688, 0.11572614312171936, 0.16722305119037628, -0.1303049772977829, 0.11494860053062439, 0.027743907645344734, -0.08461873233318329, -0.021547943353652954, -0.03129022195935249, -0.06389716267585754, -0.08536309748888016], metadata={'source': 'AAAMLP-569to.pdf', 'page': 107}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 108 ═════════════════════════════════════════════════════════════════════════ # create_folds.py # import pandas and model_selection module of scikit-learn import pandas as pd from sklearn import model_selection  if __name__ == \"__main__\":      # Read training data     df = pd.read_csv(\"../input/cat_train.csv\")      # we create a new column called kfold and fill it with -1     df[\"kfold\"] = -1          # the next step is to randomize the rows of the data     df = df.sample(frac=1).reset_index(drop=True)          # fetch labels     y = df.target.values          # initiate the kfold class from model_selection module     kf = model_selection.StratifiedKFold(n_splits=5)          # fill the new kfold column     for f, (t_, v_) in enumerate(kf.split(X=df, y=y)):         df.loc[v_, \\'kfold\\'] = f          # save the new csv with kfold column     df.to_csv(\"../input/cat_train_folds.csv\", index=False) ═════════════════════════════════════════════════════════════════════════  We can now check our new folds csv to see the number of samples per fold:  ═════════════════════════════════════════════════════════════════════════ In [X]: import pandas as pd  In [X]: df = pd.read_csv(\"../input/cat_train_folds.csv\")  In [X]: df.kfold.value_counts() Out[X]: 4    120000 3    120000 2    120000 1    120000 0    120000 Name: kfold, dtype: int64 ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[-0.053685978055000305, -0.20448970794677734, -0.028384484350681305, 0.013994233682751656, 0.17085984349250793, -0.08285992592573166, 0.06774941086769104, -0.022417545318603516, 0.07331310957670212, 0.06849350035190582, 0.07046331465244293, -0.0874420627951622, 0.09393183141946793, 0.03835366666316986, 0.09793636202812195, 0.03204529732465744, -0.043469399213790894, 0.03565520420670509, -0.19410894811153412, 0.0379701629281044, 0.013648789376020432, 0.01619007997214794, -0.0398695170879364, -0.04183494672179222, -0.06964743137359619, -0.09240671992301941, 0.020773986354470253, -0.04179134592413902, -0.06111613288521767, -0.11601901799440384, 0.1353762149810791, 0.11674842238426208, 0.012557195499539375, -0.00774225452914834, 0.0595005601644516, 0.07547041773796082, -0.1942770630121231, 0.036888208240270615, 0.03640943765640259, 0.12316582351922989, 0.040406886488199234, 0.05502782389521599, 0.07792188227176666, 0.03094911389052868, 0.08507578819990158, 0.0905015617609024, -0.12149570882320404, -0.003189962822943926, 0.06939470022916794, 0.031027518212795258, 0.044323645532131195, 0.07754845172166824, -0.12402346730232239, 0.09447713941335678, -0.05835777893662453, -0.21592159569263458, 0.00659038545563817, -0.10534229129552841, -0.05789369344711304, 0.1056186854839325, -0.05740897357463837, -0.12679292261600494, -0.013686861842870712, -0.09005220234394073, 0.07225650548934937, -0.018364574760198593, 0.01910657249391079, 0.03337724134325981, 0.04263291507959366, 0.031454283744096756, -0.057096123695373535, 0.11840216815471649, -0.15003512799739838, -0.009725945070385933, 0.06792686134576797, -0.03954319655895233, 0.23070326447486877, -0.060408782213926315, -0.028747111558914185, -0.06841522455215454, -0.04775994271039963, 0.03248610347509384, -0.01398305594921112, -0.08500596135854721, 0.06739676743745804, -0.12516480684280396, 0.08215828984975815, 0.08212047815322876, 0.04059578478336334, -0.018740344792604446, -0.008510534651577473, 0.04960259050130844, -0.01906735636293888, 0.049925800412893295, -0.02296752668917179, 0.07234561443328857, 0.09251625835895538, 0.09362166374921799, 0.04050150513648987, 0.05741165950894356, -0.0719529315829277, -0.08193599432706833, 0.1300593465566635, 0.029375096783041954, 0.03197154030203819, -0.15542256832122803, 0.09325214475393295, 0.05185624584555626, -0.025381889194250107, -0.12779350578784943, 0.0384695865213871, -0.010683732107281685, 0.0443071685731411, 0.12954972684383392, 0.08105260878801346, -0.06383544206619263, -0.022699745371937752, 0.055525586009025574, -0.07196710258722305, 0.08391453325748444, -0.07619179785251617, 0.04932296648621559, 0.0749613344669342, 0.059773918241262436, -0.058191921561956406, -0.05814225971698761, -0.07057040184736252, 1.343242243598825e-32, 0.002989948494359851, 0.09466785192489624, 0.025759415701031685, -0.10955533385276794, 0.06587380170822144, -0.15664489567279816, 0.016319407150149345, 0.0430004708468914, 0.01355174370110035, 0.15501068532466888, -0.20448441803455353, 0.11470364034175873, 0.0006710360758006573, 0.0953880026936531, 0.04930669069290161, -0.030006617307662964, -0.08425036817789078, 0.14251986145973206, -0.07812496274709702, 0.03302214667201042, 0.13349957764148712, -0.022020386531949043, 0.01951674371957779, -0.0951910987496376, -0.06064555048942566, -0.06440933048725128, -0.049105122685432434, 0.06962215155363083, -0.17272676527500153, 0.009857747703790665, -0.18936340510845184, 0.05568710342049599, -0.015006037428975105, -0.0029403110966086388, 0.07826684415340424, -0.13372588157653809, -0.06464239954948425, -0.03590040281414986, -0.07405354827642441, -0.055756937712430954, -0.044974565505981445, 0.07215073704719543, 0.06062910333275795, -0.03131440654397011, -0.073308564722538, -0.078482486307621, 0.049300722777843475, -0.015548200346529484, -0.13779915869235992, -0.011518841609358788, 0.08017238974571228, -0.1275239884853363, 0.06959075480699539, -0.0069347345270216465, -0.06917144358158112, 0.08523867279291153, 0.003844993421807885, -0.07745096832513809, 0.10973578691482544, 0.16976268589496613, -0.04440036416053772, -0.09574632346630096, -0.09698141366243362, 0.07761107385158539, 0.1678173840045929, 0.08797222375869751, 0.09457019716501236, 0.001537187839858234, 0.14238262176513672, 0.054412003606557846, 0.018054421991109848, 0.0754970833659172, -0.0953558012843132, -0.1303817331790924, 0.03066898323595524, -0.0185537151992321, 0.1397417187690735, 0.011004297062754631, -0.017551738768815994, 0.027237623929977417, -0.03823382407426834, 0.11187794059515, -0.09634974598884583, -0.21078507602214813, -0.0059819999150931835, 0.05216381326317787, -0.039780087769031525, -0.15551139414310455, -0.24172186851501465, -0.09908416122198105, -0.06534701585769653, -0.021142620593309402, -0.08732682466506958, -0.14944837987422943, 0.05933178588747978, -1.1173102457240644e-32, -0.012698374688625336, 0.057850178331136703, 0.030634595081210136, 0.03027118369936943, 0.016756879165768623, 0.04583793878555298, 0.0025835183914750814, 0.00822040531784296, -0.08849259465932846, -0.07864827662706375, -0.06917105615139008, -0.03573555871844292, 0.07329793274402618, -0.01911460980772972, -0.042021188884973526, 0.10670054703950882, 0.015491417609155178, 0.12366944551467896, -0.06214411184191704, -0.05012380704283714, -0.02173803187906742, 0.11912684887647629, -0.144537553191185, -0.02113460563123226, -0.12808778882026672, 0.012171297334134579, -0.12849365174770355, 0.09378700703382492, 0.13565927743911743, -0.013823098503053188, -0.003888260805979371, -0.052696336060762405, -0.141708105802536, 0.029814185574650764, -0.028362901881337166, -0.018483510240912437, 0.07154503464698792, 0.020182272419333458, -0.013854876160621643, 0.07146557420492172, 0.019009195268154144, 0.0427095852792263, -0.042326752096414566, 0.03746858611702919, 0.0007212117197923362, -0.015005375258624554, 0.049598731100559235, -0.026137253269553185, 0.04027300328016281, -0.10585138201713562, 0.07431983202695847, 0.007760937791317701, -0.06834792345762253, 0.09189929813146591, -0.0730653777718544, 0.025083042681217194, -0.09425804764032364, -0.07130402326583862, -0.03606032207608223, -0.08467412739992142, -0.01613716594874859, -0.036273423582315445, -0.02261863835155964, 0.06672630459070206, 0.00788776483386755, 0.017143091186881065, -0.11149193346500397, -0.017326025292277336, -0.08445965498685837, 0.1040041521191597, -0.09248387068510056, -0.13392098248004913, 0.039979398250579834, -0.11770416051149368, -0.15264078974723816, 0.041079796850681305, 0.0028481490444391966, -0.04988500103354454, -0.0014129297342151403, 0.030071506276726723, -0.0759061947464943, -0.153535395860672, -0.0023754218127578497, 0.1712176501750946, -0.005105425138026476, 0.1035759449005127, 0.1615414172410965, -0.0003779011021833867, 0.10518696904182434, -0.0678548589348793, -0.018256578594446182, 0.03616033494472504, 0.04793092608451843, 0.23671036958694458, -0.049299586564302444, -9.964863778577637e-08, 0.04969477653503418, 0.10599171370267868, -0.049178607761859894, -0.03231848403811455, 0.11559614539146423, 0.09532900154590607, 0.004511821083724499, 0.04230466112494469, -0.109064020216465, 0.00783194787800312, 0.12405002117156982, 0.027689332142472267, -0.08739106357097626, 0.1754457950592041, 0.004078148398548365, 0.07557947933673859, -0.06382118910551071, 0.07630345225334167, 0.0026675479020923376, 0.177010640501976, 0.07614374905824661, -0.0200969111174345, 0.09757812321186066, -0.0353410579264164, 0.009912684559822083, -0.051822956651449203, 0.008351803757250309, 0.036392953246831894, 0.10395415872335434, 0.05464841425418854, 0.0026993961073458195, -0.10199500620365143, -0.10007170587778091, -0.02606026828289032, 0.17258086800575256, 0.11305322498083115, -0.013402859680354595, -0.11514550447463989, -0.06979156285524368, 0.09931574761867523, -0.04900204390287399, 0.05941849946975708, -0.031569816172122955, 0.0754995122551918, 0.08311830461025238, 0.05053647235035896, -0.04423469305038452, -0.03949429467320442, 0.0518791601061821, -0.04375465586781502, -0.02617664821445942, -0.034285612404346466, -0.09211524575948715, 0.024661527946591377, 0.04398112744092941, 0.10083294659852982, -0.08477633446455002, -0.07698693871498108, 0.12916876375675201, 0.01426040567457676, 0.06457877904176712, -0.05267565697431564, 0.009750328958034515, 0.011893190443515778], metadata={'source': 'AAAMLP-569to.pdf', 'page': 108}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 109 All folds have 120000 samples. This is expected as training data has 600000 samples, and we made five folds. So far, so good.  Now, we can also check the target distribution per fold.  ═════════════════════════════════════════════════════════════════════════ In [X]: df[df.kfold==0].target.value_counts() Out[X]: 0    97536 1    22464 Name: target, dtype: int64  In [X]: df[df.kfold==1].target.value_counts() Out[X]: 0    97536 1    22464 Name: target, dtype: int64  In [X]: df[df.kfold==2].target.value_counts() Out[X]: 0    97535 1    22465 Name: target, dtype: int64   In [X]: df[df.kfold==3].target.value_counts() Out[X]: 0    97535 1    22465 Name: target, dtype: int64  In [X]: df[df.kfold==4].target.value_counts() Out[X]: 0    97535 1    22465 Name: target, dtype: int64 ═════════════════════════════════════════════════════════════════════════  We see that in each fold, the distribution of targets is the same. This is what we need. It can also be similar and doesn’t have to be the same all the time. Now, when we build our models, we will have the same distribution of targets across every fold.  One of the simplest models we can build is by one-hot encoding all the data and using logistic regression.'),\n",
       " VectorParams(vector=[-0.007783037610352039, -0.04583261162042618, -0.04615422710776329, -0.0022166306152939796, 0.17192144691944122, -0.14076179265975952, -0.04274577274918556, -0.015055768191814423, -0.0915050059556961, -0.02524540200829506, 0.11826411634683609, -0.0979120284318924, -0.0792718380689621, -0.13419190049171448, -0.03031625784933567, 0.08789899945259094, -0.1620386689901352, 0.06102820113301277, -0.1683247834444046, -0.009259919635951519, -0.01181130949407816, 0.13488657772541046, 0.01727607659995556, 0.12380868941545486, -0.08679240942001343, 0.07512777298688889, 0.08117370307445526, 0.09649143368005753, -0.14291039109230042, -0.06655894964933395, -0.025855902582406998, 0.09068365395069122, -0.07022324204444885, -0.00015611718117725104, 0.06015755236148834, 0.035483457148075104, -0.07818221300840378, 0.07849583029747009, -0.03015647642314434, 0.1127103641629219, -0.056386906653642654, -0.0936170443892479, 0.10827242583036423, 0.021696489304304123, 0.09722068905830383, 0.01369479764252901, -0.14847898483276367, -0.10047566145658493, 0.11858557164669037, -0.08635760843753815, -0.032696228474378586, 0.10524061322212219, -0.11292561888694763, 0.0199704859405756, -0.09674820303916931, -0.15169169008731842, -0.014589599333703518, -0.05008992552757263, 0.11564101278781891, 0.024715714156627655, -0.08124841004610062, -0.05182715877890587, 0.05099134519696236, -0.06273964047431946, 0.008912184275686741, -0.07554967701435089, -0.1223478764295578, 0.010945817455649376, -0.11368299275636673, 0.12463096529245377, -0.0885588526725769, 0.060355138033628464, -0.11201097071170807, 0.10319946706295013, -0.031800661236047745, 0.014886671677231789, 0.21225151419639587, -0.03572656959295273, 0.17010906338691711, 0.052733879536390305, -0.1797446608543396, 0.029371457174420357, 0.05392460525035858, -0.037716519087553024, -0.02096235565841198, -0.1465974599123001, -0.008580626919865608, 0.02678103558719158, -0.02647237479686737, -0.03611571714282036, 0.06884545832872391, -0.07196605205535889, 0.011641384102404118, 0.028453808277845383, -0.0016166613204404712, 0.09977900236845016, 0.038564763963222504, 0.06546314805746078, 0.0005477839149534702, 0.14557389914989471, -0.08903774619102478, 0.023000553250312805, 0.02069569006562233, 0.024394970387220383, -0.06965275853872299, 0.007169447373598814, 0.2012299746274948, 0.09259196370840073, 0.10455043613910675, -0.052433811128139496, 0.11391659080982208, -0.06549064069986343, -0.09407962113618851, 0.011747214011847973, 0.05460909754037857, 0.03062429279088974, -0.05971366539597511, 0.017126308754086494, -0.14102572202682495, 0.12197265028953552, -0.08559945225715637, 0.038164954632520676, 0.013830597512423992, 0.10260648280382156, -0.05685814470052719, -0.09512583166360855, -0.032422471791505814, 1.735412285224889e-32, -0.08610302954912186, 0.04512948915362358, 0.015207884833216667, -0.14602887630462646, -0.05696218088269234, -0.04238055273890495, -0.04206158220767975, 0.04361047223210335, 0.04080020263791084, 0.1281987577676773, -0.22221003472805023, 0.08779706805944443, -0.1057305783033371, -0.03413692116737366, -0.02744942717254162, -0.0648488774895668, 0.04223793372511864, -0.022583119571208954, -0.04862741380929947, 0.018215777352452278, 0.2810311019420624, -0.06019896641373634, 0.02780231460928917, -0.13356071710586548, -0.030571136623620987, -0.09397824108600616, -0.12280616909265518, -0.009415335021913052, -0.09655182808637619, 0.011620909906923771, -0.1904228776693344, -0.012198819778859615, 0.004768818151205778, -0.05037630721926689, -0.00036222831113263965, -0.10022050887346268, 0.07874110341072083, 0.10399194806814194, -0.0007920271018519998, -0.005832046736031771, -0.07728518545627594, 0.043311957269907, 0.05453917756676674, -0.008803942240774632, 0.006706038024276495, 0.001240075915120542, 0.11119265109300613, 0.0698673203587532, -0.07578226923942566, 0.07914893329143524, -0.016325632110238075, -0.10546492785215378, 0.011878589168190956, 0.0075689139775931835, -0.1644730567932129, 0.0826469212770462, 0.0807575061917305, -0.07596126943826675, 0.03651290014386177, 0.050579432398080826, -0.0005252709379419684, 0.021693065762519836, -0.02132737636566162, 0.027255389839410782, -0.028608331456780434, -0.027857525274157524, 0.17130303382873535, 0.0164992343634367, 0.07465501874685287, -0.056185461580753326, -0.04321598634123802, -0.04923645034432411, -0.014540407806634903, -0.11767937242984772, 0.09886638820171356, -0.12816758453845978, 0.08633985370397568, -0.02277417480945587, -0.09060981869697571, -0.01909434236586094, 0.11565503478050232, 0.11777153611183167, -0.07754751294851303, -0.14804263412952423, 0.03293566778302193, 0.016901742666959763, 0.02450263872742653, -0.07650443911552429, -0.21954649686813354, -0.07787624001502991, -0.17325344681739807, -0.005128024611622095, -0.01358722522854805, -0.18878482282161713, 0.0827304869890213, -1.8724857998535128e-32, 0.12308093905448914, 0.024445759132504463, 0.09231572598218918, -0.001430824981071055, 0.12692934274673462, 0.09011414647102356, 0.04876188933849335, 0.040703367441892624, -0.030473319813609123, -0.2046242356300354, 0.005678967107087374, -0.13926221430301666, -0.0023276524152606726, -0.05376921221613884, 0.04850861057639122, 0.10273067653179169, -0.23530107736587524, 0.2423594444990158, -0.048321112990379333, 0.06678929179906845, -0.02513566054403782, 0.17375153303146362, -0.12000543624162674, 0.06708814948797226, -0.1459358036518097, -0.021247947588562965, 0.036773115396499634, 0.04856296256184578, 0.07547289878129959, -0.009857412427663803, -0.105974942445755, -0.017265312373638153, -0.1555064618587494, 0.08699729293584824, -0.026383355259895325, 0.023425666615366936, 0.07016942650079727, -0.056308627128601074, -0.11727429181337357, 0.09560584276914597, 0.10302127152681351, 0.14782194793224335, -0.22520659863948822, 0.10543986409902573, -0.026227042078971863, 0.03600509092211723, 0.016409914940595627, 0.032894063740968704, 0.021014317870140076, -0.02257140353322029, 0.03180808946490288, -0.007242328021675348, -0.003634752705693245, 0.0408172532916069, -0.020094605162739754, 0.09813062846660614, -0.030783021822571754, -0.05967002362012863, -0.1747077852487564, -0.039556652307510376, -0.1148960068821907, 0.0023793585132807493, -0.01291172206401825, -0.07601138204336166, 0.1639605462551117, -0.05593553185462952, -0.08344744890928268, 0.08974853903055191, 0.045989636331796646, -0.03988182917237282, -0.11721712350845337, -0.07394798845052719, -0.004760736599564552, -0.12097717076539993, 0.0004823622584808618, 0.09221859276294708, -0.03979688882827759, -0.10108758509159088, 0.004234810825437307, 0.11285267025232315, -0.006480725947767496, 0.003511871211230755, 0.08745813369750977, 0.22233688831329346, 0.0038478269707411528, 0.12416224926710129, 0.1560472697019577, 0.026548119261860847, -0.01873875968158245, -0.020619062706828117, 0.07302642613649368, -0.016756583005189896, 0.17010179162025452, 0.2070656716823578, -0.08519160002470016, -1.0067186906326242e-07, 0.0056068310514092445, 0.009266266599297523, -0.03243842348456383, -0.005353165324777365, 0.06638671457767487, 0.05534673109650612, -0.05431137979030609, 0.0025077282916754484, -0.053499504923820496, 0.040315181016922, 0.06352756172418594, 0.07868044078350067, -0.14128315448760986, -0.002693832851946354, -0.004493148997426033, 0.10110227763652802, -0.029077839106321335, 0.07200608402490616, -0.02411099150776863, 0.1141451969742775, 0.11488671600818634, -0.05341126397252083, -0.048355456441640854, -0.0731615498661995, 0.03258129954338074, -0.15395809710025787, -0.0829295963048935, 0.08689495176076889, 0.05535716563463211, 0.048183705657720566, -0.015998393297195435, -0.15390121936798096, 0.0026341702323406935, 0.008295752108097076, 0.14974482357501984, -0.009268676862120628, 0.13631829619407654, -0.12914907932281494, -0.03788328915834427, 0.03757346794009209, -0.10705666989088058, 0.12145088613033295, -0.10783091932535172, -0.034364696592092514, -0.06458690762519836, -0.009047206491231918, 0.0020446176640689373, 0.06295540183782578, 0.1419130265712738, 0.01182666327804327, -0.03593575581908226, -0.029735898599028587, -0.0960121676325798, 0.015332152135670185, 0.13854406774044037, -0.017649902030825615, -0.029351986944675446, 0.08197496831417084, 0.02158726565539837, 0.005886116065084934, 0.05097552016377449, 0.02174890972673893, 0.0658535286784172, -0.08598153293132782], metadata={'source': 'AAAMLP-569to.pdf', 'page': 109}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 110 ═════════════════════════════════════════════════════════════════════════ # ohe_logres.py import pandas as pd  from sklearn import linear_model from sklearn import metrics from sklearn import preprocessing  def run(fold):     # load the full training data with folds     df = pd.read_csv(\"../input/cat_train_folds.csv\")      # all columns are features except id, target and kfold columns     features = [         f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")     ]      # fill all NaN values with NONE     # note that I am converting all columns to \"strings\"     # it doesn’t matter because all are categories     for col in features:         df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")          # get training data using folds     df_train = df[df.kfold != fold].reset_index(drop=True)      # get validation data using folds     df_valid = df[df.kfold == fold].reset_index(drop=True)      # initialize OneHotEncoder from scikit-learn     ohe = preprocessing.OneHotEncoder()      # fit ohe on training + validation features     full_data = pd.concat(         [df_train[features], df_valid[features]],         axis=0     )     ohe.fit(full_data[features])      # transform training data     x_train = ohe.transform(df_train[features])      # transform validation data     x_valid = ohe.transform(df_valid[features])      # initialize Logistic Regression model     model = linear_model.LogisticRegression()'),\n",
       " VectorParams(vector=[-0.15653257071971893, -0.18854883313179016, -0.11753860861063004, 0.05108680948615074, 0.2526094913482666, -0.21596691012382507, -0.04293373227119446, 0.09601700305938721, -0.1285068541765213, 0.06940913945436478, 0.10304611176252365, -0.1580132693052292, -0.10234306007623672, -0.053050339221954346, -0.031891074031591415, 0.08418470621109009, -0.13556452095508575, -0.002676432952284813, -0.1662011444568634, 0.04471283778548241, 0.005465212278068066, 0.14323438704013824, -0.06319605559110641, 0.2274363934993744, -0.061437223106622696, -0.1175171509385109, 0.030811820179224014, 0.09746363013982773, -0.12296069413423538, -0.062142495065927505, 0.09282989054918289, -0.017710737884044647, 0.0910157635807991, 0.03225297853350639, 0.05318762734532356, 0.07499377429485321, -0.1466951072216034, -0.060560405254364014, -0.1211693063378334, -0.0008062415872700512, 0.03990178927779198, -0.01487769465893507, 0.06635638326406479, 0.01758142188191414, 0.11341838538646698, 0.07839351147413254, -0.09561415016651154, -0.09867437183856964, 0.12238311767578125, -0.0659116804599762, 0.013553357683122158, 0.09671980887651443, -0.11292657256126404, -0.07351362705230713, -0.10926175117492676, -0.13090984523296356, -0.00678768428042531, -0.13399991393089294, 0.14410918951034546, -0.10997495800256729, -0.0481560155749321, -0.021984871476888657, -0.061313286423683167, -0.06471578776836395, 0.06327695399522781, -0.0938117727637291, -0.02680840902030468, -0.10455752164125443, -0.0027001691050827503, 0.1821928322315216, 0.00024445998133160174, -0.06947223842144012, -0.02310139313340187, 0.035959336906671524, 0.17097437381744385, 0.05786914378404617, 0.10911095887422562, -0.09518028795719147, 0.02150547318160534, -0.004479372873902321, -0.17774800956249237, 0.051346052438020706, 0.1827183961868286, -0.06301436573266983, -0.007822846993803978, -0.1406511813402176, 0.10480324923992157, 0.023067766800522804, 0.16583251953125, -0.018782896921038628, 0.06643065065145493, 0.0645785704255104, -0.13147002458572388, 0.09063675254583359, 0.00982882734388113, 0.026024091988801956, 0.12556535005569458, 0.07378195971250534, -0.02453278936445713, 0.07330439239740372, -0.053368017077445984, 0.03872076794505119, 0.1251486986875534, 0.03514126315712929, 0.10885124653577805, -0.05686341971158981, 0.1517961025238037, 0.10793869942426682, 0.10016454756259918, -0.06338299065828323, 0.097044438123703, -0.008806956931948662, 0.03022572584450245, 0.09144419431686401, 0.17157794535160065, 0.034287359565496445, -0.08253012597560883, -0.016511179506778717, -0.1357371211051941, 0.17036652565002441, -0.05293121188879013, 0.037847042083740234, 0.07379519194364548, 0.07964523881673813, -0.04991866648197174, -0.11402107775211334, -0.08972004055976868, 5.810948692088481e-33, -0.09705028682947159, 0.02163531631231308, 0.013555653393268585, -0.25078147649765015, 0.04598034918308258, -0.0015038078418001533, -0.11444974690675735, 0.058368146419525146, -0.12546105682849884, 0.12415670603513718, -0.16927041113376617, 0.0797877237200737, -0.06544655561447144, 0.07918878644704819, 0.04860680550336838, -0.15902429819107056, 0.081397145986557, -0.0008904135320335627, -0.07321172952651978, 0.018137972801923752, 0.24489891529083252, -0.13020238280296326, 0.006269991863518953, -0.11734975874423981, -0.03127047419548035, 0.06082218885421753, 0.050141774117946625, 0.03324295952916145, -0.119036965072155, 0.07282834500074387, -0.2050323784351349, 0.022482579573988914, 0.028733594343066216, -0.05821556597948074, 0.0035018501803278923, -0.07116171717643738, 0.12181439995765686, 0.003327323356643319, -0.0750482827425003, -0.07207870483398438, -0.10276573896408081, 0.07631461322307587, 0.0462070032954216, -0.06437600404024124, 0.004109477158635855, -0.09714493155479431, 0.0641414001584053, 0.2513083517551422, -0.07637819647789001, 0.09299696981906891, 0.031196381896734238, -0.19632025063037872, -0.08621848374605179, -0.0028861246537417173, -0.11373666673898697, 0.042023107409477234, 0.11542290449142456, -0.06190863251686096, 0.0530773401260376, 0.06247396394610405, 0.09619133919477463, -0.09203758090734482, -0.06034009903669357, 0.018492229282855988, 0.017288586124777794, -0.0033053697552531958, 0.06281854957342148, -0.05977335944771767, 0.09697704017162323, -0.017528727650642395, -0.10423601418733597, 0.08010756969451904, 0.07509732246398926, -0.05688440427184105, 0.043336305767297745, -0.09268148988485336, 0.1857207864522934, -0.02032363973557949, -0.16038548946380615, 0.00810299813747406, -0.07587036490440369, 0.18659617006778717, -0.029015466570854187, -0.19414642453193665, 0.003577102907001972, -0.06011540815234184, 0.0062883817590773106, -0.0258085485547781, -0.3214937746524811, -0.07234839349985123, -0.07426939159631729, -0.08911752700805664, 0.10558980703353882, -0.019730200991034508, -0.10233571380376816, -6.287022802145554e-33, 0.06081631779670715, -0.02266744151711464, 0.027217181399464607, 0.0724944919347763, 0.08946550637483597, 0.054112132638692856, 0.04251084476709366, 0.07641094923019409, -0.053240057080984116, -0.306390643119812, 0.14253902435302734, -0.11347846686840057, 0.08345126360654831, 0.02405664324760437, 0.1190432459115982, 0.008640659041702747, -0.15223635733127594, 0.19693176448345184, -0.0268541369587183, 0.12008249759674072, 0.043107833713293076, 0.09391647577285767, -0.12665744125843048, -0.059169702231884, -0.0850374773144722, -0.047018151730298996, 0.04641219973564148, 0.19571958482265472, 0.09485580772161484, -0.0024543406907469034, -0.08422497659921646, 0.15672440826892853, -0.16365808248519897, 0.15196417272090912, 0.03042876534163952, 0.04234836995601654, 0.05710246041417122, -0.034146714955568314, -0.049325525760650635, 0.13044601678848267, 0.20818732678890228, 0.09704497456550598, -0.2436121106147766, -0.06359317898750305, 0.025565285235643387, 0.05092423036694527, 0.0349646620452404, 0.03700374811887741, 0.11693780869245529, -0.07922856509685516, 0.10825932770967484, -0.1371675282716751, 0.05717400088906288, 0.18956229090690613, -0.12657158076763153, 0.14819912612438202, -0.023556504398584366, -0.016659412533044815, -0.14082220196723938, -0.08375811576843262, -0.05410671979188919, 0.05968880653381348, 0.08285319805145264, -0.002686023712158203, 0.026618167757987976, 0.030205482617020607, -0.188846617937088, 0.06647415459156036, 0.052243392914533615, 0.09791428595781326, -0.1280662715435028, -0.019766321405768394, 0.08114100992679596, 0.025432590395212173, -0.1307489275932312, 0.010732262395322323, -0.08157292008399963, -0.14313249289989471, 0.0366230346262455, -0.007063193712383509, -0.07406678795814514, 0.0681932345032692, 0.11147937923669815, 0.20130476355552673, 0.01999943144619465, 0.06116954982280731, 0.1521655023097992, 0.19134968519210815, 0.030053382739424706, -0.0541422963142395, -0.01660110056400299, 0.02911721169948578, 0.11994576454162598, 0.14012828469276428, -0.10212817043066025, -9.921588173256168e-08, -0.045951005071401596, -0.031916432082653046, -0.015095259062945843, 0.07367189228534698, 0.17149078845977783, 0.10158597677946091, -0.009738042950630188, -0.10689086467027664, -0.07649727165699005, 0.04076408967375755, 0.1470794379711151, 0.0446854867041111, -0.18687613308429718, -0.035383082926273346, -0.06886086612939835, 0.1079915389418602, 0.04597970098257065, 0.08356959372758865, 0.0014751447597518563, -0.01981261558830738, -0.04810938239097595, -0.06102989614009857, -0.03743796795606613, -0.1693587452173233, -0.04116535931825638, -0.13794808089733124, -0.09437873214483261, 0.20348721742630005, -0.05194684863090515, -0.05916720628738403, -0.038623176515102386, -0.11081363260746002, 0.007466898765414953, 0.10124485194683075, 0.01757422275841236, 0.10508240014314651, 0.04087850823998451, -0.0012465822510421276, 0.01589609868824482, 0.06895202398300171, 0.016186220571398735, 0.1461629420518875, -0.09679915010929108, -0.06888426840305328, 0.018926113843917847, 0.060799490660429, -0.024922426789999008, 0.030713720247149467, 0.08979737758636475, 0.008213934488594532, 0.011597665026783943, 0.09537028521299362, -0.09521277993917465, -0.015024595893919468, 0.16359081864356995, -0.014840345829725266, -0.11437218636274338, -0.08068766444921494, -0.1005873829126358, 0.151797354221344, -0.021171387284994125, -0.15502533316612244, 0.001225713756866753, -0.0059964838437736034], metadata={'source': 'AAAMLP-569to.pdf', 'page': 110}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 111     # fit model on training data (ohe)     model.fit(x_train, df_train.target.values)      # predict on validation data     # we need the probability values as we are calculating AUC     # we will use the probability of 1s     valid_preds = model.predict_proba(x_valid)[:, 1]      # get roc auc score     auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)      # print auc     print(auc)   if __name__ == \"__main__\":     # run function for fold = 0     # we can just replace this number and      # run this for any fold     run(0) ═════════════════════════════════════════════════════════════════════════  So, what’s happening?  We have created a function that splits data into training and validation, given a fold number, handles NaN values, applies one-hot encoding on all the data and trains a simple Logistic Regression model.  When we run this chunk of code, it produces an output like this:  ═════════════════════════════════════════════════════════════════════════ ❯ python ohe_logres.py /home/abhishek/miniconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1): STOP: TOTAL NO. of ITERATIONS REACHED LIMIT. Increase the number of iterations (max_iter) or scale the data as shown in:     https://scikit-learn.org/stable/modules/preprocessing.html. Please also refer to the documentation for alternative solver options:     https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression   extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG) 0.7847865042255127 ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[-0.1294431984424591, -0.12421160936355591, -0.07812022417783737, 0.053521666675806046, 0.22692276537418365, -0.18767696619033813, 0.015902575105428696, 0.1254139393568039, -0.09561426192522049, 0.08172453194856644, 0.05647692084312439, -0.13063038885593414, -0.1273690015077591, -0.06912938505411148, -0.06453438848257065, 0.0817723348736763, -0.1552044004201889, -0.09411434084177017, -0.1698053926229477, 0.09814678132534027, 0.04034099727869034, 0.10532665997743607, 0.024162301793694496, 0.2004653513431549, -0.014173035509884357, -0.041619572788476944, 0.08496353030204773, 0.1344326287508011, -0.06085137650370598, -0.09755068272352219, -0.023753391578793526, -0.009176652878522873, 0.08058547228574753, 0.00927460566163063, 0.06226886436343193, -0.00013256387319415808, -0.09775103628635406, -0.00548949372023344, -0.07786963880062103, -0.05278795212507248, 0.043784238398075104, -0.002119050594046712, 0.0016793953254818916, 0.06052340939640999, 0.04602157697081566, 0.035264112055301666, -0.107028067111969, -0.04996357858181, 0.07751354575157166, -0.016739187762141228, 0.04164740443229675, 0.02614990621805191, -0.09085157513618469, -0.1457509696483612, -0.17468823492527008, -0.12264257669448853, 0.05364024639129639, -0.12971259653568268, 0.07266246527433395, -0.09733013063669205, -0.005898958072066307, 0.004141803830862045, -0.022607270628213882, -0.03048042021691799, 0.007540409918874502, -0.03993549942970276, -0.10710129141807556, -0.020078886300325394, 0.02804766222834587, 0.1531977355480194, -0.06569050997495651, -0.018815327435731888, 0.001956932246685028, 0.0237545408308506, 0.12954381108283997, 0.009579897858202457, 0.07113641500473022, -0.07919328659772873, -0.015471265651285648, -0.06926991045475006, -0.08289245516061783, -0.013209686614573002, 0.11214587837457657, -0.09049925208091736, 0.0659596174955368, -0.1545455902814865, 0.1533687859773636, -0.06467965990304947, 0.06290853768587112, -0.0893537849187851, 0.15112407505512238, 0.006928945891559124, -0.06315268576145172, 0.09340197592973709, 0.029445277526974678, 0.09446488320827484, 0.07868541777133942, 0.015377247706055641, -0.021945765241980553, 0.12045896798372269, -0.04894913733005524, 0.11123989522457123, 0.09068956226110458, 0.0017649236833676696, 0.03868352249264717, -0.032329246401786804, 0.1219465583562851, 0.05231281742453575, 0.036828719079494476, 0.0337660126388073, 0.10675936937332153, -0.012824146077036858, -0.008081899024546146, 0.07106392830610275, 0.11874236911535263, 0.11489406228065491, -0.11612165719270706, 0.0809173509478569, -0.24569565057754517, 0.15266798436641693, -0.060494765639305115, 0.07024333626031876, 0.08403480798006058, 0.09124354273080826, -0.0010535013861954212, -0.06125639006495476, -0.04636358097195625, 1.1299464426534194e-32, -0.04438111558556557, 0.016915637999773026, -0.05825133994221687, -0.1752595603466034, 0.011427697725594044, -0.012935577891767025, -0.10107822716236115, 0.03098388947546482, -0.008450975641608238, 0.10415132343769073, -0.15858863294124603, 0.07995915412902832, 0.0006227791309356689, 0.013097039423882961, 0.04611727595329285, -0.04441847652196884, 0.07933786511421204, -0.013581600040197372, -0.08417250216007233, 0.11708253622055054, 0.1340532749891281, -0.08242525905370712, 0.0015078814467415214, -0.13214506208896637, -0.0587003119289875, 0.11825728416442871, 0.008057832717895508, 0.14272712171077728, -0.08987496793270111, 0.040422115474939346, -0.15898284316062927, 0.011002818122506142, -0.0024718260392546654, -0.06934556365013123, 0.015252986922860146, 0.03289090842008591, 0.07693661004304886, 0.004230388905853033, -0.024927841499447823, -0.03555700182914734, -0.05909395217895508, 0.029462823644280434, 0.053670886904001236, -0.037108078598976135, 0.043444182723760605, -0.1365230530500412, -0.03464074805378914, 0.2334214448928833, -0.16066648066043854, 0.11555616557598114, -0.008083556778728962, -0.11395096778869629, -0.06207413971424103, 0.047673989087343216, -0.1044379472732544, 0.024939823895692825, 0.03180301561951637, -0.006902629043906927, 0.060147058218717575, 0.012616252526640892, 0.1669631004333496, -0.10049132257699966, -0.03267722949385643, -0.023998955264687538, 0.04870767146348953, 0.14771853387355804, 0.10964541882276535, -0.028390798717737198, 0.011994974687695503, -0.005191677715629339, -0.12203893065452576, 0.0734296590089798, 0.011869454756379128, -0.015352537855505943, -0.01473094429820776, -0.04124501347541809, 0.13370564579963684, 0.03328954800963402, -0.0796385332942009, 0.0006461846060119569, 0.022217117249965668, 0.21439962089061737, -0.04628627002239227, -0.13546718657016754, -0.013812755234539509, -0.08158531039953232, 0.04295234754681587, -0.008213928900659084, -0.3272969424724579, 0.007352751214057207, -0.08521094173192978, -0.05469784140586853, 0.11413419991731644, -0.021464122459292412, -0.04276496544480324, -1.2648016525052477e-32, 0.035118285566568375, -0.0056218234822154045, 0.05284823477268219, -0.011145511642098427, 0.025434937328100204, 0.049987465143203735, 0.06660398840904236, 0.09687110781669617, -0.1108751967549324, -0.21224264800548553, 0.1664516180753708, -0.11901804059743881, 0.04391055926680565, 0.0572480708360672, 0.11597312241792679, 0.043829094618558884, -0.1163904070854187, 0.21954067051410675, 0.0461256243288517, 0.009722280316054821, 0.08463820070028305, 0.13917256891727448, -0.06966391205787659, -0.0567733496427536, -0.15257114171981812, -0.006251184735447168, -0.012598943896591663, 0.04432770982384682, 0.03578071668744087, -0.06754443794488907, -0.07612691074609756, 0.148060142993927, -0.19789394736289978, 0.13688944280147552, -0.02816900424659252, -0.0038712036330252886, -0.04690953344106674, -0.025220366194844246, -0.08613190799951553, 0.13404002785682678, 0.09170988947153091, 0.08426906168460846, -0.22897620499134064, -0.07037132978439331, -0.015088023617863655, -0.022752799093723297, -0.00900749396532774, 0.07022970914840698, 0.05868052318692207, -0.09784921258687973, 0.09044528752565384, -0.11232495307922363, -0.003711867844685912, 0.13350577652454376, -0.09592431783676147, 0.19747625291347504, -0.030578522011637688, -0.02752538211643696, -0.15888948738574982, 0.01672414503991604, -0.0627397820353508, 0.07317889481782913, 0.014979355037212372, -0.05553865805268288, 0.011859692633152008, 0.017577769234776497, -0.13018611073493958, 0.03875935077667236, 0.10719415545463562, 0.026899784803390503, -0.05796048045158386, -0.050544578582048416, -0.03486579656600952, -0.056489843875169754, -0.03793954849243164, 0.10380150377750397, -0.08547230809926987, -0.07557845115661621, 0.005196703597903252, -0.011991685256361961, -0.07114209234714508, -0.04178342968225479, 0.06284331530332565, 0.20454303920269012, -0.07982078194618225, 0.06699010729789734, 0.04864145442843437, 0.08505523949861526, 0.07891800999641418, 0.014809033833444118, -0.020078949630260468, 0.06784360110759735, 0.1007300540804863, 0.14602209627628326, -0.07924886792898178, -1.001830938207604e-07, -0.003410270670428872, 0.06378424167633057, 0.05377602204680443, 0.12202977389097214, 0.08521455526351929, 0.10739205032587051, -0.05184897035360336, -0.05954056605696678, -0.18849316239356995, 0.017719553783535957, 0.04139513149857521, 0.030920512974262238, -0.21206410229206085, 0.01975276693701744, -0.08650224655866623, 0.07991637289524078, -0.029086915776133537, 0.11678209155797958, -0.011505687609314919, -0.04718182235956192, -0.025416286662220955, -0.0292056854814291, 0.011143377982079983, -0.08745499700307846, -0.04899284988641739, -0.12632964551448822, -0.02664320170879364, 0.14378248155117035, -0.17933209240436554, -0.025212496519088745, 0.06727547198534012, -0.10810858756303787, 0.01674019917845726, 0.04425773769617081, -0.0008274084539152682, 0.06984313577413559, 0.05510933697223663, -0.08920302242040634, 0.01966184563934803, 0.12928925454616547, -0.008507128804922104, 0.072876937687397, -0.14274679124355316, -0.029987240210175514, 0.03301790729165077, -0.025536997243762016, 0.04569590836763382, -0.04678395390510559, 0.06818389147520065, -0.05811242014169693, -0.02229631319642067, 0.052505675703287125, -0.13048483431339264, -0.026238666847348213, 0.08854444324970245, 0.0322163924574852, -0.09713967144489288, -0.031009189784526825, -0.07172851264476776, 0.11833743005990982, -0.070685975253582, -0.17890363931655884, 0.022578740492463112, -0.037249621003866196], metadata={'source': 'AAAMLP-569to.pdf', 'page': 111}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 112 There are a few warnings. It seems logistic regression did not converge for the max number of iterations. We didn’t play with the parameters, so that is fine. We see that AUC is ~ 0.785.  Let’s run it for all folds now with a simple change in code.  ═════════════════════════════════════════════════════════════════════════ # ohe_logres.py . . .      # initialize Logistic Regression model     model = linear_model.LogisticRegression()      # fit model on training data (ohe)     model.fit(x_train, df_train.target.values)      # predict on validation data     # we need the probability values as we are calculating AUC     # we will use the probability of 1s     valid_preds = model.predict_proba(x_valid)[:, 1]      # get roc auc score     auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)      # print auc     print(f\"Fold = {fold}, AUC = {auc}\")   if __name__ == \"__main__\":     for fold_ in range(5):         run(fold_) ═════════════════════════════════════════════════════════════════════════  Please note that we are not making a lot of changes and that’s why I have shown only some lines of the code; some of which have changes.  This gives:  ═════════════════════════════════════════════════════════════════════════ ❯ python -W ignore ohe_logres.py Fold = 0, AUC = 0.7847865042255127 Fold = 1, AUC = 0.7853553605899214 Fold = 2, AUC = 0.7879321942914885'),\n",
       " VectorParams(vector=[-0.006606763228774071, -0.10072637349367142, -0.13178543746471405, 0.07298710942268372, 0.16607098281383514, -0.011574487201869488, 0.029612865298986435, -0.07385269552469254, -0.10170961916446686, 0.018670352175831795, -0.04370071366429329, -0.1460036039352417, -0.08486682921648026, -0.046598926186561584, -0.0684671476483345, 0.11589694023132324, -0.06817641109228134, 0.06871306896209717, -0.15967227518558502, -0.02868838608264923, -0.05395349860191345, 0.1085335910320282, 0.002299566986039281, 0.16001304984092712, -0.03536171093583107, -0.033375952392816544, 0.011956519447267056, 0.07994763553142548, -0.14643074572086334, -0.03389319032430649, -0.04562542214989662, 0.0422472320497036, 0.061233799904584885, -0.03751115873456001, 0.0233002956956625, -0.006074174307286739, -0.1414206326007843, 0.051194772124290466, -0.049216143786907196, -0.00634546997025609, 0.012847243808209896, -0.007463766727596521, 0.0717710554599762, 0.04910696670413017, 0.001817729091271758, 0.049429237842559814, -0.09086014330387115, -0.052569322288036346, 0.0013556086923927069, -0.03900456801056862, 0.0647817999124527, 0.09924501180648804, -0.19343113899230957, 0.029706226661801338, -0.1394995152950287, -0.17781443893909454, -0.020066823810338974, -0.11969977617263794, 0.10285945981740952, 0.06216523051261902, -0.06810175627470016, -0.09288938343524933, 0.011183949187397957, -0.09178417176008224, 0.06343449652194977, -0.054030176252126694, -0.06379443407058716, 0.00021486429614014924, -0.0337279736995697, 0.07778194546699524, -0.041285961866378784, 0.05222754552960396, -0.03549696132540703, 0.100734181702137, 0.13081349432468414, 0.07794325053691864, 0.18215250968933105, -0.024370109662413597, 0.2105238437652588, 0.03989673778414726, -0.14070641994476318, 0.03749938681721687, 0.06908352673053741, -0.002667117863893509, 0.07752048224210739, -0.1943257749080658, 0.06758816540241241, 0.045809775590896606, -0.018497632816433907, 0.0045753363519907, 0.055493876338005066, -0.03843148797750473, 0.11098136752843857, -0.029781365767121315, 0.007708053104579449, 0.12366460263729095, 0.1478825807571411, -0.01293034665286541, -0.007290463894605637, 0.08597148954868317, -0.09514514356851578, 0.05618948116898537, 0.0461713932454586, -0.10175342857837677, 0.004266409669071436, -0.033901333808898926, 0.1373777538537979, 0.0690695196390152, 0.11696966737508774, -0.08478882163763046, 0.04477747529745102, -0.06411808729171753, -0.06465312093496323, -0.0027411989867687225, 0.0738905817270279, 0.03524864464998245, -0.04368618503212929, -0.028772376477718353, -0.10022380948066711, 0.16164055466651917, -0.1673373579978943, -0.031026024371385574, -0.0026836013421416283, 0.08080529421567917, 0.09076709300279617, -0.044353850185871124, -0.006678981240838766, 1.5484228723565353e-32, -0.047474704682826996, 0.04081122577190399, -0.036304231733083725, -0.06250271201133728, 0.04383167624473572, -0.1355542689561844, 0.009152608923614025, 0.005366472061723471, 0.04935615509748459, 0.15759284794330597, -0.10004547983407974, 0.13518978655338287, -0.03060862608253956, 0.013890431262552738, 0.005381714552640915, -0.0204781424254179, 0.015809381380677223, -0.049596987664699554, -0.08330775052309036, -0.007702073082327843, 0.25747472047805786, 0.02049705944955349, 0.007137230597436428, -0.077943816781044, 0.028363622725009918, -0.07311394065618515, -0.11100316047668457, -0.02774486131966114, -0.060850851237773895, 0.03937830403447151, -0.2728484272956848, -0.015140483155846596, -0.019748874008655548, -0.06575692445039749, -0.03719392791390419, -0.16907870769500732, 0.055946990847587585, 0.10264992713928223, -0.04655739292502403, 0.02846318669617176, 0.044606346637010574, 0.025685949251055717, 0.038247521966695786, -0.04733417555689812, 0.04002322629094124, 0.0833619087934494, 0.10068859159946442, 0.1287035197019577, -0.1664331555366516, 0.1741274744272232, -0.0379522368311882, -0.08106502890586853, 0.017351018264889717, 0.10314546525478363, -0.14938034117221832, 0.08981025964021683, 0.12126718461513519, -0.048277296125888824, 0.04881281033158302, 0.02682853490114212, 0.01391677837818861, -0.03783736750483513, -0.0008235960849560797, -0.01917882263660431, 0.026770714670419693, -0.03319137543439865, 0.16140267252922058, 0.010416492819786072, 0.028065191581845284, -0.08279640227556229, -0.09103911370038986, 0.028361449018120766, -0.06426563113927841, -0.13960197567939758, -0.004703686572611332, -0.08625596761703491, 0.13499049842357635, -0.008681271225214005, -0.08784952759742737, 0.025483397766947746, 0.04544202238321304, 0.19076628983020782, -0.002017994411289692, -0.13746216893196106, 0.015113560482859612, -0.078924261033535, -0.009369643405079842, -0.11066609621047974, -0.17864945530891418, -0.07919091731309891, -0.06189967319369316, -0.06422699242830276, 0.07010683417320251, -0.13283485174179077, 0.005929000675678253, -1.477192469737314e-32, 0.016251493245363235, -0.10767465084791183, 0.05880243703722954, 0.05364491418004036, 0.02815396524965763, 0.07308974862098694, 0.003952072933316231, 0.019116081297397614, -0.018541501834988594, -0.19736060500144958, 0.04286283254623413, -0.06348425149917603, 0.049928177148103714, -0.019647423177957535, 0.027773577719926834, -0.013939916156232357, -0.1600513607263565, 0.24983364343643188, 0.025738853961229324, 0.20754145085811615, -0.03206149861216545, 0.2032952457666397, -0.08614125102758408, 0.05839211493730545, -0.056575216352939606, -0.04262504354119301, 0.04088793694972992, 0.044370949268341064, 0.08954866230487823, 0.019306721165776253, -0.08252851665019989, 0.059027545154094696, -0.00968839693814516, 0.053149331361055374, -0.13993221521377563, -0.11114950478076935, 0.09145431965589523, -0.060190264135599136, -0.09228990226984024, 0.16300265491008759, 0.19129769504070282, 0.09192980825901031, -0.295396089553833, 0.11474547535181046, -0.023299966007471085, 0.019478116184473038, -0.06630736589431763, 0.03333447128534317, -0.06746449321508408, 0.0213204026222229, 0.10974549502134323, -0.035982392728328705, -0.10074836015701294, 0.04751960560679436, -0.04177803918719292, 0.11477275937795639, -0.050465259701013565, -0.04926636442542076, -0.050118688493967056, 0.09700828045606613, -0.1531846970319748, 0.06968065351247787, 0.06193958967924118, -0.114573173224926, 0.1474658101797104, -0.02402794547379017, -0.1015094667673111, 0.06766953319311142, -0.03400951623916626, 0.006634140852838755, -0.032009873539209366, -0.09142682701349258, -0.08101697266101837, -0.02948831021785736, 0.007081231568008661, 0.03425278142094612, 0.001306204474531114, -0.004171919077634811, -0.005171718075871468, 0.10661981254816055, -0.06288168579339981, -0.0017074383795261383, 0.07152276486158371, 0.23379382491111755, -0.034199658781290054, 0.07273025065660477, 0.19980724155902863, 0.04334864020347595, 0.023465948179364204, -0.006710864137858152, 0.05799926817417145, 0.019745446741580963, 0.1434759795665741, 0.2900938093662262, -0.07203495502471924, -9.944793788463357e-08, -0.024709530174732208, 0.16781006753444672, -0.08382236957550049, -0.01691991463303566, -0.019591500982642174, 0.02714136429131031, -0.10155508667230606, 0.05171439051628113, -0.10049691051244736, 0.15342698991298676, 0.14917856454849243, 0.003566698869690299, -0.12814117968082428, 0.051936011761426926, -0.034452009946107864, 0.13142229616641998, 0.032787732779979706, 0.07104599475860596, -0.07248496264219284, 0.05843580514192581, 0.1004166230559349, -0.007818939164280891, 0.08881168067455292, -0.06682684272527695, -0.007667648606002331, -0.14829391241073608, -0.0308986846357584, 0.08379458636045456, 0.09103255718946457, -0.01671619340777397, -0.13508813083171844, -0.10703197866678238, -0.0570577047765255, 0.019004493951797485, 0.04604490473866463, 0.0940534844994545, 0.06708013266324997, -0.17524652183055878, -0.012239603325724602, 0.1290038675069809, -0.043267544358968735, 0.06975413113832474, -0.23206856846809387, -0.09671779721975327, -0.12277723103761673, 0.0439198762178421, -0.03172488883137703, 0.044647060334682465, 0.14149224758148193, 0.02069435827434063, -0.10321645438671112, -0.057520147413015366, -0.13384762406349182, -0.01821283996105194, 0.17416881024837494, 0.03388319909572601, -0.05244943127036095, -0.03537571802735329, 0.07323151081800461, 0.0381491594016552, 0.04943246394395828, -0.0778183862566948, -0.053186189383268356, -0.07989457994699478], metadata={'source': 'AAAMLP-569to.pdf', 'page': 112}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 113 Fold = 3, AUC = 0.7870315929550808 Fold = 4, AUC = 0.7864668243125608 ═════════════════════════════════════════════════════════════════════════  Note that I use “-W ignore” to ignore all the warnings.   We see that AUC scores are quite stable across all folds. The average AUC is 0.78631449527. Quite good for our first model!  Many people will start this kind of problem with a tree-based model, such as random forest. For applying random forest in this dataset, instead of one-hot encoding, we can use label encoding and convert every feature in every column to an integer as discussed previously.  The code is not very different from one hot encoding code. Let’s take a look.  ═════════════════════════════════════════════════════════════════════════ # lbl_rf.py import pandas as pd  from sklearn import ensemble from sklearn import metrics from sklearn import preprocessing   def run(fold):      # load the full training data with folds     df = pd.read_csv(\"../input/cat_train_folds.csv\")      # all columns are features except id, target and kfold columns     features = [         f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")     ]      # fill all NaN values with NONE     # note that I am converting all columns to \"strings\"     # it doesnt matter because all are categories     for col in features:         df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")          # now its time to label encode the features     for col in features:                  # initialize LabelEncoder for each feature column'),\n",
       " VectorParams(vector=[-0.055880554020404816, -0.08366504311561584, -0.07284509390592575, 0.04340217262506485, 0.23452317714691162, -0.05814486742019653, 0.07290823012590408, 0.0071545373648405075, -0.08027592301368713, -0.0116059435531497, -0.00935791339725256, -0.19878092408180237, -0.08232176303863525, -0.08024922758340836, -0.05556393787264824, 0.08259943872690201, -0.06258553266525269, 0.007303125690668821, -0.1294723004102707, -0.009599464945495129, 0.01563108153641224, 0.09984328597784042, 0.006520262453705072, 0.12245858460664749, -0.013093600980937481, -0.06650491803884506, 0.033370401710271835, 0.1311848759651184, -0.05576271191239357, -0.038377437740564346, 0.0207379013299942, -0.024646207690238953, 0.06764382869005203, -0.019842520356178284, 0.03076396882534027, -0.007430479396134615, -0.12543296813964844, -0.028299573808908463, -0.04048992693424225, 0.06556160002946854, 0.016515959054231644, -0.045837461948394775, 0.037368547171354294, 0.04598815366625786, -0.011385521851480007, 0.11240143328905106, -0.11538729071617126, -0.05919203534722328, 0.045767366886138916, 0.0013380716554820538, 0.08145881444215775, 0.0245883297175169, -0.15750661492347717, -0.032878026366233826, -0.1282343566417694, -0.0667756125330925, 0.016588952392339706, -0.17820316553115845, 0.08414070308208466, -0.026061920449137688, 0.04712393134832382, -0.10614336282014847, -0.023468105122447014, -0.033411797136068344, 0.01463149394840002, -0.042211562395095825, -0.08189476281404495, -0.031000107526779175, -0.08372899144887924, 0.02675376832485199, -0.042446114122867584, 0.044477611780166626, -0.013098117895424366, 0.11001188308000565, 0.038906898349523544, 0.038805630058050156, 0.13965067267417908, -0.04501555114984512, 0.08925234526395798, 0.002389720641076565, -0.2112441062927246, 0.04867801070213318, 0.08080419898033142, -0.0010223117424175143, 0.0793607160449028, -0.1370970755815506, 0.10101578384637833, -0.006794992368668318, 0.02451462484896183, -0.05698181688785553, 0.11634301394224167, -0.013589069247245789, -0.029929805546998978, 0.05681942403316498, -0.027645258232951164, 0.09003373980522156, 0.11914698034524918, -0.02718786895275116, 0.028018668293952942, 0.08119423687458038, -0.13250909745693207, 0.0011272019473835826, 0.029976891353726387, -0.06378359347581863, -0.023608792573213577, -0.05149145424365997, 0.042126450687646866, 0.11449629068374634, 0.0912955179810524, -0.009834794327616692, 0.04610913619399071, -0.022374199703335762, -0.012942221015691757, 0.09514771401882172, 0.09149029105901718, 0.12344826757907867, -0.09990668296813965, 0.05049969628453255, -0.1390605866909027, 0.15037252008914948, -0.20366764068603516, 0.03447822853922844, 0.008054403588175774, -0.03956594690680504, -0.053779613226652145, -0.04676755890250206, -0.043403737246990204, 1.6328583377025125e-32, -0.02125823125243187, -0.010208838619291782, -0.03861366584897041, -0.10178858041763306, 0.028574177995324135, -0.12895752489566803, -0.06229700893163681, 0.010331716388463974, 0.07451731711626053, 0.10053447633981705, -0.14168280363082886, 0.0826512798666954, -0.023986566811800003, -0.017846455797553062, -0.04962430149316788, 0.014983464032411575, 0.004280694294720888, -0.019165493547916412, -0.11161236464977264, 0.09443411231040955, 0.2292923480272293, 0.02279103919863701, -0.019478030502796173, -0.029324276372790337, -0.06457620859146118, 0.04778354614973068, -0.09891637414693832, 0.04694032669067383, -0.06786786019802094, 0.04460553079843521, -0.2590101361274719, -0.05667221546173096, 0.0370553582906723, -0.07941032201051712, -0.0472683347761631, -0.11340934783220291, 0.14639204740524292, 0.09209084510803223, -0.10878061503171921, -0.05787016078829765, 0.03602641448378563, 0.05216735601425171, 0.017331335693597794, -0.11208032816648483, 0.015571288764476776, -0.052477650344371796, 0.0429152175784111, 0.1081136018037796, -0.00196648552082479, 0.1369805485010147, 0.0015446282923221588, -0.19029255211353302, 0.018047431483864784, 0.07221723347902298, -0.15996189415454865, 0.2087705135345459, 0.08880530297756195, 0.04791586101055145, 0.042951229959726334, 0.04961056262254715, 0.029770009219646454, -0.0010512080043554306, 0.0215945802628994, -0.027633188292384148, 0.10643427073955536, 0.03361152112483978, 0.10533416271209717, -0.07037591189146042, 0.05822164937853813, -0.08846951276063919, -0.13597264885902405, 0.10973139852285385, -0.05963651463389397, -0.09167936444282532, 0.05603678897023201, -0.09394942969083786, 0.050269704312086105, 0.04085155576467514, -0.0795421153306961, 0.07145122438669205, -0.025705959647893906, 0.21705874800682068, -0.10486495494842529, -0.161709725856781, 0.07593382149934769, 0.014899584464728832, -0.008606874383985996, -0.09540995955467224, -0.24387750029563904, -0.011699069291353226, -0.08968149870634079, -0.11184369772672653, 0.08392747491598129, -0.10991694033145905, -0.006877127569168806, -1.638187735215553e-32, 0.019128229469060898, -0.03603191673755646, 0.09432265907526016, 0.03979318216443062, 0.07124090939760208, 0.1232750192284584, 0.04497303068637848, 0.08010563999414444, -0.07365196198225021, -0.16179440915584564, 0.0334586463868618, -0.07689940184354782, 0.0723901316523552, 0.010278424248099327, 0.06600900739431381, -0.017988331615924835, -0.12816663086414337, 0.16413071751594543, -0.06974007934331894, 0.1711723357439041, 0.027160443365573883, 0.17439310252666473, -0.11964123696088791, 0.012487221509218216, -0.07964198291301727, -0.01841397024691105, 0.0427701361477375, 0.11170049011707306, 0.06306374818086624, -0.0572454035282135, -0.0277885552495718, 0.07214329391717911, -0.0597112737596035, 0.10869007557630539, -0.05534285679459572, -0.14576031267642975, 0.016712438315153122, -0.1221642717719078, -0.1450590044260025, 0.16820606589317322, 0.085060253739357, 0.11126568168401718, -0.2859882712364197, 0.05382050946354866, -0.08646490424871445, -0.041223395615816116, -0.021227167919278145, -0.011983019299805164, 0.025143183767795563, -0.08325983583927155, 0.09707031399011612, -0.0863991379737854, -0.12282191216945648, 0.09992440044879913, -0.09377627074718475, 0.09997818619012833, -0.08854303508996964, 0.0053939479403197765, -0.06398743391036987, 0.11879788339138031, -0.0662367194890976, 0.07664044201374054, 0.01795712299644947, -0.04397641494870186, 0.09888751804828644, 0.026194965466856956, -0.14276154339313507, 0.08535682410001755, 0.051165468990802765, 0.061404380947351456, -0.03918091207742691, -0.0071868691593408585, 0.02102813869714737, -0.04699735343456268, 0.015285482630133629, 0.06166640296578407, 0.004955599550157785, -0.002105863532051444, -0.0008690912509337068, 0.00799346249550581, -0.0991627648472786, -0.07736378163099289, 0.0447554774582386, 0.26002204418182373, 0.000625911692623049, 0.12724590301513672, 0.18051283061504364, 0.05664809048175812, 0.009975498542189598, -0.06375452876091003, 0.046357784420251846, 0.010551822371780872, 0.1173589900135994, 0.25492143630981445, -0.08938345313072205, -1.0041009090855368e-07, -0.05245792120695114, 0.07079886645078659, -0.020435042679309845, 0.06443434208631516, -0.023882854729890823, 0.10814428329467773, 0.003597525181248784, 0.01806274801492691, -0.16092979907989502, 0.009472326375544071, 0.15020349621772766, 0.0008592496742494404, -0.21153193712234497, 0.0633162260055542, -0.020579954609274864, 0.08734088391065598, 0.019018610939383507, 0.1803114265203476, -0.002250947756692767, 0.13213080167770386, 0.06121208518743515, -0.1396559476852417, 0.12006183713674545, -0.0746440589427948, -0.03790772706270218, -0.14682771265506744, 0.013908639550209045, 0.0815420001745224, 0.06887490302324295, 0.043329041451215744, -0.08060891926288605, -0.1458577811717987, -0.00802562851458788, 0.08539849519729614, 0.05029453709721565, 0.11846140772104263, -0.0035214507952332497, -0.14463448524475098, 0.061596449464559555, 0.2487742006778717, 0.026906700804829597, 0.10965238511562347, -0.2393827587366104, -0.08964502066373825, -0.05373384803533554, 0.08066636323928833, 0.0012786805164068937, 0.028077661991119385, 0.1131349578499794, -0.06031663715839386, -0.1345476508140564, -0.09062544256448746, -0.19199469685554504, -0.003696543164551258, 0.06589267402887344, 0.027000436559319496, -0.10017567873001099, 0.01725415140390396, -0.02729650028049946, 0.06794849783182144, 0.024644503369927406, -0.10472933948040009, -0.048628658056259155, -0.041680291295051575], metadata={'source': 'AAAMLP-569to.pdf', 'page': 113}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 114         lbl = preprocessing.LabelEncoder()                  # fit label encoder on all data         lbl.fit(df[col])          # transform all the data         df.loc[:, col] = lbl.transform(df[col])      # get training data using folds     df_train = df[df.kfold != fold].reset_index(drop=True)      # get validation data using folds     df_valid = df[df.kfold == fold].reset_index(drop=True)      # get training data     x_train = df_train[features].values      # get validation data     x_valid = df_valid[features].values      # initialize random forest model     model = ensemble.RandomForestClassifier(n_jobs=-1)      # fit model on training data (ohe)     model.fit(x_train, df_train.target.values)      # predict on validation data     # we need the probability values as we are calculating AUC     # we will use the probability of 1s     valid_preds = model.predict_proba(x_valid)[:, 1]      # get roc auc score     auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)      # print auc     print(f\"Fold = {fold}, AUC = {auc}\")   if __name__ == \"__main__\":     for fold_ in range(5):         run(fold_) ═════════════════════════════════════════════════════════════════════════  We use random forest from scikit-learn and have removed one-hot encoding. Instead of one-hot encoding, we use label encoding. Scores are as follows:'),\n",
       " VectorParams(vector=[-0.0334363617002964, -0.15457798540592194, -0.07940033823251724, 0.10968933999538422, 0.23211371898651123, -0.1596117466688156, -0.08130129426717758, -0.04742127284407616, -0.05502597987651825, 0.11965516954660416, -0.100140780210495, -0.07662388682365417, -0.14906184375286102, 0.048785965889692307, 0.09479183703660965, 0.07312430441379547, -0.024922704324126244, -0.005862575490027666, -0.14913636445999146, 0.10239562392234802, 0.03528646379709244, 0.04174239933490753, -0.02282664179801941, 0.04737867787480354, -0.032867759466171265, -0.13865020871162415, 0.005034177098423243, 0.047167014330625534, -0.20920917391777039, -0.006496467627584934, 0.012592128477990627, -0.030753524973988533, 0.06475403159856796, 0.005219184327870607, -0.032933421432971954, 0.03755632042884827, -0.0356721468269825, 0.037657663226127625, -0.02513611875474453, -0.005635443609207869, -0.04327167198061943, -0.006113101728260517, -0.05708255246281624, -0.006482324562966824, 0.0363377220928669, -0.04466388002038002, -0.1136813685297966, 0.002542640781030059, 0.07374338060617447, -0.007571669761091471, -0.05043893679976463, 0.007464794907718897, -0.10065559297800064, 0.0032013615127652884, -0.1483512818813324, -0.1222916767001152, -0.0539834089577198, -0.11287464201450348, 0.030100978910923004, -0.0284725371748209, -0.04234105348587036, -0.1516590714454651, -0.00837501510977745, -0.09733787178993225, 0.0016638666857033968, -0.08559595793485641, -0.03777345269918442, 0.02204504795372486, 0.06936021894216537, 0.05009404942393303, -0.03175630420446396, -0.0038244668394327164, -0.06560096144676208, 0.1058444157242775, 0.051933299750089645, 0.0019867499358952045, 0.15681281685829163, -0.019379165023565292, 0.14544232189655304, -0.01744319684803486, -0.04765276610851288, 0.06952191889286041, 0.014526285231113434, -0.007435873616486788, 0.0052652861922979355, -0.14564010500907898, 0.10315588116645813, 0.06914767622947693, -0.025562357157468796, -0.03886941075325012, 0.13368405401706696, -0.04198602959513664, 0.09663942456245422, 0.01962520182132721, 0.021264338865876198, 0.07696153968572617, 0.18156352639198303, -0.019933009520173073, -0.008309740573167801, 0.07769278436899185, -0.014144794084131718, 0.08630230277776718, 0.06580491364002228, -0.016636734828352928, 0.03654596582055092, -0.0196389053016901, 0.10448035597801208, 0.058892857283353806, 0.0256281029433012, -0.07466141134500504, 0.0483299158513546, 0.05754179134964943, -0.10979872196912766, 0.049834057688713074, 0.11488372087478638, 0.06762559711933136, 0.02238505519926548, -0.038859035819768906, -0.07741042971611023, 0.2068410962820053, -0.07406600564718246, 0.03758587688207626, 0.0033013320062309504, 0.06124577298760414, 0.13695086538791656, -0.012099443934857845, -0.025219900533556938, 1.952210324651776e-32, 0.007058017421513796, 0.15790171921253204, -0.0761040598154068, -0.128104567527771, 0.04097817838191986, -0.11961802840232849, 0.08179625868797302, 0.012357194907963276, 0.049302611500024796, 0.14991222321987152, -0.15499049425125122, 0.11025752127170563, -0.018230518326163292, -0.003085165284574032, 0.08275505900382996, -0.02356371283531189, -0.059125907719135284, 0.013840435072779655, -0.07871055603027344, -0.016309842467308044, 0.12158295512199402, 0.0042640031315386295, 0.00642992090433836, -0.016761140897870064, -0.006355235818773508, -0.013052503578364849, -0.01499955728650093, -0.0770043283700943, -0.03456609696149826, 0.0672813281416893, -0.10552352666854858, 0.005517661105841398, -0.10003539174795151, 0.00131877395324409, 0.033031001687049866, -0.10264980792999268, 0.024802524596452713, 0.009919878095388412, -0.03377685695886612, -0.04447811841964722, -0.09251820296049118, 0.07737897336483002, 0.055620063096284866, -0.14396286010742188, -0.04117918759584427, 0.02496618777513504, 0.07314593344926834, 0.15410643815994263, -0.09695571660995483, 0.13043488562107086, 0.04800788685679436, -0.0798681303858757, -0.04528530687093735, 0.10362274944782257, -0.07404523342847824, 0.10750193148851395, 0.1890534609556198, -0.10549910366535187, 0.07241329550743103, 0.07021044939756393, 0.029372243210673332, -0.10233175754547119, 0.022373169660568237, -0.005104480776935816, 0.04792686551809311, -0.08420325070619583, 0.1525770127773285, -0.00871652364730835, -0.02670329622924328, -0.06055813282728195, -0.0765368863940239, 0.05239718779921532, 0.027022793889045715, -0.16991111636161804, 0.07039900869131088, 0.018343020230531693, 0.2510277032852173, -0.048590004444122314, -0.06263596564531326, 0.08129837363958359, 0.001897837151773274, 0.16691288352012634, 0.019010527059435844, -0.24284358322620392, 0.011616231873631477, -0.0010225287405773997, -0.003997177351266146, -0.1415896862745285, -0.2350161224603653, -0.09852082282304764, -0.10410043597221375, 0.05347472056746483, 0.043285004794597626, -0.12889599800109863, 0.04323938488960266, -1.5000387901927207e-32, 0.03430844843387604, -0.19064928591251373, 0.06792215257883072, 0.09685411304235458, 0.02821245789527893, 0.044373396784067154, -0.0343661792576313, 0.005499397870153189, -0.11752897500991821, -0.24939435720443726, 0.010176209732890129, -0.08365042507648468, 0.10316018015146255, 0.06568837910890579, 0.1425144374370575, 0.012273021042346954, 0.0005602791206911206, 0.19168323278427124, -0.020894747227430344, 0.21247266232967377, -0.0021300730295479298, 0.1855359524488449, -0.10440868139266968, -0.07122555375099182, -0.13648545742034912, -0.06232086196541786, 0.003915922250598669, 0.07287365198135376, 0.04647882282733917, -0.03164898231625557, -0.0671619176864624, 0.14072667062282562, -0.0842265859246254, -0.0502401702105999, -0.04995964094996452, 0.0033735663164407015, 0.026339216157794, -0.07634225487709045, -0.03002610057592392, 0.05532379448413849, 0.15851236879825592, 0.08970653265714645, -0.1925903707742691, -0.03452947735786438, -0.07639306038618088, -0.04606813192367554, -0.13555297255516052, 0.06172583997249603, -0.0012645943788811564, 0.09379424154758453, 0.10804693400859833, -0.07140997052192688, -0.06807612627744675, 0.06404544413089752, -0.014714262448251247, 0.022535977885127068, -0.05950328707695007, -0.06586086750030518, -0.07152663916349411, 0.04414302855730057, -0.13658998906612396, 0.15770132839679718, -0.03457842022180557, -0.0515894778072834, 0.11431245505809784, -0.03373485431075096, -0.09365030378103256, 0.07676850259304047, -0.060666803270578384, 0.009848580695688725, -0.08230463415384293, -0.043672408908605576, 0.009954793378710747, 0.0007310893852263689, -0.033571284264326096, 0.0862579345703125, 1.2697810234385543e-05, -0.006685754284262657, -0.017075469717383385, 0.05149568244814873, 0.04814816638827324, 0.03320671617984772, 0.025818541646003723, 0.08126585930585861, -0.016965476796030998, 0.19870591163635254, 0.10151826590299606, 0.01682867296040058, 0.06092717871069908, -0.06049440801143646, 0.0032020544167608023, 0.0016705464804545045, 0.21609416604042053, 0.2084563672542572, -0.02220873162150383, -9.912650256183042e-08, -0.02218489535152912, 0.14386914670467377, 0.034764211624860764, -0.03088574856519699, 0.07746239006519318, 0.05745358020067215, -0.03898432478308678, 0.14547289907932281, -0.13207992911338806, 0.07001947611570358, 0.13354235887527466, 0.051046039909124374, -0.13116879761219025, 0.09299402683973312, -0.03609252721071243, 0.14835156500339508, 0.01833655871450901, 0.025870641693472862, -0.06234924495220184, 0.07619520276784897, 0.07078450173139572, 0.006307333242148161, 0.06072581186890602, -0.02359471656382084, 0.050019942224025726, -0.10739698261022568, 0.00716668926179409, 0.061763253062963486, 0.10462342947721481, -0.05907939001917839, -0.1035560667514801, -0.013466855511069298, -0.0797257125377655, 0.018764782696962357, 0.08392438292503357, 0.08096528798341751, 0.0836489275097847, -0.11342734843492508, -0.11938377469778061, 0.08221066743135452, 0.034600548446178436, 0.044666845351457596, -0.10547564923763275, -0.09349434822797775, -0.06083843484520912, 0.012002630159258842, -0.07560275495052338, -0.007744510192424059, 0.11142133921384811, -0.029259072616696358, -0.06936682015657425, -0.059178490191698074, -0.1360870897769928, -0.01625104807317257, 0.11061932146549225, 0.05514691770076752, -0.02825656533241272, -0.046744454652071, 0.01634380780160427, 0.08502749353647232, 0.03701266646385193, -0.08447464555501938, -0.07822287082672119, 0.030019018799066544], metadata={'source': 'AAAMLP-569to.pdf', 'page': 114}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 115 ═════════════════════════════════════════════════════════════════════════ ❯ python lbl_rf.py Fold = 0, AUC = 0.7167390828113697 Fold = 1, AUC = 0.7165459672958506 Fold = 2, AUC = 0.7159709909587376 Fold = 3, AUC = 0.7161589664189556 Fold = 4, AUC = 0.7156020216155978 ═════════════════════════════════════════════════════════════════════════  Wow! Huge difference! The random forest model, without any tuning of hyperparameters, performs a lot worse than simple logistic regression.   And this is a reason why we should always start with simple models first. A fan of random forest would begin with it here and will ignore logistic regression model thinking it’s a very simple model that cannot bring any value better than random forest. That kind of person will make a huge mistake. In our implementation of random forest, the folds take a much longer time to complete compared to logistic regression. So, we are not only losing on AUC but also taking much longer to complete the training. Please note that inference is also time-consuming with random forest and it also takes much larger space.  If we want, we can also try to run random forest on sparse one-hot encoded data, but that is going to take a lot of time. We can also try reducing the sparse one-hot encoded matrices using singular value decomposition. This is a very common method of extracting topics in natural language processing.   ═════════════════════════════════════════════════════════════════════════ # ohe_svd_rf.py import pandas as pd  from scipy import sparse from sklearn import decomposition from sklearn import ensemble from sklearn import metrics from sklearn import preprocessing   def run(fold):     # load the full training data with folds     df = pd.read_csv(\"../input/cat_train_folds.csv\")      # all columns are features except id, target and kfold columns     features = [         f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")'),\n",
       " VectorParams(vector=[-0.03535386919975281, -0.07427176088094711, -0.011112497188150883, 0.028949959203600883, 0.21836644411087036, -0.15789861977100372, -0.04976450279355049, 0.005533394869416952, -0.12445466965436935, -0.04949228838086128, 0.03396490588784218, -0.09766574203968048, -0.15308621525764465, -0.1624726802110672, -0.07699394226074219, 0.08288823068141937, -0.1098325103521347, 0.014347860589623451, -0.11177144199609756, -0.031602270901203156, -0.04806980490684509, 0.09239929169416428, -0.008292998187243938, 0.09620485454797745, -0.019137421622872353, 0.048552364110946655, 0.04771707206964493, 0.06144484132528305, -0.038045503199100494, -0.04812950640916824, 0.04924086481332779, 0.0712246522307396, -0.04214397445321083, -0.0038470090366899967, 0.06273823231458664, 0.09457779675722122, -0.05672461539506912, 0.0729958638548851, -0.0890769213438034, 0.12367700040340424, -0.03627024218440056, -0.027548035606741905, 0.0614655576646328, 0.04983069747686386, 0.054155465215444565, 0.04246252402663231, -0.11583451181650162, -0.13200870156288147, 0.13320142030715942, -0.10478808730840683, -0.005577723030000925, 0.06230049952864647, -0.10701274871826172, 0.00795773509889841, -0.09253175556659698, -0.11932076513767242, -0.04116203635931015, -0.06469208002090454, 0.050996582955121994, 0.04978983476758003, -0.02506377547979355, -0.08599235117435455, 0.04035741090774536, -0.05593974143266678, 0.05053962767124176, -0.04656732454895973, -0.051093775779008865, -0.04912562668323517, -0.16143208742141724, 0.07176641374826431, -0.00871296040713787, 0.10916769504547119, -0.10807526856660843, 0.16472265124320984, -0.08235301077365875, -0.007339805830270052, 0.20720884203910828, -0.01691209338605404, 0.2279246598482132, 0.0624883696436882, -0.17187179625034332, 0.05281968414783478, 0.03716074302792549, -0.06358955055475235, -0.015607228502631187, -0.06972238421440125, -0.006986126769334078, -0.016036953777074814, -0.04164695739746094, 0.00865327287465334, 0.14005456864833832, -0.021550944074988365, 0.008911147713661194, 0.046488191932439804, -0.026788368821144104, 0.05274175480008125, 0.11521369963884354, 0.06296899914741516, -0.02499580569565296, 0.1469111442565918, -0.1142188161611557, -0.009475680068135262, 0.010515062138438225, 0.014704371802508831, -0.08282410353422165, -0.0044747148640453815, 0.1870741844177246, 0.08493132889270782, 0.1133456602692604, -0.024989012628793716, 0.07884440571069717, -0.04791240394115448, -0.06251738965511322, 0.01709326170384884, 0.03908896446228027, 0.023711295798420906, -0.051208361983299255, 0.02819463051855564, -0.10009386390447617, 0.15912221372127533, -0.16654539108276367, 0.05701219290494919, -0.026414230465888977, 0.08211401104927063, -0.05906270816922188, -0.050403788685798645, -0.018787965178489685, 2.0482007525295423e-32, -0.0650404840707779, 0.0542936772108078, -0.029370423406362534, -0.10441776365041733, -0.07413024455308914, -0.0660075917840004, -0.004822603426873684, 0.017314404249191284, 0.017862727865576744, 0.10216192156076431, -0.18590182065963745, 0.02077496610581875, -0.0832274779677391, -0.01777585595846176, -0.03308539092540741, -0.0817236453294754, 0.05559701472520828, -0.0010181948309764266, -0.08749718964099884, 0.0004906400572508574, 0.2595173120498657, -0.028234858065843582, -0.03678973391652107, -0.09423597902059555, -0.11307600885629654, -0.055999208241701126, -0.12600256502628326, -0.03669073060154915, -0.09813697636127472, 0.0426538921892643, -0.27157407999038696, -0.010408318601548672, 0.024609006941318512, 0.02160651981830597, 0.012638366781175137, -0.10756361484527588, 0.14167021214962006, 0.1108885407447815, -0.047842174768447876, -0.08477198332548141, -0.021186431869864464, 0.04969916120171547, 0.025908512994647026, -0.11488673835992813, 0.06942391395568848, -0.001713549834676087, 0.12240668386220932, 0.08378799259662628, -0.050438832491636276, 0.13032028079032898, -0.03529307618737221, -0.0764559730887413, 0.008840847760438919, 0.026789039373397827, -0.1304856389760971, 0.12452618777751923, 0.12394250184297562, -0.0745658278465271, 0.06963393837213516, 0.10787539929151535, -0.027710603550076485, 0.01795297861099243, 0.005995950195938349, 0.02660392038524151, 0.007365355733782053, -0.04287876561284065, 0.11626638472080231, -0.0526055283844471, 0.07678157836198807, -0.05006029084324837, -0.10418787598609924, -0.005460425280034542, -0.024503376334905624, -0.13135987520217896, 0.09227700531482697, -0.17661231756210327, 0.09540586918592453, 0.03563467040657997, -0.08413857966661453, -0.04637075588107109, 0.010460034012794495, 0.16046801209449768, -0.0407291054725647, -0.20872655510902405, 0.05345684289932251, 0.009728819131851196, 0.012854439206421375, -0.09293307363986969, -0.16444528102874756, -0.0571264773607254, -0.13439494371414185, -0.10750409215688705, 0.04084223136305809, -0.21364088356494904, 0.024118363857269287, -1.988460807189609e-32, 0.04077032953500748, 0.029241465032100677, -0.010365399532020092, 0.03420524299144745, 0.0851028710603714, 0.13968750834465027, 0.04268776252865791, 0.09183771908283234, -0.08646020293235779, -0.19816149771213531, 0.02677818201482296, -0.09252367168664932, -0.06368253380060196, -0.035057030618190765, 0.012612415477633476, 0.022175559774041176, -0.09181594848632812, 0.14979426562786102, -0.08282775431871414, 0.11559473723173141, -0.05587939918041229, 0.1883799433708191, -0.07141101360321045, 0.059920839965343475, -0.13002842664718628, -0.0025030989199876785, 0.0584896057844162, 0.12289077788591385, 0.1074625626206398, -0.009108038619160652, -0.07438918948173523, 0.005136158782988787, -0.11078009754419327, 0.07006910443305969, -0.0024795401841402054, -0.07948547601699829, 0.04277869313955307, -0.11268056184053421, -0.07311858981847763, 0.03506291285157204, 0.12544088065624237, 0.10012044757604599, -0.24307680130004883, 0.11880835145711899, -0.07932969182729721, -0.00011197123967576772, -0.051387425512075424, -0.008263003081083298, 0.02566223032772541, 0.0005446624127216637, 0.06255630403757095, -0.037361498922109604, -0.012783724814653397, 0.0815134346485138, -0.013091765344142914, 0.024603186175227165, -0.00931587815284729, -0.014060035347938538, -0.11645685881376266, 0.004840102978050709, -0.10505077242851257, 0.03827967122197151, -0.0569259412586689, -0.0844387635588646, 0.21386569738388062, -0.03397466614842415, -0.06275276094675064, 0.07073415070772171, 0.05509579926729202, -0.01737802103161812, -0.13182178139686584, 0.01708851382136345, -0.014573048800230026, -0.09987762570381165, -0.007624558638781309, 0.06440724432468414, 0.026463299989700317, -0.06088187173008919, 0.08714509010314941, 0.0638100877404213, -0.047286197543144226, 0.006725617218762636, 0.08352135121822357, 0.17587122321128845, 0.05699729919433594, 0.1685098558664322, 0.11034668982028961, 0.04749850183725357, -0.053925689309835434, -0.011585823260247707, 0.1070796474814415, -0.031602565199136734, 0.173253133893013, 0.20509088039398193, -0.012479045428335667, -1.0071086364860093e-07, -0.04328106343746185, 0.06635362654924393, -0.02562457136809826, 0.01791890524327755, 0.08681491762399673, -0.036341436207294464, -0.006030918564647436, 0.03015989065170288, -0.08473493903875351, 0.019196536391973495, 0.09337883442640305, 0.045874979346990585, -0.15212640166282654, 0.046893563121557236, 0.07599765062332153, 0.07861089706420898, -0.06228122487664223, 0.04473942518234253, -0.036870039999485016, 0.09778635203838348, 0.031612150371074677, -0.08053901791572571, -0.057103630155324936, -0.10954823344945908, 0.043238312005996704, -0.16003315150737762, -0.023278674110770226, 0.12756800651550293, 0.16610637307167053, 0.020541200414299965, -0.0964205265045166, -0.1434040516614914, 0.020712383091449738, 0.027751609683036804, 0.09046022593975067, 0.06889622658491135, 0.13181346654891968, -0.11602388322353363, -0.008120381273329258, 0.08439044654369354, -0.07079215347766876, 0.1566181778907776, -0.07363615185022354, -0.07787494361400604, -0.08877649903297424, 0.05955412983894348, 0.019391344860196114, -0.03187398612499237, 0.11638245731592178, -0.025526465848088264, -0.08553177118301392, -0.010929443873465061, -0.10017792135477066, 0.0578005351126194, 0.10545476526021957, -0.024206852540373802, -0.09415800869464874, 0.06888842582702637, -0.007532529067248106, 0.051193155348300934, 0.09588620811700821, -0.03414301201701164, -0.06554093211889267, -0.027569811791181564], metadata={'source': 'AAAMLP-569to.pdf', 'page': 115}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 116     ]      # fill all NaN values with NONE     # note that I am converting all columns to \"strings\"     # it doesnt matter because all are categories     for col in features:         df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")      # get training data using folds     df_train = df[df.kfold != fold].reset_index(drop=True)      # get validation data using folds     df_valid = df[df.kfold == fold].reset_index(drop=True)      # initialize OneHotEncoder from scikit-learn     ohe = preprocessing.OneHotEncoder()      # fit ohe on training + validation features     full_data = pd.concat(         [df_train[features], df_valid[features]],         axis=0     )     ohe.fit(full_data[features])      # transform training data     x_train = ohe.transform(df_train[features])      # transform validation data     x_valid = ohe.transform(df_valid[features])      # initialize Truncated SVD     # we are reducing the data to 120 components     svd = decomposition.TruncatedSVD(n_components=120)      # fit svd on full sparse training data     full_sparse = sparse.vstack((x_train, x_valid))     svd.fit(full_sparse)      # transform sparse training data     x_train = svd.transform(x_train)      # transform sparse validation data     x_valid = svd.transform(x_valid)      # initialize random forest model     model = ensemble.RandomForestClassifier(n_jobs=-1)'),\n",
       " VectorParams(vector=[-0.10016030073165894, -0.08114857971668243, -0.16046780347824097, 0.052508700639009476, 0.22504045069217682, -0.13183657824993134, 0.030527835711836815, 0.0469164177775383, -0.12676723301410675, 0.0514318086206913, 0.01068516168743372, -0.15178139507770538, -0.05936647951602936, -0.07731343060731888, 0.025430191308259964, 0.10079160332679749, -0.025721143931150436, 0.01494758203625679, -0.10284659266471863, 0.019546322524547577, 0.06976477056741714, 0.07931967824697495, -0.0880279541015625, 0.12219757586717606, -0.05513982102274895, -0.07774998247623444, 0.0868772566318512, 0.07597408443689346, -0.1839597374200821, -0.0383673831820488, 0.03645215183496475, -0.07700899988412857, 0.1064760833978653, -0.03835635259747505, -0.03335081785917282, 0.0497821606695652, -0.1354975551366806, 0.004164402838796377, -0.0585075244307518, -0.011306035332381725, 0.04995123669505119, 0.002177273854613304, -0.0009395562228746712, 0.026648813858628273, 0.03287717327475548, 0.020323580130934715, -0.09933912754058838, -0.01599050685763359, 0.03161053732037544, -0.06950230151414871, 0.04966156929731369, -0.0008141221478581429, -0.12030375003814697, 0.0234077051281929, -0.1149609312415123, -0.11377593874931335, 0.002876162063330412, -0.14352555572986603, 0.08059854060411453, -0.023182297125458717, 0.025721533223986626, -0.05187760666012764, 0.0019098144257441163, -0.0439286008477211, 0.09339570999145508, -0.0371386744081974, -0.11596929281949997, -0.02984841912984848, 0.00945808831602335, 0.0006424050661735237, -0.03621240705251694, 0.024805936962366104, -0.021294904872775078, 0.1461659073829651, 0.006166623439639807, -0.0029282914474606514, 0.16579407453536987, -0.01790902391076088, 0.07098498940467834, 0.02416614443063736, -0.14992494881153107, 0.06791387498378754, 0.06328366696834564, -0.003961936105042696, 0.07378746569156647, -0.06361326575279236, 0.07361763715744019, 0.08861755579710007, -0.04001866653561592, -0.05424567684531212, 0.0924667939543724, -0.009314199909567833, -0.0084007503464818, 0.06337457150220871, -0.0424896702170372, 0.08884716778993607, 0.19130012392997742, -0.058737508952617645, -0.030885538086295128, 0.0609709732234478, -0.10574435442686081, 0.023329967632889748, 0.019017904996871948, 0.029052501544356346, 0.024474870413541794, -0.03394867852330208, 0.04577089101076126, 0.08015206456184387, 0.11931070685386658, -0.03196598216891289, 0.019403427839279175, -0.004083751235157251, -0.07302746176719666, 0.04268326237797737, 0.10765295475721359, 0.08761213719844818, -0.05960483103990555, 0.02357550337910652, -0.14358970522880554, 0.1581030637025833, -0.15568895637989044, 0.025409376248717308, 0.055689483880996704, 0.06174209713935852, 0.03155004605650902, -0.06816550344228745, -0.042034175246953964, 1.0469236276435428e-32, -0.08118889480829239, 0.07643746584653854, -0.07690644264221191, -0.1740346997976303, 0.10282860696315765, -0.05654297396540642, 0.0019651108887046576, 0.05107918754220009, 0.06959422677755356, 0.16636963188648224, -0.19200080633163452, 0.03270930051803589, -0.046202611178159714, 0.030850576236844063, -0.022275660187005997, -0.008699082769453526, -0.03930675610899925, 0.023175053298473358, -0.14899736642837524, 0.04010896757245064, 0.11185435205698013, 0.019091779366135597, 0.02439885400235653, -0.0909867212176323, -0.015704095363616943, -0.004564350936561823, 0.002229197882115841, 0.026969388127326965, -0.040893469005823135, 0.056247737258672714, -0.14046280086040497, -0.05636085569858551, -0.023275677114725113, -0.06472586840391159, -0.04141776263713837, -0.14707687497138977, 0.06646604090929031, 0.02028038538992405, -0.07256437838077545, -0.07566296309232712, 0.038523100316524506, 0.01791027933359146, 0.08503679186105728, -0.08422094583511353, -0.0013319869758561254, 0.021285992115736008, 0.022730302065610886, 0.1386142522096634, -0.07624202966690063, 0.1402824968099594, 0.0364493653178215, -0.15750810503959656, -0.028820782899856567, 0.03607543557882309, -0.19069033861160278, 0.07124090939760208, 0.09456568956375122, 0.0322662815451622, 0.12175262719392776, 0.12143570184707642, 0.045665208250284195, -0.10035098344087601, 0.032530542463064194, -0.01809355989098549, 0.053141411393880844, -0.03529961779713631, 0.17980115115642548, -0.09203701466321945, -0.005913897417485714, -0.012472684495151043, -0.07915285229682922, 0.048774607479572296, 0.08783043175935745, -0.08692614734172821, 0.015121493488550186, -0.05369718745350838, 0.16675372421741486, 0.07858013361692429, -0.05789316073060036, 0.0017608493799343705, -0.011679750867187977, 0.20379537343978882, 0.02343945950269699, -0.21608655154705048, 0.006496242247521877, -0.015107343904674053, -0.0464109368622303, -0.08804770559072495, -0.2761745750904083, -0.02463400922715664, -0.13607142865657806, -0.024404369294643402, 0.04703570902347565, -0.044385191053152084, -0.022700920701026917, -8.204324617997754e-33, 0.049918755888938904, -0.06523016095161438, 0.0935392901301384, 0.04455982521176338, 0.08900217711925507, 0.07578787952661514, -0.051536448299884796, 0.09205678105354309, -0.1283641755580902, -0.15682236850261688, 0.12602581083774567, -0.06189373508095741, 0.060960736125707626, -0.03164204582571983, 0.09866663068532944, 0.055549800395965576, -0.050864703953266144, 0.12667222321033478, -0.031332772225141525, 0.11697159707546234, 0.04410308972001076, 0.11583923548460007, -0.159340038895607, -0.04775248467922211, -0.09089802950620651, -0.010070772841572762, 0.1112341657280922, 0.09380114078521729, 0.02481842413544655, 0.018811147660017014, -0.10314959287643433, 0.13645674288272858, -0.1608249396085739, 0.05076390504837036, -0.10772533714771271, -0.05562692508101463, -0.02471124194562435, -0.042258087545633316, -0.0479729138314724, 0.08338944613933563, 0.06398971378803253, 0.13934442400932312, -0.3094467222690582, -0.04485759139060974, -0.07087866961956024, 0.029153017327189445, -0.039373572915792465, 0.04681450128555298, 0.15352843701839447, 0.06850170344114304, 0.10707872360944748, -0.09790163487195969, -0.055455323308706284, 0.20081374049186707, -0.11093945801258087, 0.11327239125967026, -0.12121983617544174, 0.027059637010097504, -0.0533423088490963, 0.01267202664166689, -0.13070136308670044, 0.04032432287931442, 0.04907684400677681, -0.04647668078541756, 0.032189179211854935, 0.009144975803792477, -0.04183883219957352, 0.07263190299272537, 0.001528457854874432, 0.03994748368859291, 0.033556051552295685, -0.0035249688662588596, 0.01356833428144455, -0.025049284100532532, -0.05083572864532471, 0.06350459903478622, 0.07083321362733841, -0.059504326432943344, 0.03245307132601738, 0.00017445669800508767, -0.07355715334415436, 0.01756691187620163, 0.038389433175325394, 0.20514465868473053, -0.001779991784133017, 0.16587483882904053, 0.06521042436361313, 0.07893344759941101, 0.08760125935077667, -0.04178975522518158, 0.021249467507004738, 0.13037298619747162, 0.2204412817955017, 0.14294929802417755, -0.07375727593898773, -9.910484521924445e-08, -0.07372024655342102, 0.040321022272109985, 0.022911425679922104, 0.013711592182517052, 0.08174078166484833, 0.08346113562583923, -0.06885839253664017, 0.08416406065225601, -0.05185457691550255, -0.0011819977080449462, 0.14609524607658386, -0.029018308967351913, -0.1978887915611267, 0.05570482462644577, -0.04471711814403534, 0.054742202162742615, 0.0068427338264882565, 0.13191646337509155, -0.018068300560116768, 0.09440838545560837, 0.04143881797790527, -0.034527409821748734, 0.09781395643949509, -0.054923851042985916, 0.013626836240291595, -0.1485036015510559, 0.013530757278203964, 0.09067361056804657, 0.03555469959974289, 0.02074860967695713, -0.14960543811321259, -0.09082112461328506, -0.006971227470785379, 0.03999660536646843, 0.07872819900512695, 0.16339349746704102, 0.017449676990509033, -0.10373534262180328, -0.07846695929765701, 0.13668334484100342, 0.06753885746002197, -0.014642213471233845, -0.0492006354033947, -0.09910719096660614, 0.021382220089435577, 0.045047059655189514, 0.02233317121863365, -0.019223447889089584, 0.10275322943925858, 0.005301852710545063, -0.02539149299263954, -0.07656975090503693, -0.09981925040483475, -0.07221850752830505, 0.018538277596235275, 0.013249353505671024, -0.13541105389595032, -0.02213134430348873, -0.03505159541964531, 0.06189001351594925, 0.09317976236343384, -0.14582373201847076, 0.022908950224518776, 0.06841111928224564], metadata={'source': 'AAAMLP-569to.pdf', 'page': 116}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 117     # fit model on training data (ohe)     model.fit(x_train, df_train.target.values)      # predict on validation data     # we need the probability values as we are calculating AUC     # we will use the probability of 1s     valid_preds = model.predict_proba(x_valid)[:, 1]      # get roc auc score     auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)      # print auc     print(f\"Fold = {fold}, AUC = {auc}\")   if __name__ == \"__main__\":     for fold_ in range(5):         run(fold_) ═════════════════════════════════════════════════════════════════════════  We one-hot encode the full data and then fit TruncatedSVD from scikit-learn on sparse matrix with training + validation data. In this way, we reduce the high dimensional sparse matrix to 120 features and then fit random forest classifier.   Below is the output of this model:  ═════════════════════════════════════════════════════════════════════════ ❯ python ohe_svd_rf.py Fold = 0, AUC = 0.7064863038754249 Fold = 1, AUC = 0.706050102937374 Fold = 2, AUC = 0.7086069243167242 Fold = 3, AUC = 0.7066819080085971 Fold = 4, AUC = 0.7058154015055585 ═════════════════════════════════════════════════════════════════════════  We see that it is even worse. It seems like the best method for this problem is one-hot encoding with logistic regression. Random forest appears to be taking way too much time. Maybe we can give XGBoost a try. In case you don’t know about XGBoost, it is one of the most popular gradient boosting algorithms. Since it’s a tree-based algorithm, we will use label encoded data.  ═════════════════════════════════════════════════════════════════════════ # lbl_xgb.py import pandas as pd'),\n",
       " VectorParams(vector=[0.021950945258140564, -0.05965113267302513, -0.12580256164073944, -0.022243373095989227, 0.12246562540531158, 0.022591140121221542, 0.03502964973449707, -0.02695387601852417, -0.13691753149032593, -0.11775313317775726, 0.09890811145305634, -0.12680450081825256, -0.04401678591966629, -0.13685649633407593, -0.01438860036432743, 0.14853650331497192, -0.08662980049848557, 0.10210039466619492, -0.15643200278282166, -0.057973090559244156, -0.048884712159633636, 0.06949220597743988, 0.0636928528547287, 0.11017132550477982, -0.11764731258153915, 0.10229581594467163, 0.055524181574583054, 0.05533478036522865, -0.09460733830928802, -0.018246494233608246, 0.00436196755617857, 0.10963848233222961, -0.030941160395741463, 0.006684109568595886, 0.14840929210186005, 0.07725141942501068, -0.11776860058307648, 0.10118044912815094, -0.01931110769510269, 0.05962017923593521, 0.0033577741123735905, -0.1399792730808258, 0.11951714009046555, 0.013671470806002617, 0.07145651429891586, 0.07005642354488373, -0.06269887089729309, -0.09716221690177917, 0.01929558627307415, -0.09840890765190125, 0.020787132903933525, 0.1073400005698204, -0.1643991619348526, 0.028182480484247208, -0.0325385145843029, -0.1407989114522934, 0.008726599626243114, -0.08153168112039566, 0.09639370441436768, 0.0732857957482338, -0.05939200893044472, -0.08729362487792969, 0.06128337234258652, -0.00792341586202383, 0.024066902697086334, -0.06679002195596695, -0.08279329538345337, -0.0237747710198164, -0.10071344673633575, 0.08488238602876663, -0.09331338107585907, 0.12657946348190308, -0.0923648327589035, 0.126645028591156, -0.09803324937820435, 0.044380251318216324, 0.1984425038099289, -0.025763601064682007, 0.2046155333518982, 0.0441841222345829, -0.17517438530921936, 0.03799489140510559, 0.1010955199599266, 0.03010442666709423, 0.02440900355577469, -0.12748196721076965, -0.008055613376200199, 0.031094659119844437, -0.11201996356248856, 0.01201156061142683, 0.06888018548488617, -0.07531818747520447, 0.07221387326717377, 0.03398000821471214, -0.0706847682595253, 0.0748075619339943, 0.031362585723400116, -0.003639005357399583, 0.021161720156669617, 0.10663232952356339, -0.13648562133312225, 0.012075692415237427, 0.028777388855814934, -0.07901015132665634, -0.10889091342687607, -0.04610539600253105, 0.1847177892923355, 0.08884261548519135, 0.13214103877544403, -0.07267031818628311, 0.05595053359866142, -0.11011596024036407, -0.05766524747014046, 0.013700886629521847, -0.015992775559425354, 0.014866468496620655, -0.036837805062532425, 0.04684538394212723, -0.07718532532453537, 0.10996463894844055, -0.1209840402007103, 0.013239031657576561, -0.0006116186850704253, 0.058532021939754486, -0.13786442577838898, -0.06009388342499733, -0.03316941112279892, 1.7180784455276636e-32, -0.09912850707769394, 0.03710364177823067, 0.02837887965142727, -0.13370558619499207, -0.07103604823350906, -0.06605047732591629, -0.04268820956349373, 0.04951869696378708, 0.08941391855478287, 0.1504538506269455, -0.12601327896118164, 0.062442436814308167, -0.12704621255397797, -0.029965395107865334, -0.05344289541244507, -0.032885514199733734, -0.015858976170420647, 0.0025409904774278402, -0.07940803468227386, -0.02841675467789173, 0.23001505434513092, 0.005115183535963297, 0.0229828879237175, -0.1202554926276207, -0.07156366854906082, -0.13829800486564636, -0.10750085860490799, -0.054187528789043427, -0.01940401829779148, -0.015053894370794296, -0.21441681683063507, -0.10218191146850586, 0.058753203600645065, 0.00896383449435234, -0.06794337183237076, -0.11123480647802353, 0.11201781779527664, 0.06997258961200714, -0.03250357508659363, 0.06585276871919632, -0.03797852247953415, 0.02143974043428898, 0.0614636093378067, -0.03948323428630829, 0.016636746004223824, 0.08230073750019073, 0.0928206592798233, -0.01006393600255251, -0.06775106489658356, 0.011291910894215107, -0.005461971275508404, -0.11346488445997238, 0.02704392559826374, 0.04239042103290558, -0.10110874474048615, 0.10628765821456909, 0.06564491987228394, -0.04177030548453331, -0.0006174998707138002, 0.04334162175655365, -0.04135262966156006, 0.03623148798942566, -0.010341279208660126, 0.055175840854644775, 0.0026278223376721144, -0.03470683842897415, 0.2075011134147644, 0.011001606471836567, 0.027389362454414368, -0.08005475997924805, -0.09132987260818481, -0.05499991402029991, -0.09166809171438217, -0.14321574568748474, 0.08279735594987869, -0.12178533524274826, 0.016002263873815536, -0.06627907603979111, -0.09996624290943146, -0.008151508867740631, 0.07146552205085754, 0.1566261649131775, -0.05959414318203926, -0.08116193115711212, 0.025290442630648613, 0.02939927577972412, 0.027544697746634483, -0.1526155173778534, -0.0990193784236908, -0.06497418135404587, -0.17570623755455017, -0.09040660411119461, -0.06183076649904251, -0.18194814026355743, 0.05557645112276077, -1.8831002199678504e-32, 0.06458152085542679, 0.01995937153697014, 0.07762088626623154, 0.03632688894867897, 0.14050447940826416, 0.07275377959012985, 0.07101273536682129, 0.038968995213508606, -0.01354825310409069, -0.1484597772359848, -0.012790222652256489, -0.09046413004398346, 0.007405422627925873, -0.05112408846616745, 0.0012280147057026625, 0.0600510835647583, -0.184969961643219, 0.21917198598384857, -0.1006527990102768, 0.07496477663516998, -0.06886591762304306, 0.2333671897649765, -0.08303675055503845, 0.07620909065008163, -0.11485122889280319, 0.011249193921685219, 0.09178032726049423, 0.04815320298075676, 0.1126258373260498, 0.016952037811279297, -0.09990653395652771, -0.004886803682893515, -0.08605577796697617, 0.14406776428222656, -0.09827087819576263, -0.06641330569982529, 0.08953777700662613, -0.06498067826032639, -0.1158786416053772, 0.11680525541305542, 0.10133898258209229, 0.1565253585577011, -0.2570924162864685, 0.14233963191509247, -0.012031941674649715, 0.037681251764297485, -0.03459331393241882, 0.003902168944478035, -0.02246559038758278, 0.038566842675209045, 0.005776656325906515, 0.0028819201979786158, -0.0914190337061882, -0.02287338487803936, -0.006366420071572065, 0.04939030483365059, -0.08343011885881424, -0.0904449000954628, -0.1291547417640686, 0.020173797383904457, -0.14997157454490662, 0.03065609373152256, 0.05114605277776718, -0.06869026273488998, 0.1751946359872818, -0.037642702460289, -0.04823419451713562, 0.06377004832029343, 0.010402597486972809, -0.03247403725981712, -0.0833156406879425, -0.08194947242736816, -0.09347251802682877, -0.05233819782733917, -0.011839562095701694, 0.0824144259095192, -0.04086219146847725, -0.07239338755607605, 0.007618344854563475, 0.0571180060505867, 0.018598541617393494, 0.0116206593811512, 0.13456541299819946, 0.24129550158977509, -0.0010935866739600897, 0.1015540286898613, 0.15615221858024597, 0.04694243520498276, 0.032160624861717224, -0.009869265370070934, 0.09158432483673096, -0.036722227931022644, 0.16309627890586853, 0.2652897238731384, -0.1040351614356041, -1.0089099333754348e-07, -0.03995026648044586, 0.0642414316534996, -0.06340642273426056, -0.012310332618653774, 0.001223716652020812, 0.040604133158922195, -0.07090479135513306, 0.00026287478976882994, -0.006627298425883055, 0.07759237289428711, 0.09693505614995956, 0.01205360796302557, -0.16321749985218048, 0.05113263428211212, -0.024913473054766655, 0.09870642423629761, 0.015131987631320953, 0.047088634222745895, 0.0002661719627212733, 0.1519966870546341, 0.09896828979253769, -0.04161813482642174, -0.04375697299838066, -0.05015147104859352, 0.048855263739824295, -0.21633003652095795, -0.12489506602287292, 0.08379380404949188, 0.13814252614974976, 0.040712326765060425, -0.03189850598573685, -0.13764318823814392, 0.017712421715259552, 0.04067865386605263, 0.1029345914721489, 0.018825538456439972, 0.05556931346654892, -0.1804579198360443, 0.0769665390253067, 0.09509898722171783, -0.06141367182135582, 0.07821392267942429, -0.1399705559015274, -0.03423348069190979, -0.08536650240421295, -0.026821812614798546, 0.01104363426566124, 0.06069185584783554, 0.09971020370721817, 0.04476651921868324, -0.1530047357082367, -0.05240171030163765, -0.0766773447394371, -0.014665867201983929, 0.15422196686267853, 0.01256687380373478, -0.05119917169213295, 0.1120375245809555, 0.020539840683341026, 0.022185195237398148, 0.01135953702032566, 0.02530994452536106, 0.060858339071273804, -0.10547585040330887], metadata={'source': 'AAAMLP-569to.pdf', 'page': 117}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 118 import xgboost as xgb  from sklearn import metrics from sklearn import preprocessing   def run(fold):     # load the full training data with folds     df = pd.read_csv(\"../input/cat_train_folds.csv\")      # all columns are features except id, target and kfold columns     features = [         f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")     ]      # fill all NaN values with NONE     # note that I am converting all columns to \"strings\"     # it doesnt matter because all are categories     for col in features:         df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")          # now it’s time to label encode the features     for col in features:                  # initialize LabelEncoder for each feature column         lbl = preprocessing.LabelEncoder()                  # fit label encoder on all data         lbl.fit(df[col])          # transform all the data         df.loc[:, col] = lbl.transform(df[col])      # get training data using folds     df_train = df[df.kfold != fold].reset_index(drop=True)      # get validation data using folds     df_valid = df[df.kfold == fold].reset_index(drop=True)      # get training data     x_train = df_train[features].values      # get validation data     x_valid = df_valid[features].values      # initialize xgboost model     model = xgb.XGBClassifier('),\n",
       " VectorParams(vector=[-0.03659219667315483, -0.1085941419005394, -0.10945667326450348, 0.04754822701215744, 0.13562935590744019, -0.07985926419496536, 0.023252682760357857, 0.05509834736585617, -0.15062108635902405, 0.015969520434737206, -0.07148455828428268, -0.19483588635921478, -0.05945057049393654, -0.10842820256948471, -0.013240271247923374, 0.08464861661195755, 0.03870968520641327, -0.07073133438825607, -0.14511682093143463, 0.022658821195364, 0.07531869411468506, 0.05809272825717926, -0.0038790982216596603, 0.061609964817762375, -0.04258079454302788, -0.10950960218906403, -0.004871400538831949, -0.006196573842316866, -0.09191685914993286, -0.06673060357570648, 0.030219294130802155, -0.026093171909451485, 0.09862970560789108, 0.011434538289904594, 0.040977947413921356, -0.005666948854923248, -0.055956870317459106, -0.0406462624669075, -0.04869545251131058, -0.008373282849788666, 0.04073791578412056, -0.022247876971960068, -0.03484077751636505, 0.02042938955128193, 0.03747515752911568, 0.10368084162473679, -0.06931117177009583, -0.09096768498420715, 0.037942543625831604, -0.022338077425956726, 0.04139484092593193, 0.06512011587619781, -0.14821812510490417, -0.020404918119311333, -0.05405861511826515, -0.04789316654205322, -0.0008810522267594934, -0.16612808406352997, 0.05905095115303993, -0.050889015197753906, 0.00019365065963938832, -0.006484104786068201, 0.005397150292992592, -0.04364067688584328, 0.044135771691799164, -0.04570586234331131, -0.1652590036392212, -0.09142707288265228, 0.002248912351205945, 0.06845531612634659, 0.03146054595708847, 0.04729112982749939, -0.004338136874139309, 0.06939168274402618, -0.039354514330625534, 0.05760694667696953, 0.0613974928855896, -0.06963249295949936, 0.0151618467643857, 0.013843797147274017, -0.10831376165151596, -0.013261173851788044, 0.06166656315326691, 0.022777916863560677, 0.016674529761075974, -0.15655331313610077, 0.07180196046829224, 0.030294226482510567, 0.0067433747462928295, -0.011094543151557446, 0.15365156531333923, 0.005196847021579742, -0.048992663621902466, 0.14011666178703308, 0.05749056488275528, 0.058964136987924576, 0.19673827290534973, -0.11029760539531708, -0.08041591197252274, 0.0824311226606369, -0.09167392551898956, 0.07544378191232681, 0.07909876853227615, -0.02951076440513134, 0.07020086795091629, -0.034011151641607285, 0.03174415975809097, 0.14599893987178802, 0.012450954876840115, -0.02103123813867569, 0.05402177572250366, 0.008287263102829456, -0.003280817996710539, 0.028599578887224197, 0.07315898686647415, 0.09645426273345947, -0.04739794135093689, 0.04408926144242287, -0.1837625652551651, 0.1026197224855423, -0.09284747391939163, 0.06029100716114044, 0.044540733098983765, 0.06916745752096176, -0.03504550829529762, -0.03653470799326897, -0.146675243973732, 1.1641594996076897e-32, -0.06687254458665848, 0.039083462208509445, -0.02964956685900688, -0.2107599675655365, 0.0061688111163675785, 0.05472712963819504, 0.04433479905128479, 0.04681660979986191, 0.12764079868793488, 0.09800104051828384, -0.18128204345703125, 0.03546970337629318, -0.07540671527385712, -0.061967067420482635, -0.010086694732308388, 0.011446211487054825, -0.01591387391090393, 0.033182885497808456, -0.13589666783809662, 0.09753065556287766, 0.1598145067691803, 0.016378408297896385, -0.02865583449602127, -0.07186194509267807, -0.04957148805260658, 0.06282146275043488, -0.00512136984616518, 0.016547858715057373, -0.08936838805675507, 0.04992345720529556, -0.13031168282032013, -0.04365682229399681, -0.034124165773391724, -0.02040194533765316, -0.09091954678297043, -0.0886973962187767, 0.05039430409669876, 0.042764727026224136, -0.06316596269607544, -0.0049268160946667194, 0.007210107520222664, -0.024667344987392426, 0.07048618048429489, -0.07616887986660004, 0.014894013293087482, -0.023585697636008263, 0.02826310507953167, 0.11111046373844147, -0.11406106501817703, 0.13410930335521698, 0.003184428671374917, -0.12134901434183121, -0.010583660565316677, 0.07004599273204803, -0.11179203540086746, 0.00391031289473176, 0.10926175862550735, 0.03542312979698181, 0.000190748818567954, 0.028708741068840027, 0.04035387560725212, -0.09562729299068451, -0.05422314256429672, -0.04000302404165268, 0.05015482008457184, 0.05352018401026726, 0.13574077188968658, -0.10936618596315384, -0.08739707618951797, -0.0025043529458343983, -0.13745811581611633, 0.005613253451883793, 0.08586974442005157, -0.06656046211719513, -0.01929282210767269, -0.056805018335580826, 0.15939028561115265, 0.08771120011806488, 0.014709949493408203, -0.05984245613217354, 0.027028720825910568, 0.27234792709350586, -0.015722068026661873, -0.16554373502731323, 0.06847640126943588, -0.015107563696801662, 0.0147350262850523, 0.0030285746324807405, -0.2171456664800644, -0.019869364798069, -0.060557469725608826, -0.11212453991174698, -0.03554172441363335, -0.05344276502728462, -0.09650611132383347, -9.606224323576199e-33, 0.04387457296252251, -0.0385521836578846, 0.02018178626894951, 0.13972102105617523, 0.10641775280237198, 0.06448422372341156, 0.0791396051645279, 0.014664394780993462, -0.11297829449176788, -0.16162480413913727, 0.09801105409860611, -0.01613704301416874, 0.08897280693054199, 0.07564807683229446, 0.08304352313280106, 0.04964639991521835, -0.03166861832141876, 0.1437591314315796, -0.03835349902510643, 0.010091470554471016, 0.021688122302293777, 0.14041921496391296, -0.09181509166955948, 0.016495944932103157, -0.06864256411790848, -0.006062701810151339, 0.02244594320654869, 0.005731252953410149, 0.05149749293923378, -0.02776997722685337, -0.062027934938669205, 0.1406133770942688, -0.08410027623176575, 0.07481458783149719, -0.01450840663164854, -0.11232586950063705, -0.025433707982301712, -0.0013479155022650957, -0.03152000159025192, 0.16241925954818726, 0.05140354484319687, 0.11720355600118637, -0.22530323266983032, 0.003314612666144967, -0.05312409624457359, 0.06024027243256569, -0.03161223605275154, -0.02045796997845173, 0.08713329583406448, 0.02317819744348526, 0.006223531439900398, -0.10006773471832275, -0.07175122201442719, 0.1006646677851677, -0.08455891162157059, 0.13603322207927704, -0.08657011389732361, 0.034163836389780045, 0.02292458713054657, 0.08131762593984604, -0.024906065315008163, 0.09069575369358063, 0.032615888863801956, -0.05256571248173714, 0.04270070791244507, 0.08037453889846802, -0.021591495722532272, 0.0805434137582779, 0.02874014340341091, 0.030656665563583374, -0.07275091856718063, -0.08783077448606491, 0.023309597745537758, -0.05017401650547981, -0.03623644635081291, 0.1256221979856491, 0.020085077732801437, -0.02500947192311287, 0.0489204116165638, -0.045142002403736115, -0.031404219567775726, 0.0077527728863060474, 0.10262230038642883, 0.13620905578136444, -0.049956243485212326, 0.17738103866577148, 0.07204511016607285, 0.1270863115787506, 0.06378558278083801, 0.003340835450217128, -0.01973840408027172, 0.07455206662416458, 0.15923015773296356, 0.06150094047188759, -0.07385656237602234, -9.991087779326335e-08, -0.06662745028734207, 0.05887638032436371, 0.04682692140340805, 0.08544552326202393, 0.048315100371837616, 0.10103822499513626, -0.10916464775800705, 0.05050837621092796, -0.07335186749696732, 0.030809123069047928, 0.12789401412010193, -0.11341502517461777, -0.214927539229393, 0.07951164245605469, 0.020204029977321625, 0.014814810827374458, 0.03277565911412239, 0.11093392968177795, -0.013394002802670002, 0.08099202811717987, 0.019740082323551178, -0.005902718752622604, 0.036468278616666794, -0.08379313349723816, 0.05832734704017639, -0.14969930052757263, 0.0055561247281730175, 0.061979591846466064, -0.016450731083750725, 0.05447383224964142, -0.016684500500559807, -0.1093401163816452, 0.04001558944582939, 0.04986513778567314, -0.01987062580883503, 0.16380424797534943, -0.013476437889039516, -0.09521297365427017, -0.019134314730763435, 0.14315593242645264, -0.020992644131183624, 0.06261724978685379, -0.0838301032781601, -0.05377812311053276, 0.028136523440480232, -0.015155244618654251, 0.07444918155670166, 0.0008202528115361929, 0.0806962251663208, -0.04339560866355896, -0.01633051037788391, -0.08649541437625885, -0.10392675548791885, -0.07624213397502899, 0.008999045938253403, 0.07224105298519135, -0.11524789035320282, 0.03354882448911667, -0.04521089792251587, 0.07884059846401215, 0.006777714006602764, -0.21835237741470337, -0.04705169424414635, 0.025496788322925568], metadata={'source': 'AAAMLP-569to.pdf', 'page': 118}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 119         n_jobs=-1,          max_depth=7,         n_estimators=200     )      # fit model on training data (ohe)     model.fit(x_train, df_train.target.values)      # predict on validation data     # we need the probability values as we are calculating AUC     # we will use the probability of 1s     valid_preds = model.predict_proba(x_valid)[:, 1]      # get roc auc score     auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)      # print auc     print(f\"Fold = {fold}, AUC = {auc}\")   if __name__ == \"__main__\":     for fold_ in range(5):         run(fold_) ═════════════════════════════════════════════════════════════════════════  It must be noted that in this code, I modified xgboost parameters a bit. Default max_depth for xgboost is 3, and I changed it to 7, and I also changed the number of estimators (n_estimators) from 100 to 200.  The 5 fold scores from this model are as follows:  ═════════════════════════════════════════════════════════════════════════ ❯ python lbl_xgb.py Fold = 0, AUC = 0.7656768851999011 Fold = 1, AUC = 0.7633006564148015 Fold = 2, AUC = 0.7654277821434345 Fold = 3, AUC = 0.7663609758878182 Fold = 4, AUC = 0.764914671468069 ═════════════════════════════════════════════════════════════════════════  We see that we have much better scores than plain random forest without any tuning and we can probably improve this further with more tuning of hyperparameters.  You can also try some feature engineering, dropping certain columns which don’t add any value to the model, etc. But it seems like there is not much we can do here'),\n",
       " VectorParams(vector=[-0.042351190000772476, 0.14208081364631653, 0.02476087585091591, 0.08466294407844543, 0.018214043229818344, 0.09128519892692566, -0.24003976583480835, -0.11813393235206604, -0.21205227077007294, -0.0479564294219017, 0.03768360614776611, -0.19183875620365143, -0.1515158712863922, -0.15932396054267883, 0.01925697736442089, 0.014487647451460361, 0.019411424174904823, 0.07928118109703064, -0.024944961071014404, 0.0029144142754375935, -0.025444408878684044, 0.07206010818481445, -0.0310114286839962, -0.056993164122104645, 0.1929241418838501, -0.011995252221822739, 0.16319453716278076, 0.16508665680885315, -0.0921788364648819, 0.022718261927366257, 0.05090257152915001, 0.09412464499473572, 0.07205777615308762, 0.05089513584971428, -0.1327897012233734, -0.03668161481618881, 0.019070258364081383, 0.16140276193618774, -0.014784235507249832, 0.02240549772977829, -0.0020056143403053284, -0.12269878387451172, 0.13060502707958221, -0.049219489097595215, 0.029612822458148003, 0.07076004892587662, 0.07053475081920624, 0.019951986148953438, 0.051206305623054504, 0.07005594670772552, -0.09198995679616928, -0.057845789939165115, 0.07192312180995941, 0.15431317687034607, -0.05502765253186226, 0.017877548933029175, -0.005220094230026007, -0.07382001727819443, -0.12319940328598022, -0.048841387033462524, -0.13085384666919708, 0.06976521015167236, 0.010308166965842247, 0.010264988988637924, 0.002230748999863863, -0.12672662734985352, -0.141351118683815, 0.12334418296813965, -0.04698677361011505, 0.09716404974460602, 0.022703085094690323, 0.047442998737096786, -0.22689475119113922, 0.017582524567842484, 0.0805809497833252, 0.010030314326286316, 0.08710669726133347, 0.023572038859128952, 0.16763226687908173, -0.1370847076177597, -0.02169090509414673, -0.03654994070529938, -0.07018882781267166, 0.02315247431397438, -0.005084878299385309, -0.08805381506681442, -0.024462545290589333, -0.027835242450237274, -0.07932116091251373, 0.048811979591846466, 0.02230318821966648, 0.061328139156103134, 0.20891520380973816, -0.019486112520098686, -0.07844270020723343, 0.0786726102232933, -0.0008575562387704849, -0.014069560915231705, 0.0017944795545190573, 0.10406432300806046, -0.14741022884845734, 0.05877460166811943, -0.008581887930631638, -0.03496531769633293, -0.09325016289949417, -0.028830504044890404, 0.15531107783317566, 0.2214847207069397, -0.02358202449977398, -0.15805333852767944, 0.11436888575553894, -0.04262030869722366, -0.11836105585098267, -0.04034755378961563, 0.03234253451228142, -0.0014208247885107994, -0.044098880141973495, 0.07658036798238754, -0.06989309191703796, 0.20098021626472473, -0.043467674404382706, 0.14581680297851562, -0.09913212060928345, 0.07065830379724503, -0.14071516692638397, -0.17888718843460083, -0.08509867638349533, 9.272835023899797e-33, 0.14024396240711212, -0.1035231202840805, -0.02939893677830696, 0.017775719985365868, 0.012549097649753094, -0.07253237813711166, 0.02131650410592556, -0.05799227952957153, 0.07341917604207993, 0.060457974672317505, 0.018040373921394348, 0.043954651802778244, -0.07031167298555374, 0.002089819172397256, -0.01573847606778145, 0.06186771020293236, -0.0645979791879654, 0.14953011274337769, -0.09486476331949234, 0.18285152316093445, 0.0847596600651741, 0.06960973888635635, 0.04410213977098465, -0.0794648826122284, -0.015291443094611168, 0.07268588989973068, -0.017521558329463005, -0.017851902171969414, -0.023555060848593712, -0.009284066036343575, -0.05604301765561104, 0.07374846190214157, -0.0010065955575555563, -0.13677479326725006, 0.020861808210611343, -0.10180488973855972, 0.13230884075164795, 0.01614084653556347, 0.06462784856557846, 0.06395404785871506, -0.04326145350933075, -0.07134640961885452, 0.11354324966669083, 0.04706854000687599, -0.013128376565873623, 0.1290002316236496, 0.13175952434539795, -4.3976600863970816e-05, -0.14801570773124695, 0.31980395317077637, -0.0046081324107944965, -0.13868488371372223, -0.01944058947265148, -0.034235112369060516, -0.25138914585113525, 0.06411503255367279, -0.07817703485488892, -0.021805288270115852, -0.10065484046936035, 0.0033115705009549856, -0.016639720648527145, 0.005683123599737883, 0.13215377926826477, 0.022015614435076714, -0.0896393358707428, 0.14007286727428436, 0.023936176672577858, -0.061329133808612823, 0.10034364461898804, 0.0907682552933693, -0.004211513791233301, 0.02968714013695717, -0.049833208322525024, 0.061500098556280136, 0.19456271827220917, 0.06253143399953842, 0.04093664139509201, -0.12155748903751373, -0.041991226375103, -0.08184245973825455, 0.1893831193447113, 0.1373254656791687, -0.08305217325687408, -0.19375990331172943, 0.15599185228347778, 0.08615852892398834, 0.07338052988052368, -0.09885092824697495, 0.14035241305828094, 0.007899027317762375, -0.16426949203014374, -0.044985175132751465, -0.07165653258562088, 0.02200215682387352, 0.09419780969619751, -1.0742353572641356e-32, -0.09445437043905258, 0.0058555020950734615, -0.05125274136662483, -0.05989113077521324, 0.0671873614192009, 0.054810408502817154, 0.05846451595425606, -0.05964934825897217, 0.05949936434626579, -0.020712299272418022, 0.030960645526647568, -0.19380390644073486, 0.10255111753940582, 0.06735847890377045, -0.07005342096090317, 0.008365570567548275, -0.04109315946698189, -0.1259220987558365, -0.006820071954280138, 0.027210015803575516, -0.040268365293741226, 0.1874694675207138, -0.11042846739292145, 0.2931314706802368, -0.10119958966970444, -0.035630423575639725, -0.18597818911075592, 0.0157080739736557, 0.04733835533261299, 0.007564682047814131, -0.11533298343420029, -0.047706928104162216, -0.13384006917476654, -0.021668413653969765, -0.05265624076128006, 0.11795219779014587, -0.07480216026306152, -0.057239606976509094, -0.04000714421272278, -0.002456141635775566, 0.07816608250141144, -0.02005227655172348, -0.17084559798240662, -0.040972646325826645, 0.053423259407281876, -0.028970493003726006, 0.036026351153850555, 0.04828427731990814, -0.012981066480278969, -0.03864814341068268, -0.040274716913700104, -0.061615414917469025, -0.03370975703001022, 0.1504421830177307, -0.0023010284639894962, -0.0786314383149147, 0.16653476655483246, -0.16474376618862152, -0.1449045091867447, 0.11205830425024033, -0.05178056284785271, 0.019181838259100914, -0.09200003743171692, 0.12568271160125732, 0.03565317019820213, -0.146750345826149, 0.06602269411087036, -0.11666124314069748, -0.05165546387434006, -0.008478038012981415, 0.0812683254480362, -0.1408158391714096, 0.14917679131031036, -0.05790793150663376, 0.0241134874522686, -0.04701538011431694, 0.12178972363471985, 0.06640800088644028, -0.010239905677735806, 0.17141640186309814, -0.08708753436803818, -0.14325770735740662, 0.20222322642803192, -0.019026625901460648, -0.01821191795170307, 0.13891535997390747, 0.0936751663684845, -0.003118891967460513, 0.008599319495260715, -0.004434893373399973, -0.16711515188217163, 0.04050835594534874, -0.1165214255452156, 0.01718982681632042, -0.04066881164908409, -9.872982786873763e-08, 0.063493512570858, 0.02684800885617733, -0.14990544319152832, -0.035516805946826935, -0.034593597054481506, -0.09442064166069031, -0.10615253448486328, 0.02315312623977661, 0.006229409947991371, 0.04687607288360596, 0.015391216613352299, 0.11721473932266235, 0.03058769181370735, -0.05305023118853569, -0.07520295679569244, 0.07335194200277328, 0.12314081937074661, 0.12638147175312042, -0.0249719750136137, -0.015885572880506516, 0.19707296788692474, -0.0559178963303566, -0.04070274904370308, 0.032065846025943756, 0.051667384803295135, -0.019393710419535637, 0.04612701013684273, 0.1573513001203537, 0.03288564085960388, 0.1531001776456833, -0.07782764732837677, -0.03770577162504196, -0.025199953466653824, -0.09592308849096298, 0.1736302524805069, -0.05550782382488251, 0.10919424891471863, -0.01920151896774769, -0.028776267543435097, 0.052321381866931915, -0.012861020863056183, -0.0885942131280899, -0.16323654353618622, -0.09280179440975189, 0.048856377601623535, -0.0663054808974266, 0.08174534142017365, 0.03284833952784538, 0.03702067583799362, 0.033020660281181335, 0.08905184268951416, -0.024371597915887833, -0.03718113526701927, -0.022142332047224045, 0.10650909692049026, 0.02027820236980915, 0.03254946693778038, -0.019688215106725693, 0.006199712865054607, -0.040324270725250244, 0.12298650294542313, -0.18697814643383026, -0.1039823666214943, -0.0058602322824299335], metadata={'source': 'AAAMLP-569to.pdf', 'page': 119}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 120 to demonstrate improvements in the model. Let’s change the dataset to another dataset with a lot of categorical variables. One more famous dataset is US adult census data. The dataset contains some features, and your job is to predict the salary bracket. Let’s take a look at this dataset. Figure 5 shows some of the columns from this dataset.  \\n Figure 5: Snapshot with few columns from the adult dataset6  This dataset has the following columns: • age • workclass • fnlwgt • education • education.num • marital.status • occupation • relationship • race • sex • capital.gain • capital.loss • hours.per.week  6 https://archive.ics.uci.edu/ml/datasets/adult'),\n",
       " VectorParams(vector=[-0.015108119696378708, -0.02896704711019993, -0.1041417270898819, 0.047891609370708466, 0.13712263107299805, -0.10386867821216583, -0.01052748691290617, -0.01872161589562893, -0.048031389713287354, 0.06035643815994263, 0.06778138875961304, -0.18529875576496124, -0.058592624962329865, -0.09405568987131119, -0.021768003702163696, -0.04188625514507294, -0.10435809940099716, -0.022328419610857964, -0.07736276835203171, 0.013460786081850529, -0.027919765561819077, 0.0325990654528141, -0.09425739198923111, 0.09224686026573181, 0.01616276241838932, -0.12667912244796753, 0.0636853352189064, 0.1387425810098648, -0.08338134735822678, -0.011754794977605343, 0.01616351306438446, 0.12028363347053528, -0.032987192273139954, 0.060443487018346786, 0.029964905232191086, 0.01242293044924736, -0.016872210428118706, 0.12713679671287537, -0.022698163986206055, 0.018422845751047134, 0.004734962712973356, -0.12808308005332947, 0.08676595985889435, -0.07913915812969208, 0.017208673059940338, -0.03364315629005432, -0.018538091331720352, -0.030272778123617172, 0.06010458245873451, -0.002959265373647213, -0.036726776510477066, 0.21919970214366913, -0.06676438450813293, 0.04704958200454712, -0.070567287504673, -0.15343455970287323, 0.04911694675683975, -0.13322106003761292, -0.00859777256846428, -0.04401691257953644, -0.15033258497714996, -0.022897424176335335, 0.039691247045993805, -0.06928777694702148, 0.026993928477168083, -0.11056555807590485, -0.10480710864067078, 0.054619383066892624, -0.1178169846534729, 0.09675459563732147, -0.01342804729938507, -0.05131795257329941, -0.14583410322666168, 0.04760691151022911, -0.00026752662961371243, -0.090947225689888, 0.16778364777565002, -0.010118509642779827, 0.14206674695014954, -0.12093335390090942, -0.008565211668610573, 0.11329668015241623, -0.027271628379821777, -0.04635424166917801, 0.030050000175833702, -0.12773704528808594, 0.04573672637343407, -0.024856941774487495, 0.04724447801709175, -0.02640911005437374, 0.23773589730262756, -0.019205784425139427, 0.08361269533634186, 0.06733355671167374, 0.12606142461299896, 0.07125937938690186, 0.06677544116973877, -0.019077446311712265, -0.02524455264210701, 0.11871226131916046, -0.03051779419183731, -0.0027877932880073786, 0.09733980149030685, -0.06208028271794319, 0.02817276492714882, -0.04868875443935394, 0.14429549872875214, 0.1889907270669937, 0.09499137848615646, -0.048547498881816864, 0.1043742373585701, 0.04491334408521652, -0.12168808281421661, 0.03936753794550896, 0.06498342752456665, 0.03571237996220589, -0.025077708065509796, -0.02802993357181549, -0.09738907217979431, 0.1627063751220703, -0.04267456382513046, 0.11161293089389801, 0.044622376561164856, 0.057311367243528366, 0.046084120869636536, -0.1523168385028839, -0.022887086495757103, 7.116589001988012e-33, -0.06813421845436096, 0.024667004123330116, 0.003419253509491682, -0.13567674160003662, -0.11205967515707016, -0.058357495814561844, -0.012127251364290714, 0.13372816145420074, -0.04962773993611336, 0.08580902963876724, -0.08104623109102249, 0.13576792180538177, -0.060910578817129135, 0.05925717204809189, 0.0547800213098526, 0.06969502568244934, -0.07410111278295517, -0.019849400967359543, -0.07435978204011917, 0.06348811089992523, 0.2301110178232193, -0.1292073130607605, 0.07075685262680054, -0.01601715013384819, -0.09866533428430557, 0.060362789779901505, -0.13385887444019318, -0.04727635905146599, -0.05521189048886299, 0.05216506868600845, -0.09852033853530884, -0.012129457667469978, 0.07799208909273148, -0.1080121099948883, 0.05084152892231941, -0.05148003250360489, 0.12492145597934723, 0.07063226401805878, -0.009888066910207272, 0.003929622005671263, -0.13396278023719788, 0.06893190741539001, 0.12225500494241714, 0.00013801935710944235, -0.04595765471458435, 0.01831791363656521, 0.1516948789358139, 0.11466836929321289, -0.09959755092859268, 0.2090875655412674, 0.0631079152226448, -0.1648215502500534, 0.018503565341234207, -0.039193883538246155, -0.13731247186660767, 0.05985064059495926, 0.05756494402885437, -0.0839003250002861, 0.06364323198795319, 0.028456678614020348, 0.023089341819286346, -0.0729127749800682, 0.05212206393480301, -0.020209450274705887, -0.0549023263156414, 0.09569154679775238, 0.20353417098522186, 0.04586372524499893, 0.06720130890607834, -0.05538506433367729, -0.138894721865654, 0.02917390689253807, -0.006685007829219103, -0.05807614326477051, 0.10267084091901779, -0.051071036607027054, 0.07277489453554153, -0.02706177346408367, -0.0013877233723178506, 0.025146139785647392, 0.13305482268333435, 0.10495735704898834, -0.108078733086586, -0.11839716136455536, 0.009263007901608944, 0.012775608338415623, 0.03565429151058197, -0.12531623244285583, -0.09644094109535217, -0.09704016894102097, -0.0463736318051815, -0.04300601780414581, -0.034386057406663895, -0.10585790872573853, -0.014866181649267673, -1.1370206411250648e-32, -0.02920559048652649, 0.022747822105884552, -0.02366212010383606, 0.021960921585559845, 0.027092017233371735, -0.021169200539588928, 0.059092115610837936, 0.005920354276895523, -0.10448034107685089, -0.13144545257091522, 0.023960750550031662, -0.1250590831041336, 0.045292917639017105, 0.06998535990715027, 0.054911766201257706, 0.0223041120916605, -0.0813145786523819, 0.13216650485992432, -0.023871660232543945, -0.023960504680871964, -0.0010794299887493253, 0.18925894796848297, -0.10638416558504105, 0.06575871258974075, -0.11783351749181747, 0.03044619783759117, -0.122311532497406, 0.034487709403038025, 0.06332528591156006, -0.004264011979103088, -0.10991833359003067, 0.0885920599102974, -0.08111104369163513, 0.016919538378715515, -0.06542979180812836, 0.04391992464661598, 0.011989651247859001, -0.06121869757771492, -0.09434545040130615, 0.05989924818277359, 0.09440407156944275, 0.13120487332344055, -0.22324131429195404, 0.0155706275254488, -0.06430276483297348, 0.05779891833662987, -0.04459360986948013, 0.08060462027788162, 0.10603833943605423, -0.024204343557357788, 0.11093338578939438, -0.05515933036804199, -0.03502907231450081, 0.19081896543502808, -0.12186315655708313, 0.09692913293838501, 0.009089791215956211, -0.04546898603439331, -0.17275479435920715, -0.026327619329094887, -0.13528947532176971, 0.04754258319735527, -0.08614648133516312, 0.08982327580451965, 0.01748979650437832, -0.0751102939248085, -0.06716838479042053, -0.05009327456355095, 0.10085131227970123, -0.163057342171669, -0.03278554230928421, -0.1237228736281395, -0.006750176660716534, -0.18068447709083557, -0.06579050421714783, 0.16648134589195251, -0.018958548083901405, -0.08481015264987946, 0.04134146124124527, 0.08001232892274857, -0.11908628046512604, -0.09706316888332367, 0.17570486664772034, 0.14150963723659515, -0.14499886333942413, 0.027246933430433273, 0.04637477546930313, -0.08554831892251968, -0.07743105292320251, 0.031031908467411995, -0.1132313534617424, 0.0034760981798171997, 0.023428861051797867, 0.0915551632642746, -0.042494408786296844, -1.0078571932581326e-07, -0.04095824062824249, 0.03664470463991165, -0.031466588377952576, -0.003943820483982563, 0.026200545951724052, 0.024104183539748192, -0.09041493386030197, -0.03138461709022522, 0.0042289444245398045, 0.12523390352725983, 0.1108107939362526, -0.04086454212665558, -0.10452581197023392, -0.006703501101583242, -0.11217095702886581, 0.09241192787885666, 0.06536540389060974, 0.03746582940220833, -0.07285186648368835, 0.0495535172522068, 0.12116268277168274, -0.025537317618727684, -0.047578755766153336, -0.0866728201508522, 0.031346339732408524, -0.05214713141322136, -0.05095613747835159, 0.19227395951747894, -0.030356774106621742, 0.016256004571914673, 0.03510254621505737, -0.11722493171691895, -0.05771372839808464, 0.03702196106314659, 0.10881809145212173, 0.030426576733589172, 0.035687122493982315, -0.053283870220184326, -0.02833317220211029, 0.013049553148448467, -0.022211015224456787, -0.03413255885243416, -0.21107254922389984, -0.09853760153055191, 0.04671500250697136, -0.015671290457248688, -0.07187812775373459, 0.00020629813661798835, 0.06460943073034286, -0.06558965146541595, 0.025423401966691017, -0.0455145463347435, -0.027437914162874222, 0.02270660549402237, 0.13494350016117096, -0.06365011632442474, -0.04539433866739273, 0.039552245289087296, 0.009430896490812302, 0.003394240513443947, 0.074435755610466, -0.020978379994630814, -0.005497473757714033, -0.03436450660228729], metadata={'source': 'AAAMLP-569to.pdf', 'page': 120}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 121 • native.country • income  Most of these columns are self-explanatory. Those which are not, we can forget about it. Let’s try to build a model first.  We see that the income column is a string. Let’s do a value counts on that column.  ═════════════════════════════════════════════════════════════════════════ In [X]: import pandas as pd  In [X]: df = pd.read_csv(\"../input/adult.csv\")  In [X]: df.income.value_counts() Out[X]: <=50K    24720 >50K      7841 ═════════════════════════════════════════════════════════════════════════  We see that there are 7841 instances with income greater than 50K USD. This is ~24% of the total number of samples. Thus, we will keep the evaluation same as the cat-in-the-dat dataset, i.e. AUC.  Before we start modelling, for simplicity, we will be dropping a few columns, which are numerical, namely:  • fnlwgt • age • capital.gain • capital.loss • hours.per.week  Let’s try to quickly throw in one hot encoder with logistic regression and see what happens. The first step is always making cross-validation. I’m not going to show that part of the code here. It is left as an exercise for the reader.  ═════════════════════════════════════════════════════════════════════════ # ohe_logres.py import pandas as pd  from sklearn import linear_model from sklearn import metrics from sklearn import preprocessing'),\n",
       " VectorParams(vector=[0.08218936622142792, -0.004696201533079147, -0.04433920979499817, -0.002049477770924568, 0.1553078293800354, -0.043800849467515945, 0.010461132042109966, -0.01190915796905756, -0.17204995453357697, -0.002078165067359805, 0.10247202217578888, -0.15921558439731598, -0.06453166157007217, -0.14497758448123932, -0.020185697823762894, 0.09342840313911438, -0.1587800532579422, 0.07747551053762436, -0.09999842941761017, -0.03509358689188957, -0.04798033833503723, 0.11708422005176544, -0.014906895346939564, 0.045173995196819305, -0.042277008295059204, 0.017559802159667015, 0.07490448653697968, 0.09856460243463516, -0.1418454647064209, -0.032527416944503784, -0.026548219844698906, 0.08249531686306, -0.025780243799090385, -0.03223961591720581, 0.08228025585412979, 0.07339311391115189, -0.07030706107616425, 0.1403682380914688, -0.03678739815950394, 0.16226805746555328, -0.07867667078971863, -0.08700679987668991, 0.12322362512350082, -0.020877230912446976, 0.06449971348047256, 0.042273763567209244, -0.07993488758802414, -0.06321463733911514, 0.15447863936424255, -0.03761540353298187, -0.05078713595867157, 0.12802280485630035, -0.10644076019525528, 0.03410353139042854, -0.11887266486883163, -0.12578265368938446, -0.037019938230514526, -0.1206364557147026, 0.03210068866610527, -0.048540834337472916, -0.130140021443367, -0.07948031276464462, 0.10424140840768814, -0.11868340522050858, 0.04912356659770012, -0.08371711522340775, -0.11357486248016357, 0.019999859854578972, -0.1434836983680725, 0.10189680010080338, -0.05078961327672005, 0.028902439400553703, -0.11827653646469116, 0.05005074664950371, -0.05681142583489418, 0.011809445917606354, 0.1695828139781952, -0.045109838247299194, 0.20039331912994385, 0.00044711079681292176, -0.18456223607063293, -0.03833307325839996, -0.025809042155742645, -0.052154362201690674, -0.059771426022052765, -0.11780538409948349, -0.0021968232467770576, 0.018005773425102234, 0.023956583812832832, 0.0077410247176885605, 0.07747579365968704, 0.013690100982785225, 0.08881932497024536, 0.04406367614865303, -0.006218062713742256, 0.06311226636171341, 0.004106502514332533, 0.015475268475711346, -0.01441981177777052, 0.15394969284534454, -0.09981585294008255, -0.0448949858546257, -0.008387458510696888, -0.10121423006057739, -0.1081804558634758, -0.021293384954333305, 0.1897944211959839, 0.1327568143606186, 0.0763365775346756, -0.07568375766277313, 0.03333526477217674, -0.07241717725992203, -0.04929377883672714, -0.03466111794114113, 0.04899708554148674, 0.05158721283078194, -0.041608311235904694, 0.05921507999300957, -0.08765659481287003, 0.1577320545911789, -0.0679502934217453, 0.08304475992918015, 0.012225178070366383, 0.05201210826635361, -0.11568017303943634, -0.12908075749874115, -0.06072176992893219, 1.3934849292680836e-32, -0.10150311142206192, 0.017173508182168007, 0.015085815452039242, -0.07726356387138367, -0.0730842873454094, -0.06386923044919968, 0.017466222867369652, 0.04071202874183655, 0.042833756655454636, 0.05750778689980507, -0.15164682269096375, 0.09099928289651871, -0.12098987400531769, -0.02109212800860405, -0.06014515459537506, -0.08688116818666458, 0.06803251802921295, 0.013860859908163548, -0.07341716438531876, 0.002661661710590124, 0.23955771327018738, -0.03795906528830528, 0.016345880925655365, -0.07444717735052109, -0.0028958742041140795, -0.10384991765022278, -0.15698540210723877, 0.02953796274960041, -0.06264480203390121, -0.017676612362265587, -0.19537293910980225, 0.0062940288335084915, -0.004866243805736303, -0.11755918711423874, 0.020002519711852074, -0.11591874063014984, 0.10562602430582047, 0.1153566762804985, -0.033308424055576324, 0.023744827136397362, -0.13901928067207336, -0.0005565531319007277, 0.07918109744787216, -0.06925114244222641, -0.001734574674628675, 0.02465921826660633, 0.14531096816062927, 0.07160378992557526, -0.0872383713722229, 0.10910337418317795, -0.004885039292275906, -0.15599538385868073, -0.0026050058659166098, 0.016971254721283913, -0.18056482076644897, 0.11712383478879929, 0.014038939028978348, -0.045631103217601776, 0.04527362063527107, 0.010227853432297707, -0.02068224921822548, -0.017529048025608063, 0.006230058614164591, 0.04762621968984604, -0.04329487681388855, 0.056743234395980835, 0.1948627382516861, 0.05031124874949455, 0.043567486107349396, -0.039306726306676865, -0.017361478880047798, -0.028625894337892532, 0.030318930745124817, -0.14167670905590057, 0.14413027465343475, -0.11693235486745834, 0.0625070184469223, -0.032889224588871, -0.07831533998250961, -0.03929338604211807, 0.07019881904125214, 0.12720178067684174, -0.10515394061803818, -0.14990632236003876, 0.05472540482878685, 0.03931216523051262, 0.03581974655389786, -0.09992016106843948, -0.10470609366893768, -0.07193204760551453, -0.18367093801498413, -0.04781664162874222, -0.043308407068252563, -0.14375336468219757, 0.06757748126983643, -1.475301246263635e-32, 0.0062975334003567696, 0.028098737820982933, 0.0237516351044178, 0.0029981040861457586, 0.1581743061542511, 0.1263766884803772, 0.07424724847078323, 0.011865039356052876, -0.01748320460319519, -0.10858079791069031, -0.03159704431891441, -0.16479331254959106, -0.031363315880298615, -0.050996601581573486, -0.056026216596364975, 0.03944958373904228, -0.10799416154623032, 0.2106976956129074, -0.0820050835609436, 0.05865243822336197, -0.06432583183050156, 0.2309996634721756, -0.10564456135034561, 0.09734348207712173, -0.10560792684555054, 0.012380236759781837, 0.0010638926178216934, 0.11726551502943039, 0.04285252466797829, 0.02151644043624401, -0.09987703710794449, -0.01830613799393177, -0.10010316967964172, 0.12039276957511902, -0.010663549415767193, -0.024148354306817055, 0.0757383331656456, -0.10710448771715164, -0.1598111093044281, 0.13987033069133759, 0.11700346320867538, 0.10526341199874878, -0.17824576795101166, 0.09229762852191925, -0.0156091945245862, 0.07841283828020096, 0.07663579285144806, 0.07105410844087601, 0.030593952164053917, 0.01954987831413746, 0.08441225439310074, -0.005585911218076944, -0.06472819298505783, 0.057939331978559494, -0.030369145795702934, 0.09705614298582077, -0.006452563218772411, -0.08360829204320908, -0.16444352269172668, -0.00214452319778502, -0.12871842086315155, 0.01650518737733364, -0.03360437601804733, 0.036094311624765396, 0.17330917716026306, -0.04671565070748329, -0.049532804638147354, 0.010218226350843906, 0.0238046832382679, 0.004617772065103054, -0.11444869637489319, -0.08174077421426773, 0.07547535002231598, -0.11345069855451584, -0.019600870087742805, 0.09259162098169327, -0.019445253536105156, -0.0560118667781353, 0.020457183942198753, 0.11054665595293045, -0.04485636577010155, -0.09102051705121994, 0.14140652120113373, 0.23432672023773193, -0.036798734217882156, 0.12783147394657135, 0.088656947016716, -0.020245958119630814, 0.017859868705272675, 0.009430519305169582, 0.05475907400250435, -0.09670012444257736, 0.1264154613018036, 0.2229587733745575, -0.08554703742265701, -1.0066732869518091e-07, 0.03129906579852104, 0.07709019631147385, -0.06381851434707642, -0.024001387879252434, -0.0067362398840487, 0.02341817319393158, 0.0067150406539440155, -0.0022768517956137657, 0.0009618565090931952, 0.09164383262395859, 0.12879277765750885, 0.052319906651973724, -0.098907470703125, 0.01123613677918911, -0.025071917101740837, 0.06456717848777771, -0.032251887023448944, 0.08269427716732025, 0.00472527788951993, 0.09404464066028595, 0.18878377974033356, -0.0948842242360115, -0.04876211658120155, -0.03280885890126228, 0.06749375909566879, -0.17469584941864014, -0.06587818264961243, 0.14005395770072937, 0.1023782342672348, 0.04294351115822792, 0.01351520698517561, -0.17444919049739838, 0.0014985589077696204, 0.0082191601395607, 0.12080775201320648, -0.04652353376150131, 0.11076212674379349, -0.09273884445428848, -0.027078034356236458, 0.1569792628288269, -0.0757320374250412, 0.13920235633850098, -0.11661635339260101, -0.07330583781003952, -0.05551895126700401, 0.004812033846974373, -0.014906611293554306, 0.05007423460483551, 0.19046972692012787, -0.02505553513765335, -0.08249980211257935, -0.00031372334342449903, -0.062330469489097595, 0.02283373288810253, 0.15807658433914185, 0.01835920847952366, -0.03444838151335716, 0.0838722363114357, -0.04654104262590408, 0.0016552999150007963, 0.07111266255378723, -0.005341567099094391, -0.007713567931205034, -0.08136402070522308], metadata={'source': 'AAAMLP-569to.pdf', 'page': 121}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 122 def run(fold):     # load the full training data with folds     df = pd.read_csv(\"../input/adult_folds.csv\")      # list of numerical columns     num_cols = [         \"fnlwgt\",         \"age\",         \"capital.gain\",         \"capital.loss\",         \"hours.per.week\"     ]      # drop numerical columns     df = df.drop(num_cols, axis=1)      # map targets to 0s and 1s     target_mapping = {         \"<=50K\": 0,         \">50K\": 1     }     df.loc[:, \"income\"] = df.income.map(target_mapping)      # all columns are features except income and kfold columns     features = [         f for f in df.columns if f not in (\"kfold\", \"income\")     ]      # fill all NaN values with NONE     # note that I am converting all columns to \"strings\"     # it doesnt matter because all are categories     for col in features:         df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")          # get training data using folds     df_train = df[df.kfold != fold].reset_index(drop=True)      # get validation data using folds     df_valid = df[df.kfold == fold].reset_index(drop=True)      # initialize OneHotEncoder from scikit-learn     ohe = preprocessing.OneHotEncoder()      # fit ohe on training + validation features     full_data = pd.concat(         [df_train[features], df_valid[features]],         axis=0'),\n",
       " VectorParams(vector=[-0.07916595786809921, -0.05958664044737816, -0.1514636129140854, 0.04167274758219719, 0.1628950536251068, -0.09236157685518265, 0.04737686365842819, 0.1291106790304184, -0.1360444277524948, -0.01309938170015812, 0.03883238881826401, -0.1998254954814911, -0.10669218748807907, -0.057205963879823685, -0.0352439358830452, 0.07508372515439987, -0.021684715524315834, -0.03789573162794113, -0.12523959577083588, 0.07493513077497482, 0.08796371519565582, 0.043295372277498245, 0.02982397936284542, 0.09469328075647354, 0.015965329483151436, -0.05797629803419113, 0.011097571812570095, 0.05508944019675255, -0.0702410638332367, -0.04741445556282997, 0.026106620207428932, -0.04103553667664528, 0.08582866191864014, 0.07489638030529022, -0.002214863197878003, -0.03786511346697807, -0.04140343517065048, -0.043939489871263504, -0.01937643066048622, -0.07123146206140518, 0.054501164704561234, -0.017948582768440247, -0.005968374665826559, -0.0007370123057626188, 0.04907524213194847, 0.0581711083650589, -0.004792165942490101, -0.04060479998588562, 0.009425800293684006, 0.015347533859312534, 0.023719312623143196, 0.016061648726463318, -0.11863221228122711, -0.06992095708847046, -0.15157924592494965, -7.691325663472526e-06, 0.06347265094518661, -0.17644745111465454, 0.07730427384376526, -0.03850570321083069, -0.05657033994793892, 0.000848081661388278, -0.03669460117816925, -0.023741528391838074, 0.010328502394258976, -0.05725047364830971, -0.15902963280677795, -0.06982522457838058, -0.03135635331273079, 0.03534175455570221, -0.06787109375, -0.055949728935956955, 0.0008100242121145129, 0.04684013873338699, 0.06575727462768555, -0.01319633424282074, 0.09705083072185516, -0.061754729598760605, 0.04906089976429939, -0.010265031829476357, -0.08671731501817703, 0.0347893163561821, 0.08618208020925522, -0.010187866166234016, 0.14610536396503448, -0.12957821786403656, 0.12532497942447662, 0.024529026821255684, 0.015332885086536407, -0.07689166069030762, 0.07894483208656311, 0.020834671333432198, -0.06196460872888565, 0.04109831899404526, 0.05626716464757919, 0.0645466297864914, 0.1442510485649109, -0.04244646057486534, -0.02951028011739254, 0.06983232498168945, -0.09319988638162613, 0.06063159555196762, 0.11152570694684982, -0.043313514441251755, 0.07006020098924637, -0.074116550385952, 0.03731332719326019, 0.1202053651213646, 0.06807461380958557, 0.005537468008697033, 0.022551555186510086, 0.007801022846251726, -0.05114363878965378, 0.05805423855781555, 0.0828351378440857, 0.11315005272626877, -0.08801867812871933, -0.025893770158290863, -0.16937141120433807, 0.09408258646726608, -0.11353335529565811, 0.057063404470682144, 0.07342200726270676, 0.1058795377612114, -0.0003792216011788696, -0.11358410120010376, -0.057554811239242554, 1.2257288814994872e-32, -0.10031523555517197, 0.042744554579257965, -0.032410379499197006, -0.20709961652755737, -0.014467449858784676, 0.06237642094492912, -0.047883644700050354, 0.012056873179972172, 0.08360063284635544, 0.11257895827293396, -0.18995530903339386, 0.08615119010210037, -0.02783382497727871, -0.0038216509856283665, -0.04301739111542702, -0.007465284783393145, -0.02763690985739231, 0.0331360287964344, -0.07129418849945068, 0.0680994987487793, 0.12108249217271805, 0.009905992075800896, 0.045873042196035385, -0.07917598634958267, -0.09790200740098953, 0.06586506217718124, -0.012953635305166245, 0.07710763812065125, -0.0636017695069313, 0.05514751002192497, -0.11092294007539749, -0.03533850237727165, 0.003878237446770072, -0.11320137977600098, -0.07191868871450424, -0.04084606096148491, 0.024995848536491394, -0.0026133758947253227, -0.06233659014105797, -0.03267519176006317, -0.060010895133018494, 0.020798588171601295, 0.09899517893791199, -0.11614971607923508, -0.00722874142229557, -0.12139676511287689, -0.02946343831717968, 0.19598433375358582, -0.05867232009768486, 0.1394011676311493, -0.019289128482341766, -0.21181292831897736, -0.0713043138384819, 0.0656915083527565, -0.11674601584672928, 0.062497008591890335, 0.07382307201623917, 0.08929308503866196, 0.018204381689429283, 0.037102412432432175, 0.05489480867981911, -0.06691040098667145, -0.00474447850137949, -0.04807848483324051, 0.027385994791984558, 0.08790995925664902, 0.18172918260097504, -0.08008993417024612, -0.04741307348012924, 0.005911551881581545, -0.113980732858181, -0.0016917269676923752, 0.04888797923922539, -0.025758424773812294, 0.007650298532098532, -0.015104676596820354, 0.07637326419353485, 0.04344197362661362, -0.04711318016052246, 0.055797029286623, 0.005298638716340065, 0.24311266839504242, -0.02814423106610775, -0.06115997955203056, 0.047186702489852905, 0.01042166817933321, 0.02150103822350502, -0.0425470769405365, -0.29770854115486145, 0.009875531308352947, -0.09429075568914413, -0.05207259953022003, 0.005733021069318056, -0.04175778850913048, -0.0633307471871376, -1.2999274808229316e-32, 0.0655495822429657, -0.00930604338645935, 0.07119116187095642, 0.1024874821305275, 0.04514799267053604, -0.005116802174597979, 0.07192311435937881, 0.05675594136118889, -0.1191914975643158, -0.1560826152563095, 0.15791501104831696, -0.11167805641889572, 0.08627130091190338, 0.0475759282708168, 0.121550552546978, 0.05136491730809212, -0.1343560516834259, 0.14898940920829773, 0.0019958922639489174, 0.10918932408094406, 0.10089099407196045, 0.13265694677829742, -0.13941340148448944, 0.01853354088962078, -0.10178094357252121, -0.010890566743910313, 0.04362785071134567, 0.030347419902682304, 0.036752209067344666, -0.0794670358300209, -0.1045970618724823, 0.14773017168045044, -0.10382208228111267, 0.03986106067895889, -0.013277377933263779, -0.049097783863544464, -0.056306298822164536, -0.03686702996492386, -0.0814635306596756, 0.14141039550304413, 0.049883536994457245, 0.10574871301651001, -0.2668195068836212, -0.04264175146818161, -0.05167444795370102, 0.02026158571243286, 0.008969124406576157, 0.028484949842095375, 0.09209328889846802, -0.024923598393797874, 0.08298001438379288, -0.0677463561296463, -0.017627160996198654, 0.12575872242450714, -0.14280201494693756, 0.1279248744249344, -0.08883140236139297, 0.024097373709082603, -0.09821297973394394, 0.029680857434868813, -0.10942009091377258, 0.042366817593574524, 0.1562657356262207, -0.08787234872579575, -0.021555757150053978, -0.003725898452103138, -0.07296165823936462, 0.06764360517263412, 0.028796931728720665, 0.015308067202568054, 0.029611783102154732, -0.0321897454559803, 0.047052234411239624, -0.00861095730215311, -0.07426680624485016, 0.07445081323385239, -0.0023748476523905993, -0.05917424336075783, 0.03915936127305031, 0.01964779570698738, -0.055931396782398224, 0.0037191067822277546, 0.05041399598121643, 0.21050232648849487, -0.06651733815670013, 0.02812260575592518, 0.09686309099197388, 0.06892525404691696, 0.0392744354903698, -0.05705263093113899, -0.00018237043695989996, 0.1011730507016182, 0.09901965409517288, 0.18389585614204407, -0.0635373666882515, -1.0072676559502725e-07, -0.02464541234076023, 0.022358648478984833, 0.05785287544131279, 0.07728841155767441, 0.040995582938194275, 0.1457633376121521, -0.09491025656461716, -0.04821851849555969, -0.15046030282974243, -0.005425794515758753, 0.10329669713973999, -0.05886225774884224, -0.2201281040906906, 0.014685828238725662, -0.07565303891897202, 0.08070851862430573, 0.06523890793323517, 0.1195945292711258, 0.006008601747453213, 0.0328013114631176, -0.027289533987641335, -0.04562000557780266, 0.0660804957151413, -0.11902277916669846, 0.0034768483601510525, -0.1381705105304718, -0.06196611374616623, 0.09506186842918396, -0.06653708964586258, 0.03783983737230301, 0.02895405888557434, -0.05308100953698158, 0.009617463685572147, 0.06018825247883797, -0.054561782628297806, 0.13067634403705597, 0.03934849426150322, -0.13482972979545593, 0.01897634007036686, 0.11393266171216965, -0.014266069047152996, 0.09387371689081192, -0.1677347719669342, -0.05717506259679794, 0.04191816225647926, 0.07812728732824326, 0.10266737639904022, -0.025598393753170967, 0.03789258003234863, -0.008391523733735085, -0.020310329273343086, -0.04587240144610405, -0.10548609495162964, -0.10036733001470566, 0.022162720561027527, -0.006233012769371271, -0.07520822435617447, -0.047040268778800964, -0.06284183263778687, 0.09889763593673706, -0.023951346054673195, -0.13888518512248993, 0.04207242280244827, -0.0100129758939147], metadata={'source': 'AAAMLP-569to.pdf', 'page': 122}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 123     )     ohe.fit(full_data[features])      # transform training data     x_train = ohe.transform(df_train[features])      # transform validation data     x_valid = ohe.transform(df_valid[features])      # initialize Logistic Regression model     model = linear_model.LogisticRegression()      # fit model on training data (ohe)     model.fit(x_train, df_train.income.values)      # predict on validation data     # we need the probability values as we are calculating AUC     # we will use the probability of 1s     valid_preds = model.predict_proba(x_valid)[:, 1]      # get roc auc score     auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)      # print auc     print(f\"Fold = {fold}, AUC = {auc}\")   if __name__ == \"__main__\":     for fold_ in range(5):         run(fold_) ═════════════════════════════════════════════════════════════════════════  And when we run this code, we get:  ═════════════════════════════════════════════════════════════════════════ ❯ python -W ignore ohe_logres.py Fold = 0, AUC = 0.8794809708119079 Fold = 1, AUC = 0.8875785068274882 Fold = 2, AUC = 0.8852609687685753 Fold = 3, AUC = 0.8681236223251438 Fold = 4, AUC = 0.8728581541840037 ═════════════════════════════════════════════════════════════════════════  This is a very good AUC for a model which is that simple!  Let’s try the label encoded xgboost without tuning any of hyperparameters now.'),\n",
       " VectorParams(vector=[0.02922726795077324, -0.02064303681254387, -0.045024801045656204, -0.0002872250333894044, 0.11122450232505798, 0.007368320599198341, 0.029646901413798332, -0.04503742232918739, -0.21494410932064056, -0.04178173094987869, 0.05508212745189667, -0.16688889265060425, -0.07961951196193695, -0.1094694510102272, 0.01739645004272461, 0.1427401453256607, -0.129231259226799, 0.013684272766113281, -0.06471147388219833, -0.040610525757074356, 0.019991934299468994, 0.07505040615797043, -0.02775716967880726, -0.00892701093107462, -0.006671393755823374, 0.040198396891355515, 0.06582970917224884, 0.016133666038513184, -0.09594468027353287, -0.0022612998727709055, -0.008462101221084595, 0.12166523933410645, 0.08017292618751526, 0.0025339960120618343, 0.04354505613446236, 0.07376393675804138, -0.01863284409046173, 0.1291031688451767, -0.05590127035975456, 0.05747578293085098, -0.042258646339178085, -0.11979757994413376, 0.0844917744398117, -0.09307751804590225, 0.062200985848903656, 0.022048216313123703, 0.0181144829839468, -0.04766704514622688, 0.06968051195144653, 0.021813467144966125, -0.002996487310156226, 0.16006264090538025, -0.085908442735672, 0.022279562428593636, -0.08978989720344543, -0.11060342937707901, 0.0038418190088123083, -0.1341140866279602, 0.05054384469985962, -0.0460796132683754, -0.14643344283103943, -0.06657081842422485, 0.08939686417579651, -0.09347846359014511, 0.10023274272680283, -0.0944477766752243, -0.10420025140047073, 0.002658556681126356, -0.19910357892513275, 0.16665810346603394, -0.02335493639111519, -0.025914141908288002, -0.13238710165023804, 0.05886608362197876, -0.06967556476593018, -0.018341705203056335, 0.24448686838150024, -0.007606500759720802, 0.1740410178899765, -0.02961556985974312, -0.12990546226501465, 0.01624130830168724, -0.06286461651325226, 0.03781890496611595, -0.07275691628456116, -0.16615012288093567, -0.06167294830083847, 0.021403919905424118, -0.031640004366636276, -0.02169044315814972, 0.07760387659072876, 0.033708877861499786, 0.07353482395410538, -0.013789988122880459, -0.021854756399989128, 0.04120555520057678, 0.10272344946861267, -0.0980752632021904, 0.007326936349272728, 0.12046030908823013, -0.12040034681558609, -0.025303548201918602, 0.03744473308324814, -0.15080778300762177, -0.037418413907289505, -0.1093405932188034, 0.1289738267660141, 0.2097138911485672, 0.0551951564848423, -0.05357363447546959, 0.07244088500738144, -0.10457883030176163, -0.06711405515670776, -0.011194674298167229, 0.035006940364837646, 0.027913179248571396, -0.037486862391233444, 0.047938331961631775, -0.09729116410017014, 0.20715296268463135, -0.028897106647491455, 0.08094485104084015, -0.027760230004787445, 0.03406292200088501, -0.12566408514976501, -0.13306233286857605, -0.0659918338060379, 1.4465122141176462e-32, -0.0707651749253273, -0.020542480051517487, -0.006936950143426657, -0.07684190571308136, -0.0523233637213707, -0.07960749417543411, 0.052531205117702484, 0.060360636562108994, 0.030084677040576935, 0.17074444890022278, -0.06144000589847565, 0.13207361102104187, -0.0854501873254776, -0.01930929534137249, -0.08058983087539673, -0.06980657577514648, -0.0014730120310559869, 0.03618241846561432, -0.08016849309206009, -0.02502172812819481, 0.148315891623497, -0.013303120620548725, 0.10437458753585815, -0.07400855422019958, -0.028475800529122353, -0.10702119767665863, -0.1343839317560196, -0.031157908961176872, 0.008969536051154137, -0.014260073192417622, -0.12593524158000946, 0.05315398797392845, -0.002335666911676526, -0.1455141007900238, -0.13854090869426727, -0.14692570269107819, 0.08942994475364685, 0.0758618637919426, -0.0793190523982048, 0.07919448614120483, -0.10608785599470139, -0.01266075111925602, 0.08574894815683365, -0.13333730399608612, 0.01610669679939747, 0.14207808673381805, 0.21310658752918243, 0.0526854582130909, -0.08235413581132889, 0.18139289319515228, -0.0214608795940876, -0.2213590294122696, -0.05487404018640518, 0.04932594299316406, -0.10471534729003906, 0.13547368347644806, 0.025032777339220047, -0.03481840342283249, 0.016108931973576546, -0.03434021398425102, 0.0145946079865098, -0.069363534450531, 0.03361154720187187, -0.019788067787885666, -0.052965469658374786, 0.02833346277475357, 0.24175415933132172, 0.0798427164554596, -0.031320203095674515, 0.004181926138699055, -0.06951753795146942, -0.019853373989462852, -0.005014895927160978, -0.16819864511489868, 0.16944262385368347, -0.1067647859454155, 0.047942567616701126, -0.01446873415261507, -0.015873786062002182, -0.0003075104614254087, 0.16513846814632416, 0.17059674859046936, -0.017313357442617416, -0.15718300640583038, 0.07004617154598236, 0.025416821241378784, 0.050007693469524384, -0.06738034635782242, -0.10226534307003021, -0.09687194228172302, -0.18835121393203735, -0.0609997883439064, -0.052735764533281326, -0.11523056775331497, -0.0006902064778842032, -1.5578219782489164e-32, -0.08089479058980942, 0.004357629455626011, 0.06495292484760284, 0.058228496462106705, 0.15016360580921173, 0.09373462200164795, 0.08047839254140854, -0.019601311534643173, -0.01655808463692665, -0.074273020029068, -0.06540489941835403, -0.11151973903179169, 0.010438677854835987, -0.003717429470270872, -0.06332568824291229, 0.07802294194698334, -0.08475883305072784, 0.15697386860847473, -0.1600157469511032, 0.05892203003168106, -0.04693802446126938, 0.21061788499355316, -0.05243442952632904, 0.08344259113073349, -0.12920589745044708, -0.002079916186630726, -0.02464117668569088, 0.11046293377876282, 0.03889944404363632, 0.01321790087968111, -0.1468169391155243, 0.011453146114945412, -0.10820047557353973, 0.06374786049127579, 0.032737936824560165, -0.062304385006427765, 0.00785380881279707, -0.060405123978853226, -0.1324768215417862, 0.04799944907426834, 0.1351117193698883, 0.10019463300704956, -0.180587500333786, 0.05831795930862427, 0.03513861820101738, 0.0492706261575222, 0.007387748919427395, 0.022212523967027664, 0.02829999476671219, 0.07103411108255386, 0.06652141362428665, 0.030772069469094276, -0.12278513610363007, 0.03812779486179352, -0.10750921070575714, 0.09665747731924057, -0.036431897431612015, -0.07979628443717957, -0.1511191874742508, 0.01724008098244667, -0.19491708278656006, -0.00937254074960947, 0.006399882957339287, 0.0927312970161438, 0.14938224852085114, -0.016526266932487488, 0.03772039711475372, 0.003514618845656514, 0.01251150295138359, -0.041575733572244644, -0.06027492880821228, -0.15103980898857117, 0.02907451242208481, -0.15063616633415222, -0.04356798902153969, 0.13701944053173065, -0.036192044615745544, -0.08272051066160202, -0.022905152291059494, 0.11788614839315414, -0.0237030740827322, -0.05430029705166817, 0.14471808075904846, 0.209676593542099, -0.05417783558368683, 0.1438918113708496, 0.05481290444731712, -0.0044787293300032616, 0.10183854401111603, 0.04274856671690941, 0.026987187564373016, -0.058575645089149475, 0.10950160771608353, 0.24391554296016693, -0.04100749269127846, -1.0083052615073029e-07, 0.016954869031906128, 0.10878435522317886, -0.0787297934293747, -0.008116425015032291, -0.005964330863207579, -0.021462781354784966, 0.008529496379196644, -0.018672386184334755, 0.05465551093220711, 0.14349107444286346, 0.1479763686656952, -0.01794504001736641, -0.09743602573871613, 0.07677511125802994, -0.04585395008325577, 0.05062253773212433, 0.05532984063029289, 0.020391954109072685, -0.024971390143036842, 0.08567184209823608, 0.22206555306911469, -0.10943921655416489, 0.0003878610150422901, -0.010341424494981766, 0.041109781712293625, -0.2040732502937317, -0.06613745540380478, 0.10148368775844574, 0.1198725774884224, 0.04404495283961296, 0.0070799593813717365, -0.14866915345191956, -0.043446898460388184, 0.0825592428445816, 0.13783583045005798, -0.017620444297790527, 0.086585633456707, -0.07905257493257523, 0.017856115475296974, 0.19772860407829285, -0.08946491777896881, 0.034070443361997604, -0.1410604864358902, -0.07469514012336731, -0.04130138084292412, 0.058724526315927505, -0.059863440692424774, 0.058681175112724304, 0.1265101581811905, -0.011171643622219563, -0.0804695412516594, -0.07026247680187225, -0.06473056226968765, -0.033330656588077545, 0.18280187249183655, 0.06815915554761887, -0.03792571648955345, 0.08022963255643845, 0.021787136793136597, -0.0008100257255136967, 0.02109997719526291, -0.014881150797009468, -0.048927802592515945, -0.10040909796953201], metadata={'source': 'AAAMLP-569to.pdf', 'page': 123}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 124 ═════════════════════════════════════════════════════════════════════════ # lbl_xgb.py import pandas as pd import xgboost as xgb  from sklearn import metrics from sklearn import preprocessing   def run(fold):     # load the full training data with folds     df = pd.read_csv(\"../input/adult_folds.csv\")      # list of numerical columns     num_cols = [         \"fnlwgt\",         \"age\",         \"capital.gain\",         \"capital.loss\",         \"hours.per.week\"     ]      # drop numerical columns     df = df.drop(num_cols, axis=1)      # map targets to 0s and 1s     target_mapping = {         \"<=50K\": 0,         \">50K\": 1     }     df.loc[:, \"income\"] = df.income.map(target_mapping)      # all columns are features except kfold & income columns     features = [         f for f in df.columns if f not in (\"kfold\", \"income\")     ]      # fill all NaN values with NONE     # note that I am converting all columns to \"strings\"     # it doesnt matter because all are categories     for col in features:         df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")          # now its time to label encode the features     for col in features:                  # initialize LabelEncoder for each feature column'),\n",
       " VectorParams(vector=[-0.05879722163081169, -0.09652078151702881, -0.05123111605644226, 0.01965022087097168, 0.20408673584461212, -0.020387515425682068, 0.1284465491771698, 0.030079632997512817, -0.16990557312965393, -0.05289195477962494, 0.09192363172769547, -0.22802329063415527, -0.0597233772277832, -0.11536519974470139, -0.045008495450019836, 0.1531054526567459, -0.04791037365794182, -0.03862766921520233, -0.1846676915884018, -0.014677844010293484, 0.01535553764551878, 0.05881328508257866, -0.006014417391270399, 0.08016212284564972, -0.003276318311691284, 0.02067776583135128, 0.07154514640569687, 0.0826631486415863, -0.04350246489048004, -0.029044456779956818, 0.021312236785888672, 0.04570271819829941, 0.12393307685852051, 0.03615587577223778, 0.08155614882707596, 0.0033633443526923656, -0.1352549046278, -0.012622414156794548, -0.0700116902589798, 0.07594242691993713, 0.04160311818122864, -0.08975912630558014, 0.035489823669195175, 0.014963227324187756, 0.09405402839183807, 0.14122635126113892, -0.0011721225455403328, -0.06284938007593155, 0.08108934015035629, -0.05276673659682274, 0.03323863446712494, 0.04629901051521301, -0.10368707031011581, -0.05956001579761505, -0.15391072630882263, -0.11262234300374985, 0.07612160593271255, -0.1773689091205597, 0.08617813140153885, -0.02954195626080036, 0.0010069411946460605, -0.09675011038780212, 0.00048284974764101207, -0.03007492795586586, 0.018865346908569336, -0.048581529408693314, -0.18417015671730042, -0.028579406440258026, -0.1246073842048645, 0.1037553995847702, -0.07593455910682678, 0.04696500301361084, -0.10141094774007797, 0.09135864675045013, -0.09647807478904724, 0.0012503123143687844, 0.2036057561635971, -0.06709694117307663, 0.09692662209272385, -0.042797259986400604, -0.22206120193004608, -0.015287199057638645, 0.1539304107427597, -0.0005771765136159956, 0.11450106650590897, -0.21031643450260162, 0.10384507477283478, 0.037126537412405014, -0.02445400319993496, -0.06611622869968414, 0.11261983960866928, 0.03874944522976875, -0.06556882709264755, 0.07386016100645065, -0.012022098526358604, 0.06037258356809616, 0.10638787597417831, -0.08037259429693222, 0.01676887646317482, 0.08724649250507355, -0.16002656519412994, 0.009559341706335545, 0.08230970054864883, -0.09312210232019424, -0.06280741095542908, -0.099106065928936, 0.033478446304798126, 0.19689598679542542, 0.06959094107151031, -0.017006635665893555, 0.005067945923656225, -0.06678475439548492, -0.03562811017036438, 0.12195330858230591, 0.03367295861244202, 0.14521758258342743, -0.08093591034412384, 0.09594164043664932, -0.19216246902942657, 0.15454818308353424, -0.1404426544904709, 0.07871592789888382, 0.05193893238902092, -0.023912401869893074, -0.15271469950675964, -0.141722172498703, -0.07140186429023743, 1.8053593418866e-32, -0.10552994906902313, 0.00025679555255919695, -0.05159490555524826, -0.17276343703269958, -0.018454693257808685, -0.08106552064418793, -0.047614794224500656, 0.07380431145429611, 0.12105196714401245, 0.1449265331029892, -0.13271325826644897, 0.08767948299646378, -0.05241546034812927, -0.04725681245326996, -0.07914964109659195, 0.01797378808259964, -0.04230998829007149, 0.00031501619378104806, -0.09281552582979202, 0.11934328079223633, 0.205520361661911, 0.006496329791843891, 0.010625519789755344, -0.025347450748085976, -0.13470570743083954, 0.0509367473423481, -0.03994418680667877, 0.01415103580802679, -0.012663151137530804, 0.03473556786775589, -0.20890146493911743, -0.03747852146625519, 0.06372761726379395, -0.11318324506282806, -0.13309068977832794, -0.08120758831501007, 0.11364393681287766, 0.07420571148395538, -0.10225159674882889, -0.030520085245370865, -0.01190156303346157, 0.034079741686582565, 0.09063613414764404, -0.15317434072494507, 0.0054201893508434296, -0.07761136442422867, 0.04885689914226532, 0.07842673361301422, 0.006043809000402689, 0.16002623736858368, -0.024888012558221817, -0.26069074869155884, -0.019748955965042114, 0.08158740401268005, -0.08271758258342743, 0.1496005654335022, 0.05329032242298126, 0.15598802268505096, 0.0639943778514862, 0.027254050597548485, 0.04976087063550949, 0.011516931466758251, -0.010831990279257298, -0.04010223224759102, 0.05380332097411156, 0.04781116172671318, 0.16361045837402344, -0.04962941259145737, 0.01427775714546442, -0.04886139929294586, -0.14768624305725098, 0.049797698855400085, 0.0005353278829716146, -0.11897438764572144, 0.10636824369430542, -0.10178937762975693, 0.005145698320120573, 0.017416540533304214, -0.07272734493017197, 0.01728699542582035, -0.04840337485074997, 0.2514098882675171, -0.07214077562093735, -0.1386098861694336, 0.0871383547782898, 0.04540916532278061, 0.06904684752225876, -0.0366545170545578, -0.2620815634727478, 0.011531000025570393, -0.15215744078159332, -0.13779667019844055, 0.04865622520446777, -0.09399598091840744, -0.013316591270267963, -1.7314792280638315e-32, -0.013885967433452606, 0.06459085643291473, 0.10301138460636139, 0.08947569876909256, 0.09704449027776718, 0.06298864632844925, 0.09081727266311646, 0.07141019403934479, -0.045010410249233246, -0.12979523837566376, 0.028878754004836082, -0.12060615420341492, 0.12386183440685272, 0.04690733551979065, 0.03469531610608101, 0.04664801061153412, -0.12616223096847534, 0.1524469554424286, -0.12529586255550385, 0.12232611328363419, 0.011310318484902382, 0.1617201417684555, -0.10233199596405029, 0.03980884701013565, -0.1679810881614685, 0.06438035517930984, 0.04077518731355667, 0.0937928780913353, 0.0782279446721077, -0.05725705623626709, -0.1373758763074875, 0.07534198462963104, -0.11124187707901001, 0.1310916692018509, 0.01984333246946335, -0.17617036402225494, -0.05236513540148735, -0.06960532069206238, -0.13769717514514923, 0.18520039319992065, 0.11171361804008484, 0.08291713893413544, -0.30821478366851807, 0.028674084693193436, -0.08091841638088226, -0.04783277213573456, -0.022591758519411087, -0.027755288407206535, 0.03508319705724716, -0.05854243412613869, 0.023389257490634918, -0.022496487945318222, -0.10332833975553513, 0.10461700707674026, -0.13419407606124878, 0.13112878799438477, -0.10651283711194992, -0.02217533439397812, -0.1271602064371109, 0.09974312782287598, -0.09585722535848618, 0.040472790598869324, 0.0827098861336708, -0.009947044774889946, 0.0931350588798523, 0.02648302912712097, -0.11494340002536774, 0.10163852572441101, 0.08205927908420563, 0.06099274009466171, -0.038018468767404556, 0.011638638563454151, 0.007751611061394215, -0.07909811288118362, -0.03729318454861641, 0.14242687821388245, -0.020709360018372536, -0.09469231218099594, 0.058963123708963394, 0.01579730026423931, -0.09439527243375778, -0.018205801025032997, 0.12203317135572433, 0.25259122252464294, -0.01779141090810299, 0.16128511726856232, 0.13384941220283508, 0.07898805290460587, 0.07453913986682892, -0.08811651915311813, 0.05563076585531235, -0.0005880481330677867, 0.17483462393283844, 0.2518596649169922, -0.1024441197514534, -1.0064644584417692e-07, -0.06501644849777222, 0.009952071122825146, 0.05960489436984062, 0.048479676246643066, 0.03322567045688629, 0.06532245874404907, -0.07599656283855438, -0.00807475671172142, -0.11126765608787537, -0.011142083443701267, 0.1776413768529892, -0.053040511906147, -0.20593881607055664, 0.043688248842954636, -0.06372157484292984, 0.10028655081987381, 0.06948139518499374, 0.12806877493858337, 0.015946073457598686, 0.10963290929794312, 0.07341434806585312, -0.13971063494682312, 0.11673704534769058, -0.06349795311689377, 0.009926773607730865, -0.181043341755867, -0.05366760119795799, 0.11692189425230026, 0.053116846829652786, 0.04043232277035713, 0.018363861367106438, -0.154713973402977, 0.0019170392770320177, 0.1350788027048111, 0.047400522977113724, 0.05041251704096794, 0.07291331887245178, -0.18488073348999023, 0.09650631248950958, 0.1901525855064392, -0.024774905294179916, 0.04928251728415489, -0.21980908513069153, -0.06282761693000793, 0.06712023168802261, 0.09799355268478394, 0.060163699090480804, -0.036525748670101166, 0.08316051214933395, -0.04070495441555977, -0.1623612493276596, -0.09240786731243134, -0.1428389549255371, -0.0015201930655166507, 0.08909107744693756, 0.043280743062496185, -0.1046517938375473, 0.06705610454082489, -0.039267610758543015, 0.08719184249639511, -0.06397660076618195, -0.11932755261659622, -0.03328319638967514, -0.04071534052491188], metadata={'source': 'AAAMLP-569to.pdf', 'page': 124}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 125         lbl = preprocessing.LabelEncoder()                  # fit label encoder on all data         lbl.fit(df[col])          # transform all the data         df.loc[:, col] = lbl.transform(df[col])      # get training data using folds     df_train = df[df.kfold != fold].reset_index(drop=True)      # get validation data using folds     df_valid = df[df.kfold == fold].reset_index(drop=True)      # get training data     x_train = df_train[features].values      # get validation data     x_valid = df_valid[features].values      # initialize xgboost model     model = xgb.XGBClassifier(         n_jobs=-1     )      # fit model on training data (ohe)     model.fit(x_train, df_train.income.values)      # predict on validation data     # we need the probability values as we are calculating AUC     # we will use the probability of 1s     valid_preds = model.predict_proba(x_valid)[:, 1]      # get roc auc score     auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)      # print auc     print(f\"Fold = {fold}, AUC = {auc}\")   if __name__ == \"__main__\":     for fold_ in range(5):         run(fold_) ═════════════════════════════════════════════════════════════════════════  Let’s run this!'),\n",
       " VectorParams(vector=[-0.06573368608951569, -0.15152662992477417, -0.05172925442457199, 0.0503108873963356, 0.08731571584939957, -0.07503621280193329, -0.030813099816441536, 0.039196498692035675, -0.14433549344539642, -0.0852796733379364, -0.059484053403139114, -0.15555834770202637, 0.021717341616749763, -0.0735694020986557, -0.0022496331948786974, 0.08563239872455597, 0.015335378237068653, -0.02272634766995907, -0.18498595058918, 0.022358499467372894, 0.04936077445745468, -0.01316505204886198, -0.0038407566025853157, 0.04094642773270607, -0.013866188004612923, -0.0970410406589508, -0.04512383043766022, -0.029920058324933052, -0.1108519583940506, -0.017903784289956093, 0.041139867156744, 0.09662236273288727, -0.0020815888419747353, -0.019358988851308823, 0.020952407270669937, 0.06322073191404343, 0.018717780709266663, -0.03723564371466637, -0.17425934970378876, -0.03348346799612045, 0.03666096553206444, -0.013404864817857742, -0.021949509158730507, -0.007053607143461704, 0.06359462440013885, 0.06389287859201431, -0.01015184074640274, -0.06970109790563583, 0.02801990695297718, -0.09066520631313324, -0.013196602463722229, 0.12061545997858047, -0.1366887241601944, 0.0701974630355835, -0.05868122726678848, -0.1330012083053589, 0.05246167629957199, -0.0875529944896698, 0.08003024011850357, -0.020213907584547997, -0.08455207198858261, 0.058749668300151825, 0.02436998300254345, -0.08413876593112946, 0.03685552999377251, -0.07259417325258255, -0.08618283271789551, -0.10438314825296402, -0.03766119107604027, 0.1705998331308365, -0.016595663502812386, 0.010936889797449112, -0.08004621416330338, 0.023474838584661484, 0.014413366094231606, -0.03892887756228447, 0.13044218719005585, -0.06157929077744484, 0.04844257980585098, -0.12392278760671616, -0.07455523312091827, -0.05681634321808815, 0.023657245561480522, -0.048578958958387375, 0.021573716774582863, -0.2025708705186844, -0.0281326025724411, -0.032878268510103226, -0.05378140136599541, 0.009705742821097374, 0.1539960503578186, 0.007698562927544117, -0.0482688769698143, 0.10842610150575638, 0.07550861686468124, 0.04319089278578758, 0.13334417343139648, -0.054796647280454636, -0.006311530712991953, 0.08590080589056015, -0.08345482498407364, 0.08534859865903854, 0.08893751353025436, 0.04216783493757248, 0.047201357781887054, -0.05996652692556381, 0.11764415353536606, 0.11251024901866913, 0.06666279584169388, -0.023562632501125336, 0.1063869521021843, -0.08181314170360565, 0.00047794473357498646, 0.07784752547740936, 0.071153424680233, 0.1074371263384819, -0.006286452990025282, 0.07303965836763382, -0.17286615073680878, 0.15537594258785248, -0.09581232070922852, -0.006947683170437813, 0.07961425185203552, 0.04418205842375755, 0.019633347168564796, 0.008610236458480358, -0.1407252550125122, 1.968212035375932e-32, -0.12045472860336304, -0.002895739860832691, 0.05469741299748421, -0.16199132800102234, -0.07302597910165787, 0.0073068770579993725, 0.03700271248817444, 0.046144407242536545, 0.07215066999197006, 0.12173310667276382, -0.20505432784557343, 0.05665815994143486, -0.07120714336633682, -0.07862388342618942, 0.011238046921789646, 0.007220015395432711, -0.0569181889295578, 0.09876981377601624, -0.08578666299581528, 0.06881660968065262, 0.20164817571640015, 0.022456999868154526, 0.06203639134764671, -0.08390288800001144, -0.0679243803024292, 0.030400924384593964, 0.00027361931279301643, -0.02480946108698845, -0.0692729651927948, 0.0362437479197979, -0.13707391917705536, -0.020640894770622253, 0.0034117524046450853, 0.004854095634073019, -0.08786739408969879, -0.07271262258291245, 0.10015776753425598, 0.019336000084877014, -0.02759561501443386, 0.03197057545185089, -0.02172181010246277, -0.029996782541275024, 0.09161768853664398, -0.07966066896915436, -0.06920432299375534, -0.02116215042769909, 0.08451969921588898, 0.08292211592197418, -0.09421717375516891, 0.11687891185283661, -0.029167164117097855, -0.07693728804588318, -0.02333260513842106, -0.009692884981632233, -0.009292731061577797, 0.0006577963940799236, 0.097784623503685, -0.011068382300436497, 0.023885171860456467, -0.004763413220643997, 0.05245296284556389, -0.04506310448050499, 0.013634350150823593, -0.06732222437858582, 0.07483316957950592, 0.028956418856978416, 0.1841394454240799, 0.022438740357756615, -0.05983961746096611, -0.0415521040558815, -0.16319744288921356, 0.02473847195506096, 0.023898616433143616, -0.074677474796772, 0.07789450138807297, -0.1332445740699768, 0.09417606890201569, -0.0036609203089028597, 0.04710926488041878, -0.050177786499261856, 0.09345388412475586, 0.20321625471115112, 0.0567142516374588, -0.15482209622859955, -0.04563271999359131, -0.018286868929862976, -0.004756137728691101, 0.005186106543987989, -0.1815713793039322, -0.03880705684423447, -0.11181391775608063, -0.10003801435232162, -0.05744996666908264, -0.09869226068258286, -0.0625283271074295, -1.6893577389908165e-32, 0.006672798190265894, -0.022811220958828926, -0.011288073845207691, 0.1402730941772461, 0.08596685528755188, 0.009877867065370083, 0.02241676300764084, 0.004731583874672651, -0.07325667887926102, -0.15427789092063904, 0.07457549124956131, -0.08685625344514847, 0.05849123001098633, 0.06119629368185997, 0.0751311182975769, 0.045530688017606735, -0.08038352429866791, 0.16201312839984894, -0.04501806199550629, -0.02396831102669239, -0.08692527562379837, 0.09576227515935898, -0.05888389050960541, -0.0023979265242815018, -0.14272622764110565, 0.010162080638110638, -0.05106062442064285, 0.03473109006881714, 0.10379043221473694, -0.0006659759674221277, -0.05843060836195946, 0.07553435117006302, -0.13635507225990295, 0.08904114365577698, 0.025853443890810013, -0.11252618581056595, -0.04766188934445381, -0.01264730654656887, -0.025947220623493195, 0.12085797637701035, 0.10678451508283615, 0.1466691941022873, -0.18033476173877716, -0.009182741865515709, 0.014726981520652771, 0.05721250921487808, -0.09567206352949142, -0.03251742199063301, 0.045006487518548965, 0.02511286549270153, 0.03534703329205513, -0.014867017976939678, -0.08246144652366638, 0.055281076580286026, -0.10377957671880722, 0.15094619989395142, -0.07324927300214767, 0.027090828865766525, -0.01883489266037941, -0.011602786369621754, -0.07139906287193298, 0.05938323214650154, -0.0245943833142519, -0.03302530199289322, 0.054032985121011734, 0.10265938192605972, -0.0017183625604957342, 0.02504519373178482, 0.05791771411895752, 0.03171680495142937, -0.0686325803399086, -0.08671839535236359, 0.06027534231543541, -0.0633644238114357, -0.051639147102832794, 0.13819988071918488, 0.006745781283825636, -0.0191861130297184, 0.01943257823586464, -0.06118611618876457, -0.01590871438384056, 0.03565441444516182, 0.1798412799835205, 0.11609701812267303, -0.03169463947415352, 0.09658751636743546, 0.08192133158445358, 0.16624145209789276, 0.08377689868211746, -0.05944082885980606, 0.03423084318637848, 0.005582021549344063, 0.10959944128990173, 0.05153992772102356, 0.0065785301849246025, -1.0073038225755226e-07, -0.062363434582948685, 0.100222148001194, -0.028217392042279243, 0.038978204131126404, 0.01962943933904171, 0.05401189625263214, -0.11717215925455093, 0.07006187736988068, -0.016299022361636162, 0.057278916239738464, 0.09332773089408875, -0.06816127151250839, -0.05798192322254181, 0.041036222130060196, -0.04236823320388794, 0.044114720076322556, 0.06607063859701157, 0.029326824471354485, -0.03622661903500557, 0.044241346418857574, 0.004841733258217573, -0.004124654456973076, 0.05072366073727608, -0.04530138522386551, 0.043565940111875534, -0.13565987348556519, -0.08024922758340836, 0.07815036177635193, 0.018598511815071106, -0.01490548625588417, 0.01540986355394125, -0.09096422046422958, 0.009864041581749916, 0.08364906162023544, 0.06176379323005676, 0.07996056973934174, 0.04426692798733711, -0.01743323914706707, 0.015154698863625526, 0.047375015914440155, -0.09991481900215149, 0.015007277019321918, -0.13322116434574127, -0.040231652557849884, 0.14323382079601288, -0.00931077916175127, -0.006278159096837044, 0.020068734884262085, 0.038900427520275116, 0.07005440443754196, 0.021455738693475723, -0.01943756453692913, -0.029990123584866524, -0.06407798826694489, 0.1570073664188385, 0.05123993381857872, -0.12313739955425262, 0.04060128703713417, 0.007072311360388994, 0.0969112440943718, -0.0389239676296711, -0.13314194977283478, -0.03726249560713768, -0.01513461209833622], metadata={'source': 'AAAMLP-569to.pdf', 'page': 125}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 126 ═════════════════════════════════════════════════════════════════════════ ❯ python lbl_xgb.py Fold = 0, AUC = 0.8800810634234078 Fold = 1, AUC = 0.886811884948154 Fold = 2, AUC = 0.8854421433318472 Fold = 3, AUC = 0.8676319549361007 Fold = 4, AUC = 0.8714450054900602 ═════════════════════════════════════════════════════════════════════════  This seems quite good already. Let’s see the scores when we increase max_depth to 7 and n_estimators to 200.  ═════════════════════════════════════════════════════════════════════════ ❯ python lbl_xgb.py Fold = 0, AUC = 0.8764108944332032 Fold = 1, AUC = 0.8840708537662638 Fold = 2, AUC = 0.8816601162613102 Fold = 3, AUC = 0.8662335762581732 Fold = 4, AUC = 0.8698983461709926 ═════════════════════════════════════════════════════════════════════════  It looks like it doesn’t improve.   This shows that parameters from one dataset are not transferrable to another dataset. We must try tuning the parameters again, but we will do it in more details in next chapters.  Now, let’s try to include numerical features in the xgboost model without parameter tuning.  ═════════════════════════════════════════════════════════════════════════ # lbl_xgb_num.py import pandas as pd import xgboost as xgb  from sklearn import metrics from sklearn import preprocessing   def run(fold):     # load the full training data with folds     df = pd.read_csv(\"../input/adult_folds.csv\")      # list of numerical columns'),\n",
       " VectorParams(vector=[0.059396982192993164, 0.0029967017471790314, -0.05348712205886841, -0.020744074136018753, 0.11951514333486557, -0.01876249350607395, 0.007183329667896032, -0.05260930955410004, -0.1674293428659439, -0.021221062168478966, 0.09680818021297455, -0.16220827400684357, -0.07307332754135132, -0.13034525513648987, -0.025465739890933037, 0.11471615731716156, -0.1275736391544342, 0.12693090736865997, -0.10945814847946167, -0.06798547506332397, -0.05733906105160713, 0.13487780094146729, -0.023345163092017174, 0.07750098407268524, -0.04473157972097397, 0.03749125450849533, 0.055881317704916, 0.11057595163583755, -0.11597617715597153, -0.056213706731796265, -0.003729540854692459, 0.12289229035377502, 0.013480711728334427, -0.023088503628969193, 0.0803060457110405, 0.04126755893230438, -0.10521066188812256, 0.14769981801509857, 0.0018084507901221514, 0.08942175656557083, -0.08932235091924667, -0.12490904331207275, 0.13671106100082397, -0.026374077424407005, 0.03826790675520897, 0.05978066101670265, -0.05230862274765968, -0.05700294300913811, 0.10006631165742874, 0.019847339019179344, -0.029358316212892532, 0.08377554267644882, -0.12234079837799072, 0.008125277236104012, -0.12745730578899384, -0.12208864092826843, -0.03251432254910469, -0.09294316917657852, 0.03557329252362251, 0.012057173997163773, -0.12239326536655426, -0.06481640785932541, 0.10800540447235107, -0.08653498440980911, 0.06127212941646576, -0.012057419866323471, -0.1099356859922409, -0.004675448872148991, -0.19205448031425476, 0.10313131660223007, -0.029522951692342758, 0.03273772820830345, -0.10046003013849258, 0.06504763662815094, -0.05233364179730415, 0.0013474675361067057, 0.1511813998222351, -0.02097095549106598, 0.2156442403793335, 0.02376197651028633, -0.1806342750787735, 0.015434115193784237, -0.019311681389808655, 0.003317151451483369, -0.010955844074487686, -0.1575142741203308, 0.01775743067264557, 0.013860125094652176, 0.015339936129748821, 0.0016211968613788486, 0.05789739266037941, 0.005516898352652788, 0.08316747099161148, -0.0019557795021682978, -0.03815120458602905, 0.04597986117005348, -0.016705773770809174, 0.012671351432800293, -0.023210033774375916, 0.1519666314125061, -0.1343279629945755, -0.005425194278359413, -0.025156239047646523, -0.1585279405117035, -0.0869307890534401, -0.0152190076187253, 0.208622008562088, 0.11414644867181778, 0.06464170664548874, -0.07735338062047958, 0.03755967319011688, -0.043901193886995316, -0.05484388396143913, -0.029948599636554718, 0.03681352362036705, 0.019504407420754433, -0.03691856190562248, 0.009279361926019192, -0.08928678184747696, 0.18470105528831482, -0.10875500738620758, 0.0861426517367363, 0.009511938318610191, 0.02033344656229019, -0.12545327842235565, -0.09174623340368271, -0.047431811690330505, 1.5340974165766518e-32, -0.10083997994661331, 0.04532875493168831, -0.011728872545063496, -0.060557566583156586, -0.07612248510122299, -0.0953679159283638, 0.020813174545764923, 0.018459906801581383, 0.030519817024469376, 0.057342298328876495, -0.09880948811769485, 0.09863371402025223, -0.0838436484336853, -0.02624380774796009, -0.057631321251392365, -0.08990778028964996, 0.10119619965553284, 0.0005285897059366107, -0.04087435081601143, -0.014233431778848171, 0.235907644033432, -0.0687989667057991, 0.03403564542531967, -0.10344064235687256, 0.03125161677598953, -0.13453996181488037, -0.1361919790506363, 0.03619987890124321, -0.03432738035917282, -0.028580404818058014, -0.17556102573871613, -0.0003396701067686081, 0.04005018621683121, -0.10842964798212051, 0.023531699553132057, -0.14239272475242615, 0.0863373801112175, 0.1061929315328598, -0.005782704334706068, 0.05173368379473686, -0.10604904592037201, -0.011487388983368874, 0.04895264282822609, -0.09305762499570847, -0.008583371527493, 0.1017514169216156, 0.1690925508737564, 0.03872299566864967, -0.06930416077375412, 0.1378255933523178, -0.0027603895869106054, -0.18226788938045502, -0.018401775509119034, 0.02467411942780018, -0.1686183661222458, 0.154524564743042, 0.002063435735180974, -0.05697423592209816, 0.01421968825161457, 0.05157154053449631, -0.04048197716474533, -0.07405634224414825, 0.0015969577943906188, 0.04006994888186455, -0.052758507430553436, 0.014796636067330837, 0.1539817452430725, 0.030181080102920532, 0.07389964163303375, -0.0425652340054512, -0.009841976687312126, -0.055646032094955444, 0.009473033249378204, -0.12692289054393768, 0.10949559509754181, -0.11807166785001755, 0.052955202758312225, -0.0581604428589344, -0.10643015056848526, -0.035276416689157486, 0.0996122732758522, 0.15455015003681183, -0.11142927408218384, -0.1294720619916916, 0.11751449853181839, -0.0003087771183345467, 0.04340183734893799, -0.14281360805034637, -0.08063773065805435, -0.04171694442629814, -0.18254317343235016, -0.0568729005753994, 0.014841441996395588, -0.14259500801563263, 0.05073181167244911, -1.6338592711422377e-32, -0.021564297378063202, 0.03635716438293457, 0.04388786107301712, 0.030235283076763153, 0.11795856058597565, 0.10454687476158142, 0.07264504581689835, 0.003484973218291998, 0.03286101296544075, -0.060528241097927094, 0.007028033956885338, -0.12419955432415009, 0.007967852056026459, -0.08391117304563522, -0.09217455983161926, 0.0979350209236145, -0.11033891141414642, 0.16615928709506989, -0.07649355381727219, 0.0709981918334961, -0.06497149169445038, 0.2639327347278595, -0.12528784573078156, 0.07751794159412384, -0.09194044023752213, 0.04083581268787384, -0.019899914041161537, 0.13732504844665527, 0.03918781131505966, 0.030094655230641365, -0.153948575258255, -0.004711275454610586, -0.08276070654392242, 0.07345081120729446, 0.007061739917844534, -0.026531098410487175, 0.1041446179151535, -0.11220017075538635, -0.16149689257144928, 0.052263498306274414, 0.10997285693883896, 0.12321547418832779, -0.1843087524175644, 0.05077885463833809, -0.050985291600227356, 0.06476956605911255, 0.053449008613824844, 0.026902418583631516, 0.03152097389101982, -0.010575494728982449, 0.07607662677764893, -0.014990119263529778, -0.0755598172545433, 0.030154690146446228, -0.06026219204068184, 0.11706298589706421, -0.0074768513441085815, -0.06888624280691147, -0.16548337042331696, 0.04646860808134079, -0.15302835404872894, 0.001981219043955207, 0.018502511084079742, 0.024514824151992798, 0.15493613481521606, -0.03591201826930046, -0.06483564525842667, 0.029339130967855453, -0.0016600919188931584, -0.020210349932312965, -0.10465798527002335, -0.09343352168798447, 0.05195045843720436, -0.0719795972108841, -0.04222613573074341, 0.0599743127822876, -0.005594839807599783, -0.04805469885468483, -0.026990165933966637, 0.13394509255886078, -0.01871105469763279, -0.06957848370075226, 0.06130918487906456, 0.2182254195213318, -0.04589183256030083, 0.12625789642333984, 0.068897545337677, -0.051803138107061386, 0.04061354696750641, -0.051797594875097275, 0.04022878408432007, -0.08078978955745697, 0.09181191772222519, 0.2805895507335663, -0.062239114195108414, -1.008272576541458e-07, 0.046707697212696075, 0.05015143007040024, -0.10405778884887695, -0.03350039944052696, -0.01377367228269577, -0.05591356381773949, 0.04353942349553108, -0.004647415596991777, 0.005538969300687313, 0.09728474915027618, 0.19089201092720032, 0.04987454041838646, -0.12354287505149841, 0.05269606411457062, -0.015296753495931625, 0.07399367541074753, -0.004159593489021063, 0.035951465368270874, 0.009433499537408352, 0.0877368301153183, 0.2124364972114563, -0.11358615756034851, -0.022392982617020607, -0.025153834372758865, 0.062229301780462265, -0.20569434762001038, -0.04084952548146248, 0.12189654260873795, 0.13440382480621338, 0.0930345356464386, 0.014820672571659088, -0.16454830765724182, -0.0027951367665082216, 0.008473902940750122, 0.11515817791223526, -0.02687283605337143, 0.09990979731082916, -0.09197905659675598, -0.006803132127970457, 0.20741847157478333, -0.051964860409498215, 0.16871514916419983, -0.13946467638015747, -0.08762630075216293, -0.08045836538076401, 0.02134469896554947, 0.027062250301241875, 0.060873378068208694, 0.1655694842338562, -0.04399174451828003, -0.08500691503286362, 0.022003328427672386, -0.09384600818157196, 0.03476167842745781, 0.16384954750537872, 0.019719354808330536, -0.04233632609248161, 0.061018314212560654, -0.02609400451183319, -0.03014778345823288, 0.0545145682990551, 0.011052592657506466, 0.009607058949768543, -0.12819595634937286], metadata={'source': 'AAAMLP-569to.pdf', 'page': 126}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 127     num_cols = [         \"fnlwgt\",         \"age\",         \"capital.gain\",         \"capital.loss\",         \"hours.per.week\"     ]      # map targets to 0s and 1s     target_mapping = {         \"<=50K\": 0,         \">50K\": 1     }     df.loc[:, \"income\"] = df.income.map(target_mapping)      # all columns are features except kfold & income columns     features = [         f for f in df.columns if f not in (\"kfold\", \"income\")     ]      # fill all NaN values with NONE     # note that I am converting all columns to \"strings\"     # it doesnt matter because all are categories     for col in features:         # do not encode the numerical columns         if col not in num_cols:             df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")          # now its time to label encode the features     for col in features:         if col not in num_cols:                     # initialize LabelEncoder for each feature column             lbl = preprocessing.LabelEncoder()                          # fit label encoder on all data             lbl.fit(df[col])              # transform all the data             df.loc[:, col] = lbl.transform(df[col])      # get training data using folds     df_train = df[df.kfold != fold].reset_index(drop=True)      # get validation data using folds     df_valid = df[df.kfold == fold].reset_index(drop=True)      # get training data'),\n",
       " VectorParams(vector=[-0.05033000186085701, -0.04978672042489052, -0.06596290320158005, 0.06925688683986664, 0.19786743819713593, -0.1203858032822609, -0.024851031601428986, 0.0538603737950325, -0.16099609434604645, 0.04140480235219002, 0.013196662999689579, -0.18378956615924835, -0.0523298978805542, 0.0037841368466615677, -0.029775990173220634, 0.08886389434337616, -0.08689343929290771, 0.06288696080446243, -0.1348159909248352, 0.027035458013415337, 0.12521839141845703, 0.1236300840973854, -0.100613534450531, 0.16278359293937683, -0.0037976065650582314, -0.08292990922927856, 0.06445653736591339, 0.06378184258937836, -0.13062046468257904, -0.012645119801163673, 0.00777181051671505, -0.04085434973239899, 0.1644672155380249, 0.08557646721601486, -0.052086763083934784, 0.006003829650580883, -0.06770075112581253, -0.07076521962881088, -0.10670678317546844, -0.018276814371347427, 0.045426145195961, -0.011570274829864502, -0.015546046197414398, 0.009152780286967754, 0.09332330524921417, 0.06963907182216644, -0.0069176857359707355, -0.08168885111808777, 0.06211882829666138, -0.055591318756341934, 0.04878562316298485, 0.09285841882228851, -0.11431416124105453, -0.06577470898628235, -0.11169227957725525, -0.07199365645647049, 0.06082451343536377, -0.21884626150131226, 0.06825944781303406, -0.09906743466854095, -0.06876972317695618, -0.0023722918704152107, -0.05713162198662758, -0.02630453370511532, 0.03216269239783287, 0.0035206296015530825, -0.20538565516471863, -0.04295150563120842, -0.023252395913004875, 0.10338909178972244, -0.04385175555944443, -0.06764506548643112, -0.10216863453388214, -0.005050268955528736, -0.02002493292093277, 0.09139443933963776, 0.20015710592269897, 0.010610366240143776, -0.028235189616680145, -0.006124927196651697, -0.18121738731861115, 0.09444167464971542, 0.12527601420879364, -0.08319088816642761, 0.12939876317977905, -0.04867032915353775, 0.052989400923252106, 0.12025979906320572, -0.027919411659240723, -0.055003128945827484, 0.07148047536611557, 0.019607627764344215, -0.029857760295271873, 0.009763974696397781, 0.01145696546882391, 0.02849729359149933, 0.14937303960323334, -0.10211200267076492, 0.009268461726605892, 0.05194540321826935, -0.09378709644079208, 0.07820159196853638, 0.08134809881448746, -0.1165660098195076, 0.02801000513136387, 0.04580691456794739, 0.058748167008161545, 0.10325616598129272, 0.08274916559457779, -0.002661402802914381, -0.0016227724263444543, -0.03754747286438942, -0.152054101228714, 0.06734525412321091, 0.05833456665277481, 0.1395505964756012, -0.105099618434906, -0.001838190364651382, -0.10941280424594879, 0.11359653621912003, -0.04688753932714462, 0.040076423436403275, 0.06491947919130325, 0.08063293993473053, 0.10700275748968124, -0.1476152390241623, -0.08806312084197998, 9.974936493810841e-33, -0.15453234314918518, 0.006921370979398489, -0.061608877032995224, -0.09377554804086685, -0.0012262744130566716, 0.037151552736759186, -0.008307992480695248, 0.05610189959406853, 0.08053682744503021, 0.12608076632022858, -0.11100359261035919, 0.15526315569877625, -0.07399117946624756, -0.040008291602134705, 0.025020752102136612, 0.127454474568367, -0.038289397954940796, -0.04704379290342331, -0.05866004154086113, 0.08157828450202942, 0.1631717085838318, 0.03103639744222164, 0.0038972992915660143, -0.012350931763648987, -0.05259332433342934, 0.02959667704999447, -0.05331530421972275, -0.012134191580116749, -0.014169278554618359, 0.0378134548664093, -0.13883601129055023, -0.01441607903689146, 0.0661391019821167, -0.10040675103664398, -0.09419010579586029, 0.014162126928567886, 0.016311530023813248, -0.013559925369918346, -0.07121706008911133, -0.03347136080265045, -0.02480696700513363, 0.03414043411612511, 0.08644504845142365, -0.0699327364563942, -0.00870983675122261, -0.017141705378890038, 0.029025092720985413, 0.16928309202194214, -0.05240527167916298, 0.15009470283985138, 0.03333178162574768, -0.11079663783311844, -0.032920315861701965, 0.024445896968245506, -0.12358340620994568, 0.0932781845331192, 0.07853377610445023, 0.03327614814043045, 0.01615513302385807, 0.06308840215206146, 0.08236713707447052, -0.1468273550271988, -0.017885936424136162, -0.04527587071061134, 0.00429614819586277, 0.06037534028291702, 0.11296021938323975, 0.0038825038354843855, 0.003860660595819354, -0.037968676537275314, -0.14381249248981476, 0.038744859397411346, 0.027801023796200752, -0.04177508503198624, -0.05109146609902382, -0.027039822190999985, 0.1040508970618248, -0.09206613898277283, -0.11466636508703232, 0.05117535591125488, 0.0019622633699327707, 0.27765920758247375, -0.0330817811191082, -0.07564836740493774, 0.05133799836039543, -0.055219877511262894, 0.05073998123407364, 0.017417749390006065, -0.26363009214401245, -0.018129946663975716, -0.11066073924303055, -0.044445861130952835, 0.04460202530026436, -0.006929174531251192, -0.03799723833799362, -1.1264488326809446e-32, -0.023887159302830696, -0.034476179629564285, 0.0479702465236187, 0.06571878492832184, 0.02934848889708519, -0.005176311358809471, 0.029274702072143555, -0.054091617465019226, -0.11785070598125458, -0.19768491387367249, 0.13001877069473267, -0.06260908395051956, 0.1120971217751503, 0.056128278374671936, 0.0814669132232666, 0.011587779968976974, -0.18116824328899384, 0.20863895118236542, -0.04409416764974594, 0.13769476115703583, 0.0367753766477108, 0.23683950304985046, -0.12924568355083466, 0.019450925290584564, -0.05870392918586731, -0.02002868987619877, -0.023148054257035255, 0.09293949604034424, 5.036822403781116e-05, -0.025393418967723846, -0.10373201221227646, 0.16058595478534698, -0.08451641350984573, -0.032603707164525986, -0.0016569398576393723, -0.06205938383936882, -0.12267161160707474, -0.05324967950582504, -0.022866515442728996, 0.19823284447193146, 0.07084821164608002, 0.14363735914230347, -0.3300110399723053, -0.035849861800670624, -0.05576927214860916, 0.02546151541173458, 0.002140188589692116, -0.03371341526508331, 0.045624684542417526, -0.03341345861554146, 0.09328209608793259, -0.06588491797447205, -0.030348040163517, 0.08556661754846573, -0.12930887937545776, 0.1756061464548111, -0.06755650043487549, 0.0180905032902956, -0.015076021663844585, 0.0030936349648982286, -0.07942112535238266, 0.060210373252630234, 0.07323342561721802, -0.01897779107093811, -0.0366915725171566, -0.08373170346021652, -0.05170663818717003, 0.0023576864041388035, 0.022642245516180992, 0.014011925086379051, -0.08159971982240677, -0.027144355699419975, 0.02513481304049492, 0.05831903964281082, -0.08841562271118164, 0.042685139924287796, 0.0047025782987475395, -0.08165443688631058, -0.03204267844557762, 0.04244115948677063, -0.0790851041674614, 0.00687584700062871, 0.12397518754005432, 0.18405629694461823, -0.006753067020326853, 0.05366513133049011, 0.11567915230989456, 0.09328603744506836, 0.08783383667469025, -0.08604706823825836, -0.010268456302583218, 0.08069215714931488, 0.09038230776786804, 0.20717892050743103, -0.05261906981468201, -9.958235835938467e-08, -0.11222219467163086, 0.06326737999916077, 0.013857024721801281, 0.059500597417354584, -0.008355769328773022, 0.014650235883891582, -0.026507021859288216, -0.019095467403531075, -0.07845564931631088, 0.05027025565505028, 0.09150204807519913, -0.04633503779768944, -0.2699783742427826, -0.01673649065196514, -0.029850086197257042, 0.18104015290737152, 0.057665884494781494, 0.07777637988328934, 0.010287277400493622, 0.10259617865085602, 0.0956449806690216, -0.060476336628198624, -0.009764482267200947, -0.01971789263188839, -0.008588368073105812, -0.2250465452671051, -0.012278199195861816, 0.18480099737644196, -0.018350299447774887, 0.06334755569696426, 0.004491652827709913, -0.0659552738070488, 0.06200169771909714, 0.07064168900251389, -0.007342105265706778, 0.10604607313871384, 0.13379406929016113, -0.10011852532625198, -0.019911788403987885, 0.11092089116573334, 0.05197475105524063, 0.05312509834766388, -0.13164395093917847, -0.1286274492740631, 0.02518206462264061, 0.07698408514261246, 0.04863942414522171, 0.08047065883874893, 0.07492485642433167, 0.008527717553079128, -0.03386305645108223, -0.027165010571479797, -0.12992370128631592, -0.07578133791685104, 0.05276492238044739, -0.012724834494292736, -0.09500778466463089, -0.02007334493100643, -0.01492401771247387, 0.03694353252649307, 0.0057079303078353405, -0.18256516754627228, 0.06653181463479996, -0.0660390853881836], metadata={'source': 'AAAMLP-569to.pdf', 'page': 127}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 128     x_train = df_train[features].values      # get validation data     x_valid = df_valid[features].values      # initialize xgboost model     model = xgb.XGBClassifier(         n_jobs=-1     )      # fit model on training data (ohe)     model.fit(x_train, df_train.income.values)      # predict on validation data     # we need the probability values as we are calculating AUC     # we will use the probability of 1s     valid_preds = model.predict_proba(x_valid)[:, 1]      # get roc auc score     auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)      # print auc     print(f\"Fold = {fold}, AUC = {auc}\")   if __name__ == \"__main__\":     for fold_ in range(5):         run(fold_)  ═════════════════════════════════════════════════════════════════════════  So, we keep the numerical columns; we just do not label encode it. So, our final feature matrix consists of numerical columns (as it is) and encoded categorical columns. Any tree-based algorithm can handle this mix easily.  Please note that we do not need to normalize data when we use tree-based models. This is, however, a vital thing to do and cannot be missed when we are using linear models such as logistic regression.  Let’s run this script now!  ═════════════════════════════════════════════════════════════════════════ ❯ python lbl_xgb_num.py Fold = 0, AUC = 0.9209790185449889 Fold = 1, AUC = 0.9247157449144706'),\n",
       " VectorParams(vector=[0.014096206985414028, -0.11303674429655075, -0.03366102650761604, -0.003772868076339364, 0.09679042547941208, -0.02115393429994583, -0.007695285603404045, -0.04756336659193039, -0.19325751066207886, 0.0036196396686136723, 0.05066904053092003, -0.16519257426261902, -0.09112294018268585, -0.10400666296482086, 0.06608512997627258, 0.1736295074224472, -0.11052645742893219, -0.014756225049495697, -0.12416864186525345, -0.07522416114807129, 0.030225658789277077, 0.0227744672447443, -0.06276026368141174, 0.0333716906607151, -0.015809349715709686, 0.07165326178073883, 0.023568101227283478, 0.05967775732278824, -0.11016237735748291, -0.030804168432950974, 0.06617578864097595, 0.09835885465145111, 0.017442846670746803, 0.022498128935694695, -0.00936779286712408, 0.06693025678396225, -0.10478783398866653, 0.027492715045809746, -0.0656205490231514, 0.06909401714801788, 0.006683414801955223, -0.10968495905399323, 0.14099282026290894, 0.06112741678953171, 0.10836932063102722, 0.0441499687731266, -0.032349660992622375, -0.022578967735171318, 0.05657529458403587, -0.13765637576580048, 0.033587243407964706, 0.14347811043262482, -0.1447736918926239, -0.03344478830695152, -0.06703966110944748, -0.191838800907135, 0.04372004047036171, -0.07882826775312424, 0.02887829765677452, -0.05179717019200325, -0.051915768533945084, -0.07762521505355835, 0.0139858927577734, -0.06037607789039612, 0.023258769884705544, -0.07163893431425095, -0.1185498908162117, 0.007372849155217409, -0.028064794838428497, 0.10865951329469681, -0.03099910169839859, 0.03623580560088158, -0.10809485614299774, 0.019519828259944916, 0.03784627839922905, 0.06797286123037338, 0.23728781938552856, -0.058515213429927826, 0.07701396197080612, 0.01744624599814415, -0.1576973795890808, 0.014649483375251293, 0.06383738666772842, 0.02097601816058159, 0.010934592224657536, -0.17914533615112305, 0.07199635356664658, -0.02388586290180683, -0.008442466147243977, 0.04853628948330879, 0.017599161714315414, -0.013266394846141338, 0.011038496159017086, -0.07970807701349258, -0.014356500469148159, 0.0822189450263977, 0.14103935658931732, -0.10863952338695526, -0.002975480630993843, 0.13844461739063263, -0.03950013220310211, 0.04817837104201317, -0.03278122842311859, -0.06875257939100266, -0.01165550947189331, -0.048354413360357285, 0.08318153768777847, 0.07500392943620682, 0.11510033160448074, -0.10366380214691162, 0.033344823867082596, -0.1352708786725998, -0.019146474078297615, -0.009666748344898224, 0.0693543329834938, 0.06257150322198868, -0.08428788185119629, 0.0362795852124691, 0.07304754853248596, 0.08989942818880081, 0.03202107176184654, 0.053398605436086655, 0.08749472349882126, -0.002020094310864806, -0.016073986887931824, -0.11328445374965668, -0.09207187592983246, 1.360370959531832e-32, -0.1514279544353485, -0.009151633828878403, 0.02044747769832611, -0.011475268751382828, 0.027950095012784004, -0.055426210165023804, 0.0023084860295057297, 0.04783715307712555, -0.025341235101222992, 0.1859506219625473, -0.1652691662311554, 0.10539256036281586, -0.06780783087015152, 0.04876270145177841, 0.07265293598175049, -0.005443286616355181, -0.033169832080602646, -0.029064331203699112, -0.005907878279685974, 0.023561902344226837, 0.2107367068529129, 0.02413642406463623, 0.133163720369339, -0.0313531868159771, -0.025925997644662857, -0.15773546695709229, 0.0007692000363022089, -0.057242900133132935, -0.08263136446475983, 0.002401892328634858, -0.1705089956521988, 0.019306354224681854, -0.09336154162883759, -0.06056632101535797, -0.05925688520073891, -0.11960311233997345, 0.06010138988494873, -0.022362833842635155, 0.10580398142337799, 0.12439366430044174, 0.09777528047561646, -0.04697858542203903, 0.035696253180503845, -0.02996160462498665, -0.015573977492749691, 0.04186970368027687, 0.13408537209033966, 0.0809340626001358, -0.03250135853886604, 0.1801980882883072, -0.0725419893860817, -0.16091950237751007, 0.0486237034201622, 0.07753933221101761, -0.041853949427604675, 0.10605321079492569, 0.01483759842813015, -0.056093472987413406, 0.08439655601978302, 0.07546808570623398, -0.07128094136714935, 0.01369869988411665, -0.017238225787878036, 0.0053525953553617, -0.014593246392905712, -0.020258191972970963, 0.13301433622837067, 0.053277645260095596, 0.08307696878910065, 0.010888122022151947, -0.15824441611766815, -0.03089914657175541, -0.04050398990511894, -0.19215653836727142, 0.0819062814116478, -0.06642141938209534, 0.07050031423568726, -0.029903490096330643, -0.02679472044110298, -0.0712055042386055, 0.030305275693535805, 0.24297267198562622, 0.01964680291712284, -0.17017686367034912, -0.028592567890882492, -0.023181376978754997, 0.00677197240293026, -0.09306135028600693, -0.18600456416606903, -0.13382942974567413, -0.29025858640670776, -0.026602385565638542, -0.01735410839319229, -0.09726624935865402, 0.06053914874792099, -1.535345791577225e-32, -0.04249292239546776, -0.06957223266363144, 0.029018567875027657, 0.04853277653455734, 0.1336374133825302, 0.0239493940025568, 0.011708959005773067, -0.1009005606174469, -0.05790981650352478, -0.10117046535015106, 0.017545251175761223, -0.09733422100543976, 0.09452889859676361, 0.013208866119384766, 0.024359596893191338, 0.09822878241539001, -0.19629745185375214, 0.1897401511669159, -0.10817120224237442, 0.12638205289840698, -0.04238586500287056, 0.18300274014472961, -0.014891878701746464, 0.0006145640509203076, -0.10930854082107544, -0.05084668844938278, 0.02156783826649189, -0.008628562092781067, 0.06525512039661407, -0.030561015009880066, -0.05038462579250336, 0.004882926121354103, -0.16071639955043793, 0.11837948858737946, 0.007588227279484272, -0.10019436478614807, 0.055728137493133545, -0.012148438021540642, -0.08903564512729645, 0.10210640728473663, 0.17261788249015808, 0.09480483084917068, -0.16494441032409668, 0.1406397670507431, 0.061428602784872055, -0.002843554364517331, -0.017809361219406128, -0.04382694140076637, -0.0014687830116599798, 0.044095009565353394, 0.03392081335186958, -0.0414394773542881, -0.09076619893312454, 0.05639176070690155, -0.047133564949035645, 0.04963122308254242, -0.05430574342608452, -0.07918816804885864, -0.04180537164211273, -0.031096098944544792, -0.09704142063856125, -0.02904471755027771, 0.11125092953443527, -0.050134122371673584, 0.15702937543392181, 0.0004003443173132837, -0.0409952811896801, 0.006611480377614498, -0.09923410415649414, 0.0745033249258995, -0.20638716220855713, -0.06297557801008224, -0.053692806512117386, -0.15345051884651184, 0.004063536413013935, 0.10219402611255646, -0.02805985137820244, -0.035302575677633286, -0.0272375401109457, 0.0380525141954422, -0.005133697763085365, -0.08221017569303513, 0.1424519121646881, 0.1276901215314865, 0.0022514855954796076, 0.05535459145903587, 0.11686433106660843, 0.14290940761566162, 0.14623349905014038, -0.012150169350206852, 0.0051271854899823666, 0.0690440759062767, 0.1117229089140892, 0.21353571116924286, -0.001143877045251429, -1.0120880489239426e-07, -0.054599422961473465, 0.01254073716700077, -0.061432190239429474, -0.020600300282239914, -0.019880427047610283, 0.007733417674899101, -0.11342573910951614, -0.03201320767402649, -0.07785342633724213, -0.0160899069160223, 0.027654370293021202, 0.04685445502400398, -0.06492342799901962, 0.1019749864935875, 0.04591832682490349, 0.07902981340885162, -0.008822494186460972, 0.07089856266975403, -0.02492710016667843, 0.004247416276484728, 0.09852700680494308, -0.09969989210367203, 0.10464946180582047, -0.02872098982334137, -0.002422313904389739, -0.15310271084308624, -0.07943893224000931, -0.0340571403503418, 0.101432204246521, 0.10277392715215683, 0.043995775282382965, -0.16264258325099945, -0.02626492641866207, -0.009067247621715069, 0.14957347512245178, 0.00014506751904264092, 0.11426253616809845, -0.08981437981128693, 0.06237856298685074, 0.06408774107694626, -0.13190533220767975, 0.06786113232374191, -0.09042666852474213, 0.0185500867664814, 0.01720951497554779, -0.03705717623233795, -0.019144143909215927, 0.05026213079690933, 0.06346973776817322, 0.029705826193094254, -0.08759348094463348, 0.010527084581553936, -0.06471753120422363, -0.004393408540636301, 0.12759236991405487, 0.05738820880651474, -0.11491549015045166, 0.010968493297696114, 0.021043704822659492, 0.001426357077434659, -0.038127634674310684, -0.08260511606931686, 0.055249735713005066, -0.08740066736936569], metadata={'source': 'AAAMLP-569to.pdf', 'page': 128}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 129 Fold = 2, AUC = 0.9269329887598243 Fold = 3, AUC = 0.9119349082169275 Fold = 4, AUC = 0.9166408030141667 ═════════════════════════════════════════════════════════════════════════  Whoa!   That’s an excellent score!  Now, we can try to add some features. We will take all the categorical columns and create all combinations of degree two. Take a look at feature_engineering function in the snippet below to know how this is done.  ═════════════════════════════════════════════════════════════════════════ # lbl_xgb_num_feat.py import itertools import pandas as pd import xgboost as xgb  from sklearn import metrics from sklearn import preprocessing   def feature_engineering(df, cat_cols):     \"\"\"     This function is used for feature engineering     :param df: the pandas dataframe with train/test data     :param cat_cols: list of categorical columns     :return: dataframe with new features     \"\"\"     # this will create all 2-combinations of values     # in this list     # for example:     # list(itertools.combinations([1,2,3], 2)) will return     # [(1, 2), (1, 3), (2, 3)]     combi = list(itertools.combinations(cat_cols, 2))     for c1, c2 in combi:         df.loc[           :,            c1 + \"_\" + c2         ] = df[c1].astype(str) + \"_\" + df[c2].astype(str)     return df   def run(fold):     # load the full training data with folds'),\n",
       " VectorParams(vector=[0.08035081624984741, -0.00040700286626815796, -0.012979711405932903, -0.010429099202156067, 0.13036590814590454, -0.013415505178272724, -0.015129507519304752, -0.053959380835294724, -0.23051206767559052, 0.011997636407613754, 0.10111898928880692, -0.16967074573040009, -0.07648086547851562, -0.12607769668102264, -0.008993024937808514, 0.12736481428146362, -0.12537091970443726, 0.08327873796224594, -0.04610932990908623, -0.04262358322739601, -5.7866177485266235e-06, 0.16498857736587524, -0.013330213725566864, 0.000578559935092926, -0.04169990494847298, 0.031595926731824875, 0.06071131303906441, 0.10815433412790298, -0.1825721710920334, -0.016264833509922028, -0.08716163784265518, 0.16949932277202606, -0.001149320974946022, 0.019151275977492332, 0.1107722818851471, 0.030410705134272575, -0.07319127023220062, 0.14383500814437866, -0.0277436301112175, 0.11764770746231079, -0.12707887589931488, -0.09699488431215286, 0.13685904443264008, -0.0726119801402092, 0.07640877366065979, 0.03348890319466591, -0.015302962623536587, -0.0711982324719429, 0.0679936408996582, -0.018146716058254242, -0.013668701983988285, 0.13556428253650665, -0.09696915000677109, 0.02375982701778412, -0.10784786939620972, -0.1828738898038864, 0.006002703215926886, -0.14857792854309082, 0.02676301635801792, -0.01167810708284378, -0.1393047422170639, -0.08143377304077148, 0.12550954520702362, -0.08648628741502762, 0.04289396107196808, -0.03961405158042908, -0.15199808776378632, 0.03960349038243294, -0.2016310691833496, 0.11495494842529297, -0.03183333948254585, 0.009642702527344227, -0.13948257267475128, 0.015868449583649635, -0.03763432428240776, 0.002093907678499818, 0.24089796841144562, 0.0013532781740650535, 0.2352382093667984, -0.051225125789642334, -0.2008352130651474, -0.01269309688359499, -0.07050067186355591, -0.013866384513676167, -0.04871104285120964, -0.1643577367067337, -0.025741329416632652, 0.0009962357580661774, 0.03432675451040268, 0.05819994583725929, 0.0444536916911602, -0.00944990012794733, 0.09833217412233353, -0.035740479826927185, -0.009004391729831696, 0.04470647871494293, 0.014155939221382141, -0.05915495753288269, -0.01286102831363678, 0.09445971995592117, -0.08501037210226059, -0.030863018706440926, 0.019287465140223503, -0.20736217498779297, -0.06261005997657776, -0.00034747645258903503, 0.22298340499401093, 0.18713949620723724, 0.050406958907842636, -0.06791139394044876, 0.06601724028587341, -0.10769302397966385, -0.05844290927052498, -0.06925283372402191, 0.03196411952376366, 0.011980785988271236, 0.028654247522354126, 0.03168438747525215, -0.003328851191326976, 0.15640133619308472, -0.06939265131950378, 0.06032450869679451, -0.042719777673482895, -0.018913090229034424, -0.12103935331106186, -0.1303129345178604, -0.08619339019060135, 1.3416910318661212e-32, -0.0962592139840126, -0.018366629257798195, -0.05111834779381752, -0.017493469640612602, -0.02816508710384369, -0.05901781842112541, 0.10170716047286987, 0.061177611351013184, 0.02565104328095913, 0.06667592376470566, -0.11401190608739853, 0.1618276983499527, -0.12221634387969971, 0.027511021122336388, -0.06950529664754868, -0.07943663001060486, 0.06789768487215042, -0.01793035678565502, -0.08551938086748123, -0.0018888185732066631, 0.22683723270893097, -0.055049020797014236, 0.05832117423415184, -0.0335264727473259, 0.05025777593255043, -0.14973653852939606, -0.1921733170747757, -0.012935456819832325, -0.06191961094737053, -0.045306771993637085, -0.14739163219928741, 0.06787533313035965, 0.04812264442443848, -0.14371077716350555, -0.0150703564286232, -0.1623680144548416, 0.1268000602722168, 0.08504358679056168, -0.002540776738896966, 0.0673917755484581, -0.1220393180847168, -0.010997586883604527, 0.07939083129167557, -0.049481991678476334, -0.021927272900938988, 0.11932028084993362, 0.14868761599063873, 0.0618855357170105, -0.09634891897439957, 0.18015146255493164, 0.004515570122748613, -0.18844930827617645, -0.0017572721699252725, 0.010515854693949223, -0.18627198040485382, 0.12705157697200775, -0.034716855734586716, -0.09448134899139404, -0.003085292875766754, 0.01009219791740179, -0.08789032697677612, -0.0815703272819519, 0.028834788128733635, 0.0027952848467975855, -0.005247917026281357, 0.04897831007838249, 0.19433541595935822, 0.08018907159566879, 0.061403755098581314, -0.05115627869963646, -0.04563305899500847, -0.03344683349132538, 0.021060511469841003, -0.17434270679950714, 0.14131402969360352, -0.09078377485275269, 0.037418000400066376, -0.026301303878426552, -0.05661687254905701, -0.010170585475862026, 0.09811995178461075, 0.2087106555700302, -0.08678553253412247, -0.10781103372573853, 0.09092838317155838, 0.036286238580942154, 0.06112310290336609, -0.08713867515325546, -0.07857486605644226, -0.09782764315605164, -0.13866066932678223, 0.005788792390376329, -0.017003687098622322, -0.12132427096366882, 0.055957239121198654, -1.4932679427319843e-32, -0.08298123627901077, 0.010655544698238373, 0.06923636794090271, -0.02911289781332016, 0.11538434028625488, 0.12244802713394165, 0.04766230657696724, -0.11778747290372849, 0.0707438588142395, -0.14357800781726837, -0.022893637418746948, -0.13938133418560028, 0.050307970494031906, -0.055571138858795166, -0.12037066370248795, 0.11372486501932144, -0.15595762431621552, 0.13753272593021393, -0.09750288724899292, 0.12991660833358765, -0.03362523764371872, 0.23910735547542572, -0.09453298896551132, 0.11632952839136124, -0.07992447167634964, 0.01023207139223814, -0.04405379667878151, 0.09048690646886826, 0.03719435632228851, 0.03125932812690735, -0.1146310567855835, 0.027098432183265686, -0.09113215655088425, 0.08590919524431229, 0.028383424505591393, 0.002432105364277959, 0.06276501715183258, -0.089012511074543, -0.15143324434757233, 0.0364152155816555, 0.1616833209991455, 0.13080184161663055, -0.18327288329601288, 0.06239433214068413, -0.018373927101492882, 0.07079648226499557, 0.11150389164686203, 0.017821738496422768, -0.007584919687360525, 0.05763160064816475, 0.08471041917800903, -0.03281492739915848, -0.053846824914216995, 0.053932130336761475, -0.059609320014715195, 0.12370672076940536, 0.0021271295845508575, -0.10232708603143692, -0.15250630676746368, 0.007679098751395941, -0.12872429192066193, 0.03465664014220238, 0.04347282648086548, 0.02647019922733307, 0.17699067294597626, -0.03924384340643883, -0.08219704031944275, 0.018956929445266724, -0.05119593068957329, -0.055644381791353226, -0.13532720506191254, -0.14606046676635742, 0.06730588525533676, -0.12737484276294708, -0.054363515228033066, 0.0749601274728775, -0.004610734526067972, -0.09646278619766235, -0.07882008701562881, 0.17638695240020752, -0.053698133677244186, -0.07910562306642532, 0.09956380724906921, 0.2402775138616562, -0.05903642252087593, 0.09792298078536987, 0.08005128055810928, -0.0362606979906559, 0.05727295204997063, 0.03321393206715584, 0.015736479312181473, -0.0862034261226654, 0.08962985128164291, 0.2547874450683594, -0.09039174765348434, -1.0078449719230775e-07, 0.09512624889612198, 0.09014320373535156, -0.1420581191778183, -0.08397936820983887, -0.016386104747653008, -0.05507098138332367, 0.02889217995107174, 0.0020274529233574867, 0.004911360796540976, 0.13780444860458374, 0.16381682455539703, 0.10240096598863602, -0.08518174290657043, 0.060875218361616135, -0.022985657677054405, 0.10671941190958023, 0.007695604115724564, 0.018193013966083527, 0.006514959502965212, 0.03936484828591347, 0.2466486692428589, -0.12819848954677582, -0.06988081336021423, 0.006995915900915861, 0.07063688337802887, -0.19956763088703156, -0.0581524558365345, 0.05667002871632576, 0.12382492423057556, 0.05858512595295906, 0.0007103302632458508, -0.18695057928562164, -0.03200821205973625, -0.008885879069566727, 0.18485701084136963, -0.04880141094326973, 0.17809033393859863, -0.10332735627889633, -0.0223917905241251, 0.20766614377498627, -0.05259830877184868, 0.11236822605133057, -0.12850487232208252, -0.07877916097640991, -0.09229976683855057, 0.020571639761328697, -0.04336323216557503, 0.09765163064002991, 0.18072645366191864, 0.045566339045763016, -0.10752733796834946, 0.02920440584421158, -0.09579971432685852, -0.005181625951081514, 0.14282342791557312, 0.054466065019369125, 0.012884818017482758, 0.06805673986673355, -0.016865404322743416, -0.061868179589509964, 0.06437603384256363, 0.07327139377593994, 0.02849983610212803, -0.12453216314315796], metadata={'source': 'AAAMLP-569to.pdf', 'page': 129}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 130     df = pd.read_csv(\"../input/adult_folds.csv\")      # list of numerical columns     num_cols = [         \"fnlwgt\",         \"age\",         \"capital.gain\",         \"capital.loss\",         \"hours.per.week\"     ]      # map targets to 0s and 1s     target_mapping = {         \"<=50K\": 0,         \">50K\": 1     }     df.loc[:, \"income\"] = df.income.map(target_mapping)      # list of categorical columns for feature engineering     cat_cols = [         c for c in df.columns if c not in num_cols         and c not in (\"kfold\", \"income\")     ]      # add new features     df = feature_engineering(df, cat_cols)      # all columns are features except kfold & income columns     features = [         f for f in df.columns if f not in (\"kfold\", \"income\")     ]      # fill all NaN values with NONE     # note that I am converting all columns to \"strings\"     # it doesnt matter because all are categories     for col in features:         # do not encode the numerical columns         if col not in num_cols:             df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")          # now its time to label encode the features     for col in features:         if col not in num_cols:                     # initialize LabelEncoder for each feature column             lbl = preprocessing.LabelEncoder()                          # fit label encoder on all data'),\n",
       " VectorParams(vector=[-0.038647543638944626, -0.1365729421377182, -0.07824614644050598, 0.031087348237633705, 0.18362103402614594, -0.05167752131819725, 0.07394825667142868, 0.052542008459568024, -0.16640082001686096, -0.030026786029338837, 0.05254072695970535, -0.18869265913963318, -0.042575906962156296, -0.1174371987581253, -0.019914932548999786, 0.13575181365013123, -0.07266692817211151, -0.028457937762141228, -0.17866665124893188, 0.024237949401140213, 0.07450428605079651, -0.010765483602881432, -0.01825953647494316, 0.045121725648641586, -0.03437753766775131, -0.019429532811045647, 0.1294601559638977, 0.08655961602926254, -0.07974161952733994, -0.06244151294231415, 0.010881212539970875, 0.02283356711268425, 0.099324069917202, 0.007341781165450811, 0.0667722299695015, 0.039825767278671265, -0.07398421317338943, -0.010989350266754627, -0.1354888528585434, 0.06306366622447968, 0.00942886434495449, -0.13425371050834656, 0.045548733323812485, 0.010604903101921082, 0.1463131457567215, 0.12132254242897034, -0.02424127236008644, -0.02642717771232128, 0.06776189059019089, -0.06398086994886398, 0.05377199128270149, 0.11381439864635468, -0.10777215659618378, -0.02466294728219509, -0.11260323226451874, -0.12672901153564453, 0.058476079255342484, -0.2009357511997223, 0.09479061514139175, -0.08294156193733215, -0.016802821308374405, -0.0646388828754425, -0.009162507019937038, -0.04639660567045212, 0.008564948104321957, -0.07046850025653839, -0.23124586045742035, -0.023259907960891724, -0.052289605140686035, 0.05778462812304497, -0.0840335562825203, 0.02234061248600483, -0.13570642471313477, 0.08403898030519485, -0.09597674757242203, 0.01399331633001566, 0.2739027440547943, -0.07310184091329575, 0.04867764189839363, -0.003190351650118828, -0.21080146729946136, 0.03186242654919624, 0.13195501267910004, -0.03137225657701492, 0.047204166650772095, -0.1837267279624939, 0.09626774489879608, 0.028912611305713654, -0.0520114041864872, -0.0406198687851429, 0.13009615242481232, 0.039483342319726944, 0.015648556873202324, 0.0395987294614315, 0.008380808867514133, 0.06493055075407028, 0.18102647364139557, -0.0993146151304245, 0.034021858125925064, 0.0930766761302948, -0.12473642081022263, 0.010778944939374924, 0.05220304802060127, -0.049462705850601196, -0.05444324389100075, -0.09550148993730545, 0.013202514499425888, 0.19394095242023468, 0.05997532978653908, -0.018657637760043144, 0.015992719680070877, -0.09150650352239609, -0.10969963669776917, 0.04032870754599571, 0.02693561092019081, 0.2016565203666687, -0.13294059038162231, 0.07783209532499313, -0.16231052577495575, 0.16898871958255768, -0.04541602358222008, 0.09623679518699646, 0.07214207947254181, -0.007821756415069103, -0.08024664968252182, -0.1475449949502945, -0.10964526236057281, 1.5742599443140214e-32, -0.07908798009157181, 0.01805369183421135, -0.06782140582799911, -0.14984802901744843, -0.008603887632489204, -0.05128469690680504, -0.01426280289888382, 0.0819135457277298, 0.11300614476203918, 0.1650228351354599, -0.18036694824695587, 0.1263917088508606, -0.07711859047412872, -0.04740474000573158, -0.03554213047027588, 0.022952402010560036, -0.0718671903014183, -0.030474387109279633, -0.08180830627679825, 0.14889326691627502, 0.246329665184021, -0.0006582180503755808, 0.05654684454202652, 0.03316439688205719, -0.11590637266635895, 0.022800657898187637, -0.03102986514568329, -0.024550898000597954, -0.031906742602586746, 0.04726924002170563, -0.23913352191448212, -0.010725725442171097, -0.03566354513168335, -0.12723352015018463, -0.13633117079734802, -0.07797861844301224, 0.04478827491402626, 0.022159481421113014, -0.035851363092660904, -0.008701421320438385, -0.03215377777814865, -0.05584031343460083, 0.03912512958049774, -0.09876970946788788, 0.02014804817736149, -0.007890326902270317, 0.10378772765398026, 0.08977513015270233, -0.04024346172809601, 0.18699057400226593, -0.008611854165792465, -0.2474738508462906, -0.0007476566242985427, 0.10371742397546768, -0.08083769679069519, 0.13782891631126404, 0.03185081481933594, 0.06601621210575104, 0.07464654743671417, 0.03649432212114334, 0.0553659163415432, -0.0012987431837245822, -0.03863881155848503, -0.03121221624314785, -0.010483757592737675, 0.018639160320162773, 0.2060455083847046, -0.00929860770702362, 0.011372680775821209, -0.01969856210052967, -0.14453716576099396, 0.060509562492370605, 0.019370926544070244, -0.14736440777778625, 0.06934136152267456, -0.10891975462436676, 0.04801270365715027, 0.03225182369351387, -0.104082852602005, 0.013234557583928108, 0.024659771472215652, 0.29087120294570923, -0.04859811067581177, -0.17729632556438446, 0.027471844106912613, 0.06568172574043274, 0.05455193296074867, -0.033498842269182205, -0.2730723023414612, -0.060617949813604355, -0.19753974676132202, -0.06831821799278259, 0.07630006223917007, -0.10280000418424606, -0.003737618215382099, -1.4865004748175065e-32, 0.02659222111105919, 0.02172680012881756, 0.092768594622612, 0.05997661128640175, 0.1092010959982872, 0.047580718994140625, 0.0487949438393116, 0.009580078534781933, -0.07507319748401642, -0.16682468354701996, 0.008274664171040058, -0.09711132198572159, 0.12442570179700851, 0.0332658514380455, 0.0503811314702034, 0.03625045716762543, -0.18583084642887115, 0.1389991194009781, -0.15511691570281982, 0.11267047375440598, -0.04979071766138077, 0.14372988045215607, -0.13183799386024475, 0.013943679630756378, -0.163531094789505, 0.022175492718815804, 0.030105259269475937, 0.04773210734128952, 0.06711502373218536, -0.02040688693523407, -0.13754837214946747, 0.1502579003572464, -0.1288604438304901, 0.12638555467128754, 0.023801367729902267, -0.15110273659229279, -0.08130112290382385, -0.06103980541229248, -0.06091488525271416, 0.13829343020915985, 0.08705879002809525, 0.11476675420999527, -0.23032592236995697, 0.015129461884498596, -0.04763968288898468, -0.018505094572901726, -0.0148387486115098, -0.005693215411156416, 0.05983803793787956, -0.015276782214641571, 0.0500175841152668, -0.027804633602499962, -0.06491182744503021, 0.07454878836870193, -0.08739782869815826, 0.14635123312473297, -0.06000010669231415, -0.05470159649848938, -0.09114433079957962, 0.0716637596487999, -0.08606655895709991, 0.030842028558254242, 0.09498288482427597, 0.027706455439329147, 0.10977835208177567, 0.02585436776280403, -0.08333981037139893, 0.07091277837753296, 0.07234998047351837, 0.0528227798640728, -0.07024706155061722, -0.03137287497520447, 0.042588427662849426, -0.07543488591909409, -0.01781764067709446, 0.11349257081747055, -0.020141439512372017, -0.05581491068005562, -0.009981481358408928, 0.01681090146303177, -0.04874274879693985, -0.05620965734124184, 0.16375792026519775, 0.198015496134758, -0.02983936108648777, 0.16242563724517822, 0.08700971305370331, 0.0976216271519661, 0.09449225664138794, -0.04341229423880577, 0.0015428635524585843, 0.030344584956765175, 0.1431017816066742, 0.23030602931976318, -0.05288596451282501, -1.0047916276789692e-07, -0.033125296235084534, 0.03127700090408325, 0.04470027983188629, 0.036842186003923416, 0.024064481258392334, 0.029498469084501266, -0.06874643266201019, -0.02577107399702072, -0.02634505182504654, 0.004297330509871244, 0.12058386206626892, 0.015086573548614979, -0.18900732696056366, 0.051775433123111725, -0.00509571423754096, 0.1401904672384262, 0.07556751370429993, 0.07029420137405396, 0.003162125125527382, 0.1310393363237381, 0.1537156105041504, -0.1357334405183792, 0.10134837031364441, -0.024507835507392883, 0.02150101587176323, -0.16776825487613678, -0.057657640427351, 0.11459625512361526, 0.020161384716629982, 0.07218810170888901, 0.023057030513882637, -0.1850878745317459, -0.003253344912081957, 0.08158537745475769, 0.1196964830160141, 0.08191091567277908, 0.12310154736042023, -0.15927304327487946, 0.03168604522943497, 0.16627733409404755, -0.010753816924989223, 0.071339912712574, -0.15421943366527557, -0.07153167575597763, 0.0005125563475303352, 0.07456930726766586, 0.01849057711660862, -0.01409859862178564, 0.11106950044631958, 0.028101304545998573, -0.18883922696113586, -0.05845293402671814, -0.12860405445098877, -0.012601048685610294, 0.05144015699625015, 0.09509432315826416, -0.1450331211090088, 0.029085449874401093, 0.03960114344954491, 0.016945824027061462, -0.06836865097284317, -0.09463423490524292, 0.036014001816511154, -0.02944953739643097], metadata={'source': 'AAAMLP-569to.pdf', 'page': 130}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 131             lbl.fit(df[col])              # transform all the data             df.loc[:, col] = lbl.transform(df[col])      # get training data using folds     df_train = df[df.kfold != fold].reset_index(drop=True)      # get validation data using folds     df_valid = df[df.kfold == fold].reset_index(drop=True)      # get training data     x_train = df_train[features].values      # get validation data     x_valid = df_valid[features].values      # initialize xgboost model     model = xgb.XGBClassifier(         n_jobs=-1     )      # fit model on training data (ohe)     model.fit(x_train, df_train.income.values)      # predict on validation data     # we need the probability values as we are calculating AUC     # we will use the probability of 1s     valid_preds = model.predict_proba(x_valid)[:, 1]      # get roc auc score     auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)      # print auc     print(f\"Fold = {fold}, AUC = {auc}\")   if __name__ == \"__main__\":     for fold_ in range(5):         run(fold_) ═════════════════════════════════════════════════════════════════════════  This is a very naïve way of creating features from categorical columns. One should take a look at the data and see which combinations make the most sense. If you use this method, you might end up creating a lot of features, and in that case, you will'),\n",
       " VectorParams(vector=[-0.03563734143972397, -0.1468716412782669, 0.005759910214692354, 0.027710283175110817, 0.05794399976730347, -0.0014681019820272923, -0.0045423200353980064, 0.019808661192655563, -0.14615952968597412, -0.05652990564703941, -0.0561700314283371, -0.20640167593955994, 0.031618643552064896, 0.002223074436187744, 0.11806078255176544, 0.22600936889648438, 0.011656412854790688, 0.06175953522324562, -0.16850998997688293, 0.02632804773747921, 0.14450791478157043, -0.03191904351115227, -0.01846439763903618, 0.03024168312549591, -0.09271897375583649, -0.1039285659790039, 0.034239716827869415, 0.06547997891902924, -0.04224049299955368, -0.08274120837450027, 0.03977926820516586, 0.09666645526885986, 0.027357595041394234, -0.01954866573214531, 0.10524885356426239, 0.0972764790058136, -0.10339980572462082, -0.09013050049543381, -0.15513911843299866, -0.01110297255218029, 0.04180150851607323, -0.09018722176551819, 0.025983063504099846, -0.03704577311873436, 0.08198729157447815, 0.06141174957156181, -0.039718009531497955, -0.001417405903339386, -0.01779794692993164, -0.07819312065839767, 0.03555714339017868, 0.095778688788414, -0.07988396286964417, 0.0562315434217453, -0.09445691108703613, -0.14412006735801697, -0.031735680997371674, -0.19502609968185425, 0.017353205010294914, -0.14965400099754333, -0.10132312774658203, -0.02776029333472252, 0.014015685766935349, -0.10468138754367828, 0.08099538087844849, -0.013931985013186932, -0.06845943629741669, -0.09477344900369644, 0.06565581262111664, 0.09187812358140945, 0.03526737540960312, -0.057741716504096985, -0.06914106011390686, 0.010093082673847675, 0.046692557632923126, -0.005241662263870239, 0.257952481508255, -0.11893041431903839, -0.01795930787920952, 0.014436020515859127, -0.10567615926265717, 0.025971045717597008, 0.020041391253471375, 0.047245487570762634, 0.055438172072172165, -0.15092986822128296, -0.014956355094909668, 0.046838968992233276, -0.03885717689990997, 0.03277016058564186, 0.11338107287883759, -0.005571947433054447, 0.020826660096645355, 0.06638791412115097, 0.045768700540065765, 0.036235466599464417, 0.1904626488685608, -0.08677215874195099, 0.011205485090613365, 0.016487348824739456, -0.030596043914556503, 0.04127711057662964, 0.008553005754947662, 0.017311569303274155, 0.08841486275196075, -0.06623567640781403, 0.09144185483455658, 0.12081978470087051, 0.07519707828760147, -0.12784011662006378, 0.023222999647259712, -0.08639875054359436, -0.0005083810538053513, -0.02539200522005558, 0.037028465420007706, 0.10226178169250488, -0.03336075320839882, 0.042412951588630676, -0.03410379961133003, 0.06765083223581314, -0.06816765666007996, 0.052346594631671906, 0.05671319738030434, 0.016802901402115822, -0.024307403713464737, -0.08330757915973663, -0.1225682944059372, 1.460276518281806e-32, -0.03450971841812134, 0.014155317097902298, -0.04365043342113495, -0.16146168112754822, 0.02176344022154808, -0.05016520619392395, 0.000555137638002634, 0.009809126146137714, -0.05253414064645767, 0.12903717160224915, -0.18550175428390503, 0.05099548399448395, -0.03436002507805824, 0.02234521694481373, 0.0037485724315047264, -0.04560765251517296, -0.08770087361335754, 0.04903460666537285, -0.12640950083732605, 0.07010504603385925, 0.020104900002479553, 0.05484858527779579, 0.13427454233169556, -0.08763062953948975, -0.09664348512887955, -0.0039986902847886086, -0.017789047211408615, -0.09800440073013306, -0.05891122668981552, 0.0371958464384079, -0.1709267497062683, -0.0369676798582077, -0.04404688626527786, -0.02939741313457489, -0.08746902644634247, -0.07112903892993927, -0.021104903891682625, 0.0026297499425709248, 0.00529125239700079, 0.08580244332551956, 0.02764296904206276, -0.003399341832846403, 0.06110512465238571, -0.10504540801048279, -0.00943474005907774, 0.07192786037921906, 0.08706077188253403, 0.09049903601408005, -0.15897858142852783, 0.12774035334587097, 0.08324845880270004, -0.10440509021282196, -0.04229521006345749, -0.009999088011682034, -0.08205851912498474, -0.022511553019285202, 0.08900639414787292, -0.03528273478150368, 0.022943507879972458, 0.1244322806596756, -0.0009863786399364471, -0.05074269697070122, 0.039196595549583435, -0.03454892709851265, 0.11028826981782913, -0.038212232291698456, 0.1783987432718277, -0.040771204978227615, -0.01649830862879753, 0.019178269430994987, -0.1742030531167984, 0.11090482026338577, 0.015630435198545456, -0.15738168358802795, 0.05211196094751358, -0.061090655624866486, 0.1899842917919159, -0.027724197134375572, 0.05093884468078613, 0.017604054883122444, 0.06709796190261841, 0.1665041744709015, 0.0927068293094635, -0.1918642371892929, -0.0860431045293808, 0.06068366765975952, -0.01449845265597105, -0.12756682932376862, -0.21106338500976562, -0.07715949416160583, -0.12317923456430435, -0.06844612956047058, 0.03427191823720932, -0.12860213220119476, -0.038495779037475586, -1.3072799041137373e-32, 0.004251922480762005, -0.023935236036777496, 0.08078084141016006, 0.07860909402370453, 0.019464215263724327, -0.037523303180933, 7.03977420926094e-05, -0.06462696939706802, -0.16206800937652588, -0.09856517612934113, 0.11139098554849625, -0.07576560974121094, 0.07529525458812714, 0.006063511595129967, 0.060194700956344604, 0.08832111954689026, -0.11494645476341248, 0.12064440548419952, -0.0557476207613945, 0.09718546271324158, -0.014520052820444107, 0.1515631377696991, -0.1769101470708847, 0.05392279475927353, -0.15838173031806946, 0.017019424587488174, -0.012474446557462215, -0.003944242373108864, 0.19712886214256287, -0.04295146092772484, -0.06671375781297684, 0.06612664461135864, -0.1303446888923645, 0.01827124133706093, 0.004411973990499973, -0.030188610777258873, -0.019742127507925034, -0.0470099002122879, 0.009098485112190247, 0.11855576932430267, 0.05445822328329086, 0.1170588880777359, -0.1573908030986786, 0.023142220452427864, -0.012026824057102203, 0.06778278201818466, -0.0349811390042305, -0.0012808232568204403, 0.03606394678354263, -0.013745494186878204, 0.07182483375072479, -0.033302340656518936, -0.047631457448005676, 0.04532017558813095, -0.06414458900690079, 0.05581627041101456, -0.08547031879425049, -0.06634853035211563, 0.0324566587805748, -0.04108941927552223, -0.11369983851909637, 0.06462203711271286, 0.09272084385156631, -0.05471470206975937, 0.08470450341701508, 0.05128271132707596, 0.016947191208600998, -0.04901652783155441, -0.1494743824005127, 0.012446461245417595, -0.11168547719717026, -0.049272336065769196, 0.11169257760047913, -0.03499830886721611, 0.017925042659044266, 0.03068341687321663, -0.019804572686553, 0.04284854978322983, -0.043662384152412415, -0.036739982664585114, -0.041297219693660736, -0.046450141817331314, 0.0872265100479126, 0.15760159492492676, 0.012143089435994625, 0.08222538232803345, 0.09685005247592926, 0.1345430314540863, 0.15965014696121216, -0.06049571931362152, -0.027416273951530457, 0.115353062748909, 0.10746265947818756, 0.18808573484420776, 0.0035758442245423794, -1.007839358635465e-07, -0.04654107615351677, 0.039971381425857544, -0.11061665415763855, 0.018654149025678635, 0.01792706735432148, 0.06841374188661575, -0.05985046923160553, 0.048956915736198425, -0.027002759277820587, 0.07100898027420044, 0.09602272510528564, -0.03823833912611008, -0.15535062551498413, 0.07932306826114655, -0.002239381894469261, 0.08504988253116608, 0.05788898468017578, 0.04259604588150978, 0.02854304201900959, 0.024684526026248932, 0.047129251062870026, 0.0026913322508335114, 0.12430495768785477, -0.028543461114168167, 0.024293240159749985, -0.10743231326341629, -0.058173321187496185, 0.061700720340013504, 0.08189006894826889, -0.03866134211421013, 0.058763038367033005, -0.0785251334309578, 0.014459602534770966, 0.006406688597053289, 0.08765112608671188, 0.12584632635116577, 0.006806086748838425, -0.07261615246534348, -0.021935803815722466, 0.15844395756721497, -0.03009902499616146, 0.09943366050720215, -0.06873835623264313, -0.05460396409034729, -0.016984645277261734, -0.030998125672340393, -0.02653341367840767, -0.02656295895576477, 0.03960885852575302, 0.07289615273475647, -0.03731946647167206, -0.07252082228660583, -0.062394678592681885, -0.0014327308163046837, 0.10007084161043167, 0.08229753375053406, -0.07969614863395691, -0.0003686300478875637, 0.05268401652574539, 0.019999053329229355, 0.0685429498553276, -0.11738733947277069, -0.009708056226372719, 0.02514035254716873], metadata={'source': 'AAAMLP-569to.pdf', 'page': 131}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 132 need to use some kind of feature selection to select the best features. We will read more about feature selection later. Let’s see the scores now.  ═════════════════════════════════════════════════════════════════════════ ❯ python lbl_xgb_num_feat.py Fold = 0, AUC = 0.9211483465031423 Fold = 1, AUC = 0.9251499446866125 Fold = 2, AUC = 0.9262344766486692 Fold = 3, AUC = 0.9114264068794995 Fold = 4, AUC = 0.9177914453099201 ═════════════════════════════════════════════════════════════════════════  It seems that even without changing any hyperparameters and just by adding a bunch of features, we can improve our fold scores a bit. Let’s see if increasing max_depth to 7 helps.  ═════════════════════════════════════════════════════════════════════════ ❯ python lbl_xgb_num_feat.py Fold = 0, AUC = 0.9286668430204137 Fold = 1, AUC = 0.9329340656165378 Fold = 2, AUC = 0.9319817543218744 Fold = 3, AUC = 0.919046187194538 Fold = 4, AUC = 0.9245692057162671 ═════════════════════════════════════════════════════════════════════════  And yet again, we have been able to improve our model.  Note that we have not yet used rare values, binary features, a combination of one-hot and label encoded features and several other methods.  One more way of feature engineering from categorical features is to use target encoding. However, you have to be very careful here as this might overfit your model. Target encoding is a technique in which you map each category in a given feature to its mean target value, but this must always be done in a cross-validated manner. It means that the first thing you do is create the folds, and then use those folds to create target encoding features for different columns of the data in the same way you fit and predict the model on folds. So, if you have created 5 folds, you have to create target encoding 5 times such that in the end, you have encoding for variables in each fold which are not derived from the same fold. And then when you fit your model, you must use the same folds again. Target encoding for unseen test data can be derived from the full training data or can be an average of all the 5 folds.'),\n",
       " VectorParams(vector=[0.09508734941482544, -0.006491053383797407, -0.07615412771701813, -0.004161312244832516, 0.08349846303462982, -0.004190829582512379, 0.03321169689297676, -0.0601651668548584, -0.18000556528568268, -0.07725045830011368, 0.043324876576662064, -0.207114115357399, -0.04128795117139816, -0.106106698513031, -0.008323347195982933, 0.04430001229047775, 0.004793982021510601, 0.05126621946692467, -0.06543456017971039, -0.026333894580602646, 0.04660555720329285, 0.07147607207298279, -0.0034930934198200703, -0.012487197294831276, 0.03514178469777107, -0.027256380766630173, 0.04556701332330704, 0.045854005962610245, -0.0935172513127327, 0.002010110067203641, 0.0049428571946918964, 0.06707094609737396, 0.05776837840676308, 0.002586603630334139, 0.061460837721824646, 0.07903435826301575, 1.6412197510362603e-05, 0.04163823276758194, -0.030036894604563713, -0.025830471888184547, -0.050046809017658234, -0.10963977128267288, 0.057834189385175705, -0.10913856327533722, 0.0491337925195694, 0.07546573132276535, 0.025053594261407852, 0.014369785785675049, 0.02562524378299713, -0.05125509575009346, -0.053797896951436996, 0.09408071637153625, -0.07366733998060226, 0.054841578006744385, -0.0022487815003842115, -0.06948809325695038, -0.001184865483082831, -0.07570818811655045, -0.015446639619767666, -0.09684555977582932, -0.22103039920330048, -0.02312261424958706, 0.1395808309316635, -0.06085743010044098, 0.0979173481464386, -0.07649603486061096, -0.13574577867984772, 0.04026664048433304, -0.1557735800743103, 0.13187628984451294, 0.01903308928012848, -0.1086425930261612, -0.09643294662237167, 0.11198548972606659, -0.012454313226044178, -0.0031214060727506876, 0.15109199285507202, 0.05098976939916611, 0.14232951402664185, -0.10481508076190948, -0.13678428530693054, -0.10506433993577957, -0.023887857794761658, 0.02203202433884144, 0.008277405053377151, -0.16733236610889435, -0.0070014530792832375, 0.043724775314331055, -0.07323815673589706, 0.06053635850548744, 0.08543077111244202, -0.010257482528686523, 0.16286630928516388, -0.00032793302671052516, 0.05945003405213356, -0.03254308924078941, 0.054200317710638046, -0.033217187970876694, -0.021304070949554443, 0.05910762771964073, -0.07622293382883072, -0.04445271193981171, 0.022793684154748917, -0.16765575110912323, -0.06021997332572937, -0.054995663464069366, 0.14621186256408691, 0.16081689298152924, 0.0638502836227417, -0.10055186599493027, 0.02122875303030014, -0.08292169123888016, -0.06856156885623932, -0.014036762528121471, 0.08179722726345062, -0.0658831000328064, -0.03191450238227844, 0.0418224111199379, -0.09607375413179398, 0.10648823529481888, -0.03289029002189636, -0.009862370789051056, -0.019326750189065933, 0.06009924039244652, -0.1594211459159851, -0.10042731463909149, -0.0799090638756752, 1.6557499146904257e-32, -0.03234339505434036, 0.007314274553209543, -0.04766817390918732, -0.1536768525838852, -0.09636382758617401, -0.009905139915645123, 0.04145213961601257, 0.038434721529483795, 0.05923888832330704, 0.09277234971523285, -0.04140615835785866, 0.12256213277578354, -0.10725099593400955, 0.009337176568806171, -0.08446992188692093, -0.02362697944045067, -0.04737980663776398, 0.048306453973054886, -0.07143443077802658, 0.03770596534013748, 0.16867123544216156, 0.05367260053753853, 0.033862680196762085, -0.10290827602148056, -0.039638686925172806, -0.08529030531644821, -0.15528635680675507, -0.1320694237947464, -0.03755277022719383, 0.00163686100859195, -0.15935637056827545, -0.009155540727078915, -0.029433246701955795, -0.08027273416519165, -0.14244268834590912, -0.12387804687023163, 0.0851670578122139, 0.03524911776185036, -0.11900008469820023, 0.028345853090286255, -0.06268893927335739, -0.0064858319237828255, 0.07260893285274506, -0.12300247699022293, 0.039955269545316696, 0.1421372890472412, 0.12699879705905914, -0.0019924845546483994, -0.040619608014822006, 0.17365874350070953, 0.003019266063347459, -0.20828254520893097, -0.08004976063966751, 0.031605690717697144, -0.11873658001422882, 0.04588489234447479, -0.006675273180007935, -0.046040069311857224, 0.053846895694732666, -0.06267384439706802, 0.00498562166467309, -0.12046732753515244, 0.0908849909901619, -0.03948532044887543, -0.005454315338283777, 0.010974643751978874, 0.18226276338100433, 0.044034164398908615, -0.051151618361473083, 0.05291188508272171, -0.03925170749425888, -0.01888631284236908, 0.04842545464634895, -0.10456939786672592, 0.11488832533359528, -0.10560555756092072, 0.032643817365169525, -0.009723430499434471, -0.02699802815914154, -0.012026202864944935, 0.1613582819700241, 0.1580488085746765, -0.0399114228785038, -0.19860917329788208, 0.017710058018565178, 0.046358127146959305, 0.005496995523571968, -0.05887738987803459, -0.0843253880739212, -0.03143472224473953, -0.12541107833385468, -0.04981771111488342, -0.05508777126669884, -0.022220885381102562, 0.009750373661518097, -1.782250004570197e-32, -0.059943925589323044, 0.03913145884871483, 0.08726027607917786, 0.06318410485982895, 0.10864181071519852, 0.06107829138636589, 0.07299007475376129, -0.09971944987773895, 0.049142025411129, -0.003513891948387027, -0.03221771866083145, -0.15756675601005554, 0.02268046885728836, -0.044621098786592484, -0.08212587237358093, -0.045154083520174026, -0.026144012808799744, 0.1520027220249176, -0.08008407801389694, -0.02761828899383545, -0.047590047121047974, 0.1942293792963028, -0.08999128639698029, 0.11241772770881653, -0.05455753952264786, 0.05819305405020714, -0.07475300878286362, 0.04536440968513489, 0.011641439981758595, -0.005078225862234831, -0.09042089432477951, 0.06852983683347702, -0.11303815990686417, -0.00041872935253195465, 0.010979202575981617, -0.0694950520992279, 0.019297610968351364, -0.02017104998230934, -0.1343453973531723, 0.05635467544198036, 0.10991234332323074, 0.13048650324344635, -0.13751867413520813, 0.07073210179805756, 0.07238923013210297, 0.07436628639698029, 0.007211639545857906, 0.01904796063899994, 0.10292398184537888, 0.0722079798579216, 0.16980120539665222, -0.0027083687018603086, -0.11497806757688522, 0.05592651292681694, -0.10612838715314865, 0.0626901239156723, -0.0329538956284523, -0.031152229756116867, -0.13916540145874023, 0.008605415001511574, -0.1683356910943985, -0.023690568283200264, 0.05891941487789154, 0.10386765003204346, 0.03896787017583847, -0.04457240551710129, 0.04480549320578575, 0.038879022002220154, 0.0027995272539556026, -0.04222840815782547, 0.0171457901597023, -0.16124047338962555, 0.09892405569553375, -0.05680908262729645, -0.04905737191438675, 0.062156159430742264, 0.03881466016173363, -0.034715503454208374, 0.013136990368366241, 0.10140848159790039, -0.033162448555231094, -0.008023183792829514, 0.15376895666122437, 0.16746307909488678, -0.03829986974596977, 0.1526220291852951, 0.016663240268826485, 0.02787572331726551, 0.015439212322235107, -0.03931671753525734, 0.0035374141298234463, -0.04422386735677719, 0.0413203164935112, 0.09943760931491852, 0.010125810280442238, -1.0100401226509348e-07, 0.017815465107560158, 0.0472446009516716, -0.13114316761493683, -0.007792745251208544, -0.05525725334882736, 0.002230369485914707, -0.11220603436231613, -0.01838039793074131, 0.031237732619047165, 0.10304080694913864, 0.1402752846479416, -0.012964904308319092, -0.06887846440076828, 0.015454942360520363, -0.040179990231990814, 0.04438132420182228, 0.01887042075395584, -0.037033867090940475, 0.009345144964754581, 0.09390606731176376, 0.2128862738609314, -0.03202740103006363, -0.05720856785774231, -0.003729389514774084, 0.0005136146210134029, -0.07800576835870743, -0.0693533718585968, 0.1176668033003807, 0.09591813385486603, 0.08507119864225388, 0.05005896836519241, -0.08454058319330215, 0.009843675419688225, 0.004718014970421791, 0.11019676178693771, -0.02061057649552822, 0.09967724233865738, 0.003636962501332164, -0.06314577907323837, 0.1307423859834671, -0.02527204342186451, 0.0035726006608456373, -0.0724717304110527, -0.07711228728294373, 0.010967356152832508, 0.018929485231637955, -0.01659538596868515, 0.09750818461179733, 0.09084828943014145, 0.037366967648267746, 0.03382633253931999, -0.04443797096610069, -0.024508045986294746, -0.011224884539842606, 0.13198037445545197, -0.03466552495956421, -0.046558357775211334, 0.04747661575675011, 0.045850206166505814, -0.029989084228873253, 0.18237987160682678, -0.03031553514301777, -0.00231845467351377, -0.047811951488256454], metadata={'source': 'AAAMLP-569to.pdf', 'page': 132}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 133 Let’s see how we can use target encoding on the same adult dataset so that we can compare.  ═════════════════════════════════════════════════════════════════════════ # target_encoding.py import copy import pandas as pd  from sklearn import metrics from sklearn import preprocessing import xgboost as xgb   def mean_target_encoding(data):      # make a copy of dataframe     df = copy.deepcopy(data)      # list of numerical columns     num_cols = [         \"fnlwgt\",         \"age\",         \"capital.gain\",         \"capital.loss\",         \"hours.per.week\"     ]      # map targets to 0s and 1s     target_mapping = {         \"<=50K\": 0,         \">50K\": 1     }      df.loc[:, \"income\"] = df.income.map(target_mapping)          # all columns are features except income and kfold columns     features = [         f for f in df.columns if f not in (\"kfold\", \"income\")         and f not in num_cols     ]      # fill all NaN values with NONE     # note that I am converting all columns to \"strings\"     # it doesnt matter because all are categories     for col in features:         # do not encode the numerical columns         if col not in num_cols:'),\n",
       " VectorParams(vector=[-0.02834596484899521, -0.1046452671289444, -0.04162554442882538, -0.03427162393927574, 0.14044901728630066, -0.052920784801244736, -0.028729796409606934, -0.06582716852426529, -0.16372552514076233, -0.08515515923500061, 0.0675991103053093, -0.08164874464273453, -0.11708825081586838, -0.059469226747751236, -0.05508625879883766, 0.09931144118309021, -0.10223592072725296, 0.1421804577112198, -0.15356138348579407, -0.08072838932275772, 0.02469046227633953, 0.163042351603508, 0.05551391467452049, 0.11168268322944641, -0.08002380281686783, 0.09538402408361435, -0.0027998005971312523, 0.07879755645990372, -0.11903298646211624, -0.07610828429460526, 0.09585961699485779, 0.13281141221523285, -0.05210757628083229, 0.04581039398908615, 0.09956043213605881, 0.07352014631032944, -0.1136121079325676, 0.08180985599756241, 0.05887104943394661, 0.10575880855321884, -0.0721094086766243, -0.06429446488618851, 0.09611191600561142, 0.014697079546749592, 0.017141569405794144, 0.0725734606385231, -0.02479596994817257, -0.15722297132015228, 0.030999353155493736, -0.039900921285152435, 0.012187584303319454, 0.15786102414131165, -0.11252293735742569, -0.007916205562651157, -0.10165663063526154, -0.18651476502418518, 0.027679165825247765, -0.10237681865692139, 0.019868522882461548, 0.02302972972393036, -0.02821863815188408, -0.11101067066192627, 0.07563793659210205, -0.043434128165245056, -0.09192439913749695, -0.001157931750640273, -0.11916163563728333, -0.04095039144158363, -0.1486368030309677, 0.04450143128633499, -0.08093221485614777, 0.11810804158449173, -0.11915045976638794, 0.012697765603661537, -0.08987195789813995, 0.05623931810259819, 0.23919835686683655, -0.06118425726890564, 0.13218581676483154, -0.03427278250455856, -0.1307925283908844, 0.05022010579705238, 0.09744839370250702, 0.03406501188874245, -0.01916915364563465, -0.22400040924549103, 0.07550427317619324, 0.07797118276357651, -0.05848732218146324, -0.015407461673021317, 0.10056518763303757, -0.04368875175714493, 0.0656256452202797, 0.008148672990500927, -0.02049838937819004, 0.07513341307640076, 0.056089937686920166, -0.016948483884334564, 0.03442218899726868, 0.13084518909454346, -0.14174020290374756, -0.09474004805088043, -0.07584570348262787, -0.12070196866989136, -0.004997859708964825, -0.03363512083888054, 0.21828092634677887, 0.1151793822646141, 0.014112348668277264, -0.08010122925043106, 0.041259828954935074, -0.09875353425741196, -0.018386229872703552, -0.019530020654201508, 0.057810597121715546, 0.0987047553062439, -0.04839914292097092, 0.050976451486349106, -0.09042958170175552, 0.12905633449554443, -0.11199957877397537, 0.04971020668745041, 0.08740612864494324, -0.050670817494392395, -0.08917029201984406, -0.052217647433280945, -0.014112237840890884, 1.806011006567337e-32, -0.1331152617931366, 0.038609933108091354, 0.04455361142754555, -0.1006271094083786, -0.027621785178780556, -0.08550021052360535, -0.004361929837614298, -0.012109048664569855, 0.010451541282236576, 0.033536020666360855, -0.13088072836399078, 0.1568020135164261, -0.08412996679544449, 0.031368453055620193, -0.09319228678941727, -0.056622643023729324, 0.02617650479078293, 0.04836050420999527, -0.05677635222673416, -0.014774501323699951, 0.3071829378604889, -0.03773599490523338, 0.03200539946556091, -0.06454092264175415, -0.057408515363931656, -0.15912087261676788, -0.14999845623970032, 0.020264852792024612, -0.054270725697278976, -0.03694088011980057, -0.33215615153312683, -0.017729442566633224, 0.04762973263859749, -0.05914894491434097, -0.008678902871906757, -0.12691177427768707, 0.17177075147628784, 0.11894555389881134, -0.07889512926340103, 0.040015045553445816, 0.055428534746170044, 0.04014139994978905, -0.019372113049030304, -0.03379112109541893, 0.011373246088624, -0.030466193333268166, 0.04592522233724594, 0.08027958124876022, -0.049245115369558334, 0.12978258728981018, -0.002812545746564865, -0.1560755968093872, 0.008447380736470222, -0.037028584629297256, -0.20115263760089874, 0.15733395516872406, 0.09708934277296066, -0.017883384600281715, 0.11003896594047546, 0.046444401144981384, -0.06984579563140869, -0.0438680462539196, -0.06868236511945724, 0.016364069655537605, 0.03891368582844734, -0.07710877060890198, 0.19880464673042297, 0.0719393938779831, 0.05081958323717117, -0.09155046939849854, -0.0709390938282013, 0.018625259399414062, -0.03623264282941818, -0.16972635686397552, 0.07074140012264252, -0.16326379776000977, 0.022532997652888298, -0.0068405321799218655, -0.2190103977918625, 0.006023904774338007, 0.10471445322036743, 0.14289015531539917, -0.11452905088663101, -0.11626718938350677, 0.08294901996850967, 0.051238395273685455, 0.063261479139328, -0.13120967149734497, -0.18568019568920135, -0.04757269099354744, -0.23937435448169708, -0.06744382530450821, 0.08468358963727951, -0.19956371188163757, 0.09441018849611282, -1.6287383769396742e-32, 0.09083911031484604, 0.02738308347761631, 0.09065279364585876, 0.0873858854174614, 0.1573001891374588, 0.08955397456884384, 0.07809709757566452, 0.1790086328983307, -0.05084088444709778, -0.09064541757106781, -0.06455453485250473, -0.21240338683128357, 0.11900639533996582, -0.07371201366186142, -0.066839799284935, 0.004430777858942747, -0.18807858228683472, 0.20639905333518982, -0.02065923437476158, 0.14874738454818726, 0.024726949632167816, 0.21846139430999756, -0.14780130982398987, 0.033806174993515015, -0.1353132724761963, 0.10180448740720749, 0.12514223158359528, 0.12898367643356323, 0.011108532547950745, -0.04046126455068588, -0.09702062606811523, -0.010206704027950764, -0.09918989986181259, 0.16234667599201202, 0.01695903018116951, 0.01190626248717308, 0.11203040182590485, -0.16037145256996155, -0.24213425815105438, 0.1312071979045868, 0.0490335077047348, 0.19135482609272003, -0.26206186413764954, 0.09261786192655563, -0.06233375519514084, 0.009224023669958115, -0.03650747239589691, 0.02032710798084736, -0.04635443165898323, -0.04740074649453163, 0.012453244999051094, 0.019889477640390396, -0.14135922491550446, 0.031874071806669235, 0.041391775012016296, -0.024462034925818443, -0.038762979209423065, -0.07099045813083649, -0.12245936691761017, 0.07771454751491547, -0.10782850533723831, 0.034287940710783005, -0.0137267941609025, -0.058250490576028824, 0.31144291162490845, 0.00023203197633847594, -0.10764670372009277, -0.06505464017391205, -0.044943466782569885, -0.013538860715925694, -0.09116403758525848, -0.08215267956256866, -0.007055289577692747, -0.024401172995567322, 0.06859530508518219, 0.07206602394580841, -0.026864826679229736, -0.029404154047369957, -0.016337454319000244, 0.16219326853752136, -0.06532219052314758, -0.17639970779418945, 0.08663683384656906, 0.215711772441864, -0.030376091599464417, 0.08083360642194748, 0.12002992630004883, 0.047211747616529465, 0.02378498762845993, -0.020727412775158882, 0.08381067961454391, -0.051883962005376816, 0.11944258958101273, 0.32094481587409973, -0.01035904511809349, -1.0039705955477984e-07, 0.019851909950375557, 0.04576439410448074, -0.09571796655654907, 0.006801375653594732, -0.064116470515728, -0.01484405342489481, 0.056748662143945694, 0.035610537976026535, -0.012297593988478184, -0.01358031015843153, 0.21727369725704193, 0.005137143190950155, -0.16180194914340973, 0.09565381705760956, 0.025012053549289703, 0.1373814195394516, -0.04083944857120514, 0.0335877425968647, 0.03595773130655289, 0.19952784478664398, 0.1574484407901764, -0.07732263952493668, 0.08609046041965485, -0.0826275497674942, 0.04392796382308006, -0.1693238914012909, -0.051608048379421234, 0.09198097884654999, 0.1115914136171341, 0.0412653312087059, -0.009657498449087143, -0.22036336362361908, 0.03658922016620636, -0.0067999777384102345, 0.09249500185251236, -0.049957018345594406, 0.04839036241173744, -0.12916913628578186, 0.0753249004483223, 0.24138332903385162, -0.03486725315451622, 0.18561764061450958, -0.24585427343845367, -0.07084770500659943, -0.05466898903250694, 0.014148260466754436, -0.02012401632964611, 0.1051037460565567, 0.160463348031044, 0.02435494400560856, -0.13292793929576874, -0.03465428575873375, -0.09129532426595688, 0.05964742600917816, 0.16053199768066406, 0.06596403568983078, -0.04529593512415886, 0.0857616737484932, 0.06406590342521667, -0.014862199313938618, 0.014008872210979462, 0.059663884341716766, 0.04947950690984726, -0.06731599569320679], metadata={'source': 'AAAMLP-569to.pdf', 'page': 133}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 134             df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")          # now its time to label encode the features     for col in features:         if col not in num_cols:                     # initialize LabelEncoder for each feature column             lbl = preprocessing.LabelEncoder()                          # fit label encoder on all data             lbl.fit(df[col])              # transform all the data             df.loc[:, col] = lbl.transform(df[col])      # a list to store 5 validation dataframes     encoded_dfs = []      # go over all folds     for fold in range(5):         # fetch training and validation data         df_train = df[df.kfold != fold].reset_index(drop=True)         df_valid = df[df.kfold == fold].reset_index(drop=True)         # for all feature columns, i.e. categorical columns         for column in features:             # create dict of category:mean target             mapping_dict = dict(                 df_train.groupby(column)[\"income\"].mean()             )             # column_enc is the new column we have with mean encoding             df_valid.loc[                 :, column + \"_enc\"             ] = df_valid[column].map(mapping_dict)         # append to our list of encoded validation dataframes         encoded_dfs.append(df_valid)     # create full data frame again and return     encoded_df = pd.concat(encoded_dfs, axis=0)     return encoded_df   def run(df, fold):     # note that folds are same as before     # get training data using folds     df_train = df[df.kfold != fold].reset_index(drop=True)      # get validation data using folds     df_valid = df[df.kfold == fold].reset_index(drop=True)'),\n",
       " VectorParams(vector=[0.06081961467862129, -0.08689825981855392, -0.1033463105559349, 0.0372128002345562, 0.18571686744689941, -0.05585554614663124, -0.018614711239933968, 0.07902907580137253, -0.20234374701976776, -0.0050347791984677315, 0.09630398452281952, -0.2906619906425476, -0.09587295353412628, -0.09098339080810547, -0.039980292320251465, 0.030317164957523346, -0.10206156969070435, 0.04563060775399208, -0.16283418238162994, 0.07211019098758698, 0.09149643778800964, 0.004140856210142374, -0.016195833683013916, 0.022373847663402557, 0.02809496782720089, -0.0541108213365078, 0.07481108605861664, 0.14409734308719635, -0.12241484969854355, -0.06509902328252792, 0.0052101025357842445, 0.02902190014719963, 0.12280575931072235, 0.105377197265625, 0.04349597170948982, -0.021660376340150833, -0.049651212990283966, 0.012020627036690712, -0.10688839107751846, 0.06151566281914711, -0.05937289819121361, -0.12082277238368988, 0.03575603663921356, 0.0030470218043774366, 0.0739160031080246, 0.07517044991254807, -0.016511887311935425, -0.03845159336924553, 0.008065246045589447, -0.08918844908475876, 0.008016572333872318, 0.15826964378356934, -0.11327017843723297, 0.016075920313596725, -0.15928928554058075, -0.11472275853157043, 0.012108481489121914, -0.2340448945760727, 0.04311838373541832, -0.12850715219974518, -0.08244868367910385, -0.08454740047454834, -0.0022634067572653294, -0.031576160341501236, 0.028851499781012535, -0.056565698236227036, -0.25890377163887024, 0.0044643166474998, -0.06864216923713684, 0.1005883440375328, -0.008656062185764313, -0.0665869414806366, -0.13287143409252167, 0.05219164490699768, -0.019395940005779266, 0.03184083104133606, 0.21420139074325562, -0.053688276559114456, 0.07085765898227692, -0.08809085190296173, -0.24096912145614624, -0.009305289946496487, 0.09290450066328049, -0.07481997460126877, 0.031606275588274, -0.14791208505630493, 0.076680988073349, 0.05651085078716278, -0.05402643606066704, 0.02075912058353424, 0.23084141314029694, 0.0060602156445384026, 0.06346560269594193, 0.041395414620637894, 0.027232980355620384, -0.018137570470571518, 0.12141873687505722, -0.09816430509090424, 0.016119033098220825, 0.06580524146556854, -0.11901942640542984, -0.0163315087556839, 0.04891394078731537, -0.045659031718969345, -0.02333611622452736, -0.037463873624801636, 0.1325138658285141, 0.2529541552066803, 0.06603395938873291, -0.06137454882264137, 0.04915125295519829, -0.07314655929803848, -0.12701013684272766, -0.019889162853360176, 0.05050937458872795, 0.20607542991638184, -0.1297256350517273, 0.06513813883066177, -0.15721364319324493, 0.14897853136062622, -0.06689198315143585, 0.06439952552318573, 0.003907297272235155, 0.028004689142107964, -0.11988285928964615, -0.18767191469669342, -0.10428158193826675, 1.5046310058110018e-32, -0.1391749233007431, -0.048344407230615616, -0.07852369546890259, -0.16327683627605438, -0.01918208971619606, -0.007838988676667213, 0.0025305943563580513, 0.028813548386096954, 0.06082773581147194, 0.09369829297065735, -0.14718745648860931, 0.19892551004886627, -0.09658948332071304, 0.0030079539865255356, -0.062265124171972275, 0.04161139577627182, 0.018861355260014534, -0.026210634037852287, -0.122578464448452, 0.16760054230690002, 0.3419138491153717, 0.01753518171608448, 0.05176296457648277, 0.047520190477371216, -0.05624273419380188, 0.055121131241321564, -0.07764126360416412, -0.03455209732055664, -0.04631683975458145, 0.06300929188728333, -0.2820786237716675, -0.037574250251054764, 0.005177455022931099, -0.14247764647006989, -0.09029676765203476, -0.03770316392183304, 0.10088696330785751, 0.08906320482492447, -0.10386999696493149, -0.0306046511977911, -0.029140669852495193, -0.05656660348176956, 0.08682282269001007, -0.06751013547182083, -0.006771388463675976, -0.071585513651371, 0.1263800412416458, 0.1941601186990738, -0.1259714663028717, 0.2091275155544281, 0.07776115834712982, -0.20368896424770355, 0.03309702128171921, 0.05722088739275932, -0.12043166905641556, 0.13218584656715393, 0.0010450398549437523, -0.011022952385246754, 0.04347360506653786, 0.007743841968476772, 0.060678157955408096, -0.08406437188386917, -0.01608634740114212, -0.05509413033723831, -0.04905562475323677, 0.04540416970849037, 0.15730524063110352, -0.04144136980175972, 0.021071605384349823, 0.026835869997739792, -0.1258060783147812, 0.12447391450405121, 0.06898093968629837, -0.08729400485754013, 0.04502516984939575, -0.043617330491542816, 0.021199392154812813, 0.0005354571621865034, -0.13843758404254913, 0.05464307963848114, 0.05146019160747528, 0.31314823031425476, -0.07112868875265121, -0.13781116902828217, 0.017741918563842773, 0.08158695697784424, 0.09403307735919952, -0.039037350565195084, -0.2449428290128708, -0.044214531779289246, -0.18106086552143097, -0.07819484919309616, 0.09765226393938065, -0.09436444193124771, -0.017977148294448853, -1.5504409022833094e-32, -0.02834755927324295, 0.07340721786022186, 0.05338508263230324, 0.04640017822384834, 0.08132531493902206, 0.14686842262744904, 0.09499306231737137, 0.015520400367677212, -0.04942813888192177, -0.17543895542621613, 0.0025536944158375263, -0.1281939297914505, 0.10795445740222931, 0.0026846993714571, 0.03231942653656006, 0.0318140834569931, -0.19593532383441925, 0.15176387131214142, -0.08226810395717621, 0.053274210542440414, -0.043659985065460205, 0.20658229291439056, -0.12647578120231628, 0.16067633032798767, -0.11424117535352707, 0.04066557437181473, -0.012599396519362926, 0.04244422912597656, 0.026561813428997993, -0.10601905733346939, -0.1007205918431282, 0.10884620249271393, -0.1355690062046051, 0.09606001526117325, 0.0591898076236248, -0.09546469151973724, -0.11394482851028442, -0.06711612641811371, -0.11849033832550049, 0.17638136446475983, 0.09377625584602356, 0.13357914984226227, -0.26413920521736145, 0.08682020008563995, -0.018345598131418228, -0.0052263690158724785, 0.09501440823078156, 0.048638440668582916, 0.08125677704811096, -0.01717120036482811, 0.06745495647192001, -0.028882654383778572, -0.07645758986473083, 0.07007763534784317, -0.05383910983800888, 0.20253895223140717, -0.024677641689777374, -0.03140781819820404, -0.13034166395664215, 0.08567977696657181, -0.09128487855195999, 0.013154927641153336, 0.07557203620672226, -0.023606782779097557, 0.14746470749378204, -0.06980709731578827, -0.08984949439764023, 0.04601434990763664, 0.06822849810123444, -0.02392810583114624, -0.08405239135026932, -0.033491216599941254, 0.0732426866889, -0.09607364982366562, -0.009210447780787945, 0.07544729113578796, -0.044257719069719315, -0.03995082899928093, 0.03398193046450615, 0.07242773473262787, -0.08493965119123459, -0.13721950352191925, 0.19469507038593292, 0.2530895173549652, -0.02812015637755394, 0.0852695107460022, 0.12526869773864746, 0.07169090211391449, 0.037046175450086594, 0.056499045342206955, -0.030461112037301064, 0.02068244107067585, 0.15596336126327515, 0.2600315511226654, -0.0393747054040432, -1.001757539143e-07, 0.07887035608291626, 0.0793648362159729, -0.07171771675348282, 0.06750821322202682, 0.0037915194407105446, 0.04865795746445656, -0.06638886779546738, -0.08328977972269058, -0.06107987090945244, 0.04256567731499672, 0.11364641040563583, -0.025821080431342125, -0.23591269552707672, 0.08913466334342957, 0.0029343508649617434, 0.0940200611948967, 0.1116376742720604, 0.06910933554172516, -0.012905498966574669, 0.09841696172952652, 0.1447831690311432, -0.08909197151660919, 0.01747400313615799, -0.032257359474897385, -0.025193464010953903, -0.14219258725643158, -0.07899732887744904, 0.1357334703207016, -0.022143622860312462, 0.025189561769366264, 0.04732184484601021, -0.128988578915596, -0.02178708277642727, 0.03403856232762337, 0.0863221287727356, 0.08340170979499817, 0.15393713116645813, -0.07241515815258026, 0.05354384332895279, 0.19673918187618256, 0.008344736881554127, 0.006249979138374329, -0.15867897868156433, -0.05841123312711716, -0.045137107372283936, 0.053560465574264526, -0.014351586811244488, 0.06209150329232216, 0.10366372019052505, 0.013116730377078056, -0.1472904235124588, -0.011488883756101131, -0.16778482496738434, 0.02024269849061966, 0.07211030274629593, 0.028261374682188034, -0.0712226927280426, 0.048796676099300385, -0.007477345410734415, -0.01819879189133644, 0.012613296508789062, -0.10653559863567352, -0.05331914499402046, -0.08160898834466934], metadata={'source': 'AAAMLP-569to.pdf', 'page': 134}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 135     # all columns are features except income and kfold columns     features = [         f for f in df.columns if f not in (\"kfold\", \"income\")     ]      # scale training data     x_train = df_train[features].values      # scale validation data     x_valid = df_valid[features].values      # initialize xgboost model     model = xgb.XGBClassifier(         n_jobs=-1,         max_depth=7     )      # fit model on training data (ohe)     model.fit(x_train, df_train.income.values)      # predict on validation data     # we need the probability values as we are calculating AUC     # we will use the probability of 1s     valid_preds = model.predict_proba(x_valid)[:, 1]      # get roc auc score     auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)      # print auc     print(f\"Fold = {fold}, AUC = {auc}\")   if __name__ == \"__main__\":     # read data     df = pd.read_csv(\"../input/adult_folds.csv\")          # create mean target encoded categories and     # munge data     df = mean_target_encoding(df)      # run training and validation for 5 folds     for fold_ in range(5):         run(df, fold_) ═════════════════════════════════════════════════════════════════════════  It must be noted that in the above snippet, I had not dropped categorical columns when I did the target encoding. I kept all the features and added target encoded'),\n",
       " VectorParams(vector=[0.02725956402719021, -0.1550719141960144, 0.04360702633857727, 0.043289538472890854, 0.026008201763033867, 0.0025668982416391373, -0.07440980523824692, 0.006812412291765213, -0.059348419308662415, -0.051657214760780334, -0.08500885963439941, -0.11523498594760895, -0.007687168195843697, 0.05667220056056976, 0.014567593112587929, 0.11607164889574051, 0.09503068774938583, 0.25142496824264526, -0.227412611246109, 0.011938106268644333, 0.0907074585556984, 0.011598042212426662, 0.04024885594844818, -0.016435755416750908, -0.01600191742181778, 0.01953895017504692, 0.012624272145330906, -0.00032177288085222244, -0.11340563744306564, -0.056382451206445694, 0.05115862563252449, 0.054138317704200745, -0.05398084223270416, 0.07698167115449905, -0.08436235785484314, 0.0384097583591938, -0.05827496945858002, 0.05757947638630867, -0.04077409207820892, -0.05578862130641937, -0.013789908960461617, 0.04745875298976898, 0.050257608294487, 0.047280896455049515, 0.13273781538009644, 0.03230302035808563, -0.1068572849035263, -0.0402260348200798, -0.02072923071682453, 0.018213383853435516, -0.007009485736489296, 0.04396963119506836, -0.08054126799106598, 0.08434560894966125, -0.039229974150657654, -0.1517537385225296, -0.06169302761554718, -0.10869811475276947, 0.0033170036040246487, -0.025318941101431847, -0.09516075998544693, -0.08158870041370392, 0.0893036425113678, -0.08675131946802139, 0.01906677335500717, -0.05081342160701752, -0.03994748368859291, 0.06942693144083023, 0.07213857769966125, 0.09807370603084564, 0.004367595538496971, -0.0026049111038446426, -0.09853874891996384, -0.025916017591953278, -0.005416388623416424, 0.06390829384326935, 0.14132395386695862, -0.00299653597176075, 0.12512296438217163, -0.034706391394138336, -0.011815598234534264, 0.0460420586168766, 0.08520051836967468, -0.00011658947914838791, 0.051259417086839676, -0.049034349620342255, 0.0800635814666748, 0.05833052843809128, -0.13604798913002014, 0.03991959989070892, 0.020385360345244408, -0.04646395146846771, 0.1724511981010437, -0.0641339048743248, 0.11794096976518631, 0.045767270028591156, 0.13682624697685242, -0.08770456910133362, 0.04115274176001549, 0.07645156979560852, 0.012596674263477325, 0.07965415716171265, 0.02572367899119854, -0.07001126557588577, 0.0047674113884568214, 0.003252272028476, 0.09814402461051941, 0.08878210186958313, -0.009105284698307514, -0.19301608204841614, 0.007887478917837143, -0.06880854070186615, -0.15780821442604065, -0.08727426081895828, 0.07034767419099808, 0.03750062733888626, 0.05624110996723175, -0.014973662793636322, 0.03881514072418213, 0.02844272553920746, -0.08442361652851105, 0.06203967332839966, -0.037303049117326736, 0.04293486475944519, 0.06699688732624054, -0.016873333603143692, -0.09954924881458282, 1.7618985239376168e-32, -0.03623199462890625, 0.0628342255949974, -0.10056477785110474, -0.014248959720134735, 0.03036005049943924, -0.09187513589859009, 0.043102554976940155, 0.06420034170150757, 0.011439645662903786, 0.08068589866161346, -0.09622789174318314, 0.15340474247932434, -0.09888160973787308, 0.0845591127872467, 0.07516589760780334, -0.10643506050109863, -0.001506071537733078, 0.009938439354300499, -0.07344474643468857, -0.016397397965192795, 0.02948344126343727, 0.03789873793721199, 0.09227488189935684, 0.018348267301917076, -0.007977630943059921, -0.05662083625793457, -0.02693057432770729, -0.08828029781579971, -0.10370069742202759, -0.00011097453534603119, -0.08405850827693939, 0.013835536316037178, -0.017721721902489662, -0.0046827588230371475, -0.020101290196180344, -0.11475984752178192, 0.07892007380723953, 0.03074321150779724, 0.039095573127269745, 0.022176798433065414, 0.02028178796172142, 0.05809222161769867, -0.008377919904887676, -0.059127628803253174, 0.008837503381073475, 0.0588497668504715, 0.07468719035387039, 0.039443474262952805, -0.12434901297092438, 0.0660395398736, 0.0936521589756012, -0.03524316847324371, -0.017547445371747017, -0.031390827149152756, -0.0651904046535492, 0.023829959332942963, 0.053756870329380035, -0.17393608391284943, -0.0023287557996809483, 0.08180572092533112, -0.04092186316847801, -0.04444363713264465, 0.05399930477142334, -0.03412855789065361, 0.05702515318989754, -0.05535457655787468, 0.1166209876537323, 0.04644763469696045, 0.05356508120894432, 0.03366779908537865, -0.06914697587490082, 0.14562636613845825, -0.031472042202949524, -0.16892361640930176, 0.0075234100222587585, -0.007361601106822491, 0.09686027467250824, -0.11983546614646912, -0.1112074926495552, 0.08563882857561111, 0.0721411183476448, 0.10579633712768555, 0.05350729823112488, -0.18873444199562073, -0.06918785721063614, -0.03473837301135063, -0.00854170136153698, -0.13443583250045776, -0.08096418529748917, -0.00010816846042871475, -0.07548754662275314, -0.0217943973839283, 0.041296690702438354, -0.03973162919282913, 0.029991891235113144, -1.2538295882346725e-32, -0.014342466369271278, 0.004122612532228231, -0.10874855518341064, 0.08427640795707703, -0.03008917346596718, 0.0005151999648660421, -0.036919839680194855, 0.05087321251630783, -0.09500567615032196, -0.15076039731502533, -0.08299393951892853, -0.10016036033630371, 0.13926833868026733, -0.07040785253047943, -0.02508847415447235, 0.0254718828946352, -0.10064098238945007, 0.0709293782711029, -0.010081140324473381, 0.13774921000003815, -0.06656228005886078, 0.15966977179050446, -0.13488133251667023, 0.057184848934412, -0.0032143164426088333, 0.1050848662853241, -0.06732580065727234, 0.0485868975520134, 0.08814223855733871, -0.0607544407248497, -0.03277704119682312, -0.06762567162513733, -0.039016127586364746, -0.06511317938566208, -0.0761159285902977, -0.014398922212421894, 0.0631595179438591, -0.03295964375138283, -0.0291513130068779, -0.0845087319612503, 0.12194967269897461, 0.061578359454870224, -0.18826289474964142, -0.0031812433153390884, -0.0014012055471539497, 0.00012621097266674042, -0.12708663940429688, 0.044307686388492584, 0.01595410704612732, 0.010042192414402962, 0.016466151922941208, -0.06300593912601471, -0.058887794613838196, 0.014424359425902367, 0.00808191392570734, 0.021281441673636436, -0.012885525822639465, -0.0775584727525711, 0.058653902262449265, 0.043540261685848236, -0.11284132301807404, -0.005458388477563858, 0.10970291495323181, -0.0510709285736084, 0.09106328338384628, -0.06192750483751297, -0.06796000152826309, -0.041248295456171036, -0.09806840121746063, -0.013114514760673046, -0.031238878145813942, -0.018494432792067528, 0.0018724659457802773, 0.06530939042568207, 0.015479915775358677, -0.029111813753843307, 0.027877967804670334, -0.01734190061688423, -0.023600155487656593, -0.0014084205031394958, -0.002394957933574915, -0.06409648060798645, 0.046114131808280945, 0.10379326343536377, 0.08281893283128738, 0.12785600125789642, 0.09523794800043106, 0.10277590155601501, 0.07144986093044281, 0.059010446071624756, 0.007598386611789465, 0.0446348637342453, 0.054171204566955566, 0.16709749400615692, -0.0334542877972126, -9.916922749653168e-08, -0.029308762401342392, 0.05570182576775551, -0.04720158129930496, -0.012161406688392162, -0.01023187767714262, -0.0010511365253478289, 0.005588451400399208, 0.16092821955680847, -0.06923124939203262, 0.045539841055870056, 0.08066415786743164, 0.044237248599529266, -0.13096362352371216, 0.025720741599798203, 0.02924063429236412, 0.17188259959220886, -0.014127297326922417, 0.005713405087590218, 0.017666982486844063, 0.05626143142580986, 0.06069687008857727, 0.0461001992225647, -0.024920420721173286, -0.01228734664618969, 0.0664781928062439, -0.04332587122917175, -0.01891234889626503, 0.14928841590881348, 0.12733975052833557, 0.0005458258092403412, -0.0349992997944355, -0.04118593782186508, 0.038714051246643066, -0.04069975018501282, 0.07295002788305283, 0.08138284832239151, 0.12143540382385254, -0.1605030596256256, -0.11220993101596832, 0.03876576945185661, 0.05182680860161781, 0.09414707124233246, -0.039351947605609894, -0.08252712339162827, 0.04559796303510666, -0.04827737435698509, 0.020135369151830673, -0.04406508803367615, 0.08615607023239136, 0.06475114822387695, -0.02960730716586113, -0.018748661503195763, -0.09843097627162933, 0.019375037401914597, 0.05329958721995354, 0.031633395701646805, -0.045310717076063156, -0.010042132809758186, 0.08539727330207825, 0.0750850960612297, -0.029519744217395782, -0.06258370727300644, -0.03331471607089043, 0.03959239646792412], metadata={'source': 'AAAMLP-569to.pdf', 'page': 135}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 136 features on top of it. Also, I used mean. You can use mean, median, standard deviation or any other function of targets.   Let’s see the results.  ═════════════════════════════════════════════════════════════════════════ Fold = 0, AUC = 0.9332240662017529 Fold = 1, AUC = 0.9363551625140347 Fold = 2, AUC = 0.9375013544556173 Fold = 3, AUC = 0.92237621307625 Fold = 4, AUC = 0.9292131180445478 ═════════════════════════════════════════════════════════════════════════  Nice! It seems like we have improved again. However, you must be very careful when using target encoding as it is too prone to overfitting. When we use target encoding, it’s better to use some kind of smoothing or adding noise in the encoded values. Scikit-learn has contrib repository which has target encoding with smoothing, or you can create your own smoothing. Smoothing introduces some kind of regularization that helps with not overfitting the model. It’s not very difficult.  Handling categorical features is a complicated task. There is a lot of information floating around in several resources. This chapter should help you get started with any problem with categorical variables. For most of the problems, however, you won’t need anything more than one-hot encoding and label encoding. For improving the models further, you might need a lot more!  We cannot end this chapter without using a neural network on this data. So, let’s take a look at a technique known as entity embedding. In entity embeddings, the categories are represented as vectors. We represent categories by vectors in both binarization and one hot encoding approaches. But what if we have tens of thousands of categories. This will create huge matrices and will take a long time for us to train complicated models. We can thus represent them by vectors with float values instead.   The idea is super simple. You have an embedding layer for each categorical feature. So, every category in a column can now be mapped to an embedding (like mapping words to embeddings in natural language processing). You then reshape these embeddings to their dimension to make them flat and then concatenate all the flattened inputs embeddings. Then add a bunch of dense layers, an output layer and you are done.'),\n",
       " VectorParams(vector=[-0.08986657857894897, -0.12644995748996735, -0.015124425292015076, -0.1203799769282341, 0.011317177675664425, -0.05506983771920204, -0.05946960300207138, -0.1290193647146225, -0.022836629301309586, 0.0006478796130977571, -0.008828391321003437, -0.14383745193481445, -0.13296262919902802, 0.02911495417356491, -0.11980028450489044, 0.0031879046000540257, 0.01852019876241684, 0.16700983047485352, -0.04347959905862808, -0.11663279682397842, -0.06411091983318329, 0.10899025946855545, -0.01806841604411602, 0.014103658497333527, -0.0014744874788448215, -0.11144433915615082, 0.019055834040045738, 0.0449066199362278, -0.0042213378474116325, -0.018941273912787437, 0.02193976566195488, 0.02912413515150547, -0.060512665659189224, 0.07539059966802597, -0.033804453909397125, 0.06306420266628265, -0.08106017112731934, -0.016234949231147766, -0.10125848650932312, 0.042502954602241516, 0.07476753741502762, -0.08381617069244385, -0.03470320999622345, -0.0012075689155608416, 0.0823875144124031, 0.0442630872130394, 0.03228483349084854, -0.07557206600904465, 0.037002310156822205, -0.0813782811164856, -0.02698798105120659, 0.05433086305856705, -0.143634632229805, 0.04654354229569435, -0.12364057451486588, 0.015385986305773258, 0.0660618245601654, -0.06619047373533249, -0.000990509521216154, -0.031242845579981804, -0.0922340601682663, -0.0114830257371068, 0.06378736346960068, -0.019374102354049683, 0.052147094160318375, -0.08972088247537613, -0.06571294367313385, 0.04612571746110916, -0.021944250911474228, -0.007479428313672543, -0.04676692932844162, 0.005725592374801636, -0.19883859157562256, 0.0248075183480978, -0.014531140215694904, -0.0026145270094275475, 0.20568688213825226, -0.001179572893306613, 0.14493010938167572, -0.02415100857615471, -0.03737249970436096, 0.04553553834557533, 0.0487334281206131, -0.07168816030025482, 0.09347821772098541, -0.16019152104854584, -0.03564603626728058, 0.052073363214731216, 0.02525932341814041, -0.04453916847705841, 0.13929755985736847, -0.06603299826383591, 0.019804365932941437, 0.009949538856744766, 0.15578581392765045, 0.054628513753414154, 0.03358101099729538, 0.06510452181100845, 0.0049631050787866116, 0.07920131087303162, -0.03673088550567627, -0.024677658453583717, 0.06901328265666962, 0.0031047752127051353, -0.0075021772645413876, 0.05509983003139496, 0.15192614495754242, 0.06587196886539459, 0.10011128336191177, -0.18834485113620758, -0.014474913477897644, -0.023948097601532936, -0.06313244253396988, -0.048083994537591934, 0.08826712518930435, -0.045954130589962006, -0.09941595792770386, 0.07512400299310684, 0.10526841878890991, 0.062233831733465195, -0.15443597733974457, 0.0755850225687027, -0.05020958557724953, 0.18867307901382446, -0.04791254550218582, -0.029252061620354652, -0.15546025335788727, 1.74567405703398e-32, 0.032132867723703384, -0.04428420960903168, 0.13278715312480927, -0.1031586229801178, -0.01749509759247303, -0.03285222128033638, -0.07267245650291443, -0.01646639034152031, 0.029642943292856216, 0.06872548162937164, -0.2134033739566803, 0.012195278890430927, -0.03231970593333244, 0.1591288149356842, 0.016448648646473885, -0.2064642310142517, -0.060977209359407425, 0.009793472476303577, 0.020981531590223312, 0.014394231140613556, 0.14566750824451447, 0.10815006494522095, 0.014529473148286343, -0.02900991588830948, -0.08098693937063217, 0.01285085454583168, -0.039156701415777206, -0.058976221829652786, -0.09373891353607178, 0.06503861397504807, -0.20651108026504517, -0.10741207748651505, 0.004761495627462864, -0.015671228989958763, -0.0759439766407013, -0.08093442022800446, 0.10729575157165527, 0.09015210717916489, -0.017424989491701126, -0.20536896586418152, 0.06167541444301605, 0.07490045577287674, 0.040714412927627563, -0.093377985060215, -0.15512217581272125, 0.1096663624048233, 0.16189563274383545, 0.06617405265569687, 0.019520491361618042, 0.014739826321601868, 0.027653368189930916, -0.09061060845851898, -0.03284158557653427, 0.0626097172498703, -0.03379463776946068, 0.05224911868572235, 0.04944822937250137, -0.012790774926543236, 0.1290569007396698, -0.0003990353434346616, -0.03166848048567772, 0.15111084282398224, 0.07886333763599396, -0.015130151994526386, -0.02237153798341751, -0.056860268115997314, 0.03970042243599892, 0.04406694322824478, 0.07182835042476654, 0.08121190965175629, -0.11604465544223785, 0.17497412860393524, -0.10214771330356598, -0.08725180476903915, 0.07145483046770096, -0.03723755478858948, 0.09021469950675964, -0.12870855629444122, -0.09668430685997009, 0.05944835767149925, -0.06474224478006363, 0.13146477937698364, 0.07231630384922028, -0.18907925486564636, -0.09182874858379364, -0.04845777526497841, -0.0192051213234663, -0.08927753567695618, 0.00046072894474491477, 0.020781707018613815, -0.1690400242805481, -0.006149313412606716, 0.037325307726860046, 0.040719568729400635, -0.02575620636343956, -1.8905170015743636e-32, -0.039680108428001404, 0.029787328094244003, -0.07555287331342697, 0.030892159789800644, -0.015595602802932262, 0.038718484342098236, -0.02768923155963421, 0.010791691951453686, 0.01845206879079342, -0.03220778703689575, -0.09994414448738098, -0.0841129869222641, 0.024660110473632812, -0.1930173933506012, 0.13293184340000153, -0.08419077098369598, -0.12825240194797516, 0.06483235955238342, -0.0699053555727005, 0.009090953506529331, -0.07575378566980362, 0.14676786959171295, -0.12672939896583557, 0.05993090942502022, -0.0283910371363163, 0.04912058264017105, -0.06068933755159378, 0.08472304791212082, -0.056306034326553345, -0.04606727883219719, -0.10653569549322128, -0.13676060736179352, -0.10045278817415237, 0.09550532698631287, -0.04280947893857956, 0.016835877671837807, 0.003979917615652084, -0.014769013971090317, -0.026998670771718025, 0.051884327083826065, 0.1726202517747879, 0.1501106470823288, -0.1155306026339531, 0.09005025774240494, -0.11290857195854187, 0.08138857036828995, -0.07364654541015625, -0.011492329649627209, 0.0874824970960617, -0.051046278327703476, 0.004174419678747654, 0.01215240266174078, -0.04052748158574104, -0.014228343032300472, 0.03098239377140999, 0.017662806436419487, 0.06539271026849747, -0.04419252648949623, 0.00015702247037552297, 0.06418785452842712, -0.13576030731201172, -0.16338761150836945, -0.0031622631940990686, -0.10656137019395828, 0.053898755460977554, -0.04630144312977791, -0.08235132694244385, 0.0841851681470871, -0.02335735782980919, -0.002228294499218464, 0.05264994129538536, 0.0682658702135086, -0.02082778327167034, 0.04221491888165474, -0.037362176924943924, -0.018953435122966766, 0.04347711056470871, -0.07561071217060089, 0.02167673408985138, -0.07275835424661636, 0.003137781750410795, -0.10184627026319504, 0.12187828868627548, 0.13337303698062897, 0.07789567112922668, 0.10571720451116562, 0.1809374988079071, 0.03337477892637253, 0.04900262504816055, 0.029490364715456963, 0.03863057121634483, 0.027552977204322815, 0.06137770786881447, 0.2760885953903198, 0.052412666380405426, -9.96795535002093e-08, -0.0530460849404335, 0.021907633170485497, 0.07391054183244705, 0.04158242791891098, -0.026042403653264046, 0.012860072776675224, 0.11064081639051437, 0.19101406633853912, 0.01284614484757185, -0.0991743728518486, -0.03831490874290466, -0.07632528245449066, -0.03771432861685753, 0.03521239012479782, 0.048675812780857086, 0.17161935567855835, -0.09371981769800186, 0.0038844221271574497, 0.022673536092042923, 0.0375085212290287, -0.012502340599894524, -0.027017904445528984, -0.03368694707751274, 0.02171139605343342, -0.05278715863823891, -0.08393968641757965, -0.026798510923981667, 0.14052756130695343, 0.13704675436019897, 0.05109652504324913, -0.08907473087310791, -0.01506586093455553, -0.033496931195259094, 0.09578012675046921, 0.15863490104675293, 0.10580901056528091, -0.007598440628498793, -0.1141408234834671, -0.1324658989906311, 0.091114841401577, -0.21342390775680542, 0.08014719188213348, -0.07736410200595856, -0.07997109740972519, 0.0599154457449913, 0.0453934483230114, -0.03592853993177414, 0.0488419346511364, 0.03647870942950249, 0.1349385678768158, 0.050467465072870255, 0.136983722448349, -0.08356834948062897, 0.15284743905067444, 0.09658520668745041, -0.05684441700577736, -0.047607023268938065, -0.060271330177783966, 0.08625708520412445, -0.022709423676133156, 0.06275804340839386, -0.02125225029885769, -0.02854003943502903, -0.060630813241004944], metadata={'source': 'AAAMLP-569to.pdf', 'page': 136}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 137  \\n Figure 6: Categories are converted to vectors of float or embeddings  For some reason, I find it super easy to do using TF/Keras. So, let’s see how it’s implemented using TF/Keras. Also, this is the only example using TF/Keras in this book and its super easy to convert it to PyTorch (using cat-in-the-dat-ii dataset).  ═════════════════════════════════════════════════════════════════════════ # entity_emebddings.py import os import gc import joblib import pandas as pd import numpy as np from sklearn import metrics, preprocessing from tensorflow.keras import layers from tensorflow.keras import optimizers from tensorflow.keras.models import Model, load_model from tensorflow.keras import callbacks from tensorflow.keras import backend as K from tensorflow.keras import utils'),\n",
       " VectorParams(vector=[0.05628806725144386, -0.16517363488674164, 0.04205373302102089, -0.05229468643665314, 0.02019561268389225, 0.020275620743632317, -0.06051294505596161, -0.015316436067223549, -0.04360582306981087, -0.05372615158557892, 0.01068047620356083, -0.10069791972637177, -0.02440154366195202, -0.0027831459883600473, -0.14624075591564178, 0.0573209747672081, 0.024207206442952156, 0.14967963099479675, -0.13627706468105316, -0.15129046142101288, 0.07127989083528519, 0.03125268593430519, -0.06734470278024673, 0.020166296511888504, 0.04621369391679764, -0.08710870146751404, 0.033342085778713226, 0.10024891793727875, -0.09787110239267349, -0.12557858228683472, 0.04475497454404831, 0.048045966774225235, -0.055278874933719635, 0.13636381924152374, -0.03619416430592537, 0.005137760657817125, -0.15427955985069275, 0.05318492650985718, -0.037247009575366974, 0.011803586035966873, 0.013345496729016304, 0.0014408821007236838, 0.04700514301657677, -0.08821119368076324, 0.02992841601371765, 0.03940388932824135, -0.05774690583348274, -0.029633082449436188, 0.049600474536418915, -0.06820724159479141, 0.014625025913119316, 0.19157817959785461, -0.045134175568819046, 0.07721954584121704, -0.030582129955291748, -0.27390390634536743, 0.02102584019303322, -0.13245975971221924, -0.0614922009408474, -0.10646321624517441, -0.07137657701969147, -0.05458027869462967, 0.11745921522378922, -0.06990649551153183, -0.003519293386489153, -0.05198594182729721, -0.08488692343235016, 0.0950649157166481, -0.031179580837488174, 0.15293164551258087, -0.016277730464935303, 0.12667083740234375, -0.1631641536951065, 0.04752332717180252, 0.014533820562064648, 0.04122810438275337, 0.20355723798274994, -0.03251968324184418, 0.11012231558561325, -0.010891404934227467, 0.010355385020375252, 0.09022072702646255, -0.06761441379785538, -0.10162585228681564, 0.024486254900693893, -0.17764103412628174, 0.0738702192902565, 0.12388229370117188, 0.03348856419324875, -0.0543123260140419, -0.028324266895651817, 0.05419295281171799, 0.06023994833230972, -0.013320052064955235, 0.12995074689388275, 0.04019778221845627, 0.022769860923290253, 0.011119551956653595, 0.003693283535540104, 0.005457664839923382, -0.06288692355155945, -0.06133922562003136, 0.05161285400390625, 0.010547258891165257, -0.01355903223156929, 0.0024602070916444063, 0.12889695167541504, 0.037633009254932404, 0.06407999247312546, -0.22533713281154633, 0.007155738305300474, -0.06042856723070145, -0.08330252021551132, 0.09213342517614365, 0.2187938094139099, 0.00893213227391243, 0.08997979015111923, 0.06601087003946304, 0.07185613363981247, 0.04511554539203644, -0.07042082399129868, 0.11906552314758301, -0.027763253077864647, 0.02284790202975273, -0.13664406538009644, -0.03650011867284775, -0.0885857418179512, 2.057209153487069e-32, -0.043785128742456436, -0.01786559633910656, -0.024277016520500183, -0.05467181280255318, 0.1084928810596466, -0.032795973122119904, 0.02014290727674961, 0.04327002540230751, -0.03935512900352478, 0.041586726903915405, -0.31050214171409607, 0.10082808136940002, 0.010045277886092663, 0.07646695524454117, 0.03742613270878792, -0.021845420822501183, 0.06687886267900467, 0.05458349734544754, -0.04033661633729935, -0.030056828632950783, 0.12226768583059311, -0.057323575019836426, 0.008827376179397106, 0.014892281964421272, -0.06796987354755402, -0.08138452470302582, -0.011854895390570164, -0.08191799372434616, -0.190776988863945, -0.033899519592523575, -0.21451249718666077, 0.011310474015772343, 0.024839475750923157, -0.02116839960217476, 0.024431873112916946, -0.16092713177204132, 0.1853615641593933, 0.15521588921546936, 0.02250831574201584, -0.16477172076702118, 0.004327285569161177, 0.08374565839767456, -0.009388194419443607, 0.006293917540460825, -0.06945748627185822, -0.006287176162004471, 0.0959596335887909, 0.05910230800509453, -0.038272008299827576, 0.10205760598182678, 0.09579484909772873, -0.09994501620531082, 0.04163498058915138, -0.057360731065273285, -0.061131127178668976, -0.0075110686011612415, 0.02661796286702156, -0.05469834432005882, 0.2224264144897461, 0.054201409220695496, -0.1320071518421173, -0.019655302166938782, 0.021931299939751625, 0.07394177466630936, 0.0842398926615715, -0.02444705180823803, 0.11683633923530579, 0.08102279156446457, 0.0763961598277092, 0.04206915199756622, -0.0759439542889595, 0.0785907730460167, -0.05754465237259865, -0.206441730260849, 0.019426479935646057, -0.1606738120317459, 0.06300138682126999, -0.2059505730867386, -0.14222349226474762, 0.08014242351055145, 0.0010637692175805569, 0.10296543687582016, -0.02684888057410717, -0.20851005613803864, -0.07660762220621109, -0.07329380512237549, 0.07720204442739487, -0.06395038962364197, -0.05782341584563255, -0.1013873890042305, -0.08925895392894745, -0.015065371990203857, 0.09035739302635193, -0.11263106018304825, 0.09616932272911072, -1.8611074553479347e-32, 0.06705714017152786, 0.05476557835936546, 0.018157728016376495, -0.011334051378071308, 0.05049872025847435, 0.09619618207216263, 0.013944425620138645, 0.0933452770113945, -0.04876946657896042, -0.16054947674274445, -0.13006404042243958, -0.0993405357003212, 0.13379783928394318, -0.026231391355395317, 0.07528252899646759, -0.0054083350114524364, -0.17589949071407318, 0.02347763441503048, -0.02803804911673069, 0.07427585870027542, -0.07596141844987869, 0.11070960760116577, -0.10453838109970093, 0.11301389336585999, -0.09506826847791672, 0.11599097400903702, -0.08930380642414093, 0.0008286428055725992, 0.014204173348844051, -0.10685775429010391, -0.03647896647453308, 0.0032317996956408024, -0.11643677204847336, 0.029497286304831505, 0.029261603951454163, -0.03633004054427147, 0.14952492713928223, -0.06407885998487473, -0.028172902762889862, 0.08987601846456528, 0.10713130235671997, 0.11173995584249496, -0.1660754382610321, 0.1463828831911087, 0.028233220800757408, 0.0571136437356472, -0.05463431775569916, -0.026044676080346107, 0.012651250697672367, 0.026425279676914215, -0.05341368541121483, -0.0034898214507848024, -0.08829446136951447, 0.011516598984599113, 0.07506613433361053, 0.030702974647283554, -0.039792247116565704, 0.028621986508369446, -0.012465122155845165, 0.007443060167133808, -0.07994553446769714, -0.13794966042041779, -0.008111347444355488, -0.04805060476064682, 0.10568690299987793, 0.036900538951158524, -0.0964646190404892, 0.014140415005385876, -0.10102008283138275, 0.06615902483463287, -0.02524634823203087, 0.03570451959967613, 0.00447564572095871, -0.06078414246439934, -0.03039058856666088, 0.02303239330649376, -0.07319959253072739, -0.04409646615386009, 0.018378177657723427, 0.09781704097986221, -0.07047323137521744, -0.07693382352590561, 0.04808662086725235, 0.018787993118166924, 0.047451201826334, 0.06231359764933586, 0.10312175005674362, 0.10854789614677429, 0.08087590336799622, 0.009806567803025246, 0.02785298600792885, 0.02930183708667755, 0.043563492596149445, 0.19043390452861786, 0.035243283957242966, -1.004563756623611e-07, 0.028240900486707687, 0.0842619240283966, -0.04294845834374428, -0.003828844055533409, -0.021264320239424706, -0.02322421967983246, 0.04170436039566994, 0.15943001210689545, 0.03718048706650734, -0.037395868450403214, 0.0730411484837532, -0.010927851311862469, -0.04149150475859642, 0.12184102833271027, 0.1045500859618187, 0.10779987275600433, -0.03171069547533989, -0.10676304996013641, 0.05341813713312149, 0.08063744753599167, 0.07024021446704865, -0.005739644635468721, -0.07439184933900833, -0.045964017510414124, -0.07354428619146347, -0.15118110179901123, -0.03246301785111427, 0.07040002942085266, 0.052648771554231644, 0.03876526653766632, 0.0308160912245512, -0.09076856821775436, 0.0068818009458482265, 0.0034938924945890903, 0.14017489552497864, 0.07154156267642975, 0.06644998490810394, -0.07252760976552963, -0.06881266832351685, -0.002519196132197976, -0.09821300208568573, 0.019493112340569496, -0.08054955303668976, -0.12376639246940613, 0.09342006593942642, 0.08843453973531723, -0.022946011275053024, -0.042094066739082336, 0.15196920931339264, 0.06452709436416626, -0.10134006291627884, 0.08069109171628952, -0.10822255164384842, 0.05201418697834015, 0.055193789303302765, -0.002247367287054658, -0.09951668232679367, 0.01326410286128521, 0.147159606218338, -0.14706020057201385, -0.023711908608675003, -0.006653535179793835, -0.033083632588386536, -0.016968028619885445], metadata={'source': 'AAAMLP-569to.pdf', 'page': 137}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 138 def create_model(data, catcols):     \"\"\"     This function returns a compiled tf.keras model     for entity embeddings     :param data: this is a pandas dataframe     :param catcols: list of categorical column names     :return: compiled tf.keras model     \"\"\"     # init list of inputs for embeddings     inputs = []      # init list of outputs for embeddings     outputs = []      # loop over all categorical columns     for c in catcols:         # find the number of unique values in the column         num_unique_values = int(data[c].nunique())         # simple dimension of embedding calculator         # min size is half of the number of unique values         # max size is 50. max size depends on the number of unique         # categories too. 50 is quite sufficient most of the times         # but if you have millions of unique values, you might need         # a larger dimension         embed_dim = int(min(np.ceil((num_unique_values)/2), 50))          # simple keras input layer with size 1         inp = layers.Input(shape=(1,))          # add embedding layer to raw input         # embedding size is always 1 more than unique values in input         out = layers.Embedding(             num_unique_values + 1, embed_dim, name=c         )(inp)                  # 1-d spatial dropout is the standard for emebedding layers          # you can use it in NLP tasks too         out = layers.SpatialDropout1D(0.3)(out)          # reshape the input to the dimension of embedding         # this becomes our output layer for current feature         out = layers.Reshape(target_shape=(embed_dim, ))(out)          # add input to input list         inputs.append(inp)          # add output to output list'),\n",
       " VectorParams(vector=[-0.04492601007223129, -0.17914819717407227, 0.010440198704600334, 0.018788712099194527, 0.04544394463300705, -0.008720692247152328, -0.009205726906657219, 0.0004900539643131196, -0.20682817697525024, -0.17546971142292023, 0.006568143144249916, -0.16173601150512695, 0.06543929129838943, -0.056820254772901535, -0.1046917587518692, 0.10649953037500381, 0.021469829604029655, 0.18903376162052155, -0.21936780214309692, -0.05048234388232231, 0.1755378544330597, 0.026224546134471893, -0.012829669751226902, 0.04714034125208855, -0.027652690187096596, -0.1054663434624672, 0.03922395780682564, 0.0349494107067585, -0.12755969166755676, -0.1087387427687645, 0.040538620203733444, -0.004336184822022915, -0.04685691371560097, 0.09966197609901428, 0.015190637670457363, 0.1058228611946106, -0.1052669882774353, 0.002143698977306485, -0.10568084567785263, 0.029552672058343887, -0.058569081127643585, -0.022533956915140152, -0.013940881937742233, -0.004696845542639494, 0.14221172034740448, -0.005411132704466581, -0.10447239130735397, -0.020991243422031403, 0.13936857879161835, -0.02109551802277565, -0.009329238906502724, 0.14449423551559448, 0.002503046067431569, 0.04873913154006004, -0.04751162603497505, -0.1423172950744629, 0.07017798721790314, -0.0440356507897377, -0.03176361694931984, -0.029233375564217567, -0.04226376861333847, -0.11419986933469772, 0.04868025705218315, -0.10604783892631531, 0.06625539809465408, -0.11955329775810242, -0.1211586445569992, 0.07821343839168549, 0.004658926744014025, 0.08851846307516098, 0.04433048889040947, 0.07725846767425537, -0.12516167759895325, -0.022166727110743523, 0.005334220826625824, -0.036914315074682236, 0.3376966714859009, 0.048425864428281784, 0.02397807128727436, -0.09061898291110992, -0.07571221888065338, -0.09144198149442673, 0.03927196189761162, -0.07750901579856873, 0.016317319124937057, -0.17372576892375946, -0.045378465205430984, 0.04964444786310196, -0.017401641234755516, -0.012902026996016502, 0.06650108098983765, 0.08781909197568893, 0.03243416175246239, -0.03693750500679016, 0.1755775511264801, 0.12111806124448776, 0.05428137257695198, -0.07766716182231903, -0.03182779252529144, 0.09539678692817688, -0.13525059819221497, -0.04982249066233635, 0.02286280132830143, -0.05224219709634781, 0.08978694677352905, -0.02459363453090191, 0.17797629535198212, 0.09475579112768173, 0.008088785223662853, -0.29537007212638855, 0.07216206938028336, -0.05789647996425629, -0.05619710683822632, 0.03765210509300232, 0.20759323239326477, 0.055692169815301895, 0.08916936069726944, 0.03843983635306358, -0.13019849359989166, 0.09124032407999039, -0.1456768959760666, 0.10096868127584457, -0.06132899597287178, 0.05658968165516853, -0.015780262649059296, -0.08011213690042496, -0.09719813615083694, 1.4685517046380072e-32, -0.09525704383850098, -0.01634080335497856, -0.13879059255123138, -0.08907472342252731, 0.060136668384075165, -0.018798131495714188, 0.0769292488694191, 0.02820475399494171, -0.15071728825569153, 0.005642736796289682, -0.3205314576625824, 0.03631896525621414, -0.04165240749716759, 0.02932688221335411, 0.006778842303901911, -0.09985636174678802, 0.008856246247887611, 0.048349395394325256, 0.05400211736559868, -0.014025196433067322, 0.16802209615707397, 0.02192026376724243, 0.05907217785716057, -0.06242191791534424, -0.10182523727416992, 0.011006730608642101, -0.024051273241639137, -0.051284633576869965, -0.127864807844162, 0.0009973009582608938, -0.22772876918315887, 0.024485256522893906, -0.01941777393221855, -0.03852153569459915, -0.05510871484875679, -0.0330066941678524, 0.1073819175362587, 0.15578985214233398, -0.013853351585566998, -0.11360690742731094, -0.1427018791437149, 0.10039246827363968, 0.015304191038012505, -0.0529872328042984, -0.1078082025051117, -0.03836722671985626, 0.06427592784166336, 0.12707002460956573, 0.02274755761027336, 0.032275713980197906, 0.051577407866716385, -0.056859202682971954, 0.053192801773548126, -0.1164068952202797, -0.13371232151985168, 0.0694306492805481, 0.13894671201705933, 0.12183224409818649, 0.12598271667957306, -0.0036233130376785994, 0.08359644562005997, 0.041088614612817764, -0.06328171491622925, 0.03785393387079239, 0.07618038356304169, 0.027220360934734344, 0.11761949956417084, 0.016269125044345856, 0.1591540277004242, -0.021816102787852287, -0.11688192188739777, 0.10963862389326096, 0.08930507302284241, -0.17805609107017517, 0.21164725720882416, -0.1664673238992691, 0.022500349208712578, -0.13981017470359802, -0.10131792724132538, 0.035179004073143005, 0.06231965869665146, 0.2317822128534317, -0.07126441597938538, -0.2078666090965271, -0.09108365327119827, 0.0641048476099968, 0.020801162347197533, 0.001312488573603332, -0.0785718783736229, -0.012336952611804008, -0.1802986115217209, -0.051843952387571335, 0.11518089473247528, -0.03194817900657654, 0.04942292720079422, -1.262019698187233e-32, 0.014926184900105, 0.12816578149795532, 0.053243376314640045, 0.03014274314045906, 0.12115662544965744, 0.07066555321216583, -0.03818640112876892, 0.030349910259246826, -0.10485535115003586, -0.1416734904050827, 0.011666202917695045, -0.16099153459072113, 0.03281315788626671, 0.007924226112663746, 0.047909412533044815, 0.041941676288843155, -0.16515807807445526, 0.09283673018217087, -0.04668036103248596, 0.02244650386273861, -0.09729322046041489, 0.16974760591983795, -0.1913328468799591, 0.0709320679306984, -0.107892706990242, 0.027423137798905373, -0.09943147748708725, 0.197225883603096, 0.15627571940422058, -0.08548479527235031, -0.10668361186981201, 0.04461127892136574, -0.15357449650764465, 0.043722815811634064, 0.05299711599946022, 0.06777798384428024, 0.020509924739599228, 0.0011270992690697312, -0.0414946973323822, 0.08276012539863586, 0.12529920041561127, 0.05673150718212128, -0.19068299233913422, 0.10639547556638718, 0.1111154854297638, 0.0695701465010643, -0.055355317890644073, 0.013348031789064407, -0.11091635376214981, 0.06138509139418602, 0.004518439993262291, -0.04289737343788147, -0.14348964393138885, 0.019171101972460747, -0.016691509634256363, 0.05237450823187828, -0.06592368334531784, -0.08455009758472443, -0.011901596561074257, 0.03800617530941963, -0.1883780062198639, -0.13091415166854858, 0.0408967025578022, -0.029886500909924507, 0.07379291206598282, 0.03548165783286095, -0.10920239239931107, 0.05556399002671242, -0.06291510164737701, 0.11619701236486435, -0.017483346164226532, 0.05325883999466896, 0.11648140102624893, -0.045239225029945374, -0.021338097751140594, -0.016027653589844704, -0.13133177161216736, -0.02747347392141819, -0.045615606009960175, 0.11047854274511337, -0.088620126247406, 0.01286990474909544, 0.11985665559768677, 0.2269759476184845, 0.10309585928916931, 0.11781395226716995, 0.13623298704624176, 0.15586869418621063, 0.04444709047675133, -0.07155542820692062, 0.06784459948539734, 0.025200366973876953, 0.1647307425737381, 0.14174488186836243, -0.07583172619342804, -9.979837756191046e-08, 0.09910695999860764, 0.10378323495388031, 0.05638086050748825, 0.07071816176176071, 0.10281359404325485, 0.07308002561330795, -0.06251468509435654, 0.05838421359658241, -0.02273288555443287, -0.00805779080837965, -0.022289682179689407, 0.007678546942770481, -0.007345404010266066, 0.012048237957060337, -0.018477173522114754, 0.11617328226566315, -0.029301241040229797, -0.01542383711785078, 0.029070332646369934, 0.00865025632083416, 0.11810988932847977, -0.0717889592051506, -0.06100828945636749, 0.07857879251241684, 0.01834123022854328, -0.14086352288722992, -0.14129406213760376, -0.004080240614712238, 0.034084975719451904, 0.0421467162668705, 0.01203304622322321, -0.04825904220342636, 0.01919267699122429, 0.08834667503833771, 0.0832977369427681, 0.08656094968318939, 0.1840914785861969, 0.005701628513634205, -0.06866048276424408, 0.11505021154880524, -0.0911310464143753, 0.06375990808010101, -0.14383389055728912, -0.08397053927183151, 0.06493839621543884, -0.05038014426827431, -0.03480318561196327, -0.19404594600200653, 0.26384907960891724, 0.11090759932994843, -0.0014408917631953955, -0.08832065761089325, -0.04274113103747368, 0.04874397814273834, 0.09038398414850235, -0.028539862483739853, -0.13840581476688385, -0.04168607294559479, 0.09921329468488693, 0.03987542912364006, -0.015079065226018429, 0.05843832716345787, -0.019550569355487823, -0.07033947110176086], metadata={'source': 'AAAMLP-569to.pdf', 'page': 138}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 139         outputs.append(out)          # concatenate all output layers     x = layers.Concatenate()(outputs)      # add a batchnorm layer.     # from here, everything is up to you     # you can try different architectures     # this is the architecture I like to use     # if you have numerical features, you should add     # them here or in concatenate layer     x = layers.BatchNormalization()(x)          # a bunch of dense layers with dropout.     # start with 1 or two layers only     x = layers.Dense(300, activation=\"relu\")(x)     x = layers.Dropout(0.3)(x)     x = layers.BatchNormalization()(x)          x = layers.Dense(300, activation=\"relu\")(x)     x = layers.Dropout(0.3)(x)     x = layers.BatchNormalization()(x)          # using softmax and treating it as a two class problem     # you can also use sigmoid, then you need to use only one     # output class     y = layers.Dense(2, activation=\"softmax\")(x)      # create final model     model = Model(inputs=inputs, outputs=y)      # compile the model     # we use adam and binary cross entropy.     # feel free to use something else and see how model behaves     model.compile(loss=\\'binary_crossentropy\\', optimizer=\\'adam\\')     return model   def run(fold):     # load the full training data with folds     df = pd.read_csv(\"../input/cat_train_folds.csv\")      # all columns are features except id, target and kfold columns     features = [         f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")     ]'),\n",
       " VectorParams(vector=[0.019991600885987282, -0.08784342557191849, -0.06899241358041763, -0.06252632290124893, 0.09386725723743439, 0.009338154457509518, -0.017669208347797394, -0.012820896692574024, -0.18467019498348236, -0.11151861399412155, 0.052207499742507935, -0.1903296411037445, -0.04980546981096268, -0.11983451247215271, -0.03492515906691551, 0.10050307214260101, -0.07346810400485992, 0.08788339048624039, -0.13471250236034393, -0.13717283308506012, 0.04612815007567406, 0.14609496295452118, 0.06797324120998383, 0.15716539323329926, -0.08996661752462387, 0.07751497626304626, 0.056083258241415024, 0.0678953230381012, -0.11422490328550339, -0.0995379164814949, -0.04844511300325394, 0.10112061351537704, -0.06212100759148598, -0.026507223024964333, 0.14827477931976318, 0.0400121733546257, -0.13144586980342865, 0.10517507046461105, 0.07015933096408844, 0.08261790126562119, -0.06357068568468094, -0.10072179138660431, 0.11829372495412827, -0.006306913215667009, 0.08900179713964462, 0.05740302801132202, -0.04954654350876808, -0.08441399782896042, 0.0982864648103714, -0.08094771951436996, 0.025746051222085953, 0.06268750131130219, -0.09377575665712357, 0.0009352007182314992, -0.13940751552581787, -0.2294771820306778, 0.041731055825948715, -0.08011525124311447, 0.059954628348350525, 0.04104657843708992, -0.06858643144369125, -0.030524274334311485, 0.06937717646360397, -0.04250422120094299, -0.05666826665401459, -0.0495508536696434, -0.14227576553821564, 0.030611280351877213, -0.14265957474708557, 0.1024150401353836, -0.04171690344810486, 0.08374118059873581, -0.08862024545669556, 0.12024848908185959, -0.0768091231584549, 0.0377955287694931, 0.28459790349006653, -0.033341314643621445, 0.14371129870414734, 0.02434016764163971, -0.1533711850643158, 0.041265130043029785, 0.0678045004606247, -0.02451423555612564, -0.019279440864920616, -0.17014116048812866, 0.04571915417909622, 0.041963860392570496, 0.027051078155636787, -0.005207792390137911, 0.03723641857504845, -0.04219881445169449, 0.048097603023052216, 0.013439749367535114, 0.014541595242917538, 0.07837405055761337, -0.0016634573694318533, 0.03551425412297249, -0.02498912625014782, 0.11239202320575714, -0.10780379921197891, -0.020318858325481415, -0.009181383065879345, -0.05413408577442169, -0.008754618465900421, 0.028878962621092796, 0.21754686534404755, 0.11889290809631348, 0.15985262393951416, -0.06529956310987473, 0.03587069362401962, -0.08600166440010071, -0.026706410571932793, -0.014329343102872372, 0.061520036309957504, 0.09501779824495316, -0.08305848389863968, 0.0682932659983635, -0.11162250488996506, 0.10299835354089737, -0.12315968424081802, 0.07528024911880493, 0.0769575759768486, 0.033525627106428146, -0.056089188903570175, -0.11497130244970322, -0.09867747873067856, 1.58618900792296e-32, -0.033077072352170944, -0.008142836391925812, -0.010708920657634735, -0.10776208341121674, -0.007308595348149538, -0.08405973762273788, -0.0028572422452270985, -0.003335778135806322, 0.023668689653277397, 0.04645905643701553, -0.16196568310260773, 0.06293287873268127, -0.11547128856182098, 0.022277256473898888, -0.04278644919395447, -0.04225761070847511, -0.03758818283677101, 0.003180893138051033, -0.06123712286353111, 0.061510585248470306, 0.21343976259231567, -0.05038958787918091, -0.04167269915342331, -0.07967332005500793, -0.08980521559715271, -0.09625519812107086, -0.1005987673997879, -0.011667617596685886, -0.11155545711517334, 0.013186485506594181, -0.2698594033718109, -0.03458511829376221, 0.10116139054298401, -0.087494857609272, -0.034382596611976624, -0.13703441619873047, 0.11502745747566223, 0.1197890117764473, 0.026605334132909775, 0.008837693370878696, 0.061587486416101456, 0.053630247712135315, -0.013297260738909245, -0.03574925661087036, 0.03302977606654167, -0.022488432005047798, 0.05928364768624306, 0.08130649477243423, -0.020216645672917366, 0.07478026300668716, 0.002599729923531413, -0.16732995212078094, -0.05035430192947388, -0.01638200506567955, -0.18784324824810028, 0.09387288242578506, 0.03827232867479324, -0.0238735880702734, 0.10732376575469971, 0.0823274776339531, -0.059267159551382065, -0.02698230929672718, -0.05244750902056694, 0.02231452241539955, 0.007284408435225487, -0.04727916046977043, 0.13204386830329895, -0.014071241952478886, 0.041121091693639755, -0.02757393755018711, -0.1608526110649109, -0.025520913302898407, -0.09448600560426712, -0.12450209259986877, 0.08401814103126526, -0.20024973154067993, 0.024125143885612488, -0.06245843321084976, -0.15113317966461182, 0.051820430904626846, 0.07275494933128357, 0.18492980301380157, -0.12941846251487732, -0.07671261578798294, 0.09886091947555542, 0.0015694133471697569, 0.06246676668524742, -0.08898476511240005, -0.1428944170475006, -0.0242468249052763, -0.1673852801322937, -0.037404969334602356, 0.021154779940843582, -0.19402693212032318, 0.03429558128118515, -1.5468578485652093e-32, 0.07467757165431976, 0.09951235353946686, 0.07565928995609283, 0.04869948700070381, 0.08566317707300186, 0.06729698926210403, 0.10100109875202179, 0.05289546400308609, -0.012933649122714996, -0.16815976798534393, -0.025537803769111633, -0.1549510657787323, 0.05145246908068657, -0.038695596158504486, -0.03361627832055092, -0.03422912210226059, -0.23023855686187744, 0.16505926847457886, -0.0933137908577919, 0.08229314535856247, -9.820209015742876e-06, 0.19101296365261078, -0.14070533215999603, 0.07451428472995758, -0.13417093455791473, 0.025729859247803688, 0.006527477875351906, 0.17726753652095795, 0.08929368108510971, -0.019144559279084206, -0.06792674213647842, -0.031927689909935, -0.1339317411184311, 0.11659769713878632, 0.010675065219402313, 0.0018881959840655327, 0.09563466906547546, -0.08946824073791504, -0.12817491590976715, 0.12051884084939957, 0.11915142089128494, 0.15013021230697632, -0.2759089171886444, 0.08186042308807373, -0.0778498649597168, 0.07810813188552856, 0.009937207214534283, 0.00379306823015213, -0.048657361418008804, -0.023831652477383614, 0.04877341911196709, -0.030487846583127975, -0.10334397852420807, 0.004452439025044441, 0.029843244701623917, -0.0003358196991030127, -0.08511823415756226, -0.04953530430793762, -0.09326718747615814, 0.04585178196430206, -0.1322377324104309, 0.05154147371649742, 0.05813373252749443, -0.12911397218704224, 0.2142014354467392, 0.027232576161623, -0.08346273005008698, 0.0942768007516861, 0.03515629097819328, 0.05942738801240921, -0.1280761957168579, -0.030115248635411263, -0.03416305407881737, -0.033264972269535065, 0.004935396835207939, 0.009237491525709629, -0.08095576614141464, -0.06675445288419724, 0.02014731988310814, 0.07918921858072281, -0.009789827279746532, -0.020046524703502655, 0.04189697653055191, 0.1659822314977646, 0.08108878135681152, 0.11938308924436569, 0.13936582207679749, 0.12523816525936127, -0.02314409613609314, -0.007546170148998499, 0.08691704273223877, -0.058249037712812424, 0.12848009169101715, 0.27562397718429565, -0.08669519424438477, -1.0057417654252276e-07, -0.03854017332196236, 0.10903602838516235, -0.061587244272232056, 0.06442778557538986, 0.016115829348564148, 0.03487401828169823, 0.031062213703989983, 0.0055339038372039795, 0.010085598565638065, 0.0378996767103672, 0.13650573790073395, 0.04847658798098564, -0.1166825219988823, 0.10219352692365646, 0.010096989572048187, 0.09130952507257462, -0.02098029851913452, 0.09688505530357361, 0.01907491683959961, 0.10799303650856018, 0.10781735181808472, -0.08105099946260452, -0.006930873729288578, -0.11200915277004242, 0.05012131482362747, -0.17661073803901672, -0.05279272794723511, 0.13795939087867737, 0.07604319602251053, 0.09321913123130798, 0.037182506173849106, -0.18354354798793793, 0.0406847707927227, -0.021495932713150978, 0.13141988217830658, -0.010400158353149891, 0.04867357760667801, -0.11110842227935791, 0.10500100255012512, 0.10156846791505814, -0.07421713322401047, 0.14891484379768372, -0.15064024925231934, -0.07487114518880844, -0.06748078018426895, -0.021335884928703308, 0.009264841675758362, 0.05400962755084038, 0.10707619041204453, 0.040338654071092606, -0.10270142555236816, 0.007754430640488863, -0.056934185326099396, 0.07519786059856415, 0.12866464257240295, -0.018384631723165512, -0.09366980195045471, 0.04449675232172012, 0.06112522631883621, -0.024884210899472237, 0.06706149876117706, 0.020202070474624634, 0.04975457489490509, -0.06088273599743843], metadata={'source': 'AAAMLP-569to.pdf', 'page': 139}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 140     # fill all NaN values with NONE     # note that I am converting all columns to \"strings\"     # it doesnt matter because all are categories     for col in features:         df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")      # encode all features with label encoder individually     # in a live setting you need to save all label encoders     for feat in features:         lbl_enc = preprocessing.LabelEncoder()         df.loc[:, feat] = lbl_enc.fit_transform(df[feat].values)      # get training data using folds     df_train = df[df.kfold != fold].reset_index(drop=True)      # get validation data using folds     df_valid = df[df.kfold == fold].reset_index(drop=True)      # create tf.keras model     model = create_model(df, features)      # our features are lists of lists     xtrain = [         df_train[features].values[:, k] for k in range(len(features))     ]     xvalid = [         df_valid[features].values[:, k] for k in range(len(features))     ]     # fetch target columns     ytrain = df_train.target.values     yvalid = df_valid.target.values      # convert target columns to categories     # this is just binarization     ytrain_cat = utils.to_categorical(ytrain)     yvalid_cat = utils.to_categorical(yvalid)          # fit the model     model.fit(xtrain,               ytrain_cat,               validation_data=(xvalid, yvalid_cat),               verbose=1,               batch_size=1024,               epochs=3              )      # generate validation predictions'),\n",
       " VectorParams(vector=[0.033805783838033676, -0.09673856943845749, 0.028843669220805168, 0.019772332161664963, 0.08755500614643097, 0.013925879262387753, -0.06255389004945755, -0.004525140859186649, -0.15801586210727692, -0.11718746274709702, -0.04444412514567375, -0.11112570762634277, -0.05116087943315506, 0.05364298075437546, -0.07076837122440338, 0.07902397960424423, 0.034924283623695374, 0.1283682882785797, -0.10068751871585846, 0.0017454541521146894, -0.02874949760735035, 0.03706921264529228, -0.04824020341038704, 0.1035839393734932, -0.020231517031788826, -0.025435885414481163, 0.045449282974004745, 0.0451858825981617, -0.004201797302812338, -0.06737722456455231, 0.060722775757312775, -0.02324594184756279, -0.004722696729004383, -0.024894213303923607, -0.03919312730431557, 0.06525350362062454, -0.11033342778682709, -0.07521885633468628, -0.038660358637571335, -0.08039858192205429, 0.010971345007419586, -0.09410061687231064, 0.007207904942333698, 0.06762824952602386, 0.1775856912136078, 0.11709004640579224, 0.04703563079237938, 0.021599462255835533, 0.033207885921001434, -0.07248779386281967, 0.020643029361963272, 0.019091131165623665, -0.08533268421888351, -0.006976199336349964, -0.14650465548038483, -0.08328506350517273, -0.05184581130743027, -0.16337032616138458, -0.02054538205265999, -0.06500431150197983, -0.03365040943026543, -0.03588562086224556, 0.04673568531870842, -0.0596466064453125, -0.07756726443767548, 0.009358621202409267, -0.03385431319475174, 0.018597980961203575, 0.0831964910030365, 0.1515272706747055, 0.13638430833816528, 0.038452886044979095, -0.06171394884586334, 0.03949342295527458, -0.04153621196746826, 0.10884704440832138, 0.12837542593479156, -0.08723211288452148, 0.06269296258687973, -0.02992916665971279, -0.03686938434839249, 0.02642415463924408, 0.03672211989760399, -0.027268782258033752, 0.1276521235704422, -0.0033757451456040144, 0.08585003018379211, -0.0028182254172861576, -0.15620137751102448, 0.05615536868572235, 0.07123351097106934, -0.042336780577898026, 0.18544349074363708, -0.09057033807039261, 0.08689829707145691, -0.025637483224272728, 0.09852142632007599, -0.10333433002233505, -0.041659630835056305, 0.12208609282970428, -0.04764220118522644, 0.12453770637512207, 0.06339312344789505, -0.001975069288164377, 0.012690681032836437, 0.04774758592247963, 0.10966438055038452, 0.12686270475387573, 0.02206980437040329, -0.08724241703748703, 0.0335015170276165, 0.009208688512444496, -0.14353646337985992, -0.02604556269943714, 0.054525237530469894, 0.13602279126644135, -0.023381784558296204, 0.01144781056791544, 0.010082649067044258, 0.14181409776210785, -0.04720201715826988, -0.01575598120689392, 0.061928603798151016, 0.053207702934741974, 0.0320609025657177, -0.04326025769114494, -0.09115777909755707, 9.027538740241956e-33, -0.06224960833787918, -0.0431203655898571, -0.15080992877483368, -0.04324376583099365, -0.0204137172549963, 0.019735459238290787, -0.013294754549860954, 0.1449194997549057, -0.0020400688517838717, 0.08950040489435196, -0.14237450063228607, 0.12008431553840637, -0.044140733778476715, 0.18613803386688232, 0.07265377789735794, -0.01758120208978653, 0.004535361658781767, -0.036374159157276154, -0.09449195116758347, 0.012211793102324009, 0.15223009884357452, -0.1022297665476799, 0.02831430546939373, 0.00959103461354971, -0.03042013943195343, -0.04001341760158539, -0.016214685514569283, -0.03379170596599579, -0.11983672529459, 0.06221533939242363, -0.22578158974647522, -0.02550678886473179, -0.002601550193503499, 0.031840916723012924, -0.006138357799500227, -0.03267712891101837, 0.06610619276762009, -0.0510014109313488, 0.10082361847162247, 0.07577479630708694, -0.028532078489661217, 0.04324434697628021, -0.004145581275224686, -0.05001885071396828, -0.02295708656311035, 0.07156635075807571, 0.04189944639801979, 0.08038748800754547, -0.12549826502799988, 0.011101432144641876, 0.036974404007196426, -0.10031641274690628, -0.0986158475279808, -0.010072075761854649, -0.14549948275089264, -0.09673409909009933, -0.022035880014300346, -0.04090417921543121, 0.002119755372405052, 0.04928893968462944, -0.00833100639283657, -0.004918739199638367, -0.044175438582897186, 0.020039351657032967, -0.11526361852884293, -0.027184633538126945, 0.11359544843435287, 0.03944578766822815, 0.05952715873718262, -0.09540586173534393, -0.13328300416469574, 0.013029265217483044, 0.03958389535546303, -0.17759326100349426, 0.07327412813901901, -0.0728154331445694, 0.13433341681957245, -0.06736583262681961, -0.09467225521802902, 0.13580501079559326, -0.027414683252573013, 0.16474759578704834, 0.0023001066874712706, -0.10686537623405457, 0.10318595916032791, -0.011935184709727764, 0.07348646223545074, -0.04666187986731529, -0.12570685148239136, 0.04954352602362633, -0.1705903261899948, 0.07204855978488922, 0.1572456657886505, 0.013287000358104706, 0.004403361119329929, -9.055260570454192e-33, -0.02488713338971138, -0.06034872680902481, 0.07535571604967117, 0.03029840812087059, -0.01870119944214821, -0.015519565902650356, -0.02200513891875744, 0.05919194594025612, -0.15676476061344147, -0.2222553938627243, 0.03310944885015488, -0.08087063580751419, 0.13048726320266724, -0.01844664476811886, -0.0013823918998241425, 0.009799908846616745, -0.17658570408821106, 0.06507522612810135, 0.0034391379449516535, 0.14303377270698547, -0.05003965273499489, 0.14263448119163513, -0.09252866357564926, -0.007342993281781673, -0.07699690759181976, 0.025777893140912056, -0.04763024300336838, -0.031466417014598846, 0.00598329259082675, 0.05299866944551468, -0.13077013194561005, 0.12249254435300827, -0.07581447064876556, 0.03822919726371765, 0.0233415886759758, 0.05411677807569504, 0.03951326385140419, -0.05670815333724022, -0.0037943648640066385, 0.14510959386825562, 0.16956888139247894, 0.030725553631782532, -0.2070164829492569, 0.0022582828532904387, -0.00436694361269474, 0.012653726153075695, -0.071553073823452, 0.02167304791510105, 0.048818036913871765, 0.03913211077451706, 0.11895624548196793, -0.0724501758813858, -0.0067522283643484116, 0.014433366246521473, 0.028842022642493248, -0.0722508430480957, -0.032220933586359024, -0.044706620275974274, -0.04914005100727081, 0.04652097821235657, -0.04207301512360573, -0.04065338522195816, 0.10252721607685089, -0.008073277771472931, 0.009819285944104195, -0.09771252423524857, -0.0026335646398365498, 0.07470589876174927, 0.006611607503145933, 0.012921343557536602, -0.11660531163215637, -0.014176866970956326, -0.041254229843616486, 0.12129495292901993, -0.09053796529769897, -0.01359415054321289, -0.010477718897163868, -0.09665194898843765, 0.0028769480995833874, 0.002921702805906534, 0.02955666370689869, 0.05994405597448349, 0.03285588324069977, 0.075713612139225, 0.09307117760181427, 0.17843058705329895, 0.10627681761980057, 0.10407241433858871, 0.08228512853384018, -0.0015372277703136206, -0.07402263581752777, 0.12150689959526062, 0.06637856364250183, 0.16497984528541565, 0.031290099024772644, -9.910134934898451e-08, 0.027385465800762177, 0.00014039705274626613, 0.0637030228972435, 0.04469718039035797, 0.003216302487999201, 0.0012479058932512999, -0.15906007587909698, 0.06497358530759811, -0.02105199545621872, 0.016129132360219955, 0.07615397125482559, 0.053469669073820114, -0.10867755860090256, -0.009699616581201553, -0.02698097750544548, 0.06648289412260056, 0.06354078650474548, 0.028489364311099052, -0.01420158613473177, 0.009419542737305164, 0.07066897302865982, 0.054061517119407654, 0.10401968657970428, -0.11435095965862274, -0.02581600286066532, -0.23551273345947266, 0.08509055525064468, 0.04245689511299133, 0.005023373756557703, -0.0033884600270539522, -0.05355847626924515, -0.061415690928697586, -0.07606295496225357, -0.018191304057836533, 0.16644825041294098, 0.091975137591362, 0.07952354103326797, -0.062189120799303055, -0.03131723031401634, 0.00915635097771883, -0.043814703822135925, 0.020416123792529106, -0.05343302711844444, -0.1023966446518898, -0.0036906469613313675, 0.0028445646166801453, -0.02705349773168564, -0.049962203949689865, 0.020842034369707108, 0.1397242695093155, -0.028443630784749985, 0.028457574546337128, -0.036527857184410095, 0.09359718859195709, 0.031126059591770172, 0.0125575615093112, -0.08702355623245239, -0.06385770440101624, 0.035856686532497406, -0.06671228259801865, -0.01666083373129368, -0.09297017008066177, -0.026460712775588036, -0.041321784257888794], metadata={'source': 'AAAMLP-569to.pdf', 'page': 140}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 141     valid_preds = model.predict(xvalid)[:, 1]      # print roc auc score     print(metrics.roc_auc_score(yvalid, valid_preds))      # clear session to free up some GPU memory     K.clear_session()  if __name__ == \"__main__\":     run(0)     run(1)     run(2)     run(3)     run(4) ═════════════════════════════════════════════════════════════════════════  You will notice that this approach gives the best results and is also super-fast if you have a GPU! This can also be improved further, and you don’t need to worry about feature engineering as neural network handles it on its own. This is definitely worth a try when dealing with a large dataset of categorical features. When embedding size is the same as the number of unique categories, we have one-hot-encoding.  This chapter is basically all about feature engineering. Let’s see how you can do some more feature engineering when it comes to numerical features and combination of different types of features in the next chapter.'),\n",
       " VectorParams(vector=[-0.022115793079137802, -0.0650142952799797, 0.09192598611116409, 0.07110313326120377, 0.0450114831328392, -0.015541325323283672, -0.11583571135997772, -0.10545950382947922, -0.11830967664718628, -0.06058361753821373, 0.0376770906150341, -0.08317868411540985, -0.1108727678656578, 0.07578321546316147, 0.10116718709468842, -0.04477901756763458, -0.094641774892807, 0.032509591430425644, 0.009822065010666847, -0.01798725128173828, 0.011395452544093132, 0.07459520548582077, -0.06116768717765808, 0.0776624083518982, -0.07485676556825638, 0.0531654879450798, 0.05574743077158928, 0.04781295359134674, -0.06357385963201523, -0.03580153360962868, -0.1687902957201004, 0.20216844975948334, -0.12307783961296082, -0.041622061282396317, -0.10360126197338104, 0.10183598101139069, 0.05388856679201126, 0.04322441294789314, -0.03357712924480438, 0.021141398698091507, -0.08028557896614075, -0.08075784891843796, 0.06420566886663437, -0.1541329175233841, 0.030643587931990623, 0.026780640706419945, 0.13202914595603943, -0.030895791947841644, -0.027768205851316452, 0.06692100316286087, -0.012184439226984978, 0.06577285379171371, -0.15191417932510376, -0.0014923056587576866, 0.07121641933917999, -0.13993625342845917, -0.016298994421958923, -0.11328140646219254, 0.046210791915655136, -0.023410886526107788, -0.14702995121479034, 0.09109751135110855, 0.02936171181499958, -0.10743623971939087, -0.0807003304362297, -0.09714050590991974, -0.11875920742750168, 0.05890028551220894, 0.05347795411944389, 0.06722746044397354, -0.08824083209037781, 0.018791954964399338, -0.10691681504249573, 0.017894668504595757, -0.030151670798659325, 0.05754726380109787, 0.214954674243927, -0.026219699531793594, 0.1272696703672409, 0.027687838301062584, -0.1052752137184143, 0.08726320415735245, -0.052203867584466934, 0.04404231533408165, 0.133199542760849, -0.009899389930069447, -0.021797779947519302, 0.11738990992307663, -0.05272362381219864, -0.04588215798139572, 0.09020518511533737, 0.014491899870336056, 0.1386360228061676, -0.13866111636161804, 0.0640878975391388, 0.04780030995607376, 0.08994949609041214, -0.10718095302581787, -0.01299125887453556, 0.10376095771789551, 0.03506932407617569, 0.025198044255375862, -0.0374750941991806, -0.0754319429397583, 0.05409253016114235, 0.06751982867717743, 0.10196619480848312, 0.09289227426052094, -0.038922373205423355, -0.036029648035764694, -0.06269843131303787, -0.044289730489254, -0.0882214680314064, -0.17837893962860107, 0.07082238048315048, -0.07533542066812515, -0.016221271827816963, -0.018489554524421692, 0.05721578001976013, 0.17797668278217316, 0.010577344335615635, 0.06748812645673752, 0.006445867940783501, 0.05253130570054054, 0.04469073563814163, 0.05537606403231621, 0.04291717708110809, 1.2211950732567625e-32, -0.023204822093248367, 0.05257047340273857, -0.045019518584012985, -0.01769997552037239, -0.0068982127122581005, -0.0168905146420002, 0.11638231575489044, -0.0056168390437960625, 0.1684895157814026, 0.051654208451509476, -0.005579803604632616, 0.088685542345047, -0.08853970468044281, 0.0725557878613472, 0.2218267023563385, -0.14176228642463684, -0.09800375252962112, 0.029765509068965912, 0.06665313243865967, 0.09557593613862991, 0.10653936862945557, -0.12526078522205353, 0.12598630785942078, -0.027088196948170662, 0.009846211411058903, -0.1858355849981308, 0.005183252971619368, -0.10627385228872299, -0.09659621119499207, -0.02779269963502884, -0.02427615039050579, 0.06503172963857651, -0.026124147698283195, -0.008009402081370354, 0.004838433116674423, -0.1166820079088211, 0.1629437804222107, -0.03629570081830025, 0.052374180406332016, 0.10376992076635361, -0.026154017075896263, -0.02422167919576168, -0.1177477315068245, -0.07252699136734009, 0.007389034144580364, 0.1858196258544922, 0.21322135627269745, -0.004267414566129446, -0.13202552497386932, -0.006589546333998442, -0.017029907554388046, -0.15407605469226837, 0.062355343252420425, -0.13174791634082794, -0.08926574140787125, 0.15672706067562103, 0.07691384106874466, -0.2058883011341095, -0.05105109512805939, -0.014311333186924458, -0.14064426720142365, 0.013662816025316715, 0.1462503969669342, -0.10676902532577515, -0.05459720641374588, -0.11834298074245453, 0.2143562287092209, 0.20067299902439117, 0.029722413048148155, -0.12731222808361053, -0.09503106027841568, 0.015406189486384392, 0.026133833453059196, -0.2900451123714447, 0.03259218856692314, -0.046393729746341705, 0.08319726586341858, -0.014719948172569275, -0.030746424570679665, 0.022075356915593147, 0.10544297844171524, 0.16882646083831787, 0.08609496057033539, -0.19211632013320923, 0.12141036242246628, 0.039616648107767105, 0.03728334233164787, 0.01667153276503086, -0.1106170192360878, -0.194791778922081, -0.18695425987243652, 0.09522037953138351, 0.07419343292713165, -0.04272759333252907, 0.10329120606184006, -1.3095906321338662e-32, -0.12037117034196854, -0.12429358065128326, 0.003973565064370632, 0.05513671785593033, 0.007004151586443186, -0.04000617563724518, -0.17670691013336182, -0.0012431025970727205, 0.024001138284802437, -0.12541958689689636, -0.0688949003815651, -0.0772208422422409, 0.13523128628730774, -0.08093951642513275, -0.042000509798526764, 0.0073191202245652676, -0.10745365917682648, 0.027222836390137672, -0.027153782546520233, 0.12875010073184967, -0.041307080537080765, 0.05109664425253868, -0.17733900249004364, -0.1232927143573761, -0.06966342031955719, -0.00019633608462754637, -0.1205248236656189, 0.07576199620962143, 0.06206738203763962, 0.012215640395879745, -0.10041579604148865, -0.05622173473238945, -0.11639928817749023, -0.03163856640458107, 0.002738683018833399, 0.027622556313872337, -0.016841601580381393, 0.006698017008602619, -0.0168837271630764, -0.04301247373223305, 0.11773849278688431, 0.08212260901927948, 0.027559829875826836, -0.005733892321586609, -0.0025150857400149107, 0.12461015582084656, -0.06932482868432999, 0.01357576809823513, 0.028211554512381554, -0.016505541279911995, 0.08577326685190201, -0.08395782113075256, -0.11063443869352341, -0.04814662039279938, 0.018070725724101067, 0.06183139979839325, 0.11253014951944351, -0.17790059745311737, -0.08922829478979111, 0.09167705476284027, -0.07264044135808945, -0.06125500053167343, 0.00119582109618932, 0.021412553265690804, -0.02196144498884678, -0.028017554432153702, 0.013978815637528896, -0.07284657657146454, -0.03595226630568504, -0.07468005269765854, -0.13641929626464844, -0.07770853489637375, 0.0761273205280304, 0.05716334655880928, -0.08405173569917679, -4.05690025218064e-06, 0.05417972058057785, 0.0006088334484957159, -0.16377568244934082, 0.11434796452522278, -0.023907845839858055, -0.17973901331424713, 0.013093027286231518, 0.05910542607307434, -0.07564517855644226, 0.03654271364212036, 0.04757179319858551, 0.002641982864588499, 0.11745764315128326, -0.07946724444627762, -0.016922693699598312, -0.004077331628650427, -0.08788874000310898, 0.16225093603134155, 0.07576100528240204, -9.99869698148359e-08, 0.03790756314992905, -0.006867474876344204, 0.08440344035625458, -0.21502994000911713, -0.04951661825180054, -0.11257219314575195, 0.07146259397268295, 0.005648226011544466, 0.025753701105713844, 0.0388776995241642, 0.18890103697776794, -0.014920167624950409, -0.01873689331114292, 0.17109957337379456, 0.0166615042835474, 0.19995643198490143, 0.019665183499455452, 0.03009367734193802, 0.0029858353082090616, -0.026527322828769684, 0.16841167211532593, -0.17006142437458038, 0.08578163385391235, -0.04006676748394966, 0.07216741889715195, -0.06246638298034668, 0.032492078840732574, 0.1435282677412033, 0.1449051946401596, 0.13624538481235504, -0.07919951528310776, -0.047550588846206665, 0.009816679172217846, -0.02677679993212223, 0.12225755304098129, -0.1337049901485443, 0.11276574432849884, -0.09438445419073105, -0.15758424997329712, 0.041451770812273026, -0.008727719075977802, 0.10598211735486984, -0.03152218833565712, -0.03667682781815529, 0.0822567567229271, 0.10401484370231628, 0.04568806663155556, 0.022609982639551163, 0.12081717699766159, 0.14528223872184753, -8.986596367321908e-05, 0.06941986829042435, 0.06800837069749832, -0.0021831702906638384, 0.11345671117305756, 0.20243021845817566, -0.025242522358894348, -0.047543350607156754, 0.032282814383506775, -0.13088177144527435, -0.02278386615216732, 0.06191873922944069, 0.030276935547590256, 0.015432825312018394], metadata={'source': 'AAAMLP-569to.pdf', 'page': 141}, content=\"Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 142 Feature engineering  Feature engineering is one of the most crucial parts of building a good machine learning model. If we have useful features, the model will perform better. There are many situations where you can avoid large, complicated models and use simple models with crucially engineered features. We must keep in mind that feature engineering is something that is done in the best possible manner only when you have some knowledge about the domain of the problem and depends a lot on the data in concern. However, there are some general techniques that you can try to create features from almost all kinds of numerical and categorical variables. Feature engineering is not just about creating new features from data but also includes different types of normalization and transformations.  In the chapter about categorical features, we have seen a way to combine different categorical variables, how we can convert categorical variables to counts, target encoding and using embeddings. These are almost all kinds of ways to engineer features from categorical variables. Thus, in this chapter, our focus will be limited to numerical variables and a combination of numerical and categorical variables.  Let’s start with the most simple but most widely used feature engineering techniques. Let’s say that you are dealing with date and time data. So, we have a pandas dataframe with a datetime type column. Using this column, we can create features like:  - Year - Week of year - Month - Day of week - Weekend - Hour - And many more.  And this can be done using pandas very easily.  ═════════════════════════════════════════════════════════════════════════ df.loc[:, 'year'] = df['datetime_column'].dt.year df.loc[:, 'weekofyear'] = df['datetime_column'].dt.weekofyear df.loc[:, 'month'] = df['datetime_column'].dt.month df.loc[:, 'dayofweek'] = df['datetime_column'].dt.dayofweek\"),\n",
       " VectorParams(vector=[-0.12028861790895462, -0.015047227963805199, 0.05945035442709923, 0.1309569627046585, 0.11167674511671066, -0.07210667431354523, -0.052430443465709686, -0.030026284977793694, -0.08934668451547623, -0.04124836251139641, 0.005772284232079983, -0.11739484965801239, -0.11464521288871765, 0.03330686315894127, 0.10658109933137894, -0.05154841020703316, -0.012874512933194637, -0.07998295873403549, 0.02228475920855999, -0.05543552711606026, 0.026686931028962135, -0.0037153244484215975, 0.03328296169638634, 0.07752397656440735, -0.10977301001548767, -0.017255259677767754, 0.07984030246734619, 0.02155398763716221, -0.03553994372487068, 0.05065825581550598, -0.18867458403110504, 0.23427903652191162, -0.12245507538318634, 0.009147853590548038, -0.04487205669283867, 0.027944393455982208, 0.08697310090065002, 0.07188764214515686, 0.006879100576043129, -0.005573235917836428, 0.03761753439903259, -0.0036700197961181402, 0.05350090190768242, -0.10218651592731476, -0.036306802183389664, -0.012590420432388783, 0.10380478203296661, -0.027543766424059868, -0.041668254882097244, 0.11112670600414276, -0.012168653309345245, 0.15632399916648865, -0.13793320953845978, 0.019662149250507355, 0.12361030280590057, -0.028383394703269005, 0.02247665822505951, -0.10002584010362625, 0.11712507903575897, -0.10819732397794724, -0.09001261740922928, 0.06088562682271004, 0.009538841433823109, -0.08834830671548843, -0.05102715641260147, -0.06794247031211853, -0.10801059007644653, 0.11024341732263565, -0.04217637702822685, 0.1279747039079666, -0.08437920361757278, 0.031575046479701996, -0.12893268465995789, 0.03270093351602554, -0.05865626037120819, 0.05189616233110428, 0.20844361186027527, -0.06566530466079712, 0.10547996312379837, 0.005836030002683401, -0.054352056235075, 0.035976991057395935, -0.026877231895923615, -0.026138441637158394, 0.017786195501685143, -0.13986606895923615, 0.05736352503299713, 0.08208774030208588, 0.012072136625647545, -0.11651588976383209, 0.08861587941646576, -0.03556827828288078, 0.06938426941633224, -0.10194604098796844, 0.06843312084674835, 0.015065385960042477, 0.13070206344127655, -0.034928157925605774, 0.09502813220024109, 0.11573712527751923, -0.022965751588344574, -0.022714128717780113, -0.004323754925280809, -0.05871210992336273, 0.01674310490489006, 0.03127596899867058, -0.005245089530944824, 0.03888944163918495, -0.03966841101646423, -0.07096341252326965, 0.004084596410393715, -0.05048585310578346, -0.03659246489405632, -0.09878640621900558, 0.08522683382034302, -0.022524066269397736, -0.0768352821469307, -0.0680454671382904, -0.021046137437224388, 0.14846758544445038, 0.0520215779542923, 0.08901983499526978, 0.041540805250406265, 0.012607541866600513, -0.01874365843832493, 0.031584855169057846, -0.0033821258693933487, 1.0953672192088678e-32, 0.008269576355814934, -0.02442614920437336, 0.018390025943517685, -0.17442761361598969, -0.0021850811317563057, 0.012454058974981308, 0.08685118705034256, 0.05964009463787079, 0.14672881364822388, 0.09361652284860611, -0.07674278318881989, 0.013098401948809624, -0.08833194524049759, -0.11798720806837082, 0.08661873638629913, -0.0362023189663887, -0.06407398730516434, 0.0460021086037159, 0.05612439289689064, 0.04606954753398895, 0.1697879582643509, -0.13293103873729706, -0.0102455485612154, -0.03945806995034218, -0.005487835966050625, -0.138884499669075, -0.03749004006385803, -0.07055535912513733, -0.0406804122030735, 0.00037816260010004044, -0.09200955182313919, 0.04971315339207649, -0.030623657628893852, 0.0012691522715613246, 0.046296022832393646, -0.11906769126653671, 0.15843366086483002, 0.06373462080955505, 0.0017505219439044595, -0.07203032076358795, -0.019941851496696472, -0.037885550409555435, -0.12229254841804504, -0.1381358802318573, 0.048074278980493546, 0.08763787895441055, 0.15970416367053986, -0.06524921208620071, -0.06027129292488098, 0.11729298532009125, -0.02469778247177601, -0.1793593168258667, 0.09071437269449234, -0.041837774217128754, -0.1338202953338623, 0.1321190595626831, 0.08799394220113754, -0.16810467839241028, 0.06460642069578171, 0.004375789780169725, -0.03792835399508476, -0.05567348003387451, 0.06420110166072845, -0.16647598147392273, -0.08994120359420776, 0.011050555855035782, 0.23716013133525848, 0.2060980498790741, -0.0008743373909965158, -0.05375680327415466, 0.08076146990060806, 0.0165373794734478, -0.040013886988162994, -0.19964684545993805, 0.12015455216169357, -0.15033221244812012, 0.22557103633880615, 0.053901489824056625, -0.10080192983150482, 0.03457609564065933, 0.15433606505393982, 0.026353778317570686, 0.1055162101984024, -0.166862353682518, -0.0026520872488617897, -0.03875388950109482, 0.10915589332580566, 0.03273819014430046, -0.1355505734682083, -0.23610101640224457, -0.20832860469818115, 0.027936818078160286, 0.04243582859635353, 0.036082133650779724, 0.10607054829597473, -1.121851106932894e-32, 0.021670131012797356, -0.17854799330234528, 0.032130174338817596, 0.05696214362978935, 0.08605162799358368, -0.02548723667860031, -0.1255873590707779, 0.0969448909163475, 0.0668482780456543, -0.10191299021244049, -0.07217623293399811, -0.1275949627161026, 0.05998064950108528, -0.07752378284931183, 0.01321377232670784, -0.002079346217215061, -0.03091210313141346, -0.02761327289044857, -0.05457744747400284, 0.1341957151889801, -0.022403333336114883, -0.011376697570085526, -0.0964728519320488, -0.08650901168584824, -0.011005687527358532, 0.04918259009718895, 0.00725538469851017, 0.05923944711685181, 0.00549319526180625, -0.004904654808342457, -0.16204382479190826, -0.06986741721630096, -0.06835618615150452, 0.017300309613347054, -0.013963446021080017, 0.025755926966667175, 0.047808174043893814, -0.08571693301200867, -0.11480561643838882, 0.02129276469349861, 0.11739130318164825, 0.11825859546661377, -0.01857234723865986, -0.017975877970457077, -0.00897182710468769, 0.19619011878967285, -0.05022161453962326, 0.026839807629585266, 0.06288161873817444, 0.02859625779092312, 0.0032146673183888197, -0.019046666100621223, -0.1301419734954834, 0.07766906917095184, -0.07823210954666138, 0.07695195078849792, 0.08268900215625763, -0.10745729506015778, -0.14980922639369965, 0.04463949799537659, -0.08260735124349594, -0.1196526288986206, -0.11159452795982361, 0.025081496685743332, 0.09613259881734848, -0.022688448429107666, -0.039558134973049164, -0.12006062269210815, 0.07381600886583328, -0.07810090482234955, -0.014913735911250114, -0.029977740719914436, 0.013127118349075317, -0.027945611625909805, -0.1414371281862259, 0.08192446827888489, 0.08313968777656555, -0.05187736824154854, -0.04820895940065384, 0.02611869014799595, -0.15789678692817688, -0.09144983440637589, 0.051930807530879974, 0.11428266763687134, -0.2325642853975296, 0.03250895440578461, 0.003201113548129797, 0.04454829543828964, 0.037096403539180756, -0.033700451254844666, -0.056582361459732056, -0.07905859500169754, -0.06808633357286453, 0.18169985711574554, 0.08809714764356613, -1.0009492967810729e-07, -0.029395047575235367, 0.09186994284391403, 0.061735741794109344, -0.08607081323862076, 0.061293382197618484, -0.11528301239013672, 0.061471953988075256, -0.010515796951949596, 0.10680307447910309, 0.04502103850245476, 0.24726340174674988, -0.09205314517021179, -0.05654137581586838, 0.07067834585905075, 0.0044302805326879025, 0.16718164086341858, -0.03567701205611229, -0.0006777311791665852, -0.01677340641617775, 0.001095769228413701, 0.11103178560733795, -0.14372681081295013, 0.08364281058311462, -0.028133954852819443, -0.026677370071411133, 0.05621857941150665, 0.024349814280867577, 0.09182775765657425, 0.15423209965229034, 0.1176275759935379, -0.04271718114614487, -0.06061549857258797, -0.05843564495444298, -0.049654871225357056, 0.057865094393491745, -0.09058376401662827, 0.012088068760931492, -0.024851223453879356, -0.1474991887807846, 0.10588908195495605, -0.0423884354531765, 0.10659527033567429, -0.1249631866812706, -0.03169980272650719, 0.0837184488773346, 0.03855205699801445, 0.0020781022030860186, 0.028258539736270905, 0.15336091816425323, 0.11067428439855576, 0.008352478966116905, -0.017995381727814674, 0.07831420749425888, -0.039275381714105606, 0.12749892473220825, 0.09378485381603241, -0.027160564437508583, -0.009272371418774128, 0.07765526324510574, -0.11546095460653305, 0.0038894691970199347, 0.05090640112757683, -0.00031070836121216416, 0.10452909767627716], metadata={'source': 'AAAMLP-569to.pdf', 'page': 142}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 143 df.loc[:, \\'weekend\\'] = (df.datetime_column.dt.weekday >=5).astype(int) df.loc[:, \\'hour\\'] = df[\\'datetime_column\\'].dt.hour ═════════════════════════════════════════════════════════════════════════  So, we are creating a bunch of new columns using the datetime column. Let’s see some of the sample features that can be created.  ═════════════════════════════════════════════════════════════════════════ import pandas as pd  # create a series of datetime with a frequency of 10 hours s = pd.date_range(\\'2020-01-06\\', \\'2020-01-10\\', freq=\\'10H\\').to_series()  # create some features based on datetime features = {     \"dayofweek\": s.dt.dayofweek.values,     \"dayofyear\": s.dt.dayofyear.values,     \"hour\": s.dt.hour.values,     \"is_leap_year\": s.dt.is_leap_year.values,     \"quarter\": s.dt.quarter.values,     \"weekofyear\": s.dt.weekofyear.values } ═════════════════════════════════════════════════════════════════════════  This will generate a dictionary of features from a given series. You can apply this to any datetime column in a pandas dataframe. These are some of the many date time features that pandas offer. Date time features are critical when you are dealing with time-series data, for example, predicting sales of a store but would like to use a model like xgboost on aggregated features.  Suppose we have a dataframe that looks like the following:  \\n Figure 1: A sample dataframe with categorical and date features'),\n",
       " VectorParams(vector=[0.04514273256063461, -0.09120035916566849, 0.03736643120646477, 0.08021238446235657, -0.09066828340291977, -0.00398853188380599, -0.047670893371105194, -0.08576521277427673, -0.15565422177314758, -0.07291115075349808, 0.2244166135787964, -0.08626990020275116, 0.05153730884194374, -0.08425271511077881, 0.06462083756923676, -0.029468733817338943, -0.03862955793738365, -0.03241272270679474, 0.0007634498178958893, -0.09580689668655396, -0.16098302602767944, 0.06610935181379318, 0.012258964590728283, -0.007055830210447311, -0.05928952246904373, 0.0263951625674963, 0.07597814500331879, 0.04389727860689163, -0.0748831108212471, -0.012884542346000671, -0.21247383952140808, 0.16813956201076508, 0.03265620768070221, 0.008165990002453327, -0.08282679319381714, -0.006138022989034653, -0.03917698562145233, 0.0027577923610806465, 0.0916011780500412, -0.011667509563267231, -0.1152450293302536, -0.07221207022666931, 0.11145314574241638, -0.17428964376449585, -0.004887311719357967, 0.07794927060604095, -0.026227962225675583, 0.03787125274538994, 0.03909134119749069, 0.085505910217762, -0.040446195751428604, 0.10754181444644928, -0.13292112946510315, 0.07132335007190704, 0.12149590253829956, -0.2319120168685913, -0.036400649696588516, -0.22942858934402466, 0.04902750253677368, -0.010140899568796158, -0.1370496302843094, -0.016495365649461746, 0.13276135921478271, -0.03718237578868866, -0.03532540053129196, -0.08127383887767792, -0.10487639904022217, 0.09227924048900604, -0.047253791242837906, 0.06509057432413101, -0.07471425831317902, 0.0049562654457986355, -0.14665767550468445, 0.04114077240228653, -0.03863378241658211, 0.11217696964740753, 0.16630293428897858, -0.044622816145420074, 0.1854432225227356, 0.02522232010960579, -0.21823517978191376, -0.016659870743751526, 0.01873673126101494, 0.09451975673437119, 0.012912483885884285, -0.14516183733940125, 0.03497086837887764, 0.050737787038087845, -0.09232486039400101, -0.13273964822292328, 0.08097808063030243, 0.16084149479866028, 0.057035721838474274, -0.08448701351881027, 0.005405832082033157, 0.005567704327404499, 0.07445931434631348, -0.1447940170764923, 0.04032937437295914, 0.19220829010009766, 0.0010959617793560028, 0.01786908693611622, 0.050580382347106934, -0.0913160964846611, -0.016014764085412025, 0.050554994493722916, 0.12361587584018707, 0.032333388924598694, -0.12812179327011108, -0.03284067660570145, -0.10380753874778748, -0.17273330688476562, -0.08679162710905075, -0.1274435818195343, 0.11500831693410873, -0.1014336571097374, 0.11788012087345123, 0.04641908034682274, 0.11021938174962997, 0.13369011878967285, 1.5057623386383057e-05, 0.19280704855918884, 0.12401489913463593, 0.10278957337141037, 0.10134793072938919, 0.052570343017578125, 0.11365846544504166, 9.842821214353986e-33, -0.054711662232875824, -0.041284773498773575, 0.044858191162347794, -0.08941378444433212, 0.14524686336517334, -0.005408702418208122, 0.1488543599843979, -0.024343963712453842, 0.15465335547924042, 0.0648929551243782, -0.07003212720155716, 0.12360990047454834, 0.010244683362543583, 0.0050633372738957405, 0.11422602832317352, -0.0893908366560936, -0.11661583185195923, 0.020810037851333618, -0.04098018258810043, 0.043056733906269073, 0.17340852320194244, -0.10799820721149445, 0.1757156103849411, 0.063436359167099, -0.028257112950086594, -0.21848613023757935, -0.041606560349464417, 0.020643744617700577, -0.04025444760918617, -0.06755374372005463, 0.013805408962070942, 0.12257357686758041, -0.023668862879276276, -0.11404198408126831, -0.09589742124080658, -0.14526581764221191, 0.17137841880321503, -0.011739660985767841, 0.01595161110162735, 0.09918348491191864, -0.06094739958643913, 0.03258486092090607, 0.002005055546760559, -0.08004648238420486, -0.13664615154266357, 0.18738609552383423, 0.09470584988594055, 0.05159371346235275, -0.05755091831088066, 0.1238512247800827, -0.037153709679841995, -0.27644461393356323, 0.03428024798631668, 0.08238320052623749, -0.1853260099887848, 0.20674607157707214, -0.05985035374760628, -0.18268364667892456, 0.08556698262691498, -0.11941780149936676, -0.05985094606876373, -0.06804408133029938, 0.047009967267513275, -0.01801346428692341, -0.08452054113149643, -0.05185993015766144, 0.1634354591369629, 0.23939281702041626, 0.06154581159353256, 0.04672509804368019, 0.0720440149307251, 0.09403205662965775, -0.02990054339170456, -0.2364553064107895, 0.008484787307679653, -0.034210652112960815, 0.09905894100666046, 0.09881549328565598, -0.12783759832382202, 0.004830240271985531, 0.07728603482246399, 0.12714119255542755, 0.08700355142354965, -0.14803963899612427, 0.06897671520709991, 0.14115342497825623, 0.09534449875354767, 0.011314166709780693, -0.16522905230522156, -0.1228845864534378, -0.2232419103384018, 0.18324950337409973, 0.05134838819503784, -0.10499802231788635, 0.09186597168445587, -1.0474296779615718e-32, -0.11174437403678894, 0.03485681861639023, 0.14250966906547546, 0.07038487493991852, 0.16410085558891296, 0.024330781772732735, -0.1197977364063263, -0.0027993209660053253, -0.03679462522268295, -0.055477872490882874, -0.13180065155029297, -0.08150781691074371, 0.1896710991859436, -0.10099762678146362, 0.047304268926382065, 0.11055532097816467, -0.029591191560029984, -0.028425097465515137, 0.021128997206687927, -0.01472245343029499, -0.0829000174999237, 0.125348299741745, -0.15799297392368317, 0.04284545034170151, -0.12615162134170532, 0.07606576383113861, -0.0643131285905838, -0.026162730529904366, -0.08240726590156555, -0.19156773388385773, -0.034905023872852325, -0.046226367354393005, -0.14179733395576477, 0.02537878416478634, 0.03172135353088379, -0.0817413181066513, 0.00968792662024498, -0.04382248595356941, -0.14580756425857544, 0.09198902547359467, 0.21052277088165283, -0.010431252419948578, -0.0024636927992105484, 0.06590297818183899, 0.05920293554663658, 0.060566436499357224, 0.1097521036863327, -0.02587735652923584, 0.06869740784168243, -0.022105073556303978, -0.0802653580904007, -0.09785277396440506, -0.16911128163337708, 0.0922311320900917, -0.035008419305086136, 0.048499129712581635, 0.14790725708007812, -0.14997471868991852, -0.04031750187277794, 0.012591437436640263, 0.018984604626893997, -0.1471390724182129, -0.1436101496219635, 0.09348934143781662, 0.08781109005212784, -0.1296454221010208, -0.06020534783601761, -0.12533771991729736, -0.01493096724152565, -0.0004995819181203842, -0.15394607186317444, -0.02384495735168457, 0.06433557718992233, -0.12838126718997955, -0.06548883765935898, 0.08880915492773056, 0.036568328738212585, -0.07268445938825607, -0.10670658200979233, -0.010985343717038631, -0.1122952252626419, -0.16983705759048462, 0.07813011854887009, 0.1631300151348114, -0.21341559290885925, -0.10717688500881195, 0.07096558064222336, -0.0458056777715683, 0.04196183755993843, 0.043249793350696564, -0.14140737056732178, -0.01047743484377861, -0.03521312028169632, 0.04821629822254181, 0.01210990734398365, -1.0049379284282622e-07, 0.06495032459497452, 0.03131098300218582, -0.041933197528123856, -0.10207825899124146, 0.055957287549972534, -0.05587898939847946, 0.021071407943964005, 0.046818237751722336, -0.05889984965324402, -0.01194782555103302, 0.21253816783428192, -0.01087164506316185, -0.031293466687202454, 0.1538110226392746, -0.02088506892323494, 0.20682598650455475, -0.07533910870552063, 0.07593750953674316, 0.01490273978561163, -0.004621795378625393, 0.016459010541439056, -0.13856622576713562, 0.11472894996404648, -0.06736008822917938, 0.021894359961152077, 0.06734761595726013, 0.10126960277557373, 0.0775538757443428, 0.14826162159442902, 0.01769629493355751, -0.10357468575239182, -0.13415321707725525, 0.016223883256316185, -0.18638858199119568, 0.17849959433078766, -0.11117143929004669, -0.05122756585478783, -0.10612216591835022, -0.14288583397865295, 0.00567774660885334, -0.06038535386323929, 0.13550636172294617, 0.04478619247674942, -0.01615019142627716, 0.10136464238166809, 0.08525282889604568, 0.005415268708020449, 0.021993372589349747, 0.1433754414319992, 0.12684915959835052, -0.09550118446350098, -0.02655189111828804, 0.14773398637771606, -0.0075583551079034805, 0.06963703781366348, 0.11304688453674316, -0.017127927392721176, 0.006758911535143852, 0.1388436257839203, -0.08008086681365967, -0.012164482846856117, 0.0007263962179422379, 0.0029678340069949627, 0.02164812944829464], metadata={'source': 'AAAMLP-569to.pdf', 'page': 143}, content=\"Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 144 In figure 1, we see that we have a date column, and we can easily extract features like the year, month, quarter, etc. from that. Then we have a customer_id column which has multiple entries, so a customer is seen many times (not visible in the screenshot). And each date and customer id has three categorical and one numerical feature attached to it. There are a bunch of features we can create from it:  - What’s the month a customer is most active in - What is the count of cat1, cat2, cat3 for a customer - What is the count of cat1, cat2, cat3 for a customer for a given week of the year - What is the mean of num1 for a given customer - And so on.  Using aggregates in pandas, it is quite easy to create features like these. Let’s see how.  ═════════════════════════════════════════════════════════════════════════ def generate_features(df):     # create a bunch of features using the date column     df.loc[:, 'year'] = df['date'].dt.year     df.loc[:, 'weekofyear'] = df['date'].dt.weekofyear     df.loc[:, 'month'] = df['date'].dt.month     df.loc[:, 'dayofweek'] = df['date'].dt.dayofweek     df.loc[:, 'weekend'] = (df['date'].dt.weekday >=5).astype(int)          # create an aggregate dictionary     aggs = {}     # for aggregation by month, we calculate the     # number of unique month values and also the mean     aggs['month'] = ['nunique', 'mean']     aggs['weekofyear'] = ['nunique', 'mean']     # we aggregate by num1 and calculate sum, max, min      # and mean values of this column     aggs['num1'] = ['sum','max','min','mean']     # for customer_id, we calculate the total count     aggs['customer_id'] = ['size']     # again for customer_id, we calculate the total unique     aggs['customer_id'] = ['nunique']          # we group by customer_id and calculate the aggregates     agg_df = df.groupby('customer_id').agg(aggs)     agg_df = agg_df.reset_index()     return agg_df ═════════════════════════════════════════════════════════════════════════\"),\n",
       " VectorParams(vector=[-0.08821173757314682, -0.02048892341554165, 0.04558076709508896, 0.08199458569288254, -0.01833765022456646, 0.06466686725616455, -0.013937713578343391, -0.014149241149425507, -0.020343594253063202, -0.11904165148735046, 0.10265643894672394, -0.023157674819231033, -0.0345783568918705, 0.010112451389431953, 0.0729825496673584, -0.03093666024506092, 0.04587985947728157, 0.019315732643008232, -0.024955928325653076, -0.08071530610322952, -0.0780961886048317, 0.016473012045025826, -0.06905165314674377, 0.03369868919253349, -0.013585095293819904, 0.07995995134115219, 0.0832463726401329, 0.08262357860803604, -0.022656260058283806, 0.01833200454711914, -0.008424509316682816, 0.06788953393697739, 0.02284805290400982, 0.003089296165853739, -0.11859967559576035, -0.013907558284699917, -0.07185452431440353, 0.09570305049419403, -0.03933604061603546, -0.1334981620311737, 0.01019497960805893, -0.12933437526226044, 0.004085958935320377, 0.0789448544383049, 0.11610235273838043, 0.03566015884280205, 0.0640828087925911, 0.017045877873897552, -0.06429141759872437, 0.016442589461803436, -0.06665732711553574, 0.07737953960895538, 0.053926020860672, 0.05841837078332901, 0.016583630815148354, -0.08963649719953537, -0.027470484375953674, -0.10190761834383011, 0.024205872789025307, -0.07789487391710281, -0.05314132198691368, -0.058261048048734665, 0.06860531866550446, -0.059853944927453995, -0.01821008138358593, 0.005016010254621506, -0.04618047922849655, 0.10734318196773529, -0.04889402166008949, 0.061045631766319275, -0.0007986752898432314, 0.020079508423805237, -0.16943009197711945, 0.020151933655142784, -0.009196901693940163, 0.08149862289428711, 0.19523917138576508, -0.028740858659148216, 0.055939435958862305, 0.04151788353919983, -0.08863035589456558, -0.00044460227945819497, -0.0010529732098802924, -0.006205346900969744, 0.024886449798941612, -0.014400394633412361, 0.03854553401470184, 0.07015444338321686, -0.1850021779537201, -0.05470602586865425, 0.05711131542921066, 0.08170740306377411, 0.15201154351234436, -0.15266892313957214, 0.04596363753080368, 0.08317454159259796, 0.08630796521902084, -0.12432264536619186, 0.12260789424180984, 0.07998596131801605, -0.021700838580727577, 0.0804169625043869, 0.0963539406657219, -0.01897345669567585, 0.025609439238905907, -0.03963501751422882, 0.04846956953406334, 0.03990620747208595, -0.07532907277345657, -0.08877437561750412, -0.048273757100105286, -0.0795709565281868, -0.08954919874668121, -0.16971948742866516, 0.06496544927358627, -0.09575336426496506, -0.032639484852552414, -0.0027336410712450743, 0.018794363364577293, 0.09478769451379776, 0.0007521937950514257, 0.049776557832956314, -0.02933996543288231, 0.06366989016532898, 0.05577683821320534, 0.08698394894599915, -0.06929777562618256, 8.951435766601783e-33, 0.011861821636557579, -0.1019330769777298, -0.07925987988710403, -0.07603593915700912, 0.05647499859333038, -0.054719842970371246, -0.027413135394454002, 0.03273126855492592, 0.12653657793998718, 0.08826839923858643, -0.038793157786130905, 0.010919071733951569, -0.02389436401426792, 0.033468957990407944, 0.05741296708583832, 0.028193343430757523, -0.02872597984969616, -0.005672612227499485, 0.042438507080078125, -0.05803632363677025, 0.06108253821730614, -0.09081051498651505, 0.08605633676052094, 0.07316503673791885, -0.017442965880036354, -0.029969271272420883, 0.030336033552885056, 0.00842428021132946, -0.017878180369734764, -0.004402650520205498, -0.03895232081413269, 0.06587833166122437, -0.050185076892375946, -0.0008255198481492698, -0.015451987273991108, -0.03687892481684685, 0.01840898022055626, -0.06015462428331375, 0.029454654082655907, -0.0028812838718295097, -0.06938628852367401, 0.017073210328817368, -0.046971261501312256, 0.06224694103002548, -0.03308110311627388, 0.11475485563278198, 0.032876964658498764, 0.014828252606093884, -0.14074411988258362, 0.14027376472949982, -0.07157979905605316, -0.1276470422744751, -0.028140773996710777, -0.022145435214042664, -0.11783146858215332, 0.15444862842559814, -0.06918137520551682, -0.1738203465938568, -0.12103919684886932, -0.03727375715970993, -0.056263744831085205, -0.009382263757288456, 0.023394139483571053, -0.10299425572156906, -0.0903545394539833, -0.005698108114302158, 0.0900532454252243, 0.10669944435358047, 0.10803581029176712, -0.00011331354471622035, 0.10457807034254074, 0.057370059192180634, -0.04992351680994034, -0.038557268679142, 0.12372332811355591, -0.029241202399134636, 0.1587163507938385, 0.0026207640767097473, -0.08886393904685974, 0.04382725805044174, 0.08640477061271667, 0.017251739278435707, 0.1298029124736786, -0.008983638137578964, 0.10198894143104553, 0.1247064471244812, 0.10108070820569992, -0.049471400678157806, -0.14238543808460236, -0.07234761118888855, -0.2504543960094452, 0.1496133655309677, 0.035846248269081116, 0.08294931799173355, 0.06808667629957199, -1.0240509320336397e-32, -0.06372633576393127, 0.049434345215559006, -0.027388663962483406, -0.010588191449642181, 0.013825196772813797, 0.060446906834840775, -0.13094483315944672, -0.025141088292002678, 0.010335643775761127, -0.06518138200044632, -0.0784953385591507, -0.07289337366819382, 0.09700287878513336, -0.08518014848232269, -0.0688987448811531, 0.06254352629184723, -0.08114024996757507, -0.12376321107149124, 0.057864703238010406, 0.09799224138259888, -0.1103825569152832, 0.05246589332818985, -0.08402753621339798, 0.10219871997833252, -0.0627739205956459, -0.006327139679342508, -0.09573493897914886, -0.039873603731393814, -0.10763882845640182, -0.04523187130689621, -0.03825024515390396, -0.07017319649457932, 0.01321393996477127, -0.0689321905374527, 0.036142852157354355, -0.05160454288125038, -0.020870789885520935, -0.13062599301338196, -0.02018885873258114, 0.03589775413274765, 0.13916897773742676, 0.026042677462100983, -0.04533909261226654, 0.016953032463788986, -0.009649418294429779, 0.002400689059868455, 0.062307748943567276, 0.014717708341777325, 0.10584597289562225, 0.02418527752161026, -0.03665097802877426, 0.003544335486367345, -0.04585186019539833, 0.017641667276620865, 0.004082044120877981, 0.0830850675702095, 0.16190364956855774, -0.0922405943274498, 0.033411428332328796, 0.1163824051618576, -0.035710640251636505, -0.06655599921941757, 0.06896218657493591, 0.047849614173173904, 0.09154699742794037, -0.11765757203102112, 0.015678780153393745, -0.09341032803058624, -0.021594742313027382, -0.11778977513313293, -0.036780454218387604, 0.003694028127938509, 0.01230529136955738, -0.008031442761421204, -0.05669473856687546, -0.11729145795106888, -0.02286411076784134, -0.11557598412036896, -0.0692007839679718, -0.01212612446397543, -0.003663169452920556, -0.025577455759048462, 0.0625898614525795, 0.036429423838853836, -0.07126856595277786, 0.005786726251244545, 0.10606787353754044, 0.06923136115074158, 0.044142838567495346, -0.05846628174185753, -0.11450789868831635, 0.09453412890434265, -0.096223846077919, 0.09441759437322617, -0.013672510161995888, -9.967556735546168e-08, -0.02549670822918415, 0.0741531029343605, -0.013390759937465191, -0.030052337795495987, 0.056081078946590424, -0.07494861632585526, 0.01005821768194437, 0.03631291165947914, 0.008358555845916271, 0.021828150376677513, 0.054816246032714844, 0.06672075390815735, -0.13354316353797913, 0.04038830101490021, 0.026172656565904617, 0.1465102732181549, 0.019781142473220825, -0.02388402633368969, -0.027593938633799553, -0.05121997743844986, 0.1473073959350586, -0.045989684760570526, 0.01721579022705555, -0.10810180008411407, 0.04259210824966431, -0.04862208664417267, 0.06675156205892563, 0.12239892035722733, 0.1409212201833725, 0.054225243628025055, -0.07986230403184891, -0.03184724599123001, -0.019117265939712524, -0.02586399018764496, 0.10528989881277084, 0.025862252339720726, 0.04013946279883385, -0.11496096104383469, -0.0936126708984375, -0.09426344931125641, -0.054126713424921036, 0.08265420794487, -0.07959489524364471, 0.009644058533012867, -0.0036193770356476307, 0.019499631598591805, -0.03838438540697098, -0.017585396766662598, 0.044714514166116714, 0.12634170055389404, 0.016357826068997383, 0.006915205158293247, 0.10975858569145203, 0.0975617989897728, 0.1219508945941925, 0.02835964411497116, 0.05722125992178917, -0.05235471948981285, 0.09563453495502472, -0.05870329961180687, -0.012111850082874298, -0.03391827270388603, -0.06867262721061707, -0.020385760813951492], metadata={'source': 'AAAMLP-569to.pdf', 'page': 144}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 145 Please note that in the above function, we have skipped the categorical variables, but you can use them in the same way as other aggregates.  \\n Figure 2: Aggregate and other features  Now, we can join this dataframe in figure 2 with the original dataframe with customer_id column to start training a model. Here, we are not trying to predict anything; we are just creating generic features. However, it would have been easier to create features if we were trying to predict something here.  Sometimes, for example, when dealing with time-series problems, you might have features which are not individual values but a list of values. For example, transactions by a customer in a given period of time. In these cases, we create different types of features such as: with numerical features, when you are grouping on a categorical column, you will get features like a list of values which are time distributed. In these cases, you can create a bunch of statistical features such as:  - Mean - Max - Min - Unique - Skew - Kurtosis - Kstat - Percentile - Quantile'),\n",
       " VectorParams(vector=[-0.08775120228528976, -0.06310626119375229, 0.09813980758190155, -0.031817056238651276, -0.035746484994888306, -0.10563510656356812, -0.0022701332345604897, 0.07305729389190674, -0.09284649789333344, -0.0010361502645537257, -0.07806815207004547, -0.0724654272198677, 0.011805322952568531, -0.006522660609334707, 0.11419336497783661, 0.0354839451611042, -0.0695439949631691, 0.04176900535821915, 0.031047195196151733, -0.11557416617870331, 0.031416524201631546, 0.16103824973106384, -0.10537631064653397, 0.0640760064125061, 0.06335601210594177, 0.031028635799884796, 0.06189780682325363, 0.07012529671192169, -0.03999491408467293, 0.03224097937345505, -0.06256644427776337, -0.014184737578034401, 0.040847647935152054, -0.05472204461693764, -0.044817883521318436, 0.03625645488500595, -0.04518406465649605, 0.02864927425980568, -0.0896001085639, -0.023167068138718605, 0.026767093688249588, -0.022998498752713203, -0.09404713660478592, -0.029387829825282097, 0.15199734270572662, 0.04656523838639259, -0.003925866913050413, -0.11627897620201111, -0.013735953718423843, -0.0007490041898563504, -0.002086807042360306, 0.15274210274219513, -0.0663360208272934, 0.026232561096549034, -0.026261309161782265, -0.06615718454122543, 0.035632211714982986, -0.15690825879573822, 0.19149301946163177, -0.13172562420368195, -0.043661221861839294, -0.0456494502723217, 0.08407971262931824, -0.0863146036863327, 0.08330319076776505, 0.017426492646336555, -0.044552598148584366, 0.09048234671354294, 0.007557430304586887, 0.05065930634737015, -0.027324967086315155, 0.06455543637275696, -0.021910453215241432, -0.016680724918842316, 0.006308095064014196, -0.06033696234226227, 0.10020618885755539, -0.02027682028710842, -0.06474068760871887, 0.014690859243273735, -0.01787237636744976, 0.01748397760093212, -0.014148619957268238, -0.11042332649230957, -0.005928454454988241, -0.11639457195997238, 0.0770123153924942, 0.1693815439939499, -0.055596936494112015, -0.03666771948337555, 0.03779725357890129, 0.0581461638212204, -0.10649363696575165, -0.08838063478469849, 0.013610362075269222, 0.1585512012243271, 0.07233155518770218, -0.11078960448503494, 0.11506064981222153, 0.05084511265158653, -0.06450027227401733, -0.07334733009338379, 0.004218021407723427, -0.010908610187470913, 0.0851021334528923, -0.04730787128210068, 0.1274292916059494, -0.022596802562475204, 0.004046945832669735, -0.0824710801243782, -0.1009906753897667, -0.07359160482883453, -0.08307899534702301, -0.07297445833683014, 0.1671748012304306, 0.05978623405098915, -0.0830141007900238, 0.04626159369945526, -0.009453429840505123, 0.10308696329593658, 0.009259494952857494, -0.052180830389261246, 0.0034828740172088146, 0.211593359708786, 0.04801845923066139, 0.07973238080739975, -0.08084186911582947, 1.6172508583962634e-32, -0.11533022671937943, 0.043706487864255905, 0.013407275080680847, -0.16358834505081177, 0.031128790229558945, 0.017991986125707626, 0.0016021673800423741, -0.046231456100940704, -0.004007305484265089, 0.014257125556468964, -0.11712858080863953, 0.07451383769512177, -0.07315937429666519, -0.03265700116753578, 0.02822089195251465, -0.15258300304412842, -0.0020889551378786564, 0.015302794054150581, 0.06822823733091354, -0.10645171254873276, 0.060694217681884766, -0.05736169219017029, 0.04965798556804657, 0.06341253966093063, -0.13257870078086853, -0.013224068097770214, -0.029907234013080597, -0.027484659105539322, -0.12017997354269028, -0.018492212519049644, -0.020575618371367455, 0.11532361060380936, -0.006902569904923439, -0.09912993013858795, 0.019921008497476578, -0.11440732330083847, 0.07641270756721497, 0.09103363752365112, 0.09182438254356384, -0.03395357355475426, -0.03124261647462845, 0.02610785886645317, -0.007992230355739594, 0.04725221171975136, -0.046455975621938705, 0.0647040456533432, 0.07559924572706223, -0.026287231594324112, -0.050814636051654816, 0.06232874095439911, -0.14084412157535553, -0.14280979335308075, -0.024095628410577774, -0.007475530728697777, -0.10313519090414047, 0.097930908203125, 0.08544888347387314, -0.08610840141773224, 0.05178506672382355, 0.005463697016239166, 0.026368407532572746, -0.010404746048152447, 0.02269127033650875, -0.12475176155567169, -0.01443369872868061, 0.01942858286201954, 0.1390303671360016, 0.195173442363739, 0.0842185914516449, 0.1444905400276184, 0.0518452450633049, 0.09530763328075409, -0.012546366080641747, -0.18472996354103088, 0.06353027373552322, -0.062315501272678375, 0.18453751504421234, 0.07060244679450989, -0.051498088985681534, -0.07927282154560089, 0.024667255580425262, -0.007779004983603954, 0.0018761161481961608, -0.20676521956920624, 0.11133620142936707, -0.06197110936045647, -0.019614413380622864, -0.07405934482812881, -0.17353969812393188, -0.16493827104568481, -0.21468833088874817, 0.12072627246379852, 0.06323933601379395, 0.05532441660761833, -0.15961715579032898, -1.5385622379946625e-32, 0.0702601745724678, 0.08895942568778992, 0.07211095839738846, 0.12061698734760284, 0.04646790400147438, 0.057394448667764664, -0.11385373771190643, 0.07933221012353897, 0.02722795307636261, -0.10542517155408859, 0.017221303656697273, -0.1990220695734024, 0.11892061680555344, -0.06008417531847954, 0.05578727275133133, 0.12570570409297943, 0.02747025340795517, 0.0454549603164196, -0.04383091256022453, 0.03525850549340248, -0.07000340521335602, 0.0036277456674724817, -0.10373847186565399, -0.08684100210666656, -0.10884565860033035, 0.005634970963001251, -0.08347070217132568, -0.011986960656940937, 0.054006800055503845, -0.14265047013759613, -0.20209653675556183, 0.11048519611358643, -0.10034927725791931, -0.016815008595585823, -0.043280087411403656, 0.012955021113157272, 0.03925143927335739, -0.12429908663034439, -0.03680257126688957, -0.03920504078269005, 0.24932357668876648, 0.09133775532245636, -0.03688691556453705, -0.11307189613580704, 0.04289354011416435, 0.11803702265024185, 0.05913562700152397, 0.055605486035346985, -0.038665883243083954, 0.013144799508154392, 0.08419544249773026, 0.05397509038448334, -0.059281591325998306, 0.11022382974624634, -0.10265921801328659, 0.07974663376808167, -0.05159779638051987, -0.05010554566979408, -0.11286208033561707, -0.08767126500606537, 0.03127440810203552, -0.14938704669475555, -0.039105597883462906, 0.025138970464468002, 0.058565884828567505, 0.037437889724969864, -0.00379424006678164, -0.07750207930803299, -0.05475010350346565, 0.0356488861143589, -0.053774043917655945, -0.018765531480312347, 0.09007967263460159, -0.1555185616016388, -0.14667734503746033, -0.03854621201753616, -0.051680948585271835, -0.08018698543310165, -0.08051982522010803, -0.010068660601973534, -0.03381025418639183, 0.06871314346790314, 0.053126540035009384, 0.03752056881785393, -0.09774002432823181, 0.08415386080741882, 0.03234362602233887, 0.07192123681306839, 0.1529082953929901, -0.09323464334011078, -0.05089204013347626, 0.07290390133857727, -0.016000261530280113, 0.10550358146429062, 0.11860854178667068, -1.0033428310407544e-07, -0.062246717512607574, 0.026816710829734802, -0.0197145976126194, -0.0021175462752580643, 0.18567803502082825, 0.08319712430238724, -0.023560848087072372, 0.023959683254361153, -0.015202654525637627, -0.09273014217615128, 0.14222145080566406, -0.11291082203388214, -0.06619402021169662, 0.00024873894290067255, -0.06584040820598602, 0.17847347259521484, 0.006183923222124577, 0.012117891572415829, 0.05328959971666336, -0.02798575721681118, -0.04775244742631912, 0.03674958646297455, 0.12365050613880157, -0.027455871924757957, -0.053880225867033005, 0.04205982759594917, -0.018549185246229172, -0.06150390952825546, 0.12249335646629333, 0.020996669307351112, -0.07188085466623306, -0.17786064743995667, -0.004571808967739344, -0.0213787779211998, 0.20693323016166687, 0.05305681750178337, -0.03608456254005432, 0.031246328726410866, -0.06437627971172333, 0.0682167336344719, -0.10731247812509537, 0.11173510551452637, -0.09628373384475708, 0.044813234359025955, 0.04344771057367325, 0.06418928503990173, 0.07112543284893036, 0.04163230583071709, 0.20117808878421783, 0.02124347910284996, 0.14241355657577515, -0.020226413384079933, 0.019375087693333626, -0.08230024576187134, 0.017528777942061424, 0.14694547653198242, -0.07169483602046967, 0.03601349890232086, -0.07856674492359161, -0.08699612319469452, 0.10138197243213654, 0.005556988995522261, -0.028246305882930756, 0.042001873254776], metadata={'source': 'AAAMLP-569to.pdf', 'page': 145}, content=\"Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 146 - Peak to peak - And many more  These can be created using simple numpy functions, as shown in the following python snippet.  ═════════════════════════════════════════════════════════════════════════ import numpy as np  feature_dict = {}  # calculate mean feature_dict['mean'] = np.mean(x)  # calculate max feature_dict['max'] = np.max(x)  # calculate min feature_dict['min'] = np.min(x)  # calculate standard deviation feature_dict['std'] = np.std(x)  # calculate variance feature_dict['var'] = np.var(x)  # peak-to-peak feature_dict['ptp'] = np.ptp(x)  # percentile features feature_dict['percentile_10'] = np.percentile(x, 10) feature_dict['percentile_60'] = np.percentile(x, 60) feature_dict['percentile_90'] = np.percentile(x, 90)  # quantile features feature_dict['quantile_5'] = np.quantile(x, 0.05) feature_dict['quantile_95'] = np.quantile(x, 0.95) feature_dict['quantile_99'] = np.quantile(x, 0.99) ═════════════════════════════════════════════════════════════════════════  The time series data (list of values) can be converted to a lot of features.   A python library called tsfresh is instrumental in this case.\"),\n",
       " VectorParams(vector=[-0.06843801587820053, -0.031388625502586365, 0.021832933649420738, 0.08270443230867386, 0.03730567917227745, -0.09679874777793884, -0.031236832961440086, -0.07266494631767273, -0.017990827560424805, -0.012290156446397305, 0.011246852576732635, -0.16246868669986725, 0.062403708696365356, -0.03239999711513519, 0.11461205780506134, 0.1068076565861702, -0.013418326154351234, 0.021022256463766098, 0.03495333343744278, -0.05703263357281685, 0.10078137367963791, 0.14467094838619232, -0.008695431984961033, 0.07126087695360184, 0.1283886432647705, -0.053668390959501266, -0.03342222422361374, 0.18336409330368042, 0.011470455676317215, 0.04194291681051254, -0.04635824263095856, 0.12274658679962158, -0.03292381390929222, -0.055250559002161026, -0.01646895334124565, 0.04989590123295784, -0.047634776681661606, 0.13500812649726868, -0.15847373008728027, 0.022942284122109413, -0.04929954186081886, -0.031909599900245667, 0.10884232819080353, 0.04323772341012955, 0.07521044462919235, 0.09236912429332733, 0.023630715906620026, -0.16625964641571045, 0.037529680877923965, -0.057218048721551895, 0.009806470945477486, 0.21329432725906372, -0.1672072857618332, 0.08905497938394547, 0.08245690912008286, -0.19169864058494568, 0.09016174077987671, -0.06110053136944771, 0.05891188606619835, -0.1054418534040451, -0.044404491782188416, -0.052535392343997955, 0.1059490442276001, -0.07213211059570312, -0.010862557217478752, 0.013660762459039688, -0.11557299643754959, 0.0908779427409172, 0.03973188251256943, 0.05546284094452858, -0.05164560303092003, 0.0800134688615799, -0.09844228625297546, -0.1482720673084259, 0.023945970460772514, -0.04415176436305046, 0.115290567278862, 0.007624176796525717, -0.013380652293562889, -0.011805066838860512, -0.07149007171392441, -0.046858303248882294, 0.06907382607460022, -0.06118553504347801, 0.0006179089541547, -0.07993277907371521, 0.16507045924663544, 0.05207381024956703, -0.0416213721036911, 0.0687866061925888, 0.023727979511022568, 0.06421720236539841, 0.06853983551263809, -0.07561906427145004, 0.02171819657087326, 0.10861153900623322, 0.13346324861049652, -0.1640748530626297, 0.07315873354673386, 0.09725306183099747, -0.06945446878671646, -0.08084866404533386, 0.010250234045088291, 0.03351747244596481, 0.06770243495702744, -0.026441844180226326, 0.07142314314842224, -0.02798626944422722, 0.07779403030872345, -0.11061105132102966, 0.019242379814386368, -0.09008096158504486, -0.1407916396856308, -0.041265204548835754, 0.06475039571523666, -0.0025636868085712194, -0.03019171766936779, 0.015608740970492363, 0.02331962250173092, 0.07742170989513397, -0.023881249129772186, -0.026042480021715164, 0.08074090629816055, 0.11305202543735504, 0.07953885197639465, -0.07370367646217346, -0.050670042634010315, 8.702961974776876e-33, -0.0789235457777977, -0.057716600596904755, -0.013367642648518085, -0.10216199606657028, 0.09569000452756882, -0.013224348425865173, 0.06334761530160904, 0.010947084985673428, 0.09885994344949722, 0.12873651087284088, -0.07896754145622253, 0.1902771145105362, -0.0138670289888978, 0.032585468143224716, 0.12491175532341003, -0.18606123328208923, 0.06529473513364792, -0.0750039741396904, 0.16038000583648682, -0.03082236275076866, 0.13341662287712097, -0.0678195208311081, 0.06659674644470215, -0.0351279117166996, -0.12240567803382874, 0.013745428994297981, -0.09652845561504364, 0.021508531644940376, -0.11987843364477158, -0.029275426641106606, -0.11544588208198547, 0.07492460310459137, -0.08875636756420135, -0.06089336425065994, -0.12228552252054214, -0.10146000981330872, 0.0964953675866127, -0.04310263693332672, 0.014687620103359222, -0.032594721764326096, 0.0935722216963768, 0.03803884610533714, 0.03130926564335823, -0.01080580335110426, -0.008638335391879082, 0.08206906914710999, 0.14350517094135284, 0.027232259511947632, -0.053936365991830826, 0.14019827544689178, -0.1335495412349701, -0.10128047317266464, 0.0035788032691925764, -0.034194644540548325, -0.1058536022901535, -0.006923595909029245, -0.015428228303790092, -0.0054067522287368774, -0.000505526433698833, -0.017639974132180214, -0.07265022397041321, -0.003666846314445138, 0.020632335916161537, -0.10617133975028992, -0.047888897359371185, 0.03526033088564873, 0.07850424200296402, 0.1158248782157898, 0.12110049277544022, 0.10518968850374222, -0.04159466177225113, 0.05115008354187012, -0.058799341320991516, -0.23720702528953552, 0.13772399723529816, 0.009164208546280861, 0.051094502210617065, -0.09297662228345871, -0.1603330820798874, -0.05804278701543808, 0.052311863750219345, 0.09662340581417084, 0.06535065174102783, -0.1541382074356079, -0.004320906940847635, -0.013711807318031788, -0.051897644996643066, -0.06655091047286987, -0.15508955717086792, -0.22660838067531586, -0.29860273003578186, 0.054234229028224945, 0.12234223634004593, 0.031184712424874306, -0.03424619138240814, -1.1672172542877662e-32, -0.06461571902036667, -0.006121458485722542, 0.05069487914443016, 0.10614462941884995, 0.14701105654239655, 0.04507838934659958, -0.0363541841506958, -0.048415228724479675, 0.042535651475191116, -0.09822775423526764, -0.053832489997148514, -0.17571063339710236, -0.005737514700740576, -0.16085265576839447, 0.05022364482283592, 0.063217893242836, -0.110568106174469, 0.035473812371492386, -0.04771034047007561, 0.09390608221292496, -0.08545011281967163, 0.2170940488576889, -0.15323583781719208, -0.021648576483130455, -0.1443261355161667, 0.08072139322757721, -0.016140077263116837, -0.10012780129909515, 0.011575521901249886, -0.07944741100072861, -0.20730489492416382, 0.011258706450462341, -0.15751489996910095, 0.08039113879203796, -0.09381964802742004, -0.10936387628316879, 0.0763377994298935, -0.11710044741630554, -0.13997073471546173, 0.13258060812950134, 0.1708519011735916, 0.18974800407886505, -0.01678817719221115, 0.08655218780040741, 0.026506107300519943, 0.03140128031373024, -0.030209582298994064, -0.019461169838905334, 0.07757008075714111, -0.005366021301597357, 0.11624642461538315, -0.02352438122034073, -0.14916957914829254, 0.04499133676290512, -0.1274738758802414, 0.0835140123963356, -0.08414909243583679, -0.01395756471902132, -0.08514999598264694, -0.0359097495675087, -0.0951460525393486, -0.1998307853937149, 0.07975425571203232, 0.06798330694437027, 0.07838283479213715, 0.1509643942117691, -0.10006175935268402, -0.08034589141607285, -0.04400668293237686, -0.02148853801190853, -0.059390075504779816, -0.09333497285842896, -0.05048520117998123, -0.06936206668615341, -0.07108119130134583, -0.01342299859970808, 0.039729222655296326, -0.19016395509243011, -0.10844594240188599, 0.01609177328646183, -0.0047258310951292515, -0.0034404508769512177, 0.08933372050523758, 0.06849606335163116, -0.056012727320194244, -0.003778853453695774, 0.02060031332075596, 0.0030213212594389915, 0.11038669943809509, -0.07685277611017227, 0.0031771743670105934, 0.10143182426691055, 0.006749809719622135, 0.2643800377845764, 0.1150943711400032, -1.0055091337335398e-07, -0.05265091359615326, 0.03618782386183739, -0.04177580773830414, 0.008663169108331203, 0.07433534413576126, 0.011325397528707981, -0.07495053112506866, -0.02848358079791069, -0.007224715314805508, -0.09582196921110153, 0.10728979110717773, -0.006409342400729656, 0.021052764728665352, 0.09774180501699448, 0.01847551390528679, 0.18632200360298157, 0.01918596401810646, -0.05679664760828018, 0.02330615743994713, -0.08106846362352371, -0.02024090476334095, -0.10717981308698654, -0.04008569195866585, -0.08329401165246964, 0.004808016121387482, -0.10122012346982956, -0.029245620593428612, -0.03979681432247162, 0.16521821916103363, 0.12447170913219452, -0.08689036965370178, -0.17254012823104858, 0.05638726055622101, 0.024784427136182785, 0.2141902893781662, 0.04245825484395027, 0.05561286583542824, -0.08853078633546829, -0.06045060232281685, 0.0723436176776886, -0.08786250650882721, 0.07517366111278534, -0.05535919964313507, 0.02416440285742283, 0.01982717774808407, -0.03038826957345009, 0.013618563301861286, -0.10214725136756897, 0.14067965745925903, 0.13486090302467346, 0.16133196651935577, 0.09226689487695694, -0.04123866185545921, -0.007073072250932455, 0.06555358320474625, 0.0721656009554863, -0.15401051938533783, -0.07141526788473129, 0.023259343579411507, -0.11784229427576065, 0.13240817189216614, -0.04948010295629501, 0.05425646901130676, -0.0737471729516983], metadata={'source': 'AAAMLP-569to.pdf', 'page': 146}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 147 ═════════════════════════════════════════════════════════════════════════ from tsfresh.feature_extraction import feature_calculators as fc  # tsfresh based features feature_dict[\\'abs_energy\\'] = fc.abs_energy(x) feature_dict[\\'count_above_mean\\'] = fc.count_above_mean(x) feature_dict[\\'count_below_mean\\'] = fc.count_below_mean(x) feature_dict[\\'mean_abs_change\\'] = fc.mean_abs_change(x) feature_dict[\\'mean_change\\'] = fc.mean_change(x) ═════════════════════════════════════════════════════════════════════════  This is not all; tsfresh offers hundreds of features and tens of variations of different features that you can use for time series (list of values) based features. In the examples above, x is a list of values. But that’s not all. There are many other features that you can create for numerical data with or without categorical data. A simple way to generate many features is just to create a bunch of polynomial features. For example, a second-degree polynomial feature from two features “a” and “b” would include: “a”, “b”, “ab”, “a2” and “b2”.  ═════════════════════════════════════════════════════════════════════════ import numpy as np  # generate a random dataframe with  # 2 columns and 100 rows df = pd.DataFrame(     np.random.rand(100, 2),     columns=[f\"f_{i}\" for i in range(1, 3)] ) ═════════════════════════════════════════════════════════════════════════  Which gives a dataframe, as shown in figure 3.  \\n Figure 3: A random dataframe with two numerical features'),\n",
       " VectorParams(vector=[0.03130057081580162, -0.11479836702346802, -0.06158505752682686, -0.07954477518796921, 0.1666153520345688, -0.06576792150735855, -0.10087926685810089, -0.1236228346824646, -0.17026042938232422, -0.03220106288790703, 0.039490148425102234, -0.147452250123024, -0.08940096199512482, 0.002097122371196747, 0.14875321090221405, 0.1555933654308319, -0.15504179894924164, 0.06481822580099106, 0.06286182254552841, -0.026856238022446632, 0.053685542196035385, 0.011746861040592194, -0.046218886971473694, -0.03599228709936142, 0.1319875419139862, -0.017529932782053947, -0.00221800385043025, 0.10893400013446808, -0.14285032451152802, 0.11383119225502014, 0.03743357211351395, 0.13254579901695251, 0.010526665486395359, -0.05463830381631851, 0.007113783620297909, 0.0926617756485939, -0.15581339597702026, 0.17303797602653503, -0.1397497057914734, 0.11329089850187302, 0.168792724609375, -0.16121499240398407, 0.1888449639081955, -0.020452525466680527, 0.1242041140794754, 0.1499025672674179, -0.14211782813072205, -0.04004431515932083, 0.14636722207069397, -0.16012464463710785, -0.00657778000459075, 0.04520566761493683, -0.06441272050142288, 0.1592443734407425, -0.10702019929885864, -0.23763611912727356, 0.07433263212442398, 0.05086478963494301, -0.042924173176288605, -0.041794303804636, 0.04256460443139076, -0.005393097177147865, -0.04917176440358162, 0.03006923384964466, -0.0002773159940261394, 0.057278454303741455, -0.014098115265369415, -0.046186890453100204, -0.13716842234134674, 0.2833632230758667, 0.037826601415872574, 0.15637865662574768, -0.24703501164913177, -0.09631290286779404, 0.0945458859205246, -0.08853387832641602, 0.13816511631011963, -0.07101435959339142, -0.03790079057216644, -0.0694577619433403, 0.050365276634693146, -0.03218461573123932, 0.10264227539300919, -0.09142162650823593, -0.08036328852176666, -0.18866172432899475, -0.04863142967224121, 0.0055821058340370655, -0.0918457955121994, 0.22427880764007568, 0.02887016162276268, 0.046552401036024094, 0.00903318077325821, -0.10124313086271286, -0.11967296898365021, 0.06833071261644363, 0.0746522918343544, -0.10101111233234406, 0.07091579586267471, 0.13860289752483368, -0.02677241899073124, -0.13168573379516602, -0.004797111265361309, -0.06901336461305618, 0.06856270134449005, 0.11341360956430435, -0.061215996742248535, 0.030826805159449577, -0.06089911237359047, -0.0093527901917696, 0.07329201698303223, -0.19744926691055298, -0.020952658727765083, -0.0995698869228363, 0.1372036635875702, 0.14862297475337982, 0.02736486680805683, 0.15460380911827087, 0.05622652918100357, 0.01827791891992092, -0.12449716031551361, 0.005498611368238926, 0.05920718237757683, 0.017520330846309662, -0.101692333817482, -0.14891153573989868, -0.2488562911748886, 1.375930537443285e-32, 0.03539569675922394, 0.03078235499560833, 0.054271992295980453, -0.13885334134101868, 0.023184239864349365, -0.08633086830377579, 0.16720235347747803, 0.04875442758202553, 0.0018257277552038431, 0.15331143140792847, -0.12557342648506165, 0.05330320820212364, 0.055726584047079086, 0.02925392985343933, 0.008229647763073444, -0.06604374200105667, 0.11961681395769119, 0.044705264270305634, 0.0649288073182106, 0.1411840319633484, 0.14062966406345367, -0.04579656198620796, 0.07772674411535263, -0.10458970814943314, -0.04230177775025368, 0.04973316937685013, -0.04184151068329811, 0.05895854905247688, -0.15027441084384918, -0.06994617730379105, -0.1790265589952469, 0.03698902577161789, -0.05244428664445877, -0.03211225941777229, 0.006136432755738497, -0.13522937893867493, 0.16088443994522095, -0.1869724541902542, 0.12314096838235855, -0.07335295528173447, 0.102204829454422, -0.0846763402223587, 0.17683255672454834, -0.12687386572360992, -0.017071716487407684, 0.151030495762825, 0.1332857608795166, 0.06627970933914185, -0.04346662759780884, 0.29349666833877563, -0.034568481147289276, -0.03479020297527313, -0.0020362508948892355, 0.12669818103313446, -0.1015130877494812, 0.025566820055246353, -0.08105023950338364, -0.03567551448941231, 0.0739826112985611, -0.002848993754014373, -0.08148516714572906, -0.06323403865098953, 0.026601985096931458, -0.2096637338399887, -0.07894442975521088, -0.013319876976311207, 0.03725261613726616, -0.006362603511661291, 0.08907543122768402, 0.08377857506275177, -0.14621996879577637, 0.031881652772426605, -0.18816612660884857, -0.26725712418556213, 0.21225549280643463, 0.09030648320913315, -0.020406512543559074, -0.04942650720477104, -0.028828341513872147, -0.0808047205209732, -0.07778153568506241, 0.17231084406375885, 0.10179420560598373, -0.1144198626279831, -0.07520423084497452, -0.03408899903297424, -0.023847881704568863, -0.04376300424337387, -0.21101438999176025, -0.155176043510437, -0.2532578110694885, 0.028070617467164993, 0.0837843269109726, 0.12514238059520721, 0.12006857246160507, -1.5357874835795465e-32, 0.004891583696007729, -0.09052910655736923, 0.05495104938745499, 0.012752163223922253, 0.03458825498819351, 0.15670792758464813, -0.09952348470687866, -0.03145218268036842, -0.04381361976265907, -0.12251365184783936, 0.041520390659570694, -0.07564681768417358, 0.12015537917613983, -0.18300746381282806, 0.052917592227458954, 0.04351094737648964, -0.09785345196723938, 0.05916709080338478, -0.13086064159870148, 0.017207099124789238, 0.1032794862985611, 0.2492106705904007, -0.07856663316488266, 0.07036136090755463, -0.17467673122882843, -0.04222485423088074, 0.019794201478362083, -0.3021546006202698, 0.03745109960436821, 0.12965014576911926, -0.12028966844081879, -0.05378067493438721, -0.21130000054836273, 0.13341394066810608, 0.10703868418931961, -0.08672048896551132, -0.10963211953639984, -0.13071611523628235, -0.02653019316494465, 0.11639346927404404, 0.14161813259124756, 0.09992342442274094, 0.0015176351880654693, 0.13015715777873993, -0.016597621142864227, -0.09310062974691391, -0.03157703951001167, 0.05856310948729515, 0.18136179447174072, 0.023571288213133812, -0.12359405308961868, 0.05839695781469345, -0.12385259568691254, 0.01407728623598814, -0.16918641328811646, -0.051247451454401016, -0.013214072212576866, 0.030539626255631447, -0.021182622760534286, -0.16590897738933563, -0.16140978038311005, -0.12525483965873718, 0.041414495557546616, 0.03794938698410988, 0.09362047165632248, 0.09207955002784729, -0.08272302895784378, -0.03275779262185097, -0.06715559959411621, 0.07199810445308685, -0.07439253479242325, -0.11302966624498367, -0.026044921949505806, -0.011378644034266472, -0.1761915534734726, -0.06354280561208725, 0.01662306673824787, -0.09751857817173004, -0.02419237419962883, 0.2167455404996872, 0.10507195442914963, -0.043343719094991684, 0.2021450251340866, 0.24318550527095795, -7.349617590080015e-06, -0.004938655998557806, 0.16942524909973145, 0.034374698996543884, 0.11955098807811737, -0.09139503538608551, 0.09018011391162872, 0.2563990354537964, 0.02277238667011261, 0.24808427691459656, 0.04003290832042694, -1.0035859787649315e-07, -0.0753154382109642, 0.03884854167699814, -0.1024765819311142, 0.00010745035979198292, -0.044906217604875565, -0.02565852738916874, -0.027645083144307137, 0.11853335797786713, -0.14417476952075958, 0.026900291442871094, -0.026226939633488655, 0.016544725745916367, -0.009082692675292492, 0.060808196663856506, 0.11465198546648026, 0.11574916541576385, 0.06601700931787491, 0.03242625296115875, -0.07073702663183212, -0.17765435576438904, -0.06930320709943771, -0.12034048140048981, -0.11912417411804199, -0.07632189244031906, -0.07680565863847733, -0.05730993673205376, 0.037680916488170624, -0.024960080161690712, 0.19068104028701782, 0.2648751437664032, -0.09741432219743729, -0.1805960088968277, -0.16203540563583374, -0.036240581423044205, 0.2744557857513428, 0.10629000514745712, -0.010985405184328556, -0.16319192945957184, 0.060643453150987625, 0.048123255372047424, -0.10690150409936905, 0.12793296575546265, -0.052318546921014786, 0.06454093754291534, -0.02681906521320343, 0.04398411884903908, 0.02820480614900589, -0.15215153992176056, -0.039781808853149414, 0.18150247633457184, 0.12126550823450089, 0.14288750290870667, -0.042036671191453934, 0.05251319706439972, -0.023124445229768753, 0.11246448755264282, -0.13602280616760254, 0.010333163663744926, 0.06255651265382767, 0.0033784823026508093, 0.048067715018987656, -0.03327556326985359, 0.17027007043361664, -0.03673763573169708], metadata={'source': 'AAAMLP-569to.pdf', 'page': 147}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 148 And we can create two-degree polynomial features using PolynomialFeatures from scikit-learn.  ═════════════════════════════════════════════════════════════════════════ from sklearn import preprocessing  # initialize polynomial features class object # for two-degree polynomial features pf = preprocessing.PolynomialFeatures(     degree=2,     interaction_only=False,     include_bias=False )  # fit to the features pf.fit(df)  # create polynomial features poly_feats = pf.transform(df)  # create a dataframe with all the features num_feats = poly_feats.shape[1] df_transformed = pd.DataFrame(     poly_feats,     columns=[f\"f_{i}\" for i in range(1, num_feats + 1)] ) ═════════════════════════════════════════════════════════════════════════  And that would give a dataframe, as shown in figure 4.  \\n Figure 4: A sample dataframe with polynomial features  So, now we have created some polynomial features. If you create third-degree polynomial features, you will end up with nine features in total. The more the'),\n",
       " VectorParams(vector=[0.12085837870836258, 0.03835105150938034, -0.07513998448848724, -0.10944773256778717, 0.12137418985366821, -0.018352491781115532, -0.01922164112329483, -0.02340942993760109, -0.16184747219085693, 0.054678577929735184, -0.006554477848112583, -0.12136264145374298, 0.004065326880663633, -0.012595932930707932, 0.04349514842033386, 0.09473014622926712, -0.0855628252029419, 0.06637971848249435, -0.06176871806383133, -0.13560259342193604, 0.09724979847669601, 0.048638563603162766, 0.0171024352312088, -0.06186840683221817, 0.10594293475151062, -0.05667736381292343, 0.014009826816618443, 0.0340859480202198, -0.092609703540802, 0.0348927266895771, 0.12065638601779938, 0.23371675610542297, 0.07867074757814407, 0.004214904736727476, -0.08859800547361374, 0.08218040317296982, -0.11306159198284149, 0.15514925122261047, 0.06442179530858994, 0.036516256630420685, -0.013760192319750786, -0.0872139260172844, 0.11180074512958527, -0.02904851920902729, 0.14038415253162384, 0.07523375004529953, -0.05060556158423424, 0.04674556851387024, 0.1409580558538437, -0.0005205334746278822, 0.08758457005023956, 0.16114720702171326, -0.010025788098573685, 0.14288575947284698, -0.1076769009232521, -0.3428094685077667, 0.13627925515174866, -0.08091189712285995, -0.02647816576063633, 0.03445780277252197, -0.05986134707927704, 0.056612033396959305, 0.024170037358999252, 0.003531409427523613, 0.08678431808948517, -0.04132988676428795, -0.1203530877828598, -0.057004060596227646, 0.02292296104133129, 0.13639342784881592, 0.0605996809899807, 0.16063229739665985, -0.10115376859903336, -0.053164687007665634, -0.048959679901599884, -0.08884073048830032, 0.054904110729694366, -0.03198054060339928, -0.008137565106153488, 0.006369268521666527, -0.14094391465187073, 0.06820446252822876, 0.19117848575115204, -0.07981100678443909, -0.14144787192344666, -0.10521698743104935, -0.013235843740403652, 0.06750024855136871, -0.17593443393707275, 0.1018742173910141, -0.01843104511499405, -0.0006200142088346183, 0.11891594529151917, -0.05532737076282501, -0.06383420526981354, -0.009183666668832302, 0.07703416049480438, -0.016675131395459175, 0.02745962329208851, 0.15664830803871155, 0.013049698434770107, -0.08683284372091293, 0.05518893525004387, -0.09641654789447784, 0.035460904240608215, -0.0038945835549384356, 0.047902531921863556, 0.01532727386802435, 0.012293703854084015, -0.11718259751796722, 0.05724705755710602, -0.09092091768980026, -0.15122097730636597, -0.1021285206079483, 0.10461875051259995, 0.0740760862827301, -0.061732884496450424, 0.1065632775425911, -0.009829233400523663, 0.11929168552160263, -0.042978350073099136, -0.01110168918967247, 0.002950607566162944, 0.09474164247512817, 0.03731422871351242, -0.07847955077886581, -0.12899620831012726, 7.789855595473385e-33, -0.027847876772284508, -0.16093094646930695, -0.03712044283747673, -0.04254976660013199, 0.14513693749904633, -0.05474711209535599, 0.07202364504337311, 0.04066814109683037, 0.12815546989440918, 0.09368971735239029, -0.09107127040624619, 0.15250009298324585, 0.020732814446091652, 0.06812792271375656, -0.0129021555185318, -0.18767789006233215, 0.003665187628939748, 0.03358917683362961, 0.021901052445173264, -0.04120488092303276, -0.05120156705379486, -0.07826592773199081, 0.14507180452346802, 0.012016828171908855, 0.08724512159824371, -0.006687616463750601, -0.041599687188863754, 0.07568591088056564, -0.053640782833099365, 0.05952180549502373, -0.1397547572851181, 0.12380051612854004, -0.014732588082551956, 0.018834805116057396, 0.00681570777669549, -0.06140470132231712, 0.09704294055700302, -0.009502077475190163, 0.06321223080158234, -0.0009228247799910605, 0.18325482308864594, -0.11033345758914948, 0.05335583537817001, -0.01367698423564434, -0.022614585235714912, 0.05748775601387024, 0.034985169768333435, 0.05155692622065544, -0.09806730598211288, 0.18172508478164673, -0.004972405731678009, 0.008222558535635471, -0.03533003479242325, 0.09288524836301804, -0.0726824551820755, -0.05167664960026741, -0.10323694348335266, -0.14402492344379425, 0.02409454807639122, 0.05485175549983978, 0.0025605091359466314, 0.011023268103599548, -0.0531407967209816, 0.02957841195166111, 0.0038773268461227417, 0.004321445245295763, 0.26007014513015747, 0.06134485453367233, 0.014369342476129532, 0.0959414467215538, -0.16473211348056793, -0.0039937300607562065, -0.016932256519794464, -0.23627826571464539, 0.07645031809806824, 0.06918203085660934, 0.1309630423784256, -0.011112196370959282, -0.16173800826072693, -0.11822003871202469, 0.02997741475701332, 0.11728428304195404, 0.028315989300608635, -0.17562898993492126, 0.045084528625011444, 0.02774449996650219, -0.03837490826845169, -0.10437127947807312, -0.21705713868141174, -0.1657421886920929, -0.23032160103321075, -0.007682413328438997, 0.03023301251232624, 0.03296859189867973, 0.10532647371292114, -1.1217091659900322e-32, -0.1988314837217331, -0.03596431389451027, 0.04254959896206856, 0.0877881869673729, -0.060117047280073166, 0.1291002482175827, -0.05189719796180725, -0.041178300976753235, -0.045138031244277954, -0.12267138808965683, -0.08692895621061325, -0.015095504932105541, 0.05574943125247955, -0.16689825057983398, -0.19354361295700073, 0.043421681970357895, -0.15417683124542236, 0.15039587020874023, -0.0521383099257946, 0.0968489721417427, -0.019693929702043533, 0.20688386261463165, -0.1357087939977646, -0.06922391802072525, -0.13789544999599457, -0.0034539964981377125, -0.04354335740208626, -0.1866176873445511, 0.10368351638317108, 0.014276242814958096, -0.20573310554027557, -0.0789085328578949, -0.11327723413705826, 0.03282960131764412, 0.08936204761266708, -0.08422030508518219, 0.020972101017832756, -0.11297805607318878, -0.0030025786254554987, 0.11220729351043701, 0.09345293790102005, 0.021598346531391144, -0.13551664352416992, -0.04861773923039436, 0.027380481362342834, -0.026334578171372414, -0.16046395897865295, 0.04056848958134651, 0.13333316147327423, -0.0025272152852267027, 0.013394740410149097, 0.1913178265094757, -0.11551348119974136, 0.08452606946229935, -0.08497440069913864, 0.07881876826286316, -0.12538877129554749, 0.1303664743900299, 0.01718280278146267, 0.04204610735177994, -0.23107445240020752, -0.09294974058866501, 0.13451729714870453, 0.039310142397880554, 0.08897162228822708, -0.055249087512493134, -0.11128804832696915, 0.010350377298891544, -0.004618410486727953, 0.05983632430434227, -0.013042311184108257, -0.10242682695388794, 0.029433483257889748, -0.019274117425084114, -0.18292415142059326, -0.030072888359427452, 0.03411348536610603, -0.20345038175582886, -0.11797066032886505, 0.14713585376739502, 0.1439361274242401, -0.11399886757135391, 0.10369226336479187, 0.14486917853355408, -0.01131536066532135, -0.058010272681713104, 0.11909527331590652, 0.0005949260084889829, 0.06777279078960419, -0.00904975738376379, 0.05975423753261566, 0.11763183027505875, 0.01648784801363945, 0.14559796452522278, 0.013798288069665432, -9.908355735888108e-08, 0.03565315157175064, 0.024616792798042297, -0.004861882887780666, -0.039960041642189026, 0.16995808482170105, 0.0832013338804245, -0.19881151616573334, 0.13933537900447845, -0.141055628657341, -0.04523533210158348, 0.16718532145023346, 0.07631565630435944, -0.187343567609787, 0.08099278807640076, 0.01483188010752201, 0.05405255779623985, 0.07336929440498352, 0.06857193261384964, 0.018183326348662376, -0.016411107033491135, 0.00031751394271850586, -0.031768254935741425, 0.09315294772386551, -0.13132095336914062, -0.10965204238891602, -0.15723314881324768, 0.031606607139110565, 0.08941534906625748, 0.09875623881816864, 0.15610311925411224, -0.0533900111913681, -0.06949925422668457, -0.13654392957687378, -0.03331809490919113, 0.16874447464942932, 0.06560731679201126, -0.13438940048217773, -0.11619177460670471, 0.007227974012494087, -0.05777374655008316, -0.05680643767118454, -0.07836969941854477, 0.010100029408931732, 0.018408412113785744, 0.0006183574441820383, 0.07404887676239014, 0.11601366102695465, 0.06353966891765594, 0.0017943773418664932, 0.1293758898973465, 0.01668049953877926, 0.211894690990448, -0.020428430289030075, -0.09073571860790253, -0.016816647723317146, 0.18026192486286163, -0.1554384082555771, -0.09169992804527283, 0.04103320837020874, -0.011646942235529423, -0.00039790564915165305, -0.03467787057161331, 0.0679626613855362, -0.14389166235923767], metadata={'source': 'AAAMLP-569to.pdf', 'page': 148}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 149 number of features, the more the number of polynomial features and you must also remember that if you have a lot of samples in the dataset, it is going to take a while creating these kinds of features. \\n Figure 5: Histogram of a numerical feature column  Another interesting feature converts the numbers to categories. It’s known as binning. Let’s look at figure 5, which shows a sample histogram of a random numerical feature. We use ten bins for this figure, and we see that we can divide the data into ten parts. This is accomplished using the pandas’ cut function.  ═════════════════════════════════════════════════════════════════════════ # create bins of the numerical columns # 10 bins df[\"f_bin_10\"] = pd.cut(df[\"f_1\"], bins=10, labels=False) # 100 bins df[\"f_bin_100\"] = pd.cut(df[\"f_1\"], bins=100, labels=False) ═════════════════════════════════════════════════════════════════════════  Which generates two new features in the dataframe, as shown in figure 6.   Figure 6: Binning numerical features'),\n",
       " VectorParams(vector=[0.17670875787734985, 0.08044915646314621, 0.018609149381518364, -0.08451443165540695, -0.0330771841108799, 0.011161524802446365, -0.001897707348689437, -0.02533702738583088, -0.14498178660869598, -0.012370647862553596, -0.09952332824468613, -0.08050866425037384, -0.008528408594429493, 0.060275543481111526, 0.09590201079845428, 0.03605044633150101, 0.10199667513370514, 0.186602383852005, -0.029533740133047104, -0.13219551742076874, 0.06331149488687515, 0.0575876422226429, -0.0871506854891777, 0.05955692008137703, 0.029323870316147804, -0.015223531983792782, 0.058258384466171265, 0.07779909670352936, -0.034282386302948, -0.05758794769644737, -0.01101037859916687, 0.12344388663768768, 0.021073143929243088, -0.0668482780456543, -0.1646541804075241, 0.012550631538033485, -0.1229047030210495, 0.05512648820877075, 0.0002781179209705442, -0.0842977985739708, -0.02483571320772171, -0.010898138396441936, 0.05974651128053665, 0.0007424594950862229, 0.15566100180149078, 0.07721813768148422, -0.0659424215555191, -0.057658322155475616, 0.09357880055904388, 0.03261645883321762, -0.05138463154435158, 0.16622748970985413, 0.03368816897273064, 0.005929954349994659, -0.06619136035442352, -0.23863941431045532, -0.0027371507603675127, -0.1555139124393463, 0.060020118951797485, -0.02755429781973362, -0.0036104395985603333, 0.09347300231456757, 0.08947982639074326, -0.12035488337278366, 0.10668743401765823, -0.046579401940107346, -0.07948978990316391, -0.09560573101043701, 0.12968192994594574, 0.04592658206820488, 0.049180999398231506, 0.08591645956039429, -0.019294966012239456, 0.02942667528986931, -0.05416605621576309, -0.03740397468209267, 0.06460408121347427, 0.02370162308216095, 0.09856916964054108, 0.05217071250081062, -0.10881531983613968, 0.13144554197788239, 0.13024643063545227, 0.011993015184998512, -0.04589400812983513, -0.003892833599820733, -0.021663343533873558, 0.09050551056861877, -0.18671013414859772, 0.06261579692363739, -0.015954630449414253, -0.026483574882149696, 0.12897291779518127, -0.08903597295284271, -0.06730825453996658, 0.033251091837882996, 0.08481532335281372, -0.09720273315906525, 0.08806665241718292, 0.15981370210647583, 0.04046374559402466, 0.015081776306033134, 0.009657441638410091, 0.004263641778379679, 0.08731158077716827, -0.0044641620479524136, 0.13390856981277466, -0.035482876002788544, -0.038362693041563034, -0.119815394282341, -0.002140466822311282, -0.14181075990200043, -0.17364166676998138, -0.1701897233724594, 0.033035919070243835, 0.09976495802402496, -0.07863890379667282, 0.023030051961541176, -0.07813449949026108, 0.09543532878160477, 0.05387212336063385, -0.0017440299270674586, -0.07168745249509811, 0.15835827589035034, 0.02620994672179222, 0.04397429898381233, -0.026967130601406097, 6.752582482576505e-33, -0.0199105404317379, -0.09775602072477341, -0.03765689581632614, -0.007336544804275036, 0.02700180746614933, -0.04266711324453354, -0.009459350258111954, -0.02893204428255558, 0.1391771286725998, 0.07208938896656036, -0.08046341687440872, 0.09840363264083862, -0.0038233851082623005, 0.06196746602654457, -0.037270527333021164, -0.17767781019210815, -0.06216664984822273, 0.019054021686315536, -0.025973094627261162, -0.10564448684453964, -0.05875026807188988, -0.18098127841949463, 0.06983096152544022, 0.05995914340019226, 0.1227344498038292, 0.006098118145018816, -0.050916727632284164, -0.10095328837633133, -0.07042916119098663, 0.07772345095872879, -0.007706693839281797, 0.0659533217549324, -0.05258115753531456, -0.029859673231840134, -0.0330188162624836, -0.18230856955051422, -0.02410409413278103, 0.011888382025063038, 0.10013829171657562, 0.18425409495830536, 0.13895078003406525, -0.003969177603721619, -0.054558008909225464, 0.12181703746318817, 0.018238255754113197, 0.17259632050991058, 0.12854216992855072, 0.05325201526284218, -0.12825851142406464, -0.035222746431827545, 0.027694594115018845, 0.014720240607857704, -0.08792217820882797, -0.06990599632263184, -0.011718397960066795, -0.035294149070978165, 0.06620827317237854, -0.061392832547426224, -0.09274963289499283, 0.02037578634917736, 0.007902707904577255, 0.07294419407844543, 0.07261540740728378, 0.008870294317603111, -0.004993145819753408, -0.13423581421375275, 0.2048233598470688, 0.023763038218021393, -0.027336440980434418, 0.04743702709674835, -0.09405121952295303, 0.04906294494867325, 0.016549399122595787, -0.14682216942310333, -0.0666034147143364, 0.049857862293720245, 0.1667698621749878, 0.01557841431349516, -0.11307329684495926, -0.10857751220464706, -0.022199168801307678, 0.002388307824730873, -0.036901794373989105, -0.12570665776729584, 0.05387137830257416, 0.04706176370382309, -0.0004985201521776617, -0.09505090117454529, -0.12308305501937866, -0.13892558217048645, -0.05952988192439079, 0.1925790160894394, 0.013627713546156883, -0.0034863343462347984, 0.031034424901008606, -8.452974733975285e-33, -0.16951511800289154, 0.11502888798713684, 0.058505017310380936, 0.05154263600707054, -0.09610160440206528, 0.05947136506438255, -0.04020937904715538, -0.060042884200811386, -0.07395092397928238, -0.022873925045132637, -0.10211794078350067, -0.0602034330368042, 0.09234689176082611, -0.12361666560173035, -0.08760897815227509, 0.12692810595035553, -0.1708446741104126, 0.012038958258926868, -0.04811691492795944, 0.11469381302595139, -0.04198480769991875, 0.10717137157917023, -0.1500467211008072, -0.003453157376497984, -0.13676416873931885, 0.0015299554215744138, -0.12276029586791992, -0.11371541768312454, 0.07042323052883148, -0.07844285666942596, -0.18711140751838684, -0.05102987959980965, -0.054790206253528595, -0.03518780320882797, 0.024689191952347755, -0.06305492669343948, -0.009650347754359245, -0.06967519223690033, 0.045020692050457, 0.04250828176736832, 0.08348480612039566, 0.01686549372971058, -0.03133079409599304, -0.09135127812623978, 0.06925695389509201, 0.0571090430021286, -0.08027121424674988, 0.032635465264320374, 0.1690181940793991, 0.0029012146405875683, 0.03994443267583847, 0.04952828213572502, -0.011713025160133839, 0.09422164410352707, -0.001667800359427929, 0.1026562824845314, -0.024635018780827522, -0.06680333614349365, 0.1180042028427124, 0.16803601384162903, -0.11686710268259048, -0.11926966905593872, 0.19637711346149445, 0.10169446468353271, 0.03699849173426628, -0.004421608056873083, -0.042600758373737335, -0.05230015516281128, -0.09190206229686737, -0.05292779579758644, 0.013676323927938938, -0.07605994492769241, 0.09153621643781662, 0.03402511402964592, -0.03997096046805382, -0.11583679914474487, 0.013901920057833195, -0.0250841211527586, -0.09455414116382599, 0.031239250674843788, 0.14961236715316772, -0.0017699907766655087, 0.08085155487060547, 0.0852169394493103, 0.04432104900479317, 0.06801801174879074, -0.03205336630344391, -0.0330878309905529, 0.1172214150428772, 0.02453569322824478, -0.019320957362651825, 0.19360370934009552, -0.09837884455919266, -0.03042302466928959, 0.09219028800725937, -9.898195685309474e-08, -0.03310488536953926, -0.031720973551273346, 0.03733310475945473, -0.05870320647954941, 0.1947055459022522, 0.11324905604124069, -0.1178080290555954, 0.1085481122136116, 0.02814420312643051, -0.05918455868959427, 0.020588936284184456, -0.012162384577095509, -0.13392537832260132, 0.007310311775654554, 0.09706170856952667, 0.04547170549631119, 0.09287320077419281, -0.030053650960326195, 0.04994918778538704, 0.003929681610316038, 0.04271186143159866, -0.02030336484313011, 0.09220517426729202, -0.0916651263833046, -0.02258159965276718, -0.11624912172555923, -0.02907104231417179, 0.12535972893238068, 0.15112659335136414, 0.12673908472061157, 0.002881989348679781, 0.005717040505260229, 0.005848334636539221, 0.017702175304293633, 0.11488573998212814, -0.0005715723382309079, -0.0981600433588028, -0.019138595089316368, -0.14554756879806519, -0.12238805741071701, 0.04001719877123833, -0.015004747547209263, -0.088398277759552, -0.04508352652192116, -0.0836929902434349, 0.08744104206562042, 0.1192949116230011, -0.04089420288801193, 0.07732608914375305, 0.05473659560084343, 0.04760899022221565, -0.009362021461129189, 0.07768464833498001, 0.0590088777244091, -0.06257923692464828, 0.09024177491664886, -0.07878052443265915, -0.033935677260160446, 0.08547753840684891, -0.13117915391921997, -0.012220878154039383, -0.12022694200277328, -0.1098969355225563, -0.09808413684368134], metadata={'source': 'AAAMLP-569to.pdf', 'page': 149}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 150 When you bin, you can use both the bin and the original feature. We will learn a bit more about selecting features later in this chapter. Binning also enables you to treat numerical features as categorical.  Yet another interesting type of feature that you can create from numerical features is log transformation. Take a look at feature f_3 in figure 7.   Figure 7: Example of a feature that has a high variance  f_3 is a special feature with a very high variance. Compared to other features that have a low variance (let’s assume that). Thus, we would want to reduce the variance of this column, and that can be done by taking a log transformation.   The values in column f_3 range from 0 to 10000 and a histogram is shown in figure 8. \\n Figure 8: Histogram of feature f_3.'),\n",
       " VectorParams(vector=[0.05584120377898216, -0.03747085481882095, -0.030668364837765694, -0.05841085687279701, 0.0766369104385376, -0.09551553428173065, 0.04271994158625603, -0.03268618509173393, 0.034930191934108734, 0.015115572139620781, -0.020258929580450058, -0.051846012473106384, -0.05887764319777489, 0.027874043211340904, 0.09815572202205658, -0.10136640816926956, -0.06434179097414017, 0.08248575776815414, -0.1514572650194168, -0.07407423853874207, 0.07747957855463028, 0.17156219482421875, -0.032458893954753876, 0.0886913388967514, 0.08413230627775192, -0.10007456690073013, -0.034109774976968765, 0.03394269198179245, -0.05816543847322464, -0.014561062678694725, -0.05397987365722656, 0.11191525310277939, -0.07981587946414948, 0.004973321221768856, -0.08026330173015594, 0.035220224410295486, -0.025825228542089462, 0.008741913363337517, -0.07104445993900299, 0.007080433424562216, -0.04265961796045303, 0.01728113368153572, 0.0910424143075943, -0.04296157509088516, 0.1093510240316391, 0.014478572644293308, -0.047392308712005615, -0.12052672356367111, 0.04480844736099243, -0.012423859909176826, -0.02599947713315487, 0.0798092931509018, -0.07678374648094177, 0.045337919145822525, 0.0019942570943385363, -0.13644149899482727, 0.03492805361747742, -0.15523992478847504, 0.02405226044356823, -0.03914548456668854, -0.07714412361383438, 0.0675685703754425, 0.07223278284072876, -0.09347506612539291, 0.10271263122558594, -0.04851966351270676, -0.043856628239154816, -0.12695926427841187, 0.0036629776004701853, 0.20627978444099426, -0.03449688106775284, -0.023553960025310516, -0.08405151963233948, -0.00708426907658577, -0.024913491681218147, 0.0037873273249715567, 0.1876455694437027, 0.008456133306026459, 0.12882493436336517, -0.06709544360637665, -0.004533803090453148, 0.07837986201047897, 0.05645003914833069, 0.09782961010932922, -0.024738915264606476, -0.08568476885557175, -0.03007536381483078, 0.036855604499578476, -0.018771449103951454, 0.07205493003129959, 0.015408264473080635, 0.008531644940376282, -0.0443342849612236, 0.046172041445970535, 0.04081995040178299, 0.057668287307024, 0.09134563058614731, 0.007218218874186277, 0.09277761727571487, 0.1136901006102562, 0.051448922604322433, 0.07360997796058655, 0.030485423281788826, -0.019830603152513504, 0.01058271061629057, 0.025734173133969307, 0.08573153614997864, 0.10330890864133835, -0.1580037772655487, -0.044607069343328476, 0.08395956456661224, -0.02985827811062336, -0.1693531572818756, -0.039189960807561874, 0.07113255560398102, 0.08325369656085968, -0.01348849106580019, -0.006813433021306992, -0.12304481118917465, 0.13794216513633728, -0.04508383199572563, 0.06647153198719025, 0.08463788777589798, 0.16928404569625854, -0.01895325258374214, 0.03670509159564972, -0.06995397806167603, 9.660798852865031e-33, -0.0832386314868927, 0.06006653606891632, 0.008522501215338707, -0.10893981903791428, 0.0033080519642680883, 0.08000773936510086, -0.04400862753391266, -0.04596685990691185, 0.0447942316532135, 0.02841178886592388, -0.1508750021457672, 0.12394428998231888, -0.004072359763085842, -0.05290525406599045, -0.005755976773798466, -0.0759226530790329, -0.0027942589949816465, 0.016235454007983208, -0.03548127040266991, 0.012856625951826572, 0.13429521024227142, -0.08726450055837631, 0.024532077834010124, 0.04263829439878464, 0.04434134066104889, 0.012214437127113342, -0.09045350551605225, -0.046866338700056076, -0.15989457070827484, 0.06783527135848999, -0.13884374499320984, 0.08233993500471115, 0.010673152282834053, -0.031900860369205475, 0.03480542078614235, -0.1524001806974411, 0.0771820917725563, -0.04436716064810753, 0.01647859252989292, 0.05642780661582947, -0.03834813833236694, 0.08249679207801819, -0.0782158225774765, -0.030286071822047234, -0.09275712072849274, 0.0588187649846077, 0.11893555521965027, 0.06205708160996437, 0.022784030064940453, -0.002128954278305173, 0.029377253726124763, 0.0265736673027277, -0.011487818323075771, -0.11919901520013809, -0.008387668058276176, 0.012385029345750809, 0.12698054313659668, -0.1549408882856369, -0.04545832797884941, 0.03536517918109894, -0.02595818042755127, -0.025986650958657265, 0.11017777025699615, -0.025591818615794182, 0.016081353649497032, -0.051707666367292404, 0.16350050270557404, 0.05083883926272392, 0.01521486695855856, -0.01820879615843296, -0.07670856267213821, -0.020149894058704376, 0.003044544253498316, -0.11429440975189209, 0.09700996428728104, -0.01444289367645979, 0.042420051991939545, 0.0099552096799016, -0.09627838432788849, -0.023042019456624985, -0.01885959319770336, 0.10118328034877777, -0.03240706026554108, -0.0563003309071064, 0.007191723212599754, -0.03319232165813446, 0.029997043311595917, -0.05470367148518562, -0.1634582132101059, -0.011958323419094086, -0.04833301901817322, 0.037586867809295654, 0.012153358198702335, -0.020983554422855377, -0.03816988319158554, -1.1391641550737893e-32, -0.22961269319057465, 0.16836078464984894, 0.021266432479023933, 0.034620095044374466, -0.0408921018242836, -0.02051357552409172, 0.003647645702585578, 0.005842884071171284, 0.06313673406839371, -0.1071731373667717, -0.030883818864822388, -0.09996502101421356, -0.03424735739827156, -0.04812299460172653, -0.07294861972332001, 0.11049294471740723, -0.16428612172603607, -0.004367194604128599, -0.10080955922603607, 0.02273756079375744, 0.11765817552804947, 0.08704551309347153, -0.133108451962471, 0.058144718408584595, -0.10884266346693039, 0.05282870680093765, -0.11961814761161804, -0.021975839510560036, -0.016452699899673462, -0.12534886598587036, -0.06707960367202759, -0.045346662402153015, -0.11756037175655365, -0.0019719903357326984, 0.025182653218507767, -0.07392911612987518, 0.026357270777225494, 0.020108362659811974, 0.03610462695360184, 0.04247936233878136, 0.04197847843170166, 0.07169163972139359, 0.004639068618416786, 0.0022932549472898245, 0.03947615623474121, 0.07774396985769272, 0.0445416085422039, 0.02935364842414856, 0.1785762757062912, -0.0235646553337574, 0.11767567694187164, -0.01061656977981329, 0.0055183046497404575, 0.134031742811203, -0.1215967908501625, 0.05632674694061279, -0.010196988470852375, -0.07846822589635849, 0.002757631940767169, 0.14988113939762115, -0.03917979449033737, -0.09550408273935318, 0.10881122946739197, 0.01173144206404686, -0.039335500448942184, -0.03853984922170639, -0.022923970595002174, -0.0089415917173028, 0.05706053227186203, -0.032868362963199615, -0.013640626333653927, -0.08432171493768692, 0.06255390495061874, -0.03173177316784859, -0.058759137988090515, -0.014426193200051785, 0.00844714604318142, -0.10922562330961227, -0.0799245536327362, 0.0012998414458706975, 0.1026184931397438, 0.012245703488588333, 0.12731952965259552, 0.09829278290271759, -0.013798613101243973, 0.042652469128370285, 0.15461720526218414, 0.04754623770713806, 0.01599532552063465, -0.016978006809949875, -0.05330105870962143, 0.12772753834724426, -0.10619309544563293, 0.02383081614971161, 0.010360670275986195, -9.966858982579652e-08, -0.10997623950242996, 0.0655735433101654, -0.044460780918598175, -0.03294123709201813, 0.09200329333543777, 0.07124994695186615, -0.029480865225195885, 0.14426545798778534, 0.044143352657556534, 0.00688982242718339, 0.0175182968378067, -0.0834604874253273, -0.09912347793579102, 0.07006494700908661, -0.03932369500398636, 0.01365399919450283, 0.06036116182804108, 0.004267425276339054, -0.04214978218078613, -0.010796533897519112, 0.01656944677233696, 0.024955619126558304, -0.08739282190799713, -0.12522736191749573, -0.04451700672507286, -0.1520472764968872, -0.013113953173160553, 0.12989948689937592, 0.07673020660877228, 0.04750102385878563, -0.06219244375824928, 0.014100252650678158, 0.019122721627354622, 0.1060219407081604, -0.02685914747416973, -0.007593204732984304, 0.08671152591705322, -0.0778905376791954, -0.11677879095077515, -0.0168745294213295, -0.02675626054406166, -0.016392024233937263, -0.03268557786941528, -0.014116525650024414, -0.03290542587637901, 0.04556645080447197, 0.012663931585848331, 0.07481158524751663, -0.009542456828057766, 0.056681349873542786, 0.12437431514263153, -0.021820414811372757, -0.04138367995619774, 0.06863034516572952, 0.05646746978163719, -0.004965092055499554, -0.04485999420285225, -0.0817917063832283, 0.060586608946323395, -0.024091996252536774, -0.03710517659783363, -0.1747143715620041, -0.08912433683872223, -0.0584588497877121], metadata={'source': 'AAAMLP-569to.pdf', 'page': 150}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 151 And we can apply log(1 + x) to this column to reduce its variance. Figure 9 shows what happens to the histogram when the log transformation is applied. \\n Figure 9: Histogram of f_3 after applying log transformation.  Let’s take a look at the variance without and with the log transformation.  ═════════════════════════════════════════════════════════════════════════ In [X]: df.f_3.var() Out[X]: 8077265.875858586  In [X]: df.f_3.apply(lambda x: np.log(1 + x)).var() Out[X]: 0.6058771732119975 ═════════════════════════════════════════════════════════════════════════  Sometimes, instead of log, you can also take exponential. A very interesting case is when you use a log-based evaluation metric, for example, RMSLE. In that case, you can train on log-transformed targets and convert back to original using exponential on the prediction. That would help optimize the model for the metric.  Most of the time, these kinds of numerical features are created based on intuition. There is no formula. If you are working in an industry, you will create your industry-specific features.   When dealing with both categorical and numerical variables, you might encounter missing values. We saw some ways to handle missing values in categorical features in the previous chapter, but there are many more ways to handle missing/NaN values. This is also considered feature engineering.'),\n",
       " VectorParams(vector=[0.0094746183604002, 0.03292711824178696, 0.03043189086019993, -0.1414022296667099, 0.019625071436166763, -0.08468884974718094, -0.07510780543088913, -0.1693097949028015, -0.08380594849586487, -0.08328106254339218, 0.017981622368097305, -0.1232442855834961, 0.042495790868997574, -0.090388223528862, 0.05013488978147507, 0.12333568930625916, 0.06268264353275299, -0.045679349452257156, -0.019531697034835815, -0.13411884009838104, -0.13903407752513885, 0.08413484692573547, -0.06615738570690155, 0.05735911801457405, 0.029475312680006027, -0.09217846393585205, 0.2189340740442276, -0.001579970819875598, -0.09236381947994232, 0.03560924157500267, -0.03488651663064957, 0.1163180023431778, -0.06715922802686691, -0.0779995322227478, -0.023158861324191093, 0.02853229269385338, -0.18174295127391815, 0.1211797222495079, -0.13794414699077606, 0.078895203769207, 0.0068329107016325, 0.07338179647922516, 0.03253661468625069, 0.04080482944846153, 0.03911646455526352, 0.09289111196994781, -0.08125825971364975, -0.12150254845619202, 0.15624967217445374, -0.12874972820281982, -0.006319159641861916, 0.08111001551151276, -0.03941762447357178, 0.14460286498069763, -0.005731736309826374, -0.3119908571243286, -0.08464685082435608, -0.16339483857154846, 0.07327862083911896, -0.09642157703638077, 0.020814478397369385, -0.0321711003780365, 0.09742195904254913, -0.07275091856718063, 0.06765110045671463, -0.1008867397904396, -0.024036645889282227, 0.03964393958449364, 0.04499125853180885, 0.12238086760044098, 0.06637537479400635, 0.010206582024693489, -0.11096735298633575, 0.09381312876939774, -0.049714069813489914, 0.01123702060431242, 0.22503238916397095, -0.1186700239777565, 0.026509620249271393, 0.20298674702644348, -0.1996554434299469, 0.05648816376924515, 0.07128345966339111, 0.08200614154338837, -0.04370781034231186, -0.0777764543890953, 0.05633610859513283, 0.14266158640384674, -0.017301851883530617, 0.011365777812898159, -0.032643843442201614, 0.024232681840658188, -0.09508223831653595, -0.17707906663417816, 0.07959257811307907, 0.07669512182474136, 0.1476803869009018, -0.06322628259658813, -0.043088674545288086, 0.1354641169309616, 0.02416055090725422, -0.095627062022686, -0.031264450401067734, -0.016817867755889893, 0.141892671585083, 0.1691575050354004, 0.08513780683279037, 0.026866929605603218, 0.053317856043577194, -0.06000519171357155, -0.07150717824697495, -0.2582519054412842, -0.18842579424381256, 0.023673562332987785, 0.11327746510505676, -0.016145281493663788, 0.1016579121351242, 0.025402966886758804, -0.10952942818403244, 0.08061867952346802, -0.0878669023513794, -0.06336887180805206, 0.059014175087213516, 0.10111893713474274, 0.06348704546689987, 0.04882107675075531, -0.032601818442344666, 7.89201854418732e-33, -0.05182621255517006, -0.169154554605484, -0.04672503098845482, -0.11192449927330017, -0.0035530314780771732, -0.045347101986408234, 0.08251988887786865, -0.026585735380649567, 0.17528635263442993, 0.10611118376255035, -0.13277895748615265, 0.009351315908133984, -0.02015659585595131, -0.08222038298845291, -0.0750516876578331, -0.09802216291427612, 0.16121068596839905, -0.11116807907819748, -0.0213556457310915, -0.0652138739824295, 0.12021038681268692, 0.005672981031239033, 0.136013925075531, -0.07939859479665756, -0.08567257225513458, -0.08593525737524033, -0.09902170300483704, -0.13587583601474762, 0.03935156390070915, 0.0012017813278362155, -0.1066943109035492, 0.19194132089614868, 0.0281390193849802, 0.03292790800333023, -0.10359859466552734, -0.08366313576698303, 0.15870097279548645, -0.006590117234736681, 0.0887385904788971, -0.09621409326791763, 0.051395099610090256, -0.011391231790184975, -0.06131523475050926, -0.031091734766960144, 0.1419835239648819, 0.10115406662225723, 0.2635951042175293, 0.022399256005883217, -0.030012937262654305, 0.1956983208656311, -0.047349605709314346, -0.026633357629179955, -0.039227768778800964, 0.013955810107290745, -0.2909589111804962, 0.009425696916878223, 0.0643150806427002, -0.23730270564556122, -0.08753979206085205, 0.02621598355472088, 0.01034511998295784, -0.09649018198251724, 0.09194327890872955, 0.03323982283473015, 0.07303718477487564, -0.0391366109251976, 0.13873110711574554, -0.012951045297086239, 0.12387034296989441, 0.01489945501089096, -0.048626743257045746, 0.06015359237790108, -0.12458100914955139, -0.09994620829820633, -0.06992202997207642, -0.03210623934864998, 0.2115546613931656, -0.02677840366959572, -0.02179799973964691, 0.0028144223615527153, 0.1717309057712555, 0.05025466904044151, -0.011422072537243366, -0.22974546253681183, 0.04942869022488594, 0.01727421022951603, 0.030720382928848267, -0.2007485032081604, -0.0650111511349678, -0.13620319962501526, -0.11885954439640045, 0.057487476617097855, -0.06631173193454742, -0.05304279550909996, 0.035480547696352005, -1.1409344495661276e-32, -0.044120121747255325, 0.028502514585852623, 0.08851177990436554, 0.08602284640073776, 0.015943918377161026, 0.08151344209909439, 0.06381697952747345, -0.04244334623217583, 0.16537709534168243, -0.14002031087875366, -0.08451509475708008, -0.0331505611538887, 0.14192497730255127, -0.08327970653772354, -0.004359818994998932, 0.13052131235599518, -0.14348912239074707, -0.005094714928418398, -0.012591924518346786, 0.0415675975382328, -0.04816090315580368, 0.08491639792919159, -0.22516216337680817, -0.01069401204586029, -0.21549122035503387, 0.0906735360622406, -0.03360734134912491, -0.1024053543806076, -0.02304154634475708, -0.12629766762256622, -0.019467191770672798, 0.030039267614483833, -0.09363460540771484, -0.1484030932188034, 0.06371887773275375, -0.037157416343688965, 0.11339893192052841, 0.013730185106396675, -0.22174179553985596, 0.0038414662703871727, 0.15413802862167358, 0.10080630332231522, -0.18632401525974274, 0.1559855043888092, -0.05619879812002182, 0.07217109948396683, -0.057081934064626694, 0.006448958534747362, 0.047220807522535324, 0.0199203509837389, 0.061752740293741226, -0.02968372404575348, -0.07780537754297256, 0.07875252515077591, 0.005549095571041107, 0.21150030195713043, -0.10424470901489258, 0.13181465864181519, 0.08396769315004349, 0.09465692937374115, -0.12134522199630737, -0.13795247673988342, 0.03626552224159241, -0.02091294154524803, -0.0056945690885186195, 0.09062839299440384, 0.09638006240129471, 0.039849236607551575, -0.08170773088932037, 0.06599375605583191, -0.0927005484700203, 0.1658991277217865, -0.016640298068523407, -0.2748337388038635, -0.022186413407325745, 0.07139580696821213, -0.0068315365351736546, -0.11983959376811981, -0.0208327267318964, 0.022928185760974884, 0.07559815049171448, 0.0057947165332734585, -0.022899582982063293, 0.04758474603295326, 0.057301852852106094, 0.10358215868473053, 0.18898986279964447, -0.08311344683170319, 0.10306397825479507, -0.01532907783985138, -0.021915657445788383, 0.2109754979610443, 0.04329006001353264, 0.059552934020757675, -0.08297538012266159, -9.99557983050181e-08, 0.05729607492685318, 0.08116032928228378, -0.067136250436306, 0.006814983207732439, 0.1626013219356537, -0.0461157001554966, -0.027276091277599335, 0.1416623592376709, -0.031446151435375214, 0.03828853368759155, 0.021437006071209908, -0.08477890491485596, -0.13325127959251404, 0.04354814440011978, 0.10736912488937378, 0.014240513555705547, 0.06922723352909088, -0.09513922780752182, -0.027803542092442513, 0.11732655018568039, 0.0260046124458313, -0.040881045162677765, -0.026445113122463226, -0.028514990583062172, 0.0037020593881607056, -0.11077289283275604, -0.06544274836778641, -0.027727283537387848, 0.15355519950389862, 0.08163458853960037, -0.07893752306699753, -0.09811213612556458, 0.1391836404800415, -0.03033563680946827, 0.12992605566978455, 0.17153917253017426, 0.13012327253818512, -0.03775864839553833, -0.16542980074882507, -0.09624038636684418, -0.13103632628917694, -0.004961950238794088, 0.10169215500354767, -0.11515854299068451, -0.0575697086751461, 0.07076741755008698, 0.06217224895954132, 0.01387301180511713, 0.1259438842535019, -0.026678185909986496, -0.035981059074401855, 0.0034291036427021027, -0.0984978899359703, -0.028112923726439476, 0.14200346171855927, -0.035617563873529434, -0.09570519626140594, 0.012438449077308178, 0.10123246908187866, -0.04406124725937843, 0.040526822209358215, -0.08965238183736801, -0.08421226590871811, -0.003486818866804242], metadata={'source': 'AAAMLP-569to.pdf', 'page': 151}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 152 For categorical features, let’s keep it super simple. If you ever encounter missing values in categorical features, treat is as a new category! As simple as this is, it (almost) always works!  One way to fill missing values in numerical data would be to choose a value that does not appear in the specific feature and fill using that. For example, let’s say 0 is not seen in the feature. So, we fill all the missing values using 0. This is one of the ways but might not be the most effective. One of the methods that works better than filling 0s for numerical data is to fill with mean instead. You can also try to fill with the median of all the values for that feature, or you can use the most common value to fill the missing values. There are just so many ways to do this.  A fancy way of filling in the missing values would be to use a k-nearest neighbour method. You can select a sample with missing values and find the nearest neighbours utilising some kind of distance metric, for example, Euclidean distance. Then you can take the mean of all nearest neighbours and fill up the missing value. You can use the KNN imputer implementation for filling missing values like this.   \\n Figure 10: A 2d array with missing values  Let’s see how a matrix with missing values, as shown in figure 10 is handled by KNNImputer.  ═════════════════════════════════════════════════════════════════════════ import numpy as np from sklearn import impute  # create a random numpy array with 10 samples # and 6 features and values ranging from 1 to 15 X = np.random.randint(1, 15, (10, 6))'),\n",
       " VectorParams(vector=[-0.15986283123493195, 0.020641356706619263, 0.0615566112101078, 0.07835151255130768, 0.16927343606948853, -0.06152511388063431, -0.011021493002772331, -0.03147778660058975, 0.006565026938915253, 0.016930127516388893, 0.09715443849563599, -0.020524445921182632, 0.11042260378599167, -0.023499643430113792, 0.039873477071523666, 0.10099051147699356, -0.02182816155254841, 0.0042150733061134815, -0.13683709502220154, -0.08783281594514847, -0.000669505912810564, 0.08560162782669067, -0.1177140325307846, 0.11548910290002823, -0.0011727032251656055, 0.03985714912414551, 0.0825868770480156, 0.06584902852773666, -0.05849824473261833, 0.022855721414089203, -0.12545916438102722, 0.10488812625408173, -0.07707259804010391, 0.018982868641614914, -0.15220627188682556, 0.013996640220284462, -0.1295132339000702, 0.10027541220188141, -0.09484685212373734, 0.03855600580573082, 0.07137446105480194, 0.09593141078948975, -0.026793627068400383, -0.04484805092215538, 0.08543074131011963, 0.04013129696249962, -0.028399717062711716, -0.08874981105327606, -0.027965545654296875, 0.0036791476886719465, -0.08563036471605301, 0.025724275037646294, -0.07432928681373596, 0.08341609686613083, 0.1012016236782074, -0.07749873399734497, -0.12846726179122925, -0.11505578458309174, 0.01984989270567894, -0.026328686624765396, 0.03459826111793518, -0.005086188204586506, 0.006040518172085285, -0.07956859469413757, 0.11434753239154816, 0.0231514610350132, -0.07991757243871689, 0.051477715373039246, -0.002588361268863082, 0.06742536276578903, 0.10213786363601685, -0.02466985397040844, -0.15764179825782776, 0.07435627281665802, -0.01015257928520441, 0.05221518501639366, 0.24616384506225586, -0.08346331864595413, 0.00013840988685842603, 0.09328728169202805, -0.21444277465343475, 0.09547282755374908, -0.07665994018316269, -0.07972685247659683, -0.0401119589805603, -0.14214441180229187, 0.014524933882057667, 0.05888104811310768, -0.08209516108036041, -0.05377935990691185, 0.05728989094495773, -0.01431667897850275, -0.001173469703644514, -0.09131825715303421, 0.1331411749124527, 0.052198681980371475, 0.16166989505290985, -0.04218899458646774, 0.0016479213954880834, 0.05120443180203438, -0.005910052452236414, 0.12073945999145508, 0.048432108014822006, -0.05292923375964165, -0.03820129483938217, 0.007010112050920725, 0.06084515154361725, 0.0015240113716572523, -0.054125215858221054, 0.012195674702525139, -0.09366906434297562, -0.0762757807970047, -0.14355656504631042, 0.021321898326277733, 0.012248236685991287, -0.06990747153759003, 0.0577150397002697, -0.15292170643806458, -0.06464096903800964, 0.015213854610919952, -0.058963362127542496, 0.020489906892180443, 0.029351575300097466, 0.13968996703624725, 0.030959121882915497, 0.0908994972705841, -0.08203107118606567, 1.0462280288614438e-32, -0.10094477236270905, -0.02907383069396019, -0.04526601731777191, -0.16562844812870026, 0.0910690575838089, -0.09690336138010025, 0.0676782950758934, 0.0012626951793208718, 0.0847449004650116, 0.05472905561327934, -0.1631886065006256, 0.06908221542835236, -0.09051484614610672, -0.07690897583961487, -0.030344616621732712, -0.04529093950986862, 0.11499808728694916, -0.04087085276842117, 0.02952113188803196, 0.07204411923885345, 0.17193011939525604, 0.04152891784906387, -0.024172820150852203, -0.05089014768600464, -0.0032100526150316, -0.012512857094407082, -0.00665065785869956, -0.05769438296556473, -0.00753012066707015, 0.01383347436785698, -0.030657345429062843, -0.005019174423068762, 0.06320414692163467, -0.020976588129997253, -0.11554422229528427, -0.11483796685934067, 0.0241878442466259, -0.08021563291549683, 0.05794437602162361, -0.16912464797496796, -0.027208132669329643, 0.04152139276266098, -0.019927488639950752, 0.06372963637113571, 0.05033391714096069, 0.07306016236543655, 0.22451211512088776, 0.08601696789264679, -0.0902898758649826, 0.15056537091732025, 0.003949487581849098, -0.007672586943954229, -0.05747700855135918, -0.015756266191601753, -0.22965072095394135, 0.04488895460963249, 0.037856996059417725, -0.24571652710437775, 0.06829448789358139, 0.11387589573860168, 0.005133727565407753, -0.0038922724779695272, -0.0933060497045517, 0.017659803852438927, 0.01463615894317627, -0.03438807651400566, 0.035718511790037155, -0.08826036006212234, 0.16413533687591553, -0.11654362827539444, -0.015294061973690987, -0.006654961500316858, -0.0737856850028038, -0.06534522026777267, 0.037307195365428925, -0.04442301020026207, 0.10228152573108673, -0.09436933696269989, -0.08741074055433273, -0.09232197701931, -0.012955565936863422, 0.04140957444906235, 0.049627307802438736, -0.07913219183683395, -0.029382145032286644, 0.010660912841558456, 0.10265002399682999, -0.17606617510318756, -0.10251961648464203, -0.16365516185760498, -0.003865704871714115, 0.06042609363794327, -0.10437048971652985, -0.06942825764417648, 0.10935334861278534, -1.0089659599663311e-32, 0.025810305029153824, 0.027636060491204262, 0.08520587533712387, 0.05721466615796089, 0.013922535814344883, 0.04106275364756584, -0.036867402493953705, -0.11898684501647949, 0.07809553295373917, -0.2632821202278137, -0.11050061136484146, -0.121576689183712, 0.11161527037620544, -0.026005184277892113, -0.018540723249316216, 0.1342983841896057, -0.12192214280366898, -0.07838284969329834, -0.01090295147150755, 0.038351692259311676, 0.020965004339814186, 0.19883082807064056, -0.16496889293193817, 0.07815522700548172, -0.18941321969032288, 0.014784532599151134, -0.02832968160510063, 0.03545317053794861, -0.051501885056495667, -0.05991925671696663, -0.02728327549993992, -0.025084998458623886, -0.05781625956296921, -0.13944588601589203, 0.012757389806210995, -0.09431315958499908, 0.011018704622983932, -0.026161108165979385, -0.1529535949230194, 0.04771953448653221, 0.11130240559577942, 0.0941511020064354, -0.223643496632576, 0.1179746612906456, -0.03380071371793747, 0.08644157648086548, 0.0009311459725722671, 0.0919841080904007, 0.22880028188228607, -0.03600839525461197, 0.06119539216160774, 0.022793661803007126, -0.023898741230368614, 0.0036584464833140373, -0.04802950844168663, 0.11038382351398468, 0.01830262318253517, 0.058865707367658615, 0.09254322201013565, -0.028835037723183632, -0.06314153969287872, -0.1252344697713852, 0.05134880542755127, -0.06539913266897202, 0.08932436257600784, -0.021169790998101234, 0.05651818960905075, 0.05467918887734413, 0.05740868300199509, -0.010374835692346096, -0.14315158128738403, 0.045255716890096664, 0.03222878277301788, -0.19521260261535645, -0.023205649107694626, -0.0012390784686431289, -0.07263164222240448, -0.09344703704118729, -0.011175095103681087, 0.07402468472719193, -0.09309650212526321, 0.03305742144584656, 0.0427575521171093, 0.10873407125473022, -0.014760713092982769, 0.14081458747386932, 0.1435392200946808, 0.025986574590206146, 0.003164878347888589, -0.08417002111673355, -0.10245714336633682, 0.0986974686384201, -0.05945310369133949, 0.0945674479007721, -0.03746857866644859, -9.96464208924408e-08, -0.07906056940555573, 0.09125816076993942, -0.00974498875439167, 0.08721152693033218, 0.10983850806951523, -0.1483573019504547, 0.0735199898481369, 0.17984846234321594, 0.047638747841119766, 0.12338807433843613, 0.01433420181274414, -0.05109749734401703, -0.2228413224220276, 0.05380845069885254, 0.052024517208337784, 0.08548431098461151, 0.07434441894292831, 0.0655137151479721, -0.0338585302233696, 0.12602771818637848, 0.08681368827819824, 0.007218014448881149, -0.08217577636241913, 0.04037915915250778, 0.11307967454195023, -0.1018584668636322, 0.04045025631785393, 0.09421747922897339, 0.14799056947231293, 0.1808115541934967, -0.019498063251376152, -0.056507658213377, 0.16408732533454895, -0.02000301703810692, 0.11845335364341736, 0.06490270793437958, 0.18591251969337463, 0.03174838796257973, -0.21030990779399872, -0.08158758282661438, -0.061382684856653214, -0.025535324588418007, -0.0023536302614957094, -0.07037458568811417, 0.022276384755969048, -0.011292846873402596, -0.00470518134534359, -0.013558372855186462, 0.18086835741996765, -0.020326294004917145, 0.03291894868016243, -0.07189182192087173, -0.036890704184770584, 0.021892745047807693, 0.14005154371261597, -0.01724756881594658, -0.05117899924516678, -0.013538787141442299, 0.13001668453216553, 0.04083774983882904, 0.10867512226104736, -0.07361681014299393, 0.017827315255999565, 0.11608064919710159], metadata={'source': 'AAAMLP-569to.pdf', 'page': 152}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 153 # convert the array to float X = X.astype(float)  # randomly assign 10 elements to NaN (missing) X.ravel()[np.random.choice(X.size, 10, replace=False)] = np.nan  # use 2 nearest neighbours to fill na values knn_imputer = impute.KNNImputer(n_neighbors=2) knn_imputer.fit_transform(X) ═════════════════════════════════════════════════════════════════════════  Which fills the above matrix, as shown in figure 11.  \\n Figure 11: Values imputed by KNN Imputer  Another way of imputing missing values in a column would be to train a regression model that tries to predict missing values in a column based on other columns. So, you start with one column that has a missing value and treat this column as the target column for regression model without the missing values. Using all the other columns, you now train a model on samples for which there is no missing value in the concerned column and then try to predict target (the same column) for the samples that were removed earlier. This way, you have a more robust model based imputation.  Always remember that imputing values for tree-based models is unnecessary as they can handle it themselves.  What I have shown until now are some of the ways of creating features in general. Now, let’s say you are working on a problem of predicting store sales of different items (per week or month). You have items, and you have store ids. So, you can create features like items per store. Now, this is one of the features that is not discussed above. These kinds of features cannot be generalized and come purely from domain, data and business knowledge. Look at the data and see what fits and'),\n",
       " VectorParams(vector=[0.15222983062267303, 0.0022782981395721436, 0.0934743881225586, 0.01768765226006508, 0.031362082809209824, -0.05061767250299454, -0.24289807677268982, -0.06315474957227707, -0.23134887218475342, 0.007373372092843056, 0.06686732172966003, -0.05606994032859802, 0.03048785775899887, 0.16173410415649414, 0.009096378460526466, 0.12228235602378845, 0.005423090420663357, 0.1973738968372345, -0.06610254943370819, -0.16956233978271484, 0.0052018556743860245, 0.002189597114920616, -0.13924290239810944, 0.06632495671510696, -0.08938559889793396, -0.022472217679023743, 0.1721583753824234, -0.027797549962997437, 0.04523827135562897, -0.04391757771372795, -0.026909874752163887, -0.12025456130504608, 0.08805912733078003, 0.01685979776084423, -0.2529281675815582, 0.007835440337657928, -0.09973525255918503, -0.038538090884685516, -0.09205394238233566, -0.05230037868022919, 0.06509922444820404, 0.01541123166680336, -0.15255407989025116, -0.058966316282749176, 0.21852745115756989, 0.10946106910705566, -0.052207961678504944, 0.059938982129096985, 0.10675965249538422, -0.0016370867379009724, -0.15961670875549316, -0.021094568073749542, -0.10493244230747223, -0.04505674168467522, -0.009454450570046902, -0.11591721326112747, -0.0956515520811081, -0.10444092750549316, 0.05580230802297592, -0.0829441249370575, 0.09915938228368759, 0.11490444839000702, -0.08357182890176773, -0.056257154792547226, 0.11273302137851715, 0.06094885990023613, -0.1126776784658432, 0.0013346336781978607, 0.12713229656219482, 0.0008240919560194016, 0.05422716960310936, 0.0995650589466095, -0.13278353214263916, 0.11686049401760101, -0.026664579287171364, 0.12027391791343689, 0.00017937039956450462, 0.14566875994205475, 0.06083403155207634, 0.12948477268218994, -0.20042791962623596, 0.08647897839546204, -0.01571362279355526, -0.07470527291297913, 0.10631515830755234, 0.048713065683841705, -0.16923454403877258, 0.03935651108622551, -0.3159993290901184, 0.018726248294115067, 0.037880755960941315, -0.09559641778469086, 0.11102411150932312, -0.2318078577518463, -0.03176547959446907, 0.008155327290296555, 0.11274345964193344, -0.18791043758392334, -0.0499081052839756, -0.011008668690919876, -0.10916139930486679, 0.04259483516216278, 0.2302071899175644, 0.11513520777225494, 0.07988351583480835, 0.11348109692335129, -0.005856539122760296, -0.17987334728240967, 0.1405884176492691, -0.1258285641670227, 0.016421040520071983, -0.11185833811759949, -0.2753451466560364, -0.14209383726119995, 0.042790185660123825, -0.07490777969360352, -0.12996868789196014, -0.09584919363260269, -0.0866977795958519, 0.1085691824555397, 0.08914321660995483, -0.046603500843048096, -0.04987921565771103, 0.06734596192836761, 0.1142759919166565, 0.15883292257785797, -0.13034820556640625, 7.981014486804105e-33, -0.010973638854920864, -0.0014064130373299122, -0.1386825442314148, 0.07361806184053421, 0.03572860360145569, -0.008012933656573296, -0.03755723685026169, 0.0899636447429657, 0.08602514863014221, 0.06074121594429016, -0.059183645993471146, -0.11476785689592361, -0.041578471660614014, 0.07579877972602844, 0.1377604603767395, 0.020810123533010483, 0.04799226298928261, 0.01490843202918768, -0.07715623080730438, -0.09898024797439575, 0.01982778310775757, -0.10576797276735306, 0.04623865336179733, -0.012709291651844978, 0.10059477388858795, -0.023606203496456146, -0.024918487295508385, -0.13285592198371887, -0.1117968037724495, -0.01544373668730259, 0.04232960194349289, 0.003973080776631832, -0.18504628539085388, -0.008277414366602898, -0.04717583209276199, 0.03382778540253639, -0.02671271376311779, -0.1458776295185089, 0.15332497656345367, -0.008258974179625511, -0.02614521235227585, -0.03560857102274895, -0.05144152790307999, -0.029886603355407715, 0.0766734704375267, 0.292448490858078, 0.08106350898742676, -0.10083909332752228, -0.0979781225323677, 0.07734383642673492, -0.10551398992538452, 0.05968223512172699, -0.03536958992481232, -0.10291706770658493, -0.13559797406196594, 0.12900148332118988, 0.0758996456861496, -0.10364479571580887, -0.08959859609603882, 0.0657423883676529, 0.03665205463767052, -0.10760143399238586, 0.025615952908992767, -0.05154658854007721, -0.040498148649930954, -0.04563628137111664, 0.14126551151275635, 0.05922204628586769, 0.0785025805234909, -0.032369814813137054, -0.007339002098888159, 0.016490653157234192, 0.010949268937110901, -0.022834762930870056, -0.10165930539369583, 0.04958381503820419, 0.14649388194084167, -0.11828300356864929, -0.03634266182780266, 0.020128708332777023, -0.044565483927726746, 0.08271624147891998, 0.04940911382436752, -0.08051154762506485, 0.19257955253124237, -0.033242445439100266, -0.010258730500936508, -0.023458320647478104, -0.1360872983932495, 0.05149466544389725, -0.10796825587749481, 0.2961964011192322, -0.01482525747269392, 0.14523226022720337, 0.07941184937953949, -1.3818456250166229e-32, -0.12974858283996582, 0.02692422643303871, -0.09000305831432343, 0.015652986243367195, -0.09829133003950119, 0.07768327742815018, -0.17656660079956055, -0.16082985699176788, -0.1170230358839035, -0.002543940208852291, 0.13950689136981964, -0.0359136164188385, 0.026983868330717087, -0.16744014620780945, -0.07675310224294662, 0.03877922147512436, -0.1468791961669922, -0.002116934861987829, 0.031164251267910004, 0.2084045559167862, -0.12149310857057571, 0.152488574385643, -0.2200256586074829, 0.0367061123251915, 0.07653793692588806, -0.14422744512557983, -0.19357232749462128, -0.05176597088575363, 0.010549848899245262, 0.056604545563459396, -0.14034856855869293, 0.013972503133118153, 0.030477317050099373, -0.18961390852928162, -0.07100836932659149, -0.16277292370796204, -0.16775861382484436, -0.15588651597499847, 0.21775098145008087, 0.2666429877281189, 0.054784297943115234, 0.063878133893013, -0.15789029002189636, 0.005482641980051994, -0.058462828397750854, -0.16989171504974365, -0.019019126892089844, 0.04490242525935173, 0.09354853630065918, -0.0853102058172226, 0.03856866434216499, 0.054253317415714264, 0.0029448382556438446, -0.06778955459594727, -0.10474181920289993, 0.187444806098938, 0.022019224241375923, 0.0770815759897232, 0.17961782217025757, 0.03417603671550751, -0.2514534294605255, -0.049860864877700806, 0.13640058040618896, 0.0171479731798172, -0.048459529876708984, -0.1468457281589508, -0.021128563210368156, 0.12783923745155334, -0.1332176923751831, -0.16992101073265076, -0.12552519142627716, -0.010632574558258057, 0.006193513981997967, 0.12489545345306396, -0.21741756796836853, -0.2514682412147522, -0.07435066998004913, -0.11194419115781784, -0.041999489068984985, 0.05749859660863876, 0.0016458947211503983, 0.03054296225309372, -0.012770948000252247, 0.1836610734462738, 0.19581906497478485, 0.03539256006479263, 0.027827328070998192, -0.13750644028186798, 0.09875664114952087, -0.018167568370699883, -0.0527716688811779, 0.1664164811372757, -0.1532515436410904, 0.3536916673183441, 0.05436597391963005, -9.962511882122271e-08, -0.2593604028224945, 0.13621151447296143, 0.08240361511707306, 0.12881049513816833, -0.059045951813459396, -0.027181049808859825, 0.0035199392586946487, 0.17207226157188416, -0.13813580572605133, 0.034516654908657074, -0.12201613187789917, -0.06154720485210419, -0.1404210329055786, 0.18922746181488037, 0.24493151903152466, 0.015240997076034546, 0.09073573350906372, 0.10662414878606796, -0.0775255486369133, 0.10175874829292297, 0.17562279105186462, -0.027215950191020966, 0.05581090599298477, 0.11025790125131607, 0.03866245970129967, -0.22939369082450867, 0.04426351934671402, 0.056219227612018585, -0.022895537316799164, 0.17519371211528778, -0.0041083600372076035, 0.1701255738735199, 0.13914716243743896, 0.05586890131235123, 0.25782525539398193, 0.11341864615678787, 0.09092795848846436, 0.06537669897079468, -0.22876974940299988, -0.01377343200147152, 0.018517380580306053, 0.08228789269924164, -0.002864992246031761, -0.001331474632024765, -0.07508274912834167, 0.03113163821399212, 0.19799897074699402, -0.18057698011398315, 0.09893934428691864, 0.0851585641503334, 0.09970360994338989, -0.0034940410405397415, 0.1361289918422699, -0.011200955137610435, 0.23651272058486938, 0.09072260558605194, 0.11514492332935333, 0.04028618335723877, 0.2238020896911621, -0.07998460531234741, 0.11900897324085236, -0.08567575365304947, 0.0054920632392168045, -0.02993648685514927], metadata={'source': 'AAAMLP-569to.pdf', 'page': 153}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 154 create features accordingly. And always remember to scale or normalize your features if you are using linear models like logistic regression or a model like SVM. Tree-based models will always work fine without any normalization of features.'),\n",
       " VectorParams(vector=[0.04211624711751938, -0.10421326011419296, 0.10694742947816849, 0.08820840716362, 0.09692442417144775, -0.07311822474002838, -0.06401143968105316, -0.07149630784988403, -0.040344852954149246, -0.021779850125312805, -0.02103649452328682, -0.04186341166496277, -0.03277358040213585, 0.010621484369039536, 0.05216981843113899, 0.03855835646390915, 0.09036009013652802, 0.02752126380801201, -0.04235328733921051, -0.05910681560635567, 0.022150056436657906, -0.015357483178377151, -0.10096823424100876, 0.12189508974552155, -0.056474748998880386, -0.0637587159872055, 0.06686299294233322, 0.027494380250573158, -0.1365606039762497, -0.016232334077358246, 0.0031304387375712395, 0.019148055464029312, -0.053222011774778366, -0.1052919551730156, -0.05867035314440727, 0.0015893180388957262, 0.04334823042154312, 0.05027760565280914, -0.025246482342481613, -0.02856392040848732, -0.06047612428665161, -0.041771482676267624, 0.005018205381929874, -0.006913162302225828, 0.14413538575172424, 0.08447162806987762, 0.0019874554127454758, -0.08242004364728928, 0.09983712434768677, -0.08058624714612961, -0.009127453900873661, 0.1129007488489151, -0.0844491496682167, -0.011087168008089066, -0.002048550173640251, -0.2167109102010727, 0.030074741691350937, -0.038147371262311935, 0.05994478613138199, -0.05740537866950035, -0.004741540178656578, -0.03913984075188637, -0.013049970380961895, -0.060781411826610565, -0.017773529514670372, 0.050974126905202866, -0.05836758390069008, -0.029093842953443527, 0.006722744088619947, 0.09149550646543503, -0.057020001113414764, 0.05838891118764877, -0.026588447391986847, 0.178937628865242, 0.0009110676473937929, -0.009697034023702145, 0.11968360096216202, 0.0008458298398181796, 0.12092740833759308, 0.02832290716469288, -0.07992032170295715, 0.14530086517333984, -0.021976539865136147, -0.013186649419367313, 0.0056616319343447685, -0.056470539420843124, 0.032950032502412796, 0.023353582248091698, -0.06803903728723526, 0.004291312303394079, 0.1462354212999344, -0.046164169907569885, 0.06650420278310776, -0.11412911862134933, 0.009482420049607754, 0.0892152264714241, 0.0404520258307457, -0.043340299278497696, -0.014252591878175735, 0.06329821795225143, 0.04342598468065262, -0.015299895778298378, 0.023752961307764053, 0.023023033514618874, 0.03457868844270706, 0.00985342264175415, 0.054469868540763855, 0.017640991136431694, 0.0004731377703137696, -0.03918883204460144, 0.0030286989640444517, -0.11759687215089798, -0.15204721689224243, -0.027052627876400948, 0.05679827183485031, 0.19892127811908722, -0.09011711925268173, -0.012052063830196857, -0.060163628309965134, 0.17263640463352203, -0.005293072666972876, -0.011567641980946064, 0.007379279471933842, 0.021702034398913383, 0.026691703125834465, 0.09924008697271347, -0.1195957139134407, 1.4409153916397936e-32, -0.014682956971228123, 0.007647049613296986, -0.05303705856204033, -0.06023010239005089, -0.0666997879743576, -0.0136452317237854, 0.0910690426826477, 0.09418750554323196, 0.08221764117479324, 0.10800741612911224, -0.050552938133478165, 0.08816127479076385, -0.060009196400642395, 0.0022770967334508896, 0.08475593477487564, -0.03248884156346321, 0.0062905894592404366, 0.004937284626066685, 0.024036109447479248, 0.003712157718837261, 0.16587725281715393, -0.12726972997188568, -0.00567598408088088, 0.017694350332021713, -0.023510795086622238, -0.1327948421239853, -0.10464141517877579, 0.020497752353549004, -0.20270247757434845, 0.011540433391928673, -0.13576754927635193, 0.06107479706406593, -0.03268098831176758, 0.0487629659473896, -0.013958456926047802, -0.1566331535577774, 0.04994223639369011, -0.11802875250577927, 0.09897100180387497, 0.07364846020936966, 0.002854487858712673, 0.04573854058980942, -0.041164446622133255, 0.06250012665987015, 0.03962109237909317, 0.18407154083251953, 0.014969621784985065, -0.046543121337890625, -0.11572416126728058, 0.12454130500555038, 0.012526408769190311, -0.04298143833875656, -0.09298057109117508, 0.035526175051927567, -0.19196201860904694, 0.04960959032177925, -0.013467589393258095, -0.1937156319618225, 0.009281064383685589, -0.04019533470273018, -0.10424520075321198, -0.05642018839716911, 0.04942559078335762, -0.07689698785543442, 0.028676804155111313, -0.030437368899583817, 0.15402871370315552, 0.15438517928123474, 0.044943906366825104, -0.04077313095331192, -0.07179224491119385, 0.010388452559709549, 0.004046156536787748, -0.2258796989917755, 0.16526657342910767, -0.11841544508934021, 0.1592162847518921, 0.03658313304185867, -0.08791112899780273, 0.016470540314912796, -0.033864863216876984, 0.1597108244895935, 0.018312934786081314, -0.12421175837516785, 0.16452710330486298, 0.0017395740142092109, -0.004492979496717453, -0.05985432118177414, -0.1614614576101303, -0.06532605737447739, -0.1317775845527649, 0.1461023986339569, 0.0009352132328785956, -0.08942794799804688, -0.0443606823682785, -1.2090067396750709e-32, 0.025954755023121834, -0.053293678909540176, 0.11843005567789078, 0.05132411792874336, -0.03897010535001755, 0.0597042590379715, -0.059079643338918686, 0.01676134578883648, -0.03525181859731674, -0.26098284125328064, -0.005983405280858278, -0.1407223790884018, 0.15954087674617767, -0.053107816725969315, 0.009922105818986893, 0.1484898328781128, -0.12167362868785858, 0.0299970805644989, 0.011015872471034527, 0.16631647944450378, -0.08905845880508423, -0.012017800472676754, -0.0957280695438385, -0.05710652843117714, -0.10379574447870255, -0.023491302505135536, -0.11259970813989639, -0.01699691452085972, 0.10689790546894073, -0.0015331852482631803, -0.11891760677099228, 0.15877744555473328, -0.1296190321445465, 0.02205316536128521, 0.025845976546406746, -0.03658398240804672, 0.014493846334517002, 0.05952538177371025, -0.026688575744628906, 0.01849638670682907, 0.12327847629785538, 0.10993227362632751, -0.12107789516448975, 0.045821767300367355, -0.011563594453036785, -0.01828848570585251, -0.0517645925283432, 0.01295661460608244, 0.0737912654876709, 0.0440562479197979, 0.09414909034967422, -0.05718490481376648, -0.07611416280269623, 0.03862294182181358, -0.03061586245894432, 0.015747785568237305, -0.044507529586553574, 0.03766439110040665, 0.04703690856695175, 0.037124063819646835, -0.0639810785651207, 0.008115474134683609, -0.020013580098748207, 0.060505211353302, 0.15635132789611816, 0.06702448427677155, -0.02588358148932457, 0.06811534613370895, -0.055997300893068314, 0.031113499775528908, -0.11603506654500961, -0.10025721788406372, 0.06630726158618927, -0.09520259499549866, -0.09511474519968033, 0.019846584647893906, -0.009842151775956154, -0.0974154844880104, -0.08319870382547379, 0.17132695019245148, 0.07681607455015182, 0.05114502087235451, -0.0012674164026975632, 0.02450980246067047, 0.04217370226979256, 0.1699388176202774, -0.03531902655959129, 0.09322832524776459, 0.0765874981880188, -0.04643627256155014, -0.021367762237787247, 0.07510878145694733, 0.054585255682468414, 0.024982118979096413, 0.057682182639837265, -9.986594307065388e-08, 0.046488068997859955, 0.03182787448167801, 0.04445382580161095, -0.07975097000598907, 0.014530597254633904, 0.019453231245279312, -0.037461407482624054, 0.14422214031219482, -0.033477574586868286, 0.06048472970724106, 0.09795600920915604, 0.01732250116765499, -0.05695321783423424, 0.15617744624614716, 0.04089842736721039, 0.06138282269239426, 0.0251238364726305, -0.015088986605405807, -0.05881933122873306, 0.04396729916334152, 0.06670475751161575, -0.1352643072605133, 0.01514703594148159, -0.027271060273051262, 0.05437396466732025, -0.15996645390987396, 0.05408081039786339, 0.022822745144367218, 0.08325368165969849, 0.11471907049417496, -0.07625673711299896, -0.16843421757221222, -0.06281425803899765, -0.0030211657285690308, 0.30676984786987305, 0.02404288947582245, -0.028138572350144386, -0.0769609659910202, -0.06508292257785797, 0.05022719129920006, -0.10760150104761124, 0.04921050742268562, -0.05688060447573662, -0.029023470357060432, -0.008721821010112762, -0.0025238150265067816, 0.062289442867040634, -0.01945842057466507, 0.0823613703250885, 0.06341065466403961, 0.07752009481191635, -0.03178088366985321, -0.07123607397079468, 0.026744447648525238, 0.017095493152737617, 0.10832396149635315, -0.031537141650915146, 0.03060348518192768, 0.010101745836436749, -0.09347112476825714, -0.02725612185895443, -0.0018427354516461492, -0.00938592292368412, -0.05771837756037712], metadata={'source': 'AAAMLP-569to.pdf', 'page': 154}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 155 Feature selection  When you are done creating hundreds of thousands of features, it’s time for selecting a few of them. Well, we should never create hundreds of thousands of useless features. Having too many features pose a problem well known as the curse of dimensionality. If you have a lot of features, you must also have a lot of training samples to capture all the features. What’s considered a “lot” is not defined correctly and is up to you to figure out by validating your models properly and checking how much time it takes to train your models.  The simplest form of selecting features would be to remove features with very low variance. If the features have a very low variance (i.e. very close to 0), they are close to being constant and thus, do not add any value to any model at all. It would just be nice to get rid of them and hence lower the complexity. Please note that the variance also depends on scaling of the data. Scikit-learn has an implementation for VarianceThreshold that does precisely this.  ═════════════════════════════════════════════════════════════════════════ from sklearn.feature_selection import VarianceThreshold data = ... var_thresh = VarianceThreshold(threshold=0.1) transformed_data = var_thresh.fit_transform(data) # transformed data will have all columns with variance less  # than 0.1 removed ═════════════════════════════════════════════════════════════════════════  We can also remove features which have a high correlation. For calculating the correlation between different numerical features, you can use the Pearson correlation.   ═════════════════════════════════════════════════════════════════════════ import pandas as pd from sklearn.datasets import fetch_california_housing  # fetch a regression dataset data = fetch_california_housing() X = data[\"data\"] col_names = data[\"feature_names\"] y = data[\"target\"]  # convert to pandas dataframe'),\n",
       " VectorParams(vector=[-0.04445163905620575, -0.12857578694820404, 0.044838618487119675, 0.05665087699890137, 0.16561801731586456, 0.006010050885379314, -0.06090645119547844, -0.022348793223500252, -0.03998725861310959, 0.08769647032022476, -0.035321194678545, -0.053542185574769974, -0.14423327147960663, 0.08769073337316513, 0.001817812561057508, 0.03822468966245651, 0.1497984230518341, -0.06423323601484299, -0.027840157970786095, 0.062117066234350204, -0.0710623487830162, 0.08115378767251968, -0.004382519982755184, 0.1307874619960785, -0.05721035227179527, -0.03149222210049629, 0.15400344133377075, 0.07926703989505768, -0.15879862010478973, -0.03019370511174202, -0.016213705763220787, 0.16170130670070648, -0.059205345809459686, -0.0740058645606041, -0.20284001529216766, 0.03746241331100464, 0.017754649743437767, 0.055285435169935226, -0.05955278128385544, -0.041413113474845886, -0.05761710926890373, -0.09726950526237488, 0.012991293333470821, 0.06518084555864334, 0.1657724529504776, -0.009123552590608597, -0.06937137246131897, -0.024694185703992844, 0.03163398429751396, 0.006492279935628176, -0.10216117650270462, 0.1690954715013504, -0.16364888846874237, 0.06705523282289505, 0.003298904513940215, -0.23043444752693176, 0.026197226718068123, -0.11702124774456024, 0.03011212684214115, 0.03629282861948013, 0.0013880524784326553, -0.07493805885314941, 0.002235795371234417, -0.007166007533669472, 0.0027477170806378126, -0.03116624988615513, -0.037331968545913696, 0.01493916567414999, 0.03311575576663017, 0.10374263674020767, -0.030954601243138313, 0.01881204918026924, -0.0193437859416008, 0.08210095763206482, 0.03632735088467598, 0.08883188664913177, 0.07086293399333954, 0.005010874941945076, 0.13450227677822113, -0.007049257401376963, -0.042521167546510696, 0.1408824622631073, -0.02000003680586815, 0.09368079155683517, 0.12177922576665878, -0.029644103720784187, 0.05278738588094711, -0.0023673188406974077, -0.1035800501704216, 0.06819663941860199, 0.16982832551002502, 0.02843911573290825, 0.07401499897241592, -0.13661767542362213, -0.02219083160161972, 0.009710966609418392, 0.0832214206457138, -0.08304381370544434, -0.025190016254782677, 0.005532689858227968, 0.026747697964310646, -0.049853961914777756, -0.001848995336331427, -0.028848109766840935, 0.048091184347867966, -0.07309366762638092, 0.056849315762519836, -0.011317707598209381, 0.0954294353723526, -0.05754203721880913, -0.08175963163375854, -0.0024546294007450342, -0.15817990899085999, 0.011717444285750389, 0.0005099934642203152, 0.16636905074119568, -0.012862580828368664, 0.07862266898155212, 0.13591592013835907, 0.14054524898529053, -0.03955734148621559, -0.04139511659741402, -0.10558567196130753, 0.012221656739711761, 0.030314676463603973, 0.11586728692054749, -0.11038969457149506, 1.3036179453373381e-32, 0.0008552813087590039, -0.07130376994609833, 0.042666755616664886, 0.010510054416954517, -0.1468724012374878, -0.11125678569078445, -0.04695117101073265, -0.015249247662723064, 0.1281767189502716, 0.10919871181249619, -0.06841715425252914, 0.12754510343074799, -0.0357266329228878, 0.015987155959010124, 0.055750634521245956, -0.051160380244255066, -0.06145304813981056, 0.00783899612724781, -0.04969695210456848, 0.0019394417759031057, 0.1023702323436737, -0.02044812962412834, -0.03951413184404373, -0.02669409103691578, -0.05483440309762955, -0.08118686825037003, -0.0847407877445221, -0.04482998698949814, -0.09767436236143112, 0.02871556207537651, -0.17677617073059082, 0.036062613129615784, -0.018003450706601143, 0.09174887835979462, -0.010537547059357166, -0.09077078104019165, -0.07123342156410217, -0.08635060489177704, 0.06682173907756805, 0.07991940528154373, -0.004815883934497833, -0.015009497292339802, 0.0201330054551363, 0.04895367473363876, 0.08028504252433777, 0.11587584018707275, 0.00031605950789526105, -0.040852662175893784, -0.05747617036104202, -0.020381808280944824, 0.035752180963754654, -0.025073567405343056, 0.006441846024245024, 0.017491105943918228, -0.09226453304290771, 0.073067307472229, -0.022261690348386765, -0.10219242423772812, -0.011852463707327843, -0.010772197507321835, -0.08673764765262604, -0.03478376939892769, -0.01085198950022459, -0.1464610993862152, -0.022666137665510178, -0.05385858565568924, 0.04887484386563301, 0.012672238983213902, 0.020381726324558258, -0.05195054039359093, 0.024683402851223946, 0.07846414297819138, 0.010020713321864605, -0.1899787336587906, 0.06313896924257278, 0.008672007359564304, 0.14241856336593628, -0.0027404166758060455, 0.01856573112308979, -0.09925756603479385, 0.028727248311042786, 0.07090851664543152, -0.04047960415482521, -0.10345751792192459, 0.035113077610731125, -0.04082051292061806, -0.007382947951555252, -0.1114409863948822, -0.2684382498264313, -0.0508262924849987, -0.030494531616568565, 0.191602885723114, 0.04476064816117287, 0.003852107794955373, 0.06612200289964676, -1.2613962453709155e-32, -0.04632654786109924, -0.09040098637342453, 0.15194593369960785, 0.06417199224233627, -0.000361541286110878, 0.08783118426799774, 0.008045964874327183, -0.14043588936328888, 0.025911986827850342, -0.18744833767414093, 0.023994164541363716, -0.13076242804527283, 0.07445785403251648, -0.12443649023771286, 0.041142769157886505, 0.20739780366420746, -0.15223519504070282, -0.007985178381204605, -0.030100027099251747, 0.11576104909181595, -0.09430821239948273, 0.08644142001867294, 0.016057953238487244, -0.0533241331577301, -0.05265835300087929, -0.03383810818195343, -0.007738681510090828, -0.013305606320500374, -0.0014636258129030466, -0.03208368271589279, -0.0610181950032711, 0.1316109001636505, -0.24341486394405365, 0.005556478630751371, 0.04192637279629707, -0.011619317345321178, -0.021796241402626038, -0.06437691301107407, -0.05352365970611572, 0.07784707099199295, 0.10336669534444809, 0.19268301129341125, -0.05629335343837738, 0.09924101084470749, 0.09972098469734192, -0.05963508412241936, -0.004378283862024546, 0.05377165600657463, 0.1733989417552948, 0.041642047464847565, 0.04494710639119148, -0.011217056773602962, -0.04102441295981407, 0.03555789217352867, -0.07369682937860489, 0.13065870106220245, 0.008451288565993309, -0.017981713637709618, 0.06325012445449829, 0.08984994888305664, 0.004885334055870771, -0.0351734533905983, -0.004512919578701258, 0.005030510947108269, 0.036858681589365005, -0.01123858243227005, 0.10671015083789825, 0.10492900758981705, -0.06660765409469604, -0.024946818128228188, -0.02810814417898655, -0.05541273579001427, 0.06699367612600327, -0.17709609866142273, -0.021806811913847923, 0.06160462275147438, -0.013829533010721207, -0.1078486442565918, -0.16947850584983826, 0.10842788964509964, 0.08048240095376968, 0.04024124518036842, -0.0009576770244166255, 0.008920201100409031, -0.029417861253023148, 0.14970645308494568, 0.10653752088546753, 0.039378806948661804, 0.054867666214704514, -0.12574955821037292, 0.0007184994174167514, 0.04728183522820473, -0.06971120089292526, 0.07205715030431747, 0.0706053227186203, -9.854626625838137e-08, 0.036836009472608566, -0.07696665823459625, -0.09769882261753082, -0.1498977690935135, 0.13158321380615234, -0.07459202408790588, -0.09066550433635712, 0.15382805466651917, -0.02777796983718872, 0.18761971592903137, 0.08630304038524628, 0.08362392336130142, -0.15479880571365356, 0.09835963696241379, 0.04306633397936821, 0.030066706240177155, 0.12317678332328796, 0.06532254815101624, -0.009686402045190334, -0.01851179264485836, 0.12439990043640137, -0.13556227087974548, -0.00848975870758295, 0.008180838078260422, 0.008857996203005314, -0.12096557766199112, -0.041434064507484436, -0.06340081244707108, 0.1749780923128128, 0.11763819307088852, -0.06862465292215347, -0.11327017098665237, -0.0002470373292453587, 0.012915274128317833, 0.20574912428855896, 0.12219115346670151, 0.04844942316412926, -0.09117045253515244, -0.09712784737348557, 0.10507947951555252, -0.03461969643831253, 0.10614743828773499, -0.08456569910049438, -0.027787892147898674, -0.05945075675845146, 0.00783449225127697, 0.11327313631772995, 0.05296250432729721, 0.0393546037375927, 0.028161192312836647, 0.017833324149250984, -0.08978762477636337, -0.009347268380224705, -0.05574500933289528, 0.04862478747963905, 0.15168873965740204, -0.06414307653903961, 0.06595514714717865, 0.032589949667453766, -0.06891436129808426, -0.028295407071709633, 0.018541719764471054, -0.06399120390415192, -0.009192842990159988], metadata={'source': 'AAAMLP-569to.pdf', 'page': 155}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 156 df = pd.DataFrame(X, columns=col_names) # introduce a highly correlated column df.loc[:, \"MedInc_Sqrt\"] = df.MedInc.apply(np.sqrt)  # get correlation matrix (pearson) df.corr() ═════════════════════════════════════════════════════════════════════════  Which gives a correlation matrix, as shown in figure 1.  \\n Figure 1: A sample Pearson correlation matrix  We see that the feature MedInc_Sqrt has a very high correlation with MedInc. We can thus remove one of them.   And now we can move to some univariate ways of feature selection. Univariate feature selection is nothing but a scoring of each feature against a given target. Mutual information, ANOVA F-test and chi2 are some of the most popular methods for univariate feature selection. There are two ways of using these in scikit-learn.  - SelectKBest: It keeps the top-k scoring features - SelectPercentile: It keeps the top features which are in a percentage specified by the user  It must be noted that you can use chi2 only for data which is non-negative in nature. This is a particularly useful feature selection technique in natural language processing when we have a bag of words or tf-idf based features. It’s best to create a wrapper for univariate feature selection that you can use for almost any new problem.'),\n",
       " VectorParams(vector=[-0.13851332664489746, -0.02581261470913887, 0.036238059401512146, 0.0361458845436573, 0.1941603720188141, -0.050823960453271866, 0.039417460560798645, 0.08754593133926392, -0.11988648027181625, -0.01416467409580946, -0.01895361766219139, -0.11035754531621933, 0.04090340808033943, 0.022363517433404922, -0.028911544010043144, 0.005817345343530178, 0.05534564331173897, -0.0181221105158329, -0.07438644021749496, 0.049741003662347794, 0.011689981445670128, 0.08894480019807816, -0.08130098134279251, 0.10903357714414597, -0.04256530851125717, -0.13841843605041504, 0.1227070540189743, 0.19294720888137817, -0.20013247430324554, -0.07432279735803604, -0.06767331808805466, 0.053602855652570724, -0.13233551383018494, 0.08716747164726257, -0.0014387216651812196, -0.006934192031621933, -0.04973352700471878, -0.026833156123757362, -0.12192227691411972, -0.05467997118830681, -0.053033020347356796, -0.09941659867763519, -0.0042038909159600735, -0.03998462110757828, 0.10693814605474472, 0.052679214626550674, -0.188627690076828, -0.049828846007585526, 0.02984885312616825, -0.05906875059008598, -0.07973887026309967, 0.201234832406044, -0.07797477394342422, 0.04406045004725456, 0.13218292593955994, -0.1164945662021637, 0.019123515114188194, -0.12468050420284271, 0.04696838930249214, -0.0355970673263073, -0.03555120900273323, -0.11624306440353394, -0.0213804692029953, -0.019732898101210594, -0.05562532693147659, -0.030574452131986618, -0.007726926822215319, 0.04149071127176285, -0.004129417706280947, 0.10998658090829849, -0.03820084035396576, 0.11262404918670654, -0.06923681497573853, 0.11716540902853012, 0.11633780598640442, 0.013314549811184406, 0.13346466422080994, 0.04947448894381523, 0.02159033715724945, 0.013402237556874752, -0.30472812056541443, 0.12366316467523575, 0.021937185898423195, 0.0406847782433033, 0.1335604041814804, -0.20574788749217987, -0.036057014018297195, 0.024333709850907326, 0.11595235019922256, 0.05214850977063179, 0.08207867294549942, 0.0288791973143816, -0.07221768796443939, -0.06603320688009262, 0.0862913504242897, 0.05907938629388809, -0.03519882634282112, -0.1397423893213272, -0.013305180706083775, 0.08068503439426422, -0.07964465767145157, -0.07948435097932816, 0.008256233297288418, -0.10444532334804535, 0.1552940309047699, 0.04465177282691002, 0.14614343643188477, -0.11284179985523224, 0.13594907522201538, -0.07930867373943329, -0.06477196514606476, -0.11546269059181213, -0.02414577640593052, 0.0008057192317210138, 0.04878842830657959, 0.13999687135219574, -0.00025281295529566705, 0.12673214077949524, 0.12223658710718155, 0.03312327340245247, 0.023487791419029236, -0.021053919568657875, 0.03408405929803848, 0.08063794672489166, 0.00934805441647768, -0.0014973500510677695, -0.16063153743743896, 1.3496018149735675e-32, -0.08669006079435349, -0.08045420795679092, 0.024047883227467537, -0.10311609506607056, -0.17571356892585754, -0.0181900467723608, -0.0990724042057991, 0.08498886972665787, 0.054781701415777206, -0.04961284250020981, -0.09334641695022583, 0.054899170994758606, -0.10606449097394943, -0.04551117867231369, 0.17185865342617035, 0.03644359111785889, -0.03594142943620682, 0.11752217262983322, 0.006681190803647041, 0.07590240240097046, 0.23104228079319, -0.09315422177314758, 0.03734408691525459, -0.0370892696082592, -0.043488435447216034, 0.013824429363012314, -0.052545107901096344, -0.08052025735378265, -0.0837402492761612, 0.02647944912314415, -0.16251526772975922, -0.04162637144327164, 0.1104123443365097, -0.03125573694705963, -0.0021333186887204647, -0.037150345742702484, -0.032919928431510925, 0.037586528807878494, -0.050569433718919754, 0.017336567863821983, 0.0005752656143158674, 0.011433370411396027, 0.09594028443098068, 0.016488919034600258, 0.05183326452970505, -0.022928018122911453, -0.06710262596607208, 0.07529470324516296, 0.04458015039563179, -0.01624663732945919, -0.018190819770097733, -0.1133228987455368, 0.013626347295939922, -0.0635012611746788, -0.07561294734477997, 0.15389972925186157, -0.021494030952453613, 0.03209773823618889, 0.08046994358301163, -0.06941081583499908, -0.051765721291303635, -0.025933871045708656, -4.4965065171709284e-05, -0.14658014476299286, 0.04789678752422333, 0.07166548818349838, 0.0029335960280150175, 0.08244526386260986, 0.11478783935308456, -0.15344256162643433, -0.08682408183813095, 0.08390672504901886, -0.08142264187335968, -0.06849762797355652, 0.03992125764489174, -0.12636341154575348, 0.13616324961185455, -0.10926713794469833, -0.03350299596786499, -0.1214338093996048, 0.022792212665081024, 0.06723844259977341, -0.15756472945213318, -0.140215665102005, -0.016546636819839478, -0.024302683770656586, 0.019050605595111847, -0.040738314390182495, -0.2172556221485138, -0.07002482563257217, -0.154392808675766, 0.05914653465151787, -0.03626430034637451, -0.04668904095888138, 0.020782288163900375, -1.5434583189026312e-32, -0.010246992111206055, 0.02212802693247795, 0.11281777173280716, 0.13822431862354279, 0.08631984889507294, 0.03464766591787338, -0.014718512073159218, -0.10674790292978287, 0.012011523358523846, -0.11474935710430145, -0.09916013479232788, -0.16544954478740692, 0.11377449333667755, -0.10214647650718689, 0.004746561869978905, 0.13524892926216125, -0.3020651340484619, 0.08553363382816315, -0.006463231984525919, 0.1607629358768463, -0.11410612612962723, 0.1075904592871666, 0.05083416774868965, -0.0424485057592392, -0.1448211669921875, 0.04965144395828247, -0.1134999468922615, 0.13083675503730774, 0.03231004625558853, 0.04645044356584549, -0.026563283056020737, 0.06725021451711655, -0.2803053557872772, -0.04718879610300064, 0.14243756234645844, -0.15586064755916595, -0.017619099467992783, -0.1212242990732193, -0.06777225434780121, 0.2030356228351593, 0.1662542223930359, 0.23798222839832306, -0.12100109457969666, 0.006303985603153706, -0.0005568102351389825, 0.05335581675171852, 0.0576125904917717, -0.0381486602127552, 0.025039611384272575, -0.09062673896551132, -0.034661490470170975, -0.0366678312420845, -0.1495014876127243, 0.14287619292736053, -0.12747998535633087, 0.0715051144361496, -0.0057417587377130985, 0.11407008022069931, -0.0017479234375059605, 0.0483987033367157, -0.05736217275261879, -0.05391976237297058, -0.0020768586546182632, 0.0787702426314354, 0.09053485840559006, 0.031045973300933838, -0.02443227358162403, 0.09434030950069427, -0.06400173157453537, 0.11975179612636566, -0.17179489135742188, -0.018553417176008224, 0.11711424589157104, -0.10712700337171555, -0.020950697362422943, 0.15762540698051453, 0.07555653899908066, -0.030615834519267082, -0.016835879534482956, 0.11639374494552612, -0.06651143729686737, -0.01488762442022562, 0.03259197622537613, 0.12659728527069092, -0.07986919581890106, 0.11019962280988693, 0.16491901874542236, 0.23482711613178253, 0.01672445237636566, -0.13153475522994995, 0.0036680418998003006, 0.05726014822721481, 0.07353485375642776, 0.07600250840187073, -0.07697395235300064, -1.0060993105298621e-07, 0.017485903576016426, -0.07381404936313629, 0.0459187775850296, -0.002854756312444806, 0.04379205405712128, -0.02740485779941082, -0.12627087533473969, -0.05667669326066971, -0.08849072456359863, 0.01090322993695736, 0.016754047945141792, 0.11004474014043808, -0.07599491626024246, -0.021159108728170395, -0.02742042765021324, -0.02777797542512417, 0.06665309518575668, 0.11486460268497467, -0.0781056135892868, 0.00709373177960515, 0.060753967612981796, -0.12020339071750641, -0.05016252398490906, 0.06755381077528, -0.029664980247616768, -0.049872785806655884, -0.008968374691903591, -0.04814665764570236, 0.13123764097690582, 0.14078976213932037, -0.0034824300091713667, -0.046321969479322433, 0.041335977613925934, 0.01554203499108553, 0.13359904289245605, 0.132010817527771, 0.027974965050816536, -0.010132493451237679, 0.006874970160424709, 0.07683943212032318, -0.038761936128139496, 0.10447477549314499, -0.16865423321723938, -0.09190712869167328, 0.08931730687618256, -0.0021788293961435556, 0.09677904844284058, -0.06300383061170578, 0.013334628194570541, 0.09901575744152069, -0.05508863180875778, -0.0430472232401371, -0.0885036513209343, 0.022339239716529846, 0.08749911934137344, 0.023198826238512993, -0.061685461550951004, -0.011401038616895676, 0.020689209923148155, -0.0728577971458435, -0.0006249945145100355, 0.029021674767136574, 0.025353243574500084, 0.05182667449116707], metadata={'source': 'AAAMLP-569to.pdf', 'page': 156}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 157 ═════════════════════════════════════════════════════════════════════════ from sklearn.feature_selection import chi2 from sklearn.feature_selection import f_classif from sklearn.feature_selection import f_regression from sklearn.feature_selection import mutual_info_classif from sklearn.feature_selection import mutual_info_regression from sklearn.feature_selection import SelectKBest from sklearn.feature_selection import SelectPercentile   class UnivariateFeatureSelction:     def __init__(self, n_features, problem_type, scoring):         \"\"\"         Custom univariate feature selection wrapper on         different univariate feature selection models from         scikit-learn.         :param n_features: SelectPercentile if float else SelectKBest         :param problem_type: classification or regression         :param scoring: scoring function, string         \"\"\"         # for a given problem type, there are only         # a few valid scoring methods         # you can extend this with your own custom         # methods if you wish         if problem_type == \"classification\":             valid_scoring = {                 \"f_classif\": f_classif,                 \"chi2\": chi2,                 \"mutual_info_classif\": mutual_info_classif             }         else:             valid_scoring = {                 \"f_regression\": f_regression,                 \"mutual_info_regression\": mutual_info_regression             }                  # raise exception if we do not have a valid scoring method         if scoring not in valid_scoring:             raise Exception(\"Invalid scoring function\")                  # if n_features is int, we use selectkbest         # if n_features is float, we use selectpercentile         # please note that it is int in both cases in sklearn         if isinstance(n_features, int):             self.selection = SelectKBest(                 valid_scoring[scoring],                 k=n_features'),\n",
       " VectorParams(vector=[-0.09440507739782333, -0.0990481898188591, 0.04580126330256462, 0.041979920119047165, 0.1648988425731659, -0.10692349821329117, -0.05287735164165497, -0.007552354596555233, -0.08107395470142365, -0.030831273645162582, -0.06261813640594482, -0.10553932189941406, 0.016950560733675957, 0.048129212111234665, 0.019774245098233223, 0.021769976243376732, 0.010577516630291939, 0.05138096958398819, -0.07649877667427063, -0.05267990380525589, 0.05735933780670166, 0.0400322750210762, -0.06053381785750389, 0.04047279432415962, 0.023774171248078346, -0.13878189027309418, 0.021248022094368935, 0.038140829652547836, -0.14919742941856384, -0.058667708188295364, -0.07655395567417145, 0.09916063398122787, -0.08398208022117615, -0.012913894839584827, -0.1263655573129654, 0.05010220780968666, -0.05683629587292671, -0.05989586189389229, -0.16960221529006958, -0.062495775520801544, -0.004376299679279327, -0.09284023940563202, 0.01439753919839859, 0.04453412443399429, 0.1583983451128006, 0.0239622313529253, -0.051136165857315063, -0.03215927258133888, 0.14735935628414154, -0.020088667050004005, -0.03966117650270462, 0.19549845159053802, -0.0909118726849556, 0.10217288136482239, 0.05091100186109543, -0.14874739944934845, 0.13053683936595917, -0.10608965158462524, 0.01778002269566059, -0.15249574184417725, 0.025224654003977776, -0.039513830095529556, 0.03194694593548775, -0.03249048441648483, -0.024411702528595924, -0.04260966181755066, -0.016234949231147766, -0.10318859666585922, -0.07227090746164322, 0.07273959368467331, -0.00539976404979825, 0.07221300899982452, -0.06398977339267731, 0.08738680928945541, 0.12087513506412506, -0.010101700201630592, 0.1964097023010254, 0.05148148909211159, 0.009699283167719841, 0.09447059035301208, -0.0570845901966095, 0.1356641948223114, 0.03423338383436203, -0.022335905581712723, 0.11703620851039886, -0.12413480132818222, -0.003128024050965905, 0.002230687066912651, 0.012178033590316772, 0.1347779482603073, 0.10949107259511948, 0.07814476639032364, -0.0010395392309874296, -0.09771119058132172, 0.044718947261571884, 0.015358689241111279, 0.031369149684906006, -0.1394869089126587, 0.04442812502384186, 0.03790659084916115, -0.08456151932477951, -0.012481708079576492, 0.15404365956783295, -0.0691152960062027, 0.08734716475009918, -0.08237085491418839, 0.0451461561024189, 0.026109186932444572, 0.05452003702521324, -0.18748241662979126, -0.09509962052106857, -0.13330116868019104, -0.027516892179846764, 0.02088298089802265, 0.05941513180732727, 0.0504990890622139, -0.09684527665376663, 0.0866965726017952, -0.0865204855799675, 0.11656132340431213, -0.011268123984336853, 0.09972050786018372, 0.031487222760915756, 0.11816952377557755, 0.06894948333501816, 0.09427377581596375, -0.22246424853801727, 1.497364393607806e-32, -0.10651688277721405, 0.03876069188117981, -0.017774907872080803, -0.06971374154090881, -0.09338823705911636, -0.03665252402424812, 0.0031594731844961643, 0.06627705693244934, 0.1038803905248642, -0.03201755881309509, -0.1164221465587616, 0.07164119929075241, -0.012330356985330582, 0.10872817784547806, 0.14152586460113525, -0.040441446006298065, -0.025404203683137894, 0.09334290027618408, 0.055661413818597794, 0.05044585093855858, 0.11273783445358276, -0.061344556510448456, 0.06353075802326202, -0.13245604932308197, -0.13924719393253326, 0.010104385204613209, -0.05057917535305023, 0.043664585798978806, -0.18699957430362701, 0.008867086842656136, -0.17017269134521484, 0.013467146083712578, 0.027924567461013794, -0.03138883784413338, 0.027141492813825607, -0.1469186693429947, 0.07138071209192276, -0.08699700981378555, 0.03639459237456322, -0.023830967023968697, -0.037238869816064835, 0.05995708331465721, 0.0007163069094531238, 0.06786692142486572, 0.047129690647125244, 0.060533374547958374, 0.004170015919953585, 0.09676875174045563, 0.001504965708591044, 0.07159390300512314, -0.02636544406414032, -0.07838579267263412, -0.025719279423356056, -0.0838257372379303, -0.1105431616306305, 0.11093371361494064, 0.009724016301333904, -0.08717584609985352, 0.03031650371849537, -0.06257309764623642, -0.08989133685827255, -0.013007999397814274, -0.047120895236730576, -0.137636199593544, -0.006954634562134743, -0.03766002506017685, 0.20187026262283325, 0.03754897788167, 0.07430244237184525, 0.008558964356780052, -0.010152037255465984, 0.006802125368267298, -0.09075993299484253, -0.15453703701496124, 0.09483779966831207, -0.1287173330783844, 0.18791869282722473, -0.0614478699862957, -0.05703799054026604, -0.13402538001537323, -0.10458384454250336, 0.2389218658208847, -0.06513157486915588, -0.1969986855983734, 0.12483588606119156, 0.03148065134882927, 0.08664967864751816, -0.09024044871330261, -0.16156570613384247, -0.07853024452924728, -0.11103460192680359, 0.0830627977848053, -0.009455778636038303, 0.012951478362083435, 0.039511822164058685, -1.4619191247002863e-32, -0.026802336797118187, 0.012241863645613194, 0.09134640544652939, 0.07968500256538391, 0.015911458060145378, -0.026582583785057068, -0.07313549518585205, -0.07291184365749359, 0.0331139899790287, -0.16749876737594604, -0.05371188744902611, -0.11977368593215942, 0.1367260217666626, -0.09796901047229767, -0.007488239090889692, 0.07894490659236908, -0.12534821033477783, -0.02357240580022335, -0.07932063192129135, 0.1216876283288002, -0.08246274292469025, 0.09358375519514084, -0.019472571089863777, -0.018879542127251625, -0.2017654925584793, -0.024180080741643906, -0.1087149977684021, 0.004051044583320618, 0.08211295306682587, -0.06314825266599655, -0.04819808527827263, 0.09327545762062073, -0.20080608129501343, -0.004177536815404892, 0.11520293354988098, -0.09161444753408432, -0.07944897562265396, -0.05361363664269447, 0.031065678223967552, 0.15419384837150574, 0.10457130521535873, 0.12003929167985916, -0.0696810781955719, 0.006630463991314173, -0.005531125236302614, 0.04097733646631241, 0.08179771900177002, 0.008343636989593506, 0.04784530773758888, 0.05271512269973755, 0.011736269108951092, 0.04812105745077133, -0.1194322407245636, 0.09941983222961426, -0.10252479463815689, 0.10687260329723358, -0.05625950172543526, -0.05431882292032242, 0.07271267473697662, 0.02199091576039791, -0.07354665547609329, -0.03662893548607826, 0.1503252238035202, 0.06783716380596161, 0.05253756418824196, 0.055555686354637146, 0.08340013772249222, 0.08490592986345291, -0.02015378512442112, 0.11044450849294662, -0.11577801406383514, -0.09707652032375336, 0.1369987428188324, -0.06024009361863136, -0.07722475379705429, 0.002685870975255966, -0.04148222878575325, -0.05100828781723976, -0.0546547994017601, 0.09612149745225906, -0.0010939332423731685, 0.03883390873670578, -0.0059056696482002735, 0.02824016474187374, -0.10745420306921005, 0.029370976611971855, 0.19013768434524536, 0.08597873151302338, 0.09025643020868301, -0.12380640208721161, 0.018253985792398453, 0.1371634304523468, 0.0636049211025238, 0.09817082434892654, 0.0825556144118309, -1.004385765668303e-07, -0.09360937029123306, 0.055752258747816086, 0.05687161535024643, -0.021059969440102577, -0.0048279184848070145, -0.03414186090230942, -0.0799756646156311, 0.1433398574590683, -0.025276735424995422, 0.054360222071409225, 0.019873883575201035, 0.04154113680124283, -0.09285062551498413, 0.03062332049012184, -0.008071644231677055, 0.016475234180688858, 0.06524144858121872, 0.14012980461120605, -0.040130384266376495, 0.024010885506868362, 0.004749759566038847, -0.13804638385772705, -0.07302756607532501, -0.07113087922334671, 0.004746842198073864, -0.15124745666980743, -0.027352625504136086, -0.10077956318855286, 0.043689653277397156, 0.14182816445827484, -0.04678942263126373, -0.057717375457286835, -0.0015265349065884948, 0.048528458923101425, 0.14217911660671234, 0.07701541483402252, 0.05394912511110306, -0.06856155395507812, -0.0009972217958420515, 0.026495305821299553, -0.013497639447450638, 0.10948845744132996, -0.0817297101020813, -0.0642291009426117, -0.03709961101412773, -0.02558121830224991, 0.09147216379642487, -0.06491255015134811, 0.026740387082099915, 0.12727606296539307, 0.1414431482553482, -0.09442138671875, -0.07330477237701416, 0.007160714827477932, 0.1367093324661255, 0.10600654780864716, -0.06406459212303162, -0.049733635038137436, 0.09723090380430222, 0.014902881346642971, -0.07933797687292099, 0.0790153369307518, 0.03785919025540352, 0.024366028606891632], metadata={'source': 'AAAMLP-569to.pdf', 'page': 157}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 158             )         elif isinstance(n_features, float):             self.selection = SelectPercentile(                 valid_scoring[scoring],                 percentile=int(n_features * 100)             )         else:             raise Exception(\"Invalid type of feature\")          # same fit function     def fit(self, X, y):         return self.selection.fit(X, y)          # same transform function     def transform(self, X):         return self.selection.transform(X)          # same fit_transform function     def fit_transform(self, X, y):         return self.selection.fit_transform(X, y) ═════════════════════════════════════════════════════════════════════════  Using this class is pretty simple.  ═════════════════════════════════════════════════════════════════════════ ufs = UnivariateFeatureSelction(     n_features=0.1,      problem_type=\"regression\",      scoring=\"f_regression\" ) ufs.fit(X, y) X_transformed = ufs.transform(X) ═════════════════════════════════════════════════════════════════════════  That should take care of most of your univariate feature selection needs. Please note that it’s usually better to create less and important features than to create hundreds of features in the first place. Univariate feature selection may not always perform well. Most of the time, people prefer doing feature selection using a machine learning model. Let’s see how that is done.  The simplest form of feature selection that uses a model for selection is known as greedy feature selection. In greedy feature selection, the first step is to choose a model. The second step is to select a loss/scoring function. And the third and final step is to iteratively evaluate each feature and add it to the list of “good” features if'),\n",
       " VectorParams(vector=[-0.1378939151763916, -0.11353589594364166, 0.03116408921778202, -0.028357209637761116, 0.19717369973659515, -0.09114690124988556, -0.009394020773470402, 0.09577438980340958, -0.08686625957489014, 0.1006830483675003, -0.03761044889688492, -0.06466346979141235, -0.06132916361093521, 0.015448912978172302, 0.055721186101436615, 0.12266343086957932, 0.08029644936323166, 0.01963196136057377, -0.07799861580133438, 0.041423141956329346, 0.1505143791437149, 0.015850730240345, -0.03551959991455078, 0.12609712779521942, -0.07531263679265976, -0.17834341526031494, 0.04236435890197754, 0.05626349896192551, -0.08499573171138763, 0.0003037770511582494, -0.06050753593444824, -0.04091868922114372, 0.15205490589141846, -0.04550676420331001, -0.10216890275478363, -0.001416439888998866, -0.07765725255012512, -0.04102268069982529, -0.15896938741207123, -0.009554068557918072, -0.039869505912065506, -0.022326476871967316, -0.012173613533377647, 0.04323001578450203, 0.10318613052368164, 0.11769524961709976, -0.0681476965546608, -0.04022059589624405, 0.11044178158044815, -0.004671253729611635, 0.10844447463750839, 0.11573594063520432, -0.12309586256742477, 0.044050734490156174, -0.06970498710870743, -0.04634486511349678, -0.039990413933992386, -0.10367760062217712, 0.10132458060979843, -0.10381817817687988, -0.018249154090881348, -0.04185838997364044, -0.021498462185263634, -0.02372349426150322, 0.046988390386104584, -0.0928029790520668, -0.029924726113677025, -0.024357927963137627, -0.02851012349128723, 0.14904367923736572, 0.009317188523709774, -0.01792673021554947, 0.019085850566625595, 0.008490152657032013, 0.08421869575977325, 0.05629240348935127, 0.1975529044866562, -0.06965864449739456, -0.05816926062107086, 0.09955274313688278, -0.05689608305692673, 0.1258435994386673, 0.03178056702017784, -0.09265551716089249, 0.07691213488578796, -0.2084970325231552, 0.10443378239870071, -0.08940400183200836, 0.13311129808425903, 0.04755300283432007, 0.14459924399852753, -0.012704703956842422, 0.0032653147354722023, -0.11676625907421112, -0.02331327274441719, 0.03296281024813652, 0.057155951857566833, -0.022287774831056595, 0.006318687926977873, 0.06108880043029785, -0.0463230274617672, 0.07774452120065689, 0.0926707312464714, -0.09324807673692703, 0.18685176968574524, -0.06185218691825867, -0.01928260177373886, 0.023785512894392014, 0.1018294095993042, -0.04694104194641113, -0.005435009486973286, -0.08580576628446579, -0.11708725243806839, 0.004425480030477047, 0.11245158314704895, 0.1554393321275711, 0.008829297497868538, 0.10272566974163055, -0.05443224683403969, 0.15221554040908813, -0.05979212746024132, 0.04017706587910652, 0.05460471659898758, 0.1512453258037567, 0.0933738499879837, -0.02188938669860363, -0.14601342380046844, 1.1290002431694043e-32, -0.1410045176744461, 0.004235370550304651, -0.013916557654738426, -0.2488497942686081, -0.08763319253921509, -0.13718560338020325, 0.10521449893712997, 0.018143968656659126, -0.005104852374643087, 0.05586310103535652, -0.20383629202842712, 0.06251248717308044, 0.0297276321798563, 0.08394764363765717, 0.1386793851852417, -0.04267570376396179, -0.017633672803640366, -0.06730689108371735, 0.015045704320073128, 0.04338475316762924, 0.15445473790168762, -0.08230043947696686, 0.09655002504587173, -0.14155295491218567, -0.06179623305797577, -0.07811962068080902, -0.057884424924850464, -0.008996434509754181, -0.1519675999879837, 0.03546891361474991, -0.10265423357486725, 0.026431946083903313, 0.0028990572318434715, -0.010467618703842163, -0.0027985144406557083, -0.06643684953451157, 0.021716998890042305, 0.041015636175870895, 0.04495687782764435, 0.03486798703670502, -0.050036150962114334, -0.011407854966819286, 0.06477728486061096, -0.030536338686943054, -0.07446064800024033, -0.02496821992099285, 0.021626533940434456, 0.121820829808712, -0.018992610275745392, 0.14469626545906067, 0.04590177163481712, -0.21553687751293182, -0.052351295948028564, 0.06772604584693909, -0.13348925113677979, 0.06491799652576447, 0.011665941216051579, -0.06722623109817505, 0.04633476212620735, 0.04654216766357422, 0.006424720399081707, -0.14222875237464905, 0.01298862136900425, -0.029414890334010124, -0.061364173889160156, -0.0731632336974144, 0.18943774700164795, -0.030636895447969437, -0.029228126630187035, -0.0329449325799942, -0.1394830346107483, 0.010129057802259922, -0.03529975935816765, -0.13608433306217194, 0.05350494384765625, -0.024829544126987457, 0.24408070743083954, 0.01055277418345213, -0.02643912471830845, -0.05454880744218826, -0.09735967963933945, 0.17238789796829224, 0.018520986661314964, -0.23260171711444855, 0.0861634761095047, 0.022337889298796654, 0.046395443379879, -0.10972410440444946, -0.2141905575990677, -0.12449227273464203, -0.1917332410812378, 0.03425873816013336, 0.0022112529259175062, -0.0047102440148591995, -0.07806771248579025, -1.1214859690001698e-32, 0.08222708106040955, -0.0724482536315918, 0.13324575126171112, 0.044516127556562424, 0.0442725270986557, 0.01927994005382061, -0.01673724874854088, -0.018992172554135323, -0.17420579493045807, -0.2076134830713272, -0.05688582733273506, -0.05463676527142525, 0.20271657407283783, 0.11343956738710403, 0.03020133450627327, 0.08868350833654404, -0.14269421994686127, 0.11417080461978912, -0.04147526994347572, 0.06126311793923378, -0.04381619393825531, 0.15203352272510529, -0.0857565775513649, -0.09516782313585281, -0.12116771936416626, -0.02359335497021675, -0.02685987576842308, 0.14120778441429138, 0.10032565146684647, -0.07825980335474014, -0.14229150116443634, 0.13865669071674347, -0.18387986719608307, 0.030801665037870407, 0.03141681104898453, 0.09795993566513062, -0.02955603040754795, -0.055468618869781494, -0.060926154255867004, 0.20986805856227875, 0.08099441230297089, 0.17198342084884644, -0.17625056207180023, 0.016334716230630875, -0.03206402063369751, -0.01711546629667282, -0.012269390746951103, 0.01313833799213171, 0.0850435197353363, -0.024911902844905853, 0.0510793961584568, -0.024333670735359192, 0.012907678261399269, 0.16434431076049805, -0.16117976605892181, 0.07868138700723648, -0.05009602755308151, -0.04762483760714531, -0.06737659871578217, -0.01235414668917656, -0.03320079296827316, 0.024278827011585236, 0.03361352160573006, 0.026950430124998093, 0.12479721754789352, -0.011102693155407906, 0.07630797475576401, 0.057634372264146805, -0.06565756350755692, -0.002151693683117628, -0.1047031581401825, -0.019105106592178345, 0.020075930282473564, -0.07428605109453201, -0.05005438253283501, 0.07676670700311661, -0.02544824592769146, -0.001044805278070271, -0.02749761939048767, 0.058757949620485306, -0.040494516491889954, -0.0003252408350817859, -0.009501973167061806, 0.15298126637935638, -0.039737749844789505, 0.11880119889974594, 0.14862702786922455, 0.1321529597043991, 0.04192176088690758, -0.0797715112566948, -0.01415987964719534, 0.06029461696743965, 0.1191776841878891, 0.17551429569721222, 0.018235674127936363, -9.956727353710448e-08, -0.041614875197410583, 0.05439797788858414, 0.03089718520641327, 0.046435967087745667, 0.07854383438825607, 0.04563514515757561, -0.024962566792964935, 0.034290410578250885, -0.15351982414722443, -0.02390620857477188, 0.07138659805059433, 0.09410672634840012, -0.09482117742300034, 0.04956505447626114, -0.0793553963303566, 0.08338326960802078, 0.01351209171116352, 0.14008831977844238, -0.036247484385967255, -0.013732733204960823, 0.03152995929121971, -0.11094126850366592, 0.036316096782684326, -0.0750146359205246, 0.03603449463844299, -0.09112811833620071, -0.0629325732588768, 0.0465531088411808, -0.042695462703704834, 0.06235808506608009, -0.0395754836499691, -0.11809276044368744, -0.01812840811908245, 0.011643113568425179, 0.17946010828018188, 0.09918728470802307, -0.04805365949869156, -0.12063643336296082, -0.11143781244754791, 0.18527302145957947, -0.05040469020605087, 0.03920485079288483, -0.08487311750650406, -0.07471530884504318, 0.05453431233763695, 0.027536187320947647, 0.12652869522571564, -0.037879668176174164, 0.00041104035335592926, 0.027710529044270515, 0.07478006929159164, -0.08448264002799988, -0.10238328576087952, -0.06020737811923027, 0.1469877064228058, -0.010196587070822716, -0.09111826866865158, -0.011259973980486393, 0.013885537162423134, 0.08420515805482864, -0.07786442339420319, -0.06586534529924393, 0.05891871824860573, 0.06513191014528275], metadata={'source': 'AAAMLP-569to.pdf', 'page': 158}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 159 it improves loss/score. It can’t get simpler than this. But you must keep in mind that this is known as greedy feature selection for a reason. This feature selection process will fit a given model each time it evaluates a feature. The computational cost associated with this kind of method is very high. It will also take a lot of time for this kind of feature selection to finish. And if you do not use this feature selection properly, then you might even end up overfitting the model.   Let’s see how it works by looking at how its implemented.  ═════════════════════════════════════════════════════════════════════════ # greedy.py import pandas as pd  from sklearn import linear_model from sklearn import metrics from sklearn.datasets import make_classification   class GreedyFeatureSelection:         \"\"\"     A simple and custom class for greedy feature selection.     You will need to modify it quite a bit to make it suitable     for your dataset.     \"\"\"     def evaluate_score(self, X, y):         \"\"\"         This function evaluates model on data and returns         Area Under ROC Curve (AUC)         NOTE: We fit the data and calculate AUC on same data.         WE ARE OVERFITTING HERE.          But this is also a way to achieve greedy selection.         k-fold will take k times longer.          If you want to implement it in really correct way,         calculate OOF AUC and return mean AUC over k folds.         This requires only a few lines of change and has been          shown a few times in this book.          :param X: training data         :param y: targets         :return: overfitted area under the roc curve         \"\"\"         # fit the logistic regression model,         # and calculate AUC on same data         # again: BEWARE         # you can choose any model that suits your data'),\n",
       " VectorParams(vector=[-0.006062460597604513, -0.04571779444813728, 0.024279985576868057, 0.016095751896500587, 0.2213810682296753, -0.06336481869220734, 0.022962365299463272, 0.08761502057313919, -0.24126598238945007, 0.01490503828972578, -0.042335137724876404, -0.03710678964853287, 0.05473462864756584, 0.021480552852153778, 0.025307968258857727, 0.1445428729057312, -0.03369665518403053, -0.036779653280973434, -0.015761110931634903, -0.0270218662917614, 0.015551050193607807, 0.1053890809416771, -0.04940105602145195, 0.1555008590221405, -0.01019983272999525, -0.09008137136697769, 0.10671883076429367, 0.10607979446649551, -0.11945715546607971, -0.06865542382001877, -0.13952495157718658, -0.06253314018249512, 0.15686354041099548, -0.0008564731106162071, -0.12111690640449524, -0.050613123923540115, -0.15776628255844116, -0.12356982380151749, -0.07075662910938263, -0.0812087282538414, 0.019957462325692177, -0.03029601275920868, -0.014905436895787716, -0.03243404999375343, 0.10029454529285431, 0.1488373726606369, -0.11848195642232895, -0.024385277181863785, 0.12820298969745636, 0.012096761725842953, -0.03423056751489639, 0.06680136173963547, -0.11605092138051987, 0.03015662357211113, -0.07158459722995758, -0.062011316418647766, 0.05556437000632286, -0.22037869691848755, 0.09505081176757812, -0.23902612924575806, 0.06473299115896225, -0.07490807771682739, 0.007417959626764059, -0.05551903322339058, 0.091132752597332, -0.19385145604610443, -0.1045965775847435, 0.11711841821670532, -0.006080603692680597, 0.20119722187519073, 0.02320062555372715, 0.07798386365175247, 0.020760685205459595, 0.06422661244869232, 0.09690555185079575, 0.11416374146938324, 0.17153674364089966, -0.08374277502298355, -0.07140672951936722, 0.09803526103496552, -0.19998076558113098, -0.01380126178264618, 0.0555037222802639, -0.03369507938623428, 0.11109689623117447, -0.25411278009414673, 0.11569039523601532, -0.013592418283224106, 0.16255395114421844, -0.017822466790676117, 0.06422156095504761, 0.031562987715005875, 0.08250432461500168, -0.05763870105147362, 0.06008850783109665, 0.059825412929058075, 0.037774037569761276, -0.12382558733224869, -0.07614041119813919, 0.07763113081455231, -0.02871393784880638, 0.04864964634180069, 0.0746108815073967, -0.12964297831058502, 0.13431993126869202, -0.029806872829794884, 0.09608098119497299, 0.05503825843334198, 0.10977652668952942, -0.17678339779376984, 0.01242076326161623, -0.12657997012138367, -0.010455620475113392, 0.09146741032600403, 0.10411354154348373, 0.13479644060134888, 0.016098545864224434, 0.1635090708732605, -0.04159921407699585, 0.12513594329357147, -0.041427720338106155, 0.05164654925465584, 0.14005911350250244, 0.1069156602025032, 0.009851756505668163, -0.10699573159217834, -0.1285121887922287, 1.7432842770187582e-32, -0.13966234028339386, -0.08753693103790283, -0.06955605000257492, -0.13402602076530457, -0.03882842883467674, -0.031012333929538727, 0.08276864886283875, -0.004066916182637215, -0.05863906443119049, 0.09188075363636017, -0.2004850208759308, 0.04969887435436249, 0.004286841489374638, 0.1643071174621582, 0.11274799704551697, -0.10483270138502121, -0.03133915364742279, -0.04784465581178665, -0.04677845165133476, 0.10739872604608536, 0.17390404641628265, -0.10626816749572754, -0.0076142954640090466, -0.16709353029727936, -0.0761406421661377, 0.006341864820569754, -0.05578060448169708, 0.0013085304526612163, -0.19855964183807373, -0.012063922360539436, -0.17134907841682434, 0.12613339722156525, -0.06617050617933273, -0.03974561765789986, 0.03692517429590225, -0.06495478749275208, 0.06448356807231903, 0.010207418352365494, 0.06747706234455109, -0.01587430015206337, 0.010084220208227634, -0.00593342911452055, -0.003876719158142805, -0.0003576999297365546, -0.04970354959368706, -0.03789236769080162, -0.12595410645008087, 0.13756296038627625, 0.0032537481747567654, 0.11366371065378189, -0.0073106782510876656, -0.24592459201812744, -0.08325717598199844, 0.04170440509915352, -0.24893148243427277, 0.007852165959775448, 0.026245757937431335, 0.07963274419307709, 0.05325285717844963, 0.012229472398757935, 0.07942415028810501, -0.11473295837640762, -0.0596778467297554, -0.09263647347688675, -0.0753554031252861, 0.04463038593530655, 0.15766994655132294, 0.04389771819114685, 0.06804877519607544, 0.001630529877729714, -0.09163415431976318, 0.006974057760089636, -0.005395568907260895, -0.15405718982219696, 0.04680180549621582, -0.11770043522119522, 0.1713285893201828, -0.07569290697574615, -0.015538429841399193, -0.012220983393490314, -0.08679036051034927, 0.20971335470676422, -0.15044064819812775, -0.2584325075149536, 0.09772547334432602, 0.0053085749968886375, 0.06077395752072334, -0.10561975091695786, -0.25157544016838074, -0.055695027112960815, -0.1904648393392563, 0.11384937912225723, 0.07989390194416046, 0.036188170313835144, -0.03343458101153374, -1.8690518869811732e-32, 0.048144545406103134, -0.0051765344105660915, 0.23559536039829254, 0.04175363853573799, 0.09431498497724533, -0.016932807862758636, -0.054296594113111496, -0.10137633234262466, -0.04179402440786362, -0.1967131644487381, -0.0003691517631523311, -0.10344181209802628, 0.20710241794586182, 0.015409478917717934, 0.07149063050746918, 0.10118327289819717, -0.19124223291873932, 0.009749339893460274, -0.04450404271483421, 0.036617398262023926, -0.06242367997765541, 0.13556373119354248, -0.04882679879665375, 0.02571389451622963, -0.21902379393577576, 0.01241280697286129, 0.03583017364144325, 0.013423219323158264, 0.02728336863219738, -0.12382716685533524, -0.10663329064846039, 0.10602419078350067, -0.19354628026485443, 0.09472863376140594, 0.062483787536621094, -0.005316145718097687, -0.007143685594201088, -0.1620774269104004, -0.1075521782040596, 0.2500433921813965, 0.17008136212825775, 0.11688649654388428, -0.16494016349315643, 0.025167113170027733, -0.004406167194247246, 0.07864993065595627, 0.10605821758508682, 0.0329749658703804, -0.023124702274799347, -0.03864249959588051, 0.005565452855080366, -0.08125489205121994, -0.12387031316757202, 0.10237662494182587, -0.17555545270442963, 0.046034302562475204, -0.10172861069440842, -0.02764195017516613, 0.015881866216659546, -0.0009477692656219006, -0.08059097826480865, 0.06387865543365479, 0.017215458676218987, 0.0632319301366806, 0.08136225491762161, 0.03095780313014984, 0.0007872055866755545, 0.09737613052129745, -0.018519433215260506, 0.07955325394868851, -0.12671667337417603, 0.08823133260011673, 0.051177676767110825, -0.07175266742706299, -0.03273139148950577, 0.06104579567909241, -0.07512855529785156, -0.046608392149209976, -0.021372394636273384, -0.020308461040258408, -0.11415262520313263, 0.04509284719824791, 0.037859443575143814, 0.11817318946123123, -0.08998230844736099, 0.09541646391153336, 0.14143869280815125, 0.07056137919425964, 0.07946927845478058, -0.12569555640220642, -0.03428465500473976, 0.054448746144771576, 0.1747622787952423, 0.13026955723762512, -0.0629676803946495, -1.0202757039223798e-07, -0.087189219892025, 0.01038360595703125, -0.03145068511366844, 0.08793368935585022, -0.008034066297113895, 0.09944900870323181, -0.10383084416389465, 0.0670333281159401, -0.14153781533241272, -0.03385423496365547, 0.047850534319877625, 0.04279842600226402, -0.14022314548492432, 0.01924346759915352, -0.0612785629928112, 0.045581214129924774, 0.0433528907597065, 0.20313017070293427, -0.003706202609464526, -0.05771562457084656, 0.05961865931749344, -0.10318594425916672, 0.10186047852039337, -0.039760783314704895, -0.08424144983291626, -0.06067084148526192, -0.004247329663485289, 0.00241532432846725, 0.013409605249762535, 0.05576423555612564, -0.00908213946968317, -0.16099539399147034, 0.05563991516828537, -0.028383610770106316, 0.20363599061965942, 0.1205994263291359, 0.027236653491854668, -0.09456755965948105, -0.09164296090602875, 0.11735077947378159, -0.07647250592708588, 0.1538136601448059, -0.11519843339920044, -0.07323110103607178, -0.016320182010531425, -0.021427232772111893, 0.07457836717367172, -0.10215208679437637, 0.11350561678409576, -0.0015376267256215215, 0.025671519339084625, -0.1042843610048294, -0.07727577537298203, -0.047714583575725555, 0.11537307500839233, -0.028640998527407646, -0.07937648147344589, -0.015403291210532188, -0.006310976110398769, -0.005417014937847853, -0.019004439935088158, -0.03545365482568741, 0.02894805185496807, 0.030480481684207916], metadata={'source': 'AAAMLP-569to.pdf', 'page': 159}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 160         model = linear_model.LogisticRegression()         model.fit(X, y)         predictions = model.predict_proba(X)[:, 1]         auc = metrics.roc_auc_score(y, predictions)         return auc          def _feature_selection(self, X, y):         \"\"\"         This function does the actual greedy selection         :param X: data, numpy array         :param y: targets, numpy array         :return: (best scores, best features)         \"\"\"         # initialize good features list          # and best scores to keep track of both         good_features = []         best_scores = []                  # calculate the number of features         num_features = X.shape[1]                  # infinite loop         while True:             # initialize best feature and score of this loop             this_feature = None             best_score = 0              # loop over all features             for feature in range(num_features):                 # if feature is already in good features,                 # skip this for loop                 if feature in good_features:                     continue                 # selected features are all good features till now                 # and current feature                 selected_features = good_features + [feature]                 # remove all other features from data                 xtrain = X[:, selected_features]                 # calculate the score, in our case, AUC                 score = self.evaluate_score(xtrain, y)                 # if score is greater than the best score                 # of this loop, change best score and best feature                 if score > best_score:                     this_feature = feature                     best_score = score              # if we have selected a feature, add it'),\n",
       " VectorParams(vector=[-0.09173188358545303, -0.013547968119382858, 0.046729981899261475, 0.03022574819624424, 0.129311203956604, -0.11494670063257217, -0.027944078668951988, 0.0713101252913475, -0.0450696237385273, 0.018708540126681328, -0.07772262394428253, 0.08484205603599548, 0.0733504444360733, -0.003294550348073244, 0.048725325614213943, 0.11295102536678314, -0.02141830325126648, 0.019941436126828194, -0.03613055869936943, -0.07491397857666016, 0.06576905399560928, 0.07545964419841766, -0.09510669857263565, 0.1170557513833046, -0.02984710969030857, -0.07705643773078918, -0.020244114100933075, 0.08540187776088715, -0.04400885850191116, -0.0686974823474884, -0.04498070478439331, 0.03339781612157822, 0.10391455888748169, 0.0317033976316452, -0.16665340960025787, 0.031662020832300186, -0.047959182411432266, -0.12080059945583344, -0.10285919159650803, -0.008638559840619564, -0.010259614326059818, 0.01592763513326645, -0.017466951161623, -0.0638965517282486, 0.11672688275575638, 0.1267792135477066, -0.13177114725112915, -0.060360077768564224, -0.08975180983543396, -0.028806068003177643, -0.0680929496884346, 0.10876351594924927, -0.17089876532554626, 0.14653654396533966, 0.05091768875718117, -0.08217575401067734, 0.10085104405879974, -0.042714525014162064, -0.001986999996006489, -0.06821507215499878, 0.08871052414178848, -0.08220086246728897, -0.03747763857245445, -0.008169167675077915, 0.05065423995256424, -0.1445172131061554, 0.021650617942214012, -0.02960723452270031, 0.04047802463173866, 0.08116430044174194, -0.004476407077163458, 0.03696714714169502, -0.08903815597295761, -0.007859866134822369, 0.09571397304534912, 0.07117801159620285, 0.19905872642993927, -0.003321269527077675, -0.04297706484794617, 0.08987689018249512, -0.12507180869579315, 0.06336088478565216, 0.04006395861506462, -0.006012325640767813, 0.07163432240486145, -0.1855698674917221, 0.0454738475382328, -0.005703392438590527, 0.1014086902141571, 0.06534144282341003, 0.0028899337630718946, -0.01882997341454029, -0.05310676991939545, -0.01247433852404356, 8.449066081084311e-05, 0.059817664325237274, 0.04597558081150055, -0.12732824683189392, -0.0835498571395874, 0.06823153048753738, -0.07460712641477585, 0.016217857599258423, 0.06538297235965729, -0.160553440451622, 0.1557946652173996, -0.023037681356072426, 0.026199059560894966, -0.037725094705820084, 0.09759590029716492, -0.2009490728378296, -0.04255957156419754, -0.05873917043209076, -0.0626436248421669, 0.03961269557476044, 0.029422685503959656, 0.03757399693131447, 0.06335123628377914, 0.09840350598096848, -3.374461812200025e-05, 0.10579241067171097, 0.03838371858000755, -0.008210007101297379, 0.035706277936697006, 0.058001626282930374, 0.07022374868392944, 0.004555414896458387, -0.09791193157434464, 9.912499376682946e-33, -0.06404200196266174, -0.06759557873010635, -0.016375362873077393, -0.20599454641342163, 0.06669735163450241, -0.08164289593696594, 0.045350331813097, 0.060604169964790344, 0.022182781249284744, 0.01850844919681549, -0.161491259932518, 0.043353378772735596, 0.038543082773685455, 0.07732085883617401, 0.18038149178028107, -0.09206194430589676, -0.0694623589515686, -0.009317961521446705, -0.016447458416223526, 0.01708417944610119, 0.1760856658220291, -0.034827399998903275, 0.06255722790956497, -0.13974477350711823, -0.02458697184920311, 0.02339235693216324, -0.0576590895652771, -0.06610234826803207, -0.24395957589149475, -0.020794343203306198, -0.13722258806228638, 0.048382457345724106, -0.06859900802373886, 0.046052057296037674, 0.027114979922771454, -0.12950828671455383, 0.05916093662381172, -0.08131790161132812, 0.005796861369162798, 0.0025355988182127476, 0.003003713209182024, -0.008265926502645016, -0.05211998149752617, 0.04875733703374863, -0.020306894555687904, -0.03000877983868122, -0.08630198985338211, 0.005251821596175432, 0.006148058921098709, 0.11561319977045059, -0.03246140107512474, -0.07682551443576813, 0.010343186557292938, -0.0741509348154068, -0.1746656596660614, 0.04801173135638237, 0.08246243000030518, 0.025639183819293976, -0.0022959013003855944, 0.06526859849691391, 0.01931086555123329, -0.036617737263441086, -0.028514264151453972, -0.04856469854712486, -0.07005336880683899, -0.01424071192741394, 0.15822356939315796, -0.0048062438145279884, 0.09422516822814941, -0.021437587216496468, -0.0679362416267395, 0.04786490276455879, 0.010082720778882504, -0.14829149842262268, 0.05870118737220764, -0.08407456427812576, 0.13410331308841705, -0.12894843518733978, 0.029284492135047913, -0.07105227559804916, -0.03955809399485588, 0.11715561896562576, -0.05197761952877045, -0.2189907431602478, 0.07716266065835953, -0.006194718647748232, 0.05164802446961403, -0.12302971631288528, -0.11489754170179367, -0.13341014087200165, -0.16609153151512146, 0.04747891053557396, -0.032770317047834396, 0.03656833618879318, 0.035101186484098434, -1.2148833298084192e-32, 0.019061829894781113, -0.06842277199029922, 0.07385557889938354, 0.07487495988607407, 0.021949822083115578, -0.045601725578308105, -0.08731053024530411, -0.08701271563768387, -0.05520152300596237, -0.1794784665107727, -0.025363238528370857, -0.004947968292981386, 0.09532549232244492, 0.07206505537033081, -0.00030504463938996196, 0.11132580786943436, -0.18012310564517975, -0.11328764259815216, -0.029955336824059486, 0.07766491919755936, 0.020181898027658463, 0.21962770819664001, -0.06794833391904831, 0.01266000047326088, -0.1049167811870575, -0.09606216847896576, -0.022432681173086166, 0.06918221712112427, 0.14402657747268677, -0.10240228474140167, 0.004578749183565378, 0.039919521659612656, -0.08472050726413727, 0.0047008744440972805, 0.030193287879228592, 0.009187574498355389, -0.040373362600803375, -0.17261818051338196, -0.0002735764137469232, 0.2667487859725952, 0.18823276460170746, 0.09545041620731354, -0.043147459626197815, 0.05713861063122749, 0.037555646151304245, 0.02800641395151615, -0.0028433327097445726, 0.022859372198581696, -0.009437565691769123, -0.048962049186229706, 0.06648097932338715, -0.015067501924932003, -0.05823525786399841, 0.10626788437366486, -0.0701172724366188, 0.012584632262587547, -0.05967200919985771, -0.0030979211442172527, 0.07667570561170578, -0.02695384994149208, -0.03222541883587837, 0.02575581893324852, 0.009216858074069023, 0.041999701410532, 0.07597033679485321, 0.09880629926919937, -0.0474042110145092, 0.025791684165596962, 0.0021996935829520226, 0.04096847027540207, -0.13564810156822205, 0.023774083703756332, 0.0273396298289299, -0.08849956840276718, -0.08921882510185242, 0.09181883931159973, -0.13029460608959198, -0.050339192152023315, -0.08337736129760742, -0.06008236110210419, -0.11911977082490921, 0.02355894260108471, 0.005720827262848616, 0.1090349480509758, -0.019621018320322037, 0.026695651933550835, 0.13017813861370087, 0.08534557372331619, 0.0897272452712059, -0.16107042133808136, 0.00490149948745966, 0.10803119093179703, 0.06391491740942001, 0.14982256293296814, -0.02592870034277439, -1.0115110882225054e-07, -0.14971207082271576, -0.06172078102827072, -0.05333501100540161, 0.09385300427675247, 0.15433500707149506, -0.023644832894206047, 0.016039544716477394, 0.1272033452987671, -0.06980955600738525, -0.05457760766148567, 0.06569209694862366, 0.08390474319458008, -0.06561974436044693, 0.049168910831213, 0.0548858717083931, 0.10896603763103485, 0.02574182115495205, 0.08006337285041809, 0.008819900453090668, 0.04626091569662094, 0.056147292256355286, -0.11317872256040573, 0.009127060882747173, -0.032797809690237045, -0.05821071192622185, -0.06659115105867386, 0.07159370929002762, 0.036488525569438934, 0.03712479770183563, 0.007418085355311632, -0.010554537177085876, -0.0331459641456604, 0.056215137243270874, 0.0690649226307869, 0.15386511385440826, 0.1385163515806198, 0.0467241033911705, -0.03272365778684616, -0.11152255535125732, 0.10194297879934311, -0.06872158497571945, 0.05812785029411316, -0.048069000244140625, -0.07493877410888672, -0.03538605570793152, -0.003205538261681795, 0.02404157631099224, -0.04270867630839348, 0.0763867199420929, -0.057281240820884705, 0.029604284092783928, -0.09259159862995148, -0.11265023797750473, -0.08809543401002884, 0.07918457686901093, 0.03539346903562546, -0.042585473507642746, -0.04323415458202362, 0.03010542318224907, 0.014285554178059101, -0.04119156301021576, 0.006219894625246525, 0.13744431734085083, 0.06686940044164658], metadata={'source': 'AAAMLP-569to.pdf', 'page': 160}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 161             # to the good feature list and update best scores list             if this_feature != None:                 good_features.append(this_feature)                 best_scores.append(best_score)              # if we didnt improve during the previous round,             # exit the while loop             if len(best_scores) > 2:                 if best_scores[-1] < best_scores[-2]:                     break         # return best scores and good features         # why do we remove the last data point?         return best_scores[:-1], good_features[:-1]      def __call__(self, X, y):         \"\"\"         Call function will call the class on a set of arguments         \"\"\"         # select features, return scores and selected indices         scores, features = self._feature_selection(X, y)         # transform data with selected features         return X[:, features], scores  if __name__ == \"__main__\":     # generate binary classification data     X, y = make_classification(n_samples=1000, n_features=100)      # transform data by greedy feature selection     X_transformed, scores = GreedyFeatureSelection()(X, y) ═════════════════════════════════════════════════════════════════════════  The greedy feature selection implemented the way returns scores and a list of feature indices. Figure 2 shows how this score improves with the addition of a new feature in every iteration. We see that we are not able to improve our score after a certain point, and that’s where we stop.  Another greedy approach is known as recursive feature elimination (RFE). In the previous method, we started with one feature and kept adding new features, but in RFE, we start with all features and keep removing one feature in every iteration that provides the least value to a given model. But how to do we know which feature offers the least value? Well, if we use models like linear support vector machine (SVM) or logistic regression, we get a coefficient for each feature which decides the importance of the features. In case of any tree-based models, we get feature importance in place of coefficients. In each iteration, we can eliminate the least'),\n",
       " VectorParams(vector=[-0.0757264792919159, -0.03242103010416031, 0.08107366412878036, 0.03585439547896385, 0.1439921259880066, -0.11741502583026886, -0.06219683215022087, 0.026734182611107826, -0.10864986479282379, 0.07763583213090897, -0.0896301195025444, -0.02957378327846527, -0.04478687793016434, 0.05157315358519554, 0.01931687630712986, 0.09832478314638138, 0.0009352753404527903, -0.07352682948112488, -0.019452694803476334, -0.03305300697684288, -0.037561867386102676, 0.053601641207933426, 0.029291465878486633, 0.08362685143947601, 0.010356541723012924, -0.13704833388328552, 0.0491454117000103, 0.021988438442349434, -0.008711851201951504, -0.05752543732523918, 0.02376040443778038, -0.01202232763171196, 0.16592849791049957, -0.05473347753286362, -0.08450610935688019, -0.022563239559531212, -0.01741384156048298, -0.031618524342775345, -0.13819366693496704, 0.04287790134549141, -0.023257752880454063, -0.03690594062209129, -0.018477847799658775, -0.05500594899058342, 0.10010799020528793, 0.005696751642972231, -0.09936237335205078, -0.10006225109100342, 0.021229999139904976, -0.02847265638411045, 0.10171264410018921, 0.10592617094516754, -0.13478204607963562, 0.2477688491344452, 0.03175842761993408, -0.09083917737007141, 0.06416065245866776, -0.030981820076704025, 0.0074820686131715775, -0.06806430220603943, 0.038745902478694916, -0.03939509764313698, -0.08007514476776123, -0.11238741874694824, 0.07083281874656677, -0.037140339612960815, -0.08295756578445435, -0.020080069079995155, 0.09800991415977478, 0.235902339220047, -0.010400901548564434, -0.08016788214445114, 0.03782365471124649, 0.002206899458542466, 0.10066123306751251, 0.12610933184623718, 0.1295711249113083, -0.0007504237582907081, 0.07893537729978561, 0.11775227636098862, -0.12333259731531143, 0.06759830564260483, 0.06491051614284515, -0.10343509912490845, 0.08092447370290756, -0.14526696503162384, -0.0014135215897113085, -0.10337278991937637, 0.04396588355302811, 0.08800867199897766, 0.05854016914963722, -0.047103773802518845, 0.11136890947818756, -0.12891200184822083, -0.08940742164850235, 0.037613268941640854, 0.009269258007407188, -0.09310042858123779, -0.10187035799026489, 0.08012547343969345, -0.08058195561170578, 0.012367871589958668, 0.0686427503824234, -0.05476038157939911, 0.05353628844022751, -0.14401598274707794, -0.05104852840304375, 0.06327999383211136, 0.09597256034612656, -0.14266808331012726, -0.009257731959223747, -0.02933668904006481, -0.10794925689697266, 0.025563204661011696, 0.04339805245399475, 0.12071351706981659, 0.08205246180295944, 0.10574749857187271, 0.010642941109836102, 0.12149285525083542, -0.03186030685901642, -0.056053970009088516, -0.00751737505197525, 0.05472917854785919, 0.1731933206319809, 0.003386520314961672, -0.11392619460821152, 1.0368187108618898e-32, -0.09990367293357849, -0.007581354584544897, -0.06078217178583145, -0.17392008006572723, -0.032826174050569534, -0.076425701379776, -0.01719173975288868, 0.09519641846418381, 0.1253030151128769, 0.10584934055805206, -0.012264306657016277, 0.0722622275352478, 0.009181198664009571, 0.0785672664642334, 0.11780352890491486, -0.06519364565610886, -0.027898143976926804, 0.0057230922393500805, -0.04206448420882225, -0.03770958632230759, 0.08523963391780853, -0.03679648041725159, 0.002118209842592478, -0.16275466978549957, -0.02727816067636013, -0.056344009935855865, -0.07646343111991882, -0.04241223260760307, -0.26546064019203186, 0.02337794005870819, -0.08521465212106705, 0.10582466423511505, -0.1285579651594162, 0.08919883519411087, -0.03965989500284195, -0.07490227371454239, -0.08293414115905762, -0.07729640603065491, 0.10407137125730515, 0.06546074151992798, -0.026859693229198456, -0.015149116516113281, -0.0588209331035614, -0.006406725384294987, 0.10588458180427551, -0.00975024700164795, 0.03693080320954323, -0.10488348454236984, -0.13680078089237213, 0.18688026070594788, 0.01631413958966732, -0.07072483748197556, -0.005750718060880899, -0.009769541211426258, -0.12907353043556213, -0.02657310664653778, 0.02169625833630562, -0.05229372903704643, 0.04703246429562569, -0.05223251134157181, -0.007310305722057819, -0.05420190840959549, 0.04538574442267418, -0.10348745435476303, -0.026423081755638123, -0.05020248517394066, 0.12963910400867462, 0.04894672706723213, -0.04855111613869667, -0.019378753378987312, -0.009868215769529343, 0.0008217389695346355, -0.026432348415255547, -0.21287404000759125, 0.0404052659869194, -0.030049772933125496, 0.2701158821582794, -0.013671234250068665, 0.00986210722476244, -0.0697048157453537, -0.03560308367013931, 0.11395874619483948, 0.12592679262161255, -0.17222116887569427, 0.16553373634815216, 0.017082173377275467, -0.006679055746644735, -0.11892455816268921, -0.09424640238285065, -0.09355215728282928, -0.06264015287160873, 0.03978348523378372, -0.021332578733563423, 0.025081420317292213, -0.06373687833547592, -1.0345769696664748e-32, 0.026851007714867592, -0.09205947816371918, 0.040295712649822235, -0.07423843443393707, -0.06937893480062485, 0.014499385841190815, -0.04877931997179985, -0.05369381979107857, -0.11673044413328171, -0.16183319687843323, 0.07371566444635391, 0.005797011777758598, 0.12029627710580826, 0.012293010950088501, -0.07230403274297714, 0.07430566847324371, -0.1765275001525879, -0.06651085615158081, 0.07369650900363922, 0.07849015295505524, -0.025979578495025635, 0.10713260620832443, -0.03737230226397514, 0.05327781289815903, -0.15059562027454376, -0.0895819440484047, -0.07568284124135971, 0.035459067672491074, 0.12420796602964401, -0.07231553643941879, -0.09000494331121445, 0.08167850226163864, -0.007933957502245903, 0.04482361301779747, 0.009472215548157692, -0.04070576652884483, -0.01275601889938116, 0.07642611861228943, 0.006999029312282801, 0.3315637707710266, 0.1342780739068985, 0.03815199434757233, -0.12150261551141739, 0.10049088299274445, -0.03127352148294449, -0.046484217047691345, 0.044447969645261765, 0.14469029009342194, 0.12249929457902908, 0.010469379834830761, 0.10430677980184555, 0.02350376918911934, 0.016832303255796432, 0.10493005812168121, -0.09680768102407455, 0.12057171016931534, 0.11407241225242615, -0.011951899155974388, 0.06671514362096786, 0.08731598407030106, -0.06697209924459457, 0.12611505389213562, 0.10656481236219406, -0.006540648639202118, 0.0349792018532753, 0.01705218479037285, -0.029099304229021072, 0.2001936137676239, -0.0379018671810627, -0.061121754348278046, -0.08176904171705246, -0.009452692233026028, -0.013763384893536568, -0.1042998805642128, -0.09722240269184113, 0.049935489892959595, 0.07095060497522354, -0.008901900611817837, -0.024382099509239197, -0.005213152151554823, -0.14513123035430908, 0.07356449216604233, -0.00033735379111021757, 0.0796002522110939, -0.0057024830020964146, 0.0692702978849411, 0.04918752238154411, 0.008493895642459393, 0.012321105226874352, -0.052425235509872437, 0.032042134553194046, 0.1085643395781517, 0.1573401391506195, 0.07609423249959946, 0.04164125397801399, -9.896339747683669e-08, -0.01578146032989025, -0.05125803500413895, -0.03381350636482239, -0.035739168524742126, 0.14019127190113068, -0.029120828956365585, -0.03648010268807411, 0.17232704162597656, -0.13201375305652618, 0.026182889938354492, 0.076502725481987, 0.18183717131614685, -0.06425128877162933, 0.08047223836183548, 0.04344476759433746, 0.07660045474767685, 0.055810071527957916, 0.08421242237091064, -0.08705530315637589, -0.024592585861682892, 0.1297408789396286, -0.11268731206655502, 0.060004863888025284, -0.028163669630885124, 0.02102220617234707, -0.03216281905770302, 0.1517897993326187, 0.07536476105451584, 0.03532390296459198, 0.06694111227989197, -0.07574524730443954, 0.00864465907216072, -0.02000618726015091, -0.0016123639652505517, 0.2714024484157562, 0.1318468451499939, -0.010284548625349998, -0.10574296861886978, -0.19247592985630035, 0.04252386838197708, -0.09153252094984055, 0.02964218333363533, -0.10189149528741837, -0.02586914785206318, -0.10715217143297195, -0.02958696149289608, -0.03959977999329567, -0.0650639757514, 0.06435699760913849, 0.016959305852651596, 0.03310262784361839, -0.060356900095939636, -0.03725464642047882, -0.07890698313713074, 0.09750934690237045, 0.09485913813114166, 0.004865238908678293, -0.11787199974060059, -0.01136193610727787, 0.013511646538972855, 0.00897712167352438, -0.047436557710170746, 0.05782647430896759, -0.04258812591433525], metadata={'source': 'AAAMLP-569to.pdf', 'page': 161}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 162 important feature and keep eliminating it until we reach the number of features needed. So, yes, we have the ability to decide how many features we want to keep. \\n Figure 2: How AUC score varies in greedy feature selection with the addition of new features  When we are doing recursive feature elimination, in each iteration, we remove the feature which has the feature importance or the feature which has a coefficient close to 0. Please remember that when you use a model like logistic regression for binary classification, the coefficients for features are more positive if they are important for the positive class and more negative if they are important for the negative class. It’s very easy to modify our greedy feature selection class to create a new class for recursive feature elimination, but scikit-learn also provides RFE out of the box. A simple usage is shown in the following example.  ═════════════════════════════════════════════════════════════════════════ import pandas as pd  from sklearn.feature_selection import RFE from sklearn.linear_model import LinearRegression from sklearn.datasets import fetch_california_housing  # fetch a regression dataset data = fetch_california_housing() X = data[\"data\"] col_names = data[\"feature_names\"] y = data[\"target\"]'),\n",
       " VectorParams(vector=[-0.03357841074466705, 0.030559483915567398, 0.07769350707530975, 0.033582378178834915, 0.190127432346344, -0.028174830600619316, -0.007329167332500219, 0.058053769171237946, -0.09164610505104065, 0.01651466079056263, -0.11445514112710953, 0.010770409367978573, -0.14377573132514954, 0.09605477750301361, 0.05066831409931183, 0.07789022475481033, 0.021494196727871895, 0.02822975628077984, -0.08798904716968536, -0.07642877846956253, 0.06683233380317688, -0.005736870691180229, -0.05509394034743309, 0.05789034068584442, 0.026027698069810867, -0.06920937448740005, 0.06480395793914795, 0.09322091937065125, -0.05824332311749458, -0.010370003059506416, -0.05401144549250603, -0.04259340465068817, 0.06223138049244881, -0.09350109100341797, -0.1660069227218628, 0.011396976187825203, -0.0776725485920906, -0.09799972921609879, -0.08563856035470963, -0.11850541830062866, 0.016872767359018326, -0.024171680212020874, -0.056057143956422806, -0.03432777151465416, 0.09511350095272064, -0.0702497735619545, -0.027783604338765144, 0.03169342502951622, -0.035629987716674805, 0.02773982845246792, 0.008635058999061584, -0.03773075342178345, -0.05992769077420235, 0.11244546622037888, 0.08598184585571289, -0.08618680387735367, -0.001951306127011776, -0.051637399941682816, -0.024112574756145477, -0.12700706720352173, -0.0644582062959671, 0.0175041351467371, 0.06645576655864716, -0.033668357878923416, 0.052251823246479034, -0.03213021904230118, -0.009786282666027546, 0.014253824949264526, -0.07455023378133774, 0.07837319374084473, 0.010346516966819763, 0.013040220364928246, -0.004865458235144615, -0.006720003671944141, 0.04709990695118904, 0.024687817320227623, 0.09810758382081985, 0.1060476005077362, 0.01717611961066723, 0.14870324730873108, -0.08847372233867645, 0.13958311080932617, 0.08392692357301712, -0.016671685501933098, -0.012814807705581188, -0.05722932890057564, 0.04411584883928299, -0.03473109379410744, -0.030372820794582367, 0.008891553618013859, 0.03982161357998848, -0.06735310703516006, 0.0016279179835692048, -0.03489943593740463, -0.01096006017178297, 0.006618609186261892, 0.00991899985820055, -0.2141459584236145, -0.09093635529279709, 0.08261361718177795, -0.1213960275053978, -0.03359893709421158, 0.06518610566854477, -0.012306582182645798, 0.11431165784597397, -0.03436347097158432, 0.010528335347771645, 0.049231816083192825, 0.02023738995194435, -0.08257308602333069, 0.0020461331587284803, -0.01914602518081665, -0.005832672119140625, 0.06140026077628136, 0.025257745757699013, -0.006002834998071194, 0.03397645428776741, 0.038637518882751465, -0.03182942420244217, 0.05373222380876541, -0.04794491454958916, 0.006737657357007265, -0.00978410616517067, 0.045548852533102036, 0.0271973367780447, 0.2391374558210373, -0.030359650030732155, 1.2217643798645452e-32, 0.021851468831300735, -0.08831091225147247, -0.07612763345241547, -0.11410612612962723, -0.004162609111517668, -0.10971594601869583, 0.06299527734518051, 0.02089865878224373, 0.11533162742853165, 0.1378796547651291, -0.10932628810405731, -0.043435849249362946, 0.05454595386981964, -0.045998889952898026, 0.0489896759390831, 0.005967643577605486, -0.009488365612924099, -0.0054754288867115974, 0.0181046761572361, 0.03251038119196892, 0.0941077247262001, -0.061832912266254425, 0.040229249745607376, -0.07302350550889969, -0.018985440954566002, -0.03729160875082016, -0.1277906447649002, -0.05262240394949913, -0.1053505688905716, 0.009365975856781006, -0.04914164915680885, 0.040777090936899185, -0.06953791528940201, -0.07230135053396225, -0.04089067131280899, -0.15816043317317963, 0.031092068180441856, -0.06551666557788849, 0.14610649645328522, 0.05547109618782997, 0.0845387727022171, -0.023016856983304024, -0.06615901738405228, -0.008000803180038929, 0.007257468067109585, 0.09768807142972946, 0.07234793901443481, -0.0598917119204998, -0.06200734153389931, 0.1150427982211113, -0.032589953392744064, -0.0431930348277092, -0.004708557389676571, -0.0420060008764267, -0.16485124826431274, 0.07396392524242401, -0.015429585240781307, -0.05175106227397919, 0.08547382056713104, -0.06650324165821075, -0.06395787745714188, -0.08799922466278076, 0.11149851977825165, -0.08348212391138077, 0.10421838611364365, -0.0633721575140953, 0.0783710703253746, 0.00020269094966351986, -0.09269483387470245, -0.0475611686706543, -0.0543450228869915, -0.06108594313263893, -0.017838912084698677, -0.18652242422103882, 0.14431047439575195, -0.00039299059426411986, 0.15757815539836884, -0.08809859305620193, 0.023806747049093246, -0.07397979497909546, -0.019178930670022964, 0.1703636795282364, 0.08315128087997437, -0.19883401691913605, 0.0944933369755745, 0.03640665113925934, 0.0075286333449184895, -0.08862218260765076, -0.16383719444274902, -0.08447182923555374, -0.1538667529821396, 0.15854454040527344, 0.02386394515633583, 0.03779062628746033, 0.056427184492349625, -1.3309508338562457e-32, -0.012101705186069012, -0.044103845953941345, 0.19720405340194702, -0.06412163376808167, 0.01439388282597065, 0.03700541704893112, -0.1540338397026062, -0.1370663344860077, -0.07987142354249954, -0.10106813162565231, 0.002943036612123251, 0.036909401416778564, 0.07100187242031097, -0.04195842519402504, 0.043080274015665054, 0.09774918109178543, -0.09289030730724335, 0.011043967679142952, -0.02490667626261711, 0.13884657621383667, -0.01500229723751545, 0.053565241396427155, -0.07440672069787979, -0.006974172778427601, -0.1229749396443367, -0.05306326225399971, -0.028472596779465675, 0.059231746941804886, 0.06693045049905777, -0.14968949556350708, -0.13259555399417877, 0.16112075746059418, -0.07562468200922012, -0.07340943813323975, -0.0270818080753088, -0.05659600719809532, -0.0748475193977356, -0.06564293801784515, -0.022500595077872276, 0.19298072159290314, 0.05713064596056938, 0.0761934444308281, -0.21085649728775024, 0.05891285836696625, -0.018602853640913963, -0.055089130997657776, 0.04360237345099449, 0.021086854860186577, 0.11684098094701767, 0.02844029851257801, 0.11719507724046707, 0.0477764792740345, 0.021055374294519424, 0.14174112677574158, -0.05509573221206665, 0.09244711697101593, -0.003547422820702195, -0.0996738076210022, 0.039215222001075745, 0.034044504165649414, -0.01952146179974079, -0.019863957539200783, 0.053614456206560135, 0.028593670576810837, 0.06820254772901535, 0.04077764227986336, 0.07127363234758377, 0.11613763123750687, 0.040723804384469986, -0.021686559543013573, -0.029267793521285057, -0.08691658824682236, 0.0817251056432724, -0.007317196112126112, -0.005881866440176964, -0.08572477847337723, -0.01675146073102951, -0.04050689935684204, -0.07691970467567444, 0.022072773426771164, 0.017803315073251724, 0.071407251060009, 0.029264725744724274, -0.054878514260053635, -0.022257566452026367, 0.07888150960206985, 0.05996057391166687, -0.09188882261514664, 0.022530706599354744, -0.14561963081359863, -0.04348291829228401, 0.07280367612838745, -0.04237416014075279, 0.06830111145973206, 0.07237083464860916, -9.994703020765883e-08, -0.03790223225951195, 0.012238835915923119, -0.05231759324669838, 0.00844626221805811, -0.0024885686580091715, -0.06151914596557617, 0.00273518031463027, 0.1445402055978775, -0.07467468827962875, 0.06057056412100792, 0.08771497011184692, 0.10486164689064026, -0.07561292499303818, 0.07932689040899277, 0.08713625371456146, 0.012048345059156418, 0.051959458738565445, 0.1031867191195488, -0.06959370523691177, 0.04665028303861618, 0.0127602219581604, -0.1316465437412262, 0.05775036662817001, -0.09321248531341553, 0.1047232449054718, -0.1322912871837616, 0.057100601494312286, 0.0257712434977293, 0.11041399091482162, 0.21445944905281067, -0.0958230197429657, 0.027088256552815437, 0.08072904497385025, 0.0714639201760292, 0.17479956150054932, 0.05347882956266403, 0.07839611917734146, -0.116229347884655, -0.11270979791879654, 0.04358264058828354, 0.03859858587384224, 0.10785262286663055, -0.04799966886639595, -0.04011893272399902, -0.0918257012963295, -0.03405280038714409, 0.13282795250415802, -0.027874145656824112, 0.1442081481218338, -0.01455308124423027, 0.09199163317680359, -0.08566483110189438, -0.04172929748892784, 0.06681057065725327, 0.03818761184811592, 0.04331408441066742, -0.10065625607967377, 0.05727149918675423, -0.04284389317035675, -0.052444830536842346, 0.09024852514266968, -0.07709155231714249, 0.021393824368715286, -0.09006607532501221], metadata={'source': 'AAAMLP-569to.pdf', 'page': 162}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 163  # initialize the model model = LinearRegression() # initialize RFE rfe = RFE(     estimator=model,     n_features_to_select=3 )  # fit RFE rfe.fit(X, y)  # get the transformed data with # selected columns X_transformed = rfe.transform(X) ═════════════════════════════════════════════════════════════════════════  We saw two different greedy ways to select features from a model. But you can also fit the model to the data and select features from the model by the feature coefficients or the importance of features. If you use coefficients, you can select a threshold, and if the coefficient is above that threshold, you can keep the feature else eliminate it.  Let’s see how we can get feature importance from a model like random forest.  ═════════════════════════════════════════════════════════════════════════ import pandas as pd from sklearn.datasets import load_diabetes from sklearn.ensemble import RandomForestRegressor  # fetch a regression dataset # in diabetes data we predict diabetes progression # after one year based on some features data = load_diabetes() X = data[\"data\"] col_names = data[\"feature_names\"] y = data[\"target\"]  # initialize the model model = RandomForestRegressor()  # fit the model model.fit(X, y) ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[0.08842363953590393, -0.07210478186607361, 0.06470675766468048, -0.06683758646249771, 0.2907860279083252, -0.14974398910999298, 0.04238473251461983, 0.12281280755996704, -0.16274379193782806, 0.03543799743056297, -0.06717775762081146, -0.04952128976583481, -0.08835597336292267, 0.04811347648501396, 0.030127020552754402, 0.17990310490131378, -0.014666910283267498, -0.1104641929268837, -0.10585162788629532, -0.05853080004453659, 0.07574658840894699, 0.024210404604673386, 0.052236683666706085, 0.009991285391151905, 0.028119871392846107, -0.08886954188346863, 0.17153562605381012, 0.2805657982826233, -0.03257858753204346, -0.06996949017047882, -0.11916885524988174, -0.07107727229595184, 0.04705175757408142, -0.11476459354162216, -0.19678737223148346, -0.05843215435743332, 0.030985673889517784, -0.15792343020439148, 0.04275786131620407, -0.05213924124836922, 0.021304618567228317, 0.06517130881547928, 0.04981106147170067, -0.1135326474905014, 0.09361154586076736, -0.02488323114812374, -0.08282238245010376, -0.020714733749628067, 0.12067364156246185, 0.06896547228097916, -0.06803251802921295, -0.08485959470272064, -0.12794141471385956, 0.01579888164997101, 0.05292543023824692, -0.0019245112780481577, -0.012885134667158127, -0.2327910214662552, 0.09808684140443802, -0.20315374433994293, -0.043532054871320724, 0.03909635171294212, 0.03175440803170204, 0.011600665748119354, -0.01403756346553564, -0.09967612475156784, 0.015058404766023159, 0.11554320156574249, -0.07554400712251663, 0.05254816263914108, 0.00764012336730957, 0.01517475489526987, -0.0691375657916069, -0.08025705814361572, 0.0381535179913044, 0.051119156181812286, 0.06838732957839966, 0.1353607326745987, -0.0549844466149807, -0.06658855825662613, -0.1758277863264084, 0.15579058229923248, 0.002246616641059518, 0.06487945467233658, -0.046250030398368835, -0.06693917512893677, 0.03287256881594658, 0.0410786047577858, -0.009457231499254704, -0.05094310641288757, 0.08098746091127396, -0.05464315041899681, -0.042374853044748306, 0.01310018915683031, -0.05357132479548454, 0.11195480823516846, 0.18240243196487427, -0.1549941748380661, -0.19708409905433655, 0.025231432169675827, -0.050684697926044464, -0.11884412169456482, 0.11560887843370438, -0.024693047627806664, 0.09242114424705505, -0.04551805183291435, 0.001505075371824205, 0.06554070860147476, 0.11932461708784103, -0.11992265284061432, -0.0659128800034523, -0.01829482801258564, -0.1515970528125763, 0.18621686100959778, 0.07305213809013367, 0.17296962440013885, -0.013646122068166733, 0.013720887713134289, -0.06149891018867493, 0.06533069908618927, -0.017383012920618057, 0.06376826018095016, -0.0635252520442009, 0.05324288830161095, -0.02814558334648609, 0.050436798483133316, -0.035483360290527344, 1.114467018763013e-32, 0.04683791846036911, -0.05638008937239647, -0.07220902293920517, -0.05804169178009033, 0.08756054937839508, -0.08151025325059891, -0.0024601195473223925, -0.05607887730002403, 0.018174074590206146, 0.14714494347572327, -0.2155693769454956, 0.07666563242673874, 0.051562875509262085, 0.02440653368830681, 0.005996411200612783, -0.024769464507699013, -0.014258288778364658, 0.06726376712322235, -0.06792165338993073, 0.09057174623012543, 0.09289395064115524, 0.11891838163137436, 0.00870943907648325, -0.17287640273571014, 0.10298963636159897, 0.026710113510489464, 0.04871722310781479, -0.003138190135359764, -0.15259842574596405, 0.028400717303156853, -0.09498369693756104, 0.020336860790848732, -0.1209951788187027, -0.11389349400997162, -0.0682554543018341, -0.12435582280158997, -0.023653430864214897, -0.07773134857416153, 0.09409128874540329, -0.008213869296014309, 0.012935456819832325, -0.09702105075120926, -0.21123208105564117, 0.011681418865919113, 0.003063060576096177, 0.15111544728279114, 0.010489758104085922, 0.0704328641295433, 0.05145873501896858, 0.07215988636016846, -0.03369484469294548, -0.07150664180517197, -0.03476091846823692, 0.061666615307331085, -0.16068002581596375, 0.1408577859401703, 0.08050414174795151, -0.02035844512283802, 0.026952285319566727, -0.08327675610780716, 0.01912015862762928, -0.09096642583608627, 0.04105890914797783, 0.00238715554587543, -0.02043384127318859, 0.037582967430353165, 0.06091766431927681, 0.026604685932397842, 0.04456620290875435, 0.06188633665442467, -0.1249997466802597, 0.025768650695681572, -0.05871567130088806, -0.2258426696062088, 0.1378183811903, -0.04165409877896309, 0.07514005154371262, 0.030667252838611603, 0.0027257034089416265, 0.11166995763778687, 0.054015934467315674, 0.08957578986883163, -0.04395736753940582, -0.32130053639411926, 0.03963560611009598, 0.018892385065555573, 0.054848384112119675, 0.009999912232160568, -0.180691659450531, -0.08712517470121384, -0.08050346374511719, 0.19463825225830078, 0.05884557217359543, 0.03901101276278496, -0.04370615631341934, -1.2875936063469287e-32, -0.07115590572357178, 0.04417865723371506, 0.3005697429180145, 0.08543917536735535, 0.02998684160411358, 0.08633511513471603, -0.12944296002388, -0.1266917735338211, -0.023528797551989555, -0.07766490429639816, -0.06354869157075882, 0.009850765578448772, 0.04844610020518303, -0.08909166604280472, 0.186964213848114, 0.0843040868639946, -0.18102096021175385, 0.11539144814014435, -0.07751467078924179, 0.04161052405834198, -0.00023352955759037286, 0.05409332737326622, -0.14727003872394562, -0.08446519821882248, -0.11429139971733093, 0.014131741598248482, -0.05008561536669731, 0.018677419051527977, 0.025749491527676582, -0.2063913643360138, -0.10223161429166794, 0.14640285074710846, -0.16644489765167236, -0.0920020043849945, 0.027564100921154022, -0.04311428219079971, 0.07549363374710083, -0.12967906892299652, -0.12904196977615356, 0.22259840369224548, 0.05443129315972328, 0.05852449685335159, -0.12395920604467392, 0.08766574412584305, -0.09792249649763107, 0.08667279034852982, 0.048203546553850174, 0.02258247137069702, 0.08873733878135681, 0.002072669332846999, 0.09679482132196426, 0.02854054607450962, 0.05376090481877327, 0.08224213868379593, -0.010917946696281433, 0.08300962299108505, -0.029748594388365746, 0.07074103504419327, 0.0026544583961367607, -0.003422999056056142, -0.09727711230516434, -0.04024786129593849, -0.012394978664815426, -0.0058182040229439735, -0.006431116722524166, -0.011781404726207256, -0.04208958521485329, -0.05889590457081795, 0.03478020802140236, -0.060908325016498566, 0.018165448680520058, -0.12567341327667236, 0.03811965510249138, -0.07768233120441437, -0.029229160398244858, 0.10710900276899338, 0.015694329515099525, -0.06481379270553589, -0.10700852423906326, 0.08557308465242386, 0.22634468972682953, 0.015259596519172192, 0.06492415815591812, 0.09135127812623978, 0.004909306764602661, 0.18560092151165009, 0.16790542006492615, 0.06782498210668564, 0.006964380852878094, -0.1627768576145172, -0.014933024533092976, 0.14096984267234802, -0.09805042296648026, 0.20084284245967865, 0.08966764062643051, -9.973191339440746e-08, -0.1023048534989357, 0.0005505123408511281, -0.019665591418743134, -0.021434489637613297, 0.03021780587732792, -0.018593430519104004, -0.04141416400671005, 0.2445608377456665, -0.08017527312040329, 0.10356206446886063, 0.051531627774238586, 0.028326435014605522, -0.1541508138179779, 0.03328537940979004, 0.040833599865436554, -0.0027802654076367617, 0.10907521843910217, -0.030351992696523666, -0.0026802783831954002, 0.02795371040701866, -0.0007904260419309139, -0.18559865653514862, 0.1611492931842804, -0.0011664001503959298, -0.015639526769518852, -0.13238108158111572, 0.013874961994588375, 0.07969719171524048, 0.028240283951163292, 0.22890371084213257, -0.07707880437374115, -0.10894832015037537, 0.049717795103788376, 0.020886195823550224, 0.15493114292621613, 0.07362524420022964, 0.023477721959352493, -0.07717369496822357, 0.009815685451030731, 0.10910046100616455, 0.020288947969675064, 0.09444376081228256, -0.04679485782980919, -0.016094224527478218, -0.02158353663980961, 0.02214730717241764, 0.01251295767724514, -0.1344105303287506, 0.11554049700498581, -0.0072270845994353294, -0.022333363071084023, -0.17547154426574707, -0.018499230965971947, 0.018046345561742783, -0.0071298847906291485, 0.07402246445417404, -0.20140716433525085, 0.00704013230279088, 0.0109186340123415, 0.005670714192092419, 0.0721462070941925, 0.006199172232300043, 0.00037349623744376004, -0.05413078889250755], metadata={'source': 'AAAMLP-569to.pdf', 'page': 163}, content=\"Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 164 Feature importance from random forest (or any model) can be plotted as follows.  ═════════════════════════════════════════════════════════════════════════ importances = model.feature_importances_ idxs = np.argsort(importances) plt.title('Feature Importances') plt.barh(range(len(idxs)), importances[idxs], align='center') plt.yticks(range(len(idxs)), [col_names[i] for i in idxs]) plt.xlabel('Random Forest Feature Importance') plt.show() ═════════════════════════════════════════════════════════════════════════  The resulting plot is shown in figure 3. \\n Figure 3: Plot of feature importance  Well, selecting the best features from the model is nothing new. You can choose features from one model and use another model to train. For example, you can use Logistic Regression coefficients to select the features and then use Random Forest to train the model on chosen features. Scikit-learn also offers SelectFromModel class that helps you choose features directly from a given model. You can also specify the threshold for coefficients or feature importance if you want and the maximum number of features you want to select.\"),\n",
       " VectorParams(vector=[0.012716892175376415, -0.13443924486637115, 0.05708848312497139, 0.12342673540115356, 0.2582492232322693, -0.04305766895413399, -0.003610015846788883, 0.03851117938756943, -0.1320945769548416, -0.03490808606147766, -0.012490896508097649, -0.036850906908512115, -0.10177713632583618, -0.029706399887800217, 0.021144475787878036, 0.11050979048013687, 0.059864554554224014, -0.06093033403158188, -0.11118356138467789, -0.01830834522843361, 0.14086207747459412, 0.005338518880307674, -0.04131311923265457, 0.07798624038696289, 0.04896267503499985, -0.11198917031288147, -0.0026360100600868464, 0.17379240691661835, -0.13778652250766754, -0.06976930052042007, -0.07770904898643494, 0.10398964583873749, -0.016697606071829796, -0.08938124775886536, -0.1662791669368744, -0.06136356666684151, -0.018124185502529144, -0.15016034245491028, -0.09608045220375061, -0.05688159912824631, 0.006643296219408512, -0.029064474627375603, -0.026461170986294746, -0.10339035093784332, 0.1036374568939209, -0.03445427864789963, -0.11303949356079102, 0.05794903263449669, 0.02480130083858967, -0.0007204351713880897, -0.0029572814237326384, -0.03898582607507706, -0.08664540946483612, 0.07986484467983246, 0.000701171054970473, -0.06755468249320984, -0.009918903931975365, -0.10162394493818283, 0.009984223172068596, -0.12255491316318512, -0.024964982643723488, -0.024148348718881607, -0.04479176551103592, 0.019842563197016716, 0.058639124035835266, -0.08177202939987183, 0.039410561323165894, -0.09403882920742035, -0.05905018001794815, 0.02488410845398903, -0.06850997358560562, 0.014620608650147915, -0.006399737671017647, 0.027682682499289513, 0.0623173713684082, 0.028687840327620506, 0.13888360559940338, 0.14167124032974243, 0.0545492060482502, -0.03481509909033775, -0.07940897345542908, 0.13942277431488037, 0.0037509871181100607, 0.0018973761470988393, -0.023977113887667656, -0.05710252374410629, -0.018131060525774956, -0.01827036775648594, -0.0456613153219223, 0.050319820642471313, 0.09141430258750916, -0.0483226515352726, 0.0016714611556380987, -0.04189854487776756, -0.012242916971445084, 0.04484973102807999, 0.07588758319616318, -0.13131476938724518, -0.03074057027697563, 0.01872144639492035, -0.11920744925737381, -0.06947269290685654, 0.1371515691280365, -0.004152997396886349, 0.09039337933063507, -0.029292788356542587, 0.018207907676696777, 0.016630684956908226, 0.1250263750553131, -0.05063260719180107, 0.019193973392248154, -0.011344436556100845, -0.021110979840159416, 0.07967894524335861, -0.015328852459788322, 0.04309114068746567, -4.4880242057843134e-05, -0.029791610315442085, 0.016250597313046455, 0.01839945837855339, -0.007594004739075899, -0.0067805699072778225, -0.014875205233693123, -0.026391057297587395, -0.012588710524141788, 0.10045401751995087, -0.08725924789905548, 1.5475365496160153e-32, 0.11178519576787949, -0.1224885880947113, -0.036986686289310455, -0.11714331805706024, 0.03479993715882301, -0.07959942519664764, 0.07286977022886276, 0.08295366168022156, 0.08943123370409012, 0.079708032310009, -0.22305455803871155, 0.002740102121606469, 0.031016867607831955, -0.011780556291341782, 0.029918348416686058, 0.02321167290210724, -0.050975773483514786, 0.05966642126441002, -0.017620448023080826, 0.06506386399269104, 0.16047446429729462, 0.06240685656666756, 0.01221273373812437, -0.16223858296871185, 0.057126134634017944, 0.05550180375576019, -0.07661766558885574, -0.06385120749473572, -0.13684818148612976, 0.03509636968374252, -0.14707151055335999, 0.0004232494975440204, 0.01928326115012169, -0.05627137050032616, 0.011499600484967232, -0.1672833263874054, 0.07462514936923981, -0.1369294673204422, 0.05561593919992447, 0.006611497141420841, 0.06676669418811798, 0.03228694945573807, -0.030398713424801826, -0.006073334254324436, -0.031810760498046875, 0.0813327506184578, -0.0006161730270832777, 0.030417287722229958, 0.05224142223596573, 0.10206087678670883, 0.014797002077102661, -0.031114943325519562, -0.06800748407840729, -0.0051002404652535915, -0.14911670982837677, 0.1044052317738533, -0.02487645484507084, -0.013532815501093864, 0.047607146203517914, -0.0004314029938541353, -0.07809382677078247, -0.0509292334318161, 0.07225217670202255, -0.08435331284999847, 0.07613085955381393, 0.026145445182919502, 0.1294742077589035, 0.021948734298348427, -0.03743498772382736, -0.10981928557157516, -0.11175505816936493, -0.02051384374499321, 0.050036005675792694, -0.14237813651561737, 0.2036110758781433, -0.07531473785638809, 0.18387693166732788, -0.09651083499193192, -0.01887838914990425, 0.006512240506708622, -0.011712653562426567, 0.15179963409900665, 0.007641338277608156, -0.12770840525627136, -0.05958043411374092, 0.010607820935547352, 0.11549191176891327, -0.12367288768291473, -0.13955698907375336, -0.142185240983963, -0.07117986679077148, 0.10018058121204376, 0.07947179675102234, -0.018153445795178413, 0.0531630665063858, -1.6253266515232064e-32, -0.04401802644133568, -0.0735945925116539, 0.22624187171459198, -0.013907876797020435, 0.05341007933020592, 0.04445856437087059, -0.07124831527471542, -0.2201879620552063, -0.044142864644527435, -0.18359233438968658, 0.02256598509848118, -0.007342216558754444, 0.04079166799783707, -0.06975508481264114, 0.17709484696388245, 0.12687626481056213, -0.12592436373233795, -0.020489143207669258, -0.1357513964176178, 0.15889683365821838, 0.03599150478839874, 0.1085328757762909, -0.07479994744062424, -0.04705120623111725, -0.08742420375347137, -0.07421181350946426, -0.028431937098503113, 0.1132110133767128, 0.10591790825128555, -0.07082269340753555, -0.045376524329185486, 0.20372548699378967, -0.18230067193508148, -0.07062862068414688, -0.028682269155979156, -0.09357298165559769, -0.1054716408252716, -0.029670797288417816, -0.01922326162457466, 0.17725418508052826, 0.1158471554517746, 0.11816702038049698, -0.1707618683576584, 0.053956713527441025, 0.008191353641450405, -0.03182293102145195, -0.04968829080462456, -0.05857067555189133, 0.1320425271987915, 0.00038834172300994396, 0.07543353736400604, -0.026050588116049767, -0.11989465355873108, 0.18695805966854095, -0.027464505285024643, 0.05932779237627983, -0.011983374133706093, 0.0009773403871804476, -0.05577068030834198, 0.010854728519916534, -0.07306879758834839, 0.015210473909974098, 0.03319101780653, -0.037320803850889206, 0.1423395872116089, 0.06871359050273895, 0.07245109975337982, -0.04659144580364227, 0.024808304384350777, -0.01564580388367176, -0.05352010577917099, -0.14118777215480804, 0.11734939366579056, -0.0011904279235750437, -0.08012965321540833, 0.07801605015993118, -0.01381174847483635, -0.03149794787168503, -0.09352254867553711, 0.12154515087604523, 0.05190211907029152, 0.019276754930615425, 0.03517218679189682, 0.05351845547556877, -0.045176055282354355, 0.0821852758526802, 0.07594042271375656, 0.08043576776981354, 0.043564025312662125, -0.1354556530714035, 0.008208192884922028, 0.026582300662994385, 0.024403143674135208, 0.10320768505334854, 0.08764403313398361, -9.98102862581618e-08, -0.031626611948013306, 0.006700663827359676, -0.035482559353113174, 0.04111691191792488, -0.015523813664913177, -0.023010289296507835, -0.041175998747348785, 0.15923535823822021, -0.04313940927386284, 0.06914860755205154, 0.10645276308059692, 0.09403281658887863, -0.08666761964559555, -0.02008085325360298, 0.08288178592920303, 0.04398289695382118, 0.02463993988931179, 0.0766543373465538, -0.0915316715836525, 0.10751903802156448, -0.06748194247484207, -0.14617598056793213, 0.005313440691679716, -0.0976795181632042, 0.05342075601220131, -0.12082042545080185, 0.010146028362214565, 0.08433988690376282, 0.12859897315502167, 0.14956779778003693, -0.04199491813778877, -0.026188386604189873, 0.056500326842069626, 0.00026266969507560134, 0.14228196442127228, 0.059000205248594284, 0.11348526179790497, -0.11754744499921799, -0.016211898997426033, 0.13891127705574036, 0.0599207878112793, 0.003075248096138239, -0.010236294008791447, -0.0501214973628521, 0.0019137037452310324, 0.00201949174515903, 0.07671374082565308, -0.059141188859939575, 0.15428562462329865, -0.00023496382345911115, 0.008513817563652992, -0.1515299379825592, -0.050421759486198425, 0.01072252169251442, 0.08678365498781204, 0.0134813841432333, -0.14983420073986053, 0.06571023911237717, 0.05003136023879051, -0.0430830679833889, 0.09941140562295914, -0.02313651517033577, 0.037606410682201385, 0.02945561707019806], metadata={'source': 'AAAMLP-569to.pdf', 'page': 164}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 165 Take a look at the following snippet where we select the features using default parameters in SelectFromModel. ═════════════════════════════════════════════════════════════════════════ import pandas as pd from sklearn.datasets import load_diabetes from sklearn.ensemble import RandomForestRegressor from sklearn.feature_selection import SelectFromModel  # fetch a regression dataset # in diabetes data we predict diabetes progression # after one year based on some features data = load_diabetes() X = data[\"data\"] col_names = data[\"feature_names\"] y = data[\"target\"]  # initialize the model model = RandomForestRegressor()  # select from the model sfm = SelectFromModel(estimator=model) X_transformed = sfm.fit_transform(X, y)  # see which features were selected support = sfm.get_support()  # get feature names print([     x for x, y in zip(col_names, support) if y == True ]) ═════════════════════════════════════════════════════════════════════════  Which prints: [\\'bmi\\', \\'s5\\']. When we look at figure 3, we see that these are the top-2 features. Thus, we could have also selected directly from feature importance provided by random forest. One more thing that we are missing here is feature selection using models that have L1 (Lasso) penalization. When we have L1 penalization for regularization, most coefficients will be 0 (or close to 0), and we select the features with non-zero coefficients. You can do it by just replacing random forest in the snippet of selection from a model with a model that supports L1 penalty, e.g. lasso regression. All tree-based models provide feature importance so all the model-based snippets shown in this chapter can be used for XGBoost, LightGBM or CatBoost. The feature importance function names might be different and may produce results in a different format, but the usage will remain the same. In the end, you must be careful when doing feature selection. Select features on'),\n",
       " VectorParams(vector=[-0.15843474864959717, 0.0826014056801796, 0.15547719597816467, 0.01655752956867218, 0.2250271737575531, -0.011444123461842537, -0.048776887357234955, 0.032346513122320175, -0.4038788676261902, -0.10884485393762589, -0.028303761035203934, -0.09065137803554535, 0.16278553009033203, -0.167610302567482, -0.1663937270641327, 0.14499720931053162, 0.046775899827480316, 0.15673258900642395, -0.12814199924468994, -0.31212058663368225, -0.12702816724777222, 0.04818416386842728, -0.12891219556331635, 0.1292833387851715, -0.22154852747917175, -0.1346026062965393, 0.1268198937177658, -0.01002712082117796, 0.0024453974328935146, -0.1769954264163971, 0.14736685156822205, 0.10567624866962433, -0.15720213949680328, -0.1318994164466858, 0.023452691733837128, 0.08608578145503998, -0.13344725966453552, 0.12951114773750305, 0.05750839784741402, 0.112373948097229, 0.10671138763427734, -0.15827564895153046, -0.0874490812420845, 0.01451192982494831, 0.21543815732002258, 0.060996800661087036, -0.19497497379779816, -0.11264972388744354, 0.04287227615714073, 0.18651416897773743, -0.32644784450531006, 0.007189798168838024, -0.0844750627875328, 0.20236149430274963, -0.06551290303468704, -0.4077011048793793, -0.16552895307540894, -0.1108459010720253, 0.17824582755565643, -0.22398741543293, 0.04324021190404892, -0.1745002716779709, -0.24045614898204803, 0.03585905581712723, 0.07210201025009155, 0.07723738253116608, -0.11102156341075897, -0.1303403675556183, -0.13690796494483948, 0.1364280879497528, 0.08073268085718155, 0.19049140810966492, -0.12520954012870789, 0.3599386215209961, -0.05185157060623169, 0.08001220226287842, 0.05571424961090088, 0.018303044140338898, 0.22831657528877258, -0.05393581837415695, -0.13685151934623718, 0.028256231918931007, 0.14700017869472504, -0.0893755778670311, 0.17271532118320465, 0.01332002878189087, -0.17390437424182892, -0.08902128785848618, -0.010200726799666882, -0.06285630166530609, 0.15334923565387726, -0.21746286749839783, 0.28005120158195496, 0.0665661096572876, -0.1613546460866928, 0.12931522727012634, 0.13831119239330292, -0.15607722103595734, -0.007401332259178162, 0.2177218645811081, -0.42092961072921753, 0.13762645423412323, -0.001593147637322545, 0.10969237238168716, 0.08544331789016724, -0.13724103569984436, 0.1036699041724205, -0.06864634156227112, 0.36202818155288696, -0.24942132830619812, 0.13024431467056274, -0.22036580741405487, 0.007499089930206537, -0.06785354763269424, 0.12645015120506287, 0.1673203557729721, -0.23686620593070984, 0.06752514839172363, -0.27535468339920044, 0.2248661071062088, -0.013024905696511269, 0.006818602792918682, 0.23919689655303955, 0.09476134181022644, 0.08342912793159485, -0.16016602516174316, -0.20674951374530792, 1.1658098936762442e-32, -0.168525829911232, -0.07929183542728424, 0.004371220711618662, -0.14159148931503296, -0.10493411868810654, -0.2782500982284546, -0.11722131818532944, -0.008730425499379635, -0.06650407612323761, 0.08193700015544891, -0.16225865483283997, -0.24420610070228577, -0.09968502819538116, -0.06000307947397232, 0.2016463279724121, 0.16290457546710968, 0.03125111758708954, 0.057740580290555954, -0.13838976621627808, 0.09024834632873535, 0.3607133626937866, -0.2368805706501007, 0.1272859275341034, -0.06670264154672623, -0.07594902813434601, 0.13079988956451416, 0.08720497786998749, 0.012838594615459442, 0.004758134484291077, 0.24599242210388184, -0.06878076493740082, 0.03923416882753372, -0.05087534710764885, 0.16397100687026978, 0.0481463186442852, 0.002160310745239258, -0.01379469782114029, -0.11423317342996597, 0.06876164674758911, 0.0645323172211647, -0.03999929875135422, -0.035827796906232834, -0.017867129296064377, 0.07960201054811478, 0.06670345366001129, 0.11977951228618622, 0.10303349792957306, -0.10484002530574799, -0.10496530681848526, 0.13496564328670502, -0.17818394303321838, 0.010994273237884045, -0.20173616707324982, -0.16373902559280396, -0.343437522649765, 0.16174666583538055, -0.1207820326089859, -0.0779346451163292, -0.0052463700994849205, 0.16515466570854187, 0.21993637084960938, -0.29225531220436096, -0.006483010947704315, -0.06576559692621231, -0.17017050087451935, -0.2917260527610779, 0.012691875919699669, -0.14469535648822784, 0.023555289953947067, -0.042037300765514374, -0.10855543613433838, -0.10097213089466095, 0.09951481223106384, -0.06929431855678558, -0.03150918334722519, -0.13577696681022644, 0.3007616400718689, 0.21433062851428986, -0.1108100414276123, 0.05383222550153732, -0.03364486247301102, 0.13677425682544708, -0.1448882669210434, -0.3468270003795624, 0.12000001966953278, -0.04902685806155205, 0.009057213552296162, -0.010920118540525436, -0.11966113746166229, 0.13939689099788666, -0.24243906140327454, 0.2017074078321457, -0.07564964145421982, -0.093162402510643, -0.022897973656654358, -7.91179991005975e-33, -0.07842741161584854, 0.17679065465927124, 0.1333301067352295, 0.37931087613105774, -0.02498408406972885, -0.06053939461708069, 0.19164584577083588, 0.15638981759548187, -0.13977034389972687, -0.08545192331075668, 0.2420799732208252, -0.1288735419511795, 0.19944898784160614, -0.1470535695552826, -0.20161470770835876, 0.14409911632537842, -0.2785819172859192, -0.03856945037841797, -0.00869973935186863, 0.053635746240615845, -0.03606900945305824, 0.11033104360103607, -0.2720476984977722, 0.09784559160470963, -0.13412988185882568, 0.19951094686985016, -0.24174141883850098, 0.07353730499744415, 0.1359090805053711, 0.14120657742023468, -0.08714117109775543, 0.04198809713125229, -0.09892626106739044, 0.09361627697944641, -0.06032221391797066, 0.04142671823501587, 0.21269163489341736, 0.041468191891908646, 0.08395727723836899, 0.5323721170425415, 0.19300809502601624, 0.24735303223133087, -0.5476332902908325, 0.05509079620242119, 0.055142592638731, -0.1892092525959015, -0.2164771556854248, -0.010166662745177746, 0.056060753762722015, -0.3109191358089447, 0.09148178994655609, 0.028633004054427147, 0.15116587281227112, 0.11250927299261093, -0.05561085790395737, 0.21547965705394745, 0.00035975128412246704, 0.11365870386362076, 0.17005866765975952, 0.12360753118991852, -0.1487879455089569, -0.019543465226888657, 0.2227540910243988, 0.2615859806537628, 0.17500486969947815, 0.05994849279522896, 0.12276067584753036, 0.2568434774875641, 0.09059534966945648, -0.03552328795194626, -0.09839466214179993, -0.13034643232822418, -0.07862165570259094, 0.08066300302743912, 0.03494502976536751, -0.023835238069295883, -0.056531161069869995, -0.04533781856298447, -0.014628840610384941, -0.10801856219768524, -0.013599487952888012, -0.06531388312578201, 0.011790245771408081, 0.3066031336784363, 0.14157554507255554, 0.31123581528663635, 0.22089286148548126, -0.11625170707702637, -0.23664645850658417, -0.23756694793701172, -0.10343308746814728, 0.13269254565238953, 0.08046623319387436, 0.17377343773841858, -0.10759714990854263, -9.803452627465958e-08, -0.23635606467723846, -0.123948834836483, 0.157075434923172, 0.09809370338916779, 0.3176157474517822, -0.13153579831123352, -0.08568674325942993, 0.18729722499847412, -0.09673887491226196, 0.15582387149333954, 0.026892859488725662, 0.07187367975711823, -0.1541544497013092, 0.16043660044670105, 0.09559589624404907, -0.008242836222052574, 0.10560204833745956, 0.422525018453598, -0.12781813740730286, 0.14330270886421204, 0.38148069381713867, 0.06040263921022415, 0.1910361647605896, -0.008921949192881584, 0.3038695454597473, -0.1673823744058609, -0.2864939272403717, 0.15358075499534607, -0.06912586092948914, 0.2784368097782135, -0.16081593930721283, -0.04767006263136864, 0.2211921662092209, -0.12671954929828644, 0.38959595561027527, 0.15351653099060059, 0.09914837032556534, -0.21496514976024628, -0.31566286087036133, -0.04686763137578964, -0.06140502542257309, 0.17421209812164307, -0.08702047169208527, -0.15622694790363312, 0.051123976707458496, 0.004157154355198145, 0.22960297763347626, -0.32427993416786194, -0.15844771265983582, 0.13209855556488037, 0.0023416399490088224, -0.1565176099538803, 0.15859468281269073, 0.16166996955871582, 0.1326231211423874, -0.09434168040752411, -0.12818990647792816, -0.07586505264043808, 0.01808779500424862, -0.16739729046821594, 0.24297912418842316, 0.05603823810815811, -0.01356141734868288, -0.08855696022510529], metadata={'source': 'AAAMLP-569to.pdf', 'page': 165}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 166 training data and validate the model on validation data for proper selection of features without overfitting the model.'),\n",
       " VectorParams(vector=[-0.0711720660328865, -0.03315918147563934, -0.15586112439632416, -0.03456396609544754, -0.05319156497716904, 0.03574913740158081, 0.03333655372262001, -0.03319728001952171, -0.12466880679130554, 0.045113515108823776, -0.047121431678533554, -0.027049997821450233, 0.03912108391523361, -0.033586807548999786, -0.049396418035030365, 0.11587348580360413, 0.06961173564195633, 0.03162779286503792, -0.18665042519569397, -0.07095878571271896, 0.1410907804965973, -0.00765627808868885, 0.005267995409667492, 0.0019490917911753058, 0.004792307503521442, -0.057811833918094635, 0.0034242758993059397, 0.07261139899492264, -0.1229744628071785, -0.010415366850793362, 0.06109707057476044, -0.02634667046368122, -0.05202051252126694, 0.09979017078876495, -0.013728883117437363, 0.05130266770720482, -0.18410040438175201, -0.09770944714546204, -0.015245016664266586, -0.005187405738979578, -0.0677649974822998, -0.0554959811270237, -0.06445327401161194, -0.02884659171104431, 0.13225020468235016, 0.0670689195394516, -0.12890148162841797, -0.045368492603302, -0.00046389500494115055, -0.02010241337120533, -0.1571955382823944, -0.006689500994980335, -0.10126300901174545, 0.06383126229047775, -0.020954297855496407, -0.031813252717256546, 0.024768780916929245, -0.02657434530556202, 0.08516377955675125, -0.12677042186260223, -0.045242298394441605, -0.11699800193309784, -0.077333465218544, -0.022099394351243973, 0.07833557575941086, 0.004980976227670908, -0.02546681836247444, -0.059791937470436096, 0.040836844593286514, 0.10430784523487091, -0.06316301971673965, 0.12252262234687805, -0.015129078179597855, -0.03638346865773201, 0.04446012154221535, 0.04468400403857231, 0.19494272768497467, 0.03191089630126953, -0.011474893428385258, -0.06520717591047287, 0.06769157946109772, 0.03527500852942467, -0.017245162278413773, 0.057577356696128845, 0.09477191418409348, -0.2005675882101059, 0.07328727841377258, -0.0107717365026474, 0.22492612898349762, -0.05229572579264641, -0.013828647322952747, -0.03534560278058052, -0.026438914239406586, -0.051387909799814224, 0.09467872232198715, 0.10154902189970016, 0.06343236565589905, -0.08511365205049515, -0.10173092782497406, 0.033239398151636124, 0.06057002395391464, 0.01770603097975254, 0.07147236168384552, -0.06732682883739471, 0.1555732935667038, -0.03210948780179024, 0.04850446805357933, 0.03682713955640793, 0.09108287841081619, -0.07505775988101959, 0.010559001006186008, 0.034858688712120056, 0.08763018995523453, 0.045949578285217285, 0.0031261334661394358, 0.13579949736595154, 0.08585347980260849, 0.11306056380271912, -0.008645688183605671, 0.1536708027124405, -0.1208006888628006, 0.018811456859111786, 0.1608385145664215, -0.026742441579699516, -1.8233309674542397e-05, -0.03484790772199631, -0.17197643220424652, 7.260374001612656e-33, -0.09142899513244629, -0.00021566946816165, -0.017983227968215942, -0.11257776618003845, -0.013735565356910229, 0.009128102101385593, 0.04364529997110367, -0.002742115641012788, 0.03677274286746979, -0.03072121925652027, -0.1943625956773758, -0.08791553974151611, 0.010553891770541668, 0.08688107877969742, 0.06871581077575684, 0.03922007977962494, -0.07195276767015457, 0.09786580502986908, -0.07877718657255173, -0.0006664117099717259, 0.12509116530418396, -0.038116421550512314, 0.038950011134147644, -0.09417121857404709, -0.06936179846525192, -0.07800601422786713, 0.11232549697160721, 0.08855979144573212, -0.18958933651447296, 0.024746723473072052, -0.1382456123828888, -0.013395317830145359, -0.060969822108745575, -0.038524825125932693, 0.08351080864667892, 0.006658816244453192, 0.026599526405334473, 0.0017822225345298648, 0.06262780725955963, -0.14951010048389435, -0.11960315704345703, -0.03417607769370079, 0.06272033601999283, 0.07268667221069336, -0.12965573370456696, -0.08214274793863297, -0.09944602847099304, 0.07270435988903046, 0.08220996707677841, 0.08037762343883514, -0.10298893600702286, -0.08008670061826706, 0.06818267703056335, -0.050903286784887314, -0.12085216492414474, 0.015048688277602196, 0.02873343601822853, 0.05708388611674309, -0.012318027205765247, 0.12216970324516296, 0.002538348315283656, -0.03381764888763428, -0.03076038882136345, 0.004366989713162184, 0.044508349150419235, 0.034982018172740936, 0.0500706285238266, 0.08045105636119843, 0.17229026556015015, -0.0009233035380020738, -0.1382913589477539, -0.03247702121734619, 0.019572889432311058, -0.09034549444913864, -0.019875943660736084, -0.05638430267572403, 0.13096220791339874, -0.007876751013100147, -0.053406644612550735, -0.11481045186519623, 0.006168896798044443, 0.29362767934799194, -0.0015314583433791995, -0.07710601389408112, -0.09222214668989182, -0.05031692236661911, -0.00443081371486187, -0.06763181835412979, -0.10559117048978806, -0.15031622350215912, -0.12226907163858414, 0.13367228209972382, -0.06533293426036835, -0.025674348697066307, -0.025513719767332077, -6.469516830742775e-33, 0.08344672620296478, -0.018669987097382545, 0.041284091770648956, 0.20643223822116852, 0.1398972123861313, 0.01687127910554409, -0.04754718765616417, -0.11260463297367096, -0.08554274588823318, -0.05833400785923004, 0.03201786428689957, -0.05747987702488899, -0.0333406999707222, -0.015295688062906265, 0.14140309393405914, 0.10140997916460037, -0.1661079376935959, -0.05680282786488533, 0.07118721306324005, 0.10917429625988007, -0.01044333167374134, 0.055408231914043427, -0.18384362757205963, 0.10807034373283386, -0.20384393632411957, 0.007089180871844292, -0.054863978177309036, 0.02529154159128666, 0.038983944803476334, 0.03089769370853901, -0.0007230356568470597, 0.0541328527033329, -0.16129964590072632, 0.05101486295461655, 0.06804487854242325, -0.018626276403665543, 0.08818535506725311, -0.05149174854159355, 0.010029210709035397, 0.22960878908634186, 0.07672037929296494, 0.13300198316574097, -0.0881994441151619, 0.029345154762268066, 0.025209695100784302, 0.18378803133964539, 0.06344214826822281, -0.13547365367412567, -0.08252273499965668, -0.0361795574426651, 0.01560260634869337, -0.10900755226612091, -0.03632943704724312, 0.1221894696354866, -0.07279624789953232, -0.02547716349363327, -0.1740986555814743, -0.007875120267271996, 0.07462888211011887, 0.02147672511637211, -0.06851550936698914, 0.01510127168148756, 0.10039256513118744, -0.005109504330903292, 0.030647380277514458, 0.10451237112283707, -0.010478196665644646, -0.08070672303438187, -0.06596247851848602, 0.033140216022729874, -0.11126872897148132, -0.020920217037200928, 0.11789687722921371, 0.04354171082377434, -0.04823336750268936, 0.014235259965062141, -0.0353519432246685, -0.008144219405949116, -0.05672810599207878, -0.11802075803279877, 0.055354807525873184, 0.010151198133826256, 0.022406766191124916, 0.21016959846019745, -0.11140687763690948, 0.15290206670761108, 0.17351461946964264, 0.15872229635715485, 0.009261109866201878, -0.11444903910160065, 0.018761571496725082, 0.0560186393558979, -0.029187429696321487, 0.1162971705198288, -0.060807593166828156, -1.0011784468133555e-07, 0.0007049908163025975, 0.09354815632104874, -0.08083520829677582, 0.04702277109026909, -0.046876486390829086, 0.048130448907613754, -0.01373472809791565, 0.10700538754463196, -0.030672216787934303, 0.035550691187381744, 0.08466105163097382, 0.02980107069015503, -0.11510829627513885, 0.14102020859718323, -0.14523464441299438, 0.03846893459558487, -0.0001308699429500848, 0.07989159971475601, -0.0722355768084526, 0.09426797181367874, 0.0737922191619873, 0.0169255118817091, 0.053569495677948, 0.0053644003346562386, 0.17921660840511322, -0.04829055443406105, -0.00033963198075070977, 0.09531418234109879, 0.028283746913075447, 0.0760054662823677, 0.04109930619597435, -0.08626734465360641, 0.019513780251145363, 0.005071250256150961, 0.0029094794299453497, 0.19445650279521942, -0.03848373889923096, -0.09657621383666992, 0.0659136101603508, 0.1150825023651123, -0.05454181879758835, 0.13932697474956512, -0.14447282254695892, -0.032223816961050034, 0.07469494640827179, -0.06833000481128693, -0.012844488956034184, -0.07400469481945038, -0.1313084065914154, 0.011954741552472115, 0.02779238484799862, -0.03851282596588135, -0.0576823428273201, 0.05246149003505707, 0.03005256876349449, -0.16825692355632782, -0.0819547027349472, -0.14319248497486115, 0.104324571788311, 0.06623351573944092, 0.1117168515920639, -0.00022694865765515715, -0.08917424082756042, 0.07821561396121979], metadata={'source': 'AAAMLP-569to.pdf', 'page': 166}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 167 Hyperparameter optimization  With great models, comes the great problem of optimizing hyper-parameters to get the best scoring model. So, what is this hyper-parameter optimization? Suppose there is a simple pipeline for your machine learning project. There is a dataset, you directly apply a model, and then you have results. The parameters that the model has here are known as hyper-parameters, i.e. the parameters that control the training/fitting process of the model. If we train a linear regression with SGD, parameters of a model are the slope and the bias and hyperparameter is learning rate. You will notice that I use these terms interchangeably in this chapter and throughout this book. Let’s say there are three parameters a, b, c in the model, and all these parameters can be integers between 1 and 10. A “correct” combination of these parameters will provide you with the best result. So, it’s kind of like a suitcase with a 3-dial combination lock. However, in 3 dial combination lock has only one correct answer. The model has many right answers. So, how would you find the best parameters? A method would be to evaluate all the combinations and see which one improves the metric. Let’s see how this is done.  ═════════════════════════════════════════════════════════════════════════ # define the best accuracy to be 0 # if you choose loss as a metric, # you can make best loss to be inf (np.inf) best_accuracy = 0 best_parameters = {\"a\": 0, \"b\": 0, \"c\": 0}  # loop over all values for a, b & c for a in range(1, 11):     for b in range(1, 11):         for c in range(1, 11):             # inititalize model with current parameters             model = MODEL(a, b, c)             # fit the model             model.fit(training_data)             # make predictions             preds = model.predict(validation_data)             # calculate accuracy             accuracy = metrics.accuracy_score(targets, preds)             # save params if current accuracy             # is greater than best accuracy             if accuracy > best_accuracy:                 best_accuracy = accuracy                 best_parameters[\"a\"] = a'),\n",
       " VectorParams(vector=[-0.08556658029556274, -0.032947927713394165, -0.17431332170963287, 0.023717015981674194, 0.141097292304039, -0.05462966114282608, -0.012761102989315987, -0.023716799914836884, -0.0059874956496059895, 0.05261873081326485, -0.12288796901702881, -0.09345057606697083, 0.01026600506156683, -0.038938771933317184, 0.0032843779772520065, 0.05709628388285637, 0.010070234537124634, -0.014499829150736332, -0.2091847062110901, 0.001028752769343555, 0.09108246117830276, -0.050096433609724045, -0.05798918753862381, -0.06891967356204987, -0.06223297119140625, -0.09263097494840622, -0.011470338329672813, -0.059347085654735565, -0.08143545687198639, -0.014140598475933075, -0.005089419893920422, 0.002788278739899397, -0.008946176618337631, 0.08148116618394852, 0.06400221586227417, -0.007992870174348354, -0.19000430405139923, -0.03541310876607895, -0.028626946732401848, 0.07114524394273758, -0.04129764437675476, 0.12897716462612152, -0.02578187733888626, -0.006372314412146807, 0.12695495784282684, 0.07201087474822998, -0.10713411122560501, -0.02242431230843067, 0.09991881996393204, -0.02728751115500927, -0.13693751394748688, 0.03751365840435028, -0.10921645909547806, 0.05320265516638756, 0.04275108873844147, -0.21189463138580322, -0.08472349494695663, -0.1406674087047577, 0.05663725733757019, 0.028132854029536247, -0.007237929385155439, -0.08933360874652863, 0.01260028313845396, -0.019656183198094368, 0.095557801425457, 0.06954595446586609, -0.06268399208784103, -0.010756601579487324, 0.026472125202417374, 0.07243014872074127, -0.020564109086990356, 0.03409929946064949, -0.12126457691192627, 0.06687617301940918, 0.06402015686035156, 0.13638359308242798, 0.15165682137012482, 0.033545009791851044, 0.009394458495080471, -0.036349818110466, -0.02850295789539814, 0.10190583765506744, 0.01667015813291073, -0.04096753150224686, 0.03264811635017395, -0.13409912586212158, -0.0495043583214283, 0.07888787239789963, 0.21497410535812378, 0.019663382321596146, 0.04055612161755562, 0.008944111876189709, -0.06266126781702042, -0.020653504878282547, 0.04474937170743942, 0.15221218764781952, 0.15637382864952087, -0.04006792604923248, -0.059369247406721115, 0.026381777599453926, -0.08980406820774078, -0.02158355712890625, 0.16636036336421967, -0.1124916598200798, -0.0024256661999970675, -0.08018279075622559, 0.05339610576629639, 0.013560572639107704, 0.10772833228111267, -0.13109992444515228, 0.012499325908720493, -0.07663669437170029, 0.031860947608947754, 0.02043447457253933, 0.14489014446735382, 0.03849343582987785, 0.06279192864894867, -0.013773227110505104, -0.022956032305955887, 0.08935017138719559, -0.09911016374826431, 0.0008712740964256227, 0.04240073263645172, -0.07362709939479828, 0.019232314079999924, 0.020896198228001595, -0.1663869172334671, 6.798504638759317e-33, -0.04326009377837181, 0.03058176301419735, -0.008557887747883797, -0.07209382951259613, -0.02651107870042324, -0.0005528834881260991, 0.15893219411373138, 0.034171611070632935, 0.10445987433195114, 0.08601196855306625, -0.19412854313850403, 0.023592766374349594, -0.12918026745319366, -0.009567514061927795, 0.11825116723775864, -0.006655036937445402, 0.008515206165611744, 0.11351482570171356, -0.11744315177202225, -0.09016051143407822, 0.17466594278812408, -0.0846836194396019, 0.057061441242694855, -0.08390610665082932, -0.026299210265278816, -0.09225956350564957, 0.07833162695169449, 0.016839120537042618, -0.08915071189403534, -0.01532356720417738, -0.01600339636206627, 0.0905526652932167, -0.12761034071445465, 0.03902576491236687, 0.034554824233055115, -0.07006131857633591, 0.03731589391827583, 0.09175936132669449, 0.060564227402210236, -0.059093866497278214, -0.1155172660946846, -0.03232146427035332, 0.07865146547555923, 0.09841331839561462, -0.008823622949421406, -0.08709069341421127, 0.02475632168352604, 0.06212231144309044, -0.04557396098971367, 0.12852974236011505, -0.09363687038421631, 0.03015512228012085, 0.046953149139881134, -0.011523254215717316, -0.04499037563800812, 0.12303825467824936, 0.02489328756928444, 0.05371331796050072, -0.017040256410837173, 0.14713864028453827, -0.061716657131910324, -0.1617356389760971, -0.011471516452729702, 0.02288670837879181, 0.1377222239971161, 0.09403873980045319, 0.027963843196630478, 0.008884000591933727, 0.15573592483997345, -0.024263950064778328, 0.0283780787140131, -0.11128497868776321, 0.024559900164604187, -0.12866517901420593, 0.04987023025751114, -0.08745281398296356, 0.1763371229171753, 0.07476530224084854, -0.07978597283363342, -0.059599608182907104, -0.04573998227715492, 0.22428759932518005, 0.04676709324121475, -0.028705086559057236, 0.06719914823770523, -0.027107173576951027, 0.006204709410667419, -0.09103962779045105, -0.19277682900428772, -0.13814210891723633, -0.09497106075286865, 0.09755735844373703, 0.013535169884562492, -0.08824032545089722, -0.020935848355293274, -3.731322126647262e-33, 0.0775681585073471, -0.11837165057659149, 0.07652882486581802, 0.09205127507448196, 0.09629204124212265, 0.052419889718294144, -0.08030802011489868, -0.14585888385772705, -0.058854907751083374, -0.09381771832704544, 0.02541654370725155, 0.051535896956920624, 0.1514478176832199, 0.007885107770562172, -0.01102993730455637, 0.08918013423681259, -0.06987821310758591, 0.05950376018881798, 0.009350141510367393, 0.05539211630821228, -0.01770283840596676, 0.13220828771591187, -0.13540083169937134, -0.027593784034252167, -0.15284813940525055, 0.05785461515188217, -0.009608578868210316, 0.10271389782428741, 0.03627506643533707, 0.07720045745372772, -0.08269836753606796, 0.09717189520597458, -0.2199338674545288, 0.044932957738637924, -0.00032595446100458503, -0.08617662638425827, 0.040975574404001236, 0.00803769938647747, -0.06063785031437874, 0.13291746377944946, 0.061863973736763, 0.05145861208438873, -0.1210763230919838, -0.06031101569533348, -0.01787402294576168, 0.03029654361307621, 0.0026317392475903034, -0.13064256310462952, 0.06880208849906921, 0.06276590377092361, 0.07996197789907455, -0.06498803198337555, -0.03788181021809578, 0.12787310779094696, 0.004966746084392071, 0.0005562040605582297, -0.18301169574260712, 0.06897946447134018, 0.053466927260160446, -0.084276482462883, -0.0739247277379036, 0.03932711109519005, 0.04581821337342262, 0.021208107471466064, 0.041406940668821335, 0.10282441973686218, 0.004118173383176327, -0.04522774741053581, -0.08647812902927399, 0.08326061069965363, -0.05538446828722954, 0.0070102280005812645, 0.08565640449523926, 0.023005230352282524, -0.10649488121271133, 0.0879865512251854, 0.03664509952068329, -0.07715247571468353, 0.060795266181230545, -0.07953935116529465, -0.0813632383942604, 0.06845545023679733, -0.0005755434976890683, 0.1367826610803604, -0.008563392795622349, 0.09223146736621857, 0.08443361520767212, 0.09947677701711655, 0.09107474237680435, -0.018932821229100227, 0.05249260738492012, 0.035235706716775894, 0.13882265985012054, 0.1041746735572815, -0.030750803649425507, -9.887640572969758e-08, -0.008981487713754177, 0.1869409680366516, -0.01660660281777382, -0.06446421891450882, 0.20540392398834229, -0.05435294657945633, -0.023048365488648415, 0.09603382647037506, -0.03870834410190582, 0.04847390204668045, 0.16104719042778015, 0.04518899694085121, 0.013004524633288383, 0.09839938580989838, -0.05544871464371681, -0.0348239466547966, -0.08436919003725052, -0.06807272881269455, -0.028241131454706192, 0.09169626981019974, -0.0022141088265925646, -0.04969634488224983, -0.031209178268909454, 0.05234126001596451, 0.20978933572769165, -0.08986784517765045, 0.04743671417236328, -0.02228943072259426, 0.09224316477775574, 0.16702251136302948, -0.037014905363321304, -0.12528309226036072, 0.02514978125691414, 0.02037302777171135, 0.059750135987997055, 0.0945654809474945, -0.10227827727794647, -0.09036491811275482, -0.09073808789253235, 0.011748511344194412, 0.017534373328089714, 0.014306299388408661, 0.007463098503649235, -0.057842932641506195, 0.03575093299150467, -0.07054227590560913, -0.11062823235988617, 0.021186163648962975, 0.06236613914370537, -0.017576051875948906, -0.013804464600980282, -0.04898744821548462, -0.07966680824756622, 0.02207438088953495, -0.015797851607203484, -0.01929834857583046, -0.0894872397184372, -0.006622416898608208, 0.0736805647611618, 0.0772051215171814, 0.060784801840782166, -0.10000084340572357, -0.12362470477819443, 0.050629012286663055], metadata={'source': 'AAAMLP-569to.pdf', 'page': 167}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 168                 best_parameters[\"b\"] = b                 best_parameters[\"c\"] = c ═════════════════════════════════════════════════════════════════════════  In the above code, we go through all the parameters from 1 to 10. So, we have a total of 1000 (10 x 10 x 10) fits for the model. Well, that might be expensive because the model can take a long time to train. In this situation, it should, however, be okay, but in a real-world scenario, there are not only three parameters and not only ten values for each parameter. Most models parameters are real-valued, and the combinations of different parameters can be infinite.  Let’s look at the random forest model from scikit-learn.  RandomForestClassifier(     n_estimators=100,     criterion=\\'gini\\',     max_depth=None,     min_samples_split=2,     min_samples_leaf=1,     min_weight_fraction_leaf=0.0,     max_features=\\'auto\\',     max_leaf_nodes=None,     min_impurity_decrease=0.0,     min_impurity_split=None,     bootstrap=True,     oob_score=False,     n_jobs=None,     random_state=None,     verbose=0,     warm_start=False,     class_weight=None,     ccp_alpha=0.0,     max_samples=None, )  There are nineteen parameters, and all the combinations of all these parameters for all the values they can assume are going to be infinite. Normally, we don’t have the resource and time to do this. Thus, we specify a grid of parameters. A search over this grid to find the best combination of parameters is known as grid search. We can say that n_estimators can be 100, 200, 250, 300, 400, 500; max_depth can be 1, 2, 5, 7, 11, 15 and criterion can be gini or entropy. These may not look like a lot of parameters, but it would take a lot of time for computation if the dataset is too large. We can make this grid search work by creating three for loops like before and'),\n",
       " VectorParams(vector=[-0.09263517707586288, 0.09219104796648026, -0.09668473154306412, 0.04313257336616516, 0.05909246578812599, 0.0002629896916914731, -0.03265182673931122, 0.06051452457904816, -0.043348368257284164, -0.08504662662744522, -0.06716101616621017, -0.16351288557052612, 0.10317253321409225, -0.06681635230779648, -0.04001041129231453, -0.07183320820331573, 0.035232461988925934, 0.012127717956900597, -0.0725526213645935, -0.0348547026515007, 0.016547800973057747, 0.03285415470600128, 0.08098345994949341, -0.06465021520853043, 0.10391169041395187, -0.11029887199401855, 0.004545086063444614, 0.07298552244901657, -0.08245400339365005, 0.06946951895952225, 0.044288575649261475, 0.06044681370258331, -0.022804085165262222, 0.08601474016904831, 0.05224921926856041, -0.10132785141468048, -0.10028019547462463, 0.029978837817907333, 0.007865888997912407, 0.047227054834365845, -0.018072208389639854, -0.0806439146399498, -0.06873822957277298, 0.0168939009308815, 0.10095217078924179, 0.0853058248758316, -0.03121905028820038, 0.025884486734867096, 0.016640115529298782, -0.011849720031023026, -0.11067488044500351, 0.09154361486434937, -0.10765987634658813, -0.01513227540999651, -0.14130671322345734, -0.10648997128009796, -0.04685087502002716, -0.02561754733324051, 0.24106651544570923, -0.07637669891119003, 0.03032892383635044, -0.15153953433036804, -0.09561046212911606, 0.006320515647530556, -0.015128927305340767, -0.12018860131502151, -0.08839365839958191, -0.07820428907871246, 0.012238078750669956, -0.06560603529214859, 0.03029921092092991, 0.0869184210896492, 0.03824496269226074, 0.05092605575919151, -0.01953519880771637, 0.06706489622592926, 0.18080462515354156, -0.06637576222419739, -0.02561156637966633, -0.007104123011231422, -0.04343177378177643, -0.039697326719760895, -0.06699544191360474, 0.038624200969934464, 0.13921700417995453, -0.10883519053459167, 0.020488720387220383, 0.150923490524292, -0.019176090136170387, -0.07238147407770157, 0.20066316425800323, 0.05996567755937576, -0.06746911257505417, 0.04660326614975929, -0.07513713836669922, 0.21783088147640228, 0.01080684270709753, -0.16732151806354523, -0.020263805985450745, 0.10940724611282349, -0.04805336520075798, 0.03321966156363487, 0.06826920807361603, -0.041301630437374115, 0.10712212324142456, -0.010816874913871288, 0.09711897373199463, 0.07727321982383728, 0.1152694970369339, -0.1372675597667694, 0.014171578921377659, -0.15092943608760834, -0.10541464388370514, -0.042660146951675415, 0.08929787576198578, 0.09065397828817368, 0.06208530440926552, -0.04623173549771309, -0.01894470676779747, 0.16105680167675018, -0.09071476012468338, -0.09472766518592834, -0.01345770712941885, -0.09557440876960754, 0.03827379643917084, 0.07212262600660324, -0.10611769556999207, 9.882033501845509e-33, -0.11316872388124466, 0.037578921765089035, 0.08463601768016815, -0.07545585930347443, -0.056717876344919205, -0.07099734991788864, 0.10782553255558014, 0.015428582206368446, 0.09366434812545776, 0.18249961733818054, -0.1773594319820404, 0.10855119675397873, -0.07860983163118362, -0.010947547852993011, 0.15356336534023285, 0.02044297382235527, -0.02190018631517887, -0.1065438911318779, 0.05346457287669182, 0.058050040155649185, 0.18654058873653412, -0.11378618329763412, 0.07699266821146011, -0.0696352943778038, 0.0006134388968348503, 0.01970387063920498, 0.03369472175836563, 0.006656198762357235, 0.05177660286426544, 0.01701807603240013, -0.10438639670610428, 0.035472527146339417, -0.029824987053871155, 0.0065520028583705425, -0.05753154307603836, -0.048026494681835175, -0.055931247770786285, -0.028141841292381287, -0.010666661895811558, 0.023098278790712357, -0.1812121421098709, 0.002474177861586213, -0.013969690538942814, 0.02965955249965191, -0.03914567083120346, 0.0021151562687009573, -0.035827167332172394, -0.0007035503513179719, 0.013083082623779774, 0.1995287835597992, -0.06586170941591263, 0.020335039123892784, -0.08800310641527176, -0.030088404193520546, -0.17551633715629578, 0.14263084530830383, 0.018809722736477852, -0.031644608825445175, 0.08214123547077179, -0.01716836541891098, 0.013463244773447514, -0.15027470886707306, 0.022237636148929596, 0.02426973544061184, -0.017649756744503975, -0.0589289590716362, 0.0693759098649025, -0.0700000673532486, -0.05312128737568855, 0.07042407989501953, 0.03127596899867058, -0.06618007272481918, 0.08906631171703339, -0.09674269706010818, 0.1366293579339981, -0.0521688237786293, 0.09806260466575623, 0.08887645602226257, -0.08051422238349915, -0.04222777113318443, 0.037478599697351456, 0.09901268780231476, 0.015997106209397316, -0.12081092596054077, 0.11302179843187332, -0.0659303218126297, -0.04501771926879883, -0.15481792390346527, -0.14172233641147614, -0.005246627144515514, -0.2636560797691345, 0.17222626507282257, -0.10836635529994965, -0.0642731562256813, -0.015537003055214882, -9.578174824313671e-33, 0.03836553171277046, 0.07568339258432388, 0.06893347948789597, 0.04557294026017189, 0.030862033367156982, 0.0026457407511770725, -0.10093880444765091, 0.02049812488257885, -0.12257472425699234, -0.09130704402923584, -0.0019522400107234716, 0.05228064954280853, 0.1252523958683014, -0.00793282687664032, -0.07216943055391312, 0.1468225121498108, -0.1443791687488556, 0.0328441858291626, 0.0760001614689827, 0.059883419424295425, -0.08301873505115509, 0.1455783247947693, -0.1496122181415558, 0.17421558499336243, -0.1528458446264267, -0.03868383169174194, 0.021033309400081635, -0.010350694879889488, -0.011178075335919857, -0.02334701269865036, -0.11155590415000916, 0.016116131097078323, 0.005492743104696274, 0.05831529572606087, 0.02457844838500023, 0.034300483763217926, 0.024392250925302505, -0.060979291796684265, 0.030646586790680885, 0.2831916809082031, 0.13718068599700928, 0.1020897850394249, -0.11614831537008286, -0.07664340734481812, 0.003384257201105356, -0.07227391004562378, -0.02420155145227909, 0.053197793662548065, 0.05219747871160507, -0.07727056741714478, 0.11458678543567657, 0.11795499175786972, -0.14745748043060303, 0.0625196099281311, -0.004344205837696791, 0.10893681645393372, -0.03278515115380287, -0.02513333596289158, -0.06238563731312752, -0.0892651304602623, -0.03852653503417969, -0.0018119397573173046, -0.020930666476488113, 0.1291012316942215, 0.05440696328878403, 0.03267747163772583, 0.010366866365075111, -0.08501990139484406, 0.009132512845098972, -0.00022839743178337812, -0.18702226877212524, -0.05039314553141594, 0.06730039417743683, -0.08610555529594421, -0.0912448912858963, -0.03473730385303497, 0.010130947455763817, 0.028792934492230415, 0.05874473229050636, -0.03508787602186203, 0.038148608058691025, 0.14823582768440247, 0.0051981424912810326, -0.0006611876888200641, -0.034876544028520584, -0.0031898468732833862, 0.1488930881023407, 0.021453870460391045, -0.02407677099108696, -0.03987835347652435, -0.04583340510725975, -0.001528761931695044, 0.03321605548262596, 0.06552762538194656, -0.09390464425086975, -9.98786262584872e-08, 0.018205158412456512, 0.16120724380016327, 0.041643936187028885, 0.02183563821017742, -0.005386668723076582, -0.013871130533516407, -0.006044154521077871, 0.010227922350168228, 0.013840489089488983, 0.09282074868679047, 0.16568028926849365, -0.03413579240441322, -0.0952247828245163, 0.16382715106010437, -0.02659529820084572, 0.07147292047739029, 0.02190602943301201, 0.10342898964881897, -0.03781203180551529, 0.23066100478172302, 0.163731649518013, 0.073604054749012, 0.04342670366168022, 0.12606601417064667, 0.19871002435684204, 0.03557635471224785, -0.17128664255142212, -0.009206402115523815, 0.04854399710893631, 0.10135503113269806, -0.042308419942855835, -0.11491130292415619, 0.07181064039468765, -0.012929071672260761, 0.0015963554615154862, 0.1551153063774109, -0.06752052903175354, -0.14504937827587128, -0.0026563440915197134, 0.073942169547081, 0.005345288664102554, -0.03257134184241295, -0.1251039057970047, -0.11238134652376175, -0.023932069540023804, -0.060301292687654495, -0.01424422673881054, -0.014941060915589333, 0.067511186003685, 0.0766405239701271, -0.015611318871378899, -0.040966108441352844, -0.1288166344165802, -0.0993545651435852, 0.0991528332233429, -0.10819588601589203, -0.1332736611366272, 0.022994045168161392, 0.04027324542403221, -0.07931085675954819, 0.07337798178195953, -0.07989957928657532, -0.11546754091978073, -0.014162982814013958], metadata={'source': 'AAAMLP-569to.pdf', 'page': 168}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 169 calculating the score on the validation set. It must also be noted that if you have k-fold cross-validation, you need even more loops which implies even more time to find the perfect parameters. Grid search is therefore not very popular. Let’s look at how it’s done with an example of predicting mobile phone price range given the specifications.  \\n Figure 1: A snapshot of the mobile price dataset7  We have 20 features like dual sim, battery power, etc. and a range of price which has 4 categories from 0 to 3. There are only 2000 samples in the training set. We can easily use stratified kfold and accuracy as a metric to evaluate. We will use a random forest model with the aforementioned parameter ranges and see how we can do a grid search in the following example.  ═════════════════════════════════════════════════════════════════════════ # rf_grid_search.py import numpy as np import pandas as pd  from sklearn import ensemble from sklearn import metrics from sklearn import model_selection  if __name__ == \"__main__\":     # read the training data     df = pd.read_csv(\"../input/mobile_train.csv\")      # features are all columns without price_range     # note that there is no id column in this dataset  7 https://www.kaggle.com/iabhishekofficial/mobile-price-classification'),\n",
       " VectorParams(vector=[-0.06482729315757751, -0.009652245789766312, -0.06867845356464386, 0.07708662003278732, 0.13763143122196198, -0.07356809824705124, 0.01816345378756523, 0.06541059166193008, -0.1295536756515503, -0.01920207589864731, -0.1161167100071907, -0.05736030265688896, 0.0264113899320364, -0.07249505817890167, -0.020610859617590904, -0.010742264799773693, -1.5516568964812905e-05, 0.010269052349030972, -0.07916217297315598, -0.07351698726415634, 0.17209428548812866, 0.06601770222187042, -0.01557216327637434, 0.007247363217175007, 0.009173359721899033, -0.10433521121740341, -0.032710961997509, 0.10449022054672241, -0.12624366581439972, 0.015066711232066154, -0.06973854452371597, -0.015105713158845901, -0.002132243709638715, 0.14344589412212372, 0.024563243612647057, 0.05399303883314133, -0.06356397271156311, -0.027659643441438675, 0.01740688644349575, 0.06712444126605988, -0.011408953927457333, 0.005635175388306379, -0.08497064560651779, -0.06344638764858246, 0.06883365660905838, 0.05744747444987297, -0.0812513455748558, -0.03822355344891548, 0.048467349261045456, 0.0181232001632452, -0.15329138934612274, 0.02006891928613186, -0.10214081406593323, -0.09339329600334167, -0.005650235805660486, -0.053028929978609085, 0.02238631621003151, -0.17566870152950287, 0.1129799485206604, -0.1714118868112564, 0.010345833376049995, -0.1439286470413208, -0.03975796699523926, -0.038320112973451614, 0.017062706872820854, -0.17836546897888184, -0.008108939044177532, 0.03671763464808464, -0.05972394347190857, 0.031191201880574226, 0.01063727866858244, 0.08161287754774094, -0.018185898661613464, 0.0134024228900671, -0.01392339263111353, 0.03174525126814842, 0.1279066950082779, -0.0316486582159996, 0.059762608259916306, -0.03486373648047447, -0.12556520104408264, 0.039518117904663086, 0.006257276050746441, 0.052700575441122055, 0.025359779596328735, -0.1216248869895935, 0.06142924726009369, 0.025618791580200195, 0.15205782651901245, -0.04891599714756012, 0.1176522746682167, -0.05218930169939995, -0.07117797434329987, 0.0834454596042633, 0.06865686178207397, 0.1462976634502411, 0.16646507382392883, -0.10402477532625198, -0.016322681680321693, 0.08853258937597275, -0.11758708953857422, -0.05223424732685089, 0.08387485146522522, -0.13844433426856995, 0.05446620285511017, -0.05069640651345253, 0.059225548058748245, 0.054793741554021835, 0.11213365197181702, -0.09631090611219406, -0.07736284285783768, -0.042208652943372726, -0.1224074736237526, 0.0715043768286705, 0.14546118676662445, 0.10419531911611557, 0.011053292080760002, 0.02956412546336651, -0.09607341885566711, 0.04046691954135895, -0.10110781341791153, 0.038055311888456345, 0.010246706195175648, 0.053058430552482605, 0.03452243655920029, 0.026308683678507805, -0.09453365951776505, 8.753915246781206e-33, -0.007677697576582432, -0.027429262176156044, 0.02472727559506893, -0.08524755388498306, 0.03731134161353111, 0.025275656953454018, 0.11922969669103622, 0.01283977273851633, 0.03681470826268196, 0.1597985029220581, -0.27230048179626465, 0.09978089481592178, -0.06223985552787781, 0.018251193687319756, 0.044681284576654434, -0.009297939948737621, -0.05241495743393898, 0.07217694073915482, -0.09451571851968765, 0.06511580944061279, 0.27250903844833374, -0.034091055393218994, -0.007501778658479452, -0.09150998294353485, -0.10257230699062347, -0.027605947107076645, -0.028258731588721275, -0.022921856492757797, -0.11924844235181808, 0.022022558376193047, -0.17709887027740479, -0.004266898147761822, 0.031148549169301987, -0.06097906082868576, 0.030016016215085983, -0.1187102422118187, 0.02956690452992916, 0.09855417162179947, -0.056729353964328766, -0.1119941845536232, -0.03256351873278618, -0.018405063077807426, 0.02434787154197693, -0.03167824447154999, -0.04277922585606575, 0.04257744550704956, -0.05906872823834419, 0.03917567431926727, 0.05046338587999344, 0.1606636643409729, -0.0824013352394104, -0.05921097472310066, 0.06473009288311005, -0.0012940835440531373, -0.12701092660427094, 0.1362936794757843, 0.08426780998706818, 0.08738600462675095, 0.0671440064907074, -0.040883809328079224, -0.044065460562705994, -0.14307105541229248, 0.015377662144601345, -0.025406520813703537, 0.13240964710712433, 0.03608288615942001, 0.12061513215303421, 0.042358025908470154, 0.08000526577234268, 0.025497552007436752, -0.0891537219285965, 0.010454113595187664, -0.06389887630939484, -0.08990202099084854, 0.05047435313463211, -0.0874863713979721, 0.11816875636577606, 0.10316360741853714, -0.02406684122979641, -0.07954572886228561, 0.006273178383708, 0.22060056030750275, -0.06955300271511078, -0.1662885695695877, 0.02515399642288685, 0.026679275557398796, 0.023451868444681168, -0.0693504586815834, -0.17462974786758423, -0.10336766391992569, -0.17262105643749237, 0.06146397441625595, 0.034821752458810806, -0.05883021280169487, -0.025963202118873596, -8.752525959395328e-33, 0.008938047103583813, 0.01689828746020794, 0.1018228530883789, 0.11243343353271484, 0.06140874698758125, 0.06871247291564941, -0.0043653217144310474, -0.019289592280983925, -0.07041371613740921, -0.11238248646259308, -0.005678015761077404, -0.05486379191279411, 0.11529677361249924, 0.075375996530056, 0.02297159843146801, 0.08330628275871277, -0.09894028306007385, 0.03893182799220085, -0.061240389943122864, 0.02823503129184246, -0.062052272260189056, 0.08995512872934341, -0.08904450386762619, 0.014516737312078476, -0.08922430127859116, 0.004205567762255669, 0.037644799798727036, 0.09016772359609604, 0.006327248644083738, -0.08438995480537415, 0.028223883360624313, 0.14549235999584198, -0.1033015251159668, 0.0744381994009018, 0.021047573536634445, -0.09410231560468674, -0.0016343400347977877, -0.16439323127269745, -0.07282532006502151, 0.21301712095737457, 0.11575111746788025, 0.10225032269954681, -0.14059853553771973, 0.0031419843435287476, 0.0041491249576210976, 0.011923681944608688, 0.006827265955507755, -0.04467359557747841, 0.05089699476957321, 0.015184024348855019, 0.052377849817276, -0.10098302364349365, -0.16806404292583466, 0.153156116604805, -0.04621589556336403, 0.040621694177389145, -0.10877853631973267, 0.021374089643359184, -0.0031463124323636293, -0.010672294534742832, -0.06348863244056702, 0.04647621884942055, -0.03184710815548897, 0.09848367422819138, 0.10372152924537659, 0.031482938677072525, -0.037242598831653595, -0.054535798728466034, -0.013776615262031555, 0.09941219538450241, -0.11803662776947021, -0.03352169692516327, 0.11046706885099411, -0.05323540419340134, -0.08617589622735977, 0.015552057884633541, -0.009672034531831741, -0.004194088280200958, 0.022577587515115738, 0.014071062207221985, -0.014849638566374779, 0.04169110581278801, 0.010826350189745426, 0.15067805349826813, -0.043536096811294556, 0.03820650652050972, 0.1523767113685608, 0.14607760310173035, -0.022876951843500137, -0.056217875331640244, 0.05347691476345062, -0.061936113983392715, 0.06448693573474884, 0.1734878122806549, -0.039067331701517105, -1.0003418537962716e-07, -0.07851658016443253, 0.19579501450061798, -0.0039006418082863092, 0.057524699717760086, 0.0889827236533165, -0.03931712359189987, 0.005640868097543716, 0.040982939302921295, -0.04810027405619621, 0.02991274930536747, 0.14877577126026154, -0.021026059985160828, -0.08266548067331314, 0.08408449590206146, 0.013726891949772835, -0.0006443386664614081, -0.09505937993526459, 0.06618185341358185, -0.0315852165222168, 0.09894276410341263, 0.08456914871931076, -0.10595707595348358, 0.04082098975777626, 0.03764953836798668, 0.13037653267383575, -0.08271121978759766, -0.013270815834403038, 0.049075059592723846, 0.06595087051391602, 0.10902726650238037, -0.0535435788333416, -0.06125621870160103, 0.09249939024448395, -0.005842589307576418, -0.014031903818249702, 0.14180885255336761, -0.07729189097881317, -0.06277944892644882, 0.001529364031739533, 0.16305559873580933, -0.0776367336511612, 0.008794130757451057, -0.0904722809791565, -0.09761559218168259, 0.011593557894229889, 0.0022047655656933784, 0.01787704974412918, -0.005760429427027702, 0.11470235139131546, -0.01089728157967329, -0.061131592839956284, -0.012014399282634258, -0.04571318253874779, 0.0042702630162239075, 0.014242583885788918, -0.019613688811659813, -0.12783695757389069, 0.03047632984817028, 0.04812069609761238, -0.05731275677680969, 0.0568200945854187, -0.14950576424598694, -0.10247073322534561, 0.04799458757042885], metadata={'source': 'AAAMLP-569to.pdf', 'page': 169}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 170     # here we have training features     X = df.drop(\"price_range\", axis=1).values     # and the targets     y = df.price_range.values      # define the model here     # i am using random forest with n_jobs=-1     # n_jobs=-1 => use all cores     classifier = ensemble.RandomForestClassifier(n_jobs=-1)      # define a grid of parameters     # this can be a dictionary or a list of     # dictionaries     param_grid = {         \"n_estimators\": [100, 200, 250, 300, 400, 500],         \"max_depth\": [1, 2, 5, 7, 11, 15],         \"criterion\": [\"gini\", \"entropy\"]     }          # initialize grid search     # estimator is the model that we have defined     # param_grid is the grid of parameters     # we use accuracy as our metric. you can define your own     # higher value of verbose implies a lot of details are printed     # cv=5 means that we are using 5 fold cv (not stratified)     model = model_selection.GridSearchCV(         estimator=classifier,          param_grid=param_grid,          scoring=\"accuracy\",         verbose=10,          n_jobs=1,         cv=5     )      # fit the model and extract best score     model.fit(X, y)     print(f\"Best score: {model.best_score_}\")      print(\"Best parameters set:\")     best_parameters = model.best_estimator_.get_params()     for param_name in sorted(param_grid.keys()):      print(f\"\\\\t{param_name}: {best_parameters[param_name]}\") ═════════════════════════════════════════════════════════════════════════  This prints a lot of stuff, let’s look at the last few lines.'),\n",
       " VectorParams(vector=[-0.0922422930598259, -0.013239654712378979, -0.07913575321435928, 0.027591869235038757, 0.15755924582481384, -0.0909503847360611, -0.044760480523109436, 0.018836425617337227, 0.03154131770133972, 0.009605051949620247, -0.1620081067085266, -0.1690884828567505, 0.07964206486940384, -0.031068887561559677, -0.08383315801620483, -0.0879455953836441, 0.10420715808868408, 0.011785624548792839, -0.13165056705474854, 0.025124285370111465, 0.10102731734514236, -0.007054096087813377, 0.024814952164888382, -0.11718285828828812, -0.03230883181095123, -0.029348377138376236, -0.08076311647891998, 0.008539119735360146, -0.2007823884487152, -0.038749612867832184, -0.016960106790065765, -0.028066027909517288, 0.04787871986627579, 0.11459715664386749, 0.010527628473937511, 0.05296711251139641, -0.13962732255458832, -0.06015942990779877, 0.01837216503918171, 0.1088440865278244, -0.11672451347112656, 0.020875783637166023, -0.012096709571778774, -0.036780521273612976, 0.19202165305614471, 0.13729828596115112, -0.1943187713623047, -0.19298318028450012, 0.04119470715522766, 0.07553339749574661, -0.17492783069610596, 0.07990799844264984, -0.052413806319236755, -0.06383964419364929, 0.011583236046135426, -0.022995896637439728, -0.020102158188819885, -0.20870238542556763, 0.0005623705219477415, -0.05129837989807129, 0.03733246773481369, -0.11928302049636841, -0.10283215343952179, 0.045230716466903687, 0.08764199912548065, -0.17400752007961273, -0.0064253248274326324, -0.10937795042991638, -0.029384098947048187, -0.02309362031519413, -0.07455015182495117, 0.09929199516773224, -0.12253653258085251, 0.08402641862630844, 0.01630941778421402, 0.09541060030460358, 0.15429624915122986, -0.0577942356467247, 0.04353073239326477, -0.11711211502552032, -0.06024938449263573, 0.11906418204307556, -0.008090549148619175, 0.03372161090373993, 0.1157846450805664, -0.09482673555612564, 0.1005566269159317, 0.12855038046836853, 0.2359447032213211, 0.007185951806604862, 0.09903904050588608, -0.05744675546884537, -0.06295916438102722, 0.06939052045345306, 0.14108961820602417, 0.1789143830537796, 0.04990820214152336, -0.04216691479086876, -0.02877219021320343, -0.005878036841750145, -0.052179478108882904, 0.016476940363645554, 0.09060529619455338, -0.13197174668312073, 0.13185545802116394, 0.04506414383649826, 0.21733573079109192, 0.17158907651901245, 0.08590951561927795, -0.17575466632843018, -0.0031370273791253567, 0.07251571118831635, -0.01500475499778986, -0.051855843514204025, 0.16715842485427856, 0.2360324114561081, 0.04453311860561371, 0.05071210861206055, 0.01353698130697012, 0.18250346183776855, -0.00018681026995182037, 0.01747759059071541, 0.10705544054508209, -0.04681466519832611, -0.03371332958340645, -0.05211114138364792, -0.021842975169420242, 4.174049666023414e-33, -0.11522556096315384, 0.055670734494924545, 0.018995219841599464, -0.1655369997024536, -0.04602887108922005, 0.04791172593832016, 0.11613032221794128, 0.07885465025901794, -0.004756817128509283, 0.04579514265060425, -0.3215351104736328, 0.09407012164592743, -0.14857950806617737, 0.05012049525976181, 0.09514573216438293, 0.04243458807468414, 0.025667566806077957, 0.07218944281339645, -0.1582426279783249, -0.0849662646651268, 0.3058808445930481, -0.12159542739391327, 0.1465485543012619, -0.08156929910182953, -0.02889437787234783, -0.060091905295848846, 0.002788033802062273, -0.0851421058177948, -0.1278381049633026, 0.008658808656036854, -0.019897807389497757, 0.03842952102422714, -0.05869477614760399, 0.0172576867043972, 0.09793966263532639, 0.008149463683366776, 0.022386915981769562, 0.16252398490905762, 0.019603531807661057, 0.06043894216418266, -0.13039788603782654, 0.016117995604872704, 0.0371476486325264, -0.050129540264606476, -0.10076707601547241, -0.09907910227775574, -0.13302099704742432, 0.0946604460477829, -0.01743233948945999, 0.1756131798028946, 0.040198441594839096, -0.02768617868423462, -0.01026932056993246, -0.07423096150159836, -0.09531328082084656, 0.1788671612739563, 0.12690086662769318, 0.11116378754377365, 0.00714114960283041, 0.11577868461608887, -0.0857950747013092, -0.11474837362766266, 0.018406525254249573, -0.09470650553703308, 0.08317582309246063, 0.03270278871059418, 0.10498419404029846, 0.02548149600625038, 0.19313135743141174, -0.035970140248537064, -0.08747881650924683, -0.03433194011449814, 0.03509259223937988, -0.0840231329202652, 0.09294188022613525, -0.12467847764492035, 0.08694002032279968, 0.08982060849666595, -0.04657067358493805, -0.032464560121297836, -0.05251847952604294, 0.2442759871482849, -0.12265129387378693, -0.2641178071498871, 0.06583152711391449, 0.011467521078884602, 0.09070122241973877, -0.09844507277011871, -0.29033589363098145, -0.10824265331029892, -0.15329445898532867, 0.08099374175071716, 0.14817193150520325, -0.12380310893058777, -0.12273207306861877, -4.01978439957722e-33, -0.020976586267352104, -0.07833009958267212, 0.029447592794895172, 0.15138152241706848, 0.0445975624024868, -0.1167621836066246, -0.031830232590436935, -0.02174438163638115, -0.19064536690711975, -0.08442732691764832, 0.026746394112706184, -0.12000122666358948, 0.17226994037628174, 0.05652659013867378, -0.01862945780158043, 0.17546339333057404, -0.046613797545433044, 0.06325925141572952, -0.070637047290802, 0.12635667622089386, 0.046850480139255524, 0.21962009370326996, -0.12399744242429733, -0.003551770932972431, -0.12761732935905457, 0.0447114035487175, 0.04483439773321152, 0.04651609808206558, 0.04782992973923683, -0.07682623714208603, -0.08023981750011444, 0.08806189894676208, -0.2005520761013031, 0.16038167476654053, 0.07842577993869781, -0.0433989092707634, -0.0036641773767769337, -0.08097808808088303, -0.06193368881940842, 0.13777703046798706, 0.1312747597694397, 0.13539287447929382, -0.22895166277885437, -0.16544868052005768, -0.03435943275690079, 0.052340805530548096, -0.03853783383965492, -0.04309761896729469, 0.044925957918167114, 0.00533926859498024, 0.011152468621730804, -0.12802401185035706, -0.18966692686080933, 0.2504485845565796, 0.00873835850507021, 0.026747513562440872, -0.1655048429965973, 0.06345798075199127, 0.0685347393155098, -0.036629997193813324, -0.025844834744930267, 0.09336275607347488, -0.021428745239973068, 0.0816618949174881, 0.21866102516651154, 0.2023027539253235, -0.04915225878357887, -0.10006459057331085, -0.11532709002494812, 0.10184317827224731, -0.24522528052330017, 0.06623029708862305, 0.09546221792697906, -0.0778660997748375, -0.0448484867811203, 0.05958548188209534, 0.07613489031791687, 0.03577880188822746, -0.019138626754283905, -0.06100950017571449, -0.062031254172325134, -0.03363250195980072, -0.02278806082904339, 0.09005039930343628, -0.1057438775897026, 0.13206106424331665, 0.12568266689777374, -0.01617453061044216, 0.021094033494591713, -0.08578246086835861, 0.02609912119805813, 0.05742241442203522, 0.16588369011878967, 0.07775334268808365, -0.013367120176553726, -9.934115041687619e-08, 0.09024284034967422, 0.1253378540277481, 0.03974148631095886, -0.03210530802607536, 0.15494444966316223, 0.007898800075054169, -0.08947746455669403, -0.022665809839963913, -0.11856457591056824, -0.09226840734481812, 0.2805345356464386, 0.031169462949037552, 0.03264058008790016, 0.09539750963449478, 0.0001992334146052599, -0.056621842086315155, -0.13420388102531433, 0.06135332211852074, 0.012377471663057804, 0.026206694543361664, 0.051928043365478516, -0.008790148422122002, -0.0287459809333086, 0.04529657959938049, 0.10189386457204819, -0.027846436947584152, -0.019304713234305382, -0.08709154278039932, 0.07149332016706467, -0.038647133857011795, -0.01250655297189951, -0.09099733084440231, 0.08063140511512756, -0.05811164528131485, 0.020459644496440887, 0.07881039381027222, -0.029229700565338135, -0.11963598430156708, -0.027825046330690384, 0.182013601064682, 0.03507339954376221, 0.06374721229076385, 0.029627600684762, -0.14143779873847961, 0.13642629981040955, -0.05868227779865265, 0.040251053869724274, -0.005380096845328808, 0.0627778172492981, -0.03948815539479256, -0.01751955784857273, -0.1549474000930786, -0.032349321991205215, -0.019671153277158737, 0.1178894191980362, -0.0335564948618412, -0.06976927816867828, -0.05364454165101051, 0.021991480141878128, -0.0077977413311600685, 0.011962306685745716, -0.10817965865135193, -0.09694148600101471, -0.012010946869850159], metadata={'source': 'AAAMLP-569to.pdf', 'page': 170}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 171 ═════════════════════════════════════════════════════════════════════════ [CV]  criterion=entropy, max_depth=15, n_estimators=500, score=0.895, total=   1.0s [CV] criterion=entropy, max_depth=15, n_estimators=500 ............... [CV]  criterion=entropy, max_depth=15, n_estimators=500, score=0.890, total=   1.1s [CV] criterion=entropy, max_depth=15, n_estimators=500 ............... [CV]  criterion=entropy, max_depth=15, n_estimators=500, score=0.910, total=   1.1s [CV] criterion=entropy, max_depth=15, n_estimators=500 ............... [CV]  criterion=entropy, max_depth=15, n_estimators=500, score=0.880, total=   1.1s [CV] criterion=entropy, max_depth=15, n_estimators=500 ............... [CV]  criterion=entropy, max_depth=15, n_estimators=500, score=0.870, total=   1.1s [Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:  3.7min finished Best score: 0.889 Best parameters set:  criterion: \\'entropy\\'  max_depth: 15  n_estimators: 500 ═════════════════════════════════════════════════════════════════════════  In the end, we see that our best five fold accuracy score was 0.889, and we have the best parameters from our grid search. Next best thing that we can use is random search. In random search, we randomly select a combination of parameters and calculate the cross-validation score. The time consumed here is less than grid search because we do not evaluate over all different combinations of parameters. We choose how many times we want to evaluate our models, and that’s what decides how much time the search takes. The code is not very different from above. Except for GridSearchCV, we use RandomizedSearchCV.  ═════════════════════════════════════════════════════════════════════════ # rf_random_search.py . . .  if __name__ == \"__main__\":     .     .     .     # define the model here     # i am using random forest with n_jobs=-1     # n_jobs=-1 => use all cores'),\n",
       " VectorParams(vector=[-0.10152410715818405, -0.025343483313918114, -0.04080059379339218, 0.049393605440855026, 0.05296161770820618, -0.08867310732603073, -0.002911378862336278, 0.04865317791700363, -0.1255979835987091, -0.036728840321302414, -0.10681045055389404, -0.027813756838440895, 0.10793094336986542, -0.047389961779117584, -0.019657835364341736, -0.014775076881051064, 0.06887665390968323, 0.028432682156562805, -0.09429516643285751, -0.03945208340883255, 0.13553369045257568, 0.10360362380743027, 0.07672082632780075, -0.06740579754114151, -0.004629963077604771, -0.1418827921152115, -0.042193420231342316, 0.028343137353658676, -0.10407913476228714, 0.008949795737862587, -0.054373420774936676, 0.025514008477330208, 0.014734779484570026, 0.14353986084461212, 0.053334977477788925, 0.0014520948752760887, -0.1362379789352417, -0.06381219625473022, 0.05347423627972603, 0.046518247574567795, -0.0520273894071579, 0.03213825076818466, -0.08065629750490189, -0.08688491582870483, 0.07604628801345825, 0.09172772616147995, -0.05312284827232361, -0.06380212306976318, 0.09795041382312775, 0.06301518529653549, -0.16527436673641205, 0.05305182561278343, -0.08967903256416321, -0.042637474834918976, -0.029145704582333565, -0.07918151468038559, 0.02912735566496849, -0.17650622129440308, 0.06472159922122955, -0.1607387661933899, 0.04015827178955078, -0.11696213483810425, -0.05872621387243271, 0.022813186049461365, -0.01867269165813923, -0.1725611537694931, 0.03927769139409065, 0.06026414781808853, 0.0321081317961216, 0.02191556617617607, 0.017811348661780357, 0.1328606903553009, -0.015693487599492073, 0.0610681027173996, 0.013234719634056091, 0.06233157217502594, 0.07427137345075607, -0.057512056082487106, 0.03095369040966034, -0.02458302304148674, -0.08195774257183075, 0.02702796645462513, 0.03477440029382706, 0.07705571502447128, 0.08741098642349243, -0.17337799072265625, 0.06357503682374954, 0.005337871145457029, 0.18820621073246002, -0.05447132885456085, 0.05643818527460098, -0.029136644676327705, -0.09504111856222153, 0.0006473303074017167, 0.12454238533973694, 0.15107858180999756, 0.1818072646856308, -0.1279527097940445, -0.0385068841278553, 0.07378678768873215, -0.01970190927386284, 0.017737310379743576, 0.09714300185441971, -0.19856785237789154, 0.12661905586719513, 0.0188607070595026, 0.1114109680056572, 0.03312065079808235, 0.12740127742290497, -0.060527775436639786, -0.07354848831892014, 0.026348035782575607, -0.07604945451021194, 0.010815372690558434, 0.14330853521823883, 0.12038211524486542, 0.032769039273262024, 0.10089828073978424, -0.10728355497121811, 0.07670263946056366, -0.1278083771467209, 0.04486536607146263, 0.019508227705955505, 0.032856643199920654, 0.032451316714286804, 0.07811959087848663, -0.08488956838846207, 1.0096590608229347e-32, -0.016309944912791252, 0.0029891557060182095, -0.00026027290732599795, -0.08856697380542755, 0.02354717254638672, 0.05896235257387161, 0.14823786914348602, 0.03688820078969002, 0.0405784472823143, 0.055481258779764175, -0.28396090865135193, 0.06685300171375275, -0.054376453161239624, 0.009705598466098309, 0.042396917939186096, -0.02259855531156063, -0.09208829700946808, 0.12190314382314682, -0.12893420457839966, 0.053192462772130966, 0.2343597412109375, -0.07474814355373383, 0.0505310595035553, -0.13988186419010162, -0.0853302851319313, -0.02024851366877556, -0.007622427307069302, -0.01971917226910591, -0.17558656632900238, 0.010487411171197891, -0.1414417326450348, 0.003855462884530425, 0.020424244925379753, -0.02959328144788742, 0.03419163450598717, -0.059201568365097046, 0.04289526864886284, 0.092796690762043, -0.07215116918087006, -0.10142401605844498, -0.06846068799495697, 0.024629702791571617, 0.10519145429134369, -0.02618231251835823, -0.09638795256614685, -0.0030558600556105375, -0.09909795224666595, 0.028451839461922646, 0.13999265432357788, 0.1108194887638092, -0.061373285949230194, -0.09089596569538116, -0.009153041988611221, -0.018235621973872185, -0.06969614326953888, 0.09735695272684097, 0.1316061019897461, 0.11419849097728729, 0.026414012536406517, -0.04402836039662361, -0.06993333995342255, -0.1295192837715149, 0.01380319893360138, 0.010715161450207233, 0.19136996567249298, 0.026466980576515198, 0.10847095400094986, 0.07189162075519562, 0.12746325135231018, 0.03231460228562355, -0.06684573739767075, -0.038661010563373566, -0.0901886448264122, -0.10236776620149612, 0.03416382521390915, -0.0697152391076088, 0.14508140087127686, 0.05941414833068848, -0.03354412689805031, -0.053316861391067505, 0.01465833093971014, 0.14715586602687836, -0.09947051852941513, -0.1306411772966385, 0.008922767825424671, 0.031710460782051086, 0.06743600219488144, -0.05531803146004677, -0.15313343703746796, -0.12195460498332977, -0.10254473239183426, 0.04388897493481636, -0.010109517723321915, -0.0597308985888958, -0.07420885562896729, -9.710887401837538e-33, -0.037180494517087936, -0.002404850209131837, 0.10455705225467682, 0.17308129370212555, 0.02485635131597519, -0.0384928360581398, -0.01899784617125988, -0.0009554781718179584, -0.055881280452013016, -0.14489059150218964, -0.03486693650484085, -0.07775496691465378, 0.1796063482761383, 0.012542163021862507, 0.011570778675377369, 0.12826725840568542, -0.10149675607681274, 0.061396341770887375, -0.04521812126040459, 0.06725699454545975, -0.06991290301084518, 0.13105888664722443, -0.11977100372314453, -0.010531500913202763, -0.10515251010656357, 0.020434139296412468, 0.019813774153590202, 0.08411625772714615, 0.03397587686777115, -0.12459313124418259, 0.023690808564424515, 0.15301263332366943, -0.17558011412620544, 0.1256852149963379, 0.04068408161401749, -0.08469361066818237, 0.018577784299850464, -0.11717350780963898, -0.08022939413785934, 0.17530736327171326, 0.117070272564888, 0.13419312238693237, -0.1444982886314392, -0.03453521803021431, 0.017671430483460426, 0.026258161291480064, -0.039587873965501785, -0.06136220693588257, 0.06462211906909943, -0.015391288325190544, 0.04352869465947151, -0.11098930984735489, -0.23275524377822876, 0.17214199900627136, -0.030006201937794685, -0.02524777501821518, -0.2097999006509781, 0.04915842041373253, 0.006682776380330324, -0.028558801859617233, -0.052256111055612564, 0.06273714452981949, -0.0310380682349205, 0.06271598488092422, 0.05791648477315903, 0.03772147372364998, -0.07824733853340149, 0.006049675866961479, -0.04461226612329483, 0.1369611918926239, -0.1659346967935562, -0.07085596770048141, 0.13453364372253418, -0.0277691837400198, -0.07812075316905975, 0.0627349391579628, 0.05244522914290428, 0.0042984215542674065, 0.0043219150975346565, -0.060530319809913635, -0.030339809134602547, 0.06130290403962135, -0.020353803411126137, 0.14753085374832153, -0.02430608496069908, 0.08418552577495575, 0.14603954553604126, 0.13676273822784424, 0.06870264559984207, -0.018574809655547142, 0.029686003923416138, -0.012003020383417606, 0.0759248211979866, 0.1093946248292923, 0.011127348057925701, -1.0023936170000525e-07, -0.03939934819936752, 0.23779022693634033, -0.03356761857867241, 0.09277822077274323, 0.10733398050069809, 0.026816995814442635, -0.07659722864627838, 0.07450598478317261, -0.08742909878492355, -0.0662851557135582, 0.15424838662147522, 0.007291906978935003, -0.07128920406103134, 0.05816765874624252, -0.007831210270524025, 0.022115761414170265, -0.11092128604650497, 0.10081461817026138, -0.05236075073480606, 0.021939661353826523, 0.02400796115398407, -0.054176729172468185, 0.04765455052256584, 0.020722463726997375, 0.08014705032110214, -0.018627658486366272, -0.028904234990477562, -0.08209698647260666, -0.006549011450260878, 0.028488943353295326, -0.03254047408699989, -0.10295746475458145, 0.020857974886894226, -0.0346454456448555, 0.007251518778502941, 0.16809962689876556, -0.14196829497814178, -0.08240918070077896, -0.047960445284843445, 0.16418541967868805, -0.047456689178943634, 0.011800703592598438, -0.10510989278554916, -0.07780154049396515, 0.016523465514183044, -0.036615874618291855, 0.05271606892347336, 0.006235918030142784, 0.09831052273511887, -0.021543309092521667, -0.03250192850828171, -0.07570616155862808, -0.07246056199073792, -0.0634072795510292, 0.05910889059305191, -0.010579484514892101, -0.13705338537693024, 0.014324351213872433, 0.06225886195898056, -0.033646419644355774, 0.06534365564584732, -0.09678060561418533, -0.11473782360553741, 0.03847183659672737], metadata={'source': 'AAAMLP-569to.pdf', 'page': 171}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 172     classifier = ensemble.RandomForestClassifier(n_jobs=-1)      # define a grid of parameters     # this can be a dictionary or a list of     # dictionaries     param_grid = {         \"n_estimators\": np.arange(100, 1500, 100),         \"max_depth\": np.arange(1, 31),         \"criterion\": [\"gini\", \"entropy\"]     }     # initialize random search     # estimator is the model that we have defined     # param_distributions is the grid/distribution of parameters     # we use accuracy as our metric. you can define your own     # higher value of verbose implies a lot of details are printed     # cv=5 means that we are using 5 fold cv (not stratified)     # n_iter is the number of iterations we want     # if param_distributions has all the values as list,     # random search will be done by sampling without replacement     # if any of the parameters come from a distribution,     # random search uses sampling with replacement     model = model_selection.RandomizedSearchCV(         estimator=classifier,          param_distributions=param_grid,         n_iter=20,         scoring=\"accuracy\",         verbose=10,          n_jobs=1,         cv=5     )      # fit the model and extract best score     model.fit(X, y)     print(f\"Best score: {model.best_score_}\")      print(\"Best parameters set:\")     best_parameters = model.best_estimator_.get_params()     for param_name in sorted(param_grid.keys()):      print(f\"\\\\t{param_name}: {best_parameters[param_name]}\") ═════════════════════════════════════════════════════════════════════════  We have changed the grid of parameters for random search, and it seems like we even improved the results a little bit.  ═════════════════════════════════════════════════════════════════════════ Best score: 0.8905 Best parameters set:'),\n",
       " VectorParams(vector=[-0.05151258781552315, -0.05633718520402908, -0.08298089355230331, -0.03569647669792175, 0.049871549010276794, -0.039032261818647385, -0.017604539170861244, 0.036496423184871674, -0.028918590396642685, -0.019020669162273407, -0.10104911774396896, -0.05468166619539261, -0.02665572240948677, -0.06676765531301498, -0.0004247013421263546, -0.030783599242568016, 0.06719692051410675, 0.050597649067640305, -0.06566444039344788, -0.07530256360769272, 0.04886068403720856, 0.05902168154716492, 0.04035237804055214, 0.0015020088758319616, -0.07685969769954681, -0.11424409598112106, 0.03176145628094673, 0.05288132280111313, -0.11379390954971313, 0.04444397985935211, -0.0013643843121826649, 0.058318253606557846, -0.058705512434244156, 0.07918979972600937, -0.04730578511953354, 0.02133815549314022, -0.04692545533180237, 0.030457409098744392, -0.10798384994268417, 0.07648177444934845, -0.06235693022608757, -0.04408607259392738, -0.04264870285987854, 0.024902204051613808, 0.060095179826021194, 0.030316846445202827, -0.12070237845182419, -0.10643826425075531, 0.0568571612238884, -0.02745928429067135, -0.1288183480501175, 0.0024903423618525267, -0.09994600713253021, 0.057134486734867096, -0.015277571976184845, -0.10852469503879547, 0.07402852177619934, -0.07037239521741867, 0.08401705324649811, -0.06662328541278839, -0.03146885335445404, -0.13952350616455078, 0.0067917522974312305, -0.04091174900531769, -0.0036855246871709824, -0.041220057755708694, 0.027585670351982117, -0.02590913139283657, -0.06977978348731995, 0.11602866649627686, -0.02367866039276123, 0.08407942950725555, -0.04493708163499832, 0.04977172240614891, 0.01700529269874096, -0.027082394808530807, 0.19479194283485413, -0.024914797395467758, 0.06518039852380753, -0.06608988344669342, -0.06470699608325958, 0.10982543975114822, 0.12633533775806427, -0.018467804417014122, 0.022453689947724342, -0.09815138578414917, -0.02413267455995083, -0.03694404289126396, 0.14508770406246185, 0.04048018902540207, 0.14066313207149506, -0.02688594162464142, -0.051643770188093185, -0.12860840559005737, -0.022766083478927612, 0.10771483182907104, 0.044816967099905014, -0.045929525047540665, 0.04518188163638115, 0.08744648098945618, -0.0554644875228405, -0.027150912210345268, 0.06818678975105286, -0.07949879765510559, 0.054449331015348434, 0.019267959520220757, 0.06297284364700317, 0.03895650804042816, 0.17132729291915894, -0.08480679243803024, 0.012616584077477455, -0.092812180519104, -0.07510994374752045, -0.020024782046675682, 0.14092668890953064, 0.06218210607767105, 0.059759464114904404, 0.016532311215996742, -0.02137826383113861, 0.10423226654529572, -0.15687240660190582, -0.033634841442108154, 0.011711567640304565, -0.013847935013473034, 0.009089767932891846, 0.02677812986075878, -0.13884569704532623, 1.1063008595078506e-32, -0.03585457801818848, 0.04373161122202873, -0.04930040240287781, -0.1275140792131424, -0.10178477317094803, 0.011442912742495537, 0.14133301377296448, 0.010066927410662174, -0.006994419265538454, 0.03912579268217087, -0.15480124950408936, -0.023337621241807938, -0.11377853155136108, 0.025200719013810158, 0.04462713003158569, -0.061526138335466385, -0.023948555812239647, 0.06872818619012833, -0.11046402156352997, -0.06622133404016495, 0.17072631418704987, -0.07511287182569504, 0.08376722782850266, -0.1085410788655281, 0.06224092096090317, -0.08986368030309677, 0.0076403263956308365, -0.06505538523197174, -0.1613711714744568, 0.0021719057112932205, -0.12789075076580048, -0.01722848415374756, 0.027440117672085762, -0.003367854282259941, 0.01267023291438818, -0.07142648845911026, 0.036844607442617416, 0.13419966399669647, -0.029406053945422173, -0.15562471747398376, -0.04108176752924919, 0.014222745783627033, 0.06619743257761002, -0.0770886018872261, -0.041901156306266785, 0.034566737711429596, -0.0617489330470562, 0.02636220119893551, 0.01909324899315834, 0.024626171216368675, 0.02686179429292679, 0.0047081876546144485, 0.029395120218396187, -0.019391607493162155, 0.04212631657719612, 0.07170043885707855, 0.029903436079621315, -0.02152407355606556, 0.0396418571472168, -0.013882960192859173, -0.017697112634778023, -0.09064263105392456, 0.08596103638410568, -0.022939467802643776, 0.060566309839487076, -0.021936416625976562, 0.11560411751270294, 0.009081210009753704, 0.09109487384557724, -0.047589074820280075, -0.04586683586239815, -0.07337913662195206, 0.0017797622131183743, -0.1250188797712326, 0.10207822173833847, -0.0785970687866211, 0.10652358084917068, -0.03615330532193184, -0.002387458924204111, -0.020692043006420135, -0.06904251128435135, 0.13366883993148804, 0.04031185805797577, -0.1287337988615036, 0.042245782911777496, -0.008853665553033352, 0.021955391392111778, -0.0777149572968483, -0.16083484888076782, -0.09526269882917404, -0.12476692348718643, 0.06983236968517303, -0.020001627504825592, -0.031872112303972244, -0.006436971481889486, -1.2803624059110516e-32, 0.10257301479578018, -0.0589163564145565, 0.0005241985782049596, 0.08679677546024323, 0.005525617394596338, 0.03547430783510208, -0.0868976041674614, 0.003393213963136077, -0.11178871244192123, -0.10327089577913284, 0.04783787578344345, -0.0838543027639389, 0.05327299237251282, -0.022339828312397003, 0.024001602083444595, 0.1071946769952774, -0.09971107542514801, 0.04968446120619774, -0.001250558765605092, 0.07083894312381744, -0.02410845272243023, 0.0965365543961525, -0.04685083031654358, 0.06904148310422897, -0.07497671991586685, -0.06490017473697662, 0.059721507132053375, 0.0792575553059578, -0.0394749641418457, -0.00018309045117348433, -0.10274040699005127, 0.007479219231754541, -0.09809336066246033, 0.09434209018945694, -0.041159432381391525, -0.013120506890118122, -0.04158996418118477, -0.06203596666455269, -0.03870144113898277, 0.1769489347934723, 0.043432578444480896, 0.1970035582780838, -0.1617976576089859, 0.0025182110257446766, -0.09957737475633621, 0.019609805196523666, 0.01483911368995905, 0.015250333584845066, 0.03495142608880997, -0.05854514613747597, 0.03159574046730995, -0.053252968937158585, -0.07807963341474533, 0.147489532828331, -0.08123264461755753, 0.04379165172576904, -0.07886142283678055, -0.011196927167475224, -0.08448248356580734, -0.04410351440310478, -0.07913019508123398, 0.04156019911170006, 0.02445795387029648, 0.03277672454714775, 0.0751824751496315, 0.012075640261173248, -0.026361024007201195, 0.016642853617668152, 0.02401108294725418, 0.05696825683116913, -0.11507533490657806, 0.016143808141350746, 0.02846965752542019, 0.07544641196727753, -0.04892682284116745, 0.02102038450539112, 0.0789058580994606, 0.056097883731126785, -0.0013265155721455812, 0.00762600963935256, -0.007280043326318264, 0.12466175854206085, 0.014313573949038982, 0.18953077495098114, -0.022734694182872772, 0.09179306775331497, 0.13930919766426086, 0.07281722873449326, 0.07066802680492401, -0.08214595913887024, 0.05963965505361557, -0.00041854273877106607, 0.14470522105693817, 0.10122985392808914, 0.03508419170975685, -1.0075334699877203e-07, -0.03986487165093422, 0.037449080497026443, 0.02594652585685253, -0.019493427127599716, 0.08081880956888199, 0.012655498459935188, -0.044381283223629, 0.13024267554283142, -0.09292236715555191, 0.012435898184776306, 0.02577049657702446, 0.09084401279687881, -0.0574265755712986, 0.05929728224873543, 0.007439000532031059, -0.00351276365108788, -0.020488876849412918, 0.11435411125421524, -0.06767628341913223, 0.00823314767330885, 0.10806785523891449, -0.07188086211681366, 0.007801189087331295, 0.08190428465604782, 0.06754367053508759, -0.0527142733335495, -0.018894901499152184, -0.016065210103988647, 0.08836597949266434, 0.13165085017681122, -0.11083203554153442, -0.05299963429570198, -0.13127560913562775, 0.0005676678847521544, 0.11937596648931503, 0.1034187451004982, -0.06372372061014175, -0.08982060849666595, -0.06567982584238052, 0.10082027316093445, -0.04417113587260246, 0.05887683108448982, -0.05571211501955986, -0.07713084667921066, -0.014665466733276844, 0.004356733988970518, -0.0551556795835495, -0.06612277776002884, 0.058579277247190475, 0.05491181090474129, 0.02718006819486618, -0.04291258007287979, -0.023048602044582367, 0.05202576890587807, 0.0037862961180508137, -0.0037933646235615015, -0.049212221056222916, 0.03136745095252991, -0.010333708487451077, -0.014284471981227398, 0.08787792921066284, -0.0010620952816680074, -0.027431529015302658, -0.03330894932150841], metadata={'source': 'AAAMLP-569to.pdf', 'page': 172}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 173  criterion: entropy  max_depth: 25  n_estimators: 300 ═════════════════════════════════════════════════════════════════════════ Random search is faster than grid search if the number of iterations is less. Using these two, you can find the optimal (?) parameters for all kinds of models as long as they have a fit and predict function, which is the standard of scikit-learn. Sometimes, you might want to use a pipeline. For example, let’s say that we are dealing with a multiclass classification problem. In this problem, the training data consists of two text columns, and you are required to build a model to predict the class. Let’s assume that the pipeline you choose is to first apply tf-idf in a semi-supervised manner and then use SVD with SVM classifier. Now, the problem is we have to select the components of SVD and also need to tune the parameters of SVM. How to do this is shown in the following snippet.  ═════════════════════════════════════════════════════════════════════════ # pipeline_search.py import numpy as np import pandas as pd  from sklearn import metrics from sklearn import model_selection from sklearn import pipeline  from sklearn.decomposition import TruncatedSVD from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.preprocessing import StandardScaler from sklearn.svm import SVC   def quadratic_weighted_kappa(y_true, y_pred):     \"\"\"     Create a wrapper for cohen\\'s kappa     with quadratic weights     \"\"\"     return metrics.cohen_kappa_score(         y_true,          y_pred,          weights=\"quadratic\"     )   if __name__ == \\'__main__\\':      # Load the training file'),\n",
       " VectorParams(vector=[-0.02866254560649395, -0.05420514941215515, -0.11603271216154099, 0.007870473898947239, 0.12278109043836594, -0.018719539046287537, 0.06089681386947632, 0.08379819244146347, -0.10816985368728638, -0.10007192939519882, -0.013022873550653458, -0.004004983231425285, -0.021384181454777718, -0.1339099258184433, -0.030994977802038193, 0.03243052214384079, -0.10384474694728851, 0.0016075563617050648, -0.08616936951875687, -0.1000356525182724, 0.009355034679174423, 0.14341872930526733, 0.009823770262300968, 0.08762652426958084, -0.05099483206868172, 0.08162765949964523, 0.014120552688837051, 0.04930615797638893, -0.09131873399019241, -0.026685403659939766, 0.014290113002061844, 0.10154306888580322, -0.014043607749044895, 0.053100645542144775, -0.05981525033712387, 0.03432222083210945, -0.03981458768248558, 0.1223914697766304, -0.08088191598653793, 0.10421644151210785, -0.0042922464199364185, -0.09684886038303375, -0.02067507803440094, -0.021742939949035645, 0.1130535751581192, 0.017857076600193977, -0.08798684924840927, -0.12071949243545532, 0.04578031972050667, 0.02332446537911892, -0.16081635653972626, 0.10954312235116959, -0.06638834625482559, 0.0026058810763061047, -0.09747322648763657, -0.1705731451511383, 0.11997092515230179, -0.1168067455291748, 0.07620899379253387, -0.04960113391280174, -0.11048875004053116, -0.09888778626918793, 0.1421789526939392, -0.05585741251707077, 0.009714759886264801, -0.10861621052026749, 0.010362946428358555, 0.05145375803112984, -0.11763587594032288, 0.08345455676317215, -0.05487419664859772, 0.1456502377986908, -0.025398313999176025, 0.1031884029507637, -0.1636108011007309, 0.04133142530918121, 0.16024211049079895, -0.06891729682683945, 0.2198667973279953, -0.005579287651926279, -0.13475444912910461, -0.029521465301513672, 0.09164698421955109, 0.046660639345645905, -0.0012902150629088283, -0.11790789663791656, 0.09375777095556259, -0.06530588120222092, 0.03886399418115616, 0.06822141259908676, 0.07987479865550995, -0.03215742111206055, 0.023669704794883728, 0.02495703101158142, 0.022880658507347107, 0.07904370129108429, 0.1208956241607666, 0.0062856352888047695, 0.00554040540009737, 0.0985039547085762, -0.04562901705503464, -0.05938385799527168, -0.021179428324103355, 0.02446313388645649, -0.05374443903565407, -0.018651660531759262, 0.13830921053886414, 0.040475890040397644, 0.15310710668563843, -0.19098548591136932, 0.073360376060009, -0.17567230761051178, -0.1316612958908081, -0.04112457484006882, 0.1241711899638176, 0.04082310572266579, 0.01634603925049305, 0.0030534749384969473, -0.12726132571697235, 0.057690586894750595, -0.14845791459083557, 0.025846965610980988, -0.027458397671580315, 0.08540765196084976, -0.07267042249441147, 0.012620826251804829, -0.0416409894824028, 1.4179956027874607e-32, -0.1863735020160675, 0.017217304557561874, -0.1156378909945488, -0.10312128812074661, 0.005143216345459223, -0.02587868832051754, -0.016556978225708008, 0.004046276211738586, -0.06791213899850845, 0.051233332604169846, -0.14439089596271515, 0.002951176604256034, -0.02237642928957939, 0.010664527304470539, -0.10047615319490433, -0.08439978212118149, 0.06395681947469711, 0.0014878266956657171, -0.05036773160099983, -0.031122148036956787, 0.2835019826889038, 0.032403554767370224, 0.055873189121484756, -0.1390962451696396, -0.054751548916101456, -0.060783203691244125, -0.07444842904806137, -0.03694815933704376, -0.12215166538953781, -0.04196964204311371, -0.1939668357372284, -0.015466042794287205, 0.08027563989162445, -0.00016260641859844327, -0.02868894301354885, -0.11410760879516602, 0.12253264337778091, 0.05352229252457619, -0.013514548540115356, -0.04764639958739281, 0.005846451036632061, 0.04532615840435028, 0.045336026698350906, -0.104671411216259, 0.00822852086275816, 0.07817094027996063, 0.02217966318130493, 0.08010992407798767, -0.008894005790352821, -0.0005740075721405447, -0.04967606067657471, -0.03791900351643562, 0.02386278472840786, 0.05435630679130554, 0.025928661227226257, 0.12293999642133713, 0.10235536098480225, -0.005149134900420904, 0.11396078020334244, -0.05801087245345116, -0.03202686086297035, -0.045324306935071945, 0.03970863297581673, 0.03860314190387726, 0.0913698598742485, -0.0215141661465168, 0.17184829711914062, 0.01276660617440939, 0.03859296441078186, -0.01467197760939598, -0.01846836693584919, -0.03228961303830147, 0.011165631003677845, -0.10337609052658081, 0.11364398896694183, -0.11441973596811295, -0.0008799177594482899, -0.00504792295396328, -0.06841111183166504, -0.05252201855182648, 0.015313554555177689, 0.15093295276165009, 0.013517409563064575, -0.1742265373468399, 0.03439634293317795, -0.01153975073248148, 0.08579456061124802, -0.13502764701843262, -0.07657990604639053, -0.19616395235061646, -0.18842798471450806, 0.015424595214426517, 0.030532730743288994, -0.07632071524858475, 0.04024263098835945, -1.3749589913623305e-32, 0.031184542924165726, 0.057593874633312225, 0.02852078154683113, 0.05983767658472061, 0.0749567523598671, 0.07844491302967072, 0.08606840670108795, 0.07731886208057404, -0.01777818612754345, -0.09102834016084671, 0.05502544716000557, -0.15587803721427917, 0.010063102468848228, 0.009565015323460102, 0.06792415678501129, 0.04639213904738426, -0.025332527235150337, 0.12804922461509705, -0.10401317477226257, 0.021602991968393326, -0.07138421386480331, 0.0931205078959465, -0.08500967919826508, 0.07240352779626846, -0.10913661122322083, -0.023851891979575157, 0.028252873569726944, 0.05129947140812874, -0.06879088282585144, -0.13017641007900238, -0.16349130868911743, 0.08741206675767899, -0.06021265313029289, 0.06634354591369629, -0.008705741725862026, 0.04493195563554764, 0.01967012509703636, -0.12368608266115189, -0.1642899364233017, 0.1562463939189911, 0.14161308109760284, 0.17249226570129395, -0.12452301383018494, 0.06016470864415169, -0.06936120986938477, 0.10096076875925064, -0.011888829991221428, 0.03439770266413689, -0.05923230201005936, 0.016850290820002556, 0.028866758570075035, 0.014143574051558971, -0.04902823269367218, 0.06666630506515503, -0.05715890973806381, -0.014029488898813725, -0.043965041637420654, 0.017238983884453773, -0.18195311725139618, -0.06671018153429031, -0.06034074351191521, 0.015638159587979317, -0.004678919445723295, -0.04707145690917969, 0.1726974993944168, 0.006838311906903982, -0.09773560613393784, 0.05145575851202011, 0.03575936332345009, 0.023187650367617607, -0.08573343604803085, -0.04885183274745941, 0.007549883797764778, -0.06423098593950272, 0.013025390915572643, 0.0625385195016861, -0.0945328027009964, -0.04574427753686905, 0.009364889934659004, 0.06220785900950432, 0.08532774448394775, 0.014218364842236042, 0.148225799202919, 0.14295487105846405, 0.01644308492541313, 0.13917700946331024, 0.07406465709209442, 0.11419707536697388, 0.01880214735865593, 0.0036422554403543472, 0.07437586784362793, -0.03318523243069649, 0.12939918041229248, 0.1424349993467331, 0.019109735265374184, -1.008534837865227e-07, -0.10260393470525742, 0.06709084659814835, -0.08525426685810089, 0.04631638526916504, -0.00594383804127574, -0.0446857288479805, -0.1273147314786911, 0.06054747849702835, -0.08494175225496292, 0.03087456338107586, 0.002321541542187333, 0.007012681104242802, -0.13172532618045807, 0.02524401806294918, 0.03463668003678322, 0.01999036781489849, -0.03854299336671829, 0.039664264768362045, 0.04225841164588928, 0.002940519480034709, 0.03117947466671467, -0.04971455782651901, 0.006725163199007511, -0.016521591693162918, -0.01903671771287918, -0.13214048743247986, -0.07193077355623245, 0.0035128388553857803, 0.1397288292646408, -0.021423719823360443, -0.0367620587348938, -0.11639085412025452, -0.021459178999066353, 0.06309524923563004, 0.17428171634674072, 0.013256481848657131, 0.06854872405529022, -0.07483981549739838, 0.04857863858342171, 0.20384372770786285, -0.04855889081954956, 0.12814205884933472, -0.1022828221321106, -0.08825545012950897, 0.002290966920554638, 0.08860411494970322, -0.06818348169326782, -0.10164561122655869, 0.12800811231136322, -0.010173308663070202, 0.0003989054821431637, 0.012974615208804607, -0.050107333809137344, 0.013523492030799389, 0.1531650722026825, -0.03961241990327835, -0.10334742069244385, 0.1468244343996048, -0.05118982866406441, 0.01954137161374092, 0.02505822665989399, 0.07966090738773346, 0.062379900366067886, -0.1200638934969902], metadata={'source': 'AAAMLP-569to.pdf', 'page': 173}, content=\"Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 174     train = pd.read_csv('../input/train.csv')          # we dont need ID columns     idx = test.id.values.astype(int)     train = train.drop('id', axis=1)     test = test.drop('id', axis=1)          # create labels. drop useless columns     y = train.relevance.values          # do some lambda magic on text columns     traindata = list(         train.apply(lambda x:'%s %s' % (x['text1'], x['text2']),axis=1)     )     testdata = list(         test.apply(lambda x:'%s %s' % (x['text1'], x['text2']),axis=1)     )          # tfidf vectorizer     tfv = TfidfVectorizer(         min_df=3,           max_features=None,          strip_accents='unicode',          analyzer='word',         token_pattern=r'\\\\w{1,}',         ngram_range=(1, 3),          use_idf=1,         smooth_idf=1,         sublinear_tf=1,         stop_words='english'     )          # Fit TFIDF     tfv.fit(traindata)     X =  tfv.transform(traindata)      X_test = tfv.transform(testdata)          # Initialize SVD     svd = TruncatedSVD()          # Initialize the standard scaler      scl = StandardScaler()          # We will use SVM here..     svm_model = SVC()          # Create the pipeline\"),\n",
       " VectorParams(vector=[0.006523143500089645, -0.01759495586156845, -0.0956978127360344, 0.0567888468503952, 0.09753967821598053, -0.05308246240019798, -0.039155762642621994, 0.13437458872795105, -0.11436479538679123, -0.01018083468079567, -0.08268330991268158, -0.07249351590871811, 0.023587480187416077, -0.06726279109716415, -0.08372452855110168, -0.04891054332256317, -0.019981518387794495, -0.03590919449925423, -0.0983954593539238, -0.15146981179714203, 0.047692276537418365, 0.04758765175938606, -0.030070466920733452, 0.010488622821867466, 0.02239219658076763, -0.06800380349159241, -0.008432438597083092, 0.16490015387535095, -0.11594909429550171, 0.01075531542301178, -0.08152023702859879, 0.0031791182700544596, -0.00829105731099844, 0.20598194003105164, 0.06875782459974289, 0.06136399134993553, -0.08712593466043472, -0.09322775900363922, -0.07501007616519928, 0.06480486690998077, -0.0331183597445488, -0.05653568357229233, -0.0348191075026989, -0.12091966718435287, 0.1113971471786499, 0.01822579652070999, -0.1821308135986328, -0.1512613147497177, 0.02558831311762333, 0.05148595944046974, -0.3020351231098175, -0.11692557483911514, -0.07568753510713577, -0.057822804898023605, 0.020074903964996338, -0.05566421523690224, 0.05427482724189758, -0.22034116089344025, 0.20480139553546906, -0.2466689497232437, -0.11469029635190964, -0.2223600596189499, -0.025704069063067436, 0.04571307450532913, 0.017625343054533005, -0.11566691845655441, -0.06555171310901642, 0.0966896191239357, -0.12141787260770798, 0.17370353639125824, 0.05058588087558746, 0.11372779309749603, -0.11487185209989548, 0.013324737548828125, -0.023219754919409752, 0.04174334928393364, 0.17471501231193542, -0.11642865836620331, 0.02973044477403164, -0.03788948431611061, -0.14812253415584564, 0.024204544723033905, -0.022066311910748482, 0.05614854395389557, 0.08660856634378433, -0.14868158102035522, 0.08045797049999237, -0.08480118215084076, 0.23435078561306, -0.04933365061879158, 0.13087813556194305, 0.08252780884504318, -0.02561763860285282, 0.0057149105705320835, 0.04914551600813866, 0.1731991171836853, 0.17309924960136414, -0.0865597054362297, -0.03769503906369209, 0.12238241732120514, -0.09434375911951065, 0.07127061486244202, 0.19577309489250183, -0.11498765647411346, 0.0676124319434166, -0.012664134614169598, 0.1324167400598526, 0.21083317697048187, 0.11179877072572708, -0.09582933783531189, -0.07096240669488907, -0.06259339302778244, -0.045736417174339294, 0.08811593800783157, 0.14022262394428253, 0.143448606133461, 0.09362779557704926, 0.17246979475021362, -0.09468983858823776, 0.10567329823970795, -0.1284327208995819, 0.017158379778265953, 0.027769790962338448, 0.031779561191797256, -0.029811248183250427, 0.0713123083114624, -0.20331978797912598, 9.691165545366617e-33, -0.1013430580496788, -0.1015654131770134, 0.018413430079817772, -0.1262412667274475, -0.03558703139424324, 0.0021314145997166634, 0.1592230498790741, -0.05610526725649834, -0.017821909859776497, 0.07927857339382172, -0.29407423734664917, 0.042653195559978485, -0.10573890805244446, 0.034050945192575455, 0.09092322736978531, -0.04191429540514946, 0.007969623431563377, 0.10665921121835709, -0.2152445763349533, 0.09624988585710526, 0.39856818318367004, -0.08653781563043594, 0.05131661146879196, -0.17173753678798676, -0.034143876284360886, -0.057521261274814606, 0.04738355055451393, -0.06223684921860695, -0.21268519759178162, 0.01581615023314953, -0.1412341296672821, 0.06050320714712143, 0.0015217035543173552, -0.06123873591423035, -0.009235179983079433, -0.1184455081820488, 0.10579279810190201, 0.08731172233819962, -0.006911063101142645, -0.1296853870153427, -0.07265523821115494, -0.020891591906547546, 0.09521762281656265, -0.03150885924696922, -0.03953826054930687, -0.04748525470495224, -0.1156325414776802, 0.08627854287624359, 0.1175624281167984, 0.15005837380886078, -0.06790383160114288, -0.05198335647583008, 0.09640437364578247, 0.019657989963889122, -0.023216458037495613, 0.08463077247142792, 0.05341796576976776, 0.05136619880795479, 0.07716745883226395, -0.05052982270717621, -0.0018933088285848498, -0.11932047456502914, 0.01668672263622284, -0.008175753057003021, 0.18549679219722748, 0.014430803246796131, 0.15080426633358002, 0.021060386672616005, 0.08897808939218521, 0.008390164002776146, -0.08808684349060059, -0.05044155195355415, -0.03875824436545372, -0.16278545558452606, 0.13243326544761658, -0.2471955567598343, 0.04099833220243454, 0.0033723502419888973, -0.08268609642982483, -0.06150076538324356, -0.11243461072444916, 0.29696565866470337, -0.1264074295759201, -0.2008143663406372, 0.124699167907238, -0.05986806005239487, 0.09172522276639938, -0.12035398185253143, -0.17481619119644165, -0.09856467694044113, -0.17778536677360535, 0.09363260865211487, 0.06445171684026718, 0.01998596079647541, -0.1580185443162918, -8.279228587400089e-33, 0.038511551916599274, -0.028268661350011826, 0.16122221946716309, 0.1507580727338791, 0.11021595448255539, -0.030452648177742958, -0.021147122606635094, -0.1020992323756218, 0.006434426177293062, -0.09858203679323196, 0.0315554141998291, -0.1535438895225525, 0.12282673269510269, 0.028705988079309464, 0.1476944088935852, 0.09960770606994629, -0.03475470095872879, 0.04401703551411629, -0.04525720328092575, -0.027046233415603638, -0.007001213263720274, 0.1104671061038971, -0.09440348297357559, 0.07657457143068314, -0.08297447860240936, 0.044753916561603546, 0.08467212319374084, 0.04042038321495056, -0.11809872835874557, -0.06665549427270889, -0.10131323337554932, 0.1401151418685913, -0.1681535691022873, 0.19363655149936676, 0.008668177761137486, -0.004535073414444923, -0.057225149124860764, -0.126212477684021, -0.06938324868679047, 0.29089927673339844, 0.059892892837524414, 0.1761757731437683, -0.24606995284557343, 0.02151559293270111, -0.07322866469621658, 0.0324128121137619, 0.1692914217710495, -0.013309851288795471, 0.025077173486351967, -0.16879001259803772, 0.019893212243914604, -0.07016704976558685, -0.17612726986408234, 0.21628208458423615, -0.06595034897327423, 0.003999244421720505, -0.1586572229862213, 0.009084452874958515, -0.10160451382398605, -0.1595284789800644, -0.02144245244562626, 0.027900835499167442, -0.03516768291592598, 0.05459817871451378, 0.14697782695293427, 0.10918796062469482, 0.01186777837574482, 0.001457724254578352, -0.0004570579912979156, 0.08252418786287308, -0.23511673510074615, -0.012811483815312386, 0.11690652370452881, 0.03534071147441864, -0.016219044104218483, 0.08929178863763809, -0.07471707463264465, 0.078595831990242, 0.040990836918354034, 0.01939210295677185, -0.023588281124830246, 0.03803159296512604, 0.057376839220523834, 0.23206233978271484, -0.034288328140974045, 0.046091366559267044, 0.2595856189727783, 0.15715108811855316, -0.0403948649764061, -0.09693102538585663, 0.11103787273168564, -0.02705671824514866, 0.17256753146648407, 0.2503936290740967, 0.046398431062698364, -1.0018088403285219e-07, -0.030570095404982567, 0.1440996527671814, -0.09996689110994339, 0.10914119333028793, 0.014510679990053177, -0.06370734423398972, -0.028470922261476517, 0.00491948751732707, -0.12894181907176971, 0.010524237528443336, 0.026754550635814667, 0.07650014758110046, -0.055303532630205154, 0.06155676767230034, 0.012140409089624882, -0.04431995376944542, -0.10397670418024063, 0.1408800482749939, -0.0718611627817154, 0.02079971693456173, 0.07738945633172989, -0.07604753971099854, 0.015903882682323456, 0.08174856752157211, 0.051707830280065536, -0.06344453245401382, -0.03290088102221489, -0.053587906062603, 0.05321703851222992, 0.13834422826766968, -0.08790002018213272, -0.1610775738954544, 0.02293936163187027, -0.010050635784864426, 0.10376403480768204, 0.1748015284538269, -0.009440538473427296, -0.05527568608522415, 0.02664411999285221, 0.27791258692741394, -0.1134832575917244, 0.10095430165529251, -0.16672030091285706, -0.08413741737604141, 0.019093254581093788, 0.038515206426382065, -0.004196930676698685, -0.038784705102443695, 0.10777293145656586, 0.038739655166864395, -0.02871568873524666, -0.09397349506616592, -0.04235653579235077, -0.030177177861332893, 0.03627575933933258, -0.029650622978806496, -0.011264124885201454, 0.032378099858760834, 0.03274993598461151, 0.010273938998579979, 0.1530245840549469, -0.07508828490972519, -0.06528190523386002, -0.0006923385080881417], metadata={'source': 'AAAMLP-569to.pdf', 'page': 174}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 175     clf = pipeline.Pipeline(         [             (\\'svd\\', svd),             (\\'scl\\', scl),             (\\'svm\\', svm_model)         ]     )          # Create a parameter grid to search for      # best parameters for everything in the pipeline     param_grid = {         \\'svd__n_components\\' : [200, 300],         \\'svm__C\\': [10, 12]     }          # Kappa Scorer      kappa_scorer = metrics.make_scorer(         quadratic_weighted_kappa,          greater_is_better=True     )          # Initialize Grid Search Model     model = model_selection.GridSearchCV(         estimator=clf,         param_grid=param_grid,         scoring=kappa_scorer,         verbose=10,         n_jobs=-1,         refit=True,         cv=5     )                                           # Fit Grid Search Model     model.fit(X, y)     print(\"Best score: %0.3f\" % model.best_score_)     print(\"Best parameters set:\")     best_parameters = model.best_estimator_.get_params()     for param_name in sorted(param_grid.keys()):      print(\"\\\\t%s: %r\" % (param_name, best_parameters[param_name]))          # Get best model     best_model = model.best_estimator_          # Fit model with best parameters optimized for QWK     best_model.fit(X, y)     preds = best_model.predict(...) ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[-0.17495885491371155, -0.10366019606590271, 0.013635989278554916, 0.011648961342871189, -0.017746148630976677, -0.15600436925888062, -0.010189635679125786, 0.08468743413686752, -0.11941591650247574, 0.00747558893635869, -0.1373942494392395, -0.0013705920428037643, 0.04974006488919258, 0.0061888559721410275, -0.10390099883079529, 0.050160542130470276, 0.06805747002363205, 0.11880455166101456, -0.053728483617305756, -0.016733938828110695, 0.003435758175328374, 0.046575773507356644, -0.07914063334465027, -0.039230335503816605, -0.08682049810886383, -0.10283802449703217, 0.04491211101412773, 0.04033685103058815, -0.08778207004070282, 0.01896340399980545, 0.16177016496658325, -0.033892713487148285, -0.035440634936094284, -0.03153390809893608, -0.052732255309820175, 0.08699432760477066, -0.05610202997922897, -0.03753553330898285, -0.05102261155843735, 0.07689347863197327, -0.08466786891222, -0.0021427783649414778, -0.12666219472885132, 0.0076803783886134624, 0.040563344955444336, 0.059271711856126785, -0.07211884111166, -0.1054588034749031, 0.010145477950572968, 0.009308259934186935, -0.07776273787021637, -0.005902086850255728, -0.08664464205503464, 0.0080237602815032, 0.022430354729294777, -0.022671958431601524, 0.05762830004096031, -0.08120094239711761, 0.0736040398478508, -0.01361195556819439, 0.010712778195738792, -0.20330697298049927, -0.04056517407298088, -0.07889895886182785, 0.05319814756512642, -0.026204358786344528, 0.042412858456373215, -0.06323076039552689, -0.030752617865800858, 0.0762990340590477, -0.029907550662755966, 0.10990827530622482, -0.07277429103851318, 0.05718477442860603, -0.07961776107549667, 0.031484536826610565, 0.15178684890270233, 0.06335585564374924, -0.043267957866191864, -0.016750268638134003, 0.06103820726275444, 0.12171266227960587, -0.030418559908866882, -0.02288678288459778, 0.08101005852222443, -0.04239751026034355, -0.014806116931140423, 0.11092966794967651, 0.17939801514148712, 0.00446627801284194, 0.02553580328822136, 0.037989016622304916, -0.10349765419960022, -0.1233091652393341, 0.060705043375492096, 0.03935444727540016, 0.07351381331682205, -0.09608028829097748, 0.018039753660559654, 0.018829092383384705, -0.015675626695156097, -0.00791484210640192, 0.1799873262643814, -0.07935631275177002, 0.14185893535614014, -0.050607845187187195, 0.021550646051764488, 0.06188451126217842, 0.1317306011915207, -0.08144744485616684, -0.013204301707446575, -0.024681610986590385, 0.039570920169353485, -0.03966543450951576, 0.024564333260059357, 0.15314717590808868, 0.09638883918523788, 0.022503940388560295, -0.1263955682516098, 0.17929542064666748, -0.1263035088777542, -0.041949983686208725, -0.025187432765960693, 0.03849688917398453, 0.10849863290786743, 0.10631569474935532, -0.10323285311460495, 1.3125744776066347e-32, -0.06178317219018936, -0.0062352679669857025, -0.016075825318694115, -0.07878700643777847, -0.022757690399885178, 0.0010234556393697858, 0.09819558262825012, -0.13755002617835999, -0.03547254949808121, 0.03485949710011482, -0.1430273801088333, 0.04402649402618408, -0.060036223381757736, 0.05645835027098656, 0.04922651872038841, 0.012800905853509903, -0.09545227140188217, 0.0005984851741231978, -0.10862888395786285, -0.01325081754475832, 0.23978383839130402, -0.016211459413170815, 0.0500212237238884, -0.05765862390398979, -0.0642356127500534, -0.03155294060707092, 0.061154432594776154, -0.05848703160881996, -0.1377163827419281, -0.009974056854844093, -0.1103939563035965, -0.07430128008127213, -0.06853383034467697, 0.05361301824450493, 0.10140972584486008, -0.10243429243564606, 0.09133241325616837, 0.03875870257616043, -0.04167687147855759, -0.09960498660802841, -0.02101438120007515, 0.02099866047501564, 0.11300283670425415, -0.0251877810806036, -0.13250775635242462, 0.022567765787243843, 0.10217858850955963, 0.028953906148672104, 0.11855251342058182, -0.06943380832672119, -0.004984536208212376, -0.008908359333872795, -0.018925921991467476, -0.018339568749070168, -0.008641141466796398, 0.10802464932203293, 0.07427965104579926, -0.05701153725385666, 0.046841640025377274, -0.014955073595046997, -0.009580900892615318, -0.06035355478525162, -0.014167461544275284, -0.09748086333274841, 0.02433571219444275, -0.07070086896419525, 0.15220683813095093, 0.06132112443447113, 0.0008164299069903791, -0.009164929389953613, -0.0034940773621201515, -0.007542543113231659, 0.07666685432195663, -0.058844178915023804, 0.03225575387477875, 0.01915452443063259, 0.1719902604818344, -0.03331555426120758, 0.0046456302516162395, 0.018010200932621956, -0.06747432053089142, 0.23943760991096497, -0.004555955529212952, -0.1526888906955719, 0.0006781507399864495, -0.06818614900112152, 0.005108005832880735, -0.0822908878326416, -0.22357094287872314, -0.11500765383243561, -0.17044410109519958, 0.037873320281505585, -0.05804384872317314, 0.002148194471374154, -0.07444178313016891, -1.130846063173783e-32, -0.0026376876048743725, -0.09497726708650589, 0.010378249920904636, 0.16001847386360168, 0.0029940283857285976, 0.027915338054299355, 0.000435155990999192, -0.029420936480164528, -0.1404179185628891, -0.15152335166931152, -0.10787225514650345, 0.020967407152056694, -5.859175757905177e-07, 0.03501970320940018, 0.10010477155447006, 0.06346777081489563, -0.058818500488996506, 0.036845896393060684, 0.03069189190864563, -0.03715670481324196, 0.014387421309947968, 0.20238393545150757, -0.1557900458574295, -0.03545299917459488, -0.01929168775677681, 0.015453132800757885, 0.042884379625320435, 0.15018387138843536, 0.02269636280834675, 0.00894229020923376, -0.11481447517871857, 0.10517625510692596, -0.1426677703857422, 0.03651413321495056, -0.000562855857424438, 0.053992003202438354, 0.018130440264940262, -0.038076724857091904, 0.040079809725284576, 0.014911556616425514, 0.04422244802117348, 0.1827896684408188, -0.03870340809226036, -0.025928981602191925, 0.033605679869651794, -0.008072919212281704, -0.058947909623384476, -0.0424400269985199, -0.016281897202134132, -0.013362211175262928, 0.03901682421565056, -0.008835491724312305, -0.09277494996786118, 0.13528425991535187, -0.05642981827259064, 0.041638053953647614, -0.07087206095457077, -0.07154513895511627, 0.01812983676791191, 0.021648278459906578, -0.10167019069194794, 0.02013634331524372, -0.034842196851968765, 0.009975099004805088, -0.06639495491981506, 0.11108342558145523, 0.006082250736653805, -0.00825608428567648, -0.08119092136621475, 0.051796771585941315, -0.13462485373020172, -0.018818221986293793, 0.13684770464897156, 0.02838011644780636, -0.08118360489606857, 0.006339773535728455, 0.008015523664653301, 0.08365955203771591, -0.008153455331921577, -0.07041903585195541, 0.08896484225988388, 0.08329016715288162, 0.010248325765132904, 0.23422537744045258, 0.03358696401119232, 0.13932205736637115, 0.0646766722202301, 0.05576745420694351, 0.10888654738664627, -0.16789133846759796, 0.017469851300120354, -0.04036986455321312, 0.11578865349292755, 0.12449979782104492, -0.059227071702480316, -9.930654698564467e-08, -0.056302011013031006, 0.06801380217075348, 0.021691087633371353, -0.039863310754299164, 0.12967008352279663, -0.013996747322380543, 0.005667949095368385, 0.12601454555988312, -0.040639009326696396, -0.03473861142992973, 0.09608213603496552, 0.019209790974855423, -0.10656251013278961, 0.08992097526788712, -0.016167301684617996, 0.13383464515209198, 0.03129931911826134, 0.0992874801158905, -0.025081057101488113, 0.027074672281742096, 0.05518621578812599, -0.014318619854748249, -0.048690907657146454, 0.10336102545261383, 0.07466095685958862, -0.08524639904499054, 0.05890028178691864, 0.030389711260795593, 0.14263783395290375, 0.09309972077608109, -0.15869826078414917, 0.027175169438123703, -0.05365719273686409, 0.136440247297287, 0.036557652056217194, 0.13203178346157074, -0.05035988986492157, 0.048128023743629456, -0.07640436291694641, -0.01389753632247448, -0.03217159956693649, 0.14734254777431488, -0.07577638328075409, -0.1244034692645073, -0.0010652001947164536, 0.11125534027814865, -0.08412983268499374, -0.07891885936260223, 0.09796210378408432, 0.11417128145694733, 0.07168310135602951, -0.0254190843552351, -0.06315744668245316, 0.10510604828596115, 0.00010494598973309621, -0.053735148161649704, -0.06806681305170059, -0.12568026781082153, 0.024158556014299393, 0.028832651674747467, -0.007540751714259386, 0.05821568891406059, -0.045818038284778595, 0.029693366959691048], metadata={'source': 'AAAMLP-569to.pdf', 'page': 175}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 176  The pipeline shown here has SVD (Singular Value Decomposition), standard scaling and an SVM (Support Vector Machines) model. Please note that you won’t be able to run the above code as it is as training data is not available. When we go into advanced hyperparameter optimization techniques, we can take a look at minimization of functions using different kinds of minimization algorithms. This can be achieved by using many minimization functions such as downhill simplex algorithm, Nelder-Mead optimization, using a Bayesian technique with Gaussian process for finding optimal parameters or by using a genetic algorithm. I will talk more about the application of downhill simplex and Nelder-Mead in ensembling and stacking chapter. First, let’s see how the gaussian process can be used for hyper-parameter optimization. These kinds of algorithms need a function they can optimize. Most of the time, it’s about the minimization of this function, like we minimize loss.   So, let’s say, you want to find the best parameters for best accuracy and obviously, the more the accuracy is better. Now we cannot minimize the accuracy, but we can minimize it when we multiply it by -1. This way, we are minimizing the negative of accuracy, but in fact, we are maximizing accuracy. Using Bayesian optimization with gaussian process can be accomplished by using gp_minimize function from scikit-optimize (skopt) library. Let’s take a look at how we can tune the parameters of our random forest model using this function.  ═════════════════════════════════════════════════════════════════════════ # rf_gp_minimize.py import numpy as np import pandas as pd  from functools import partial  from sklearn import ensemble from sklearn import metrics from sklearn import model_selection  from skopt import gp_minimize from skopt import space   def optimize(params, param_names, x, y):     \"\"\"     The main optimization function.      This function takes all the arguments from the search space     and training features and targets. It then initializes'),\n",
       " VectorParams(vector=[-0.058080945163965225, -0.07109099626541138, 0.029957624152302742, 0.03211464360356331, 0.03720447048544884, -0.08441533148288727, 0.01274343952536583, 0.04793119430541992, -0.18855394423007965, -0.05493977665901184, -0.053040940314531326, -0.21733497083187103, 0.04639999940991402, -0.06274522840976715, -0.12568847835063934, 0.08447693288326263, -0.023692209273576736, 0.01869986765086651, -0.07993211597204208, -0.011228161863982677, 0.03859155625104904, 0.055692560970783234, 0.02336902730166912, 0.04631609469652176, -0.04119689390063286, -0.05890225991606712, -0.03188784793019295, 0.04452866315841675, -0.06839800626039505, -0.10641974210739136, -0.02088909037411213, 0.008727643638849258, -0.005675653927028179, -0.008948191069066525, 0.06124485656619072, -0.005640857387334108, -0.1033768504858017, -0.011125962249934673, -0.049117084592580795, 0.0902189388871193, -0.039805181324481964, -0.033791422843933105, -0.017941979691386223, 0.06026299670338631, 0.06645182520151138, 0.10169291496276855, -0.08990178257226944, -0.024230968207120895, 0.1042071133852005, -0.0243076141923666, -0.03415096551179886, -0.010220714844763279, -0.12368548661470413, -0.049521833658218384, -0.11780156195163727, -0.049066923558712006, -0.06721743196249008, -0.07226124405860901, 0.04509054869413376, -0.060215990990400314, 0.03072807565331459, -0.10665939748287201, -0.06459327787160873, -0.07181057333946228, -0.014680488035082817, 0.011009563691914082, -0.021176449954509735, 0.0331147275865078, -0.05168251320719719, 0.09227240085601807, 0.0564878024160862, 0.14228595793247223, 0.015979886054992676, 0.021293438971042633, 0.02678205445408821, 0.0498499721288681, 0.12251070141792297, -0.03519250079989433, -0.005819134879857302, 0.008543225936591625, -0.1729859709739685, 0.01873723603785038, -0.03446923568844795, -0.08002886921167374, 0.07734771072864532, -0.1542789489030838, 0.091520294547081, -0.02617439068853855, 0.05668788030743599, -0.039030782878398895, 0.18103528022766113, -0.03191110119223595, -0.06290494650602341, 0.0011310772970318794, 0.06319990009069443, 0.12064923346042633, 0.07364791631698608, 0.013863696716725826, -0.06496424227952957, 0.07127019017934799, -0.13537530601024628, 0.06074552610516548, 0.0793447494506836, 0.05972075089812279, 0.07000178098678589, -0.084670789539814, 0.10592343658208847, -0.03331933915615082, 0.08396753668785095, -0.09385690838098526, -0.0022536362521350384, -0.003874048124998808, -0.0027833920903503895, 0.07121781259775162, 0.1036832332611084, 0.24449072778224945, -0.019953712821006775, 0.1172429770231247, -0.07511024922132492, 0.14315691590309143, -0.1523352861404419, 0.10332546383142471, 0.02971881628036499, 0.08468857407569885, -0.0432506687939167, -0.00809794943779707, -0.1117318868637085, 2.1708284701441172e-32, -0.08951711654663086, 0.037699174135923386, 0.10971414297819138, -0.05741169676184654, -0.056078583002090454, -0.13208800554275513, -0.048702795058488846, -0.027870595455169678, -0.05385354161262512, 0.050640713423490524, -0.19039253890514374, 0.06727050989866257, 0.027697721496224403, 0.0072586494497954845, 0.08199403434991837, -0.007872391492128372, -0.08021683990955353, 0.015146181918680668, -0.09058526158332825, 0.11619976162910461, 0.32626667618751526, -0.07717720419168472, 0.0072274040430784225, -0.15104787051677704, -0.17183931171894073, 0.06250681728124619, -0.03837632015347481, 0.06788305193185806, -0.1749146431684494, 0.059571098536252975, -0.20980849862098694, -0.028974903747439384, 0.0019251882331445813, 0.02817635051906109, -0.008523889817297459, -0.06447239965200424, 0.04214320331811905, 0.09573902934789658, -0.07858995348215103, -0.008670290932059288, -0.06063307449221611, 0.014415569603443146, 0.024822646751999855, -0.04404477775096893, -0.019997933879494667, -0.09248808026313782, 0.05570102855563164, 0.08835958689451218, 0.04294831305742264, 0.16103309392929077, -0.04883994907140732, -0.12816834449768066, -0.09556053578853607, 0.00457629282027483, -0.13577261567115784, 0.15479831397533417, 0.128571018576622, 0.015244352631270885, 0.07300285249948502, 0.039424456655979156, -0.037634097039699554, -0.03992047533392906, -0.0662556141614914, -0.051719944924116135, 0.04042436555027962, 0.04752597212791443, 0.02885734662413597, -0.03467442840337753, 0.060628850013017654, 0.022499946877360344, -0.19385342299938202, 0.05296134576201439, -0.10730305314064026, -0.05175812914967537, 0.13412316143512726, -0.11430542916059494, 0.10264136642217636, 0.05481964722275734, -0.015930308029055595, -0.04655474051833153, 0.05247297137975693, 0.19887393712997437, -0.12819421291351318, -0.25793248414993286, 0.008834613487124443, -0.07809481024742126, 0.06217321753501892, 0.002218578476458788, -0.20199526846408844, -0.023455815389752388, -0.19680388271808624, 0.01140884030610323, 0.024528078734874725, -0.06087420880794525, -0.07267134636640549, -2.0800587065519403e-32, 0.0783616378903389, -0.011662133038043976, 0.12345341593027115, 0.11007518321275711, 0.03612707927823067, 0.06319078803062439, 0.11014950275421143, 0.09339361637830734, -0.08050297945737839, -0.1342000514268875, 0.029069265350699425, -0.062637098133564, 0.11366190761327744, 0.07484136521816254, 0.06873913109302521, 0.031121892854571342, -0.05977741256356239, 0.08796785771846771, -0.01703956536948681, 0.009225590154528618, -0.06908901780843735, 0.1138097420334816, -0.15329989790916443, -0.05722074583172798, -0.12512968480587006, 0.04471120238304138, 0.0012814197689294815, 0.11550051718950272, 0.07732480019330978, -0.11208692193031311, 0.004207295831292868, 0.06981697678565979, -0.14744217693805695, 0.1130264550447464, 0.046456169337034225, -0.08404877781867981, -0.04064479470252991, -0.07718995213508606, -0.014359871856868267, 0.07659581303596497, 0.08363798260688782, 0.17739960551261902, -0.16515135765075684, 0.025189321488142014, -0.0023706716019660234, -0.003455938072875142, -0.07929621636867523, 0.012969942763447762, 0.001500672660768032, -0.12105131894350052, -0.028793998062610626, -0.038027431815862656, -0.13866150379180908, -0.0005288231186568737, -0.03208746388554573, 0.06804610043764114, -0.07596792280673981, -0.043693095445632935, -0.034969061613082886, 0.06836888194084167, -0.06462571769952774, 0.013102279976010323, 0.004658577032387257, -0.05173535272479057, 0.12538914382457733, 0.03779972717165947, -0.04131566733121872, 0.050564270466566086, 0.03801828250288963, 0.09891534596681595, -0.18311448395252228, 0.0554671585559845, -0.01128243375569582, -0.1616974025964737, -0.006827039178460836, 0.018990924581885338, -0.04633086174726486, 0.08641368895769119, 0.08084756880998611, -0.010534869506955147, -0.050979554653167725, -0.06323818117380142, 0.037081874907016754, 0.17641326785087585, 0.01982591487467289, 0.103518545627594, 0.14772069454193115, 0.12754105031490326, 0.06093169376254082, -0.03612223267555237, 0.043532438576221466, -0.020113995298743248, 0.11472994089126587, 0.2719300091266632, 0.012589589692652225, -1.011686947549606e-07, -0.012357077561318874, 0.13008034229278564, 0.007552505005151033, 0.16616058349609375, 0.0391780361533165, 0.00038766127545386553, -0.11867354065179825, -0.041819341480731964, -0.086574025452137, -0.04979850724339485, 0.15477637946605682, -0.026001879945397377, -0.12729761004447937, 0.1341170072555542, -0.06464209407567978, -0.019982067868113518, -0.0701819583773613, 0.18357397615909576, 0.0034826970659196377, 0.06237870082259178, 0.022570405155420303, -0.12934239208698273, 0.0678720772266388, -0.03412748500704765, 0.07433625310659409, -0.06814102083444595, 0.024335239082574844, 0.07764896750450134, 0.03790602833032608, 0.04515962675213814, -0.016880236566066742, -0.11494377255439758, -0.005165125243365765, 0.04553825408220291, -0.009432831779122353, 0.10460736602544785, 0.022052258253097534, 0.028171846643090248, 0.0709574818611145, 0.17150400578975677, -0.05803705379366875, 0.09929278492927551, -0.1488083302974701, -0.06244179606437683, 0.01730627752840519, -0.012786345556378365, 0.07379642128944397, -0.12733380496501923, 0.08038773387670517, 0.009551956318318844, -0.007049675565212965, -0.08184551447629929, -0.1169726625084877, 0.030550232157111168, 0.07064299285411835, 0.04110795632004738, -0.1259629875421524, -0.09770072251558304, -0.07132411748170853, 0.003779607592150569, -0.04520237445831299, -0.14392654597759247, -0.0985441580414772, 0.06617415696382523], metadata={'source': 'AAAMLP-569to.pdf', 'page': 176}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 177     the models by setting the chosen parameters and runs      cross-validation and returns a negative accuracy score     :param params: list of params from gp_minimize     :param param_names: list of param names. order is important!     :param x: training data     :param y: labels/targets     :return: negative accuracy after 5 folds     \"\"\"     # convert params to dictionary     params = dict(zip(param_names, params))      # initialize model with current parameters     model = ensemble.RandomForestClassifier(**params)      # initialize stratified k-fold     kf = model_selection.StratifiedKFold(n_splits=5)      # initialize accuracy list     accuracies = []      # loop over all folds     for idx in kf.split(X=x, y=y):         train_idx, test_idx = idx[0], idx[1]         xtrain = x[train_idx]         ytrain = y[train_idx]          xtest = x[test_idx]         ytest = y[test_idx]          # fit model for current fold         model.fit(xtrain, ytrain)          #create predictions         preds = model.predict(xtest)          # calculate and append accuracy         fold_accuracy = metrics.accuracy_score(             ytest,             preds         )         accuracies.append(fold_accuracy)          # return negative accuracy     return -1 * np.mean(accuracies)   if __name__ == \"__main__\":'),\n",
       " VectorParams(vector=[-0.036154597997665405, -0.039806850254535675, -0.046682074666023254, 0.0015310727758333087, 0.004413514398038387, -0.050201430916786194, 0.019571123644709587, 0.03895709663629532, -0.13986632227897644, -0.06014960631728172, 0.0005454266793094575, -0.08855992555618286, 0.03233238309621811, -0.027268346399068832, 0.045707013458013535, 0.03124273754656315, 0.0814397782087326, 0.03678424283862114, -0.1573014259338379, -0.05995059758424759, 0.09411527216434479, 0.17108844220638275, -0.026357444003224373, 0.011480889283120632, -0.05879294499754906, -0.15573656558990479, 0.03606489673256874, 0.10297206789255142, -0.13978372514247894, -0.0012768275337293744, 0.014072130434215069, 0.012821389362215996, -0.057111915200948715, 0.0793599784374237, 0.07726443558931351, 0.02258387766778469, -0.15706394612789154, -0.03360305353999138, -0.03127216920256615, 0.10478109866380692, -0.15359681844711304, 0.06674235314130783, -0.07851055264472961, -0.021791083738207817, 0.0510161854326725, 0.05512187257409096, -0.04077097773551941, 0.0066562616266310215, 0.10409866273403168, -0.035993415862321854, -0.08096621930599213, 0.180153027176857, -0.07733602821826935, 0.024334095418453217, -0.04962925985455513, -0.13898499310016632, -0.013241930864751339, -0.20304468274116516, 0.14874866604804993, -0.11523587256669998, -0.08447255194187164, -0.0529763363301754, 0.0545593798160553, -0.06987587362527847, -0.01412578672170639, -0.15656007826328278, -0.08561337739229202, 0.033855192363262177, -0.007421188987791538, 0.08616039156913757, 0.0169646218419075, 0.11880466341972351, -0.15696260333061218, -0.0761261060833931, 0.02166244573891163, 0.00746076600626111, 0.25478145480155945, -0.0527295283973217, 0.06245569512248039, -0.07335051149129868, -0.02918337844312191, 0.023424837738275528, 0.014858758077025414, 0.035686712712049484, 0.04010653868317604, -0.18683871626853943, -0.025187550112605095, 0.0898742526769638, 0.10241912305355072, -0.04652988538146019, 0.10658154636621475, 0.034801095724105835, -0.06576036661863327, 0.06713049858808517, 0.0024239972699433565, 0.021478751674294472, 0.03443966060876846, -0.12351515889167786, -0.050079550594091415, 0.06489909440279007, -0.07126566767692566, -0.11641769856214523, 0.07203441113233566, -0.11157533526420593, -0.003265921724960208, 0.0018667323747649789, 0.10547231882810593, 0.07105690985918045, 0.11417409777641296, -0.07636625319719315, -0.045949190855026245, -0.12504670023918152, -0.13353967666625977, -0.04804712161421776, -0.04718856140971184, 0.15566614270210266, 0.03759349137544632, 0.008766598999500275, -0.057570163160562515, 0.03838777169585228, -0.04382884129881859, 0.015314324758946896, -0.031149854883551598, 0.07608768343925476, 6.524170021293685e-05, -0.015342078171670437, -0.10931897908449173, 9.625299658154168e-33, -0.12706376612186432, -0.1506069302558899, -0.01962330751121044, -0.15792280435562134, -0.024610610678792, 0.01379817072302103, 0.09736853837966919, 0.03569287434220314, 0.002848970703780651, 0.04556651785969734, -0.21152842044830322, 0.1242976039648056, -0.16589079797267914, -0.03263791278004646, 0.10028702020645142, -0.1108691394329071, -0.0360616110265255, 0.027001023292541504, 0.0004335216945037246, 0.04690926522016525, 0.1014014258980751, -0.032749276608228683, 0.03407879173755646, -0.030290840193629265, -0.03139437362551689, 0.006836738903075457, 0.007545849308371544, -0.054617900401353836, -0.08155521750450134, 0.01254019234329462, -0.2197473645210266, 0.009881346486508846, -0.011502854526042938, 0.02507811412215233, 0.009489035233855247, -0.06788533926010132, 0.0902751013636589, 0.050535816699266434, -0.015811864286661148, -0.037363793700933456, -0.126791849732399, 0.06777625530958176, 0.09459639340639114, 0.07400250434875488, -0.06419287621974945, 0.027059409767389297, 0.06701375544071198, 0.10980742424726486, 0.027319302782416344, 0.11347382515668869, -0.12836512923240662, -0.05694776400923729, 0.04171118140220642, -0.04094279557466507, -0.17162977159023285, 0.012623168528079987, -0.061534333974123, 0.029555045068264008, 0.09119769930839539, -0.04275888949632645, -0.07830173522233963, -0.04608479142189026, 0.10059663653373718, 0.01818881370127201, 0.08614859730005264, 0.02323492430150509, 0.09146197885274887, 0.051602642983198166, 0.18971221148967743, 0.10950160771608353, -0.03221655637025833, 0.010295013897120953, 0.11058174818754196, -0.07153717428445816, 0.17065125703811646, -0.04079177603125572, 0.1321747899055481, 0.00041325308848172426, -0.13831765949726105, -0.017793847247958183, -0.006348481867462397, 0.1730949580669403, -0.03192407637834549, -0.07434727251529694, 0.04053785651922226, -0.0384477861225605, 0.08517809957265854, -0.01732458360493183, -0.14242099225521088, -0.12771563231945038, -0.23089797794818878, 0.08601433038711548, -0.08808866143226624, -0.015378832817077637, 0.06444865465164185, -1.0021794637370494e-32, -0.023974550887942314, 0.10520175844430923, 0.0783473327755928, 0.020656846463680267, 0.05715801939368248, 0.007301142904907465, -0.05907784402370453, -0.034555867314338684, 0.00522221252322197, -0.06012294068932533, -0.09301590919494629, -0.03600415214896202, 0.08947096765041351, -0.007861289195716381, -0.009696501307189465, 0.13960091769695282, -0.17174066603183746, 0.04846245422959328, -0.07518485933542252, 0.06437963247299194, -0.11863137036561966, 0.1953173279762268, -0.24970769882202148, 0.06446637213230133, -0.12395067512989044, 0.023872075602412224, -0.0406009815633297, 0.09316720068454742, 0.08732286095619202, -0.04563508927822113, -0.10627458989620209, 0.14802224934101105, -0.16338081657886505, 0.03935224935412407, 0.016945146024227142, -0.04267173260450363, 0.10845449566841125, -0.0426800474524498, -0.10256889462471008, 0.11590005457401276, 0.16589301824569702, 0.10991083085536957, -0.031094064936041832, 0.024074377492070198, 0.0737423226237297, 0.10052376985549927, 0.09389788657426834, -0.15261448919773102, 0.010837344452738762, -0.010909255594015121, -0.025736963376402855, -0.022989952936768532, -0.14675940573215485, 0.10344576835632324, -0.01804574579000473, 0.02117769606411457, -0.05008324980735779, -0.014526523649692535, -0.014883441850543022, -0.062230926007032394, 0.043918415904045105, 0.04255182668566704, 0.012647302821278572, -0.04039689525961876, 0.049451932311058044, -0.04556303471326828, -0.023719744756817818, -0.09060601890087128, 0.016627181321382523, 0.09380054473876953, -0.16325369477272034, 0.032534584403038025, 0.18122440576553345, -0.05108945444226265, -0.10865788906812668, 0.09727641940116882, 0.021607566624879837, -0.04076792672276497, 0.03642358258366585, 0.09505867213010788, 0.08142700046300888, 0.027136562392115593, 0.06269840151071548, 0.16308224201202393, -0.0017639773432165384, 0.09671293944120407, 0.07685866206884384, 0.17552435398101807, -0.02451169304549694, 3.757631202461198e-05, 0.006763842422515154, -0.08869641274213791, 0.1394747942686081, 0.1147925928235054, -0.13540472090244293, -1.002495579882634e-07, 0.0562591627240181, 0.12180248647928238, 0.00651666522026062, -0.041596680879592896, 0.08001542091369629, 0.023954467847943306, -0.019779805094003677, 0.06545274704694748, 0.0017783785006031394, -0.004077942110598087, 0.10294634848833084, 0.049441829323768616, -0.016105277463793755, 0.0959688052535057, -0.11638493835926056, 0.06198137626051903, -0.0021667403634637594, -0.012628906406462193, 0.009945357218384743, 0.11625555157661438, 0.0508839376270771, -0.02148977853357792, -0.08296874165534973, -0.006043642293661833, 0.07651432603597641, -0.14487114548683167, 0.022135961800813675, -0.015483192168176174, 0.10104979574680328, 0.04218749701976776, -0.022297034040093422, -0.10290616005659103, 0.004666118882596493, -0.0029726894572377205, 0.013360647484660149, 0.06351428478956223, 0.05574912577867508, -0.033188220113515854, -0.04871334135532379, 0.05398382246494293, -0.08825759589672089, 0.04448901116847992, -0.07420840859413147, -0.0773220956325531, 0.03808746859431267, -0.04299755394458771, 0.052805230021476746, -0.06930629163980484, 0.1366654634475708, 0.08912402391433716, 0.004536010790616274, -0.03393077850341797, -0.0882720947265625, 0.010106133297085762, 0.16549406945705414, -0.07528895884752274, -0.14207719266414642, 0.04827306792140007, -0.06250081956386566, -0.07848154008388519, 0.02166237123310566, 0.004881871864199638, -0.05433500185608864, 0.03258420154452324], metadata={'source': 'AAAMLP-569to.pdf', 'page': 177}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 178     # read the training data     df = pd.read_csv(\"../input/mobile_train.csv\")      # features are all columns without price_range     # note that there is no id column in this dataset     # here we have training features     X = df.drop(\"price_range\", axis=1).values     # and the targets     y = df.price_range.values      # define a parameter space     param_space = [         # max_depth is an integer between 3 and 10         space.Integer(3, 15, name=\"max_depth\"),         # n_estimators is an integer between 50 and 1500         space.Integer(100, 1500, name=\"n_estimators\"),         # criterion is a category. here we define list of categories         space.Categorical([\"gini\", \"entropy\"], name=\"criterion\"),         # you can also have Real numbered space and define a          # distribution you want to pick it from         space.Real(0.01, 1, prior=\"uniform\", name=\"max_features\")     ]      # make a list of param names     # this has to be same order as the search space     # inside the main function     param_names = [         \"max_depth\",         \"n_estimators\",         \"criterion\",         \"max_features\"     ]      # by using functools partial, i am creating a      # new function which has same parameters as the      # optimize function except for the fact that     # only one param, i.e. the \"params\" parameter is     # required. this is how gp_minimize expects the      # optimization function to be. you can get rid of this     # by reading data inside the optimize function or by     # defining the optimize function here.     optimization_function = partial(         optimize,         param_names=param_names,         x=X,         y=y     )'),\n",
       " VectorParams(vector=[-0.20843541622161865, -0.061597637832164764, -0.013693359680473804, -0.00252961041405797, 0.029889890924096107, -0.13498876988887787, 0.003930206410586834, 0.05046723783016205, 0.0071888817474246025, 0.012568301521241665, -0.06436450779438019, 0.09707809239625931, 0.020811332389712334, 0.006084955297410488, -0.06667476147413254, 0.052602194249629974, 0.06499136239290237, -0.042708832770586014, -0.008666601963341236, -0.050082240253686905, 0.04667657986283302, 0.11498606950044632, -0.008475621230900288, 0.02634686417877674, -0.07539696991443634, -0.04519755765795708, 0.0861397534608841, 0.10781879723072052, 0.004597187042236328, -0.012724566273391247, 0.14814677834510803, -0.0027943807654082775, -0.023387787863612175, -0.02337680384516716, 0.09793349355459213, 0.08967829495668411, -0.15891391038894653, -0.10299026221036911, -0.0694655030965805, 0.0461636483669281, -0.08312516659498215, 0.04642128199338913, -0.021366940811276436, 0.10601449012756348, 0.12242638319730759, 0.030773097649216652, -0.10922346264123917, -0.09682729840278625, 0.10120972990989685, -0.12306278198957443, -0.14330226182937622, 0.1267259567975998, -0.07855530083179474, 0.0051947543397545815, 0.06678224354982376, -0.07355155050754547, -0.020881082862615585, -0.13466086983680725, 0.0892830640077591, -0.12403874099254608, 0.062421366572380066, -0.11595723032951355, -0.06376727670431137, -0.06857556104660034, -0.030055446550250053, -0.04251199588179588, 0.08712048828601837, -0.0627022534608841, 0.009410745464265347, 0.13608692586421967, -0.010049874894320965, 0.09813724458217621, -0.0999169871211052, -0.06285171955823898, 0.05739699676632881, -0.047389086335897446, 0.1349349468946457, 0.013759404420852661, -0.01768781803548336, -0.04153605177998543, 0.04358048737049103, 0.07587111741304398, 0.050196170806884766, -0.049882903695106506, -0.08740326762199402, -0.12704207003116608, -0.04701168090105057, 0.027400564402341843, 0.17856045067310333, 0.004272283986210823, 0.0020821874495595694, 0.006528314668685198, -0.21921543776988983, -0.032450322061777115, 0.008136211894452572, 0.047833289951086044, 0.08010585606098175, -0.02877059392631054, -0.035785410553216934, 0.05080895125865936, -0.006634796503931284, 0.011388817802071571, 0.08298645168542862, -0.17340652644634247, 0.09175202995538712, -0.01851304993033409, 0.06375632435083389, 0.05236539617180824, 0.13985851407051086, 0.008962399326264858, -0.005404934287071228, -0.037492863833904266, 0.010970750823616982, 0.027498042210936546, 0.06560342013835907, 0.11231745034456253, -0.023992788046598434, 0.01631692424416542, -0.06417088210582733, 0.19951991736888885, -0.07396882027387619, -0.005111228208988905, -0.08882583677768707, 0.0719451978802681, -0.052568379789590836, 0.03350101783871651, -0.05957530066370964, 9.474585119331426e-33, -0.015013450756669044, -0.021065684035420418, 0.08840826898813248, -0.1820371150970459, -0.038001250475645065, 0.07642661780118942, 0.005750519223511219, -0.04962773621082306, -0.08808179944753647, 0.03895081207156181, -0.14347954094409943, -0.008033678866922855, -0.14989858865737915, -0.0101389205083251, 0.1117636039853096, -0.11035650968551636, 0.001258336240425706, 0.06506199389696121, -0.09450161457061768, 0.021031321957707405, 0.11759787797927856, -0.02263166382908821, 0.06688883900642395, -0.1636943817138672, -0.08201117813587189, 0.03181206062436104, 0.012136387638747692, -0.04102807864546776, -0.11588333547115326, 0.04225970804691315, -0.1795967072248459, 0.0367356538772583, -0.0759756937623024, 0.08129645138978958, 0.043104805052280426, -0.06981917470693588, 0.14450103044509888, -0.02955668792128563, -0.01153087243437767, -0.05513046681880951, -0.08093850314617157, 0.05356435850262642, 0.15327197313308716, 0.002449244726449251, -0.031214499846100807, -0.008742155507206917, 0.05101978778839111, 0.03662389889359474, 0.023410487920045853, 0.09021984785795212, -0.03921416774392128, -0.02107258141040802, -0.07271887362003326, -0.026668235659599304, -0.013166195712983608, 0.05743836238980293, 0.08478310704231262, -0.09299512952566147, 0.01010176632553339, 0.05247870087623596, 0.054638780653476715, -0.07748293876647949, -0.0269264318048954, -0.020261911675333977, 0.020909132435917854, 0.023955756798386574, 0.09337692707777023, 0.08083909004926682, 0.171237975358963, 0.10199566185474396, -0.05981776490807533, 0.06825808435678482, 0.04830476641654968, -0.15481312572956085, 0.21139822900295258, -0.09243465214967728, 0.16262832283973694, -0.05259587988257408, -0.02766728214919567, 0.009720948524773121, -0.07024083286523819, 0.04402779042720795, -0.06485994160175323, -0.147898867726326, -0.038309548050165176, -0.0822349414229393, 0.06160799041390419, 0.010832114145159721, -0.20634905993938446, -0.1581568419933319, -0.22557103633880615, 0.006985379382967949, 0.026086829602718353, 0.08300787955522537, -0.12537440657615662, -1.0710675469254634e-32, 0.06574659049510956, -0.11734559386968613, 0.07525430619716644, 0.12560053169727325, 0.0142509825527668, -0.003934786189347506, -0.023919187486171722, -0.01656113751232624, -0.05760148540139198, -0.12107248604297638, -0.022958748042583466, -0.05633213743567467, 0.07899001240730286, 0.034838464111089706, 0.05922292172908783, 0.1653560847043991, -0.06146275997161865, 0.04067067429423332, -0.025563014671206474, -0.0592825785279274, -0.024046465754508972, 0.14242501556873322, -0.11958526819944382, -0.049920618534088135, -0.05344744399189949, -0.01600620150566101, -0.009863045997917652, 0.12761422991752625, 0.08138898015022278, 0.01440523099154234, -0.015405809506773949, 0.06831587851047516, -0.1714385598897934, 0.1535465121269226, 0.001699497690424323, 0.06108647212386131, 0.0069899787195026875, -0.02913687378168106, 0.00016809366934467107, 0.010173140093684196, 0.15924598276615143, 0.05289175733923912, -0.05402091518044472, -0.04023793712258339, 0.03983902186155319, 0.032637737691402435, 0.026770394295454025, -0.07091249525547028, 0.04211101308465004, -0.0430339016020298, 0.07891596108675003, -0.01923133246600628, -0.1020636186003685, 0.15645278990268707, -0.11893026530742645, 0.037286046892404556, -0.1810356080532074, 0.03813624009490013, 0.009205489419400692, -0.0614713691174984, 0.043193116784095764, -0.005669689737260342, 0.027708275243639946, 0.05522880330681801, 0.03259638324379921, 0.12162478268146515, -0.07887337356805801, -0.03391803056001663, 0.02834228053689003, 0.11435603350400925, -0.13193854689598083, 0.006951914634555578, 0.041023869067430496, 0.03205865994095802, -0.05702699348330498, 0.11997286230325699, 0.0376744344830513, -0.06409009546041489, -0.06842625886201859, -0.06459929794073105, 0.015643160790205002, 0.06915783882141113, 0.023207521066069603, 0.14255273342132568, 0.00026702880859375, 0.03597990795969963, 0.11530184745788574, 0.08177538216114044, 0.07799060642719269, -0.08642394840717316, -0.012073874473571777, 0.07034478336572647, 0.05160222202539444, 0.11157441139221191, -0.05106773599982262, -1.0034741393383229e-07, -0.13767306506633759, -0.008858705870807171, 0.02682737074792385, -0.015932878479361534, 0.1933661699295044, 0.022178491577506065, 0.08149223029613495, 0.006428849417716265, -0.05884530767798424, -0.1377549171447754, 0.12632670998573303, -0.05241919681429863, -0.06979047507047653, 0.049080003052949905, -0.0781528502702713, 0.06596769392490387, 0.0006265914416871965, -0.04342666640877724, 0.043241340667009354, -0.011000595986843109, -0.07016244530677795, 0.0007605765131302178, -0.01348003838211298, -0.10225379467010498, -0.11250970512628555, -0.09151163697242737, -0.04089253395795822, 0.05724272131919861, 0.06657355278730392, -0.006986074149608612, -0.05275952070951462, -0.10224063694477081, -0.0411863811314106, 0.10050397366285324, -0.07944086194038391, 0.06846115738153458, -0.04975678026676178, 0.021991273388266563, 0.0030531107913702726, -0.031340960413217545, -0.062384381890296936, 0.09674061089754105, -0.011903798207640648, -0.05913901701569557, 0.01901727169752121, 0.02381961978971958, 0.08123192191123962, -0.04698284715414047, 0.07172798365354538, 0.03094181977212429, 0.04554307088255882, 0.053268060088157654, -0.10103867948055267, -0.01658668741583824, 0.1326221376657486, 0.0007437714375555515, -0.13184890151023865, -0.0731377974152565, -0.09031723439693451, 0.03541750833392143, -0.05732042342424393, 0.024267544969916344, -0.0703437551856041, 0.13934825360774994], metadata={'source': 'AAAMLP-569to.pdf', 'page': 178}, content=\"Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 179      # now we call gp_minimize from scikit-optimize     # gp_minimize uses bayesian optimization for      # minimization of the optimization function.     # we need a space of parameters, the function itself,     # the number of calls/iterations we want to have     result = gp_minimize(         optimization_function,         dimensions=param_space,         n_calls=15,         n_random_starts=10,         verbose=10     )      # create best params dict and print it     best_params = dict(         zip(             param_names,             result.x         )     )     print(best_params) ═════════════════════════════════════════════════════════════════════════  Yet again, this produces a lot of output, and the last part of it is shown below.  ═════════════════════════════════════════════════════════════════════════ Iteration No: 14 started. Searching for the next optimal point. Iteration No: 14 ended. Search finished for the next optimal point. Time taken: 4.7793 Function value obtained: -0.9075 Current minimum: -0.9075 Iteration No: 15 started. Searching for the next optimal point. Iteration No: 15 ended. Search finished for the next optimal point. Time taken: 49.4186 Function value obtained: -0.9075 Current minimum: -0.9075 {'max_depth': 12, 'n_estimators': 100, 'criterion': 'entropy', 'max_features': 1.0} ═════════════════════════════════════════════════════════════════════════  It seems like we have managed to crack 0.90 accuracy. That’s just amazing!  We can also see (plot) how we achieved convergence by using the following snippet.\"),\n",
       " VectorParams(vector=[-0.07468841224908829, -0.06034542992711067, 0.00153067905921489, -0.01373429223895073, 0.0904950499534607, -0.21824386715888977, -0.017666898667812347, 0.061579518020153046, -0.11636270582675934, -0.014463672414422035, -0.09397769719362259, -0.027646051719784737, -0.18268278241157532, -0.06101537495851517, -0.03115144371986389, 0.016315270215272903, 0.06668463349342346, -0.1253773272037506, 0.10112112015485764, -0.08272961527109146, 0.005597739480435848, 0.09570019692182541, -0.049045246094465256, 0.00240151584148407, 0.03881591558456421, -0.26601269841194153, 0.06342335790395737, 0.16368669271469116, -0.12384045869112015, 0.012911736965179443, 0.05572796240448952, -0.09389578551054001, -0.17073030769824982, 0.06585761904716492, -0.04088117182254791, 0.012092001736164093, -0.02245296910405159, -0.11258058249950409, 0.06234341487288475, 0.06697754561901093, -0.14694012701511383, 0.03176238015294075, -0.1347380131483078, -0.06294813752174377, 0.0471331812441349, 0.0615878626704216, -0.17062577605247498, -0.10966171324253082, -0.03922932222485542, 0.016361000016331673, -0.16324470937252045, -0.08575921505689621, -0.09740960597991943, 0.015884017571806908, 0.09344559907913208, -0.036674946546554565, -0.015033239498734474, -0.16414567828178406, 0.12932927906513214, -0.13210555911064148, -0.019775982946157455, -0.0876680314540863, -0.13081765174865723, -0.0740964263677597, 0.046115629374980927, -0.06234432011842728, 0.15070106089115143, 0.01795295439660549, 0.04411124438047409, 0.14434796571731567, -0.029306286945939064, 0.15131056308746338, -0.0018525589257478714, 0.0530393086373806, 0.0790189728140831, 0.062316279858350754, 0.003142774570733309, 0.04647662490606308, 0.016491243615746498, -0.1732078343629837, 0.09108684957027435, 0.2137359231710434, -0.04038846865296364, 0.018351813778281212, -0.008771223947405815, -0.19014465808868408, -0.09426280856132507, 0.08535829931497574, 0.20533020794391632, -0.021260755136609077, 0.13099029660224915, 0.04141456261277199, -0.06308538466691971, 0.06113550439476967, -0.035772766917943954, 0.07977452129125595, 0.15773414075374603, -0.20633481442928314, -0.048282939940690994, 0.10174793750047684, -0.0016283877193927765, -0.10335948318243027, 0.17454417049884796, -0.1425049901008606, 0.08387734740972519, -0.11192753165960312, 0.06822055578231812, 0.029952220618724823, 0.17161162197589874, -0.10848106443881989, 0.05745521932840347, 0.0062345098704099655, 0.002876594662666321, 0.10140874236822128, 0.027048800140619278, 0.12001067399978638, 0.010214895941317081, 0.04287115857005119, -0.1052003875374794, 0.1589578539133072, -0.14517807960510254, 0.04886714741587639, -0.10474055260419846, 0.11365871876478195, 0.07164976745843887, 0.025786809623241425, -0.17143267393112183, 1.7238439514448592e-32, 0.05601278319954872, 0.0223520677536726, 0.08316957205533981, -0.2581312358379364, -0.10620252043008804, 0.01354814600199461, 0.022617731243371964, -0.1357213854789734, 0.038070470094680786, 0.08741912245750427, -0.2518581748008728, -0.12738244235515594, -0.13933973014354706, -0.0764220803976059, 0.03795352578163147, -0.13781465590000153, -0.11581877619028091, 0.2355945110321045, -0.11876674741506577, 0.021750057116150856, 0.1053973138332367, 0.0029087907169014215, -0.04702131077647209, -0.09205224364995956, 0.0019468378741294146, 0.08069393038749695, -0.02534208446741104, -0.014640526846051216, -0.15171237289905548, 0.12714223563671112, -0.1092144325375557, 0.006102732848376036, -0.04756857827305794, -0.007512478623539209, 0.010493515059351921, -0.11857716739177704, 0.050817642360925674, -0.02655276283621788, -0.004401355981826782, -0.06393229961395264, -0.03660530596971512, 0.05207916349172592, 0.08663871884346008, -0.04386015608906746, -0.023747097700834274, 0.06219075992703438, -0.030088050290942192, 0.13917574286460876, 0.11434681713581085, 0.06525867432355881, -0.18822500109672546, -0.11547570675611496, -0.0199333094060421, 0.05135933309793472, -0.07167481631040573, 0.06439610570669174, 0.08818849921226501, 0.03843497484922409, 0.059169888496398926, -0.006069558206945658, 0.07424379885196686, -0.16508398950099945, 0.0778007060289383, -0.10087966173887253, 0.10986030101776123, -0.04173718020319939, -0.012932460755109787, -0.0501219667494297, -0.029147062450647354, 0.10604282468557358, -0.05186550319194794, 0.03719210624694824, -0.09062213450670242, -0.1362486481666565, 0.11242274194955826, -0.10263977199792862, 0.20393289625644684, 0.10808911174535751, -0.16172434389591217, -0.04884461686015129, -0.09168902784585953, 0.1947537362575531, 0.015022220090031624, -0.23220546543598175, 0.08898413181304932, -0.18503889441490173, 0.06989416480064392, 0.04631107673048973, -0.23144182562828064, -0.12605947256088257, -0.10946094244718552, 0.11119653284549713, -0.01366625539958477, 0.08550179749727249, -0.05384374037384987, -1.7306236151132267e-32, 0.020958514884114265, 0.00298454356379807, 0.20650465786457062, 0.1852361559867859, 0.06276201456785202, 0.14072909951210022, -0.13228699564933777, -0.059032078832387924, -0.16823935508728027, -0.11040006577968597, 0.0241140965372324, -0.0633484348654747, 0.03581995144486427, -0.03655889630317688, 0.17413337528705597, 0.08287796378135681, -0.015998609364032745, -0.016585521399974823, 0.12663774192333221, 0.011506222188472748, -0.09273626655340195, 0.034376632422208786, -0.0004300289147067815, 0.09127341210842133, -0.0945013165473938, -0.06801361590623856, -0.11653786897659302, 0.07013595104217529, 0.09534287452697754, -0.02820117212831974, -0.14178535342216492, 0.18588882684707642, -0.11732860654592514, -0.020774345844984055, 0.07567448168992996, 0.0689576119184494, 0.09679491817951202, 0.0363646000623703, -0.036823391914367676, 0.17762507498264313, 0.17265670001506805, 0.14167754352092743, -0.03449445590376854, -0.0043680667877197266, -0.01419476792216301, 0.07244986295700073, -0.06378259509801865, -0.10564268380403519, 0.07321124523878098, 0.016744835302233696, 0.005315341986715794, -0.032533638179302216, 0.03919659182429314, -0.051877401769161224, -0.1202174574136734, 0.09680268913507462, -0.044578034430742264, 0.055765967816114426, -0.021426163613796234, -0.039516717195510864, -0.21117796003818512, -0.0020563232246786356, -0.06737910211086273, 0.04068674519658089, -0.10766951739788055, 0.01667999103665352, 0.03678835555911064, -0.04053099453449249, 0.06658948212862015, -0.0029698614962399006, -0.04883556067943573, 0.04543967545032501, 0.028505269438028336, 0.005199517123401165, -0.12635907530784607, 0.0247499980032444, 0.08212451636791229, 0.048644136637449265, 0.0070970128290355206, -0.07112130522727966, 0.18797342479228973, 0.12009748816490173, 0.14419595897197723, 0.15821458399295807, -0.05025380849838257, 0.18694955110549927, 0.1561124473810196, 0.1899617612361908, 0.031468089669942856, -0.073221854865551, 0.05399518832564354, 0.03378867730498314, 0.1292770504951477, 0.0685681402683258, 0.04558079317212105, -1.0009430440049982e-07, -0.04086267575621605, -0.010859082452952862, 0.07237345725297928, 0.08522762358188629, 0.05147102102637291, 0.0676775649189949, 0.07698731124401093, 0.23129387199878693, -0.0701170340180397, -0.052459605038166046, 0.09876648336648941, 0.04053406044840813, -0.03587183728814125, 0.08083295822143555, -0.02282734587788582, 0.04740457609295845, -0.11285658925771713, 0.05448239669203758, -0.02741950936615467, 0.11696501076221466, -0.0580860935151577, -0.05071462318301201, 0.044268589466810226, 0.01160035002976656, 0.1148957684636116, -0.05202299356460571, 0.062107689678668976, 0.02817060798406601, 0.16152559220790863, 0.05746420845389366, -0.07862910628318787, -0.05210644751787186, -0.034017663449048996, 0.1028338149189949, -0.14384284615516663, 0.12281423062086105, -0.11256102472543716, 0.0070069413632154465, -0.04712684080004692, 0.0873396173119545, -0.12036589533090591, 0.13310302793979645, -0.17166495323181152, -0.12501269578933716, -0.042183056473731995, 0.028037313371896744, 0.05062944442033768, -0.04321511834859848, 0.10957538336515427, -0.06757796555757523, -0.008671710267663002, -0.045824237167835236, -0.0590578131377697, -0.09352671355009079, 0.0353156179189682, 0.015311971306800842, -0.1381755769252777, 0.012962463311851025, 0.0051485816948115826, 0.011046080850064754, 0.09867772459983826, -0.043901629745960236, -0.14578790962696075, 0.07080479711294174], metadata={'source': 'AAAMLP-569to.pdf', 'page': 179}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 180 ═════════════════════════════════════════════════════════════════════════ from skopt.plots import plot_convergence  plot_convergence(result) ═════════════════════════════════════════════════════════════════════════ The convergence plot is shown in figure 2.  \\n Figure 2: Convergence plot of our random forest parameter optimization   There are many libraries available that offer hyperparameter optimization. scikit-optimize is one such library that you can use. Another useful library for hyperparameter optimization is hyperopt. hyperopt uses Tree-structured Parzen Estimator (TPE) to find the most optimal parameters. Take a look at the following snippet where I use hyperopt with minimal changes to the previous code.  ═════════════════════════════════════════════════════════════════════════ # rf_hyperopt.py import numpy as np import pandas as pd  from functools import partial  from sklearn import ensemble from sklearn import metrics from sklearn import model_selection  from hyperopt import hp, fmin, tpe, Trials'),\n",
       " VectorParams(vector=[-0.027698008343577385, 0.016678649932146072, -0.04423609748482704, 0.006073496770113707, 0.05351957678794861, -0.07938208431005478, 0.04695890098810196, 0.0546271912753582, -0.1378454715013504, -0.039386868476867676, 0.010444841347634792, -0.16802869737148285, 0.058252401649951935, -0.06425069272518158, -0.034537676721811295, 0.09723703563213348, 0.045752882957458496, -0.01830131933093071, -0.04964440315961838, -0.029202602803707123, 0.05364339053630829, 0.09157729893922806, 0.00455822516232729, -0.024281106889247894, -0.014758770354092121, -0.14816728234291077, -0.028907477855682373, 0.11760511994361877, -0.11456713825464249, -0.04894981533288956, 0.04371633380651474, -0.02120092697441578, -0.013234734535217285, 0.08193551003932953, 0.06190452724695206, 0.0037616719491779804, -0.13765284419059753, -0.07067117840051651, -0.08845021575689316, 0.11649912595748901, -0.054244544357061386, -0.022253867238759995, -0.1667395532131195, 0.028341980651021004, 0.04525379836559296, 0.1316196471452713, -0.07345548272132874, 0.02451498806476593, 0.11527927219867706, -0.05573783442378044, -0.13301658630371094, 0.06098445504903793, -0.15043708682060242, -0.04374600574374199, -0.11156760156154633, -0.011872749775648117, 0.037652354687452316, -0.07914271205663681, 0.12395775318145752, -0.1636335402727127, -0.012842947617173195, -0.08460963517427444, -0.06470374017953873, -0.11258656531572342, 0.026576979085803032, -0.11564714461565018, -0.04793901368975639, 0.03509768098592758, -0.04192356765270233, 0.08558237552642822, -0.01302366703748703, 0.11741040647029877, 0.0033141886815428734, -0.03895382955670357, -0.00543305603787303, 0.027997354045510292, 0.1275777369737625, -0.028402220457792282, 0.050097983330488205, -0.03815985471010208, -0.027303144335746765, -0.06325599551200867, -0.09034031629562378, -0.04618171229958534, 0.1112392470240593, -0.22024042904376984, 0.023436421528458595, 0.09165104478597641, 0.14158998429775238, -0.12237828969955444, 0.15369999408721924, -0.034502532333135605, -0.08648686856031418, 0.012703442014753819, 0.06230616942048073, 0.09231381863355637, 0.09790238738059998, -0.1049414649605751, -0.019964370876550674, 0.09658101946115494, -0.0644223764538765, -0.09321567416191101, 0.08322766423225403, -0.030081501230597496, 0.02860952913761139, -0.06298359483480453, 0.11266789585351944, 0.08474087715148926, 0.11900831758975983, -0.1636113077402115, -0.1134314239025116, -0.08100052922964096, -0.05190088972449303, 0.03940480202436447, 0.07714513689279556, 0.23537443578243256, 0.08765573054552078, 0.08233422785997391, -0.15056255459785461, 0.06056016683578491, -0.16674089431762695, 0.0809715986251831, -0.0001917129848152399, 0.10983838140964508, -0.028124555945396423, 0.029176030308008194, -0.14694011211395264, 1.1980368059880065e-32, -0.09042827039957047, 0.0062892865389585495, 0.031950272619724274, -0.0788014754652977, -0.007274518255144358, -0.018837420269846916, 0.0724143460392952, -0.07854566723108292, -0.024622317403554916, 0.07775146514177322, -0.2215873897075653, 0.04778015986084938, -0.025745831429958344, 0.010972509160637856, 0.07440178096294403, -0.07341280579566956, -0.06279286742210388, 0.02422267198562622, -0.04073240980505943, 0.03220423310995102, 0.2568517029285431, -0.042750220745801926, -0.015583775006234646, -0.1359269767999649, -0.1248430535197258, 0.036537449806928635, -0.022929968312382698, 0.035343848168849945, -0.16479966044425964, 0.0474228672683239, -0.25436389446258545, 0.03338296338915825, -0.037953007966279984, -0.013369313441216946, -0.01224370114505291, -0.031039893627166748, 0.0037339162081480026, 0.07497499138116837, -0.060269951820373535, -0.050488073378801346, -0.10026683658361435, 0.0595187284052372, 0.09250358492136002, -0.023260222747921944, -0.08463387936353683, 0.002971720416098833, 0.05019782856106758, 0.15322941541671753, 0.03873196616768837, 0.12894782423973083, -0.1419081836938858, -0.07151415944099426, -0.0728011503815651, -0.0006876765983179212, -0.17362645268440247, 0.12444516271352768, 0.09752676635980606, 0.049318380653858185, 0.03893063962459564, -0.07265948504209518, 0.005688996519893408, -0.06362918019294739, -0.02231656201183796, -0.009834260679781437, -0.027732746675610542, 0.08754348009824753, 0.11600027233362198, -0.030046766623854637, 0.10945110768079758, 0.0677076131105423, -0.08067887276411057, 0.04643988609313965, 0.03114059567451477, -0.027148021385073662, 0.12922321259975433, -0.09173726290464401, 0.10081547498703003, 0.06311331689357758, -0.02046368457376957, -0.07884443551301956, 0.06133362278342247, 0.2119971662759781, -0.01901290751993656, -0.2618904113769531, 0.03815024718642235, -0.13951855897903442, 0.028872672468423843, -0.11190803349018097, -0.16749189794063568, -0.10616663098335266, -0.22851680219173431, -0.010180888697504997, -0.07797615975141525, -0.05153389647603035, -0.050409648567438126, -1.3695221830529835e-32, 0.01047705952078104, 0.03287201747298241, 0.08097639679908752, 0.1009276807308197, 0.05741995945572853, 0.12202553451061249, 0.018138984218239784, 0.016726981848478317, -0.0705135241150856, -0.09225674718618393, -0.03822527825832367, -0.011264757253229618, 0.08503621816635132, 0.04245622828602791, 0.0481908917427063, 0.09835293889045715, -0.0762089267373085, 0.09293580800294876, 0.06965667009353638, -0.021350208669900894, -0.15256863832473755, 0.079341359436512, -0.13846559822559357, 0.030409114435315132, -0.15081432461738586, 0.02425522543489933, 0.00653632078319788, 0.09735474735498428, 0.052561018615961075, -0.0885375440120697, -0.0941360667347908, 0.07407261431217194, -0.14857986569404602, 0.07274656742811203, 0.042412690818309784, -0.023367980495095253, 0.02039913833141327, -0.04976462945342064, -0.060514986515045166, 0.18487221002578735, 0.16074223816394806, 0.12445042282342911, -0.0392339825630188, 0.04495149105787277, -0.008650158531963825, 0.05225546285510063, -0.006316793616861105, -0.03266458958387375, -0.005447758361697197, -0.09146153181791306, 0.01736786775290966, 0.02274484932422638, -0.09933751821517944, 0.056703440845012665, -0.08669737726449966, 0.1329653263092041, -0.09598865360021591, 0.015437997877597809, -0.10316552221775055, 0.03138937056064606, -0.06952390819787979, 0.036925651133060455, -0.08960061520338058, -0.00225185533054173, 0.06681781262159348, 0.016005510464310646, -0.05407983437180519, -0.03006347455084324, 0.07149869203567505, 0.008687793277204037, -0.1430174708366394, 0.015650669112801552, 0.09478601068258286, -0.11213418841362, -0.13532593846321106, 0.0016649591270834208, -0.10116814821958542, 0.09869109839200974, 0.09982877224683762, 0.03706284984946251, 0.029442602768540382, -0.004837803542613983, 0.08661915361881256, 0.13678745925426483, -0.03387252986431122, 0.07457160204648972, 0.09834540635347366, 0.17358455061912537, -0.05217950418591499, -0.07463457435369492, 0.04145316779613495, -0.01788065768778324, 0.08502991497516632, 0.2483874410390854, 0.013811456970870495, -1.004941481141941e-07, 0.043894264847040176, 0.16427387297153473, 0.017544010654091835, 0.0977291390299797, 0.029475310817360878, 0.0966724082827568, -0.050803761929273605, 0.019737055525183678, -0.011075755581259727, 0.026916053146123886, 0.10205312818288803, -0.046167921274900436, -0.07585150003433228, 0.1527123749256134, -0.1478976309299469, 0.09722066670656204, -0.033976972103118896, 0.08760564774274826, 0.012608957476913929, 0.09195654094219208, 0.06561069190502167, -0.02659599855542183, 0.009035053662955761, 0.00014281416952144355, 0.16466356813907623, -0.02964152581989765, -0.07842598110437393, 0.11537235975265503, 0.07683876156806946, 0.08148470520973206, -0.025645457208156586, -0.08232114464044571, -0.025532472878694534, 0.03500749170780182, -0.015424598008394241, 0.10972394049167633, 0.010064256377518177, -0.027860043570399284, 0.0690254271030426, 0.1496264636516571, -0.13542792201042175, 0.13591761887073517, -0.13591094315052032, -0.07044889777898788, 0.07657492905855179, 0.035035278648138046, -0.008531823754310608, -0.1273215264081955, 0.08247532695531845, 0.000783889030572027, 0.014728803187608719, -0.02170838974416256, -0.11942341178655624, 0.011484269984066486, 0.10850916057825089, -0.0577179417014122, -0.14581657946109772, -0.06921502202749252, -0.0563749261200428, -0.012919462285935879, 0.024342423304915428, -0.07983403652906418, -0.09761331975460052, 0.04683713987469673], metadata={'source': 'AAAMLP-569to.pdf', 'page': 180}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 181 from hyperopt.pyll.base import scope   def optimize(params, x, y):     \"\"\"     The main optimization function.      This function takes all the arguments from the search space     and training features and targets. It then initializes     the models by setting the chosen parameters and runs      cross-validation and returns a negative accuracy score     :param params: dict of params from hyperopt     :param x: training data     :param y: labels/targets     :return: negative accuracy after 5 folds     \"\"\"      # initialize model with current parameters     model = ensemble.RandomForestClassifier(**params)      # initialize stratified k-fold     kf = model_selection.StratifiedKFold(n_splits=5)      .     .     .          # return negative accuracy     return -1 * np.mean(accuracies)   if __name__ == \"__main__\":     # read the training data     df = pd.read_csv(\"../input/mobile_train.csv\")      # features are all columns without price_range     # note that there is no id column in this dataset     # here we have training features     X = df.drop(\"price_range\", axis=1).values     # and the targets     y = df.price_range.values      # define a parameter space     # now we use hyperopt      param_space = {         # quniform gives round(uniform(low, high) / q) * q         # we want int values for depth and estimators'),\n",
       " VectorParams(vector=[-0.03280187025666237, 0.054898250848054886, -0.018905848264694214, -0.04514957219362259, -0.03619980439543724, -0.18299449980258942, 0.0724240317940712, 0.10015852749347687, -0.15635621547698975, -0.015438741073012352, -0.10627715289592743, -0.04635036736726761, -0.052554331719875336, 0.004500392358750105, -0.05347030609846115, 0.11828119307756424, 0.039515722543001175, -0.08416850119829178, -0.08387123048305511, -0.05392473563551903, 0.08507592976093292, 0.11422838270664215, 0.05170726776123047, 0.035785920917987823, 0.006594467908143997, -0.16152802109718323, -0.002607776550576091, 0.2220538705587387, -0.1256973296403885, 0.01966738887131214, 0.06011544167995453, 0.03480175510048866, -0.10579793900251389, 0.04294075071811676, 0.08438342064619064, 0.08354907482862473, -0.1692127287387848, -0.17924639582633972, -0.026534564793109894, 0.03138979151844978, -0.06418019533157349, -0.024668138474225998, -0.23050446808338165, 0.0002554887323640287, -0.013035601936280727, 0.07799841463565826, -0.12521067261695862, -0.017009537667036057, 0.11439580470323563, 0.050902076065540314, -0.139425590634346, 0.05231117084622383, 0.00015486087067984045, 0.02227543294429779, 0.08592250943183899, -0.06479425728321075, 0.07959120720624924, -0.10422328859567642, 0.02733829990029335, -0.20579920709133148, -0.09594164043664932, -0.04127740487456322, -0.08842498064041138, -0.03500078245997429, 0.011447743512690067, -0.17470161616802216, -0.04883056506514549, -0.0051935031078755856, -0.1131485253572464, 0.1637127548456192, -7.345425547100604e-05, 0.04772479832172394, -0.09161985665559769, -0.0603417307138443, 0.09786008298397064, 0.002480626106262207, 0.11461974680423737, 0.019345205277204514, 0.011362705379724503, -0.09651514142751694, -0.009299371391534805, 0.04883798956871033, -0.015332113020122051, 0.025090642273426056, 0.02207375504076481, -0.28030338883399963, -0.033640433102846146, 0.07639548182487488, 0.19696038961410522, -0.10117840766906738, 0.037889860570430756, -0.02393248677253723, -0.11743243038654327, -0.022532176226377487, 0.1868012249469757, -0.0013868821552023292, 0.09878744930028915, -0.1195695772767067, -0.0658113956451416, 0.06053362041711807, -0.06011027842760086, -0.15618525445461273, 0.08038350194692612, -0.06792497634887695, 0.053861021995544434, -0.07361515611410141, 0.1380690187215805, -0.0003572263231035322, 0.1565607786178589, -0.1052827313542366, -0.05381851643323898, -0.04203648492693901, 0.053555749356746674, -0.0001426947710569948, 0.08934104442596436, 0.22031281888484955, -0.006312522571533918, 0.1396082043647766, -0.10789401084184647, 0.1646934598684311, -0.08939477801322937, 0.01850227266550064, 0.03033633530139923, 0.09110623598098755, 0.015537027269601822, -0.016029436141252518, -0.08298732340335846, 6.81617746163996e-33, 0.012722702696919441, -0.06704052537679672, -0.08591210097074509, -0.20326128602027893, 0.018334317952394485, 0.1732145994901657, 0.08342956006526947, -0.09293795377016068, -0.018492506816983223, 0.08137569576501846, -0.2987256646156311, -0.017938556149601936, -0.09803532809019089, -0.07539039850234985, 0.06468536704778671, -0.07476598024368286, -0.0503426194190979, 0.1948600709438324, -0.06413856148719788, 0.0008266012882813811, 0.13996246457099915, -0.006067228503525257, -0.03232058510184288, -0.14285553991794586, -0.08407556265592575, -0.017197804525494576, -0.034340858459472656, -0.08620420843362808, -0.26008644700050354, 0.05049208551645279, -0.13067279756069183, 0.010569486767053604, -0.07231368869543076, -0.0303738284856081, -0.03454206883907318, -0.012524839490652084, 0.013818535022437572, 0.055279690772295, 0.02053740993142128, -0.061809927225112915, -0.029822219163179398, 0.02192641608417034, 0.14980681240558624, -0.05229511857032776, 0.0017275232821702957, 0.06186332181096077, -0.09561516344547272, 0.11546958237886429, 0.005927523598074913, 0.17244543135166168, -0.1284528374671936, -0.08218224346637726, -0.065080925822258, -0.03600023686885834, -0.0647687017917633, 0.054861340671777725, 0.10512331873178482, 0.12210547924041748, 0.07369543612003326, -0.1082070991396904, -0.010496735572814941, -0.041356414556503296, 0.048118993639945984, -0.08336447924375534, 0.04911324381828308, 0.08357171714305878, 0.10584893822669983, 0.01709241047501564, 0.10644636303186417, 0.14938423037528992, -0.05946572124958038, 0.049783263355493546, 0.07009391486644745, -0.07438333332538605, 0.0745379626750946, -0.08486387133598328, 0.21595045924186707, -0.016827132552862167, -0.07912470400333405, -0.13986432552337646, -0.014018001966178417, 0.19899392127990723, -0.0973537415266037, -0.22172044217586517, -0.03350848704576492, -0.12496494501829147, 0.058444757014513016, -0.01761573553085327, -0.21747219562530518, -0.0883110985159874, -0.1715022772550583, 0.034168343991041183, 0.019313795492053032, 0.014381238259375095, -0.10238231718540192, -9.685312318183492e-33, 0.01589123159646988, 0.042466480284929276, 0.18737788498401642, 0.01740618795156479, -0.005618680734187365, 0.06029638648033142, 0.022352585569024086, -0.0832294300198555, -0.09212400764226913, -0.015342926606535912, 0.026950934901833534, -0.10989813506603241, 0.03639572113752365, -0.0009810526389628649, 0.09508046507835388, 0.14029577374458313, -0.0820784792304039, 0.024821391329169273, 0.15587396919727325, 0.04391101002693176, -0.009390466846525669, 0.1263158917427063, -0.17974551022052765, 0.08921854197978973, -0.11873659491539001, -0.04875785484910011, 0.05688485503196716, 0.04468110576272011, 0.1358463317155838, -0.0796063095331192, -0.0848085880279541, 0.07609915733337402, -0.2289828509092331, 0.10240506380796432, 0.18645481765270233, 0.028717638924717903, 0.13604536652565002, 0.03325733542442322, -0.07772975414991379, 0.10012829303741455, 0.2104029357433319, 0.1197386384010315, 0.015291028656065464, 0.020098738372325897, -0.032990459352731705, 0.07995244115591049, 0.0053603071719408035, -0.1769963502883911, 0.024000519886612892, -0.03816147521138191, 0.01827097497880459, -0.09952382743358612, -0.06468076258897781, 0.191207155585289, -0.14856836199760437, 0.0840158686041832, -0.09110283851623535, 0.04130186513066292, -0.06427362561225891, -0.01949097029864788, -0.050189144909381866, 0.014233659021556377, 0.012082476168870926, 0.034267064183950424, -0.03245273604989052, 0.029957713559269905, -0.07932445406913757, -0.0678693950176239, 0.07988982647657394, 0.03460517153143883, -0.15899407863616943, -0.007814791053533554, 0.1738579124212265, -0.040618471801280975, -0.08164522051811218, 0.1896265596151352, 0.043978866189718246, 0.017790481448173523, 0.05412526801228523, 0.0224815234541893, 0.02091948315501213, 0.12382569909095764, 0.05968984216451645, 0.14426971971988678, -0.04068552702665329, 0.09138194471597672, 0.048940688371658325, 0.17555826902389526, 0.00846942700445652, -0.17398032546043396, 0.11338124424219131, 0.04521086812019348, 0.15525616705417633, 0.053176503628492355, 0.019599400460720062, -1.0040016462653512e-07, 0.019613467156887054, -0.027674561366438866, 0.052825115621089935, 0.10125637799501419, 0.10159365832805634, -0.020369209349155426, -0.04505439102649689, 0.02201250195503235, -0.09639742970466614, -0.03603534400463104, 0.0537717379629612, 0.05650852248072624, -0.06382337957620621, 0.036010343581438065, -0.01967502199113369, -0.012926600873470306, -0.05380796268582344, 0.011999314650893211, 0.049347370862960815, 0.08142902702093124, -0.05251491069793701, -0.05856624245643616, 0.020678091794252396, -0.08547773212194443, -0.04018890857696533, -0.07448048144578934, -0.007093637716025114, -0.030560849234461784, 0.041749242693185806, 0.06126981973648071, 0.033574268221855164, 0.031156359240412712, 0.029627462849020958, 0.058902520686388016, -0.07187231630086899, 0.020803695544600487, -0.05234288051724434, 0.03887408599257469, -0.016239114105701447, 0.08003921806812286, -0.1657959371805191, 0.0785929262638092, -0.054772358387708664, -0.12289417535066605, 0.0643656998872757, -0.016089264303445816, 0.0921797826886177, -0.09901346266269684, 0.09708097577095032, 0.030358927324414253, 0.0736386850476265, 0.02789018489420414, 0.10143095999956131, -0.04734249785542488, 0.1489987075328827, -0.03509567305445671, -0.1498444676399231, -0.002774347085505724, -0.028329040855169296, -0.011936423368752003, 0.06031505763530731, -0.02092899940907955, -0.0789622962474823, 0.00786722544580698], metadata={'source': 'AAAMLP-569to.pdf', 'page': 181}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 182         \"max_depth\": scope.int(hp.quniform(\"max_depth\", 1, 15, 1)),         \"n_estimators\": scope.int(             hp.quniform(\"n_estimators\", 100, 1500, 1)         ),         # choice chooses from a list of values         \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),         # uniform chooses a value between two values         \"max_features\": hp.uniform(\"max_features\", 0, 1)     }      # partial function     optimization_function = partial(         optimize,         x=X,         y=y     )      # initialize trials to keep logging information     trials = Trials()          # run hyperopt     hopt = fmin(         fn=optimization_function,         space=param_space,         algo=tpe.suggest,         max_evals=15,         trials=trials      )     print(hopt) ═════════════════════════════════════════════════════════════════════════  As you can see, this is not very different from the previous code. You have to define the parameter space in a different format, and you also need to change the actual optimization part by using hyperopt instead of gp_minimize. The results are quite good!  ═════════════════════════════════════════════════════════════════════════ ❯ python rf_hyperopt.py 100%|██████████████████| 15/15 [04:38<00:00, 18.57s/trial, best loss: -0.9095000000000001] {\\'criterion\\': 1, \\'max_depth\\': 11.0, \\'max_features\\': 0.821163568049807, \\'n_estimators\\': 806.0} ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[-0.030929919332265854, -0.0955299511551857, 0.014468759298324585, 0.02251720242202282, -0.04347963258624077, 0.01795840449631214, -0.0005777754704467952, 0.01856757514178753, -0.06553042680025101, -0.04017084836959839, -0.10144971311092377, 0.02709692157804966, -0.003741086460649967, -0.00545259565114975, -0.025948408991098404, 0.03843783214688301, 0.1160784512758255, 0.1304989904165268, -0.17874790728092194, 0.02881491370499134, 0.1544366031885147, -0.07154577970504761, -0.006480586715042591, -0.10885564982891083, -0.09961853921413422, -0.13751624524593353, -0.048577748239040375, -0.01142237801104784, -0.06835635006427765, -0.03951162472367287, 0.07116980105638504, -0.0023194747045636177, -0.18058878183364868, 0.08174828439950943, -0.10378828644752502, 0.0706479474902153, -0.01645398512482643, 0.02199028991162777, -0.05641186609864235, -0.0009380623232573271, -0.07359106093645096, -0.04981447011232376, -0.0226364154368639, 0.06227799504995346, 0.3041144013404846, 0.08246207982301712, 0.03369520977139473, -0.02717960998415947, 0.04220415651798248, -0.03607141599059105, -0.12151563912630081, -0.06679891049861908, 0.011422238312661648, 0.06922657787799835, 0.060090966522693634, 0.043831001967191696, 0.04518235847353935, 0.03235682100057602, 0.02010810375213623, -0.091311976313591, -0.056499894708395004, -0.05929647758603096, -0.1785772144794464, -0.12088986486196518, -0.05338010936975479, -0.10375966131687164, 0.0963754802942276, -0.02767912857234478, 0.08317456394433975, 0.13201312720775604, -0.03478548303246498, 0.10616852343082428, -0.013387142680585384, 0.0873115286231041, 0.019559795036911964, 0.03738497570157051, 0.0651477798819542, 0.00010514385212445632, 0.07832912355661392, -0.011740896850824356, 0.057504843920469284, 0.0658046305179596, -0.0047072600573301315, 0.019294841215014458, 0.11348871886730194, -0.043794143944978714, 0.014302561059594154, -0.01097124069929123, 0.048214882612228394, -0.0709582194685936, 0.0719381645321846, -0.050611142069101334, -0.0773000568151474, -0.10342667251825333, 0.10443557053804398, 0.041539549827575684, 0.032986707985401154, -0.1413099467754364, -0.03511367365717888, 0.04377268627285957, 0.0007273434894159436, 0.024667249992489815, 0.08239776641130447, -0.0025120594073086977, 0.10038108378648758, 0.05092291906476021, -0.008377498015761375, 0.12516231834888458, 0.12649467587471008, -0.1298360675573349, -0.05084172636270523, 0.06025601923465729, -0.10308129340410233, -0.04468795657157898, 0.05158879980444908, 0.020135411992669106, 0.07623455673456192, -0.0976242795586586, -0.03829753398895264, 0.17277805507183075, -0.12265210598707199, 0.06845179200172424, -0.07397236675024033, -0.011988027021288872, 0.06672654300928116, 0.02243666723370552, -0.11460881680250168, 8.336555242837784e-33, -0.005198479164391756, 0.155305415391922, -0.10641001164913177, -0.11910813301801682, -0.08806615322828293, -0.05820167437195778, 0.08914739638566971, -4.090076981810853e-05, 0.10300371050834656, 0.03729278966784477, -0.11207085102796555, -0.06923110038042068, -0.06661777198314667, 0.0660112276673317, 0.058466602116823196, -0.056793663650751114, -0.08382973074913025, 0.07272390276193619, 0.004996068775653839, -0.06898748129606247, -0.05606328323483467, -0.06864932179450989, 0.10004390776157379, -0.03005804307758808, -0.06936982274055481, -0.030292853713035583, 0.13832515478134155, 0.0017740518087521195, -0.06298608332872391, 0.008874675258994102, 0.04002409055829048, -0.039813194423913956, -0.016601353883743286, 0.09130338579416275, 0.00190390320494771, 0.00016306317411363125, -0.0676293671131134, 0.0003956285072490573, 0.0636885017156601, -0.07008963823318481, -0.03231833130121231, 0.06508507579565048, 0.057802457362413406, 0.025182737037539482, -0.01709526963531971, -0.00984068401157856, 0.005335332825779915, 0.003480711951851845, -0.0473274402320385, -0.04305321350693703, -0.02778908982872963, -0.025806834921240807, -0.07125820964574814, -0.03972866013646126, -0.08715983480215073, 0.10198228806257248, 0.0797303095459938, -0.02130294032394886, -0.06943337619304657, 0.042080577462911606, -0.045778900384902954, -0.10175923258066177, 0.05268411710858345, 0.05963285267353058, 0.023114163428544998, -0.09512698650360107, 0.11984646320343018, 0.09707523882389069, 0.03916920721530914, -0.06651958078145981, -0.09657201170921326, -0.10861383378505707, 0.08851849287748337, -0.045660071074962616, 0.06874466687440872, -0.026875289157032967, 0.1463993936777115, -0.0712975412607193, -0.003878597868606448, 0.05910671129822731, 0.027945220470428467, 0.22357067465782166, 0.06947153806686401, -0.07607648521661758, -0.020030243322253227, -0.0081924544647336, -0.0059587107971310616, -0.09978945553302765, -0.06717921793460846, -0.05894320458173752, -0.12545828521251678, 0.0533888041973114, -0.04327019304037094, -0.059061601758003235, -0.02681863307952881, -6.537039430305915e-33, -0.013252489268779755, -0.008464389480650425, -0.0234660804271698, 0.17406059801578522, 0.004719338845461607, -0.024734506383538246, -0.1239243596792221, -0.15464834868907928, -0.10917834937572479, -0.1408747136592865, -0.018927372992038727, 0.023525916039943695, 0.00720516312867403, 0.015268289484083652, -0.06933607161045074, 0.11387112736701965, -0.16753685474395752, 0.053761906921863556, 0.02573351189494133, 0.07778720557689667, -0.04499423876404762, 0.08868730068206787, -0.12827003002166748, 0.010054441168904305, -0.11039087921380997, -0.08706274628639221, -0.08374940603971481, 0.11897499114274979, 0.04526286572217941, 0.023752212524414062, -0.012141936458647251, 0.06807145476341248, -0.004445313010364771, -0.033407971262931824, 0.0677262470126152, 0.04668426141142845, 0.05289505794644356, -0.012419505044817924, 0.0961785688996315, 0.19695337116718292, 0.044773127883672714, 0.17669729888439178, 0.005853173788636923, -0.12031654268503189, 0.004013125319033861, -0.01937248930335045, -0.15745948255062103, -0.09828684478998184, -0.03840957209467888, 0.09684638679027557, 0.041047003120183945, -0.0361066572368145, -0.036477185785770416, 0.0026433984749019146, -0.07941458374261856, -0.035188715904951096, -0.038181912153959274, 0.05081242322921753, 0.13465820252895355, 0.10065967589616776, -0.16400185227394104, -0.025131043046712875, 0.05456390976905823, -0.005616938695311546, -0.09534037858247757, 0.012332553043961525, 0.046451739966869354, 0.03748534992337227, 0.0008529226179234684, 0.05924507603049278, -0.1296183317899704, 0.019572662189602852, 0.11221311241388321, 0.10438936948776245, -0.14681951701641083, -0.0717821717262268, -0.02452639490365982, 0.018154049292206764, -0.0790485367178917, -0.11033803969621658, 0.10129238665103912, 0.005583303980529308, -0.05784390866756439, 0.15273024141788483, -0.059343818575143814, 0.18318882584571838, 0.14838869869709015, 0.11591757833957672, -0.01202413160353899, -0.15738798677921295, -0.01050453819334507, -0.0005773085285909474, 0.038982927799224854, 0.03433254733681679, -0.06680934876203537, -9.935233435953705e-08, -0.02711517922580242, 0.08437440544366837, 0.16109994053840637, 0.033095832914114, 0.05683067440986633, -0.007324017118662596, 0.011223182082176208, 0.28371283411979675, -0.04353218898177147, 0.0024017959367483854, 0.10692805051803589, 0.03441430628299713, -0.013229942880570889, -0.005167731549590826, 0.04687226936221123, 0.08799056708812714, 0.07477287203073502, 0.06839926540851593, -0.08563189953565598, 0.07680585235357285, 0.01996743306517601, -0.01903603784739971, 0.03675011917948723, 0.010385693982243538, 0.3185802102088928, -0.13179922103881836, -0.01683216355741024, 0.11472062021493912, 0.034529779106378555, 0.05521192401647568, 0.08830805122852325, 0.09262993186712265, 0.025081921368837357, -0.08570295572280884, -0.026799215003848076, 0.1950165331363678, 0.056502338498830795, -0.19759154319763184, -0.06572366505861282, 0.07662953436374664, 0.028409261256456375, 0.1684541255235672, -0.016813797876238823, -0.0764366164803505, 0.0932852104306221, -0.05444549024105072, 0.04766983538866043, -0.11281312257051468, -0.0789327397942543, 0.008852463215589523, 0.11123231053352356, -0.06023619323968887, 0.0008468570886179805, -0.0704100951552391, -0.006257170811295509, 0.03790758177638054, -0.025438465178012848, 0.006612066179513931, 0.0824442207813263, 0.1559496521949768, -0.07823887467384338, 0.020318305119872093, -0.13230304419994354, 0.04537276551127434], metadata={'source': 'AAAMLP-569to.pdf', 'page': 182}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 183 We get an accuracy which is a little better than before and a set of parameters that we can use. Please note that criterion is 1 in the final result. This implies that choice 1 was selected, i.e., entropy.  The ways of tuning hyperparameters described above are the most common, and these will work with almost all models: linear regression, logistic regression, tree-based methods, gradient boosting models such as xgboost, lightgbm, and even neural networks!  Although, these methods exist, to learn, one must start with tuning the hyper-parameters manually, i.e., by hand. Hand tuning will help you learn the basics, for example, in gradient boosting, when you increase the depth, you should reduce the learning rate. It won’t be possible to learn this if you use automated tools. Refer to the following table to know what to tune. RS* implies random search should be better.  Once you get better with hand-tuning the parameters, you might not even need any automated hyper-parameter tuning. When you create large models or introduce a lot of features, you also make it susceptible to overfitting the training data. To avoid overfitting, you need to introduce noise in training data features or penalize the cost function. This penalization is called regularization and helps with generalizing the model. In linear models, the most common types of regularizations are L1 and L2. L1 is also known as Lasso regression and L2 as Ridge regression. When it comes to neural networks, we use dropouts, the addition of augmentations, noise, etc. to regularize our models. Using hyper-parameter optimization, you can also find the correct penalty to use.'),\n",
       " VectorParams(vector=[-0.000931089511141181, -0.09974013268947601, -0.09781571477651596, -0.014025514014065266, 0.13476784527301788, -0.07706102728843689, 0.01393172051757574, 0.04731164500117302, -0.13048028945922852, 0.04348768666386604, 0.015083780512213707, -0.11271076649427414, -0.07140098512172699, 0.0006052448879927397, -0.06289681792259216, 0.07679259032011032, 0.03784993663430214, -0.07289707660675049, -0.12536291778087616, -0.03663315623998642, -0.004765813238918781, 0.11890300363302231, -0.0621456503868103, 0.00535168731585145, 0.03140036761760712, -0.08261768519878387, -0.0012098822044208646, 0.03391318768262863, -0.040801744908094406, -0.09479376673698425, -0.05952369049191475, 0.031223835423588753, 0.0812152847647667, 0.017482541501522064, -0.02230791561305523, 0.005025016143918037, -0.015182836912572384, -0.037284694612026215, -0.07621254771947861, 0.07658892869949341, -0.08288247883319855, 0.010495069436728954, 0.023474717512726784, -0.09180985391139984, 0.0919261947274208, -0.0033332540187984705, -0.13151349127292633, -0.08828916400671005, 0.009387345053255558, -0.10455393046140671, -0.07001963257789612, -0.03351093828678131, -0.15646953880786896, 0.057282354682683945, -0.09625651687383652, -0.07879234105348587, -0.047019828110933304, -0.1334255039691925, 0.13577106595039368, 0.05315376818180084, 0.00583406537771225, -0.0038776432629674673, -0.10428682714700699, 0.04100636765360832, 0.05194845423102379, 0.012174094095826149, -0.14551536738872528, -0.05014166235923767, 0.02704000473022461, 0.08983247727155685, -0.054993920028209686, -0.013738050125539303, -0.22209353744983673, 0.15012772381305695, 0.011156410910189152, 0.07431939244270325, 0.15981784462928772, 0.030035721138119698, 0.011433626525104046, -0.036073949187994, -0.1632254272699356, 0.08719927072525024, 0.014278016984462738, 0.011568021029233932, 0.06912524253129959, -0.07599784433841705, -0.05694190040230751, 0.10282313078641891, 0.05800950899720192, 0.04311276227235794, 0.08364365249872208, 0.098229318857193, -0.11134489625692368, 0.06260660290718079, -0.10721318423748016, 0.09418487548828125, 0.11857913434505463, -0.1339205503463745, -0.041110649704933167, 0.13748498260974884, -0.1146308109164238, 0.028810152783989906, -0.010306223295629025, -0.035529520362615585, 0.005338911432772875, -0.016317209228873253, 0.10167864710092545, 0.039737530052661896, 0.10871053487062454, -0.07217282056808472, -0.057860493659973145, 0.018722670152783394, -0.043841198086738586, -0.043380819261074066, 0.0708136036992073, 0.003413461148738861, 0.06820935755968094, 0.04845360666513443, -0.02612401358783245, 0.09355361759662628, 0.018220657482743263, 0.037052176892757416, -0.04912657290697098, 0.0996699184179306, 0.06645780056715012, -0.03745501488447189, -0.23166368901729584, -2.30818931967312e-33, 0.028294863179326057, 0.03403860330581665, -0.014271608553826809, -0.19793669879436493, 0.045212458819150925, 0.056797392666339874, -0.023717286065220833, -0.047941241413354874, -0.01109520997852087, 0.11581231653690338, -0.15415160357952118, 0.02696492150425911, -0.09477499127388, -0.04698413982987404, 0.11396358907222748, -0.02006438747048378, -0.04180784523487091, 0.10873664170503616, -0.1222136989235878, 0.05590845271945, 0.08878834545612335, -0.06414153426885605, 0.02151707001030445, -0.09940724819898605, 0.037151362746953964, 0.02152067981660366, 0.08365778625011444, 0.00021293785539455712, -0.06233224645256996, 0.005307411774992943, -0.027169842272996902, 0.07626719027757645, -0.12339026480913162, -0.011898757889866829, -0.06112978234887123, -0.022880060598254204, -0.039267804473638535, 0.052635978907346725, 0.06579042226076126, 0.018356509506702423, -0.0850716233253479, 0.026583321392536163, 0.019612189382314682, -0.05756973475217819, 0.03948385640978813, -0.013351935893297195, 0.04792912304401398, 0.054427873343229294, -0.042614154517650604, 0.009862511418759823, -0.07054755836725235, -0.04270090162754059, -0.06887464970350266, 0.04773762822151184, -0.07959441095590591, 0.13244663178920746, 0.030217519029974937, 0.06668785959482193, 0.11099886894226074, 0.04060930013656616, 0.020221132785081863, -0.10295069962739944, -0.04275666922330856, -0.13681548833847046, 0.08835960179567337, 0.061719585210084915, 0.04982852190732956, -0.04127354547381401, 0.019528737291693687, -0.0039441571570932865, -0.053920019418001175, 0.0056412373669445515, 0.13378942012786865, -0.10487518459558487, 0.03990843519568443, -0.06770811229944229, 0.13164153695106506, 0.0518236942589283, -0.021036555990576744, -0.011320767924189568, -0.0755455419421196, 0.13567179441452026, 0.00018133007688447833, -0.15587468445301056, 0.006366351619362831, -0.09010220319032669, 0.006504013203084469, -0.07994520664215088, -0.21586595475673676, -0.08076616376638412, -0.12407036870718002, -0.008308188058435917, 0.015435582958161831, -0.07289814203977585, -0.08455745875835419, 2.0085102592424247e-33, 0.05374988913536072, -0.0026275983545929193, 0.014785567298531532, 0.11308783292770386, 0.10482566058635712, 0.02927958033978939, 0.006587551441043615, 0.09359767287969589, -0.09764479100704193, -0.03753435239195824, 0.10472730547189713, 0.02672656811773777, 0.024130145087838173, -0.03191370889544487, 0.12326298654079437, 0.03859376534819603, 0.07451457530260086, 0.06976506859064102, -0.04986177384853363, 0.0030300284270197153, 0.0026620642747730017, 0.3140656054019928, -0.09654304385185242, 0.05660741403698921, -0.07463996112346649, -0.013160357251763344, -0.030688844621181488, 0.09783419966697693, -0.06815267354249954, -0.06303832679986954, -0.04542078822851181, 0.029697997495532036, -0.17821022868156433, -0.024189649149775505, 0.0340392105281353, -0.0017683462938293815, 0.027653509750962257, 0.020031167194247246, -0.07894778996706009, 0.19466392695903778, 0.13775119185447693, 0.04468970373272896, -0.09567699581384659, -0.01816018670797348, -0.05787118151783943, 0.025997929275035858, 0.06125890091061592, -0.0018446509493514895, -0.034310292452573776, 0.058777764439582825, 0.011194894090294838, -0.011539123952388763, -0.007628830149769783, 0.21916906535625458, 0.04035979509353638, 0.014752148650586605, 0.0032291305251419544, 0.03566526994109154, -0.05025539919734001, -0.06633057445287704, -0.06055482104420662, -0.0031925560906529427, -0.12463782727718353, 0.006510992534458637, 0.10182458907365799, 0.059334222227334976, 0.010854914784431458, 0.008291133679449558, -0.062104303389787674, 0.06867427378892899, -0.017752790823578835, -0.04711266607046127, 0.12423090636730194, -0.02716362662613392, -0.05625569447875023, 0.0206746906042099, 0.026724042370915413, -0.06156866252422333, 0.0007532067247666419, -0.00012608154793269932, -0.1061287447810173, -0.02712399885058403, 0.08634142577648163, 0.19364382326602936, 0.06452026963233948, 0.05382508784532547, -0.04625887796282768, 0.09424977749586105, 0.08103039860725403, -0.025486763566732407, -0.09796889871358871, 0.08721604943275452, 0.12198904156684875, 0.07485248893499374, 0.07551204413175583, -9.962479907699162e-08, -0.0888843908905983, 0.036857858300209045, -0.02611400932073593, 0.042776741087436676, 0.1825900375843048, 0.015591369941830635, -0.034811802208423615, 0.09449328482151031, -0.15708719193935394, 0.029813187196850777, 0.1561109572649002, 0.007837919518351555, -0.09676538407802582, 0.010817382484674454, -0.005757925566285849, -0.06792415678501129, 0.0627945214509964, 0.14376085996627808, -0.06299972534179688, 0.06594298779964447, 0.007404562551528215, 0.04070247709751129, -0.033677838742733, -0.08928807824850082, 0.07712198048830032, -0.19583910703659058, -0.02735965885221958, 0.11263448745012283, 0.043520163744688034, 0.06908781081438065, -0.07116924226284027, 0.01279776357114315, 0.10452122986316681, -0.06890209019184113, -0.005088728852570057, 0.15884287655353546, -0.03221089392900467, 0.03712962940335274, 0.007514107506722212, 0.034466031938791275, -0.047762561589479446, 0.06447403132915497, 0.025704529136419296, 0.015504689887166023, 0.10652352124452591, 0.06741825491189957, 0.009830712340772152, -0.1043451651930809, 0.19154717028141022, -0.11351217329502106, 0.037255484610795975, 0.01704159565269947, -0.04221779480576515, -0.015741242095828056, 0.01429632119834423, 0.003164283698424697, -0.06120665371417999, 0.033675625920295715, -0.0010145006235688925, 0.026453528553247452, 0.09340140223503113, -0.17280162870883942, -0.03797636926174164, 0.004095674492418766], metadata={'source': 'AAAMLP-569to.pdf', 'page': 183}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 184   Model Optimize Range of values Linear Regression  - fit_intercept - normalize   - True/False - True/False Ridge  - alpha - fit_intercept - normalize   - 0.01, 0.1, 1.0, 10, 100 - True/False - True/False k-neighbors  - n_neighbors - p  - 2, 4, 8, 16 …. - 2, 3  SVM  - C - gamma - class_weight   - 0.001,0.01..10..100..1000 - ‘auto’, RS* - ‘balanced’ , None Logistic Regression  - Penalty - C   - l1 or l2 - 0.001, 0.01…..10...100  Lasso  - Alpha - Normalize  - 0.1, 1.0, 10 - True/False  Random Forest  - n_estimators - max_depth - min_samples_split - min_samples_leaf - max features  - 120, 300, 500, 800, 1200 - 5, 8, 15, 25, 30, None - 1, 2, 5, 10, 15, 100 - 1, 2, 5, 10 - log2, sqrt, None  XGBoost  - eta - gamma - max_depth - min_child_weight - subsample - colsample_bytree - lambda - alpha   - 0.01,0.015, 0.025, 0.05, 0.1 - 0.05-0.1,0.3,0.5,0.7,0.9,1.0 - 3, 5, 7, 9, 12, 15, 17, 25 - 1, 3, 5, 7 - 0.6, 0.7, 0.8, 0.9, 1.0 - 0.6, 0.7, 0.8, 0.9, 1.0 - 0.01-0.1, 1.0 , RS* - 0, 0.1, 0.5, 1.0 RS*'),\n",
       " VectorParams(vector=[-0.03779139369726181, -0.028405331075191498, 0.02136034145951271, -0.1560993641614914, 0.09513373672962189, -0.1790507584810257, 0.028541989624500275, -0.07166111469268799, -0.07657121121883392, -0.03531666100025177, -0.11061064898967743, -0.1318507343530655, 0.15386039018630981, 0.15653608739376068, -0.07408872246742249, 0.003163132816553116, -0.04058314859867096, 0.08106075972318649, -0.16557306051254272, 0.020667821168899536, 0.1086759939789772, -0.017142435535788536, -0.008224970661103725, -0.09435225278139114, -0.11295653879642487, -0.021956438198685646, 0.16743218898773193, 0.09456205368041992, -0.1341574788093567, -0.117813840508461, 0.03628889471292496, 0.041114065796136856, 0.08516384661197662, 0.05690447613596916, -0.07141143083572388, 0.03737752139568329, -0.061514683067798615, 0.06513885408639908, -0.0822993740439415, -0.00871553085744381, -0.04279229789972305, 0.04059566557407379, 0.0031032757833600044, -0.08376596868038177, 0.2757243514060974, 0.06254445016384125, 0.08644083887338638, -0.22242958843708038, 0.15999828279018402, -0.11266306042671204, -0.13983754813671112, 0.025715744122862816, -0.1978679895401001, 0.07773375511169434, 0.0295784343034029, -0.1884070336818695, 0.07707624137401581, -0.23150035738945007, 0.05797414854168892, -0.1025204136967659, 0.04015485197305679, -0.05705730617046356, -0.017670929431915283, -0.01290629617869854, 0.09656594693660736, -0.08487622439861298, -0.01150493137538433, -0.10730211436748505, 0.061031974852085114, -0.06353435665369034, -0.05692034959793091, 0.13756445050239563, 0.08223573863506317, 0.03902214765548706, -0.1523934006690979, -0.039461586624383926, 0.22333434224128723, 0.02770599164068699, 0.06914617121219635, -0.11875429004430771, 0.06369450688362122, 0.03508741408586502, 0.0803540050983429, 0.12754753232002258, 0.08837196975946426, -0.0019469363614916801, -0.12479285895824432, 0.2744045853614807, 0.04769476130604744, -0.03836647793650627, -0.08036509156227112, -0.004942100495100021, -0.20243802666664124, -0.01801202818751335, 0.09121167659759521, -0.052740465849637985, 0.1735640913248062, -0.16142229735851288, 0.004241993650794029, 0.10097984224557877, 0.13023006916046143, -0.1728438138961792, 0.032933518290519714, 0.07068990170955658, 0.174959197640419, 0.19943705201148987, 0.2292230725288391, 0.07655184715986252, 0.22722917795181274, -0.14722386002540588, -0.01998080313205719, -0.06541220843791962, -0.2085314840078354, 0.024465110152959824, 0.0324951633810997, 0.05519365519285202, -0.054347045719623566, 0.14416420459747314, -0.13272106647491455, 0.13379554450511932, -0.10520987957715988, -0.01638888753950596, -0.021334512159228325, 0.08994992077350616, 0.03435433655977249, -0.09951858222484589, -0.20801013708114624, 1.1982004935763585e-32, -0.13401953876018524, -0.09499669075012207, -0.009648018516600132, 0.03377233445644379, 0.17071853578090668, 0.046030644327402115, 0.046550825238227844, -0.10322866588830948, 0.031811729073524475, -0.02196754887700081, -0.028253208845853806, 0.09022575616836548, -0.06815990805625916, 0.21788892149925232, 0.10222899168729782, -0.09248679876327515, -0.11973711848258972, -0.006508419290184975, -0.0857515037059784, -0.017416805028915405, 0.04922720789909363, 0.020698806270956993, 0.11612243205308914, -0.053962960839271545, -0.08482962846755981, -0.04643964394927025, 0.015127223916351795, -0.09569378942251205, 0.15049929916858673, -0.00014900323003530502, -0.1485660970211029, 0.1201346293091774, 0.02068186178803444, 0.03476561978459358, -0.008761396631598473, -0.07458654046058655, -0.06482227891683578, 0.1319020688533783, 0.013199605979025364, -0.07918243110179901, -0.052564866840839386, 0.06967932730913162, 0.03829415887594223, -0.14142155647277832, 0.015492305159568787, 0.07827530056238174, 0.0821276605129242, 0.2980588972568512, -0.13817477226257324, 0.07432615756988525, -0.009953521192073822, -0.1688658595085144, -0.06763873994350433, -0.1724289357662201, -0.09507216513156891, 0.053650446236133575, 0.22700683772563934, -0.024400781840085983, -0.016568753868341446, -0.0644775927066803, 0.052110105752944946, 0.006332785822451115, -0.04839329794049263, 0.04364421218633652, -0.036029644310474396, 0.0069455052725970745, 0.04330398142337799, 0.023624524474143982, -0.10219049453735352, 0.16408036649227142, -0.08504730463027954, 0.16973429918289185, 0.04716278985142708, -0.20701539516448975, 0.012312192469835281, -0.08279913663864136, 0.024697478860616684, 0.050753649324178696, -0.2073991894721985, 0.050989095121622086, -0.018720241263508797, 0.1815984547138214, -0.08367276191711426, -0.30537524819374084, -0.17339733242988586, 0.13419951498508453, 0.09335917234420776, -0.1285700798034668, -0.12194737792015076, -0.13809001445770264, -0.09865910559892654, 0.043005093932151794, 0.04465329274535179, 0.04377075284719467, -0.06060747429728508, -1.0117022904098546e-32, 0.03337196633219719, 0.16330090165138245, -0.028194207698106766, 0.12434850633144379, 0.06495293974876404, -0.049264948815107346, 0.08521204441785812, 0.008614355698227882, 0.05918126180768013, -0.13708049058914185, -0.04734572023153305, 0.00748184509575367, -0.01794440671801567, 0.02982303872704506, 0.038246240466833115, -0.0896095409989357, -0.03681904077529907, 0.030206553637981415, -0.11166256666183472, -0.060202207416296005, -0.19601193070411682, 0.251781165599823, -0.11350570619106293, -0.09235274791717529, -0.2680824100971222, 0.24468731880187988, -0.05396147072315216, 0.10722563415765762, -0.06416544318199158, -0.09647897630929947, -0.1764202117919922, 0.06982988864183426, -0.14516572654247284, -0.03099404089152813, 0.10138805210590363, 0.1158531904220581, 0.09200362861156464, -0.14986485242843628, -0.0819806307554245, 0.015370011329650879, 0.16198661923408508, 0.08056939393281937, -0.01952473260462284, 0.029628906399011612, -0.042618244886398315, -0.008542969822883606, 0.025718770921230316, 0.07057136297225952, -0.02065453492105007, 0.14143015444278717, -0.026100896298885345, -0.019827868789434433, -0.12247045338153839, 0.011487787589430809, -0.023038603365421295, 0.1012382060289383, -0.21334308385849, 0.1189425140619278, 0.1826752871274948, 0.09675239026546478, -0.17316573858261108, -0.08954276144504547, -0.16607946157455444, 0.023646099492907524, -0.03794509917497635, -0.00018514133989810944, -0.1987317055463791, -0.046508513391017914, -0.006991344504058361, 0.15272760391235352, -0.11040498316287994, -0.007929980754852295, 0.06987278163433075, -0.07555097341537476, -0.058245256543159485, -0.051189959049224854, -0.11797510832548141, 0.012561316601932049, -0.01995401829481125, -0.0481802262365818, 0.08476049453020096, -0.17184367775917053, 0.10418292880058289, 0.19055798649787903, 0.058908116072416306, 0.15373753011226654, 0.04237684607505798, -0.02744053304195404, 0.25381729006767273, -0.11880440264940262, 0.03121812455356121, 0.0219791978597641, 0.12963800132274628, 0.1934167444705963, 0.02265976555645466, -9.932962541370216e-08, 0.027817413210868835, 0.0269719697535038, 0.08040090650320053, -0.13549384474754333, 0.197322815656662, 0.017620008438825607, -0.0031022578477859497, 0.19984681904315948, 0.03849443048238754, -0.002843506634235382, 0.1653568148612976, -0.031042419373989105, -0.1255180835723877, 0.002000222448259592, -0.1259268820285797, 0.1998147964477539, 0.045395318418741226, -0.07374800741672516, 0.08657851815223694, 0.039974670857191086, -0.08788515627384186, -0.19784489274024963, -0.03948266804218292, 0.14703407883644104, -0.1554976999759674, -0.13101404905319214, -0.1492842137813568, 0.012714548036456108, 0.04696105048060417, -0.017330573871731758, -0.019920919090509415, -0.04553736746311188, 0.1846567690372467, 0.07566089928150177, 0.16528935730457306, 0.02730390802025795, -0.08903562277555466, 0.06097758933901787, -0.044719964265823364, -0.011778879910707474, -0.051684409379959106, 0.09320023655891418, 0.09067556262016296, -0.12291964888572693, 0.0899132639169693, 0.11600591242313385, 0.08076014369726181, -0.11017801612615585, 0.08588413894176483, 0.09551415592432022, 0.01500194612890482, 0.06579668074846268, -0.06019052490592003, 0.05573173612356186, 0.16272228956222534, -0.17067383229732513, -0.060473836958408356, -0.06607046723365784, 0.12181934714317322, 0.23946212232112885, 0.0016006547957658768, 0.045316003262996674, -0.03410851210355759, -0.05349750071763992], metadata={'source': 'AAAMLP-569to.pdf', 'page': 184}, content=\"Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 185 Approaching image classification & segmentation  When it comes to images, a lot has been achieved in the last few years. Computer vision is progressing quite fast, and it feels like many problems of computer vision are now much easier to solve. With the advent of pretrained models and cheaper compute, it’s now as easy as pie to train a near state-of-the-art model at home for most of the problems related to images. But there are many different types of image problems. You can have the standard classification of images in two or more categories to a challenging problem like self-driving cars. We won’t look at self-driving cars in this book, but we will obviously deal with some of the most common image problems.  What are the different approaches that we can apply to images? Image is nothing but a matrix of numbers. The computer cannot see the images as humans do. It only looks at numbers, and that’s what the images are. A grayscale image is a two-dimensional matrix with values ranging from 0 to 255. 0 is black, 255 is white and in between you have all shades of grey. Previously, when there was no deep learning (or when deep learning was not popular), people used to look at pixels. Each pixel was a feature. You can do this easily in Python. Just read the grayscale image using OpenCV or Python-PIL, convert to a numpy array and ravel (flatten) the matrix. If you are dealing with RGB images, then you have three matrices instead of one. But the idea remains the same.  ═════════════════════════════════════════════════════════════════════════ import numpy as np import matplotlib.pyplot as plt  # generate random numpy array with values from 0 to 255 # and a size of 256x256 random_image = np.random.randint(0, 256, (256, 256)) # initialize plot plt.figure(figsize=(7, 7)) # show grayscale image, nb: cmap, vmin and vmax plt.imshow(random_image, cmap='gray', vmin=0, vmax=255) plt.show() ═════════════════════════════════════════════════════════════════════════  The code above generates a random matrix using numpy. This matrix consists of values ranging from 0 to 255 (included) and is of size 256x256 (also known as pixels).\"),\n",
       " VectorParams(vector=[0.0733070895075798, 0.024344496428966522, 0.07901816815137863, -0.06355402618646622, 0.04548892751336098, -0.08660641312599182, -0.051983270794153214, 0.04114879295229912, 0.023803843185305595, 0.06994471698999405, -0.024157552048563957, -0.09380828589200974, 0.20780049264431, 0.17738987505435944, -0.11865759640932083, 0.01425706036388874, -0.09745418280363083, -0.057744186371564865, -0.12447918206453323, 0.15518611669540405, 0.06680215150117874, 0.05141334608197212, 0.010236707516014576, -0.09737659245729446, -0.1575523018836975, -0.04693599417805672, 0.0396251305937767, -0.08922752737998962, 0.01346638984978199, -0.09448105096817017, 0.03235065937042236, 0.14207614958286285, 0.0012073350371792912, 0.044018641114234924, 0.0008573833620175719, 0.018970131874084473, -0.05312902480363846, 0.12402850389480591, -0.023886319249868393, 0.13905927538871765, 0.022345276549458504, -0.0498201921582222, -0.10399466007947922, -0.029546070843935013, 0.0793466567993164, 0.11204705387353897, -0.11990746855735779, -0.03097001649439335, 0.004579971544444561, 0.007505342364311218, -0.08126693964004517, -0.00371773773804307, -0.21050871908664703, 0.16539739072322845, -0.11347295343875885, -0.2069758176803589, -0.10216126590967178, -0.11224693059921265, -0.0672689750790596, -0.09690484404563904, 0.07596845924854279, 0.010596330277621746, -0.035126734524965286, 0.003779631108045578, 0.13692501187324524, -0.024407116696238518, -0.02988353930413723, -0.011295660398900509, 0.06159590557217598, 0.04674382880330086, 0.045608557760715485, 0.0394764319062233, 0.01056377962231636, 0.1431659609079361, -0.16049137711524963, -0.003902787109836936, 0.1551816314458847, 0.07575125247240067, 0.1588795781135559, -0.1377517580986023, -0.04115752503275871, 0.005160732194781303, 0.016727648675441742, 0.057742200791835785, 0.18128904700279236, 0.08443859219551086, -0.12294390052556992, 0.08144691586494446, -0.17651379108428955, 0.04877018183469772, 0.04871406406164169, 0.03868184611201286, 0.09510335326194763, 0.01098556723445654, 0.1809501051902771, 0.004972012247890234, 0.09272947907447815, -0.05188711732625961, 0.05137122794985771, 0.08459537476301193, -0.0793733224272728, -0.06943223625421524, -0.005275578238070011, -0.0090753473341465, 0.11152337491512299, -0.13977201282978058, 0.0123636769130826, -0.0454058013856411, 0.2044525146484375, -0.10374107211828232, -0.001728424453176558, 0.052087921649217606, -0.06285088509321213, -0.05545029044151306, 0.15046940743923187, 0.08028967678546906, -0.05784139782190323, 0.02907814458012581, -0.015256529673933983, -0.024729998782277107, -0.06368406116962433, -0.08815796673297882, -0.10317143052816391, 0.0029793521389365196, 0.12567786872386932, -0.030546659603714943, -0.22953568398952484, 9.454144741938565e-33, 0.014495733194053173, -0.04723873361945152, 0.034498415887355804, -0.06514903157949448, 0.05333016812801361, 0.023331280797719955, -0.008448214270174503, 0.0009549030219204724, 0.09262743592262268, 0.1277095079421997, -0.12966617941856384, 0.05885540321469307, 0.022127389907836914, 0.02676253207027912, 0.07215581089258194, 0.030449600890278816, -0.08559999614953995, 0.04124755412340164, -0.11599984019994736, -0.022415289655327797, 0.05727468058466911, -0.021523887291550636, 0.06117606908082962, 0.016754504293203354, 0.013927909545600414, 0.029080063104629517, -0.06905056536197662, -0.11802667379379272, -0.041313592344522476, -0.023573309183120728, -0.1180867925286293, 0.0408756248652935, 0.026309188455343246, 0.04491179808974266, -0.12917441129684448, -0.07292567193508148, -0.1435779184103012, 0.038847245275974274, -0.06770513951778412, 0.02598601020872593, -0.020575398579239845, 0.0058098952285945415, 0.04213111102581024, -0.05730893090367317, 0.01639345847070217, 0.05447068437933922, -0.022043747827410698, -0.06732955574989319, -0.09657643735408783, -0.010416296310722828, 0.1690089851617813, 0.03814360499382019, -0.07405480742454529, -0.10933324694633484, -0.08908478170633316, 0.12159968167543411, -0.02534429170191288, 0.06117170304059982, -0.026698892936110497, 0.08811581134796143, 0.233800008893013, 0.011907714419066906, 0.07928097993135452, 0.09238839894533157, 0.005262627266347408, -0.011414343491196632, -0.046849217265844345, -0.0295771062374115, -0.006744541227817535, 0.02157704159617424, -0.09014129638671875, 0.07332655042409897, 0.08069067448377609, -0.18069389462471008, 0.08275201171636581, -0.029051944613456726, 0.08781368285417557, 0.1037142425775528, -0.029329245910048485, -0.011550233699381351, -0.007541473954916, 0.07862506061792374, 0.07980812340974808, -0.1517503708600998, -0.0111796073615551, 0.04480435326695442, 0.1312379539012909, -0.10417947173118591, -0.13813969492912292, 0.0665806457400322, -0.05185655876994133, 0.11899848282337189, -0.1620578020811081, 0.03683943301439285, 0.08615340292453766, -8.735131581739035e-33, -0.058089613914489746, 0.06737957894802094, 0.05548550561070442, 0.03401527181267738, -0.08120808750391006, 0.09798096865415573, 0.010168658569455147, 0.04196067526936531, -0.021707039326429367, -0.09979409724473953, 0.11520084738731384, 0.16524557769298553, -0.06513017416000366, 0.008405488915741444, -0.13691668212413788, 0.04243645444512367, -0.08479921519756317, -0.07233259826898575, -0.0005352525622583926, 0.09232866019010544, -0.05257943272590637, 0.24172444641590118, -0.18635042011737823, 0.06370799243450165, -0.1815650910139084, 0.21457061171531677, -0.041351545602083206, -0.07484948635101318, 0.09060215204954147, -0.14877688884735107, -0.04900231584906578, 0.028365982696413994, -0.022322796285152435, -0.06664589047431946, -0.030301978811621666, -0.007519028149545193, 0.030660131946206093, -0.10365267843008041, -0.013633865863084793, 0.02325952984392643, 0.09073688089847565, 0.03480997309088707, -0.09694593399763107, 0.032115038484334946, -0.02429467812180519, -0.09851787984371185, 0.08879631012678146, -0.041700925678014755, 0.11113641411066055, 0.02054421789944172, 0.034534890204668045, -0.007086625322699547, -0.10956969112157822, 0.16853947937488556, 0.019257595762610435, 0.04422745481133461, -0.1623726338148117, -0.0273569468408823, 0.09090324491262436, 0.0906454473733902, -0.13120102882385254, 0.012124027125537395, -0.1376979500055313, 0.04875233769416809, -0.040673330426216125, -0.009854073636233807, -0.02209395356476307, -0.02168588526546955, 0.053896497935056686, 0.022682135924696922, -0.052681565284729004, 0.09237640351057053, -0.08654391020536423, -0.0911162942647934, 0.01788061298429966, 0.06945839524269104, 0.07609740644693375, -0.03492606431245804, -0.03969474509358406, -0.08143319934606552, -0.12352367490530014, -0.05119297280907631, 0.02922709658741951, 0.1564512997865677, 0.03286909684538841, 0.09129656106233597, 0.1371525526046753, -0.13169503211975098, 0.05321049317717552, -0.07457053661346436, 0.02324710041284561, 0.06902645528316498, 0.04802921041846275, 0.024111885577440262, 0.13415968418121338, -9.966922220883134e-08, -0.07544418424367905, -0.0830424427986145, -0.08588756620883942, -0.07656490057706833, 0.10925079137086868, -0.07421192526817322, -0.14264576137065887, 0.12530039250850677, -0.05060901492834091, 0.014005517587065697, 0.12111833691596985, 0.019828032702207565, -0.22195948660373688, -0.08773408085107803, 0.021814873442053795, -0.01360245794057846, -0.05758700147271156, 0.05121827498078346, 0.01969411037862301, 0.11591366678476334, -0.08371992409229279, -0.10308480262756348, 0.042959488928318024, -0.030147787183523178, 0.029122369363904, -0.14040672779083252, -0.022732863202691078, -0.049623358994722366, 0.008461318910121918, 0.06735596805810928, -0.04004843533039093, 0.03123476728796959, -0.04725603759288788, 0.026528794318437576, 0.13789179921150208, 0.004694935865700245, 0.017802663147449493, -0.14525097608566284, 0.013932858593761921, 0.031550437211990356, 0.09426159411668777, -0.073185995221138, -0.04335763677954674, -0.05507076159119606, 0.058345794677734375, -0.03269282355904579, 0.01828146167099476, -0.16224022209644318, 0.08645445853471756, 0.037313755601644516, 0.022695433348417282, 0.010224714875221252, 0.0008006726857274771, -0.04066142439842224, 0.02867094613611698, 0.09838646650314331, 0.005917239002883434, -0.12485916912555695, 0.09275595843791962, 0.20133471488952637, 0.1814451962709427, -0.1781369000673294, -0.0478501170873642, -0.022104429081082344], metadata={'source': 'AAAMLP-569to.pdf', 'page': 185}, content=\"Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 186 Image Ravelled version of the image     Figure 1: A 2-D image array (single channel) and its ravelled version  As you can see that the ravelled version is nothing but a vector of size M, where M = N * N. In this case, this vector is of the size 256 * 256 = 65536.  Now, if we go ahead and do it for all the images in our dataset, we have 65536 features for each sample. We can now quickly build a decision tree model or random forest or SVM-based model on this data. The models will look at pixel values and would try to separate positive samples from negative samples (in case of a binary classification problem).  All of you must have heard about the cats vs dogs problem. It's a classic one. But let's try something different. If you remember, at the beginning of the chapter on evaluation metrics, I introduced you to a dataset of pneumothorax images. So, let’s try building a model to detect if an X-ray image of a lung has pneumothorax or not. That is, a (not so) simple binary classification.   No pneumothorax Pneumothorax \\n  Figure 2: Comparison of non-pneumothorax and pneumothorax x-ray images8.  8 https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation\"),\n",
       " VectorParams(vector=[-0.04533110186457634, -0.06154982000589371, -0.06558414548635483, -0.03960512951016426, 0.2129633128643036, -0.10474234819412231, 0.03526414930820465, -0.03797231242060661, -0.10949423909187317, -0.0040969327092170715, -0.0333985909819603, -0.1295682191848755, 0.10366883128881454, 0.10361533612012863, -0.15682220458984375, 0.049038179218769073, -0.09899133443832397, 0.02932390570640564, -0.15881630778312683, 0.07854404300451279, 0.007146095857024193, 0.049472469836473465, 0.053442489355802536, -0.04288176819682121, -0.07268621027469635, 0.04267267882823944, 0.11264510452747345, -0.0045121717266738415, -0.1348753273487091, -0.12077172100543976, 0.07947809249162674, 0.06692957878112793, -0.03893495351076126, -0.008187614381313324, 0.05530894547700882, 0.10452236235141754, -0.09749150276184082, 0.06367694586515427, -0.026675166562199593, -0.045134518295526505, 0.013554477132856846, -0.022304868325591087, -0.013149750418961048, -0.03864661976695061, 0.011979441158473492, 0.11513816565275192, -0.07916076481342316, -0.03187213093042374, 0.06754041463136673, -0.046599242836236954, -0.04352186247706413, 0.002208472229540348, -0.3340185284614563, 0.09982237219810486, 0.014220239594578743, -0.09112587571144104, -0.06850481778383255, -0.2210719734430313, 0.03963340073823929, -0.08099588006734848, 0.08764011412858963, -0.07106838375329971, -0.07755638659000397, -0.006498266477137804, 0.14801964163780212, 0.04229426011443138, -0.05812560021877289, -0.14252178370952606, 0.12130075693130493, -0.07878398895263672, -0.03981687128543854, 0.09775803983211517, 0.02831576205790043, 0.18153025209903717, -0.10646020621061325, 0.0696769505739212, 0.15244615077972412, 0.039680540561676025, 0.034368567168712616, -0.1283009797334671, -0.033286940306425095, 0.06963770091533661, 0.04883855953812599, -0.049267299473285675, 0.11572808027267456, -0.01646943762898445, -0.09480119496583939, 0.12461364269256592, -0.061615537852048874, -0.05183177813887596, 0.11972731351852417, 0.0958818793296814, -0.06871356070041656, -0.015746816992759705, 0.16001686453819275, -0.016566557809710503, 0.09995504468679428, -0.04381056874990463, 0.06679914891719818, 0.10351928323507309, 0.03653564676642418, 0.010391995310783386, -0.01050163246691227, -0.035545799881219864, 0.10735523700714111, -0.037184473127126694, 0.10578149557113647, 0.04838632047176361, 0.13837888836860657, -0.11186400055885315, -0.024717245250940323, -0.019505664706230164, -0.22332148253917694, -0.06629037857055664, 0.05050558224320412, 0.07532867044210434, 0.006477560847997665, 0.03259439766407013, -0.16006268560886383, 0.03335528448224068, -0.0829533189535141, -0.03214289993047714, 0.00024150976969394833, 0.06040005013346672, 0.13526637852191925, -0.15828436613082886, -0.18439815938472748, 1.5715931884423872e-32, -0.07181203365325928, 0.08352890610694885, 0.08347655832767487, -0.08825255930423737, 0.0680714100599289, 0.01936292089521885, -0.012145446613430977, -0.04771172255277634, -0.015205766074359417, 0.09019217640161514, -0.26532062888145447, 0.16689865291118622, -0.08798360824584961, 0.04950509965419769, 0.09242862462997437, -0.009136470966041088, -0.09761425852775574, 0.07567086070775986, -0.10281360894441605, 0.02707289531826973, 0.17560243606567383, -0.02471238188445568, 0.0343698225915432, 0.03225051611661911, -0.07085568457841873, -0.06151983514428139, -0.021550510078668594, -0.04013698920607567, 0.01622706465423107, 0.016082461923360825, -0.17072179913520813, 0.03454456105828285, 0.024339521303772926, 0.04775087162852287, -0.031355589628219604, -0.03461546078324318, -0.14268365502357483, 0.06705451756715775, -0.03898949176073074, 0.057652197778224945, 0.05977312847971916, 0.05114487558603287, 0.015144402161240578, -0.031829796731472015, 0.006081313826143742, 0.0335838720202446, 0.0848991870880127, 0.15180955827236176, -0.1378469467163086, 0.035326894372701645, 0.09434080123901367, -0.09405703097581863, -0.0929660052061081, -0.024977631866931915, -0.13354671001434326, 0.03617589920759201, 0.18640737235546112, -0.03154951333999634, 0.03906555473804474, -0.04355401545763016, 0.2149302363395691, -0.039030272513628006, 0.009195434860885143, 0.08407136052846909, -0.011083624325692654, -0.08221252262592316, 0.10923363268375397, 0.010027958080172539, -0.04087476059794426, 0.04787562042474747, -0.09951404482126236, 0.09844183176755905, 0.06670396775007248, -0.08103463053703308, 0.1357835978269577, -0.0873246043920517, 0.07474753260612488, 0.07623858004808426, -0.12551096081733704, 0.04812312126159668, -0.05627139285206795, 0.11066929250955582, 0.032896626740694046, -0.26274949312210083, -0.09480740875005722, 0.00793073233217001, 0.05726853385567665, -0.11927618086338043, -0.23682521283626556, -0.069332055747509, -0.053947657346725464, -0.004522227682173252, -0.08645348995923996, 0.007541025057435036, -0.037784356623888016, -1.2693361219635447e-32, 0.07556675374507904, -0.01708059571683407, 0.09338773041963577, 0.08602273464202881, 0.024692034348845482, 0.05659867078065872, 0.017083628103137016, 0.1321718990802765, -0.11688196659088135, -0.20767448842525482, 0.10602620989084244, -0.020328830927610397, 0.01883973553776741, -0.11362158507108688, -0.06626760214567184, -0.01218258123844862, 0.016468357294797897, 0.038223471492528915, -0.04182130843400955, 0.12270628660917282, -0.02082359604537487, 0.2566613256931305, -0.06416890770196915, 0.006324371788650751, -0.2351343333721161, 0.16101744771003723, 0.12617766857147217, -0.03902696073055267, 0.00566521193832159, -0.04462135210633278, -0.12705981731414795, 0.04003208875656128, -0.11376620084047318, 0.02099423296749592, -0.07310518622398376, -0.004996639676392078, 0.08345431834459305, -0.008878781460225582, -0.06967072933912277, 0.12309782207012177, 0.1269281655550003, 0.17271219193935394, -0.26816102862358093, 0.08294367790222168, -0.029803426936268806, -0.11556514352560043, 0.06757485121488571, 0.010181433521211147, 0.07506616413593292, 0.05221367999911308, 0.09141028672456741, -0.04792855679988861, 0.009396277368068695, 0.1546761393547058, 0.003119003027677536, 0.10025113075971603, -0.15039613842964172, 0.017112724483013153, 0.0628666877746582, 0.07774820923805237, -0.11314943432807922, -0.07404480874538422, -0.09153255075216293, 0.01270294189453125, 0.07212603837251663, 0.001963887130841613, -0.09234535694122314, 0.07399418950080872, -0.06066998094320297, 0.23932567238807678, -0.031981077045202255, -0.03654203563928604, -0.0347425751388073, 0.0018872107611969113, -0.007501502521336079, 0.01655498333275318, 0.07004952430725098, 0.008023399859666824, 0.07734385132789612, 0.016070416197180748, -0.08924268186092377, -0.04468265920877457, 0.06450404971837997, 0.24125568568706512, 0.06573456525802612, 0.18944977223873138, 0.09394605457782745, -0.07932373136281967, 0.08109087496995926, -0.042934488505125046, -0.0058875540271401405, -0.023613372817635536, 0.1382165402173996, 0.043275270611047745, 0.06580531597137451, -9.94314106605998e-08, -0.055938899517059326, 0.05929284170269966, -0.07546120882034302, -0.04920714721083641, 0.0558539442718029, -0.014853578060865402, -0.11381586641073227, 0.1302427053451538, -0.04037705436348915, -0.05707136541604996, 0.1757156103849411, -0.055080071091651917, -0.16040703654289246, 0.006159974727779627, -0.06067341938614845, 0.10401801019906998, 0.0049028415232896805, 0.036394402384757996, 0.0031276887748390436, 0.09738855063915253, -0.03684869408607483, -0.06717020273208618, 0.08464162051677704, 0.0027448455803096294, -0.021259402856230736, -0.04037487879395485, -0.007444854825735092, 0.05774621292948723, 0.028337405994534492, -0.01323335338383913, -0.02776428312063217, -0.1104285717010498, -0.02606811188161373, -0.04364380985498428, 0.06286316365003586, 0.058090824633836746, -0.007336048409342766, -0.027418723329901695, -0.0889640673995018, 0.01032331958413124, -0.01868418976664543, -0.0020011616870760918, -0.07031106948852539, -0.08093409240245819, 0.05221967399120331, 0.054204557090997696, 0.08383821696043015, -0.06553757935762405, 0.017602933570742607, 0.036239638924598694, 0.07143526524305344, -0.028658024966716766, -0.08607303351163864, -0.0162850059568882, 0.11007750034332275, -0.030959023162722588, 0.045231446623802185, -0.07359297573566437, 0.04289417713880539, 0.1485329419374466, 0.029882004484534264, -0.14239102602005005, -0.02726912312209606, -0.019234707579016685], metadata={'source': 'AAAMLP-569to.pdf', 'page': 186}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 187 In figure 2, you can see a comparison between non-pneumothorax and pneumothorax images. As you must have already noticed, it is quite difficult for a non-expert (like me) to even identify which of these images have pneumothorax.   The original dataset is about detecting where exactly pneumothorax is present, but we have modified the problem to find if the given x-ray image has pneumothorax or not. Don’t worry; we will cover the where part in this chapter. The dataset consists of 10675 unique images and 2379 have pneumothorax (note that these numbers are after some cleaning of data and thus do not match original dataset). As a data doctor would say: this is a classic case of skewed binary classification. Therefore, we choose the evaluation metric to be AUC and go for a stratified k-fold cross-validation scheme.  You can flatten out the features and try some classical methods like SVM, RF for doing classification, which is perfectly fine, but it won\\'t get you anywhere near state of the art. Also, the images are of size 1024x1024. It’s going to take a long time to train a model on this dataset. For what it’s worth, let’s try building a simple random forest model on this data. Since the images are grayscale, we do not need to do any kind of conversion. We will resize the images to 256x256 to make them smaller and use AUC as a metric as discussed before.  Let’s see how this performs.  ═════════════════════════════════════════════════════════════════════════ import os  import numpy as np import pandas as pd  from PIL import Image from sklearn import ensemble from sklearn import metrics from sklearn import model_selection from tqdm import tqdm   def create_dataset(training_df, image_dir):     \"\"\"     This function takes the training dataframe     and outputs training array and labels     :param training_df: dataframe with ImageId, Target columns     :param image_dir: location of images (folder), string     :return: X, y (training array with features and labels)'),\n",
       " VectorParams(vector=[-0.06433869153261185, -0.047441516071558, 0.027119731530547142, -0.09902715682983398, 0.04964462295174599, -0.15284575521945953, 0.09886085987091064, -0.04541917145252228, -0.10641839355230331, 0.04392562061548233, -0.047690361738204956, 0.03221805393695831, 0.16370782256126404, -0.09784279763698578, -0.12366596609354019, 0.08890817314386368, -0.236748605966568, 0.09921938925981522, -0.08502230048179626, -0.1640816479921341, -0.06101546064019203, 0.04662355035543442, 0.15431110560894012, -0.08118908852338791, -0.06386817991733551, -0.06311698257923126, 0.18973706662654877, 0.09217733144760132, -0.12576067447662354, -0.11270835250616074, 0.07891633361577988, 0.04039078950881958, 0.02933032065629959, -0.04947151243686676, -0.005320001393556595, 0.1366979330778122, -0.16085155308246613, 0.020050793886184692, -0.017861708998680115, 0.09229926019906998, 0.035318903625011444, 0.06982749700546265, -0.05551442876458168, -0.08649075031280518, 0.1434149593114853, 0.07788075506687164, -0.06135959178209305, -0.13272187113761902, 0.1580566167831421, -0.07517879456281662, -0.16960182785987854, 0.031896259635686874, -0.19481301307678223, 0.026099100708961487, -0.1052912250161171, -0.10520928353071213, 0.15285632014274597, -0.11153053492307663, 0.01276008877903223, -0.006807396654039621, 0.030033133924007416, -0.046693746000528336, 0.053444016724824905, -0.0877191573381424, 0.06891115754842758, -0.10094784200191498, -0.057354886084795, 0.05855269357562065, 0.043969325721263885, -0.0756862685084343, -0.06171296909451485, 0.208520770072937, -0.05617247894406319, 0.10632476210594177, -0.09437873959541321, -0.059097081422805786, 0.10182034969329834, -0.018960000947117805, 0.10674593597650528, -0.11920447647571564, -0.14626355469226837, -0.16158102452754974, 0.12298676371574402, -0.07275700569152832, 0.0901883989572525, -0.10932871699333191, 0.0213848277926445, 0.09427010267972946, 0.013745889998972416, -0.13014674186706543, 0.03199196979403496, 0.07716772705316544, -0.14889079332351685, 0.03961455449461937, 0.01365408580750227, 0.07203824073076248, 0.20167025923728943, -0.09349636733531952, -0.004496995825320482, 0.0965723842382431, 0.09532603621482849, -0.1108822450041771, 0.00011807747796410695, 0.07383865118026733, 0.09273909032344818, 0.07870300114154816, 0.2687753438949585, 0.09648662060499191, 0.10696060210466385, -0.1585502028465271, -0.03624345734715462, 0.023082681000232697, -0.08924519270658493, 0.042252980172634125, 0.042524728924036026, 0.062296800315380096, -0.06442102789878845, 0.07204584032297134, -0.1566155105829239, 0.049963947385549545, -0.1291055679321289, 0.06809283792972565, -0.09885606914758682, 0.03555259853601456, -0.13227207958698273, -0.05191994085907936, -0.07098259031772614, 1.8751330131315646e-32, -0.05873957648873329, -0.06057862192392349, 0.08753266930580139, -0.12255876511335373, 0.1388421505689621, -0.04437296837568283, 0.12157165259122849, -0.1000945195555687, -0.13176704943180084, -0.047343660145998, -0.20220044255256653, -0.016845328733325005, -0.053985122591257095, 0.089849092066288, -0.004688877612352371, -0.13618707656860352, -0.08611003309488297, 0.1522660255432129, 0.08116023242473602, -0.016582172363996506, 0.19580957293510437, 0.01670135371387005, 0.005620014853775501, -0.0264281015843153, -0.1536864936351776, -0.14376845955848694, -0.03815395012497902, 0.07307785749435425, -0.06540214270353317, -0.040981050580739975, -0.19486238062381744, 0.049020685255527496, -0.06041821837425232, -0.031676191836595535, -0.09921226650476456, -0.22202983498573303, 0.06788557022809982, 0.1713329702615738, -0.17276139557361603, -0.034372422844171524, 0.0844726413488388, 0.06445634365081787, 0.11889945715665817, -0.09949705749750137, -0.05876966193318367, 0.05725307762622833, 0.09851627796888351, 0.1962158977985382, -0.04256735369563103, 0.07430833578109741, -0.034892067313194275, -0.12057908624410629, 0.022177040576934814, 0.005780757870525122, -0.09831488132476807, 0.0016154325567185879, 0.22277486324310303, -0.07338245213031769, 0.11445435136556625, -0.0074938139878213406, 0.04474306479096413, 0.06963898241519928, -0.039325278252363205, 0.18379704654216766, 0.0803450345993042, -0.06229109689593315, 0.23822730779647827, -0.025605827569961548, -0.014275992289185524, 0.0760686993598938, -0.07500668615102768, 0.19380180537700653, 0.014770238660275936, -0.16757100820541382, 0.0769893005490303, -0.12638242542743683, -0.013587139546871185, 0.051348794251680374, -0.23342525959014893, 0.026028703898191452, 0.010802717879414558, 0.12384947389364243, -0.0508078970015049, -0.34357237815856934, -0.08273624628782272, -0.0369761660695076, 0.08698373287916183, -0.24198777973651886, -0.19816258549690247, -0.18235518038272858, -0.1121155321598053, -0.001972789876163006, -0.003140106098726392, -0.007584250532090664, -0.04454974830150604, -1.5120630688440757e-32, 0.13190805912017822, 0.10610689222812653, 0.1689092516899109, 0.06059924140572548, 0.1179681345820427, 0.06636872887611389, 0.09470068663358688, 0.05185577645897865, -0.007840664125978947, -0.20999184250831604, -0.05166322737932205, -0.13300655782222748, 0.0307780634611845, -0.04416554048657417, 0.007413792423903942, -0.031978342682123184, 0.014791257679462433, 0.10050218552350998, -0.07175258547067642, 0.04633735492825508, -0.15691453218460083, 0.2170877456665039, -0.017820190638303757, 0.044984012842178345, -0.17640268802642822, 0.14554943144321442, 0.09498926997184753, 0.10927695780992508, -0.041081029921770096, -0.07512965798377991, -0.10104161500930786, 0.044019732624292374, -0.18687619268894196, 0.07212329655885696, 0.048740193247795105, -0.016617393121123314, 0.14293573796749115, -0.08310678601264954, -0.0726565420627594, 0.13094580173492432, 0.13211214542388916, 0.07728049904108047, -0.09042728692293167, 0.03566646948456764, 0.029421327635645866, -0.03479672595858574, 0.01899832859635353, 0.010166271589696407, -0.12908786535263062, 0.14559374749660492, -0.02587776817381382, -0.016084838658571243, -0.1206672191619873, 0.05548930913209915, 0.0870586410164833, 0.042234163731336594, -0.16410495340824127, 0.0761198103427887, -0.012744905427098274, 0.03375519439578056, -0.1061789020895958, -0.07285332679748535, -0.1635882407426834, -0.09292769432067871, 0.12529076635837555, 0.12854650616645813, -0.23499323427677155, 0.05243847519159317, 0.07103446125984192, 0.14933715760707855, -0.10165058821439743, 0.03268986567854881, 0.12844376266002655, -0.03801708668470383, -0.05712895467877388, 0.021236825734376907, -0.06453737616539001, 0.0263355802744627, -0.005064947064965963, 0.08355330675840378, 0.004156819079071283, -0.08887563645839691, 0.08381307125091553, 0.15883290767669678, 0.011554560624063015, 0.17031678557395935, 0.08966340869665146, -0.020005492493510246, 0.1927853673696518, -0.01037854515016079, 0.024517124518752098, -0.08790997415781021, 0.25521159172058105, 0.17741115391254425, 0.03725622221827507, -1.0021370400181695e-07, 0.032955776900053024, 0.12243996560573578, -0.0699952095746994, 0.07399126142263412, 0.059125423431396484, 0.015321030281484127, -0.022658243775367737, 0.09669861197471619, 0.010567836463451385, -0.08480819314718246, 0.1997814178466797, -0.01009182259440422, -0.10365679115056992, 0.13647527992725372, -0.0527954064309597, 0.0739382803440094, -0.029392942786216736, 0.047987744212150574, 0.07960550487041473, 0.033430229872465134, 0.015388415195047855, -0.08206425607204437, -0.026708709076046944, -0.02347484976053238, -0.09328819066286087, -0.12902286648750305, -0.007893475703895092, -0.05192573741078377, 0.08932669460773468, -0.0616208091378212, -0.016174685209989548, -0.20533901453018188, 0.0925818681716919, 0.05227198079228401, 0.2012246698141098, -0.059437885880470276, -0.03525727614760399, -0.049583595246076584, -0.01966925337910652, 0.06089058518409729, -0.11288472265005112, 0.08132218569517136, -0.029096512123942375, -0.09008210152387619, 0.07052899897098541, -0.036435533314943314, 0.0504644438624382, 0.027871055528521538, 0.18140192329883575, 0.046347521245479584, 0.027365216985344887, -0.09394638240337372, -0.023308033123612404, -0.061809103935956955, 0.22377778589725494, -0.02399432472884655, -0.03413599729537964, 0.07025150209665298, 0.05910444259643555, 0.08194470405578613, 0.043426513671875, -0.03549819067120552, -0.008202964439988136, -0.04961277171969414], metadata={'source': 'AAAMLP-569to.pdf', 'page': 187}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 188     \"\"\"     # create empty list to store image vectors     images = []     # create empty list to store targets     targets = []     # loop over the dataframe     for index, row in tqdm(         training_df.iterrows(),          total=len(training_df),          desc=\"processing images\"     ):         # get image id         image_id = row[\"ImageId\"]         # create image path         image_path = os.path.join(image_dir, image_id)         # open image using PIL         image = Image.open(image_path + \".png\")         # resize image to 256x256. we use bilinear resampling         image = image.resize((256, 256), resample=Image.BILINEAR)         # convert image to array         image = np.array(image)         # ravel         image = image.ravel()         # append images and targets lists         images.append(image)         targets.append(int(row[\"target\"]))     # convert list of list of images to numpy array     images = np.array(images)     # print size of this array     print(images.shape)     return images, targets   if __name__ == \"__main__\":     csv_path = \"/home/abhishek/workspace/siim_png/train.csv\"     image_path = \"/home/abhishek/workspace/siim_png/train_png/\"      # read CSV with imageid and target columns     df = pd.read_csv(csv_path)      # we create a new column called kfold and fill it with -1     df[\"kfold\"] = -1          # the next step is to randomize the rows of the data     df = df.sample(frac=1).reset_index(drop=True)          # fetch labels'),\n",
       " VectorParams(vector=[-0.02835703454911709, -0.13058876991271973, -0.032853953540325165, 0.09644956141710281, 0.229421466588974, -0.10392848402261734, -0.0029465951956808567, 0.0769762247800827, -0.07266795635223389, 0.10113555938005447, 0.017175056040287018, -0.14513948559761047, -0.08854925632476807, -0.019373221322894096, -0.05176874250173569, 0.061985451728105545, -0.07996947318315506, 0.03627839311957359, -0.11042417585849762, 0.03480810672044754, 0.07351000607013702, 0.07818970084190369, 0.06197693943977356, 0.06485054641962051, 0.00030640672775916755, -0.09835506230592728, 0.04635254666209221, 0.027777424082159996, -0.11549066007137299, -0.08428549766540527, -0.01636100374162197, 0.03891106694936752, 0.07701772451400757, 0.017649127170443535, -0.06986517459154129, 0.038506146520376205, -0.007523589301854372, 0.01624336838722229, -0.1153557226061821, 0.04215579479932785, -0.08549827337265015, -0.006308096460998058, 0.0072541614063084126, 0.01701575145125389, 0.04427393153309822, 0.13801899552345276, -0.062072400003671646, -0.1043602004647255, 0.10536220669746399, 0.01094333827495575, 0.025457607582211494, 0.06784233450889587, -0.22490178048610687, -0.062286101281642914, -0.09282051771879196, -0.05339839681982994, 0.03441423922777176, -0.1770469844341278, 0.02456510066986084, 0.023608198389410973, 0.014392951503396034, -0.13471390306949615, -0.031581271439790726, -0.07767069339752197, 0.07108902931213379, -0.03176082670688629, -0.010664260014891624, -0.02101929299533367, 0.008786754682660103, 0.03854113072156906, -0.02216705121099949, 0.08023365586996078, -0.031210247427225113, 0.0049118283204734325, -0.0663447231054306, 0.03767125681042671, 0.19662228226661682, 0.034506604075431824, 0.1023574024438858, -0.09320205450057983, -0.107674740254879, 0.07040462642908096, 0.03732216730713844, -0.06585125625133514, 0.07378602772951126, -0.11662403494119644, 0.12927459180355072, 0.058148205280303955, 0.05764263868331909, -0.04090350866317749, 0.13220027089118958, 0.04706895351409912, -0.12081893533468246, -0.01970045454800129, 0.021502090618014336, 0.0817900151014328, 0.16699157655239105, 0.02016049064695835, 0.09676595032215118, 0.09067261219024658, -0.04202404245734215, 0.03452155366539955, 0.049251899123191833, 0.0033941289875656366, 0.07054764032363892, -0.04344553500413895, 0.15106822550296783, 0.06713156402111053, 0.054405733942985535, -0.061014723032712936, -0.02303953655064106, -0.10692008584737778, -0.09535801410675049, 0.0814751461148262, 0.0997285395860672, 0.03412344306707382, -0.05710792914032936, 0.045974250882864, -0.12467455863952637, 0.12148813158273697, -0.06931823492050171, 0.08433671295642853, 0.057278234511613846, 0.039957113564014435, 0.0022362424060702324, -0.07540067285299301, -0.07919802516698837, 1.402524333889113e-32, -0.10117476433515549, -0.01917257159948349, 0.015989292412996292, -0.096366748213768, 0.03294098749756813, -0.0651588961482048, 0.04743977636098862, -0.016605602577328682, 0.007173279765993357, 0.10804175585508347, -0.20935995876789093, 0.05638527870178223, -0.01197351235896349, 0.020369280129671097, 0.0444270558655262, -0.035868190228939056, -0.05465424433350563, 0.017023464664816856, -0.023603271692991257, 0.020306741818785667, 0.28104114532470703, -0.033769287168979645, 0.0018862952711060643, -0.07821482419967651, -0.12241135537624359, -0.0406709648668766, -0.04835409298539162, 0.00959526002407074, -0.09394212812185287, 0.027285218238830566, -0.17816253006458282, 0.053303707391023636, -0.04714198783040047, -0.020454345270991325, 0.024373233318328857, -0.07892794162034988, 0.08729982376098633, 0.136125847697258, -0.06563590466976166, -0.023041876032948494, 0.09302164614200592, 0.032429039478302, 0.03673122823238373, -0.04022674262523651, -0.0575769878923893, -0.08737010508775711, 0.08048795908689499, 0.1710166037082672, -0.053642578423023224, 0.1108495369553566, -0.019637582823634148, -0.16638073325157166, -0.005577202886343002, -0.024124225601553917, -0.09129630774259567, 0.17689093947410583, 0.1625901758670807, -0.004354292061179876, 0.041729800403118134, 0.015244977548718452, -0.031910885125398636, 0.024585753679275513, -0.0363406240940094, 0.052925195544958115, -0.013542060740292072, 0.01582569070160389, 0.13896514475345612, -0.05684063211083412, 0.028760602697730064, 0.043642379343509674, -0.09200211614370346, 0.1167081743478775, -0.11744119971990585, -0.18088994920253754, 0.046858251094818115, -0.109088234603405, 0.122010737657547, 0.059077393263578415, -0.14012411236763, 0.006606181617826223, -0.07719994336366653, 0.20563802123069763, -0.11122317612171173, -0.2806105613708496, 0.060158632695674896, 0.004425890278071165, 0.06300987303256989, -0.047915130853652954, -0.2392895370721817, -0.18246211111545563, -0.16664567589759827, -0.05623295530676842, 0.09429370611906052, -0.08074618130922318, 0.002728428691625595, -1.3183067758084196e-32, 0.08677754551172256, 0.00709161814302206, 0.12394841760396957, 0.15805906057357788, 0.07762336730957031, 0.13037188351154327, 0.05814644321799278, 0.07676346600055695, -0.14522778987884521, -0.1473418027162552, -0.037474051117897034, -0.08216440677642822, 0.11934114247560501, 0.027846280485391617, 0.05999840050935745, 0.02161499485373497, -0.05666666850447655, 0.0953657329082489, -0.10115207731723785, 0.037460602819919586, -0.07203079760074615, 0.145908385515213, -0.004488756880164146, -0.026321573182940483, -0.13425523042678833, 0.012732041999697685, -0.0023703575134277344, 0.11670474708080292, -0.028758667409420013, -0.10308700054883957, -0.10140552371740341, -0.02433033101260662, -0.10697299242019653, 0.06900244206190109, -0.004476620815694332, -0.08081371337175369, 0.0453520193696022, -0.07370749115943909, -0.1325453370809555, 0.19166725873947144, 0.08746300637722015, 0.13330289721488953, -0.20240584015846252, 0.10717736184597015, -0.04586314037442207, -0.0486159548163414, -0.0475553460419178, 0.014700825326144695, 0.014996761456131935, -0.04873461276292801, 0.0913330614566803, -0.10611368715763092, -0.11705104261636734, 0.08878902345895767, -0.10017463564872742, 0.16752459108829498, -0.13441544771194458, -0.000999249517917633, -0.09651471674442291, 0.10484778881072998, -0.02372955158352852, -0.037662941962480545, -0.04499497264623642, -0.048976317048072815, 0.16107715666294098, 0.00399826280772686, -0.12123138457536697, 0.029196545481681824, -0.02996099181473255, 0.13081711530685425, -0.06277374923229218, -0.012036528438329697, -0.02864878810942173, -0.07712682336568832, 0.03622380271553993, -0.0006969360983930528, -0.001483454369008541, 0.025733649730682373, 0.10273028165102005, 0.06782490760087967, -0.030749108642339706, -0.04492136836051941, 0.020162658765912056, 0.13214664161205292, -0.049415115267038345, 0.13065829873085022, 0.14624318480491638, 0.06391552835702896, 0.06183392181992531, -0.08167856186628342, 0.01583084836602211, -0.06547702103853226, 0.09714236855506897, 0.2112712413072586, 0.014072027057409286, -1.0004667672092182e-07, 0.01283904630690813, 0.09199992567300797, 0.07947292923927307, 0.027685299515724182, 0.07968614995479584, 0.034564364701509476, -0.11638448387384415, 0.04192911833524704, -0.10068226605653763, 0.019375504925847054, 0.10899556428194046, 0.03468283265829086, -0.14123670756816864, 0.13472311198711395, -0.053932152688503265, 0.00010294011008227244, 0.032686103135347366, 0.12475814670324326, -0.04389302432537079, 0.06033262237906456, 0.054902780801057816, -0.12244388461112976, 0.08472825586795807, 0.007702550385147333, 0.02158030867576599, -0.0968967080116272, 0.007430661004036665, 0.020200196653604507, 0.06763211637735367, 0.013856178149580956, -0.05635044723749161, -0.1389271467924118, 0.0011003490071743727, 0.020607126876711845, 0.06763660907745361, 0.10879354923963547, 0.002882055239751935, -0.06687329709529877, -0.05139639228582382, 0.22014689445495605, -0.045193810015916824, 0.05904073268175125, -0.13633950054645538, -0.07852126657962799, -0.02686396613717079, 0.024202214553952217, 0.012278887443244457, -0.030145473778247833, 0.03247027099132538, -0.051091913133859634, -0.04442889615893364, -0.06583480536937714, -0.14868412911891937, 0.06078847497701645, 0.06999243795871735, -0.004605213645845652, -0.04143742099404335, -0.06034817546606064, -0.013603933155536652, 0.09629108756780624, -0.012343158945441246, -0.12077101320028305, -0.06934241205453873, -0.033202268183231354], metadata={'source': 'AAAMLP-569to.pdf', 'page': 188}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 189     y = df.target.values          # initiate the kfold class from model_selection module     kf = model_selection.StratifiedKFold(n_splits=5)          # fill the new kfold column     for f, (t_, v_) in enumerate(kf.split(X=df, y=y)):         df.loc[v_, \\'kfold\\'] = f      # we go over the folds created     for fold_ in range(5):         # temporary dataframes for train and test         train_df = df[df.kfold != fold_].reset_index(drop=True)         test_df = df[df.kfold == fold_].reset_index(drop=True)                  # create train dataset         # you can move this outside to save some computation time         xtrain, ytrain = create_dataset(train_df, image_path)          # create test dataset         # you can move this outside to save some computation time         xtest, ytest = create_dataset(test_df, image_path)          # fit random forest without any modification of params         clf = ensemble.RandomForestClassifier(n_jobs=-1)         clf.fit(xtrain, ytrain)          # predict probability of class 1         preds = clf.predict_proba(xtest)[:, 1]          # print results         print(f\"FOLD: {fold_}\")         print(f\"AUC = {metrics.roc_auc_score(ytest, preds)}\")         print(\"\") ═════════════════════════════════════════════════════════════════════════  This gives a mean AUC of around 0.72.  Which is not bad but hopefully, we can do a lot better. You can use this approach for images, and this is how it was used in good old times. SVM was quite famous for image datasets. Deep Learning has been proved to be the state of the art when solving such problems, hence we could try that next.'),\n",
       " VectorParams(vector=[-0.19889193773269653, -0.15552788972854614, 0.06367430835962296, -0.026874076575040817, 0.041882406920194626, -0.021551068872213364, -0.028324976563453674, -0.0740647241473198, 0.014794179238379002, -0.16319401562213898, -0.16881631314754486, 0.028157727792859077, -0.006476733833551407, 0.05286592245101929, -0.265031099319458, 0.061428409069776535, 0.04022298753261566, 0.055799491703510284, -0.2990865409374237, -0.006992483977228403, 0.22070641815662384, 0.0004852080310229212, -0.08511395752429962, -0.04670863598585129, 0.0765490010380745, 0.11201506108045578, -0.09608287364244461, -0.2043461948633194, 0.05080687254667282, -0.10238296538591385, 0.06496816128492355, 0.06458919495344162, 0.03440258651971817, 0.10984921455383301, -0.0565200038254261, 0.08730456978082657, -0.007816856727004051, 0.0909499004483223, 0.05952482670545578, 0.018343238160014153, 0.042655885219573975, -0.0579342320561409, -0.02588416449725628, 0.09200264513492584, 0.09127040207386017, 0.13873805105686188, -0.020814310759305954, -0.15085147321224213, 0.04438034072518349, -0.00766088766977191, -0.10053864866495132, 0.009959626942873001, -0.06970521807670593, 0.14610885083675385, 0.07986804097890854, -0.19327379763126373, -0.11699880659580231, 0.04641026630997658, -0.15700706839561462, 0.06194661930203438, 0.03024967946112156, -0.12434264272451401, -0.001333480584435165, 0.042197465896606445, 0.0950416773557663, -0.12730208039283752, -0.11074995994567871, -2.1875539459870197e-05, -0.04875517636537552, 0.05021386966109276, 0.09661269932985306, 0.18633942306041718, -0.0719367116689682, 0.016220616176724434, 0.2037389725446701, -0.05775536969304085, 0.1543199121952057, 0.1070120632648468, -0.012856593355536461, -0.0933687835931778, 0.22942955791950226, 0.029337193816900253, 0.0345878079533577, -0.02703046426177025, 0.06592697650194168, -0.029847286641597748, -0.24966175854206085, -0.04678774252533913, -0.030276913195848465, -0.0948202833533287, -0.10110989958047867, 0.05181996896862984, -0.111906997859478, -0.07626599073410034, 0.20840659737586975, -0.0016213638009503484, -0.1779787242412567, -0.11884040385484695, -0.055088110268116, 0.12151797860860825, 0.0014397429767996073, -0.04788484424352646, 0.22382484376430511, 0.04770684242248535, 0.17116035521030426, -0.038674246519804, 0.08467122167348862, 0.12688954174518585, 0.017383703961968422, -0.19945788383483887, 0.07572692632675171, -0.1275509148836136, 0.058743592351675034, -0.06018482521176338, 0.10726732015609741, 0.007769275922328234, -0.06768440455198288, 0.042748477309942245, 0.13872526586055756, 0.0931982472538948, -0.18001002073287964, 0.07200061529874802, -0.1299075335264206, -0.03176353499293327, 0.06649186462163925, 0.1422121524810791, -0.1688617318868637, 1.0172410728541354e-32, -0.0001233205257449299, -0.021899178624153137, 0.02911936305463314, 0.001142263412475586, 0.001273790025152266, -0.11712825298309326, 0.011829614639282227, -0.04649636894464493, 0.02997712977230549, 0.061694178730249405, -0.13600820302963257, -0.001043900614604354, -0.03576646000146866, 0.2138308584690094, 0.08576154708862305, -0.049793124198913574, -0.04666414484381676, 0.06675437837839127, 0.06191422790288925, -0.12512260675430298, 0.05539759248495102, 0.06980686634778976, 0.04166051372885704, -0.04599756374955177, -0.15572437644004822, -0.056061699986457825, 0.027791084721684456, -0.03620017692446709, -0.04179497808218002, 0.0659731775522232, -0.12750190496444702, 0.10432327538728714, -0.06065846234560013, 0.07432062178850174, -0.07932757586240768, 0.034547995775938034, -0.039348453283309937, -0.03317702189087868, 0.09310849756002426, -0.06530541926622391, -0.06280843168497086, 0.08491451293230057, 0.06427731364965439, -0.09765556454658508, -0.0717402845621109, -0.10804855078458786, 0.03523406758904457, -0.02220471017062664, -0.16021233797073364, 0.03315990790724754, 0.07354799658060074, -0.030507780611515045, -0.07521002739667892, -0.09299348294734955, 0.0800510123372078, 0.019772056490182877, 0.06111591309309006, 0.13795888423919678, 0.07951028645038605, 0.1939513236284256, 0.09556731581687927, 0.019977698102593422, -0.2068050056695938, 0.11653556674718857, 0.019001007080078125, 0.04304053261876106, 0.14890508353710175, 0.04892329126596451, 0.14376574754714966, 0.011609748005867004, -0.05387202277779579, 0.018087685108184814, 0.019154228270053864, -0.08854152262210846, 0.18110154569149017, -0.11743085831403732, 0.01811692863702774, -0.08002609759569168, -0.07555429637432098, 0.1496237814426422, -0.023488717153668404, 0.1427871435880661, -0.05344732478260994, -0.05947235971689224, -0.28934699296951294, 0.14786171913146973, 0.10566680133342743, -0.05241364240646362, -0.019598986953496933, -0.011510027572512627, -0.09661435335874557, -0.027804603800177574, 0.0015169342514127493, -0.04624694958329201, 0.06128362566232681, -1.0149074226941655e-32, 0.05550489202141762, 0.056502752006053925, -0.13469953835010529, 0.11141803860664368, -0.022674934938549995, -0.017112042754888535, -0.035996850579977036, 0.0405653677880764, -0.08989808708429337, -0.11637342721223831, 0.05398883670568466, 0.03979504853487015, 0.08721655607223511, -0.01152399368584156, -0.008130430243909359, -0.1473655104637146, -0.1159466803073883, -0.1363225132226944, 0.04978109896183014, -0.11263687908649445, 0.11994776874780655, 0.14363057911396027, -0.015774628147482872, 0.06648612767457962, -0.15853868424892426, -0.029765291139483452, -0.08519227057695389, 0.020153045654296875, 0.08085451275110245, 0.07250463962554932, -0.09566453844308853, -0.15558521449565887, -0.1304556131362915, 0.11103177070617676, 0.08731339126825333, 0.13021133840084076, 0.046234481036663055, 0.02188555710017681, -0.021955441683530807, -0.074747234582901, 0.08155791461467743, -0.101353719830513, 0.0874616801738739, 0.024936141446232796, 0.01077521312981844, -0.02469681389629841, -0.018172144889831543, -0.003938970621675253, -0.11146724224090576, -0.01388951949775219, -0.04711896926164627, -0.017658449709415436, -0.13967852294445038, 0.04894896596670151, -0.031704388558864594, 0.056764718145132065, -0.003798768389970064, 0.06687953323125839, 0.177414670586586, 0.06676209717988968, -0.09007638692855835, -0.056627485901117325, -0.2095487415790558, -0.07857024669647217, -0.05405623838305473, 0.10132168233394623, -0.14018546044826508, 0.14459764957427979, 0.04059356823563576, 0.12496409565210342, -0.12461306154727936, -0.009228217415511608, 0.06662832945585251, 0.038334477692842484, -0.12513814866542816, -0.06288070231676102, 0.02727910876274109, -0.012876679189503193, -0.020183125510811806, 0.06071928143501282, -0.1598389744758606, 0.004871714394539595, -0.04215154051780701, 0.2191985696554184, 0.231997549533844, 0.01669541746377945, 0.09360940009355545, -0.05592470243573189, 0.07314172387123108, -0.0630456805229187, -0.0020458020735532045, -0.0610189288854599, -0.1085418239235878, 0.14195142686367035, -0.1081339418888092, -9.96921372120596e-08, -0.002506740391254425, 0.088237464427948, -0.03332662209868431, -0.08338158577680588, 0.22919782996177673, -0.13618555665016174, 0.06866853684186935, 0.31595566868782043, -0.0702354833483696, 0.1164667010307312, 0.049012646079063416, 0.07373020052909851, -0.04779072478413582, -0.07134245336055756, -0.03192218393087387, 0.10325995832681656, -0.049783855676651, -0.0670703798532486, 0.050622712820768356, -0.05525464564561844, 0.08561038225889206, -0.07742741703987122, -0.019207706674933434, -0.0256251972168684, 0.008146549575030804, -0.11052652448415756, -0.1464952528476715, -0.04073995724320412, 0.035723648965358734, -0.006232246290892363, -0.03661521524190903, 0.07357168942689896, -0.004169779364019632, -0.08073979616165161, 0.1594577133655548, 0.10916492342948914, -0.09639409929513931, -0.0028638094663619995, -0.051204878836870193, -0.13251395523548126, -0.06775128096342087, 0.10155036300420761, 0.08790542930364609, -0.04243028163909912, 0.06338763982057571, 0.040301453322172165, -0.029427338391542435, -0.04223167151212692, 0.001758374273777008, 0.008704300038516521, 0.07789314538240433, 0.1261824518442154, 0.13120445609092712, 0.2774242162704468, 0.012755029834806919, -0.17761288583278656, -0.04170253127813339, -0.2187804877758026, -0.052459876984357834, 0.17315484583377838, 0.05106019228696823, 0.12028337270021439, -0.03699345886707306, 0.07806724309921265], metadata={'source': 'AAAMLP-569to.pdf', 'page': 189}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 190 I won’t go into the history of deep learning and who invented what. Instead, let’s take a look at one of the most famous deep learning models AlexNet and see what’s happening there.   \\n Figure 3: AlexNet architecture9. Please note that the input size in this figure is not 224x224 but 227x227  Nowadays, you might say that it is a basic deep convolutional neural network, but it is the foundation of many new deep nets (deep neural networks). We see that the network in figure 3 is a convolutional neural network with five convolution layers, two dense layers and an output layer. We see that there is also max pooling. What is it? Let’s look at some terms which you will come across when doing deep learning. \\n Figure 4: An image of size 8x8 with a filter of size 3x3 and stride of 2.  Figure 4 introduces two new terms: filter and strides. Filters are nothing but two-dimensional matrices which are initialized by a given function. “He initialization”  9 A. Krizhevsky, I. Sutskever, and G. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, 2012'),\n",
       " VectorParams(vector=[-0.11920635402202606, -0.049254972487688065, 0.03662145510315895, -0.06279734522104263, 0.03137614578008652, -0.1064189076423645, 0.017823467031121254, -0.07258431613445282, 0.10801524668931961, -0.04430992156267166, 0.009762449190020561, -0.011080349795520306, 0.02525801584124565, 0.00521861482411623, -0.14400818943977356, 0.01739141345024109, -0.12774406373500824, 0.14329646527767181, -0.20967648923397064, -0.02105727232992649, 0.135389506816864, -0.11409119516611099, -0.00764521723613143, -0.05008811131119728, 0.040520139038562775, 0.13739144802093506, -0.017326224595308304, -0.06469286978244781, 0.04956245422363281, -0.08006101846694946, -0.03317933529615402, 0.05548733472824097, 0.05366373807191849, 0.03886891528964043, -0.08720055967569351, 0.05154428258538246, -0.00497717410326004, 0.13048405945301056, 0.06182533875107765, 0.06781775504350662, -0.05702881142497063, -0.01830766536295414, -0.005281899590045214, -0.059214264154434204, 0.16330048441886902, 0.076080322265625, 0.0017621179576963186, -0.07956795394420624, -0.022305605933070183, -0.07541682571172714, -0.09784266352653503, 0.006660928949713707, -0.15797962248325348, 0.16270513832569122, 0.016594158485531807, -0.04426361620426178, 0.07944750785827637, 0.06025143340229988, -0.05459096282720566, 0.013608912006020546, -0.04817148298025131, -0.030168185010552406, -0.03374112769961357, 0.05934076011180878, 0.09047811478376389, -0.08385254442691803, -0.017890680581331253, -0.08543957769870758, 0.03776713088154793, 0.04734870046377182, -0.05193519964814186, 0.14651261270046234, -0.010716582648456097, -0.02289637178182602, -0.015195786952972412, 0.024142736569046974, 0.16070318222045898, 0.08676237612962723, 0.11300582438707352, -0.0753481313586235, 0.1264430582523346, -0.025358347222208977, 0.12386208772659302, 0.026262711733579636, 0.05032391473650932, -0.023544231429696083, -0.09653273969888687, -0.018511956557631493, -0.015531666576862335, -0.06915442645549774, -0.012259570881724358, 0.047437142580747604, -0.20422771573066711, -0.027231942862272263, 0.17167775332927704, -0.009636997245252132, -0.006879196502268314, -0.06546500325202942, -0.03817720338702202, 0.09756525605916977, 0.03822070732712746, -0.10656017810106277, 0.04431598633527756, 0.04532556235790253, 0.13299846649169922, 0.03401821479201317, 0.052005451172590256, -0.040040578693151474, 0.05938778072595596, -0.0577922947704792, -0.006420177407562733, -0.17109684646129608, -0.07711349427700043, 0.03752518817782402, 0.04568791016936302, -0.04406670853495598, 0.02375664934515953, -0.021625662222504616, 0.11972576379776001, -0.09491407126188278, -0.05581184849143028, 0.03902103379368782, -0.07323656231164932, -0.10819968581199646, 0.03173822909593582, -0.03029102273285389, -0.005086185410618782, 7.716095529011194e-33, -0.030058257281780243, -0.005234564654529095, -0.05027160793542862, -0.009442024864256382, 0.02313208021223545, -0.030325211584568024, 0.009744256734848022, -0.07040022313594818, 0.08632861077785492, -0.0051205274648964405, -0.060474395751953125, 0.00017448402650188655, -0.009255480952560902, 0.16175112128257751, 0.0447462797164917, -0.02542254328727722, -0.0010953376768156886, -0.05888807401061058, -0.04127529636025429, -0.06662248075008392, 0.05797969922423363, 0.04159378260374069, 0.05750056728720665, 0.03916513919830322, -0.10093141347169876, -0.08193499594926834, -0.03497092053294182, -0.13681025803089142, -0.0775219276547432, 0.0003052069805562496, -0.07861694693565369, 0.0028433504048734903, -0.062197715044021606, -0.03910980001091957, -0.06286413967609406, -0.07950301468372345, 0.10442866384983063, -0.07458574324846268, 0.035553429275751114, 0.0048930346965789795, -0.00834028609097004, 0.12321429699659348, 0.0784660279750824, -0.1462957262992859, -0.03317016735672951, -0.025642627850174904, 0.06128554418683052, 0.03564007952809334, 0.010918005369603634, 0.057676441967487335, 0.09491029381752014, -0.008455249480903149, -0.007261088117957115, -0.15125127136707306, 0.04297637566924095, -0.009933456778526306, 0.10915440320968628, -0.02333814837038517, 0.01864778809249401, 0.08962778002023697, -0.06600617617368698, -0.042544398456811905, -0.023652302101254463, 0.11343856900930405, -0.015049058943986893, 0.0013663794379681349, -0.04051739722490311, 0.03129630535840988, 0.06234990060329437, -0.024215461686253548, -0.0845007449388504, 0.06386930495500565, 0.014073236845433712, -0.044690750539302826, 0.005320029333233833, 0.022023575380444527, 0.026381511241197586, -0.05419964715838432, -0.1143767386674881, -0.01396713312715292, -0.052827831357717514, 0.05884260684251785, 0.007702414877712727, -0.0699613094329834, -0.164726123213768, 0.03811829537153244, 0.17742684483528137, -0.09628945589065552, 0.023030875250697136, -0.14153940975666046, -0.020422901958227158, -0.010466150008141994, 0.023800687864422798, 0.06512483209371567, 0.023428069427609444, -6.977138637782026e-33, 0.05737742409110069, 0.15701624751091003, -0.09003157168626785, 0.05529698356986046, -0.06169653311371803, 0.07617197185754776, 0.08462480455636978, -0.056405097246170044, 0.06499341875314713, -0.1279069036245346, -0.0923491045832634, 0.06201587989926338, 0.00016943042282946408, -0.01296429242938757, -0.006748480722308159, -0.062093209475278854, -0.11017365008592606, -0.048462968319654465, -0.06703361123800278, -0.010936693288385868, 0.08685261756181717, 0.1269177347421646, -0.037511445581912994, -0.03428729996085167, -0.10272852331399918, 0.04897536709904671, -0.014939654618501663, 0.049290284514427185, 0.013799937441945076, -0.0041643427684903145, 0.010365525260567665, -0.12697772681713104, -0.016115296632051468, -0.0290362611413002, 0.004898359999060631, 0.009161458350718021, 0.00042480663978494704, 0.017933115363121033, 0.02863525226712227, -0.08888041973114014, 0.13667689263820648, -0.023673061281442642, 0.022827086970210075, -0.045686181634664536, -0.018865257501602173, 0.014506245963275433, -0.0026066824793815613, 0.008207837119698524, -0.11636628210544586, 0.064021997153759, -0.027811400592327118, 0.05456211417913437, -0.07222969084978104, 0.010730123147368431, -0.04002774506807327, 0.12120223045349121, -0.07839418947696686, 0.05407782644033432, 0.09720119088888168, 0.011411124840378761, -0.06296196579933167, -0.10951223224401474, -0.04053214192390442, -0.08015204221010208, 0.035327568650245667, 0.10269549489021301, -0.07150707393884659, 0.009984361939132214, 0.00685162004083395, 0.08364549279212952, -0.108603335916996, 0.04825166240334511, 0.11896543204784393, 0.0005608904757536948, -0.020315438508987427, -0.019718866795301437, 0.051519472151994705, -0.03704623505473137, 0.04226319491863251, 0.006973373703658581, -0.10566461831331253, -0.023028157651424408, -0.030645929276943207, 0.06471531838178635, 0.03688967972993851, 0.052337102591991425, 0.057318150997161865, -0.020256532356142998, 0.1372717022895813, -0.058060817420482635, 0.025626908987760544, 0.007137702777981758, 0.02207406423985958, 0.012218471616506577, 0.05995061621069908, -9.9873197711986e-08, -0.028171876445412636, 0.013710999861359596, -0.00479308282956481, 0.0027104427572339773, 0.12401151657104492, -0.037697747349739075, 0.12382418662309647, 0.11554540693759918, -0.008149775676429272, -0.004280706401914358, 0.15423446893692017, 0.07205764204263687, -0.09321656823158264, -0.08391468226909637, -0.04939136654138565, 0.2070714235305786, -0.0278899148106575, -0.05555952340364456, -0.017337307333946228, -0.08492497354745865, -0.05265442654490471, -0.06776612997055054, -0.08531270176172256, 0.06105629354715347, -0.008477015420794487, -0.02622065320611, -0.11570942401885986, 0.03177260234951973, 0.030701112002134323, -0.042747415602207184, 0.0614478625357151, 0.05508449301123619, 0.12496241182088852, -0.00905891228467226, 0.10056162625551224, 0.05022247135639191, 0.0370730496942997, -0.033050812780857086, -0.055952806025743484, -0.005263046361505985, -0.0031685205176472664, 0.01288234069943428, 0.17678040266036987, -0.1162349060177803, 0.0876225009560585, 0.0048081111162900925, -0.005515374708920717, -0.08309455215930939, -0.01509124506264925, 0.04835287481546402, 0.05168268457055092, -0.03346346691250801, 0.01942071132361889, 0.13491949439048767, 0.09715008735656738, -0.16578032076358795, -0.04066403582692146, -0.05173439905047417, 0.07661940157413483, 0.17669185996055603, -0.03140031546354294, 0.1107877865433693, 0.006849320605397224, 0.019244585186243057], metadata={'source': 'AAAMLP-569to.pdf', 'page': 190}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 191 which is also known “Kaiming normal initialization” is a good choice for convolutional neural networks. It is because most modern networks use ReLU (Rectified Linear Units) activation function and proper initialization is required to avoid the problem of vanishing gradients (when gradients approach zero and weights of network do not change). This filter is convolved with the image. Convolution is nothing but a summation of elementwise multiplication (cross-correlation) between the filter and the pixels it is currently overlapping in a given image. You can read more about convolution in any high school mathematics textbook. We start convolution of this filter from the top left corner of the image, and we move it horizontally. If we move it by 1 pixel, the stride is 1. If we move it by 2 pixels, the stride is 2. And that’s what stride is.   Stride is a useful concept even in natural language processing, e.g. in question and answering systems when you have to filter answer from a large text corpus. When we are exhausted horizontally, we move the filter by the same stride downwards vertically, starting from left again. Figure 4 also shows a filter going outside the image. In these cases, it’s not possible to calculate the convolution. So, we skip it. If you don’t want to skip it, you will need to pad the image. It must also be noted that convolution will decrease the size of the image. Padding is also a way to keep the size of the image the same. In figure 4, A 3x3 filter is moving horizontally and vertically, and every time it moves, it skips two columns and two rows (i.e. pixels) respectively. Since it skips two pixels, stride = 2. And resulting image size is [(8-3) / 2] + 1 = 3.5. We take the floor of 3.5, so its 3x3. You can do it by hand by moving the filters on a pen and paper.  \\n Figure 5: Padding enables us to provide an image with the same size as the input'),\n",
       " VectorParams(vector=[-0.06747549772262573, -0.10656363517045975, 0.14810605347156525, -0.07772549986839294, 0.0319204218685627, -0.13318051397800446, -0.004150798078626394, -0.03233867883682251, 0.08635406196117401, -0.09856996685266495, -0.10609401762485504, -0.020139891654253006, -0.018612762913107872, 0.019553543999791145, -0.10638253390789032, 0.020342187955975533, 0.05385129898786545, 0.22445403039455414, -0.3371349573135376, 0.015170215629041195, 0.20749489963054657, -0.10447623580694199, -0.035476408898830414, -0.006177658215165138, 0.06415707617998123, 0.0775863453745842, -0.06575827300548553, -0.14118441939353943, 0.11826343089342117, -0.010977541096508503, -0.026636961847543716, 0.16956479847431183, 0.05085061863064766, 0.057511601597070694, -0.04533911868929863, 0.07376585155725479, -0.012877115979790688, 0.06010407954454422, 0.08612145483493805, 0.010960828512907028, -0.03788059949874878, 0.04824645072221756, 0.0358298234641552, 0.0089365029707551, 0.14373986423015594, 0.14464427530765533, -0.022141221910715103, -0.09874550253152847, 0.02114894427359104, -0.016554713249206543, 0.013832658529281616, 0.031222516670823097, -0.07284962385892868, 0.19448742270469666, 0.013972161337733269, -0.08918537199497223, -0.04628625139594078, 0.06671341508626938, -0.054168909788131714, 0.11591126024723053, -0.04512489587068558, -0.06831870228052139, 0.09997273981571198, 0.08413846045732498, 0.019570359960198402, -0.21295267343521118, -0.05335410311818123, -0.08098863810300827, -0.0570177286863327, 0.03757518157362938, 0.040652766823768616, 0.1973135769367218, -0.08715321868658066, -0.03304283693432808, 0.023860614746809006, -0.05420051887631416, 0.09103093296289444, 0.09824490547180176, 0.07705534994602203, -0.11112243682146072, 0.1648893654346466, -0.0211798008531332, 0.07446926087141037, -0.1067623719573021, 0.038902733474969864, -0.04409148916602135, -0.13953600823879242, 0.027273287996649742, -0.03139986842870712, 0.03177676349878311, -0.03350115194916725, 0.03978312388062477, -0.23351003229618073, -0.06432368606328964, 0.09481043368577957, -0.03628233075141907, -0.13383489847183228, -0.0056124585680663586, -0.0361921563744545, 0.08885261416435242, 0.03434673324227333, -0.06791062653064728, 0.1356995701789856, 0.04764638841152191, 0.15858343243598938, 0.017888816073536873, 0.02029586397111416, 0.052547257393598557, 0.07999107241630554, -0.044734179973602295, 0.022289127111434937, -0.05335254967212677, 0.058407194912433624, -0.0004063066153321415, -0.008779942989349365, 0.006970762740820646, -0.0121221374720335, 0.0405154824256897, 0.1316535919904709, 0.0318925604224205, -0.164400115609169, 0.0217141006141901, -0.14723050594329834, -0.03816148266196251, 0.10639476031064987, 0.05110812187194824, -0.05182522535324097, 1.320398421068914e-32, -0.028621258214116096, -0.039919186383485794, -0.04614287614822388, -0.058007609099149704, 0.008413562551140785, -0.00678249029442668, 0.008134244941174984, -0.042681820690631866, 0.08476310223340988, -0.045883797109127045, -0.03704638406634331, -0.08130360394716263, -0.018581831827759743, 0.14984272420406342, 0.008014277555048466, -0.03380155190825462, -0.03240704908967018, 0.00561893405392766, 0.00088450190378353, -0.06826137006282806, 0.04928876459598541, 0.014283772557973862, 0.04045303910970688, 0.06772756576538086, -0.07930127531290054, -0.16218110918998718, -0.010149514302611351, -0.021056944504380226, -0.07106838375329971, 0.015535586513578892, -0.09649326652288437, 0.034353118389844894, -0.005561321508139372, 0.06092675030231476, -0.10516917705535889, 0.061648424714803696, 0.05737260729074478, -0.008059650659561157, -0.018692782148718834, -0.0295259989798069, -0.05483055114746094, 0.09150815010070801, 0.00754183204844594, -0.0832056775689125, -0.07237844914197922, -0.12077749520540237, 0.09778176248073578, 0.01069813221693039, -0.07442174851894379, 0.02896290086209774, 0.04513586312532425, -0.10916684567928314, 0.010109972208738327, -0.1857505738735199, 0.11850788444280624, 0.028467699885368347, 0.11908655613660812, 0.02492833510041237, 0.04098637402057648, 0.11480064690113068, -0.06738359481096268, -0.12721331417560577, -0.14407213032245636, 0.14222759008407593, -0.033335912972688675, -0.04489948973059654, 0.06910477578639984, 0.10187126696109772, 0.04312898591160774, -0.020444447174668312, -0.10987462848424911, 0.049542393535375595, -0.04710083827376366, -0.03636014461517334, 0.0053106085397303104, -0.03388987481594086, 0.06016220152378082, -0.041791342198848724, -0.0970650166273117, 0.0680551752448082, -0.016511576250195503, 0.1782332807779312, 0.046949878334999084, -0.08857850730419159, -0.20857317745685577, 0.1268213540315628, 0.10889062285423279, -0.13031905889511108, -0.02041609026491642, -0.1379360854625702, 0.08071762323379517, -0.07739991694688797, -0.01154216006398201, 0.047229111194610596, 0.07010959088802338, -1.1286377500989695e-32, 0.016540782526135445, 0.05415875092148781, -0.1169692799448967, 0.1803331971168518, -0.02085236832499504, 0.07204818725585938, 0.04778115078806877, -0.017699116840958595, -0.037785641849040985, -0.31327056884765625, -0.05270722135901451, 0.09823436290025711, -0.03688700869679451, 0.012417388148605824, -0.06294567137956619, -0.10824571549892426, -0.07840513437986374, -0.054862335324287415, -0.0087515814229846, 0.015276379883289337, 0.07569839060306549, 0.1266430914402008, 0.0009287380380555987, 0.020039143040776253, -0.1230476051568985, 0.011147961020469666, -0.12802620232105255, -0.013196146115660667, 0.0712716355919838, -0.026203736662864685, 0.005178084131330252, -0.09315702319145203, -0.09163597226142883, 0.035228654742240906, 0.07040663063526154, -0.007399864494800568, 0.07866847515106201, 0.013980978168547153, -0.0001879389601526782, -0.048327237367630005, 0.08242358267307281, -0.03501907363533974, 0.0925927460193634, -0.009193113073706627, -0.04199179634451866, -0.040649984031915665, -0.022950876504182816, -0.0961342379450798, -0.08206355571746826, 0.08678940683603287, -0.0733356699347496, 0.007844092324376106, -0.1390402615070343, 0.062051333487033844, -0.004183822777122259, -0.023670535534620285, -0.029780099168419838, 0.028124917298555374, 0.09427367150783539, 0.019577130675315857, -0.09265352785587311, -0.05964093282818794, -0.14741866290569305, -0.0261517446488142, -0.07394075393676758, 0.10964782536029816, -0.11877410858869553, 0.07633072137832642, 0.07578495889902115, 0.11423589289188385, -0.04146156832575798, -0.023398661985993385, 0.0434306375682354, 0.00913983304053545, -0.08935857564210892, -0.06415160000324249, 0.054301582276821136, -0.019576527178287506, -0.024218805134296417, 0.07107436656951904, -0.12480562925338745, 0.05819423869252205, -0.0911812111735344, 0.18408426642417908, 0.02343560941517353, -0.02097206376492977, 0.07211562991142273, 0.013828016817569733, 0.04294529929757118, -0.03638265281915665, -0.03187665343284607, -0.11503849178552628, -0.031918786466121674, 0.07447140663862228, -0.01898735761642456, -9.973570769261642e-08, 0.0034765617456287146, 0.00646781362593174, -0.08606363087892532, -0.09046512097120285, 0.2053864300251007, -0.13904471695423126, 0.044836048036813736, 0.2818335294723511, -0.05269969627261162, 0.05808957666158676, 0.06824810802936554, 0.06536123156547546, -0.066712386906147, -0.1343308389186859, 0.06485762447118759, 0.15723785758018494, 0.023527508601546288, -0.06547267735004425, 0.050898756831884384, 0.03560488298535347, -0.057176001369953156, -0.06648287922143936, -0.02184767834842205, -0.012694301083683968, 0.09220927953720093, -0.08807411789894104, -0.09238184988498688, 0.027264153584837914, 0.04673735052347183, -0.07684653997421265, -0.07719942927360535, 0.04734032601118088, 0.07317497581243515, -0.05018598586320877, 0.16890889406204224, 0.06840799748897552, -0.05646400898694992, -0.03935764729976654, -0.04850095883011818, 0.04825952649116516, 0.013882746919989586, 0.038547202944755554, 0.20705845952033997, -0.12181548774242401, 0.045757293701171875, 0.05382411554455757, 0.10613777488470078, -0.022670643404126167, -0.026756813749670982, 0.041599515825510025, 0.1030707135796547, 0.07054128497838974, 0.035452213138341904, 0.14847208559513092, 0.037215229123830795, -0.09890928864479065, -0.0369492806494236, -0.027301689609885216, 0.0947451964020729, 0.1296626478433609, -0.028765898197889328, 0.0743793323636055, -0.0260568019002676, 0.024302681908011436], metadata={'source': 'AAAMLP-569to.pdf', 'page': 191}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 192 We see the effect of padding in figure 5. Now, we have a 3x3 filter which is moving with a stride of 1. Size of the original image is 6x6, and we have added padding of 1. The padding of 1 means increasing the size of the image by adding zero pixels on each side once. In this case, the resulting image will be of the same size as the input image, i.e. 6x6. Another relevant term that you might come across when dealing with deep neural networks is dilation, as shown in figure 6.  \\n Figure 6: Example of dilation  In dilation, we expand the filter by N-1, where N is the value of dilation rate or simply known as dilation. In this kind of kernel with dilation, you skip some pixels in each convolution. This is particularly effective in segmentation tasks. Please note that we have only talked about 2-dimensional convolutions. There are 1-d convolutions too and also in higher dimensions. All work on the same underlying concept.  Next comes max-pooling. Max pooling is nothing but a filter which returns max. So, instead of convolution, we are extracting the max value of pixels. Similarly, average pooling or mean-pooling returns mean of pixels. They are used in the same way as the convolutional kernel. Pooling is faster than convolution and is a way to down-sample the image. Max pooling detects edges and average pooling smoothens the image.'),\n",
       " VectorParams(vector=[-0.06012076511979103, -0.2100013792514801, 0.01703859679400921, -0.06632284075021744, 0.026866815984249115, -0.14780071377754211, -0.0024862815625965595, -0.01939026080071926, -0.12438534200191498, -0.21997018158435822, -0.09383147954940796, 0.006763672921806574, -0.0351298488676548, -0.020131194964051247, -0.10580797493457794, 0.0885128527879715, -0.03751305118203163, 0.11066332459449768, -0.2788466215133667, -0.045011408627033234, 0.1949210911989212, -0.003582076169550419, 0.03394075855612755, -0.012216530740261078, 0.012082139030098915, 0.055416762828826904, 0.023823991417884827, 0.039538025856018066, -0.011398493312299252, -0.18218185007572174, 0.10531451553106308, 0.06315167248249054, -0.1541985124349594, 0.0692409873008728, 0.01054078433662653, 0.004896729718893766, -0.023902760818600655, 0.13101467490196228, -0.06396466493606567, 0.03862086310982704, 0.042149174958467484, -0.006196870468556881, -0.09014499187469482, -7.481079956050962e-05, 0.08933896571397781, 0.18315765261650085, 0.05732521042227745, 0.027787664905190468, 0.1770711988210678, -0.12636861205101013, -0.05755709484219551, 0.00359963602386415, -0.07220861315727234, 0.09562929719686508, 0.09466108679771423, -0.02781059220433235, 0.013208192773163319, -0.0650012418627739, -0.11296133697032928, -0.00046797748655080795, 0.19360864162445068, -0.002701336285099387, -0.0037073593121021986, -0.011272729374468327, 0.0325251929461956, -0.07918994128704071, -0.002591919619590044, 0.01863935776054859, -0.041262488812208176, -0.012268728576600552, 0.01879889890551567, 0.11495848000049591, -0.012003620155155659, 0.0568261481821537, 0.11727067828178406, -0.09531427174806595, 0.2789667546749115, 0.1578068882226944, -0.015447873622179031, -0.1988859623670578, 0.0699314996600151, 0.0389825738966465, 0.05128449201583862, -0.017668941989541054, 0.05768805742263794, -0.1316162347793579, -0.07460890710353851, 0.09000749886035919, -0.0004485220997594297, -0.0190568994730711, -0.051495276391506195, 0.01454467698931694, -0.12634636461734772, -0.04240795224905014, 0.19016559422016144, 0.06174571439623833, 0.04074414446949959, -0.11417414993047714, -0.06000876799225807, 0.15820668637752533, -0.09440318495035172, -0.21631331741809845, -0.001007445389404893, 0.04765060171484947, 0.1804429441690445, 0.12965500354766846, 0.1321975737810135, 0.1387365758419037, 0.13265901803970337, -0.20020046830177307, 0.036193717271089554, -0.15138591825962067, 0.06164703890681267, 0.09545385837554932, 0.22276118397712708, 0.04199568182229996, 0.020147519186139107, 0.09873653948307037, 0.11497728526592255, 0.04684765264391899, -0.08400299400091171, 0.054022207856178284, -0.03902318328619003, 0.045549552887678146, 0.06414022296667099, -0.08313515037298203, -0.10571937263011932, 1.18372934996537e-32, -0.13608957827091217, 0.003429233329370618, -0.11885590106248856, -0.021859191358089447, 0.029326993972063065, 0.011961043812334538, 0.09859313815832138, -0.03833944723010063, 0.029506703838706017, -0.024611245840787888, -0.257840633392334, -0.04982902482151985, -0.1140545904636383, 0.0388350784778595, -0.030533505603671074, -0.015266678296029568, -0.025064295157790184, 0.07346858084201813, 0.03265487030148506, -0.058828242123126984, 0.15433724224567413, 0.08885711431503296, -0.09435201436281204, -0.04283926635980606, -0.17931652069091797, -0.12290138751268387, -0.07263138890266418, -0.17615346610546112, -0.023936767131090164, -0.021591385826468468, -0.08916580677032471, 0.0020521513652056456, 0.0015891785733401775, -0.0031572398729622364, -0.07115983217954636, -0.11612744629383087, 0.0464898981153965, 0.09496667236089706, 0.021178018301725388, -0.15112616121768951, -0.04090586677193642, 0.1510554552078247, -0.004198562819510698, -0.13819022476673126, -0.07806994020938873, -0.12111405283212662, 0.03744563087821007, 0.18804752826690674, -0.09794634580612183, 0.021283568814396858, -0.014939405024051666, -0.03500022366642952, 0.01307640876621008, -0.1321508139371872, 0.07690606266260147, -0.031466785818338394, 0.18456271290779114, 0.13957716524600983, 0.14516088366508484, 0.076869435608387, 0.06188950315117836, 0.018929915502667427, -0.10823742300271988, 0.13094472885131836, 0.01407094020396471, 0.053237881511449814, -0.034095339477062225, 0.05714618042111397, 0.10301261395215988, -0.004455980379134417, -0.1782415807247162, 0.16095255315303802, -0.0019414579728618264, -0.13868378102779388, 0.08849558234214783, -0.14271323382854462, 0.005099558737128973, -0.13713403046131134, -0.1593952625989914, 0.05104142799973488, -0.13445644080638885, 0.25002384185791016, -0.0720166340470314, -0.10253775864839554, -0.2688226103782654, 0.11847680062055588, 0.12480591237545013, -0.189002126455307, -0.10100596398115158, -0.008459532633423805, -0.16216245293617249, -0.07022056728601456, 0.07970323413610458, -0.024284128099679947, 0.0573166124522686, -8.542494506262156e-33, 0.06295928359031677, 0.16275523602962494, 0.0244872085750103, 0.08645257353782654, 0.00045615213457494974, 0.1288502812385559, 0.032676491886377335, -0.035195041447877884, -0.04592585563659668, -0.09102670103311539, -0.0024880145210772753, -0.0518207810819149, -0.02798142284154892, -0.03207404911518097, 0.1642969697713852, -0.10933073610067368, -0.0391152985394001, 0.03164585679769516, 0.07000727951526642, 0.008130257949233055, -0.060954730957746506, 0.31893932819366455, -0.14453516900539398, -0.03841532766819, -0.18935953080654144, 0.05598313361406326, 0.004660911858081818, 0.1520584523677826, -0.010433717630803585, -0.033131469041109085, -0.06291451305150986, 0.004127962049096823, -0.12332553416490555, 0.061448466032743454, -0.023865902796387672, 0.07500176131725311, 0.07650057971477509, -0.07367941737174988, -0.11027509719133377, -0.017193233594298363, 0.25976744294166565, 0.05629686638712883, -0.08501090854406357, 0.047703348100185394, -0.0959860235452652, 0.05941794812679291, -0.0007976536289788783, -0.030967216938734055, -0.11301577836275101, 0.08524373918771744, -0.01844700425863266, -0.10270791500806808, -0.17822420597076416, -0.0038748669903725386, 0.030704688280820847, 0.10629834234714508, 0.04392401874065399, 0.1401861608028412, 0.1323273926973343, -0.04768569394946098, -0.13982266187667847, -0.19891992211341858, -0.03185882419347763, 0.07033324241638184, 0.03182744234800339, 0.03562529385089874, -0.16443310678005219, 0.18681973218917847, 0.09902498871088028, 0.19801944494247437, -0.19166390597820282, 0.15614992380142212, 0.13995087146759033, -0.010101964697241783, -0.03393927589058876, 0.008406241424381733, 0.05975683405995369, -0.033028025180101395, 0.02266647294163704, 0.03721573203802109, -0.23214377462863922, 0.008765746839344501, -0.010369904339313507, 0.17589335143566132, 0.06848238408565521, 0.12186495959758759, 0.1319829374551773, 0.1716422140598297, 0.08935806155204773, -0.12434133887290955, 0.08198066800832748, 0.07855363190174103, 0.10682112723588943, 0.06132873147726059, 0.07744164764881134, -9.900207942337147e-08, -0.020037949085235596, 0.013866745866835117, 2.3037840946926735e-05, 0.09648969769477844, 0.12653258442878723, -0.08774508535861969, -0.0002056045486824587, 0.19422994554042816, -0.05192955955862999, -0.02914389967918396, 0.03145025297999382, 0.04655018076300621, 0.023491378873586655, -0.09519536793231964, -0.09405075013637543, 0.14127157628536224, -0.09331812709569931, -0.20791414380073547, 0.024157309904694557, -0.05386151000857353, -0.05758247151970863, -0.10735172778367996, -0.011429503560066223, 0.1731247454881668, -0.06053050607442856, -0.07099667191505432, -0.08283877372741699, -0.1141233891248703, 0.08858366310596466, 0.03840694576501846, 0.022206038236618042, -0.04052423685789108, 0.1577722430229187, 0.025341294705867767, 0.1355191171169281, -0.005760165862739086, -0.1081417053937912, 0.12480282783508301, -0.042524367570877075, 0.10787022858858109, -0.11238022148609161, 0.11802113801240921, 0.058254268020391464, -0.08955813944339752, 0.14993305504322052, -0.012638017535209656, 0.020236296579241753, -0.17404046654701233, 0.05189911276102066, -0.05356776341795921, 0.0301434975117445, 0.06702429056167603, 0.08621685951948166, 0.16842740774154663, 0.09184275567531586, -0.13468745350837708, -0.15362097322940826, -0.008964813314378262, 0.016706854104995728, 0.12636934220790863, -0.061979152262210846, 0.13535359501838684, -0.11942865699529648, -0.0644441694021225], metadata={'source': 'AAAMLP-569to.pdf', 'page': 192}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 193 There are way too many concepts in convolutional neural networks and deep learning. The ones that I discussed are some of the basics that will help you get started. Now, we are well prepared to start building our first convolutional neural network in PyTorch. PyTorch provides an intuitive and easy way to implement deep neural networks, and you don’t need to care about back-propagation. We define the network in a python class and a forward function that tells PyTorch how the layers are connected to each other. In PyTorch, the image notation is BS, C, H, W, where, BS is the batch size, C channels, H is height and W is the width. Let’s see how AlexNet is implemented in PyTorch.  ═════════════════════════════════════════════════════════════════════════ import torch import torch.nn as nn import torch.nn.functional as F   class AlexNet(nn.Module):     def __init__(self):         super(AlexNet, self).__init__()         # convolution part         self.conv1 = nn.Conv2d(             in_channels=3,              out_channels=96,              kernel_size=11,              stride=4,              padding=0         )         self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2)         self.conv2 = nn.Conv2d(             in_channels=96,             out_channels=256,             kernel_size=5,             stride=1,             padding=2         )         self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2)         self.conv3 = nn.Conv2d(             in_channels=256,             out_channels=384,             kernel_size=3,             stride=1,             padding=1         )         self.conv4 = nn.Conv2d(in_channels=384,out_channels=384,             kernel_size=3, stride=1,padding=1)'),\n",
       " VectorParams(vector=[-0.03366025537252426, -0.10464128106832504, 0.006651334464550018, -0.07457982748746872, 0.11040080338716507, -0.17301924526691437, 0.010032221674919128, -0.0813356414437294, -0.10406535863876343, -0.21457433700561523, -0.0724944919347763, -0.014058771543204784, -0.010909462347626686, -0.03444625437259674, -0.11164649575948715, 0.05228544771671295, -0.07957019656896591, 0.15265589952468872, -0.18812160193920135, -0.027384847402572632, 0.03555278107523918, 0.0027593099512159824, -0.07373498380184174, 0.04221199452877045, 0.07005356252193451, 0.014705426059663296, 0.02863558568060398, -0.009417799301445484, -0.07642687857151031, -0.2397165447473526, 0.09707514196634293, 0.1819854974746704, -0.10702769458293915, -0.042639151215553284, 0.025098785758018494, 0.09974611550569534, -0.07367491722106934, 0.05739270895719528, -0.09159214794635773, 0.023821163922548294, 0.051899973303079605, 0.07681211829185486, 0.05760018527507782, 0.054643772542476654, 0.12241299450397491, 0.12140048295259476, 0.0063302358612418175, -0.020355958491563797, 0.24255329370498657, -0.14946454763412476, -0.053495414555072784, 0.15071465075016022, -0.18382993340492249, 0.1828547716140747, 0.0019199354574084282, -0.09664395451545715, 0.059614989906549454, -0.14659976959228516, 0.02273508533835411, 0.06402166187763214, 0.12562206387519836, -0.06256305426359177, 0.05427255481481552, 0.0182784590870142, 0.05138420686125755, -0.055558592081069946, -0.008149784058332443, -0.012831789441406727, -0.012859704904258251, 0.042744193226099014, -0.026766132563352585, 0.17611953616142273, -0.08437671512365341, 0.04350557178258896, 0.0841103121638298, -0.047504082322120667, 0.2568496763706207, 0.05670515447854996, -0.011164032854139805, -0.08353403210639954, -0.00985128153115511, -0.016778524965047836, 0.07086288928985596, -0.09829023480415344, 0.023830987513065338, -0.15180525183677673, -0.05561208352446556, 0.059523001313209534, 0.051386311650276184, 0.014478538185358047, -0.05393871292471886, 0.07244925200939178, -0.1770876795053482, -0.043525330722332, 0.020503748208284378, 0.046084169298410416, 0.08097194135189056, -0.12882474064826965, -0.01931747794151306, 0.15656867623329163, -0.0070616090670228004, -0.12867441773414612, 0.028578218072652817, 0.016282089054584503, 0.16741371154785156, 0.07091012597084045, 0.18353119492530823, 0.20220530033111572, 0.08074688911437988, -0.19950035214424133, 0.04537436366081238, -0.15607818961143494, 0.07193180173635483, 0.12102748453617096, 0.235325425863266, 0.11223024129867554, 0.012449040077626705, 0.03606323152780533, -0.08411701768636703, 0.056829795241355896, -0.08746951818466187, 0.014988379552960396, -0.014580253511667252, -0.0024098344147205353, 0.0189050380140543, -0.06168879568576813, -0.12909039855003357, 1.3516968397803205e-32, -0.11445081233978271, 0.022272810339927673, -0.07834718376398087, -0.10751770436763763, 0.06322552263736725, 0.021078649908304214, 0.16367092728614807, -0.06197098642587662, -0.0735543966293335, 0.0019279646221548319, -0.23277631402015686, -0.05247336998581886, -0.1607019454240799, 0.0316084548830986, 0.025160573422908783, -0.111143559217453, -0.01692211627960205, 0.13228857517242432, -0.0345577634871006, -0.0860791951417923, 0.10903908312320709, 0.03661205247044563, -0.10137487947940826, -0.203169047832489, -0.12687158584594727, -0.10708370059728622, -0.02883663959801197, -0.11337460577487946, -0.09730467200279236, 0.03064420260488987, -0.1693773865699768, 0.04925863444805145, -0.044069014489650726, 0.04689844697713852, 0.0018573424313217402, -0.11980529874563217, 0.04428371787071228, 0.07816638052463531, 0.03320663422346115, -0.13081485033035278, -0.031061096116900444, 0.18246448040008545, -0.03167866915464401, -0.1176815927028656, -0.04416600614786148, -0.11157435178756714, 0.09332183003425598, 0.19678857922554016, -0.08041150122880936, 0.07852110266685486, -0.00609563896432519, -0.03476415574550629, -0.04831533879041672, -0.07183405011892319, -0.03369397670030594, -0.045675478875637054, 0.14732670783996582, 0.16816939413547516, 0.10525135695934296, 0.15150070190429688, 0.08581902086734772, 0.052567362785339355, -0.2124595046043396, 0.09406246244907379, 0.08186278492212296, 0.07698199152946472, 0.12282717227935791, 0.06479015946388245, 0.048155948519706726, 0.026937827467918396, -0.1985914409160614, 0.11826997250318527, 0.04470926523208618, -0.21909034252166748, 0.11030320823192596, -0.18469536304473877, 0.10666358470916748, -0.11601398885250092, -0.1550748348236084, -0.031629230827093124, -0.07695695012807846, 0.20391115546226501, -0.052061110734939575, -0.18619242310523987, -0.2329416573047638, -0.04797559976577759, 0.1060086041688919, -0.21502560377120972, -0.10518699884414673, -0.20575132966041565, -0.1513756364583969, -0.04926086217164993, 0.09962091594934464, -0.017259174957871437, -0.08089493215084076, -1.1029475414669392e-32, 0.0365166962146759, 0.14763334393501282, 0.13736097514629364, 0.09977348148822784, 0.04288609325885773, 0.04517039656639099, 0.1063973605632782, 0.08798620849847794, 0.008321959525346756, -0.19467875361442566, -0.03677937015891075, -0.05317896604537964, -0.018160000443458557, -0.025352712720632553, 0.07433244585990906, -0.029094520956277847, -0.03016088157892227, -0.005569986999034882, -0.07123127579689026, -0.03496995568275452, -0.15066766738891602, 0.26491066813468933, 0.02674538642168045, 0.01648080162703991, -0.16666558384895325, 0.10836426168680191, -0.035542070865631104, 0.0985419973731041, 0.05100388824939728, -0.11783065646886826, -0.07009347528219223, 0.022046474739909172, -0.12449687719345093, 0.05192825198173523, 0.010300518944859505, -0.033640146255493164, 0.04331562668085098, 0.04821014404296875, -0.02682001329958439, 0.06280605494976044, 0.27925312519073486, 0.10785612463951111, -0.13900400698184967, 0.0042754169553518295, -0.04284285753965378, 0.051601070910692215, -0.06053108349442482, 0.008834514766931534, 0.01796981319785118, 0.08695797622203827, -0.11396283656358719, -0.06287810206413269, -0.15041980147361755, 0.031077377498149872, -0.03305257856845856, 0.0650571808218956, -0.008299537003040314, 0.11955919861793518, 0.08210140466690063, -0.062100835144519806, -0.14467911422252655, -0.15038135647773743, -0.002588218078017235, -0.11823191493749619, 0.18682578206062317, 0.06694994866847992, -0.15665358304977417, 0.0708208680152893, 0.02278115600347519, 0.19336482882499695, -0.1078859493136406, 0.07860109210014343, 0.018510933965444565, -0.08728238195180893, -0.05101461336016655, -0.02467946894466877, -0.0009119901806116104, -0.049998022615909576, 0.013391250744462013, 0.06085933744907379, -0.17899072170257568, 0.1085178554058075, 0.031878918409347534, 0.24394077062606812, 0.1355554461479187, 0.1308574378490448, 0.04903649911284447, 0.1191786453127861, 0.12778924405574799, -0.0811808854341507, 0.05404600873589516, 0.10220123827457428, 0.17303350567817688, 0.20073139667510986, 0.09361068159341812, -9.98056108869605e-08, -0.05261664092540741, 0.0016582906246185303, 0.04554367437958717, 0.09578726440668106, 0.10759857296943665, -0.01488241832703352, 0.036401838064193726, 0.15391303598880768, -0.04237731173634529, -0.10383711755275726, 0.0961056798696518, -0.012409718707203865, -0.07216420769691467, -0.02283850684762001, -0.04481164366006851, 0.0374484658241272, -0.09787283837795258, -0.1095752865076065, -0.02804838865995407, -0.044792719185352325, -0.01460462436079979, -0.19417910277843475, 0.028139254078269005, 0.09252980351448059, -0.1381828784942627, -0.14788907766342163, -0.05089309811592102, -0.12176299095153809, 0.1263522356748581, 0.006456300616264343, -0.03922296315431595, -0.05150895565748215, 0.15935839712619781, 0.06675916165113449, 0.13404272496700287, 0.10193509608507156, -0.05148203670978546, 0.08874548971652985, -0.09121459722518921, 0.09250882267951965, -0.19163495302200317, 0.15179507434368134, 0.02530144527554512, -0.09032805263996124, 0.19951754808425903, -0.10653197765350342, 0.029805580154061317, -0.1313088834285736, 0.1444137543439865, -0.02283031865954399, 0.06483849883079529, 0.03163791447877884, 0.0011957308743149042, 0.031870801001787186, 0.19086553156375885, -0.01361027266830206, -0.20395037531852722, 0.019938327372074127, 0.016003336757421494, 0.07688240706920624, -0.003294987604022026, 0.0822790116071701, -0.0260601956397295, -0.028223378583788872], metadata={'source': 'AAAMLP-569to.pdf', 'page': 193}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 194         self.conv5 = nn.Conv2d(in_channels=384, out_channels=256,             kernel_size=3,             stride=1,             padding=1         )         self.pool3 = nn.MaxPool2d(kernel_size=3, stride=2)         # dense part         self.fc1 = nn.Linear(             in_features=9216,              out_features=4096         )         self.dropout1 = nn.Dropout(0.5)         self.fc2 = nn.Linear(             in_features=4096,              out_features=4096         )         self.dropout2 = nn.Dropout(0.5)         self.fc3 = nn.Linear(             in_features=4096,              out_features=1000         )     def forward(self, image):         # get the batch size, channels, height and width         # of the input batch of images         # original size: (bs, 3, 227, 227)         bs, c, h, w = image.size()         x = F.relu(self.conv1(image))  # size: (bs, 96, 55, 55)         x = self.pool1(x)  # size: (bs, 96, 27, 27)         x = F.relu(self.conv2(x))  # size: (bs, 256, 27, 27)         x = self.pool2(x)  # size: (bs, 256, 13, 13)         x = F.relu(self.conv3(x))  # size: (bs, 384, 13, 13)         x = F.relu(self.conv4(x))  # size: (bs, 384, 13, 13)         x = F.relu(self.conv5(x))  # size: (bs, 256, 13, 13)         x = self.pool3(x)  # size: (bs, 256, 6, 6)         x = x.view(bs, -1)  # size: (bs, 9216)         x = F.relu(self.fc1(x))  # size: (bs, 4096)         x = self.dropout1(x)  # size: (bs, 4096)         # dropout does not change size         # dropout is used for regularization         # 0.3 dropout means that only 70% of the nodes          # of the current layer are used for the next layer         x = F.relu(self.fc2(x))  # size: (bs, 4096)         x = self.dropout2(x)  # size: (bs, 4096)         x = F.relu(self.fc3(x))  # size: (bs, 1000)         # 1000 is number of classes in ImageNet Dataset         # softmax is an activation function that converts         # linear output to probabilities that add up to 1'),\n",
       " VectorParams(vector=[-0.14126747846603394, -0.19431746006011963, 0.014995846897363663, -0.03276972845196724, 0.04025249183177948, -0.083539217710495, 0.015294058248400688, 0.014805406332015991, -0.01053403690457344, -0.12422022968530655, -0.10604191571474075, -0.03131531551480293, 0.032198116183280945, 0.0877084955573082, -0.15816143155097961, 0.026238566264510155, -0.13784338533878326, 0.12860512733459473, -0.3274577260017395, -0.05533040687441826, 0.22975364327430725, -0.0525304414331913, 0.11298082768917084, -0.055005259811878204, -0.06052054092288017, 0.028605777770280838, 0.017223773524165154, -0.05266108363866806, -0.027042381465435028, -0.07987629622220993, 0.06184382736682892, 0.10485845059156418, -0.07074807584285736, 0.047914765775203705, 0.019591376185417175, 0.024080030620098114, -0.14659681916236877, 0.14222267270088196, -0.03951679542660713, 0.05815661698579788, 0.007675242610275745, 0.05696047469973564, -0.10830607265233994, -0.10923875868320465, 0.06587406247854233, 0.0661124661564827, -0.06156822293996811, -0.060026779770851135, 0.12874950468540192, -0.08079497516155243, -0.09910426288843155, 0.03792840987443924, -0.19633634388446808, 0.2239895761013031, 0.033883512020111084, -0.18455690145492554, -0.09524788707494736, -0.12768089771270752, -0.06770631670951843, -0.07055751979351044, 0.06437648832798004, -0.054753001779317856, -0.06045527756214142, -0.03331632912158966, 0.08983834087848663, -0.0028494782745838165, -0.004988199099898338, -0.03605813533067703, 0.1127137839794159, -0.07358504831790924, 0.020607929676771164, 0.12564179301261902, -0.09709351509809494, 0.11037994921207428, -0.02199646271765232, -0.09184359759092331, 0.33256280422210693, 0.0950450599193573, 0.0419442281126976, -0.16948705911636353, 0.08059187978506088, -0.0009926902130246162, 0.11427668482065201, -0.027403784915804863, 0.013979355804622173, -0.05444653332233429, -0.1208077222108841, 0.16397473216056824, -0.0806739330291748, -0.004468912724405527, -0.08134068548679352, 0.031056184321641922, -0.05933188647031784, 0.038740210235118866, 0.16683527827262878, 0.05173223093152046, 0.07704346626996994, -0.033233776688575745, -0.030187688767910004, 0.08466704189777374, -0.026397772133350372, -0.18603211641311646, 0.08358854055404663, 0.04204932600259781, 0.14900168776512146, 0.012473132461309433, 0.14217209815979004, 0.05501846596598625, 0.08663272857666016, -0.2489510178565979, 0.06705953925848007, -0.02295611798763275, -0.05911906063556671, -0.07228749245405197, 0.18551155924797058, 0.03392564877867699, -0.038931913673877716, 0.06760197877883911, 0.01914169080555439, 0.05549680441617966, -0.09249231219291687, 0.025516485795378685, -0.09336869418621063, -0.005615815054625273, 0.03241490200161934, -0.06752575933933258, -0.13087376952171326, 1.3342598504538104e-32, -0.059164345264434814, 0.06305291503667831, -0.07085172086954117, -0.05025114864110947, 0.04870864003896713, -0.04122027009725571, 0.07278880476951599, 0.01637887954711914, -0.03982178866863251, 0.05339982360601425, -0.22814366221427917, -0.004258865024894476, -0.11927024275064468, 0.07351063191890717, -0.0573357492685318, -0.012811997905373573, -0.06764841824769974, 0.05508105084300041, -0.052643366158008575, -0.014296138659119606, 0.0899491012096405, 0.04624481499195099, 0.07890103757381439, 0.04730041325092316, -0.12556129693984985, -0.02581048756837845, -0.07143057882785797, -0.10737975686788559, -0.04679352417588234, -0.021805526688694954, -0.0745648443698883, 0.044323332607746124, 0.04596405476331711, 0.01976892724633217, -0.07005622982978821, -0.08559999614953995, -0.02854899875819683, 0.043127987533807755, 0.03795073553919792, -0.07977880537509918, -0.06542011350393295, 0.13689857721328735, -0.0387498214840889, -0.09775407612323761, -0.046244654804468155, 0.02523220330476761, 0.00826312880963087, 0.09292575716972351, -0.05087665095925331, 0.031422894448041916, 0.11661650985479355, 0.0010769772343337536, 0.03042491152882576, -0.04418974369764328, -0.007384601980447769, 0.02772972732782364, 0.14870589971542358, 0.07131040841341019, 0.17230600118637085, 0.07484427094459534, 0.11923184990882874, 0.0034561902284622192, -0.016940031200647354, 0.2102077603340149, 0.013464363291859627, -0.004936935380101204, 0.07713278383016586, 0.08162519335746765, 0.022162171080708504, -0.002852211706340313, -0.2515260577201843, 0.15591484308242798, 0.027769125998020172, -0.1204356700181961, 0.08899329602718353, -0.01125261839479208, -0.013011842966079712, -0.10446211695671082, -0.2253398299217224, 0.12478434294462204, -0.09678517282009125, 0.1778404414653778, 0.02003622055053711, -0.12153417617082596, -0.2195122241973877, 0.1694137454032898, 0.12432825565338135, -0.16019737720489502, -0.04908416420221329, -0.10944242775440216, -0.13070015609264374, -0.02331787534058094, 0.029314851388335228, -0.00855948869138956, 0.05235978960990906, -8.507056290320741e-33, 0.1271921694278717, 0.13988341391086578, -0.05010618269443512, 0.0405813604593277, -0.009794630110263824, 0.05024635046720505, -0.016088280826807022, -0.015247480012476444, -0.04762036353349686, -0.10701648145914078, 0.0190950445830822, -0.06986518949270248, -0.04190581664443016, -0.07435140013694763, 0.05364513397216797, -0.06908668577671051, -0.04305627569556236, -0.005033309105783701, -0.07024343311786652, 0.044692423194646835, -0.06930981576442719, 0.23057036101818085, -0.16694077849388123, -0.0024911565706133842, -0.25522005558013916, 0.09174403548240662, 0.0013054963201284409, 0.04420875012874603, 0.12449733912944794, -0.09427227079868317, -0.053664565086364746, -0.016763240098953247, -0.10015407204627991, 0.006841253489255905, -0.017955197021365166, 0.08083325624465942, 0.08440008759498596, -0.09308229386806488, 0.020535726100206375, -0.017507411539554596, 0.20040246844291687, 0.1344377100467682, -0.08919651806354523, 0.07751168310642242, -0.06146560236811638, -0.006985843181610107, 0.0717775747179985, -0.03651975840330124, -0.08355095982551575, 0.0493917241692543, 0.0006301216781139374, -0.02833215706050396, -0.12555529177188873, 0.060738034546375275, 0.1115572601556778, 0.011013610288500786, -0.03866088017821312, 0.01745707541704178, 0.13294892013072968, -0.041329897940158844, -0.18972203135490417, -0.21974459290504456, -0.05496353656053543, -0.03466721251606941, 0.01442529633641243, 0.1352306306362152, -0.08909434080123901, 0.03827386349439621, 0.02404605783522129, 0.21319659054279327, -0.056822776794433594, 0.05154532939195633, 0.08478869497776031, 0.09881296753883362, -0.015593364834785461, -0.027908140793442726, -0.04828508198261261, 0.034571077674627304, 0.0016933041624724865, 0.0708732008934021, -0.09074327349662781, -0.12162627279758453, 0.013049054890871048, 0.1761922985315323, 0.17183271050453186, 0.1456000804901123, 0.14537668228149414, 0.013274161145091057, 0.15327312052249908, -0.027904948219656944, 0.039393845945596695, 0.027363639324903488, 0.14609313011169434, 0.07901032269001007, 0.07537761330604553, -9.97622890963612e-08, 0.05700524523854256, 0.050709448754787445, -0.10282750427722931, 0.03912176936864853, 0.07440506666898727, -0.09870383888483047, -0.001905675046145916, 0.18729424476623535, -0.06361114978790283, 0.04169217124581337, 0.14738300442695618, 0.03232137858867645, -0.014031889848411083, -0.04166276007890701, -0.07131040841341019, 0.12357515096664429, -0.051536280661821365, -0.027866218239068985, 0.08595681190490723, 0.009691753424704075, 0.049136970192193985, -0.07606780529022217, -0.03144533559679985, 0.0831058993935585, 0.03187410533428192, -0.08004876971244812, -0.09148968756198883, -0.04121307283639908, -0.04716859012842178, -0.015919603407382965, 0.062316253781318665, -0.03052043542265892, 0.0686117485165596, -0.02540891245007515, 0.12815974652767181, 0.008099071681499481, 0.033696696162223816, 0.0275112371891737, -0.06279237568378448, 0.01828591525554657, -0.014438727870583534, 0.01039355993270874, 0.01873282715678215, -0.06613534688949585, 0.03339054062962532, 0.012788977473974228, 0.002048232825472951, -0.1533547341823578, 0.07733426243066788, 0.08358936011791229, 0.02815418504178524, 0.0010096123442053795, 0.07156357169151306, 0.09146741032600403, 0.059623606503009796, -0.013609614223241806, -0.029904212802648544, -0.02818528562784195, 0.06785896420478821, 0.0704304426908493, -0.05496719479560852, 0.11438418924808502, -0.09193752706050873, -0.07702972739934921], metadata={'source': 'AAAMLP-569to.pdf', 'page': 194}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 195         # for each sample in the batch         x = torch.softmax(x, axis=1)  # size: (bs, 1000)         return x ═════════════════════════════════════════════════════════════════════════  When you have a 3x227x227 image, and you apply a convolutional filter of size 11x11, it means that you are applying a filter of size 11x11x3 and convolving it with an image of size 227x227x3. So, now, you need to think in 3 dimensions instead of 2. The number of output channels is the number of different convolutional filters of the same size applied to the image individually. So, in the first convolutional layer, the input channels are 3, which is the original input, i.e. the R, G, B channels. PyTorch’s torchvision offers many different models like AlexNet, and it must be noted that this implementation of AlexNet is not the same as torchvision’s. Torchvision’s implementation of AlexNet is a modified AlexNet from another paper: Krizhevsky, A. One weird trick for parallelizing convolutional neural networks. CoRR, abs/1404.5997, 2014.  You can design your own convolutional neural networks for your task, and many times it is a good idea to start from something on your own. Let’s build a network to classify images from our initial dataset of this chapter into categories of having pneumothorax or not. But first, let’s prepare some files. The first step would be to create a folds file, i.e. train.csv but with a new column kfold. We will create five folds. Since I have shown how to do this for different datasets in this book, I will skip this part and leave it an exercise for you. For PyTorch based neural networks, we need to create a dataset class. The objective of the dataset class is to return an item or sample of data. This sample of data should consist of everything you need in order to train or evaluate your model.  ═════════════════════════════════════════════════════════════════════════ # dataset.py import torch  import numpy as np  from PIL import Image from PIL import ImageFile  # sometimes, you will have images without an ending bit # this takes care of those kind of (corrupt) images ImageFile.LOAD_TRUNCATED_IMAGES = True   class ClassificationDataset:'),\n",
       " VectorParams(vector=[0.033626310527324677, -0.15712958574295044, 0.02393173798918724, -0.03135111555457115, 0.0989287793636322, -0.027646804228425026, 0.053902655839920044, 0.018059374764561653, -0.19414043426513672, -0.16973109543323517, -0.07718877494335175, -0.07535944133996964, 0.10898769646883011, 0.02329912967979908, -0.029733745381236076, 0.10124571621417999, -0.06937609612941742, 0.16629137098789215, -0.24085593223571777, -0.09590905159711838, 0.07606028765439987, 0.012747564353048801, 0.15132105350494385, -0.03180185705423355, -0.06408897787332535, -0.1324486881494522, 0.07971189171075821, 0.0276243444532156, -0.07587134838104248, -0.19278426468372345, 0.0968223288655281, 0.07529599964618683, -0.0025954432785511017, 0.08765880763530731, 0.04591107740998268, 0.09430224448442459, -0.09040132910013199, 0.006662801373749971, -0.04709275811910629, 0.035679176449775696, 0.046286799013614655, 0.06890856474637985, -0.03620850667357445, -0.1532561033964157, 0.11440404504537582, 0.14192526042461395, -0.05952503904700279, -0.08688133209943771, 0.127997025847435, -0.008891783654689789, -0.035962026566267014, -0.04142327234148979, -0.2735748887062073, 0.18020929396152496, -0.08765441179275513, -0.126066192984581, 0.06988656520843506, -0.13886748254299164, 0.044011883437633514, -0.04786962643265724, 0.057084549218416214, -0.05331733822822571, -0.002373485593125224, -0.042648330330848694, -0.06528723984956741, -0.05999195575714111, 0.001025509787723422, -0.033093977719545364, 0.061826374381780624, 0.015344205312430859, 0.0691017359495163, 0.0628243088722229, 0.025634555146098137, 0.100537970662117, 0.01775616593658924, -0.16483546793460846, 0.21149079501628876, 0.11306232959032059, 0.047057826071977615, -0.0823705792427063, -0.07135824114084244, -0.09440930932760239, 0.04604124650359154, -0.015401467680931091, 0.2450084090232849, -0.14101947844028473, -0.06572042405605316, 0.09061837941408157, 0.01792301796376705, -0.0035982842091470957, -0.0299658365547657, 0.05001663416624069, -0.058295104652643204, 0.009670639410614967, 0.04906352981925011, 0.009845435619354248, 0.029854601249098778, -0.15560095012187958, -0.11661583185195923, 0.1063491627573967, -0.023587606847286224, -0.10893941670656204, 0.0025375441182404757, 0.0013059007469564676, 0.12771135568618774, 0.038575347512960434, 0.10803864896297455, 0.04769257456064224, 0.13633236289024353, -0.1711299866437912, -0.02390020526945591, -0.17099525034427643, -0.09806013852357864, 0.028784869238734245, 0.12407094240188599, 0.1295519471168518, -0.1038929894566536, 0.050958018749952316, -0.08631240576505661, 0.048151616007089615, -0.09248513728380203, 0.08888965100049973, -0.011986864730715752, -0.04240809753537178, -0.016578521579504013, -0.08380335569381714, -0.15917490422725677, 1.46752285320745e-32, -0.02917441911995411, -0.025864027440547943, 0.0481710359454155, -0.06707917898893356, 0.13702507317066193, -0.06789814680814743, 0.0052034249529242516, 0.025420084595680237, -0.09613312035799026, -0.07114801555871964, -0.06900344043970108, 0.035273805260658264, -0.07170902192592621, 0.1847783625125885, 0.0586724691092968, -0.028394734486937523, -0.04122975096106529, 0.18294745683670044, 0.027923578396439552, 0.07545197010040283, 0.04060392081737518, -0.044704221189022064, 0.04593012109398842, -0.032402705401182175, -0.07487163692712784, -0.07506503909826279, -0.006760760210454464, 0.014296120032668114, -0.06761996448040009, -0.02401435747742653, -0.18100358545780182, -0.0005901788244955242, 0.11618148535490036, 0.06807605177164078, -0.08039844036102295, -0.11281967163085938, -0.04445778578519821, 0.18051975965499878, -0.06937868148088455, -0.10999339818954468, 0.007068539969623089, 0.11243008822202682, 0.027312446385622025, -0.13993455469608307, -0.03256645053625107, 0.06501338630914688, -0.011781788431107998, 0.076280876994133, -0.07188677787780762, 0.09115809947252274, 0.049755215644836426, -0.12711116671562195, 0.015018919482827187, -0.08251291513442993, -0.12871617078781128, -0.00763041852042079, 0.09771834313869476, 0.13829198479652405, 0.08048683404922485, -0.16882659494876862, 0.11080051958560944, 0.05451858043670654, 0.03651171922683716, 0.13869421184062958, 0.0903608426451683, 0.07441254705190659, 0.16118472814559937, -0.004551623482257128, 0.06977915018796921, 0.07380155473947525, -0.17903810739517212, 0.11350597441196442, -0.01819697767496109, -0.18173782527446747, 0.09034520387649536, -0.12830066680908203, 0.011294900439679623, -0.12788106501102448, -0.15726891160011292, 0.1704387068748474, -0.11319614946842194, 0.099028080701828, 0.0501210018992424, -0.18028274178504944, -0.10363215953111649, -0.03056974709033966, 0.12173838168382645, -0.12578527629375458, -0.04457872733473778, -0.11073122918605804, -0.09888287633657455, 0.058768756687641144, -0.08277403563261032, 0.03782367333769798, -0.05135190486907959, -1.1806872440538388e-32, 0.16218061745166779, 0.15811413526535034, 0.0931403636932373, 0.048641081899404526, 0.03014443814754486, 0.020008444786071777, 0.01880485564470291, 0.19545038044452667, 0.04171079769730568, -0.19961872696876526, 0.050327956676483154, -0.032155852764844894, 0.05478174611926079, -0.15832200646400452, -0.09116949141025543, -0.13942000269889832, -0.0819014310836792, 0.015950724482536316, -0.03427712246775627, 0.05584995076060295, -0.14596980810165405, 0.18186916410923004, -0.013850085437297821, -0.03722580894827843, -0.2848723828792572, 0.11255237460136414, 0.01795177347958088, 0.023369522765278816, 0.10945951193571091, -0.0791330561041832, 0.03600897639989853, 0.05982433632016182, -0.10905907303094864, -0.023445069789886475, -0.021812358871102333, 0.04936490207910538, 0.11615322530269623, -0.05049002915620804, -0.09857150912284851, 0.18820346891880035, 0.19291819632053375, 0.08605639636516571, -0.13596008718013763, -0.0015212747966870666, -0.06264927238225937, -0.11779404431581497, 0.04059915617108345, 0.1194835752248764, -0.05520176887512207, 0.05794192850589752, -0.01107014250010252, -0.06699571013450623, -0.15479731559753418, 0.0446796640753746, 0.10167782008647919, 0.06817314028739929, -0.13780423998832703, -0.024778274819254875, 0.03948495537042618, 0.007548690773546696, -0.18246930837631226, -0.12065282464027405, -0.08367648720741272, -0.10211513191461563, 0.011325989849865437, 0.05709734186530113, -0.1994260847568512, 0.03193666785955429, -0.06840138882398605, 0.2235751897096634, 0.04407301917672157, 0.16186274588108063, 0.0942259281873703, 0.06965481489896774, -0.1008051261305809, 0.02270997129380703, -0.07611464709043503, -0.023563459515571594, 0.027705596759915352, -0.0459819957613945, -0.08371579647064209, -0.07357152551412582, -0.05581171438097954, 0.28116554021835327, 0.05189625173807144, 0.12410105764865875, 0.11418154090642929, 0.16052104532718658, 0.21834544837474823, -0.09761665016412735, 0.023907816037535667, -0.02522449940443039, 0.17766164243221283, 0.2435602843761444, -0.035110969096422195, -1.002813831973981e-07, -0.028141649439930916, 0.08142870664596558, 0.05812103673815727, 0.04298008605837822, -0.00022076090681366622, 0.028726231306791306, 0.08160272985696793, 0.2128407210111618, 0.010955514386296272, 0.028658147901296616, 0.0897984430193901, 0.041319623589515686, -0.07820941507816315, 0.08703645318746567, -0.11586373299360275, 0.06042758747935295, -0.011265452951192856, 0.11700712144374847, 0.05174928158521652, 0.04557473212480545, -0.014663077890872955, -0.17006485164165497, 0.07222263514995575, -0.024732619524002075, -0.018413957208395004, -0.12372913956642151, -0.08223708719015121, -0.009884024038910866, -0.07442614436149597, -0.05088426172733307, 0.052989691495895386, -0.05243915691971779, 0.10786228626966476, 0.0564599335193634, 0.07306082546710968, 0.04899505153298378, -0.11781825870275497, -0.002876468701288104, -0.09397904574871063, 0.026083339005708694, -0.10620565712451935, 0.05592716857790947, -0.043447040021419525, -0.05878935381770134, 0.12520112097263336, -0.045246247202157974, 0.10603268444538116, -0.13264067471027374, 0.028191974386572838, 0.04314139485359192, -0.011827847920358181, -0.011603833176195621, -0.07347431778907776, -0.042991142719984055, 0.10464787483215332, -0.0035493725445121527, -0.05160218104720116, 0.00819533970206976, 0.10478353500366211, 0.15087394416332245, -0.0013830988900735974, -0.029439613223075867, -0.10911360383033752, -0.05596067011356354], metadata={'source': 'AAAMLP-569to.pdf', 'page': 195}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 196     \"\"\"     A general classification dataset class that you can use for all     kinds of image classification problems. For example,     binary classification, multi-class, multi-label classification     \"\"\"     def __init__(         self,          image_paths,          targets,          resize=None,          augmentations=None     ):         \"\"\"         :param image_paths: list of path to images         :param targets: numpy array         :param resize: tuple, e.g. (256, 256), resizes image if not None         :param augmentations: albumentation augmentations         \"\"\"         self.image_paths = image_paths         self.targets = targets         self.resize = resize         self.augmentations = augmentations      def __len__(self):         \"\"\"         Return the total number of samples in the dataset         \"\"\"         return len(self.image_paths)      def __getitem__(self, item):         \"\"\"         For a given \"item\" index, return everything we need         to train a given model         \"\"\"         # use PIL to open the image         image = Image.open(self.image_paths[item])         # convert image to RGB, we have single channel images         image = image.convert(\"RGB\")         # grab correct targets         targets = self.targets[item]          # resize if needed         if self.resize is not None:             image = image.resize(                 (self.resize[1], self.resize[0]),                  resample=Image.BILINEAR             )'),\n",
       " VectorParams(vector=[-0.1026274785399437, -0.05140118673443794, 0.014394637197256088, 0.1104232519865036, 0.014193490147590637, -0.054364752024412155, 0.018170729279518127, 0.003287447150796652, -0.16030465066432953, -0.13242855668067932, -0.014039356261491776, -0.07526718825101852, -0.09015792608261108, -0.01755494810640812, -0.043954379856586456, 0.07383766770362854, -0.12478520721197128, 0.0022833168040961027, -0.08542870730161667, -0.23344579339027405, 0.06217405945062637, 0.024333549663424492, 0.08870717883110046, -0.0032144300639629364, -0.034829236567020416, -0.04286087304353714, 0.014728996902704239, 0.05887627601623535, 0.043561987578868866, -0.048726458102464676, 0.0384804829955101, 0.017525935545563698, -0.08517888933420181, 0.07064861804246902, 0.03449692949652672, 0.1216815933585167, -0.15862548351287842, -0.05532466992735863, -0.10908541828393936, 0.04867864027619362, 0.07402162998914719, 0.03024747408926487, -0.17202603816986084, -0.13141696155071259, 0.0904749408364296, 0.019772863015532494, 0.04404037818312645, -0.06525042653083801, 0.021489989012479782, -0.10163489729166031, -0.027471277862787247, -0.07245340198278427, -0.09433605521917343, 0.0865899845957756, 0.00588800385594368, -0.0065915826708078384, 0.11582279205322266, -0.07377605140209198, 0.0005221980973146856, -0.1672440469264984, -0.05267765000462532, -0.06528599560260773, -0.04509259760379791, -0.07920841127634048, 0.05957123264670372, -0.0076180677860975266, -0.03994091600179672, 0.026056446135044098, 0.028082681819796562, 0.0014078597305342555, -0.003899442497640848, 0.030309811234474182, -0.051709890365600586, 0.08515118807554245, -0.021517008543014526, -0.2013872116804123, 0.22936442494392395, 0.046975038945674896, 0.05189768224954605, -0.15445134043693542, 0.01875794678926468, -0.04173298925161362, 0.1591498702764511, -0.1316343992948532, 0.1589200496673584, -0.10798627883195877, -0.10330111533403397, 0.06738041341304779, 0.0025768543127924204, -0.06468791514635086, -0.023938287049531937, -0.10093764960765839, -0.1889089196920395, 0.04545745253562927, 0.1625957489013672, 0.04360843449831009, 0.1476467251777649, -0.07256540656089783, -0.07822796702384949, 0.09250158816576004, 0.004893195815384388, -0.07121217995882034, -0.07152587920427322, 0.06714914739131927, 0.162397563457489, 0.12861251831054688, 0.08845090121030807, 0.12549293041229248, -0.007547515910118818, -0.11137829720973969, -0.003039030823856592, 0.05745856091380119, -0.06865593791007996, -0.08182267099618912, 0.0456852950155735, -0.013665029779076576, -0.14721937477588654, 0.12024777382612228, -0.07416807115077972, 0.13032355904579163, -0.07713641226291656, 0.017097007483243942, -0.03478364646434784, 0.19136296212673187, -0.04223256930708885, -0.12585905194282532, -0.16926135122776031, 1.8347581617270777e-32, -0.04086684808135033, -0.030037961900234222, -0.02870241180062294, -0.12288367748260498, 0.06592203676700592, -0.045955441892147064, 0.064236119389534, -0.021163711324334145, -0.0841166228055954, -0.020240340381860733, -0.16431693732738495, 0.0038244796451181173, -0.10298653692007065, 0.14061219990253448, 0.016581283882260323, -0.04570860043168068, -0.06387251615524292, 0.1349286586046219, 0.10457827895879745, 0.034306738525629044, 0.13077162206172943, 0.027164479717612267, -0.12637019157409668, -0.022171536460518837, -0.1450679451227188, 0.007405920419842005, -0.03487786278128624, -0.038343146443367004, -0.13159044086933136, -0.008003020659089088, -0.1793871372938156, 0.011779144406318665, 0.08550161868333817, -0.03568156436085701, -0.007791514974087477, -0.15326367318630219, 0.061683379113674164, 0.08131790161132812, -0.054267529398202896, -0.17180268466472626, 0.04564376547932625, 0.18180619180202484, 0.02081899531185627, -0.12000411748886108, -0.12854889035224915, 0.05839760974049568, -0.019956929609179497, 0.25419721007347107, -0.0268460214138031, 0.05599915236234665, -0.0157725028693676, -0.031803082674741745, -0.013535923324525356, 0.03523045778274536, -0.011400321498513222, 0.0053075943142175674, 0.15856315195560455, 0.05670132115483284, 0.2109944075345993, -0.11847390979528427, 0.20973017811775208, 0.0716376006603241, 0.01752559281885624, 0.0988839790225029, -0.03510143607854843, 0.05386778339743614, 0.05804399028420448, 0.0058790347538888454, 0.029303627088665962, 0.09201840311288834, -0.26095932722091675, 0.1182098463177681, -0.08856989443302155, -0.08428531140089035, 0.23704858124256134, -0.11191841959953308, 0.07327129691839218, -0.1544727385044098, -0.1912315934896469, 0.03329985961318016, -0.044063128530979156, 0.19223260879516602, 0.011700556613504887, -0.2650129497051239, -0.11074761301279068, -0.09548293054103851, 0.025327185168862343, -0.12545353174209595, -0.07766792178153992, -0.08330806344747543, -0.11320172250270844, 0.013537390157580376, -0.01482519879937172, 0.06895159184932709, -0.0729682445526123, -1.6714686251496213e-32, 0.1288887858390808, 0.170005202293396, 0.05266837403178215, 0.012326625175774097, 0.008779406547546387, -0.008599677123129368, 0.009446701966226101, 0.019202498719096184, 0.07878638803958893, -0.12449312210083008, 0.08634234964847565, -0.06558245420455933, -0.1251877248287201, -0.053570471704006195, 0.039155784994363785, 0.006812190171331167, -0.10729427635669708, 0.06253964453935623, -0.048850011080503464, -0.006314058322459459, -0.15396109223365784, 0.19191837310791016, -0.050779927521944046, -0.007857413031160831, -0.23809434473514557, 0.10678774863481522, 0.05475149303674698, 0.13698865473270416, 0.055944111198186874, -0.022450687363743782, -0.05030176043510437, -0.0024303190875798464, -0.13884063065052032, 0.05012611672282219, 0.019164836034178734, 0.1266828179359436, 0.14710350334644318, -0.01063109003007412, -0.10954567790031433, 0.129635751247406, 0.22615380585193634, 0.14383624494075775, -0.16924837231636047, 0.11981868743896484, -0.12428306043148041, 0.032890722155570984, 0.004844985902309418, 0.0003896657726727426, -0.0560072585940361, -0.00961258914321661, 0.061420463025569916, -0.09602893888950348, -0.05896446853876114, 0.021682098507881165, -0.04909698665142059, 0.014423897489905357, -0.015887148678302765, -0.09364253282546997, 0.034155700355768204, 0.0034100250340998173, -0.053837794810533524, -0.13347531855106354, -0.03666657954454422, -0.0895686075091362, -0.06521052867174149, -0.04024731367826462, -0.19858603179454803, 0.07234220206737518, 0.06357458978891373, 0.1803305298089981, -0.1056303009390831, 0.16507560014724731, 0.19418631494045258, 0.055008746683597565, -0.07686536014080048, 0.06406813859939575, 0.0032894921023398638, -0.03777892887592316, 0.04642973095178604, -0.001552456640638411, -0.13606175780296326, -0.03062986396253109, 0.03525311127305031, 0.13489726185798645, -0.01883016712963581, 0.13775570690631866, 0.18125899136066437, 0.18314625322818756, 0.07095615565776825, -0.08986196666955948, 0.05018695443868637, -0.06316385418176651, 0.18187624216079712, 0.17720571160316467, 0.05294157192111015, -1.0038915121413083e-07, -0.05520341545343399, 0.015139487572014332, 0.046823158860206604, 0.061377137899398804, -0.0075105419382452965, -0.0026403258088976145, 0.07128848135471344, 0.10947460681200027, -0.0002890166360884905, -0.10733383148908615, 0.10986903309822083, 0.06257439404726028, -0.005957709159702063, -0.006093757692724466, -0.05535740777850151, 0.17807476222515106, -0.015817834064364433, 0.06320387125015259, 0.02826867625117302, -0.040262043476104736, -0.019826268777251244, -0.057049501687288284, 0.05303848534822464, -0.0015971589600667357, -0.012496967799961567, -0.04662482440471649, 0.008929875679314137, 0.06308377534151077, -0.03211783990263939, 0.03715693578124046, 0.029011402279138565, -0.06286267936229706, 0.10394022613763809, 0.156561478972435, 0.10151300579309464, 0.07690935581922531, 0.009894118644297123, 0.036695145070552826, -0.06871017068624496, 0.027287226170301437, -0.1833946704864502, 0.0332375168800354, -0.08647532761096954, -0.04494030028581619, 0.15318985283374786, -0.03442034497857094, 0.0060849315486848354, -0.07265366613864899, 0.0710027813911438, 0.018756713718175888, 0.09518271684646606, -0.005484340712428093, -0.09328177571296692, 0.07589999586343765, 0.18101300299167633, -0.09696200489997864, -0.04048929736018181, -0.0062811654061079025, -0.005243405234068632, 0.041357897222042084, -0.01665857993066311, -0.055273495614528656, 0.034461770206689835, -0.09217546880245209], metadata={'source': 'AAAMLP-569to.pdf', 'page': 196}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 197         # convert image to numpy array         image = np.array(image)          # if we have albumentation augmentations         # add them to the image         if self.augmentations is not None:             augmented = self.augmentations(image=image)             image = augmented[\"image\"]          # pytorch expects CHW instead of HWC         image = np.transpose(image, (2, 0, 1)).astype(np.float32)          # return tensors of image and targets         # take a look at the types!         # for regression tasks,          # dtype of targets will change to torch.float         return {             \"image\": torch.tensor(image, dtype=torch.float),             \"targets\": torch.tensor(targets, dtype=torch.long),         } ═════════════════════════════════════════════════════════════════════════  Now we need engine.py. engine.py has training and evaluation functions. Let’s see how engine.py looks like.  ═════════════════════════════════════════════════════════════════════════ # engine.py import torch import torch.nn as nn  from tqdm import tqdm   def train(data_loader, model, optimizer, device):     \"\"\"     This function does training for one epoch     :param data_loader: this is the pytorch dataloader     :param model: pytorch model     :param optimizer: optimizer, for e.g. adam, sgd, etc     :param device: cuda/cpu     \"\"\"      # put the model in train mode     model.train()      # go over every batch of data in data loader     for data in data_loader:'),\n",
       " VectorParams(vector=[-0.0824493020772934, -0.09633169323205948, 0.026199759915471077, 0.07540453225374222, 0.05652368813753128, -0.1667967587709427, -0.06138629838824272, 0.04830411449074745, -0.1247749924659729, -0.1525419056415558, -0.07580380886793137, -0.10038150101900101, -0.022251849994063377, -0.08774740248918533, -0.06366616487503052, 0.02312711998820305, -0.10556920617818832, -0.00022856268333271146, -0.07832454144954681, -0.2075100839138031, 0.07037002593278885, 0.05207058787345886, 0.07640012353658676, 0.08953265845775604, -0.0363159216940403, -0.08189311623573303, 0.10151217877864838, -0.03493122756481171, 0.02898246981203556, -0.06298399716615677, 0.11312324553728104, -0.09388917684555054, -0.1396874189376831, 0.11478497087955475, 0.0307016521692276, 0.14846433699131012, -0.15409986674785614, -0.09668418020009995, -0.11251948028802872, 0.028461532667279243, 0.0919007807970047, 0.0023530854377895594, -0.03266849368810654, -0.05523281171917915, 0.04218738526105881, 0.015012005344033241, 0.10483044385910034, -0.10922002792358398, 0.034290019422769547, -0.07443296164274216, 0.023125048726797104, -0.0006461660959757864, -0.11100853979587555, 0.04712478816509247, -0.05872008949518204, 0.03310391306877136, 0.1969597041606903, -0.16286316514015198, 0.0006993939750827849, -0.18063092231750488, -0.03845018893480301, -0.08631199598312378, -0.10119554400444031, -0.09162859618663788, -0.04960579797625542, -0.07868440449237823, 0.06283119320869446, -0.044967737048864365, 0.10615574568510056, 0.043755028396844864, 0.01248407643288374, 0.11891505122184753, 0.030986011028289795, 0.06545983254909515, -0.09345851093530655, -0.13737189769744873, 0.27069443464279175, 0.0786481723189354, 0.06546568125486374, -0.21516379714012146, -0.008637038059532642, -0.08566107600927353, 0.02306007780134678, -0.04664694890379906, 0.19605010747909546, -0.2480476051568985, 0.019238008186221123, 0.12613803148269653, 0.15695823729038239, -0.07529112696647644, 0.06210468336939812, 0.040632788091897964, -0.0923285037279129, 0.0690503716468811, 0.13630537688732147, 0.08043340593576431, 0.12107797712087631, -0.13305144011974335, -0.1345624178647995, 0.1392439603805542, -0.08714048564434052, -0.02575412206351757, 0.015092283487319946, 0.14580777287483215, 0.07066468894481659, 0.08489733189344406, 0.10126100480556488, 0.11468243598937988, -0.04623140022158623, -0.07750805467367172, 0.11740300059318542, 0.07319404184818268, -0.027300158515572548, 0.0808180421590805, 0.20355160534381866, 0.011570081114768982, -0.11546318978071213, 0.030810987576842308, -0.028096148744225502, 0.22105206549167633, -0.17359894514083862, 0.10096640139818192, -0.13235776126384735, 0.0339653380215168, -0.12251404672861099, -0.18287743628025055, -0.11666741967201233, 1.6388673178871222e-32, -0.06965944916009903, -0.03545695170760155, -0.05281500890851021, -0.1997603178024292, 0.03573642298579216, 0.02909083291888237, 0.05619067698717117, 0.021765492856502533, -0.08605632930994034, 0.0022419332526624203, -0.2612902820110321, -0.03027072362601757, -0.1282067745923996, 0.1586841344833374, 0.03197014704346657, -0.07121334224939346, 0.023095885291695595, 0.11945797502994537, 0.1742742657661438, 0.03352643549442291, 0.19603227078914642, -0.1001138836145401, -0.21089980006217957, -0.1040726825594902, -0.17225556075572968, 0.13830506801605225, -0.03167666494846344, -0.051645297557115555, -0.08736661076545715, -0.0036523824092000723, -0.1416710615158081, 0.04759063944220543, 0.1001252681016922, -0.012448841705918312, 0.0061838203109800816, -0.13453415036201477, 0.09715145081281662, 0.1988673061132431, 0.06528285145759583, -0.11536645889282227, -0.03722767159342766, 0.10847143083810806, 0.030449403449892998, -0.11384899169206619, -0.13375739753246307, -0.0563742034137249, 0.014303766191005707, 0.1487404704093933, -0.04201802983880043, 0.024807674810290337, 0.025995345786213875, -0.14005737006664276, -0.042194951325654984, -0.07877461612224579, -0.05048292502760887, -0.07072010636329651, 0.15244291722774506, 0.06955277919769287, 0.24894177913665771, -0.12055294960737228, 0.18529875576496124, 0.08545274287462234, -0.047837596386671066, 0.07647611945867538, -0.07397472858428955, 0.032092899084091187, 0.05832398682832718, 0.10700902342796326, 0.05853359401226044, 0.05613936483860016, -0.20598067343235016, 0.13308295607566833, -0.05103478580713272, -0.18092797696590424, 0.2845258414745331, -0.11397994309663773, 0.0596567802131176, -0.2191561907529831, -0.2835004925727844, 0.05166565999388695, -0.04248897731304169, 0.1993161290884018, -0.06908733397722244, -0.2573552429676056, -0.0741209015250206, -0.09766089171171188, 0.009485775604844093, -0.032871171832084656, -0.12578187882900238, -0.06504349410533905, -0.23069602251052856, -0.09001073241233826, 0.049065086990594864, 0.07109564542770386, -0.10381194204092026, -1.5306075207858542e-32, 0.06791697442531586, 0.12786124646663666, 0.03946929797530174, 0.08024439960718155, 0.12395793944597244, -0.007987809367477894, 0.03739555925130844, 0.026467353105545044, 0.034574709832668304, -0.11330262571573257, -0.05110848322510719, -0.13580116629600525, -0.11230180412530899, -0.06348282098770142, 0.06528184562921524, 0.029647592455148697, -0.056892309337854385, 0.01952899433672428, -0.030921582132577896, -0.04658135771751404, -0.1698175072669983, 0.25029420852661133, -0.21754741668701172, -0.052106231451034546, -0.1546911746263504, 0.03817277401685715, 0.09272576123476028, 0.21221806108951569, 0.05183348059654236, -0.06288161873817444, -0.03331857547163963, -0.013316873461008072, -0.12619169056415558, 0.09642983227968216, -0.03583690524101257, 0.16575808823108673, 0.14931116998195648, -0.07573644071817398, -0.10629858076572418, 0.1401289999485016, 0.40055423974990845, 0.13722845911979675, -0.11472152918577194, 0.15713317692279816, -0.022444890812039375, 0.07432956993579865, -0.029864341020584106, 0.015503565780818462, -0.07610582560300827, 0.02831769362092018, 0.0014531492488458753, -0.09404179453849792, -0.15083928406238556, 0.0539449006319046, -0.013816374354064465, 0.04273141175508499, 0.0778919905424118, -0.11962831765413284, -0.040580909699201584, 0.03825848549604416, -0.13035300374031067, -0.18087626993656158, 0.02123595029115677, -0.021421371027827263, -0.01180735882371664, 0.029093759134411812, -0.15684112906455994, 0.16970199346542358, 0.0591425821185112, 0.19212733209133148, -0.07253025472164154, 0.14960722625255585, 0.10329380631446838, 0.043909087777137756, -0.10256630927324295, 0.09362522512674332, -0.05897046625614166, 0.03522493317723274, 0.08164568990468979, 0.0034482271876186132, -0.00916481576859951, -0.06782401353120804, 0.0369727723300457, 0.15948081016540527, 0.025853874161839485, 0.093251071870327, 0.10626702755689621, 0.1715160608291626, 0.08504993468523026, -0.12364745885133743, 0.006022282876074314, -0.15076012909412384, 0.1896677166223526, 0.1354624181985855, 0.08972460776567459, -1.0070082367974464e-07, -1.4308899153547827e-05, 0.11306563019752502, 0.0764513909816742, 0.15745097398757935, -0.001725690090097487, -0.010598957538604736, 0.04844566807150841, 0.06881742924451828, 0.1058327779173851, -0.0948297306895256, 0.1392671912908554, -0.08080820739269257, 0.036032792180776596, -0.004373039584606886, -0.03746403381228447, 0.32471343874931335, 0.10517782717943192, 0.0027629369869828224, 0.06411498039960861, -0.10721820592880249, -0.028315238654613495, -0.13609744608402252, 0.0039299908094108105, -0.04139041155576706, -0.06477130204439163, -0.08719981461763382, -0.01892920956015587, 0.07451122254133224, 0.0012025899486616254, -0.0076838647946715355, -0.047365449368953705, -0.09132356941699982, 0.09316083788871765, 0.12880633771419525, 0.11268484592437744, 0.10721801221370697, 0.06949474662542343, -0.013318667188286781, 0.10050969570875168, 0.10478659719228745, -0.14820560812950134, 0.03155844658613205, -0.09793288260698318, -0.14011472463607788, 0.05018669739365578, 0.056310608983039856, -0.06165044754743576, -0.08785106241703033, 0.050203192979097366, 0.14977431297302246, 0.002654250944033265, 0.03237614035606384, -0.1351223886013031, 0.11563587933778763, 0.18795502185821533, -0.19009697437286377, -0.034274376928806305, -0.15327642858028412, -0.07373233884572983, 0.002949577057734132, 0.05058394372463226, 0.01286665815860033, -0.1660493165254593, -0.04908701032400131], metadata={'source': 'AAAMLP-569to.pdf', 'page': 197}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 198         # remember, we have image and targets         # in our dataset class         inputs = data[\"image\"]         targets = data[\"targets\"]          # move inputs/targets to cuda/cpu device         inputs = inputs.to(device, dtype=torch.float)         targets = targets.to(device, dtype=torch.float)          # zero grad the optimizer         optimizer.zero_grad()         # do the forward step of model         outputs = model(inputs)         # calculate loss         loss = nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))         # backward step the loss         loss.backward()         # step optimizer         optimizer.step()         # if you have a scheduler, you either need to         # step it here or you have to step it after         # the epoch. here, we are not using any learning         # rate scheduler   def evaluate(data_loader, model, device):     \"\"\"     This function does evaluation for one epoch     :param data_loader: this is the pytorch dataloader     :param model: pytorch model     :param device: cuda/cpu     \"\"\"     # put model in evaluation mode     model.eval()      # init lists to store targets and outputs     final_targets = []     final_outputs = []      # we use no_grad context     with torch.no_grad():          for data in data_loader:             inputs = data[\"image\"]             targets = data[\"targets\"]             inputs = inputs.to(device, dtype=torch.float)             targets = targets.to(device, dtype=torch.float)'),\n",
       " VectorParams(vector=[-0.10592382401227951, -0.08676882088184357, 0.0010046843672171235, 0.11811498552560806, 0.16415169835090637, -0.09684453904628754, -0.02849874086678028, -0.029224004596471786, -0.1427590548992157, -0.16593411564826965, -0.012035781517624855, 0.01775336265563965, -0.016445590183138847, -0.03446158021688461, -0.14960013329982758, -0.003012667875736952, 0.0009204093948937953, 0.05109375715255737, -0.12995938956737518, -0.14252085983753204, 0.11205291748046875, 0.08087082207202911, 0.004412746522575617, 0.07611658424139023, -0.03195600211620331, -0.02587132714688778, 0.08867983520030975, 0.0661962553858757, -0.08559614419937134, -0.11236496269702911, 0.050549428910017014, -0.046977777034044266, -0.059660475701093674, 0.06272529065608978, 0.07876923680305481, 0.043856605887413025, -0.07382131367921829, -0.038686469197273254, 0.011616886593401432, -0.0421522855758667, 0.06479983776807785, 0.02884816564619541, -0.07783250510692596, -0.020544547587633133, 0.055283695459365845, 0.0970899909734726, -0.05432126298546791, -0.08706764131784439, 0.08114335685968399, -0.1475711613893509, -0.09993085265159607, -0.047756701707839966, -0.12381244450807571, 0.0829852744936943, 0.00012645921378862113, -0.06838912516832352, 0.12288031727075577, -0.12742699682712555, -0.16059936583042145, -0.1569565236568451, -0.06088130548596382, 0.0025829195510596037, -0.13449691236019135, 0.014529659412801266, 0.052364811301231384, 0.03793322667479515, -0.0205093827098608, 0.07586261630058289, 0.12202372401952744, -0.05285406485199928, 0.03959648683667183, 0.05788708105683327, -0.04410329833626747, 0.05121127516031265, -0.015103434212505817, -0.033248841762542725, 0.2553229331970215, 0.1136544868350029, -0.004588748328387737, -0.14950931072235107, -0.06218845024704933, -0.07143159210681915, 0.05581245571374893, -0.033879347145557404, 0.09694531559944153, -0.11551541835069656, -0.0218692384660244, 0.10381980985403061, 0.12349333614110947, -0.06864690035581589, -0.1209469586610794, -0.06544477492570877, -0.020558318123221397, 0.07050008326768875, 0.19211864471435547, 0.18762393295764923, 0.11254014074802399, -0.11211714148521423, -0.0847552940249443, 0.13186688721179962, -0.04213026538491249, -0.0884484276175499, 0.0806502178311348, 0.05364670976996422, 0.125620037317276, 0.15669533610343933, 0.1386355608701706, 0.02937636338174343, 0.08869317173957825, -0.22259745001792908, 0.016667481511831284, 0.0014141653664410114, -0.020163223147392273, 0.04413704201579094, 0.20835940539836884, -0.03448300436139107, -0.005787561181932688, 0.11442086100578308, -0.105649933218956, 0.1528734564781189, -0.10763828456401825, 0.05652550235390663, 0.038945555686950684, 0.06070586293935776, -0.04505089670419693, -0.10086718946695328, -0.2228674441576004, 1.2996471254202605e-32, -0.09430327266454697, -0.130239337682724, -0.018840856850147247, -0.10026465356349945, 0.10843826830387115, -0.017917035147547722, 0.12644366919994354, 0.0540664903819561, -0.027021078392863274, -0.031276315450668335, -0.23414850234985352, 0.00022526239627040923, -0.06667404621839523, 0.10795535147190094, 0.045571643859148026, -0.003848599037155509, 0.04726161062717438, 0.17560146749019623, 0.04878335818648338, 0.07230009883642197, 0.15753889083862305, 0.007776261307299137, -0.13198333978652954, -0.054096803069114685, -0.12299314886331558, 0.03250442072749138, -0.09701396524906158, -0.0750550851225853, -0.1800352931022644, -0.010153485462069511, -0.21450215578079224, 0.03469011187553406, 0.06415073573589325, -0.00624784454703331, -0.10289640724658966, -0.12362734973430634, 0.05310822278261185, -0.02739415131509304, 0.04315262287855148, -0.16392509639263153, 0.03994554653763771, 0.04621775075793266, -0.07718147337436676, -0.0694291740655899, -0.06900745630264282, -0.015557736158370972, -0.10560833662748337, 0.11874925345182419, -0.1013009175658226, 0.05872942879796028, 0.0892488956451416, -0.09462875872850418, -0.05722774192690849, -0.08579413592815399, -0.13424474000930786, -0.04992636293172836, 0.08022154867649078, 0.0973132774233818, 0.2594606280326843, 0.0124746672809124, 0.12875913083553314, 0.007205547299236059, -0.09737883508205414, 0.1582983434200287, 0.11228523403406143, 0.028509266674518585, 0.02782435156404972, 0.10141225159168243, 0.08340800553560257, 0.03877255693078041, -0.2227495163679123, 0.06060441583395004, -0.08273742347955704, -0.10434915870428085, 0.17633548378944397, -0.16546738147735596, 0.0030911206267774105, -0.17765235900878906, -0.12724284827709198, 0.11607658863067627, 0.06834650039672852, 0.22802382707595825, -0.14025062322616577, -0.1957997977733612, -0.06186839938163757, 0.08710841089487076, 0.07051948457956314, -0.14028267562389374, -0.029340947046875954, 0.0014693342382088304, -0.1283389925956726, -0.09247469902038574, -0.034531813114881516, 0.0008803213713690639, -0.015253476798534393, -1.2813539353959702e-32, 0.08701927214860916, 0.1326194703578949, 0.0015695984475314617, 0.004465489648282528, 0.034634292125701904, 0.029324404895305634, -0.007122610695660114, 0.016608143225312233, -0.09562051296234131, -0.11009372770786285, 0.017333682626485825, -0.2138870805501938, 0.03023722395300865, -0.06633241474628448, 0.05600442364811897, 0.0007004369399510324, -0.03654974699020386, -0.003303925273939967, 0.04807340353727341, 0.029498212039470673, -0.060903701931238174, 0.11713137477636337, -0.17558448016643524, 0.01673158071935177, -0.1200975775718689, 0.04218466579914093, -0.07788517326116562, 0.2252701371908188, 0.07137636840343475, -0.07436476647853851, -0.05904937908053398, 0.03836090862751007, -0.07866086065769196, -0.0252069104462862, -0.011175019666552544, 0.15508824586868286, 0.0677289366722107, -0.008316645398736, -0.03320402652025223, 0.15704606473445892, 0.2115553915500641, 0.077468641102314, -0.189477801322937, 0.13075432181358337, -0.0600137785077095, -0.044145092368125916, -0.08832035213708878, 0.017666451632976532, -0.007742307614535093, -0.0397745817899704, 0.07590469717979431, -0.09906744211912155, -0.13681848347187042, 0.026858344674110413, -0.09918113797903061, 0.0454099215567112, 0.0824674591422081, 0.07418720424175262, 0.07438989728689194, -0.05890657752752304, -0.08412861824035645, -0.19767889380455017, -0.06308365613222122, -0.008297815918922424, 0.0011070453329011798, 0.05498110130429268, -0.1413652002811432, 0.11042243242263794, -0.0025120098143815994, 0.12536326050758362, -0.08544665575027466, 0.07807665318250656, 0.0881795883178711, 0.03316723555326462, -0.07597292214632034, 0.04313125088810921, 0.01414596289396286, -0.03102528676390648, 0.04682677239179611, -0.0017067949520424008, -0.18403925001621246, -0.09401212632656097, 0.03683040291070938, 0.047412991523742676, 0.12534107267856598, 0.07915730029344559, 0.0940151959657669, 0.1025577262043953, 0.08680485188961029, -0.13968431949615479, 0.0538969561457634, 0.014823487028479576, 0.14401373267173767, 0.1139964759349823, 0.05092838779091835, -1.0058458599360165e-07, 0.0010932959849014878, 0.04498167335987091, 0.05939290300011635, 0.17063622176647186, 0.05932669714093208, 0.0817873477935791, 0.04271885007619858, 0.12236863374710083, 0.06193212792277336, -0.07161492854356766, 0.04611087217926979, -0.06040610000491142, 0.003602154552936554, 0.07833266258239746, -0.022639261558651924, 0.23677955567836761, 0.005547729786485434, -0.05702490732073784, 0.016007523983716965, -0.008708559907972813, 0.04596976563334465, -0.11069819331169128, -0.03579413890838623, 0.0714135617017746, -0.02693161927163601, -0.09427231550216675, -0.05479045584797859, 0.053698938339948654, -0.022353708744049072, 0.0766412615776062, -0.009350858628749847, -0.0777013748884201, 0.03864461928606033, -0.007692493032664061, 0.14173373579978943, 0.13768714666366577, 0.028864461928606033, -0.05289754271507263, -0.004816945176571608, 0.031338535249233246, -0.13470272719860077, 0.06316868215799332, -0.08873945474624634, -0.0540105402469635, 0.1459500789642334, -0.10058949142694473, -0.06288705766201019, -0.14114037156105042, 0.08666849136352539, -0.04646942764520645, 0.011773732490837574, 0.015298274345695972, -0.038026198744773865, 0.08304490894079208, 0.06977736204862595, -0.03923896700143814, 0.023493357002735138, -0.06518014520406723, -0.035702113062143326, 0.09723334014415741, 0.03624536842107773, -0.005217103287577629, 0.03061590902507305, 0.012542279437184334], metadata={'source': 'AAAMLP-569to.pdf', 'page': 198}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 199             # do the forward step to generate prediction             output = model(inputs)              # convert targets and outputs to lists             targets = targets.detach().cpu().numpy().tolist()             output = output.detach().cpu().numpy().tolist()                          # extend the original list             final_targets.extend(targets)             final_outputs.extend(output)          # return final output and final targets     return final_outputs, final_targets ═════════════════════════════════════════════════════════════════════════  Once we have engine.py, we are ready to create a new file: model.py. model.py will consist of our model. It’s a good idea to keep it separate because that allows us to easily experiment with different models and different architectures. A PyTorch library called pretrainedmodels has a lot of different model architectures, such as AlexNet, ResNet, DenseNet, etc. There are different model architectures which have been trained on large image dataset called ImageNet. We can use them with their weights after training on ImageNet, and we can also use them without these weights. If we train without the ImageNet weights, it means our network is learning everything from scratch. This is what model.py looks like.  ═════════════════════════════════════════════════════════════════════════ # model.py import torch.nn as nn import pretrainedmodels   def get_model(pretrained):     if pretrained:         model = pretrainedmodels.__dict__[\"alexnet\"](             pretrained=\\'imagenet\\'         )     else:         model = pretrainedmodels.__dict__[\"alexnet\"](             pretrained=None         )     # print the model here to know whats going on.     model.last_linear = nn.Sequential(         nn.BatchNorm1d(4096),         nn.Dropout(p=0.25),         nn.Linear(in_features=4096, out_features=2048),'),\n",
       " VectorParams(vector=[-0.05260959267616272, -0.12661327421665192, 0.04234105721116066, -0.11211852729320526, 0.13474507629871368, -0.1847507804632187, -0.12427280843257904, -0.11645829677581787, -0.11369878798723221, -0.11156419664621353, 0.021750088781118393, 0.00794889498502016, -0.06287835538387299, -0.11832728981971741, -0.16657230257987976, 0.055474746972322464, -0.006391782313585281, 0.16736473143100739, -0.17976222932338715, -0.07620423287153244, 0.19603809714317322, 0.1450837105512619, -0.11076584458351135, -0.013063278049230576, 0.033457204699516296, 0.1497226059436798, 0.05842088907957077, 0.15087702870368958, -0.03493056818842888, -0.2688072621822357, 0.1652836799621582, 0.1301514208316803, -0.15169118344783783, -0.009709987789392471, -0.00123685784637928, 0.11849762499332428, -0.1078203022480011, -0.021213555708527565, -0.04588378965854645, 0.010598844848573208, 0.020300518721342087, -0.004804801195859909, 0.028048314154148102, 0.06349979341030121, 0.26182126998901367, 0.10585755109786987, -0.06582286953926086, -0.03639659658074379, 0.22393721342086792, -0.14579692482948303, -0.08396964520215988, 0.028250355273485184, -0.030492765828967094, 0.00853155180811882, 0.007984921336174011, -0.05198989808559418, -0.07253363728523254, -0.06579364836215973, 0.06173664331436157, -0.035212915390729904, 0.10177718102931976, 0.008486744947731495, 0.043767862021923065, 0.11950935423374176, -0.00848881434649229, -0.15415212512016296, -0.00875916238874197, 0.03418361395597458, -0.02120930701494217, 0.19422176480293274, -0.03290671482682228, 0.16531148552894592, -0.1084410548210144, -0.04870016127824783, 0.10985235869884491, 0.010279124602675438, 0.1930379867553711, 0.03433240205049515, -0.010435551404953003, -0.16131925582885742, 0.010290180332958698, 0.05186240002512932, 0.07858548313379288, -0.11831554770469666, -0.022327246144413948, -0.1775619387626648, -0.06396804749965668, 0.08466016501188278, 0.07608114182949066, -0.10216397047042847, 0.049363695085048676, 0.19917787611484528, -0.2327118217945099, -0.062074437737464905, -0.0116810854524374, 0.08122570067644119, 0.11194372177124023, -0.07527297735214233, -0.04921179637312889, 0.2398269772529602, -0.07451613247394562, -0.10996020585298538, -0.015692496672272682, -0.00927464384585619, 0.14545315504074097, 0.027670197188854218, 0.1473226249217987, 0.09990458190441132, 0.07591225206851959, -0.1947546899318695, 0.06619976460933685, -0.12708333134651184, 0.10167837888002396, 0.07281291484832764, 0.2721302807331085, 0.05059369280934334, -0.08220122754573822, 0.1011485680937767, 0.044792331755161285, 0.06833385676145554, -0.08998819440603256, 0.026785198599100113, -0.01250682957470417, 0.11425257474184036, -0.06864171475172043, -0.055602800101041794, -0.18336710333824158, 1.1150078196327882e-32, -0.13008490204811096, -0.08318669348955154, -0.069385826587677, -0.1269214153289795, -0.00029289163649082184, 0.08969347178936005, 0.09508585929870605, -0.061662476509809494, -0.03850322961807251, -0.005297421477735043, -0.2606995701789856, -0.10966798663139343, -0.12751875817775726, 0.0308351032435894, 0.038723938167095184, -0.14501246809959412, -0.008883385919034481, 0.1516755223274231, -0.012367060407996178, -0.06614327430725098, 0.07854413986206055, -0.028231121599674225, -0.05553404241800308, -0.18522480130195618, -0.12445782124996185, -0.10581473261117935, 0.005415922962129116, -0.1432759314775467, -0.09356656670570374, 0.04546163231134415, -0.09803351759910583, 0.04894401133060455, -0.046644557267427444, 0.03494686633348465, -0.1195584237575531, -0.07659510523080826, 0.031693365424871445, 0.06110889092087746, 0.04049012437462807, -0.0936751514673233, -0.04641849175095558, 0.09927603602409363, -0.0010454519651830196, -0.09759140014648438, -0.1154378280043602, -0.1584780514240265, 0.1545267254114151, 0.164989173412323, -0.008894420228898525, 0.09553637355566025, 0.04022771120071411, -0.05574437975883484, 0.032849304378032684, -0.14547570049762726, -0.12014196813106537, -0.02671339362859726, 0.14315125346183777, 0.1360348016023636, 0.05771708860993385, 0.2167666107416153, -0.0670541450381279, 0.003118310123682022, -0.13801389932632446, -0.0330834686756134, 0.03576852008700371, 0.05795161426067352, -0.03391043096780777, 0.01327586080878973, 0.17007148265838623, 0.14525127410888672, -0.18794915080070496, 0.06953668594360352, 0.11483565717935562, -0.11561715602874756, 0.1030115932226181, -0.18598061800003052, 0.06997181475162506, -0.04367491975426674, -0.14311662316322327, -0.09685303270816803, -0.0887027382850647, 0.3049301505088806, -0.054462119936943054, -0.2091895192861557, -0.17469586431980133, -0.16823087632656097, 0.08146675676107407, -0.18407326936721802, -0.19746184349060059, -0.1349920630455017, -0.20319944620132446, -0.1118089109659195, 0.1834183782339096, 0.03280459716916084, -0.06269723176956177, -1.0077197155492687e-32, 0.03761240839958191, 0.13324518501758575, 0.037683118134737015, 0.13542494177818298, 0.001623834017664194, 0.0688173770904541, 0.20553186535835266, 0.005223222076892853, -0.09144963324069977, -0.22345326840877533, 0.03007512167096138, -0.024834925308823586, 0.06745883822441101, 0.0259298924356699, 0.24513530731201172, -0.0466775968670845, -0.031332507729530334, 0.04939001053571701, 0.024461042135953903, 0.037165138870477676, -0.03710063546895981, 0.2564656436443329, 0.03960089385509491, 0.059758204966783524, -0.08582101762294769, 0.07738970965147018, 0.012179317884147167, 0.08923010528087616, 0.03333082050085068, -0.11769802868366241, -0.03199506551027298, -0.037164147943258286, -0.28988853096961975, 0.22516903281211853, 0.04169940948486328, 0.02982853725552559, 0.05449634790420532, -0.03752478212118149, -0.041742339730262756, 0.15337415039539337, 0.29149264097213745, 0.11291679739952087, -0.2588256001472473, 0.11401453614234924, 0.028776908293366432, 0.018066024407744408, 0.0877523273229599, -0.02836575359106064, -0.037055619060993195, -0.016733072698116302, -0.09816654026508331, -0.041342463344335556, -0.128727525472641, 0.16842439770698547, 0.004893057979643345, 0.09947283565998077, -0.11097518354654312, 0.013107243925333023, 0.06016896665096283, -0.10895294696092606, -0.18815961480140686, -0.14044857025146484, -0.010933361947536469, 0.006418836303055286, 0.25277701020240784, 0.0756012499332428, -0.09778328239917755, 0.0676778107881546, -0.008912628516554832, 0.27827078104019165, -0.12162680923938751, 0.11425046622753143, -0.06211479753255844, -0.06648190319538116, -0.023929806426167488, -0.08624777942895889, 0.07179665565490723, -0.1316143274307251, -0.027005348354578018, -0.01637912169098854, -0.2429019808769226, 0.03449486941099167, 0.14865052700042725, 0.2514541447162628, 0.05957444757223129, 0.07441791892051697, 0.016384847462177277, 0.10196015238761902, 0.15234749019145966, -0.10334409773349762, 0.05651175230741501, 0.11729654669761658, 0.19439886510372162, 0.14074912667274475, 0.11878874897956848, -9.938935363607015e-08, -0.061146751046180725, -0.09468978643417358, 0.0030145524069666862, 0.112201027572155, 0.2965089678764343, -0.10512427240610123, -0.0313718244433403, 0.08606588840484619, -0.11433267593383789, -0.13416145741939545, 0.10496312379837036, -0.03207242488861084, -0.06251603364944458, -0.07774202525615692, -0.04636401683092117, 0.1886335015296936, -0.04051386937499046, -0.07896068692207336, -0.04239648953080177, -0.0995776355266571, -0.08006040006875992, -0.019472770392894745, -0.1071108728647232, 0.06864842772483826, -0.022885991260409355, -0.16946792602539062, -0.10018253326416016, -0.06289644539356232, 0.19059023261070251, 0.05060964077711105, -0.09282056987285614, -0.1036706492304802, 0.12609712779521942, 9.395834058523178e-05, 0.13010495901107788, 0.09896647930145264, 0.013105745427310467, 0.15287916362285614, -0.05742296203970909, 0.06825900822877884, -0.2093033790588379, 0.24952161312103271, 0.07360901683568954, -0.06414686888456345, 0.22030511498451233, -0.045143403112888336, 0.056012704968452454, -0.13786914944648743, 0.1501973569393158, -0.16435173153877258, -0.002583928406238556, 0.09814317524433136, -0.002209300175309181, 0.13594962656497955, 0.08066821098327637, -0.21022844314575195, -0.23917844891548157, 0.05043657869100571, -0.016431190073490143, 0.11542506515979767, 0.026451697573065758, 0.00647107744589448, 0.015237906947731972, -0.03276451304554939], metadata={'source': 'AAAMLP-569to.pdf', 'page': 199}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 200         nn.ReLU(),         nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1),         nn.Dropout(p=0.5),         nn.Linear(in_features=2048, out_features=1),     )     return model ═════════════════════════════════════════════════════════════════════════  If you print the final model, you will be able to see what it looks like:  ═════════════════════════════════════════════════════════════════════════ AlexNet(   (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))   (_features): Sequential(     (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))     (1): ReLU(inplace=True)     (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)     (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))     (4): ReLU(inplace=True)     (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)     (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))     (7): ReLU(inplace=True)     (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))     (9): ReLU(inplace=True)     (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))     (11): ReLU(inplace=True)     (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)   )   (dropout0): Dropout(p=0.5, inplace=False)   (linear0): Linear(in_features=9216, out_features=4096, bias=True)   (relu0): ReLU(inplace=True)   (dropout1): Dropout(p=0.5, inplace=False)   (linear1): Linear(in_features=4096, out_features=4096, bias=True)   (relu1): ReLU(inplace=True)   (last_linear): Sequential(     (0): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)     (1): Dropout(p=0.25, inplace=False)     (2): Linear(in_features=4096, out_features=2048, bias=True)'),\n",
       " VectorParams(vector=[-0.030904296785593033, -0.03991875424981117, 0.054998163133859634, 0.08089806139469147, 0.16101673245429993, -0.041507571935653687, 0.006439067889004946, 0.032620206475257874, -0.11664745211601257, -0.14996817708015442, 0.020350370556116104, -0.11994091421365738, 0.010661648586392403, -0.1361096203327179, -0.040630798786878586, 0.018022099509835243, -0.0826813131570816, -0.0059965550899505615, -0.15331386029720306, -0.2000402957201004, 0.0009701617527753115, 0.038280997425317764, 0.12245602905750275, 0.04053929075598717, -0.03376191481947899, 0.01570979319512844, 0.07672261446714401, -0.01245674304664135, -0.09439124166965485, -0.13496598601341248, 0.09807463735342026, -0.03734789416193962, -0.0535629466176033, 0.06135134398937225, 0.11622797697782516, 0.11402414739131927, -0.09221743792295456, 0.005135394167155027, -0.03227531164884567, 0.059349171817302704, 0.11186497658491135, 0.025924256071448326, 0.048661552369594574, -0.12349759787321091, 0.08201737701892853, 0.03250521793961525, -0.0366717129945755, -0.0674888864159584, 0.10573428124189377, -0.02284582518041134, -0.1411125212907791, -0.0008108886540867388, -0.12022180110216141, 0.0439680740237236, 0.01744851842522621, -0.08570502698421478, 0.09013508260250092, -0.046113021671772, 0.00927499309182167, -0.02382400631904602, 0.052340805530548096, -0.10488910228013992, -0.10883263498544693, -0.026127876713871956, 0.0021499183494597673, -0.1312246322631836, 0.06146683171391487, 0.008045961149036884, 0.09269484132528305, 0.04084409028291702, 0.017071902751922607, 0.1192873865365982, -0.035870205610990524, 0.08130987733602524, -0.09590581804513931, -0.11953649669885635, 0.20896658301353455, -0.02733212523162365, 0.08300566673278809, -0.1692686229944229, -0.03205567225813866, -0.08295662701129913, 0.059968866407871246, -0.15869469940662384, 0.10758789628744125, -0.15551899373531342, 0.04082940146327019, 0.07723399996757507, -0.03890948370099068, -0.11567528545856476, -0.03832364082336426, -0.03030172549188137, -0.14952974021434784, 0.054704952985048294, 0.1250852346420288, 0.1633571982383728, 0.1146584153175354, -0.06814625859260559, -0.06633766740560532, 0.12474993616342545, 0.004831256344914436, -0.001824993290938437, -0.035798147320747375, 0.09756743162870407, 0.08425957709550858, 0.07141471654176712, 0.15166714787483215, 0.1184307411313057, 0.01783471554517746, -0.1090797483921051, 0.07091934233903885, -0.015035731717944145, -0.06823507696390152, 0.040652357041835785, 0.13145683705806732, -0.02504582516849041, -0.05695861950516701, 0.04996452480554581, -0.18471823632717133, 0.0761910006403923, -0.07597919553518295, -0.01371530070900917, -0.08289873600006104, 0.022613735869526863, -0.10609520226716995, -0.1688319891691208, -0.1127738356590271, 1.57833758728023e-32, -0.10810451954603195, -0.10473603755235672, 0.01903948001563549, -0.16136297583580017, 0.07704325765371323, -0.048100825399160385, 0.011245421133935452, 0.04650965332984924, -0.04411333054304123, 0.04096803069114685, -0.1960473358631134, -0.09277308732271194, -0.11948909610509872, 0.1058889776468277, -0.0025524822995066643, -0.07063962519168854, -0.05117053538560867, 0.07573796063661575, 0.10778744518756866, 0.022952934727072716, 0.14227689802646637, -0.06965259462594986, -0.07976725697517395, -0.07985194027423859, -0.12919363379478455, 0.013182230293750763, -0.003127114148810506, -0.00605745380744338, -0.14296682178974152, 0.010920110158622265, -0.1673119068145752, 0.06323759257793427, -0.0578247494995594, -0.019651005044579506, -0.06373461335897446, -0.10437202453613281, 0.032081108540296555, 0.11879006773233414, -0.017673829570412636, -0.06165684759616852, -0.020372986793518066, 0.13303329050540924, -0.0568300299346447, -0.08936606347560883, -0.08232613652944565, 0.030672544613480568, -0.04819701984524727, 0.13788089156150818, -0.036868076771497726, 0.08866487443447113, -0.002115079667419195, -0.08002841472625732, 0.01494060829281807, -0.01769462786614895, -0.0786423310637474, -0.025967860594391823, 0.11934852600097656, 0.024740194901823997, 0.12266657501459122, -0.0982075184583664, 0.1525474339723587, 0.05656523257493973, 0.02466008998453617, 0.07394780963659286, 0.045428838580846786, 0.0384061336517334, 0.11014507710933685, 0.06976951658725739, 0.011746178381145, 0.013302131555974483, -0.1488773077726364, 0.12571577727794647, -0.025984957814216614, -0.1780840903520584, 0.21159566938877106, -0.07451023161411285, 0.08312413096427917, -0.06003924459218979, -0.1980752944946289, 0.08612485975027084, 0.001805005595088005, 0.15507428348064423, -0.05362314730882645, -0.29515889286994934, -0.09778674691915512, 0.07011032849550247, 0.0435369573533535, -0.09055235981941223, -0.1365131139755249, -0.12516281008720398, -0.14457271993160248, 0.06133323535323143, 0.0474887378513813, 0.034412652254104614, -0.04529660940170288, -1.5345410187572933e-32, 0.1521933376789093, 0.1575605869293213, 0.14513373374938965, 0.02685231901705265, 0.10493840277194977, 0.07692020386457443, 0.12361691147089005, 0.1218944862484932, -0.1017737090587616, -0.13013610243797302, 0.055430036038160324, -0.13180766999721527, -0.12406031042337418, -0.07523050159215927, 0.00304416217841208, -0.07056660205125809, -0.04311578348278999, 0.03196891024708748, -0.026039624586701393, 0.03841139003634453, -0.09969959408044815, 0.2100180834531784, -0.13018493354320526, 0.051393065601587296, -0.200753852725029, 0.10941924154758453, -0.02933892235159874, 0.0679626315832138, -0.02164413034915924, -0.07280519604682922, -0.024413375183939934, 0.06118728592991829, -0.16309893131256104, 0.057003412395715714, 0.019579527899622917, 0.09078407287597656, 0.08512035757303238, 0.028440410271286964, -0.13562758266925812, 0.2887984812259674, 0.1706864833831787, 0.19906452298164368, -0.17012757062911987, 0.15829525887966156, 0.029174230992794037, 0.000666706298943609, 0.0813651904463768, 0.003961960785090923, -0.061600539833307266, 0.07953893393278122, 0.06668700277805328, -0.10376587510108948, -0.1083277240395546, 0.014662040397524834, 0.06255366653203964, 0.051364537328481674, -0.07023758441209793, -0.060684554278850555, -0.1341797560453415, -0.021699849516153336, -0.1338505893945694, -0.129448801279068, -0.10393446683883667, -0.05699646845459938, 0.0686500072479248, 0.06186798959970474, -0.18904584646224976, 0.09835407882928848, -0.013066591694951057, 0.14068809151649475, -0.07720411568880081, 0.05249551683664322, 0.10283787548542023, 0.050326693803071976, -0.052646905183792114, 0.12514229118824005, -0.047228116542100906, -0.04549768939614296, 0.05019053444266319, 0.06961645931005478, -0.07635489851236343, -0.032730523496866226, 0.021851446479558945, 0.08422478288412094, 0.021560078486800194, 0.13401857018470764, 0.04881633073091507, 0.023234663531184196, 0.12300021946430206, -0.10814477503299713, 0.017958644777536392, -0.0172029547393322, 0.26707834005355835, 0.1060933917760849, 0.06227231025695801, -1.0035618203119157e-07, -0.0154168251901865, 9.179846529150382e-05, 0.1016068235039711, 0.05622047558426857, 0.06210161745548248, 0.017475789412856102, -0.10016720741987228, 0.11555857956409454, 0.07617339491844177, -0.1291898787021637, 0.1283898502588272, -0.07552846521139145, -0.06070322543382645, 0.07976317405700684, -0.07937189191579819, 0.10372772812843323, 0.011926633305847645, 0.11044037342071533, 0.03399020433425903, -0.0007603987469337881, -0.013131589628756046, -0.12522433698177338, 0.02542678825557232, -0.011228546500205994, 0.021614519879221916, -0.13425230979919434, -0.030240196734666824, 0.062095291912555695, 0.019259490072727203, -0.00458439951762557, -0.050074461847543716, -0.13972721993923187, 0.12901364266872406, 0.09922140836715698, 0.1640152484178543, 0.041031353175640106, 0.07813697308301926, -0.020246289670467377, -0.01793764717876911, -0.023282520473003387, -0.20225898921489716, 0.0597434937953949, -0.03837868198752403, -0.05399228259921074, 0.06304146349430084, -0.03495503216981888, 0.09836703538894653, -0.0500858873128891, 0.014718004502356052, 0.038994960486888885, -0.06061148643493652, -0.06792214512825012, 0.01784515380859375, 0.07768528908491135, 0.12333802878856659, -0.12703873217105865, -0.024150425568223, 0.02601258084177971, 0.0033008502796292305, 0.08525073528289795, 0.0344325415790081, -0.039505403488874435, -0.05019795149564743, -0.0264961589127779], metadata={'source': 'AAAMLP-569to.pdf', 'page': 200}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 201     (3): ReLU()     (4): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)     (5): Dropout(p=0.5, inplace=False)     (6): Linear(in_features=2048, out_features=1, bias=True)   ) ) ═════════════════════════════════════════════════════════════════════════  Now, we have everything, and we can start training. We will do so using train.py.  ═════════════════════════════════════════════════════════════════════════ # train.py import os  import pandas as pd import numpy as np  import albumentations import torch  from sklearn import metrics from sklearn.model_selection import train_test_split  import dataset import engine from model import get_model   if __name__ == \"__main__\":     # location of train.csv and train_png folder     # with all the png images      data_path = \"/home/abhishek/workspace/siim_png/\"      # cuda/cpu device     device = \"cuda\"      # let\\'s train for 10 epochs     epochs = 10      # load the dataframe     df = pd.read_csv(os.path.join(data_path, \"train.csv\"))      # fetch all image ids     images = df.ImageId.values.tolist()'),\n",
       " VectorParams(vector=[0.015511028468608856, -0.12158562988042831, 0.14425790309906006, 0.04399682953953743, 0.05848192796111107, -0.0782008245587349, -0.006882318761199713, -0.0003176454920321703, -0.12711265683174133, -0.09269903600215912, -0.024040719494223595, -0.12659792602062225, 0.09960666298866272, -0.07089617848396301, -0.043007247149944305, 0.016013897955417633, -0.01041189581155777, 0.09087006747722626, -0.19109949469566345, -0.07362735271453857, 0.09298087656497955, 0.08582846075296402, 0.09810180217027664, 0.016573278233408928, 0.06315658986568451, -0.08812820911407471, 0.06900271028280258, 0.0029978081583976746, 0.015019409358501434, -0.08893819153308868, 0.05001849681138992, -0.0025975953321903944, -0.008184914477169514, 0.04921892657876015, 0.03040282428264618, 0.015440947376191616, -0.09415236860513687, -0.07712244242429733, -0.14176353812217712, 0.028871877118945122, -0.01277825329452753, 0.0038006603717803955, -0.03164779767394066, -0.0523294135928154, -0.002039276994764805, 0.1232447549700737, 0.031608909368515015, -0.0877201035618782, 0.12845391035079956, -0.07970995455980301, -0.0029030072037130594, -0.001653185929171741, -0.1689184606075287, 0.0430656298995018, -0.03930375352501869, -0.01851559244096279, 0.03423463925719261, -0.02886294014751911, 0.020157504826784134, -0.07065223157405853, 0.03215770423412323, -0.06222305819392204, -0.018498990684747696, -0.009796415455639362, 0.04155392572283745, -0.002960398094728589, -0.0128460843116045, -0.019273709505796432, 0.12814131379127502, -0.05862490087747574, 0.11619218438863754, 0.10285694152116776, 0.06722218543291092, 0.052140697836875916, -0.011037307791411877, 0.05021069943904877, 0.15244241058826447, 0.1197555810213089, 0.07879408448934555, -0.1813288778066635, -0.06116184964776039, -0.05752303823828697, 0.115383081138134, -0.10162154585123062, 0.18051643669605255, -0.08768872171640396, -0.037351109087467194, 0.09813068062067032, 0.004064843989908695, -0.0012650445569306612, 0.011343495920300484, 0.09144589304924011, -0.21555845439434052, 0.0654221922159195, 0.16083593666553497, 0.06653697788715363, 0.02611086145043373, -0.11934345960617065, -0.06227707862854004, 0.11129095405340195, 0.005202972795814276, -0.024564582854509354, -0.008695562370121479, 0.09001260995864868, 0.12854140996932983, 0.019262488931417465, 0.14729833602905273, 0.006830462254583836, -0.008968707174062729, -0.11212065815925598, 0.04434514045715332, -0.028821125626564026, -0.11570794135332108, 0.0013651011977344751, 0.13739271461963654, 0.09402935951948166, -0.0448475144803524, 0.1081065759062767, -0.1730237454175949, 0.04965773969888687, -0.18328984081745148, -0.05182405188679695, -0.04408147931098938, 0.022233938798308372, -0.0930662751197815, -0.13717280328273773, -0.17234693467617035, 1.5735049830672058e-32, -0.05057411640882492, -0.1350879669189453, 0.04823476821184158, -0.16520629823207855, -0.0031278361566364765, -0.07075579464435577, -0.007322856690734625, 0.03319738805294037, -0.03700404614210129, -0.07772421836853027, -0.1768771857023239, -0.02950751781463623, -0.1137479692697525, 0.09630965441465378, 0.049867548048496246, -0.021137546747922897, -0.08539536595344543, 0.055820245295763016, 0.15823015570640564, 0.11787888407707214, 0.20065702497959137, -0.11073857545852661, -0.05667883902788162, -0.054196953773498535, -0.1526268571615219, -0.02247811108827591, -0.019352253526449203, -0.004972937051206827, -0.02550094947218895, 0.008304744958877563, -0.19290412962436676, -0.012899058870971203, 0.08154191821813583, -0.03783775120973587, -0.14024323225021362, -0.11885663866996765, 0.047143302857875824, 0.11581986397504807, -0.07050240784883499, -0.08040297031402588, 0.02699611894786358, 0.13279050588607788, 0.02761184051632881, -0.06678573787212372, -0.06532805413007736, 0.016983231529593468, -0.07106813043355942, 0.10440250486135483, -0.017394796013832092, 0.14243365824222565, 0.0408591702580452, -0.08991116285324097, -0.016000930219888687, -0.09736768901348114, -0.11340861022472382, 0.0418570451438427, 0.15800140798091888, 0.12791620194911957, 0.10988634824752808, -0.03451339900493622, 0.03923192620277405, 0.08228258043527603, 0.027916712686419487, 0.11856158822774887, 0.04714919626712799, 0.06667160242795944, 0.0628770962357521, -0.028704499825835228, -0.04303300380706787, -0.001346756238490343, -0.14499501883983612, 0.12043701857328415, -0.09951639175415039, -0.11566183716058731, 0.14820225536823273, -0.13017304241657257, 0.0018496245611459017, -0.027174975723028183, -0.19988924264907837, 0.07819796353578568, -0.028092505410313606, 0.2504485845565796, -0.09403897821903229, -0.18279697000980377, -0.09656128287315369, 0.07566801458597183, 0.031401559710502625, -0.16781401634216309, -0.11431068927049637, -0.0040416838601231575, 0.022202426567673683, 0.019893577322363853, -0.005120125133544207, 0.0689743310213089, -0.10925436019897461, -1.2552869073561044e-32, 0.08821527659893036, 0.21589945256710052, 0.09347402304410934, -0.007072699721902609, 0.09884391725063324, 0.05828094482421875, 0.07735973596572876, 0.07784536480903625, 0.03201301023364067, -0.1067914068698883, 0.10209085792303085, -0.15607140958309174, -0.1457304060459137, -0.06413090229034424, -0.0014569393824785948, -0.12995819747447968, -0.03679301217198372, 0.03214282914996147, -0.0019059081096202135, 0.0203009694814682, -0.08908365666866302, 0.27346551418304443, -0.1028842031955719, 0.029300939291715622, -0.19519555568695068, 0.09015662968158722, -0.04739861935377121, 0.1542467325925827, 0.03355007618665695, -0.09184934198856354, -0.05099501833319664, 0.05422308295965195, -0.1587899625301361, -0.021911494433879852, 0.02616085298359394, 0.03978864476084709, 0.1077486127614975, -0.07853314280509949, -0.07451535761356354, 0.14058029651641846, 0.17479775846004486, 0.1158340722322464, -0.1739509403705597, 0.06443443894386292, -0.007543179672211409, -0.08201120048761368, 0.04435087367892265, -0.014468303881585598, 0.007690889295190573, -0.04662443324923515, 0.052417345345020294, -0.07647906988859177, -0.16451658308506012, 0.04275115579366684, 0.08236173540353775, 0.10747698694467545, -0.04652472585439682, -0.016117088496685028, 0.00843642745167017, -0.03231092169880867, -0.1187596246600151, -0.12813813984394073, -0.11743269115686417, -0.13688330352306366, -0.005489293485879898, 0.08047998696565628, -0.1262633502483368, 0.026116590946912766, 0.03895062953233719, 0.211453378200531, -0.1628720611333847, 0.07181710004806519, 0.16589297354221344, 0.09281588345766068, -0.03413331136107445, -0.017611145973205566, 0.04930718615651131, -0.012041394598782063, 0.06503478437662125, -0.017612865194678307, -0.15261760354042053, 0.02311311475932598, 0.044640738517045975, 0.10820090025663376, 0.15037058293819427, 0.1980123519897461, 0.07482767850160599, 0.04943336546421051, 0.12790662050247192, -0.0173999834805727, 0.011538822203874588, -0.020366981625556946, 0.1379643678665161, 0.18088029325008392, 0.006151389796286821, -1.0042727893733172e-07, 0.0007804031483829021, 0.08086295425891876, 0.02932664565742016, 0.10346922278404236, 0.050657812505960464, -0.01049773022532463, 0.002022143453359604, 0.06750268489122391, 0.03574735298752785, -0.11757911741733551, 0.04960887134075165, 0.00044327927753329277, -0.09652413427829742, -0.006201832555234432, -0.12979990243911743, 0.11548791080713272, -0.05957261100411415, -0.006712515372782946, 0.03229152411222458, -0.03396141156554222, -0.06854197382926941, -0.1498449295759201, -0.004487236496061087, 0.02925749123096466, 0.006228335201740265, -0.05486997216939926, -0.007307589985430241, 0.011963008902966976, 0.05978872627019882, 0.01248947624117136, 0.00548166548833251, -0.11452082544565201, 0.0958036556839943, 0.10853658616542816, 0.09268037974834442, 0.08754606544971466, 0.03248250111937523, 0.05546678230166435, 0.012702256441116333, 0.07571452856063843, -0.17173080146312714, 0.05897829681634903, 0.013258842751383781, -0.0712801143527031, 0.11567826569080353, -0.040386658161878586, 0.04368017241358757, 0.041026465594768524, 0.05632220581173897, -0.03707865998148918, 0.007362160831689835, -0.02005123905837536, -0.14238932728767395, 0.07859351485967636, 0.09470850229263306, -0.13966995477676392, 0.015973340719938278, -0.056150391697883606, -0.02136433683335781, 0.11282394826412201, -0.011343300342559814, -0.10915085673332214, -0.08680181950330734, -0.03457440808415413], metadata={'source': 'AAAMLP-569to.pdf', 'page': 201}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 202     # a list with image locations     images = [       os.path.join(data_path, \"train_png\", i + \".png\") for i in images     ]      # binary targets numpy array     targets = df.target.values      # fetch out model, we will try both pretrained     # and non-pretrained weights     model = get_model(pretrained=True)      # move model to device     model.to(device)      # mean and std values of RGB channels for imagenet dataset     # we use these pre-calculated values when we use weights     # from imagenet.      # when we do not use imagenet weights, we use the mean and     # standard deviation values of the original dataset     # please note that this is a separate calculation     mean = (0.485, 0.456, 0.406)     std = (0.229, 0.224, 0.225)      # albumentations is an image augmentation library     # that allows you to do many different types of image     # augmentations. here, i am using only normalization     # notice always_apply=True. we always want to apply     # normalization     aug = albumentations.Compose(         [             albumentations.Normalize(                 mean, std, max_pixel_value=255.0, always_apply=True             )         ]     )      # instead of using kfold, i am using train_test_split     # with a fixed random state     train_images, valid_images, train_targets, valid_targets = train_test_split(         images, targets, stratify=targets, random_state=42     )      # fetch the ClassificationDataset class     train_dataset = dataset.ClassificationDataset(         image_paths=train_images,'),\n",
       " VectorParams(vector=[-0.07544026523828506, -0.10362513363361359, -0.008142796345055103, 0.08942501246929169, 0.13015343248844147, -0.10216314345598221, -0.005782323889434338, 0.0860951766371727, -0.1624651402235031, -0.12230037152767181, 0.000629412941634655, -0.18320664763450623, -0.10139219462871552, -0.059281881898641586, -0.09343422949314117, 0.020609797909855843, -0.059014685451984406, -0.0821344256401062, -0.16200977563858032, -0.09499292820692062, 0.08371539413928986, 0.03521939367055893, 0.04548092558979988, 0.08857914060354233, 0.045572467148303986, -0.04603835940361023, -0.029829228296875954, 0.053368207067251205, 0.016275906935334206, -0.08686315268278122, 0.05063551664352417, -0.011738648638129234, -0.02688748575747013, 0.04120837152004242, 0.0314975380897522, -0.02343330904841423, -0.10953184217214584, -0.07997681945562363, -0.05024660378694534, 0.06813574582338333, 0.009870313107967377, -0.00695005850866437, -0.03605936840176582, -0.006615832448005676, 0.06463341414928436, 0.13339298963546753, -0.016002610325813293, -0.04266428202390671, 0.013435362838208675, -0.0909680649638176, 0.02055269293487072, 0.021992424502968788, -0.05671921744942665, 0.01831001043319702, -0.06034630537033081, -0.04860175400972366, 0.007334859576076269, -0.11641073226928711, 0.06758369505405426, -0.10296514630317688, -0.032093923538923264, -0.036668140441179276, -0.016924776136875153, -0.05926425755023956, -0.045537449419498444, -0.03175032138824463, -0.031069697812199593, -0.05635925382375717, 0.08673599362373352, 0.07148627936840057, 0.10006619244813919, 0.07145419716835022, -0.0216817669570446, 0.1972275972366333, 0.01063345093280077, 0.017607031390070915, 0.12356460094451904, 0.03247545287013054, -0.016569867730140686, -0.18261227011680603, -0.13868999481201172, -0.09773159772157669, 0.07151421904563904, -0.0017669707303866744, 0.1573089212179184, -0.10541681200265884, 0.10254371166229248, -0.007511431351304054, 0.09864865988492966, 0.01739022321999073, 0.027117781341075897, 0.037914618849754333, -0.10628526657819748, 0.03866586089134216, 0.14674340188503265, 0.05060809850692749, 0.14604900777339935, 0.03448236361145973, -0.19785402715206146, 0.09830719232559204, -0.04135590046644211, -0.015754224732518196, -0.048015300184488297, 0.12372472882270813, 0.07312986999750137, 0.11624222248792648, 0.09368127584457397, 0.07948914915323257, 0.0363241508603096, -0.08121727406978607, 0.1150360107421875, 0.027717923745512962, -0.011099964380264282, -0.06681652367115021, 0.07652412354946136, 0.02326922118663788, -0.16121543943881989, 0.08829673379659653, -0.1102367714047432, 0.22137485444545746, -0.12159791588783264, 0.06949659436941147, 0.006795715074986219, 0.09891863167285919, -0.048366978764534, -0.12493138760328293, -0.1272123008966446, 1.6776947779155454e-32, -0.09445299953222275, -0.05474766716361046, -0.08836144953966141, -0.19836004078388214, -0.031071050092577934, 0.020665744319558144, 0.015859056264162064, -0.005427228286862373, -0.09481124579906464, -0.011861074715852737, -0.17536728084087372, 0.01101664174348116, -0.028319954872131348, 0.07197272777557373, 0.010332037694752216, -0.025051631033420563, 0.07571075856685638, 0.04877414554357529, -0.031484268605709076, 0.01655605249106884, 0.2096678912639618, -0.04544168710708618, -0.09579738229513168, -0.14792853593826294, -0.11853586137294769, 0.14913325011730194, -0.006900747772306204, -0.04044405370950699, -0.0912189856171608, 0.054456766694784164, -0.17182724177837372, 0.00682053854689002, 0.02234048582613468, 0.010335485450923443, -0.024192512035369873, -0.08116581290960312, 0.12071532756090164, 0.04816292226314545, -0.013335677795112133, -0.0992741733789444, -0.016854098066687584, 0.10753007233142853, 0.01542028971016407, -0.12682442367076874, -0.05305144190788269, -0.10690188407897949, -0.03675765171647072, 0.1583748161792755, 0.014643319882452488, 0.07832790911197662, -0.08332417160272598, -0.12349699437618256, 0.03305361419916153, -0.031725361943244934, -0.0727405995130539, 0.01831880584359169, 0.06527605652809143, 0.08889596909284592, 0.10874376446008682, -0.01960797980427742, 0.14663416147232056, 0.05380505695939064, -0.10319365561008453, 0.03819751366972923, 0.05102929472923279, 0.016840346157550812, 0.027748623862862587, -0.04771967604756355, -0.004761036019772291, 0.07132363319396973, -0.16177727282047272, 0.015103001147508621, 0.06262355297803879, -0.08296072483062744, 0.12476542592048645, -0.18488125503063202, 0.09563633799552917, 0.0032520766835659742, -0.18935531377792358, 0.08411841839551926, -0.11103063076734543, 0.12319735437631607, -0.08461926877498627, -0.21338216960430145, -0.07134048640727997, -0.04499070346355438, 0.054229605942964554, -0.03649478778243065, -0.1424092799425125, -0.017938774079084396, -0.07267779111862183, -0.10456564277410507, 0.07602924853563309, 0.009908156469464302, -0.14083603024482727, -1.667181009504997e-32, 0.047780562192201614, 0.1298956423997879, 0.08001206815242767, 0.07285980880260468, 0.04925644025206566, 0.08735514432191849, 0.05155869200825691, 0.04188288375735283, -0.10691269487142563, -0.08226820081472397, 0.09094589948654175, -0.1294488161802292, -0.05020126327872276, -0.03226104751229286, 0.07686296850442886, -0.04539358243346214, -0.07936304062604904, 0.08793123066425323, 0.06103501841425896, 0.0424010306596756, -0.0020995570812374353, 0.2314354032278061, -0.19865670800209045, 0.015046054497361183, -0.1234767884016037, 0.004038470331579447, -0.025341404601931572, 0.14774110913276672, -0.019034678116440773, -0.08465468883514404, -0.020465288311243057, 0.12696298956871033, -0.18884994089603424, 0.0030895366799086332, -0.003664191346615553, 0.09602279961109161, 0.037300001829862595, 0.02064048871397972, -0.11447270214557648, 0.18897345662117004, 0.17524537444114685, 0.10956009477376938, -0.15301428735256195, 0.09791816771030426, -0.09468858689069748, 0.01386606227606535, -0.0038187457248568535, 0.07993413507938385, 0.0016091106226667762, -0.005902833305299282, 0.0892816111445427, -0.0957978293299675, -0.14320728182792664, 0.04358528181910515, 0.007145906798541546, -0.030223309993743896, 0.008695547468960285, -0.029716307297348976, -0.05789479240775108, 0.05035736784338951, -0.004636438097804785, -0.05125616863369942, 0.042029645293951035, -0.08983788639307022, 0.030531780794262886, 0.06270690262317657, -0.148692324757576, 0.14316530525684357, 0.046934422105550766, 0.1596820205450058, -0.0903775691986084, 0.08513546735048294, 0.058333124965429306, 0.009212532080709934, -0.05719815567135811, 0.10453132539987564, -0.03223245218396187, 0.017160769551992416, 0.07914126664400101, -0.09309695661067963, -0.1285957545042038, -0.019698455929756165, 0.04357041046023369, 0.19352313876152039, 0.009434524923563004, 0.13903148472309113, 0.10473757237195969, 0.16413836181163788, 0.04425201937556267, -0.04379195347428322, 0.05925677344202995, -0.02665332332253456, 0.15050600469112396, 0.1561715453863144, -0.008628826588392258, -1.0111282477964778e-07, -0.028257163241505623, 0.03855237364768982, 0.009597545489668846, 0.14075613021850586, 0.08524077385663986, 0.04045826569199562, -0.031231334432959557, 0.08043055981397629, -0.09848076105117798, -0.029318369925022125, 0.12701717019081116, -0.014932657591998577, -0.123803049325943, -0.02294895425438881, 0.04980333894491196, 0.05471503734588623, -0.07340475916862488, 0.11209580302238464, -0.010364146903157234, -0.05167931318283081, -0.008750924840569496, -0.06520787626504898, -0.00352307572029531, -0.0974818617105484, 0.015422779135406017, -0.12470025569200516, 0.02114906534552574, 0.06914917379617691, -0.08262348920106888, 0.015922674909234047, -0.01913992129266262, -0.07996592670679092, 0.10460668057203293, -0.013363780453801155, 0.06438368558883667, 0.128234401345253, -0.028414353728294373, 0.08456961810588837, -0.046749234199523926, 0.039247144013643265, -0.10220498591661453, 0.1445682793855667, -0.05450885742902756, -0.06385177373886108, 0.06626392900943756, -0.027866898104548454, -0.0007502216612920165, -0.09619209915399551, 0.06277558207511902, -0.03247924521565437, 0.003341573290526867, -0.003787087043747306, -0.09673119336366653, 0.02401946485042572, 0.057678915560245514, -0.11904642730951309, -0.10268685221672058, -0.1197158694267273, -0.0589776374399662, 0.052580539137125015, 0.12542644143104553, -0.07131867110729218, -0.08618918061256409, -0.010330460965633392], metadata={'source': 'AAAMLP-569to.pdf', 'page': 202}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 203         targets=train_targets,         resize=(227, 227),         augmentations=aug,     )      # torch dataloader creates batches of data     # from classification dataset class     train_loader = torch.utils.data.DataLoader(         train_dataset, batch_size=16, shuffle=True, num_workers=4     )      # same for validation data     valid_dataset = dataset.ClassificationDataset(         image_paths=valid_images,         targets=valid_targets,         resize=(227, 227),         augmentations=aug,     )      valid_loader = torch.utils.data.DataLoader(         valid_dataset, batch_size=16, shuffle=False, num_workers=4     )      # simple Adam optimizer     optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)      # train and print auc score for all epochs     for epoch in range(epochs):         engine.train(train_loader, model, optimizer, device=device)         predictions, valid_targets = engine.evaluate(             valid_loader, model, device=device         )         roc_auc = metrics.roc_auc_score(valid_targets, predictions)         print(             f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\"         ) ═════════════════════════════════════════════════════════════════════════  Let’s train it without pretrained weights:  ═════════════════════════════════════════════════════════════════════════ Epoch=0, Valid ROC AUC=0.5737161981475328 Epoch=1, Valid ROC AUC=0.5362868001588292 Epoch=2, Valid ROC AUC=0.6163448214387008 Epoch=3, Valid ROC AUC=0.6119219143780944 Epoch=4, Valid ROC AUC=0.6229718888519726 Epoch=5, Valid ROC AUC=0.5983014999635341'),\n",
       " VectorParams(vector=[-0.05773008242249489, -0.1902492642402649, -0.026154782623052597, 0.12423491477966309, 0.16396498680114746, -0.14879998564720154, -0.039851535111665726, 0.1077495664358139, -0.025199145078659058, -0.05386773496866226, 0.042522940784692764, -0.08575181663036346, -0.11506976187229156, 0.015088273212313652, -0.15393197536468506, -0.029299326241016388, -0.03978181257843971, -0.04780677333474159, -0.19182085990905762, -0.013278285041451454, 0.13064777851104736, 0.04853518307209015, -0.047073736786842346, 0.12989240884780884, -0.003954851999878883, -0.154144287109375, -0.05842690169811249, 0.09547434747219086, -0.03397076204419136, -0.05573072284460068, -0.0644228532910347, 0.03760627284646034, 0.08176543563604355, 0.058452948927879333, -0.0424019880592823, -0.049369923770427704, -0.047997862100601196, -0.10429482161998749, 0.014870022423565388, -0.02111940085887909, -0.07235237956047058, 0.018907327204942703, 0.044171370565891266, -0.0042895302176475525, 0.07889797538518906, 0.09457042813301086, -0.07400937378406525, 0.008698290213942528, 0.05836164206266403, -0.15653900802135468, 0.011520497500896454, -0.025302529335021973, -0.1497924029827118, 0.07487189769744873, -0.06126448139548302, 0.05844637751579285, -0.022320501506328583, -0.19749243557453156, 0.08229118585586548, -0.10355488955974579, -0.04023933410644531, -0.04500650614500046, -0.0891016274690628, -0.03332052007317543, 0.12981732189655304, -0.06177026033401489, -0.0741908997297287, -0.13768309354782104, 0.08728039264678955, 0.0876479223370552, 0.07669170200824738, 0.03912566974759102, 0.005937805864959955, 0.08431555330753326, 0.027311427518725395, 0.04932558536529541, 0.187602698802948, 0.062258996069431305, -0.02047286182641983, -0.16046449542045593, -0.0500306561589241, 0.019409283995628357, 0.08856256306171417, -0.027936942875385284, 0.0992526188492775, -0.1669517159461975, 0.06126965582370758, 0.042351581156253815, 0.16213935613632202, -0.03623204678297043, 0.0196856502443552, 0.07328077405691147, -0.0417216420173645, 0.08599454164505005, 0.0633852630853653, 0.13755691051483154, 0.19069677591323853, 0.021010562777519226, -0.1250089854001999, 0.0855155736207962, -0.003911621868610382, -0.05355231463909149, 0.01427709311246872, 0.04860604554414749, 0.12813295423984528, 0.09248572587966919, 0.1494913101196289, 0.00314130331389606, 0.027697117999196053, -0.060217827558517456, 0.10916373878717422, 0.03702850639820099, 0.01988600566983223, -0.004908325150609016, 0.11732655763626099, 0.024977924302220345, -0.08535930514335632, 0.05986696481704712, -0.13962703943252563, 0.21254920959472656, -0.14533880352973938, -0.0032951324246823788, 0.09850295633077621, -0.00029960833489894867, -0.02555973455309868, -0.1462285816669464, -0.16332855820655823, 1.5594867721232685e-32, -0.12157544493675232, -0.07976429164409637, -0.05882759392261505, -0.15892700850963593, 0.05922461301088333, -0.007218272425234318, 0.06973443925380707, -0.01996440440416336, -0.1195278987288475, 0.011209802702069283, -0.2588789463043213, 0.08526715636253357, -0.09837885946035385, 0.07458896934986115, -0.01510242372751236, -0.0035875688772648573, 0.041019827127456665, 0.0639914870262146, -0.0376073382794857, 0.042310409247875214, 0.19357916712760925, -0.07948927581310272, -0.06003011018037796, -0.1776847094297409, 0.0583232045173645, 0.06396645307540894, -0.02461913414299488, -0.017287906259298325, -0.14810670912265778, 0.02458816021680832, -0.1626701056957245, -0.04239682853221893, 0.036007724702358246, -0.05861232802271843, -0.04745033383369446, -0.0411890484392643, 0.18843498826026917, 0.006112683564424515, 0.047542694956064224, -0.14370492100715637, -0.044309817254543304, 0.15277916193008423, -0.047152720391750336, -0.1374417245388031, 0.02358696050941944, -0.10404106974601746, -0.05855894088745117, 0.17266255617141724, -0.16548967361450195, 0.10072087496519089, 0.05473998188972473, -0.1674351692199707, -0.039149582386016846, -0.03271406143903732, -0.11031074076890945, -0.01745748519897461, 0.12505483627319336, 0.061777953058481216, 0.11737613379955292, 0.07507267594337463, 0.16603949666023254, -0.05156790837645531, -0.12010043114423752, 0.08045682311058044, 0.12335392832756042, 0.04346424713730812, 0.07289500534534454, -0.06559174507856369, -0.019276265054941177, 0.07655830681324005, -0.2806486189365387, -0.042049698531627655, 0.009929569438099861, -0.10600891709327698, 0.0899224802851677, -0.1320231556892395, 0.080284982919693, -0.027671748772263527, -0.1381780505180359, 0.158842995762825, -0.1251325011253357, 0.29933035373687744, -0.13236717879772186, -0.15879926085472107, -0.14696919918060303, 0.03063219040632248, 0.0990428775548935, -0.09113490581512451, -0.1279563158750534, -0.030001144856214523, -0.017976082861423492, -0.14941856265068054, 0.08888330310583115, 0.04354939982295036, -0.04169735684990883, -1.5929935039094885e-32, 0.05908825993537903, 0.062464483082294464, 0.10280610620975494, 0.1176762580871582, 0.036702606827020645, 0.03931287303566933, 0.07094082236289978, 0.007821832783520222, -0.12725357711315155, -0.25259801745414734, 0.20692190527915955, -0.16055139899253845, -0.06619065999984741, -0.015221540816128254, 0.22034327685832977, -0.011646810919046402, -0.07347310334444046, 0.037512436509132385, 0.09250105917453766, 0.04938202723860741, 0.06482398509979248, 0.190036803483963, -0.2509813904762268, 0.018155166879296303, -0.14555701613426208, 0.005111984442919493, -0.03944004327058792, 0.14442665874958038, 0.007102726027369499, -0.12958085536956787, -0.10536442697048187, 0.0840332955121994, -0.08450385183095932, 0.12635715305805206, -0.07956374436616898, 0.15593144297599792, 0.03408370912075043, -0.06917084753513336, -0.07150135934352875, 0.2213326394557953, 0.21290528774261475, 0.13794010877609253, -0.2066575288772583, 0.07079768180847168, -0.14054428040981293, -0.0008890014141798019, -0.01642497628927231, -0.021467193961143494, 0.14673711359500885, -0.11752927303314209, 0.1796187311410904, -0.17212393879890442, -0.17303971946239471, 0.1524118334054947, -0.0350763164460659, 0.026372194290161133, -0.05763548985123634, 0.018850307911634445, -0.0015118597075343132, -0.01610446721315384, -0.03424292057752609, -0.0673666000366211, 0.014756242744624615, -0.06173676624894142, 0.03068358078598976, 0.08268837630748749, -0.163295179605484, 0.041294779628515244, 0.018249012529850006, 0.08036290109157562, -0.0928286537528038, 0.023790523409843445, 0.06254153698682785, -0.020235002040863037, -0.07806156575679779, 0.018209820613265038, -0.006799394730478525, -0.029553689062595367, -0.0034150949213653803, -0.06848710775375366, -0.2872205078601837, 0.0017069699242711067, 0.011884249746799469, 0.21788090467453003, -0.06446442008018494, 0.1256944239139557, 0.11034680902957916, 0.06130717694759369, 0.05877208709716797, -0.03882035240530968, 0.022681137546896935, 0.049200356006622314, 0.2263283133506775, 0.1022769883275032, -0.04819757863879204, -1.0163326180645527e-07, -0.008543157950043678, 0.031037740409374237, 0.010663519613444805, 0.02832510881125927, 0.037057243287563324, 0.09958859533071518, -0.06879304349422455, 0.0682448148727417, -0.10457760095596313, -0.026855573058128357, 0.17203110456466675, 0.04360752925276756, -0.1138748973608017, -0.03641537204384804, -0.04322465881705284, 0.19216388463974, -0.07407955080270767, 0.058245934545993805, 0.04686112701892853, -0.0989268347620964, 0.021608954295516014, -0.028550168499350548, 0.06626681238412857, -0.011068991385400295, -0.053098347038030624, -0.10291987657546997, -0.019283656030893326, 0.05030956119298935, -0.11376869678497314, 0.07265298068523407, -0.029836181551218033, -0.09533281624317169, 0.09521457552909851, 0.005351387429982424, 0.08707182109355927, 0.20137430727481842, -0.05880671739578247, 0.007325371727347374, -0.03747660666704178, 0.04146382957696915, -0.026707947254180908, 0.09472153335809708, -0.17722873389720917, -0.0597417838871479, 0.1223171129822731, -0.06716243922710419, -0.004992012400180101, -0.0028091557323932648, 0.09852789342403412, -0.12465513497591019, 0.003264330793172121, 0.021452710032463074, -0.09576620161533356, -0.00686680618673563, -0.05274388939142227, 0.018624840304255486, -0.05937913432717323, -0.09511996060609818, -0.17541572451591492, 0.09679506719112396, 0.10174421221017838, -0.11977902054786682, 0.01919364742934704, -0.018551727756857872], metadata={'source': 'AAAMLP-569to.pdf', 'page': 203}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 204 Epoch=6, Valid ROC AUC=0.5523236874306134 Epoch=7, Valid ROC AUC=0.4717721611306046 Epoch=8, Valid ROC AUC=0.6473408263980617 Epoch=9, Valid ROC AUC=0.6639862888260415 ═════════════════════════════════════════════════════════════════════════  This AUC is around 0.66 which is even lower than our random forest model. What happens when we use pretrained weights?  ═════════════════════════════════════════════════════════════════════════ Epoch=0, Valid ROC AUC=0.5730387429803165 Epoch=1, Valid ROC AUC=0.5319813942934937 Epoch=2, Valid ROC AUC=0.627111577514323 Epoch=3, Valid ROC AUC=0.6819736959393209 Epoch=4, Valid ROC AUC=0.5747117168950512 Epoch=5, Valid ROC AUC=0.5994619255609669 Epoch=6, Valid ROC AUC=0.5080889443530546 Epoch=7, Valid ROC AUC=0.6323792776512727 Epoch=8, Valid ROC AUC=0.6685753182661686 Epoch=9, Valid ROC AUC=0.6861802387300147 ═════════════════════════════════════════════════════════════════════════  The AUC is much better now. However, it is still lower. The good thing about pretrained models is that we can try many different models easily. Let’s try resnet18 with pretrained weights.  ═════════════════════════════════════════════════════════════════════════ # model.py import torch.nn as nn import pretrainedmodels   def get_model(pretrained):     if pretrained:         model = pretrainedmodels.__dict__[\"resnet18\"](             pretrained=\\'imagenet\\'         )     else:         model = pretrainedmodels.__dict__[\"resnet18\"](             pretrained=None         )     # print the model here to know whats going on.     model.last_linear = nn.Sequential(         nn.BatchNorm1d(512),         nn.Dropout(p=0.25),         nn.Linear(in_features=512, out_features=2048),'),\n",
       " VectorParams(vector=[-0.04125703498721123, -0.12485706806182861, 0.015414711087942123, 0.02243734337389469, 0.0534784197807312, -0.05788629502058029, -0.07049237191677094, 0.07186275720596313, -0.04067886620759964, -0.09684494137763977, -0.1342473328113556, -0.02518627606332302, -0.06081277132034302, 0.04040180891752243, -0.13153159618377686, -0.036476973444223404, 0.04295963793992996, 0.10788329690694809, -0.18399164080619812, -0.00022338330745697021, 0.11622916907072067, 0.04474654048681259, 0.010937299579381943, -0.0768398717045784, 0.003603897523134947, -0.05433446168899536, -0.0003198786871507764, 0.02621118351817131, -0.06913065910339355, -0.11899395287036896, 0.12495529651641846, 0.002700667828321457, 0.00924359168857336, 0.058176189661026, -0.03192519769072533, 0.05216703563928604, -0.03430256247520447, -0.009538797661662102, 0.04570847004652023, -0.013135327957570553, -0.019374310970306396, 0.03824611380696297, 0.0037112003192305565, 0.002455546520650387, 0.18272191286087036, 0.08081749826669693, -0.07303067296743393, -0.004549327306449413, 0.1209724098443985, -0.04876250773668289, -0.025134362280368805, 0.03417607396841049, -0.09097768366336823, 0.0906587690114975, -0.003665383905172348, 0.08171332627534866, -0.12843403220176697, -0.07066790014505386, -0.011693842709064484, -0.05913364887237549, 0.07443027198314667, -0.025683481246232986, -0.01577695459127426, -0.03899785131216049, 0.010130684822797775, -0.004507146775722504, -0.008268376812338829, -0.1216978058218956, 0.0966416746377945, 0.030125031247735023, 0.2234424203634262, 0.08177630603313446, -0.03303616866469383, 0.03570591285824776, -0.02210504561662674, 0.06875386834144592, 0.2079942524433136, 0.0005105237942188978, 0.029416371136903763, -0.053094930946826935, 0.08037345111370087, 0.07023236155509949, 0.029843833297491074, -0.044163040816783905, 0.1246974915266037, -0.11895859241485596, 0.051559820771217346, -0.06912680715322495, 0.019544754177331924, -0.04805884510278702, 0.05685420334339142, 0.07218001782894135, -0.0039072055369615555, -0.07706647366285324, 0.14257587492465973, 0.00831146351993084, 0.04001148045063019, -0.10248751938343048, -0.1523711085319519, 0.14157778024673462, -0.04814079403877258, -0.044889919459819794, 0.003324315184727311, -0.07057192176580429, 0.06731488555669785, 0.11484184861183167, 0.17138633131980896, 0.0863146036863327, 0.06058761849999428, -0.09537142515182495, 0.03529602289199829, 0.010211460292339325, -0.06600164622068405, -0.05466813966631889, 0.1257457584142685, 0.07844506204128265, -0.09495426714420319, -0.013508910313248634, -0.05057593435049057, 0.131813645362854, -0.15659795701503754, 0.09722939133644104, -0.015243273228406906, -0.04844176024198532, 0.05168551206588745, 0.006437186151742935, -0.18574610352516174, 1.6966233226364552e-32, -0.20694312453269958, 0.03682282567024231, -0.05442729592323303, -0.27061429619789124, 0.04166803136467934, -0.03989265114068985, 0.0828721672296524, 0.09613309800624847, -0.05958512797951698, -0.055157896131277084, -0.24362018704414368, 0.00426836684346199, -0.08411162346601486, 0.12031111866235733, 0.026820426806807518, -0.10579228401184082, 0.08762089163064957, 0.042763739824295044, -0.02699962817132473, 0.0462665818631649, 0.04424203932285309, -0.13938859105110168, 0.006739174947142601, -0.10753984749317169, -0.0025709783658385277, -0.00514344684779644, 0.07344295084476471, 0.05824398249387741, -0.04498511552810669, -0.021505968645215034, -0.08001258224248886, -0.035820264369249344, -0.030164934694767, 0.02769305184483528, -0.018794776871800423, -0.09030372649431229, 0.009748205542564392, 0.09629799425601959, 0.04925753176212311, -0.0098983533680439, -0.08032484352588654, 0.12318433821201324, -0.06200547516345978, -0.07176418602466583, -0.029510581865906715, -0.004414642229676247, 0.024452392011880875, 0.06862442940473557, -0.041451595723629, 0.04053599014878273, 0.08679720014333725, -0.07029719650745392, -0.03470343351364136, -0.07124349474906921, -0.07588749378919601, -0.0750311017036438, 0.08641519397497177, 0.11575513333082199, 0.07200787216424942, 0.08395059406757355, 0.04318540543317795, -0.13772331178188324, -0.06819619238376617, 0.04169362038373947, 0.0965118408203125, -0.021433576941490173, 0.03961963206529617, 0.02314719557762146, 0.03163881599903107, 0.030910098925232887, -0.15253946185112, 0.1123988926410675, 0.15950699150562286, -0.10525021702051163, 0.09550131857395172, -0.10888920724391937, 0.06187440827488899, 0.014452737756073475, -0.12941941618919373, 0.12065475434064865, -0.08951929956674576, 0.25886306166648865, -0.030561499297618866, -0.1422046720981598, -0.051434002816677094, 0.07567253708839417, 0.1260405033826828, -0.03354134410619736, -0.00944546703249216, 0.04704969748854637, -0.045773088932037354, -0.008561666123569012, 0.007735884748399258, 0.027968712151050568, -0.027653686702251434, -1.1275569565117854e-32, 0.02023104950785637, 0.040684185922145844, -0.05091297999024391, 0.10538619756698608, -0.01659747213125229, 0.07751845568418503, 0.0272036325186491, 0.026449335739016533, -0.17145571112632751, -0.1671622395515442, 0.14293447136878967, -0.13906002044677734, 0.04231651872396469, -0.1051083356142044, 0.03630213439464569, -0.08176656067371368, -0.08960717916488647, -0.02968781255185604, 0.11772220581769943, 0.027147160843014717, 0.06455045193433762, 0.24332794547080994, -0.13557812571525574, -0.039086200296878815, -0.1291145533323288, -0.01892617717385292, -0.0773344486951828, 0.1967611163854599, 0.04738885909318924, -0.008834920823574066, -0.10924990475177765, 0.06628559529781342, -0.1576668620109558, -0.0048989709466695786, 0.11598227918148041, 0.1624620258808136, -0.024745717644691467, -0.058951281011104584, -0.08738639950752258, 0.19513064622879028, 0.11914347857236862, 0.11182460188865662, -0.11118889600038528, 0.05507238209247589, -0.0319373719394207, 0.043989259749650955, 0.027509566396474838, -0.03596781566739082, 0.018148208037018776, 0.0456266850233078, 0.091188445687294, -0.1039276123046875, -0.22231924533843994, 0.07277485728263855, 0.039421197026968, 0.017412355169653893, -0.053808994591236115, 0.012110940180718899, 0.013568557798862457, 0.01830458454787731, -0.05328231304883957, -0.11944741755723953, -0.089723140001297, -0.0459616482257843, 0.1258983314037323, 0.11638841778039932, -0.09078843891620636, 0.08915746957063675, -0.03962792083621025, 0.16230826079845428, -0.131832554936409, -0.07169090211391449, 0.1476905792951584, 0.13181425631046295, -0.06270093470811844, -0.0515088215470314, 0.015189407393336296, 0.05240236595273018, -0.02697000466287136, -0.05768095701932907, -0.09158830344676971, -0.030022960156202316, -0.13510382175445557, 0.1871052384376526, 0.06061868742108345, 0.11977807432413101, 0.031291112303733826, 0.00825478509068489, 0.08076271414756775, 0.058689381927251816, -0.012657650746405125, 0.013695301488041878, 0.1416507065296173, 0.06910208612680435, -0.049956437200307846, -1.0036846731509286e-07, 0.017354892566800117, -0.010731849819421768, 0.037945784628391266, 0.02746419981122017, 0.12025265395641327, 0.0034257080405950546, -0.05723036825656891, 0.10166807472705841, -0.05951967090368271, -0.007596306502819061, 0.11851370334625244, 0.013041738420724869, -0.11579660326242447, -0.10884255170822144, -0.0006453909445554018, 0.01536486018449068, -0.003865571925416589, 0.07065045833587646, 0.07045517861843109, -0.09768456220626831, 0.023951716721057892, 0.003495238721370697, -0.04496516287326813, -0.062453433871269226, 0.03321871533989906, -0.1171397790312767, 0.04745131731033325, -0.024939075112342834, -0.11893247067928314, 0.011765086092054844, -0.02917998470366001, -0.04400992393493652, 0.12305252254009247, -0.07600432634353638, 0.11967179924249649, 0.1369425356388092, -0.02647298574447632, 0.1264803111553192, -0.030101321637630463, 0.0640297532081604, -0.023190774023532867, 0.0920315682888031, -0.07975803315639496, -0.10628916323184967, 0.008909998461604118, -0.1042368933558464, 0.04770112410187721, -0.05588093400001526, 0.0980079174041748, -0.08418124169111252, 0.10326282680034637, -0.028185009956359863, -0.036068785935640335, 0.018715273588895798, 0.002535806968808174, -0.07615125179290771, -0.026227101683616638, -0.13674885034561157, -0.08920268714427948, 0.1650892198085785, -0.0044400133192539215, -0.05423557385802269, -0.05878405272960663, -0.0020359796471893787], metadata={'source': 'AAAMLP-569to.pdf', 'page': 204}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 205         nn.ReLU(),         nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1),         nn.Dropout(p=0.5),         nn.Linear(in_features=2048, out_features=1),     )     return model ═════════════════════════════════════════════════════════════════════════  When trying this model, I also changed the image size to 512x512 and added a step learning rate scheduler which multiplies the learning rate by 0.5 after every 3 epochs.  ═════════════════════════════════════════════════════════════════════════ Epoch=0, Valid ROC AUC=0.5988225569880796 Epoch=1, Valid ROC AUC=0.730349343208836 Epoch=2, Valid ROC AUC=0.5870943169939142 Epoch=3, Valid ROC AUC=0.5775864444138311 Epoch=4, Valid ROC AUC=0.7330502499939224 Epoch=5, Valid ROC AUC=0.7500336296524395 Epoch=6, Valid ROC AUC=0.7563722113724951 Epoch=7, Valid ROC AUC=0.7987463837994215 Epoch=8, Valid ROC AUC=0.798505708937384 Epoch=9, Valid ROC AUC=0.8025477500546988 ═════════════════════════════════════════════════════════════════════════  This model seems to perform the best. However, you might be able to tune the different parameters and image size in AlexNet to get a better score. Using augmentations will improve the score further. Optimising deep neural networks is difficult but not impossible. Choose Adam optimizer, use a low learning rate, reduce learning rate on a plateau of validation loss, try some augmentations, try preprocessing the images (e.g. cropping if needed, this can also be considered pre-processing), change the batch size, etc. There’s a lot that you can do to optimize your deep neural network.   ResNet is an architecture much more complicated compared to AlexNet. ResNet stands for Residual Neural Network and was introduced by K. He, X. Zhang, S. Ren and J. Sun in the paper, deep residual learning for image recognition, in 2015. ResNet consists of residual blocks that transfer the knowledge from one layer to further layers by skipping some layers in between. These kinds of connections of layers are known as skip-connections since we are skipping one or more layers. Skip-connections help with the vanishing gradient issue by propagating the gradients to further layers. This allows us to train very large convolutional neural networks without loss of performance. Usually, the training loss increases at a given'),\n",
       " VectorParams(vector=[-0.13947133719921112, -0.041636645793914795, 0.11458049714565277, 0.03927126154303551, 0.06843729317188263, 0.05510032922029495, -0.007785669062286615, -0.04393099993467331, 0.024914732202887535, -0.07171901315450668, -0.030089903622865677, 0.07161905616521835, -0.04181680828332901, -0.01569805108010769, -0.20173439383506775, -0.0320872887969017, 0.14244654774665833, 0.006260864436626434, -0.1844189167022705, -0.11621807515621185, 0.021864721551537514, -0.023703239858150482, -0.021747197955846786, 0.020039988681674004, -0.0339750312268734, -0.06068086624145508, -0.019352717325091362, -0.02507278136909008, -0.0092152189463377, -0.12922796607017517, 0.02553281933069229, 0.04049130529165268, -0.03806544095277786, 0.10585933923721313, -0.05705564096570015, 0.06629277020692825, -0.038391537964344025, 0.1005377322435379, 0.0012549039674922824, -0.03499292582273483, 0.05357804149389267, -0.06820545345544815, 0.07031254470348358, 0.0889815092086792, 0.17328885197639465, 0.04492046311497688, -0.12025851011276245, 0.023552164435386658, 0.11445165425539017, -0.1132797971367836, -0.024846991524100304, 0.026218045502901077, -0.07439982146024704, 0.20888829231262207, 0.09875766187906265, 0.003609074279665947, -0.0711698904633522, 0.04370565712451935, -0.06807184964418411, 0.012212893925607204, 0.005523134488612413, -0.13053329288959503, -0.06526447832584381, -0.07035182416439056, 0.027175381779670715, -0.03971249610185623, -0.008096806704998016, 0.06360359489917755, 0.14300018548965454, 0.0012916398700326681, 0.11287909001111984, 0.17238681018352509, -0.11988817155361176, 0.07522070407867432, 0.1184905618429184, 0.005534321069717407, 0.16596275568008423, 0.13079816102981567, 0.001425266033038497, -0.07299268990755081, 0.06636597961187363, 0.12646900117397308, 0.13975390791893005, -0.04927552118897438, 0.08396009355783463, 0.017090177163481712, -0.13258230686187744, -0.01400349847972393, -0.043652743101119995, -0.0760137140750885, 0.0036973534151911736, -0.006260069087147713, -0.06650816649198532, 0.027190666645765305, 0.11446939408779144, 0.10294075310230255, -0.07028099149465561, -0.11883307248353958, -0.14860914647579193, 0.12672126293182373, 0.13758043944835663, -0.10892193019390106, 0.09756697714328766, -0.016760213300585747, 0.1510908156633377, 0.045201078057289124, 0.16028906404972076, 0.1301966905593872, -0.030682971701025963, -0.11356978118419647, 0.01949961669743061, -0.08508520573377609, -0.03795328363776207, -0.05189650133252144, 0.08668522536754608, -0.07252427190542221, -0.04532768949866295, -0.07573755830526352, 0.01666206121444702, 0.12535174190998077, -0.17575711011886597, 0.15796025097370148, -0.05194398760795593, -0.010021057911217213, 0.06903527677059174, 0.02441752329468727, -0.18725594878196716, 1.1539500372972105e-32, -0.1042865663766861, -0.02142343670129776, 0.027420183643698692, -0.1317916214466095, 0.031557925045490265, -0.0767856314778328, 0.04735702648758888, 0.05518679320812225, 0.040918461978435516, 0.005218262784183025, -0.19791363179683685, -0.138072669506073, -0.09867559373378754, 0.12577968835830688, -0.030172372236847878, -0.10592816770076752, 0.09459094703197479, 0.05436233431100845, -0.015722177922725677, 0.04400428757071495, -0.09168021380901337, -0.12806850671768188, 0.04119262844324112, -0.055577803403139114, -0.02477937377989292, -0.10293310880661011, -0.046352237462997437, 0.05434161424636841, 0.0004727506311610341, 0.040235184133052826, -0.07855915278196335, -0.0020620329305529594, 0.10243061184883118, 0.022831635549664497, -0.15378525853157043, -0.03882528096437454, 0.05127677693963051, -0.050477899610996246, 0.010179095901548862, -0.10716461390256882, -0.05205244943499565, 0.1738096922636032, -0.05174506828188896, 0.03693736344575882, -0.07880131900310516, -0.08125524967908859, 0.10169440507888794, 0.06847193837165833, -0.23394523561000824, 0.08035896718502045, 0.1058809831738472, 0.042469535022974014, -0.11834164708852768, -0.16226723790168762, -0.016961488872766495, 0.001836059265770018, 0.07648465037345886, 0.022893520072102547, 0.07886924594640732, 0.04050968214869499, 0.16256487369537354, -0.11098208278417587, -0.232841357588768, 0.2205771654844284, 0.021369170397520065, 0.07954582571983337, 0.05043376237154007, -0.025086624547839165, 0.022978655993938446, -0.003854484762996435, -0.14314813911914825, -0.04285718873143196, 0.0384228341281414, -0.018514148890972137, 0.1544099599123001, -0.013291592709720135, -0.059377096593379974, -0.16789425909519196, -0.08421891927719116, 0.19621910154819489, -0.027395734563469887, 0.21025709807872772, -0.1155659481883049, -0.051794663071632385, -0.13409632444381714, 0.09831977635622025, 0.15793076157569885, -0.1585010141134262, 0.13380929827690125, -0.06074899062514305, 0.0777580738067627, -0.08138561993837357, 0.03795774653553963, 7.83758150646463e-05, 0.002864465583115816, -7.735389064728034e-33, 0.08259008824825287, 0.1879374235868454, -0.14427520334720612, 0.02466864138841629, -0.00014030025340616703, 0.07476229220628738, 0.04384121298789978, 0.015286669135093689, -0.06311032176017761, -0.1761268675327301, 0.18559373915195465, -0.12540282309055328, -0.0074331872165203094, -0.026600701734423637, -0.03775482624769211, -0.0140862837433815, -0.03951582312583923, -0.17938457429409027, 0.17322535812854767, 0.012441102415323257, 0.0716542899608612, 0.05563861504197121, -0.03881821408867836, 0.033008549362421036, -0.19089582562446594, -0.040529560297727585, -0.17941942811012268, 0.1011815071105957, 0.028390588238835335, 0.06183449551463127, -0.13048189878463745, -0.08519624173641205, -0.06866351515054703, -0.018789129331707954, -0.029352758079767227, 0.18003082275390625, 0.06082037091255188, 0.03660275787115097, -0.022307271137833595, 0.02326403558254242, 0.17951011657714844, -0.11513413488864899, -0.06841021031141281, -0.00783973652869463, -0.13248082995414734, -0.043482810258865356, -0.0559217669069767, -0.01650230400264263, -0.13105599582195282, 0.06027394160628319, -0.034477706998586655, -0.025765294209122658, -0.08745014667510986, 0.015685932710766792, -0.013858544640243053, 0.02972828969359398, -0.026769669726490974, 0.14415660500526428, 0.14507293701171875, -0.0036881272681057453, -0.03594541177153587, -0.2815638780593872, -0.20240043103694916, -0.09538991749286652, 0.054967693984508514, 0.07648906111717224, -0.0758499726653099, 0.081906259059906, 0.06649990379810333, 0.12140247970819473, -0.04400830343365669, 0.05438302457332611, 0.08448883146047592, 0.05151069536805153, -0.12855379283428192, -0.11706484854221344, 0.005679917987436056, -0.05866953730583191, 0.001750738127157092, 0.1019844189286232, -0.13295197486877441, 0.05051475763320923, -0.10290054976940155, 0.16001908481121063, 0.23363378643989563, 0.15398626029491425, 0.0012849393533542752, -0.07521553337574005, 0.042973391711711884, 0.1231013610959053, -0.037251319736242294, 0.026467470452189445, 0.036809489130973816, 0.08509230613708496, -0.01534152403473854, -9.905201636684069e-08, -0.06730145215988159, 0.04508073627948761, -0.030361859127879143, 0.027876203879714012, 0.15079034864902496, -0.13276782631874084, 0.08370152115821838, 0.16873572766780853, -0.033372025936841965, 0.098414845764637, -0.006826502736657858, 0.041493915021419525, -0.03826538473367691, -0.05377762392163277, 0.019836964085698128, 0.12687534093856812, 0.0488390177488327, 0.009715095162391663, 0.02684648707509041, -0.08822905272245407, 0.08737470954656601, 0.0612751729786396, -0.11067669838666916, 0.015065210871398449, 0.08251804113388062, -0.15805315971374512, 0.016629785299301147, 0.07644452154636383, -0.047261372208595276, -0.005834315903484821, -0.04702375456690788, 0.028228217735886574, 0.07099362462759018, -0.012223959900438786, 0.09187786281108856, 0.16828200221061707, -0.004492220003157854, 0.07996263355016708, -0.08994799107313156, -0.00352707551792264, -0.04172360897064209, 0.060341157019138336, 0.06294425576925278, -0.1118125468492508, 0.09280995279550552, -0.07014574110507965, 0.05510299652814865, -0.03477543592453003, -0.022519472986459732, -0.08420698344707489, 0.1057400181889534, 0.0967639610171318, 0.039485685527324677, 0.14287766814231873, 0.08435818552970886, -0.07068069279193878, 0.08204489201307297, -0.07647734880447388, -0.051646482199430466, 0.2102033793926239, -0.04905399680137634, 0.08412038534879684, -0.05399182438850403, -0.03355254977941513], metadata={'source': 'AAAMLP-569to.pdf', 'page': 205}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 206 point if we are using a large neural network, but that can be prevented by using skip-connections. This can be better understood by figure 7.  \\n Figure 7: Comparison of simple convnet and residual convnet10. See the skip connections. Please note that the final layers are omitted in this figure.  A residual block is quite simple to understand. You take the output from a layer, skip some layers and add that output to a layer further in the network. The dotted lines mean that the input shape needs to be adjusted as max-pooling is being used and use of max-pooling changes the size of the output.   ResNet comes in many different variations: 18, 34, 50, 101 and 152 layers and all of them are available with weights pre-trained on ImageNet dataset. These days pretrained models work for (almost) everything but make sure that you start with smaller models, for example, begin with resnet-18 rather than resnet-50. Some other ImageNet pre-trained models include:  - Inception - DenseNet (different variations)  10 K. He, X. Zhang, S. Ren and J. Sun, Deep residual learning for image recognition, 2015'),\n",
       " VectorParams(vector=[-0.13254006206989288, -0.044839780777692795, 0.12371169775724411, -0.013384760357439518, 0.13905075192451477, 0.011837249621748924, 0.053603317588567734, -0.016238979995250702, 0.03988362476229668, -0.03878554701805115, -0.1337486058473587, 0.005728450138121843, -0.030228428542613983, 0.096931092441082, -0.08448538929224014, -0.02798159047961235, 0.1367730349302292, 0.12128522247076035, -0.1773836612701416, 0.025884749367833138, 0.03924186900258064, 0.07052770256996155, 0.07210790365934372, 0.04044583812355995, -0.012839792296290398, -0.11635662615299225, 0.07963646203279495, -0.05998266860842705, 0.10925549268722534, 0.014447374269366264, 0.0705842599272728, -0.039508163928985596, 0.16136841475963593, 0.1457023173570633, -0.05526551231741905, 0.027635561302304268, -0.07088814675807953, 0.04149787873029709, 0.01010202243924141, -0.05110058933496475, 0.01974715106189251, -0.08513259887695312, -0.07759512960910797, -0.005722250789403915, 0.21290944516658783, -0.02669502981007099, -0.014755429700016975, -0.07106286287307739, 0.06354410201311111, -0.02978559024631977, 0.036592137068510056, -0.08478303998708725, -0.07428030669689178, 0.15840178728103638, 0.07109631597995758, 0.07064225524663925, 0.04051801189780235, -0.10972936451435089, 0.02087191306054592, -0.0354938767850399, 0.02266383357346058, -0.09192251414060593, -0.16691629588603973, -0.03610650822520256, -0.03119630552828312, 0.015340607613325119, 0.06877842545509338, -0.01997348479926586, 0.18429581820964813, -0.12393476068973541, 0.08383160829544067, 0.15619279444217682, -0.05039128288626671, 0.0658736377954483, -0.06304240971803665, 0.01823703572154045, 0.2371951937675476, 0.11666995286941528, 0.012361982837319374, -0.17723530530929565, 0.16910824179649353, -0.04384331777691841, 0.10323657095432281, 0.013142826035618782, 0.14704428613185883, 0.08069716393947601, -0.17232745885849, 0.10983257740736008, -0.0034651560708880424, -0.09251010417938232, -0.12315710633993149, -0.10941969603300095, 0.003566076746210456, 0.019288120791316032, 0.10524200648069382, -0.05082439258694649, 0.07566040009260178, -0.21314744651317596, -0.004209032282233238, 0.17613646388053894, 0.05875255912542343, -0.08665098994970322, 0.04966362938284874, 0.040495261549949646, 0.057541947811841965, -0.028460213914513588, 0.10699984431266785, 0.060345735400915146, 0.07072484493255615, -0.03671356290578842, 0.09201808273792267, -0.029730873182415962, -0.04352444410324097, -0.014346952550113201, 0.12540538609027863, -0.0514121875166893, 0.05761846899986267, 0.044428858906030655, 0.15841399133205414, 0.016252795234322548, -0.23505306243896484, 0.014294642955064774, -0.046568360179662704, 0.12984880805015564, 0.09941930323839188, -0.2097500115633011, -0.2445703148841858, 6.797371021394742e-33, 0.008944369852542877, -0.032100748270750046, 0.09792501479387283, -0.1408485472202301, 0.1146148070693016, -0.0664837583899498, 0.04878491163253784, -0.07452565431594849, 0.09186086803674698, -0.05044809728860855, -0.12061417102813721, -0.056941479444503784, -0.040535878390073776, 0.07710382342338562, 0.018992628902196884, -0.18150651454925537, -0.011857490986585617, -0.04014959931373596, -0.09046532958745956, 0.04622766748070717, -0.06196281686425209, -0.11281871050596237, -0.03697469085454941, 0.027674729004502296, -0.020609112456440926, -0.061217375099658966, -0.017489036545157433, -0.0929243266582489, 0.055664170533418655, 0.09024861454963684, -0.1335495263338089, 0.04035031422972679, 0.08746147900819778, 0.12184285372495651, -0.15208734571933746, -0.06401482969522476, -0.019806379452347755, 0.0013950361171737313, 0.053399860858917236, -0.14210346341133118, -0.027304673567414284, 0.10974733531475067, 0.095802903175354, -0.10268795490264893, -0.03148860111832619, -0.12788385152816772, -0.05525670573115349, 0.2021215707063675, -0.17036715149879456, 0.03064081259071827, 0.15803274512290955, 0.023456474766135216, -0.04284146428108215, -0.20132043957710266, -0.20675499737262726, 0.017294688150286674, 0.1387777477502823, 0.10708215832710266, 0.13166996836662292, 0.0998256504535675, 0.1536060869693756, 0.05128711089491844, -0.02201966382563114, 0.1842157244682312, -0.029798172414302826, -0.06402274966239929, -0.02796720154583454, 0.018181195482611656, -0.10747910290956497, 0.05570712685585022, -0.23680371046066284, 0.048313260078430176, -0.03257323428988457, -0.12535503506660461, 0.1638784259557724, 0.06669136881828308, -0.030921630561351776, 0.015340233221650124, -0.09179823845624924, 0.0727844089269638, -0.062299396842718124, 0.1221722662448883, -0.05707276612520218, -0.07217129319906235, -0.028897596523165703, 0.13799208402633667, 0.10750272870063782, -0.18667204678058624, 0.04058822616934776, 0.015175474807620049, 0.04982585459947586, -0.04112847149372101, -0.01767107844352722, 0.15081152319908142, 0.03730013966560364, -3.4332439425855926e-33, 0.15053792297840118, 0.2562966048717499, -0.12883822619915009, 0.08521406352519989, -0.0349549762904644, -0.025177039206027985, 0.0955660492181778, 0.014059709385037422, -0.12369906902313232, -0.20088741183280945, 0.008399470709264278, 0.06306060403585434, -0.030583621934056282, 0.00044932510354556143, 0.04374457523226738, -0.05899903550744057, -0.09918326139450073, -0.03667782247066498, 0.03424222022294998, 0.10002493858337402, 0.024183837696909904, 0.1018458753824234, -0.17393285036087036, -0.04425055533647537, -0.2688601315021515, 0.025084594264626503, -0.09106960892677307, 0.08195767551660538, -0.018619133159518242, 0.033883802592754364, -0.13230107724666595, 0.032889656722545624, 0.01046751718968153, -0.11959579586982727, -0.07025056332349777, 0.11268835514783859, 0.05143788084387779, 0.03781699389219284, 0.03119906596839428, 0.07150683552026749, 0.1798122227191925, -0.053380802273750305, -0.12928976118564606, 0.023842215538024902, -0.12485722452402115, -0.03177546337246895, -0.02309306338429451, 0.10023690015077591, -0.16153372824192047, 0.07143937796354294, -0.13410691916942596, 0.08323290944099426, -0.14637160301208496, -0.01175241731107235, -0.015276327729225159, 0.0727807804942131, 0.030534321442246437, 0.012397391721606255, 0.15705806016921997, -0.008149025030434132, -0.11724749952554703, -0.09848658740520477, -0.14812517166137695, 0.10375236719846725, 0.08423225581645966, 0.0246414877474308, -0.06264786422252655, 0.16672606766223907, -0.06626049429178238, 0.047250501811504364, -0.061251603066921234, 0.07647261768579483, 0.028417453169822693, 0.03273548558354378, -0.07932698726654053, -0.01254519447684288, -0.046348702162504196, -0.09726553410291672, 0.07890063524246216, -0.0077344984747469425, -0.10428149253129959, -0.1561490297317505, -0.029912827536463737, 0.1341201215982437, 0.10836947709321976, 0.14127127826213837, 0.12951306998729706, -0.027390480041503906, 0.05480828136205673, -0.0752577930688858, -0.10327690839767456, 0.0035405175294727087, 0.1486911028623581, 0.07443112134933472, 0.02589215710759163, -9.816191237632665e-08, -0.15662600100040436, 0.06480035185813904, -0.0483231246471405, 0.07706355303525925, 0.15306410193443298, -0.12221518903970718, -0.01492184679955244, 0.21515284478664398, -0.0034113533329218626, 0.02005534991621971, -0.1430329978466034, 0.00817734282463789, -0.1616514027118683, -0.154523104429245, -0.16352014243602753, 0.2186208814382553, 0.08334220200777054, 0.07296690344810486, -0.010921112261712551, -0.052437227219343185, 0.047376200556755066, 0.007133553735911846, 0.04154952988028526, -0.01324987132102251, 0.11525988578796387, -0.136003315448761, -0.053123679012060165, 0.17550532519817352, 0.07460325956344604, 0.04189414903521538, -0.1240052804350853, 0.049519624561071396, 0.06521876156330109, 0.08525067567825317, 0.1372707039117813, 0.23996427655220032, -0.13908207416534424, 0.007919673807919025, 0.0009757659281603992, -0.0879666730761528, -0.004114560782909393, -0.09338486194610596, 0.011047699488699436, -0.11322608590126038, -0.013013109564781189, 0.061668578535318375, -0.019569212570786476, -0.05255241319537163, 0.06432899832725525, -0.05688582733273506, 0.1036701649427414, 0.027702001854777336, 0.03126216679811478, 0.14397397637367249, -0.010100623592734337, 0.08295303583145142, 0.04732351750135422, -0.12951426208019257, 0.056121401488780975, 0.13378316164016724, 0.018453633412718773, 0.10282225906848907, -0.10382021963596344, -0.07808977365493774], metadata={'source': 'AAAMLP-569to.pdf', 'page': 206}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 207 - NASNet - PNASNet - VGG - Xception - ResNeXt - EfficientNet, etc.  A majority of the pre-trained state-of-the-art models can be found in pytorch-pretrainedmodels repository on GitHub: https://github.com/Cadene/pretrained-models.pytorch. It is out of the scope of this chapter (and this book) to discuss these models in details. Since we are only looking at applications, let’s see how a pre-trained model like this can be used for a segmentation task.   \\n Figure 8: U-Net architecture11.  Segmentation is a task which is quite popular in computer vision. In a segmentation task, we try to remove/extract foreground from background. Foreground and  11 O. Ronneberger, P. Fischer and T. Brox. U-Net: Convolutional networks for biomedical image segmentation. In MICCAI, 2015'),\n",
       " VectorParams(vector=[-0.06355512142181396, -0.08923172205686569, 0.01066550612449646, -0.03212476894259453, 0.04240056127309799, -0.12892991304397583, -0.017597531899809837, -0.04858279228210449, -0.04141400754451752, -0.12272340059280396, -0.10064801573753357, -0.0257356408983469, -0.010653842240571976, 0.08300136774778366, -0.08960439264774323, -0.05690199136734009, -0.031761106103658676, 0.11341536790132523, -0.1732027232646942, -0.08477392792701721, 0.10423612594604492, 0.019460279494524002, 0.09380921721458435, -0.051098816096782684, 0.060430943965911865, -0.09072305262088776, 0.045506350696086884, -0.014250136911869049, 0.021226607263088226, -0.06016268581151962, 0.17199398577213287, 0.14102166891098022, -0.014172338880598545, 0.0332534983754158, -0.06632018089294434, 0.07670433074235916, -0.05012158304452896, 0.010689676739275455, -0.07249981164932251, 0.04150698333978653, 0.025876296684145927, 0.06547681987285614, -0.12701505422592163, -0.026637401431798935, 0.03401848301291466, 0.0847683921456337, -0.00979118887335062, -0.01946384459733963, 0.0954178124666214, -0.07088039815425873, 0.0018313162727281451, 0.04339640587568283, -0.1931915581226349, 0.21489271521568298, 0.01065713632851839, -0.032209284603595734, 0.009490227326750755, -0.053786538541316986, -0.01561131700873375, -0.07982389628887177, 0.04003845155239105, -0.03693312406539917, -0.03572974354028702, -0.0049590906128287315, 0.10015492886304855, -0.061450984328985214, 0.012066783383488655, -0.05175606533885002, 0.03425724059343338, -0.03860582038760185, -0.011806385591626167, 0.06813548505306244, -0.052558887749910355, 0.0140660610049963, -0.009589520283043385, -0.035287320613861084, 0.2503907382488251, 0.1070047914981842, 0.05513165146112442, -0.11829950660467148, 0.1092567965388298, -0.01828138902783394, 0.025475047528743744, -0.03672712668776512, 0.05750637874007225, -0.05877133831381798, -0.1308262199163437, 0.12329772114753723, -0.019675612449645996, -0.07664604485034943, -0.08840671181678772, -0.060381948947906494, -0.11428551375865936, -0.05649612098932266, 0.068551205098629, -0.027952905744314194, 0.044427379965782166, 0.0108416136354208, -0.03124948777258396, 0.10142294317483902, -0.004734436981379986, -0.23533876240253448, -0.023830700665712357, -0.09566082060337067, 0.030482523143291473, 0.06799539923667908, 0.13314791023731232, 0.045009367167949677, 0.08028001338243484, -0.13981682062149048, -0.011301504448056221, -0.0022845473140478134, -0.010210351087152958, -0.07687196880578995, 0.14922985434532166, 0.06572017073631287, 0.06321907788515091, 0.01972990669310093, 0.04159312695264816, 0.01715504378080368, -0.12705287337303162, -0.0062669431790709496, -0.0867878869175911, 0.0739411860704422, 0.07911813259124756, -0.14702749252319336, -0.11536311358213425, 1.2156455644265305e-32, -0.1075449138879776, 0.040504515171051025, -0.015182547271251678, -0.026627210900187492, 0.1021006852388382, 0.060419972985982895, 0.06597918272018433, -0.0900716558098793, -0.02639559656381607, 0.026912569999694824, -0.19452637434005737, 0.04401351884007454, -0.12212307751178741, 0.1618691086769104, 0.03711182624101639, -0.05961890518665314, -0.07972748577594757, 0.06562329828739166, -0.030099298804998398, 0.06278526037931442, 0.034900106489658356, 0.011565545573830605, -0.009104355238378048, 0.07385624200105667, -0.06328484416007996, -0.0534357950091362, -0.06902475655078888, -0.14704254269599915, -0.05246897041797638, -0.027271952480077744, -0.1252041608095169, 0.05195460468530655, 0.028587231412529945, -0.0011785030364990234, -0.06118113920092583, -0.10666566342115402, 0.011494922451674938, 0.10418415069580078, -0.07343597710132599, -0.1415061056613922, 0.07391105592250824, 0.15541070699691772, -0.048008255660533905, -0.1410018503665924, -0.06530506908893585, -0.0684889703989029, -0.042835891246795654, 0.12813059985637665, -0.021595045924186707, 0.007092576939612627, 0.12909400463104248, -0.05305633693933487, -0.06649791449308395, -0.19168919324874878, -0.0005085431039333344, -0.029258009046316147, 0.1686139851808548, 0.07705153524875641, 0.18879583477973938, 0.047532618045806885, 0.05917827785015106, -0.013277996331453323, -0.017288506031036377, 0.17844536900520325, 0.017728321254253387, -0.00033432699274271727, 0.0014191800728440285, 0.041209228336811066, -0.016759399324655533, 0.03472791612148285, -0.2527259886264801, 0.16917669773101807, 0.009274723939597607, -0.15323187410831451, 0.09178613126277924, 0.03394155949354172, -0.08766137063503265, -0.0706917941570282, -0.15463723242282867, 0.10723423212766647, -0.17160800099372864, 0.18023008108139038, -0.008793345652520657, -0.11413317918777466, -0.08581404387950897, 0.08933404088020325, 0.06372158229351044, -0.15340402722358704, -0.048544734716415405, -0.04434206709265709, -0.09727094322443008, -0.051846034824848175, 0.020927777513861656, 0.0007278444245457649, 0.07516734302043915, -1.1434484646405519e-32, 0.049861326813697815, 0.19131317734718323, -0.07229222357273102, 0.06481165438890457, -0.0023774467408657074, 0.0345122255384922, 0.007398652844130993, 0.06923723965883255, -0.0509670190513134, -0.14839351177215576, 0.013194299302995205, -0.029486695304512978, -0.025061458349227905, -0.01786065101623535, 0.049112629145383835, -0.058822691440582275, -0.040141161531209946, -0.017504557967185974, 0.0157142486423254, 0.022879991680383682, -0.0020320829935371876, 0.20317235589027405, -0.09709444642066956, -0.04905635118484497, -0.22563982009887695, 0.08956140279769897, -0.014883315190672874, 0.16565553843975067, 0.08804501593112946, -0.03941148892045021, -0.13287776708602905, -0.03593183308839798, -0.11645503342151642, 0.05505921691656113, -0.007854187861084938, 0.05591424182057381, 0.14634177088737488, -0.0248881746083498, -0.02641378343105316, -0.010628176853060722, 0.16410988569259644, 0.11982681602239609, -0.09776735305786133, 0.08264893293380737, -0.1125081479549408, -0.06714089214801788, 0.005732309073209763, -0.04555130749940872, -0.1512487381696701, 0.04395609721541405, -0.0017644912004470825, 0.0029184995219111443, -0.17325374484062195, 0.060765914618968964, -0.009014134295284748, 0.10994367301464081, -0.024923361837863922, 0.011731311678886414, 0.14760400354862213, -0.028204355388879776, -0.12175670266151428, -0.12550105154514313, -0.024305231869220734, -0.08262559026479721, 0.07109326124191284, 0.10292007774114609, -0.10854952782392502, 0.06114383041858673, -0.004834367893636227, 0.16019505262374878, 0.02355257235467434, 0.0007135048508644104, 0.10752259194850922, 0.0973471999168396, 0.006748898420482874, 0.043915003538131714, -0.018390823155641556, -0.023418238386511803, -0.027155952528119087, 0.01261056773364544, -0.22848466038703918, -0.1347537785768509, -0.031858302652835846, 0.17215998470783234, 0.16479212045669556, 0.11937801539897919, 0.04970863088965416, 0.03615783154964447, 0.11229802668094635, -0.10477426648139954, 0.0007761111482977867, 0.047912925481796265, 0.1646037995815277, 0.11906251311302185, 0.14617861807346344, -1.0036212927388988e-07, -0.10028878599405289, -0.022992035374045372, -0.11392650008201599, -0.03803819790482521, 0.016607899218797684, -0.15507331490516663, 0.017046650871634483, 0.1919591873884201, -0.023640191182494164, -0.0910181850194931, 0.078492671251297, -0.017626386135816574, -0.03836333751678467, -0.06543825566768646, 0.021595582365989685, 0.2226530909538269, 0.022364459931850433, 0.01972348429262638, 0.02891743741929531, -0.04944664239883423, 0.06990554928779602, -0.09029580652713776, -0.006590785924345255, 0.11659931391477585, -0.06283773481845856, -0.05132310092449188, -0.04545779526233673, 0.04009180888533592, 0.028501059859991074, 0.018699340522289276, -0.010320236906409264, -0.0027135126292705536, 0.0738317221403122, 0.0811547040939331, 0.09275664389133453, 0.017019925639033318, -0.037152308970689774, -0.01584498956799507, -0.06030659377574921, 0.022537484765052795, -0.06116986274719238, -0.009029003791511059, 0.0025601214729249477, -0.0968233197927475, 0.07552749663591385, 0.07573022693395615, 0.08648309111595154, -0.12177255749702454, 0.07186248153448105, 0.07233373075723648, 0.06695656478404999, 0.05866093188524246, -0.0009654667228460312, 0.0021630902774631977, 0.10368662327528, -0.04642350971698761, 0.04091256484389305, -0.0879119336605072, 0.07900349050760269, 0.030692145228385925, -0.07735339552164078, 0.13896533846855164, -0.04012046754360199, -0.061893150210380554], metadata={'source': 'AAAMLP-569to.pdf', 'page': 207}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 208 background can have different definitions. We can also say that it is a pixel-wise classification task in which your job is to assign a class to each pixel in a given image. The pneumothorax dataset that we are working on is, in fact, a segmentation task. In this task, given the chest radiographic images, we are required to segment pneumothorax. The most popular model used for segmentation tasks is U-Net. The structure is represented in figure 8.  U-Nets have two parts: encoder and decoder. The encoder is the same as any convnet you have seen till now. The decoder is a bit different. Decoder consists of up-convolutional layers. In up-convolutions (transposed convolutions), we use filters that when applied to a small image, creates a larger image. In PyTorch, you can use ConvTranspose2d for this operation. It must be noted that up-convolution is not the same as up-sampling. Up-sampling is an easy process in which we apply a function to an image to resize it. In up-convolution, we learn the filters. We take some parts of the encoder as inputs to some of the decoders. This is important for the up-convolutional layers.  Let’s see how this U-Net is implemented.  ═════════════════════════════════════════════════════════════════════════ # simple_unet.py import torch import torch.nn as nn from torch.nn import functional as F   def double_conv(in_channels, out_channels):     \"\"\"     This function applies two convolutional layers     each followed by a ReLU activation function     :param in_channels: number of input channels     :param out_channels: number of output channels     :return: a down-conv layer     \"\"\"     conv = nn.Sequential(         nn.Conv2d(in_channels, out_channels, kernel_size=3),         nn.ReLU(inplace=True),         nn.Conv2d(out_channels, out_channels, kernel_size=3),         nn.ReLU(inplace=True)     )     return conv   def crop_tensor(tensor, target_tensor):'),\n",
       " VectorParams(vector=[-0.019437287002801895, -0.08508486300706863, -0.026208076626062393, -0.03320497274398804, 0.10977882891893387, -0.14688801765441895, -0.03782432898879051, 0.031035270541906357, -0.21146807074546814, -0.19443057477474213, -0.005239500198513269, -0.11200877279043198, -0.08084841817617416, -0.02190539613366127, -0.03402595594525337, 0.09079286456108093, -0.04502590745687485, 0.12452278286218643, -0.12906093895435333, 0.013738363981246948, 0.08109341561794281, 0.0672312006354332, -0.0258132703602314, 0.0179563220590353, 0.03621216118335724, -0.06543496251106262, 0.07192069292068481, 0.03303905576467514, -0.026739835739135742, -0.18613269925117493, 0.12921787798404694, 0.13402695953845978, -0.11304715275764465, 0.047350864857435226, 0.05815697833895683, -0.039215680211782455, -0.12237723916769028, -0.03398708254098892, -0.03554064780473709, 0.032640065997838974, 0.16258181631565094, 0.1253412663936615, -0.035892780870199203, 0.01335189864039421, -0.005606422200798988, 0.146534726023674, -0.0006117175216786563, 0.10571634024381638, 0.185904860496521, -0.14920002222061157, -0.03900730609893799, 0.0318961963057518, -0.10631924867630005, 0.08349372446537018, -0.04798862710595131, -0.06443443894386292, -0.008216159418225288, -0.020314287394285202, -0.05557556077837944, -0.1149987205862999, 0.022330187261104584, 0.03547736257314682, 0.02626613713800907, -0.037563107907772064, -0.017210928723216057, -0.08457495272159576, -0.025294100865721703, 0.02311677485704422, -0.07722120732069016, 0.07194536179304123, 0.02097127214074135, 0.08126148581504822, -0.09054729342460632, 0.12598802149295807, 0.14709095656871796, -0.0722251683473587, 0.19286885857582092, 0.104780413210392, 0.0022242616396397352, -0.08890615403652191, -0.11706472933292389, -0.056983549147844315, 0.08108504116535187, -0.11011336743831635, 0.012450412847101688, -0.1739250272512436, -0.0365777388215065, 0.07063338905572891, 0.1707923412322998, -0.07510189712047577, 0.08420327305793762, 0.0476846806704998, -0.14752033352851868, 0.0027408921159803867, 0.138229101896286, 0.06576282531023026, -0.01785307750105858, 0.02597816474735737, -0.1266840547323227, 0.1552044153213501, -0.03440341725945473, -0.14497363567352295, -0.025403432548046112, 0.13513346016407013, 0.09124557673931122, 0.0760025680065155, 0.1191568523645401, 0.08864996582269669, 0.11339052766561508, -0.12819014489650726, 0.04867485910654068, -0.10700546950101852, 0.04739440605044365, 0.023431196808815002, 0.14081451296806335, 0.07639004290103912, -0.006235676351934671, 0.04197850078344345, 0.02163258194923401, 0.039928000420331955, -0.09919966757297516, 0.032644327729940414, -0.017634496092796326, 0.06574054062366486, -0.0690445825457573, 0.047986265271902084, -0.13116708397865295, 1.0394587977054398e-32, -0.11738427728414536, -0.060660168528556824, -0.06784921884536743, -0.08985362201929092, 0.02876324951648712, 0.02281482331454754, 0.06683173775672913, -0.043441154062747955, -0.04820379242300987, -0.045487914234399796, -0.24939705431461334, -0.06252927333116531, -0.06804262846708298, 0.09146947413682938, 0.02259478159248829, -0.15622159838676453, 0.0794449970126152, 0.07601998001337051, 0.015229531563818455, 0.04274412617087364, 0.22331610321998596, 0.11163388192653656, -0.11119326204061508, -0.060787905007600784, -0.12980346381664276, -0.13097630441188812, -0.05507802963256836, -0.08240167051553726, -0.09728188812732697, 0.06156517192721367, -0.2192636877298355, -0.08921916037797928, -0.04844643548130989, -0.006429383996874094, -0.0023339076433330774, -0.10307566076517105, 0.023580750450491905, 0.1124458909034729, -0.0920717790722847, -0.2910636365413666, 0.008986273780465126, 0.13036614656448364, 0.07780399918556213, -0.17087693512439728, -0.04337114095687866, -0.15220656991004944, 0.032421670854091644, 0.19879081845283508, -0.07557527720928192, 0.008710336871445179, -0.02261454425752163, -0.07869326323270798, -0.0002617632271721959, -0.1241866946220398, 0.04673869535326958, 0.016168367117643356, 0.15029965341091156, 0.17921733856201172, 0.20535291731357574, 0.05102401226758957, 0.020469313487410545, -0.011107073165476322, -0.09141583740711212, 0.10767026245594025, 0.08094057440757751, 0.101908840239048, -0.004985543433576822, 0.012068569660186768, 0.12388163059949875, 0.0074547212570905685, -0.14892952144145966, 0.11884662508964539, 0.01159843523055315, -0.09716720879077911, 0.04832398518919945, -0.2171156406402588, 0.13520947098731995, -0.14916670322418213, -0.10351389646530151, 0.025805767625570297, -0.10521464049816132, 0.175672248005867, 0.011921373195946217, -0.21745139360427856, -0.25887784361839294, -0.039290618151426315, 0.04627063497900963, -0.08601599931716919, -0.12413521111011505, -0.05174970254302025, -0.14041385054588318, -0.026210708543658257, 0.012341286987066269, -0.03501621261239052, -0.015868015587329865, -9.210232602878818e-33, 0.046939559280872345, 0.0658644363284111, 0.10523470491170883, 0.09488796442747116, 0.007057080511003733, 0.07881476730108261, 0.1075698509812355, 0.12385226786136627, -0.051920704543590546, -0.08201894909143448, -0.0309084951877594, -0.019571853801608086, 0.04223952069878578, -0.10458646714687347, 0.16939076781272888, 0.012129575945436954, -0.07276322692632675, 0.10848288983106613, 0.09590102732181549, 0.011979700066149235, -0.17288273572921753, 0.23429009318351746, -0.033786870539188385, -0.005140634253621101, -0.10977309942245483, 0.04448492079973221, -0.07294567674398422, 0.17406395077705383, -0.06647210568189621, -0.03928971290588379, -0.12075428664684296, 0.05878700688481331, -0.17004387080669403, 0.08281738311052322, -0.01558092050254345, -0.021142736077308655, 0.030225438997149467, 0.002620941260829568, -0.11752080917358398, 0.06976409256458282, 0.16127115488052368, 0.1054244115948677, -0.15790849924087524, 0.0810018926858902, -0.01934734359383583, 0.028389833867549896, 0.037992026656866074, 0.02575385570526123, -0.024115074425935745, -0.0018253583693876863, -0.09884653240442276, -0.13822041451931, -0.05546935275197029, 0.11559464037418365, -0.028646469116210938, 0.06107686460018158, 0.09015537798404694, 0.11942938715219498, 0.0897340178489685, -0.05817252770066261, -0.03974609076976776, -0.13008292019367218, -0.07030923664569855, -0.07324203848838806, 0.08237010985612869, 0.04864589497447014, -0.1496766358613968, 0.12240663915872574, -0.0012196594616398215, 0.15123912692070007, -0.08599037677049637, 0.21692433953285217, 0.09654980152845383, -0.0633096992969513, -0.13506612181663513, 0.06102181598544121, 0.015249076299369335, 0.02979280799627304, 0.03362170606851578, -0.005537951365113258, -0.2669733762741089, -0.0049433596432209015, 0.007620010990649462, 0.24415311217308044, 0.09944421052932739, 0.06086461618542671, 0.07995724678039551, 0.15460212528705597, 0.04188230261206627, -0.030797844752669334, -0.014951370656490326, -0.05685483664274216, 0.14173699915409088, 0.1445794254541397, 0.09875589609146118, -1.0013234685857242e-07, -0.0859239250421524, 0.046828195452690125, -0.0031843280885368586, 0.11491022258996964, 0.07881272584199905, -0.0395270437002182, -0.0024516989942640066, 0.09226866066455841, 0.009907432831823826, 0.006697408389300108, -0.08116617053747177, 0.010993986390531063, -0.0384979173541069, 0.04538826271891594, -0.042174696922302246, 0.0543159581720829, -0.050934430211782455, -0.057644497603178024, -0.06278537958860397, -0.06192684546113014, 0.03089817799627781, -0.13307994604110718, 0.0406983308494091, 0.13459992408752441, -0.039475902915000916, -0.11685442179441452, -0.09274567663669586, 0.04528399556875229, 0.1543530523777008, -0.03174411877989769, -0.08538924902677536, -0.08099690824747086, 0.11573316901922226, 0.04808999225497246, 0.08539755642414093, 0.08657309412956238, -0.06675051897764206, 0.12364130467176437, -0.002184623619541526, 0.11705764383077621, -0.14965303242206573, 0.07838084548711777, 0.01126718707382679, -0.10231539607048035, 0.19496387243270874, -0.06005014851689339, 0.0561998188495636, -0.06300120800733566, 0.06562860310077667, -0.0018962230533361435, 0.06883121281862259, 0.05399318039417267, -0.02282869629561901, 0.1188739612698555, 0.13420157134532928, -0.1566535234451294, -0.18972332775592804, 0.011380955576896667, -0.05677420645952225, 0.05000709742307663, 0.025376614183187485, 0.0561923086643219, -0.11857534945011139, -0.04327630624175072], metadata={'source': 'AAAMLP-569to.pdf', 'page': 208}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 209     \"\"\"     Center crops a tensor to size of a given target tensor size     Please note that this function is applicable only to      this implementation of unet. There are a few assumptions     in this implementation that might not be applicable to all     networks and all other use-cases.     Both tensors are of shape (bs, c, h, w)     :param tensor: a tensor that needs to be cropped     :param target_tensor: target tensor of smaller size     :return: cropped tensor     \"\"\"     target_size = target_tensor.size()[2]     tensor_size = tensor.size()[2]     delta = tensor_size - target_size     delta = delta // 2     return tensor[         :,          :,          delta:tensor_size - delta,           delta:tensor_size - delta     ]   class UNet(nn.Module):     def __init__(self):         super(UNet, self).__init__()          # we need only one max_pool as it is not learned         self.max_pool_2x2 = nn.MaxPool2d(kernel_size=2, stride=2)          self.down_conv_1 = double_conv(1, 64)         self.down_conv_2 = double_conv(64, 128)         self.down_conv_3 = double_conv(128, 256)         self.down_conv_4 = double_conv(256, 512)         self.down_conv_5 = double_conv(512, 1024)          self.up_trans_1 = nn.ConvTranspose2d(             in_channels=1024,             out_channels=512,             kernel_size=2,             stride=2         )         self.up_conv_1 = double_conv(1024, 512)          self.up_trans_2 = nn.ConvTranspose2d(             in_channels=512,             out_channels=256,'),\n",
       " VectorParams(vector=[0.00656470051035285, -0.236245796084404, -0.01639823243021965, -0.11866199970245361, 0.06759710609912872, -0.19610916078090668, -0.054277144372463226, -0.08195050060749054, -0.16694454848766327, -0.17492865025997162, 0.018228167667984962, -0.10167978703975677, -0.04955187812447548, -0.09108763188123703, -0.03314824774861336, 0.10157104581594467, -0.07450301945209503, 0.16054575145244598, -0.12190263718366623, -0.0016831789398565888, 0.12528951466083527, -0.017763780429959297, 0.005877957679331303, 0.05779317021369934, 0.09468406438827515, -0.05757417529821396, 0.12924133241176605, 0.079422228038311, 0.00949612632393837, -0.1303117424249649, 0.05874263122677803, 0.1576113998889923, -0.1888575255870819, 0.05465764179825783, 0.006874282844364643, 0.030999675393104553, -0.01722959615290165, 0.0006353919161483645, -0.10177450627088547, 0.09149619936943054, 0.03185906261205673, 0.09085474163293839, -0.024643799290060997, -0.06796194612979889, 0.028289761394262314, 0.20130181312561035, 0.0551605261862278, 0.008243102580308914, 0.17285773158073425, -0.21013382077217102, 0.005510576535016298, 0.0987972766160965, -0.09798115491867065, 0.07460431754589081, -0.039802830666303635, -0.10165348649024963, 0.014922687783837318, -0.1067701056599617, -0.026727620512247086, 0.05577676370739937, 0.07899268716573715, 0.06238280609250069, 0.03098178468644619, 0.007397403474897146, -0.02103670872747898, -0.11986134946346283, 0.006663590203970671, -0.005785527639091015, -0.10596304386854172, 0.0232508834451437, -0.06406564265489578, 0.04351482540369034, -0.007011259440332651, 0.05645962432026863, 0.10579800605773926, -0.07561064511537552, 0.27254167199134827, 0.11376838386058807, 0.019472599029541016, -0.1797284185886383, 0.009595467709004879, 0.006436294876039028, 0.06411291658878326, 0.00087259168503806, 0.02948867157101631, -0.1735873818397522, -0.07600054889917374, 0.08062314242124557, 0.05725744739174843, -0.02329413592815399, 0.030012767761945724, -0.019205724820494652, -0.10974171757698059, 0.03505077213048935, 0.08194257318973541, 0.02782466821372509, 0.0664147362112999, -0.043964702636003494, -0.03655856102705002, 0.10095228254795074, 0.021855536848306656, -0.21276801824569702, -0.009598033502697945, 0.09431146085262299, 0.11903980374336243, 0.09981659799814224, 0.1939639151096344, 0.1856936663389206, 0.07291024923324585, -0.1295846402645111, 0.026504091918468475, -0.10163816064596176, 0.012651494704186916, 0.01429701503366232, 0.1121932789683342, 0.18865317106246948, -0.03208981081843376, 0.08472742140293121, 0.0015019119018688798, -0.010519716888666153, -0.14934100210666656, -0.021651936694979668, 0.06203531473875046, 0.1136293038725853, -0.0015946585917845368, -0.045885119587183, -0.13395531475543976, 1.318992970635712e-32, -0.10287291556596756, 0.06847301125526428, -0.11002721637487411, -0.07278341054916382, -0.050180308520793915, 0.07841599732637405, 0.07455955445766449, -0.06335266679525375, -0.10662148892879486, 0.009370283223688602, -0.1839069277048111, 0.001754475524649024, -0.09157748520374298, 0.09612153470516205, -0.043656546622514725, -0.1076330840587616, -0.03748608008027077, 0.06583511084318161, 0.045696936547756195, 0.060848258435726166, 0.23823927342891693, 0.0033786313142627478, -0.10396018624305725, -0.07207362353801727, -0.2157944291830063, -0.04317894205451012, -0.09897953271865845, -0.14112214744091034, -0.06390613317489624, 0.020541345700621605, -0.15882377326488495, -0.0871673971414566, -0.007525957655161619, -0.011026403866708279, -0.04146772623062134, -0.10256887972354889, 0.0831291675567627, 0.104556605219841, -0.09143151342868805, -0.1550777554512024, -0.00040792481740936637, 0.16300630569458008, 0.026422590017318726, -0.22531470656394958, -0.04333437606692314, -0.14796216785907745, -0.03620710223913193, 0.15634280443191528, -0.04477526992559433, 0.0314948596060276, 0.05162971094250679, -0.0736435279250145, -0.06053229421377182, -0.1020456999540329, 0.07057646661996841, -0.03858725354075432, 0.19905243813991547, 0.13127872347831726, 0.20086240768432617, 0.07430215924978256, -0.017036665230989456, 0.024017125368118286, -0.122492216527462, -0.017190054059028625, 0.06310667097568512, 0.10007831454277039, 0.041288238018751144, -0.05459221452474594, 0.0576886348426342, 0.0364522822201252, -0.23132634162902832, 0.13387975096702576, 0.015024653635919094, -0.09594782441854477, 0.15107180178165436, -0.10541174560785294, -0.02491731569170952, -0.1667894572019577, -0.14998453855514526, 0.03547447919845581, -0.16955076158046722, 0.2524513602256775, -0.015127735212445259, -0.07196593284606934, -0.19761262834072113, 0.06156569719314575, 0.0317649282515049, -0.14878109097480774, -0.15729698538780212, 0.019359087571501732, -0.10341186821460724, -0.06332533061504364, 0.074474036693573, -0.03896569833159447, -0.09902028739452362, -1.2649416832697894e-32, -0.014525982551276684, 0.21108965575695038, 0.06329619884490967, 0.06886812299489975, -0.051325228065252304, 0.015142150223255157, 0.1169980838894844, 0.07851696759462357, 0.013825825415551662, -0.1491488665342331, 0.041652411222457886, -0.06348763406276703, 0.03819744661450386, 0.01850590854883194, 0.17826291918754578, -0.04157416895031929, -0.010359303094446659, 0.10550136864185333, 0.05611705407500267, -0.060641102492809296, -0.08118658512830734, 0.3123086392879486, -0.08086317032575607, -0.06298498064279556, -0.12811590731143951, 0.0939287319779396, -0.00647180899977684, 0.21501441299915314, 0.026861736550927162, -0.10287967324256897, -0.028430571779608727, 0.028645869344472885, -0.10820881277322769, 0.09179971367120743, -0.008971507661044598, 0.03426428884267807, -0.06808717548847198, -0.0910947173833847, -0.07761432975530624, 0.057504914700984955, 0.1632327139377594, 0.13114579021930695, -0.06851830333471298, 0.007410420570522547, -0.08521884679794312, 0.05890174210071564, -0.057038720697164536, 0.05861115828156471, 0.0013441717019304633, 0.048541244119405746, -0.05591651424765587, -0.04781736433506012, -0.17385618388652802, 0.02926694042980671, -0.018954548984766006, 0.10847485065460205, 0.008448520675301552, 0.14792390167713165, 0.08817383646965027, 0.009800163097679615, -0.0660160481929779, -0.10640278458595276, 0.026585157960653305, -0.12433207780122757, 0.11436804383993149, 0.09070317447185516, -0.14239531755447388, 0.043755851686000824, 0.06822337210178375, 0.11139951646327972, -0.07663020491600037, 0.09187675267457962, 0.037328366190195084, -0.07108475267887115, 0.03744078800082207, 0.04708905518054962, -0.06137027218937874, 0.02993062138557434, 0.05442308634519577, -0.051875725388526917, -0.2281804382801056, -0.030548840761184692, 0.04104932025074959, 0.2752586901187897, 0.07203506678342819, 0.08478307723999023, 0.05120214819908142, 0.15956884622573853, 0.09131889790296555, -0.14332880079746246, 0.16214266419410706, 0.030313784256577492, 0.13164277374744415, 0.13417203724384308, 0.09683442115783691, -1.0100641389954035e-07, -0.05509326234459877, -0.02740340866148472, -0.03425024822354317, 0.005667367018759251, -0.004700840916484594, -0.0733325406908989, 0.03289264440536499, 0.11193864047527313, -0.006691374816000462, -0.1410214900970459, 0.07312563806772232, -0.007334305439144373, -0.06717851012945175, 0.030604977160692215, -0.02268591709434986, 0.07447823137044907, -0.08000142872333527, -0.10290680080652237, -0.02851063758134842, -0.09480062127113342, -0.08653805404901505, -0.13523465394973755, -0.061292774975299835, 0.05692002922296524, -0.15675568580627441, -0.07591527700424194, -0.07051669806241989, -0.05945403128862381, 0.06390762329101562, -0.034003596752882004, -0.03913573548197746, -0.04030104726552963, 0.08714532852172852, 0.13331235945224762, 0.12094797194004059, 0.04314816743135452, -0.14771586656570435, 0.0701122060418129, -0.006441135890781879, 0.11069341748952866, -0.11526394635438919, 0.04099145904183388, -0.09207994490861893, -0.0872822105884552, 0.13466748595237732, 0.020034680142998695, 0.1127406507730484, -0.13585814833641052, 0.05528108403086662, 0.03620383143424988, 0.06046450510621071, 0.08952001482248306, 0.014704031869769096, 0.05603494495153427, 0.169780433177948, -0.15692485868930817, -0.18373215198516846, -0.06901820749044418, -0.011242655105888844, 0.05659552291035652, -0.08794408291578293, 0.10945454239845276, -0.09452319890260696, -0.037349022924900055], metadata={'source': 'AAAMLP-569to.pdf', 'page': 209}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 210             kernel_size=2,             stride=2         )         self.up_conv_2 = double_conv(512, 256)          self.up_trans_3 = nn.ConvTranspose2d(             in_channels=256,             out_channels=128,             kernel_size=2,             stride=2         )         self.up_conv_3 = double_conv(256, 128)          self.up_trans_4 = nn.ConvTranspose2d(             in_channels=128,             out_channels=64,             kernel_size=2,             stride=2         )         self.up_conv_4 = double_conv(128, 64)          self.out = nn.Conv2d(             in_channels=64,             out_channels=2,             kernel_size=1         )      def forward(self, image):         # encoder         x1 = self.down_conv_1(image)         x2 = self.max_pool_2x2(x1)         x3 = self.down_conv_2(x2)         x4 = self.max_pool_2x2(x3)         x5 = self.down_conv_3(x4)         x6 = self.max_pool_2x2(x5)         x7 = self.down_conv_4(x6)         x8 = self.max_pool_2x2(x7)         x9 = self.down_conv_5(x8)                  # decoder         x = self.up_trans_1(x9)         y = crop_tensor(x7, x)         x = self.up_conv_1(torch.cat([x, y], axis=1))         x = self.up_trans_2(x)         y = crop_tensor(x5, x)         x = self.up_conv_2(torch.cat([x, y], axis=1))         x = self.up_trans_3(x)'),\n",
       " VectorParams(vector=[-0.11191948503255844, -0.10482840240001678, 0.03338954970240593, -0.04629149287939072, 0.15528260171413422, -0.13963499665260315, 0.048049572855234146, -0.07964347302913666, -0.03554964438080788, -0.1028515100479126, -0.08202382922172546, 0.011283636093139648, 0.01964302733540535, 0.08963388204574585, -0.08849615603685379, -0.001652384176850319, 0.03443668410181999, 0.13424047827720642, -0.1851489245891571, -0.06486473232507706, 0.1689939647912979, 0.014439914375543594, 0.07501769810914993, -0.083274245262146, 0.01755605638027191, -0.1470680683851242, 0.0847514420747757, -0.0679248571395874, -0.018612485378980637, -0.05404277518391609, 0.09072483330965042, 0.09018533676862717, -0.018231110647320747, 0.005711019970476627, -0.02355511114001274, -0.06740444153547287, -0.0922442078590393, 0.0016491133719682693, -0.030244044959545135, 0.043040357530117035, -0.00815038476139307, 0.06298606097698212, -0.09725789725780487, -0.047599732875823975, 0.06659937649965286, 0.05716017633676529, -0.0232260562479496, -0.013162916526198387, 0.09460581839084625, -0.054025959223508835, 0.04534900188446045, 0.03824634477496147, -0.15241213142871857, 0.19215786457061768, 0.05697796493768692, -0.09101610630750656, 0.027516119182109833, -0.06547533720731735, -0.04982622712850571, -0.10103517025709152, 0.039484862238168716, 0.01843501813709736, -0.008700634352862835, -0.04016658291220665, 0.031787872314453125, -0.01813647337257862, -0.011930546723306179, -0.0296727754175663, 0.10855618864297867, -0.11997832357883453, -0.004871548153460026, 0.09056350588798523, -0.10106386989355087, 0.11945029348134995, -0.00427260622382164, -0.006743358448147774, 0.3129180073738098, 0.1429411768913269, 0.047839418053627014, -0.1306191086769104, 0.09541796892881393, 0.000622626394033432, 0.13724921643733978, -0.048674847930669785, 0.11290968954563141, -0.021100269630551338, -0.15426695346832275, 0.08583059906959534, 0.04867098107933998, -0.08387172222137451, -0.14362181723117828, 0.036500364542007446, -0.11775270104408264, 0.0006990768015384674, 0.07863921672105789, -0.0856095552444458, 0.05796251818537712, -0.05038629099726677, -0.0738389864563942, 0.1666613221168518, -0.006619756110012531, -0.22386452555656433, 0.05085527151823044, -0.05154123902320862, 0.11430136859416962, 0.12558093667030334, 0.12655054032802582, 0.050500016659498215, 0.1369808465242386, -0.15143755078315735, 0.04039916396141052, -0.013535469770431519, -0.08087152242660522, -0.054448872804641724, 0.1462690830230713, -0.00032874057069420815, 0.08111944794654846, -0.012578752823174, 0.0158656295388937, -0.008420811034739017, -0.14328205585479736, 0.04589215666055679, -0.08504632115364075, 0.10587316006422043, 0.11421700567007065, -0.07197470963001251, -0.121421217918396, 1.231980233925557e-32, -0.07559037953615189, 0.02615230903029442, -0.06840863078832626, -0.11562672257423401, 0.1496100127696991, 0.043088462203741074, 0.13983698189258575, -0.024963384494185448, -0.03494156897068024, -0.03801249712705612, -0.19121961295604706, -0.010900424793362617, -0.04357827082276344, 0.1416766494512558, 0.0356740839779377, -0.07591787725687027, 0.0020908741280436516, 0.02986069582402706, 0.03874782472848892, 0.05088258907198906, 0.024462277069687843, -0.00979485921561718, -0.03286805376410484, 0.01819891482591629, -0.12479770928621292, -0.057233527302742004, -0.06218230724334717, -0.10199174284934998, 0.0344647653400898, 0.020591601729393005, -0.13232830166816711, 0.06300875544548035, 0.09613875299692154, 0.002318708458915353, -0.11435306072235107, -0.16770774126052856, 0.029361682012677193, 0.05284028500318527, -0.06096263229846954, -0.1359233409166336, 0.06672483682632446, 0.1915413737297058, 0.030308617278933525, -0.17283670604228973, -0.018882442265748978, -0.07212266325950623, -0.06126755103468895, 0.2333003580570221, -0.11240455508232117, 0.008700504899024963, 0.13956692814826965, -0.019538000226020813, -0.03045426495373249, -0.2047383189201355, -0.07334721088409424, -0.0041124094277620316, 0.16349384188652039, 0.13017871975898743, 0.22993704676628113, 0.11769638955593109, 0.023808181285858154, 0.025462830439209938, -0.05967038869857788, 0.18472084403038025, 0.030547622591257095, 0.0010617207735776901, 0.02856438048183918, -0.010205940343439579, -0.04268556833267212, 0.010873529128730297, -0.23467504978179932, 0.11036732792854309, 0.0030669793486595154, -0.0915464386343956, 0.04322323203086853, -0.06292590498924255, -0.08087395876646042, -0.018750542774796486, -0.16641201078891754, 0.11002232134342194, -0.15045441687107086, 0.23782682418823242, -0.011965054087340832, -0.1257471889257431, -0.16161608695983887, 0.13744711875915527, 0.11003066599369049, -0.16903941333293915, -0.04058680683374405, 0.011978021822869778, -0.04075327515602112, -0.022112125530838966, -0.005229105707257986, 0.08505367487668991, 0.0659533366560936, -9.364514767056305e-33, 0.027077727019786835, 0.22248350083827972, -0.06127743795514107, 0.06321902573108673, -0.028450042009353638, -0.003564506769180298, 0.11936640739440918, 0.03824584186077118, -0.06813343614339828, -0.1524621546268463, 0.06360436975955963, -0.08324488997459412, -0.0662367194890976, -0.03332133963704109, 0.08579440414905548, -0.05574134737253189, -0.14849638938903809, -0.04494199901819229, 0.015848420560359955, 0.08691323548555374, -0.028395984321832657, 0.23687487840652466, -0.18306758999824524, -0.032113369554281235, -0.26384949684143066, 0.10757672786712646, -0.030816685408353806, 0.19169825315475464, 0.04578832536935806, -0.11171557009220123, -0.07719756662845612, 0.029592029750347137, -0.10090817511081696, -0.003266611136496067, -0.05724801868200302, 0.12452856451272964, 0.13178010284900665, -0.017171040177345276, 0.022830098867416382, 0.018285837024450302, 0.14531847834587097, 0.02947930432856083, -0.10703852027654648, 0.10106037557125092, -0.11512882262468338, -0.051749151200056076, -0.030828647315502167, 0.01616358384490013, -0.1256347894668579, 0.0434085875749588, -0.0732681006193161, -0.07055419683456421, -0.20002560317516327, 0.046502891927957535, -0.00590129941701889, 0.13001689314842224, -0.004103145562112331, 0.088168203830719, 0.1823732703924179, 0.03901883214712143, -0.11341116577386856, -0.1461946964263916, -0.04957102984189987, -0.04471950605511665, 0.13238021731376648, 0.0817139595746994, -0.032236695289611816, 0.10157687962055206, 0.03702658414840698, 0.12506262958049774, 0.015569845214486122, 0.07442687451839447, 0.10353928804397583, 0.01846902444958687, 0.012371405027806759, 0.02143722027540207, -0.0025790855288505554, -0.022646600380539894, -0.026591915637254715, -0.021555254235863686, -0.23958295583724976, -0.15278485417366028, -0.03184501826763153, 0.14737603068351746, 0.13788706064224243, 0.07595160603523254, 0.03426048159599304, 0.017475316300988197, 0.09233392775058746, -0.10357986390590668, -0.006204334087669849, -0.0038268249481916428, 0.1568078100681305, 0.05742408707737923, 0.17337578535079956, -9.987505222852633e-08, -0.04837902635335922, 0.07835343480110168, -0.11677519977092743, -0.02915639989078045, 0.04273966699838638, -0.1168365627527237, 0.042469218373298645, 0.1437148153781891, 0.03412206470966339, -0.06665582954883575, 0.018131742253899574, 0.00427756505087018, -0.09472813457250595, -0.09254683554172516, -0.03103131800889969, 0.16219156980514526, -0.05828605964779854, -0.028482167050242424, 0.0271582193672657, -0.01431463472545147, 0.0290987491607666, -0.0780259370803833, -0.07277217507362366, 0.03591763973236084, -0.024004213511943817, -0.08820940554141998, -0.03826190531253815, 0.09621196985244751, -0.0048334538005292416, -0.00447266548871994, -0.0496772900223732, -0.01690940000116825, 0.07888059318065643, 0.06024610996246338, 0.18791186809539795, 0.029817573726177216, -0.06146455183625221, -0.005770581308752298, -0.0239209346473217, 0.03142968565225601, -0.014052987098693848, -0.06195974349975586, 0.0003142324276268482, -0.16308578848838806, 0.08355824649333954, 0.013503783382475376, 0.08819784224033356, -0.09186491370201111, 0.04569799825549126, 0.04924224689602852, 0.1030898243188858, -0.030862711369991302, -0.03653213009238243, 0.026822809129953384, 0.09605138003826141, -0.11088642477989197, -0.0006596434395760298, -0.1412055492401123, 0.1042371541261673, 0.13729843497276306, -0.035716984421014786, 0.0764840841293335, -0.061935681849718094, -0.06207738071680069], metadata={'source': 'AAAMLP-569to.pdf', 'page': 210}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 211         y = crop_tensor(x3, x)         x = self.up_conv_3(torch.cat([x, y], axis=1))         x = self.up_trans_4(x)         y = crop_tensor(x1, x)         x = self.up_conv_4(torch.cat([x, y], axis=1))                  # output layer         out = self.out(x)          return out   if __name__ == \"__main__\":     image = torch.rand((1, 1, 572, 572))     model = UNet()     print(model(image)) ═════════════════════════════════════════════════════════════════════════  Please note that the implementation of U-Net that I have shown above is the original implementation of the U-Net paper. There are many variations that can be found on the internet. Some prefer to use bilinear sampling instead of transposed convolutions for up-sampling, but that’s not the real implementation of the paper. It might, however, perform better. In the original implementation shown above, there is a single channel image with two channels in the output: one for foreground and one for the background. As you can see, this can be customized for any number of classes and any number of input channels very easily. The input image size is different than output image size in this implementation as we are using convolutions without padding.   We see that the encoder part of the U-Net is a nothing but a simple convolutional network. We can, thus, replace this with any network such as ResNet. The replacement can also be done with pretrained weights. Thus, we can use a ResNet based encoder which is pretrained on ImageNet and a generic decoder. In place of ResNet, many different network architectures can be used. Segmentation Models Pytorch12 by Pavel Yakubovskiy is an implementation of many such variations where an encoder can be replaced by a pretrained model. Let’s apply a ResNet based U-Net for pneumothorax detection problem.  Most of the problems like this should have two inputs: the original image and a mask. In the case of multiple objects, there will be multiple masks. In our pneumothorax dataset, we are provided with RLE instead. RLE stands for run- 12 https://github.com/qubvel/segmentation_models.pytorch'),\n",
       " VectorParams(vector=[-0.06724248826503754, -0.027600044384598732, 0.004249483812600374, -0.008207290433347225, 0.10883573442697525, -0.11754977703094482, 0.07876306772232056, -0.01738356426358223, -0.045938510447740555, -0.0892104059457779, 0.033711038529872894, -0.07490863651037216, 0.0069448938593268394, -0.04008413106203079, -0.06463595479726791, -0.014731818810105324, -0.16554979979991913, 0.049067508429288864, -0.18496988713741302, -0.203699991106987, 0.15113039314746857, 0.018305135890841484, 0.07815881818532944, -0.015237892977893353, -0.11387964338064194, -0.018266314640641212, 0.06795159727334976, 0.02508806437253952, 0.004941300023347139, -0.05294318497180939, 0.09139320999383926, 0.03440546616911888, 0.0693877711892128, 0.0503159761428833, 0.09364132583141327, 0.14391523599624634, -0.09296606481075287, 0.03497524932026863, -0.12151942402124405, 0.06282247602939606, -0.08375948667526245, 0.012543626129627228, -0.049294278025627136, -0.08275039494037628, 0.038230713456869125, 0.07103762775659561, 0.02883998118340969, -0.036049745976924896, -0.04159568250179291, -0.11975948512554169, -0.11053305119276047, 0.027352746576070786, -0.14069072902202606, 0.13049553334712982, -0.007441169582307339, -0.1332911103963852, 0.035730231553316116, -0.09397110342979431, -0.015724482014775276, -0.07099168002605438, -0.046193499118089676, -0.04526929929852486, 0.003967517055571079, -0.05266914516687393, -0.0017359019257128239, 0.006786402780562639, -0.03815793991088867, -0.03649645298719406, 0.07583227008581161, -0.023575417697429657, -0.11846490204334259, 0.1414114087820053, -0.12831854820251465, 0.14769917726516724, -0.06097559630870819, -0.06668669730424881, 0.1887858808040619, 0.0031779129058122635, 0.10531662404537201, -0.18381139636039734, 0.04587724059820175, -0.008249495178461075, 0.18970318138599396, 0.00022658398665953428, 0.120045006275177, -0.10238061845302582, -0.09517533332109451, 0.1227388083934784, -0.08114147186279297, -0.03920730575919151, -0.09382463991641998, -0.07594124972820282, -0.03360651433467865, 0.06429950147867203, 0.0861656442284584, 0.009547811932861805, 0.11630195379257202, -0.042363639920949936, 0.010806947946548462, 0.06407012790441513, -0.0418243482708931, -0.0901598334312439, -0.06462263315916061, 0.0022060656920075417, 0.06801001727581024, 0.13330180943012238, 0.14087744057178497, 0.09101744741201401, 0.12029058486223221, -0.19486242532730103, 0.08368736505508423, 0.02160998433828354, -0.11802355200052261, -0.0853641927242279, 0.05729314684867859, -0.015485154464840889, -0.028335601091384888, 0.11973526328802109, -0.10473307222127914, 0.15284055471420288, -0.09963565319776535, 0.01616033725440502, -0.11903917044401169, 0.14049042761325836, -0.04898037388920784, -0.1638663113117218, -0.13332903385162354, 1.5665343015668297e-32, -0.0517243966460228, 0.008873999118804932, -0.08343864977359772, -0.11046657711267471, 0.040148600935935974, 0.015771951526403427, 0.10744117200374603, -0.06908372044563293, -0.14024563133716583, 0.05482134222984314, -0.09364615380764008, -0.07420191913843155, -0.08438094705343246, 0.15656225383281708, 0.02093243971467018, -0.03658568114042282, 0.02715117298066616, 0.08353514969348907, -0.04304078221321106, -0.10229480266571045, 0.09838300198316574, 0.0712646096944809, -0.0002586663467809558, -0.040419936180114746, -0.053834233433008194, 0.022691097110509872, -0.07384028285741806, -0.10497137904167175, 0.008489467203617096, 0.024517247453331947, -0.20640592277050018, 0.06306268274784088, 0.10728811472654343, 0.04647596552968025, 0.004194390494376421, -0.0902315080165863, 0.09955067932605743, 0.04394163936376572, -0.06492146849632263, -0.06156991422176361, 0.06325093656778336, 0.17632785439491272, 0.06090880185365677, -0.0700782909989357, -0.06761371344327927, 0.03498750180006027, 0.01189772691577673, 0.23994453251361847, -0.06978580355644226, 0.0630049854516983, -0.02300885133445263, 0.014334618113934994, -0.002311798045411706, -0.08911755681037903, -0.07059507071971893, -0.03217289596796036, 0.11596208810806274, -0.04050850495696068, 0.1380748152732849, -0.08854430168867111, 0.13400299847126007, 0.05841044336557388, 0.010280090384185314, 0.1198006272315979, -0.08581070601940155, -0.06198201701045036, 0.12314102053642273, -0.028453556820750237, -0.05613716319203377, 0.037996482104063034, -0.1752493530511856, 0.10964390635490417, -0.07585135102272034, -0.04454861581325531, 0.14828743040561676, -0.07633137702941895, 0.04665767401456833, -0.05918591469526291, -0.1710493564605713, 0.08101332932710648, -0.08066503703594208, 0.1366831511259079, 0.014011157676577568, -0.32175320386886597, -0.13688115775585175, 0.01863711141049862, 0.11104036867618561, -0.05791941657662392, -0.1532621830701828, -0.11609012633562088, -0.13528020679950714, -0.027704408392310143, 0.039118777960538864, 0.025456102564930916, -0.038338325917720795, -1.5744074688550496e-32, 0.10564422607421875, 0.22226379811763763, 0.010007098317146301, 0.03680795803666115, -0.03838341683149338, -0.017079073935747147, 0.041259586811065674, 0.030728260055184364, -0.08053195476531982, -0.1275753676891327, 0.0022877005394548178, -0.08453558385372162, -0.16950872540473938, -0.10955808311700821, -0.019625378772616386, -0.08438851684331894, -0.02979102171957493, 0.005381036549806595, -0.09201627969741821, 0.03361443802714348, -0.15121951699256897, 0.20163016021251678, -0.09889045357704163, -0.0017298663733527064, -0.2284282147884369, 0.14766250550746918, -0.003943801857531071, 0.1341642439365387, -0.013579766266047955, 0.06801266223192215, -0.13478267192840576, 0.02170868217945099, -0.19627538323402405, -0.014137999154627323, -0.060953352600336075, 0.04293329268693924, 0.08456563204526901, -0.07052366435527802, -0.07946818321943283, 0.04577801749110222, 0.12112580984830856, 0.09640859812498093, -0.14087843894958496, 0.17372187972068787, -0.06762013584375381, -0.05124041438102722, 0.07593093812465668, 0.059127915650606155, -0.013544154353439808, 0.03880210965871811, -0.029810035601258278, -0.023787928745150566, -0.09045743197202682, 0.06700076162815094, 0.042744703590869904, 0.09605924785137177, -0.14049693942070007, 0.009686397388577461, -0.07723212987184525, -0.04373342916369438, -0.10885252803564072, -0.09546013176441193, -0.05224389582872391, -0.012339241802692413, 0.07048939168453217, 0.055777616798877716, -0.15411975979804993, 0.0764160305261612, 0.09755464643239975, 0.06518808752298355, 0.06346457451581955, 0.05620775744318962, 0.12996774911880493, 0.07557237893342972, -0.06111861765384674, 0.07896087318658829, -0.028668204322457314, 0.04121246933937073, 0.031550083309412, 0.13455834984779358, -0.07044932246208191, -0.07170861959457397, 0.0602637454867363, 0.18599805235862732, 0.03903787583112717, 0.16004396975040436, 0.1315833479166031, 0.003969121258705854, 0.05858300253748894, -0.06605695933103561, -0.022118842229247093, -0.00851840153336525, 0.22694896161556244, 0.15288572013378143, 0.1176137924194336, -1.0042605680382621e-07, -0.00822378508746624, -0.027519799768924713, -0.08112642914056778, -0.04396215081214905, 0.0041579389944672585, -0.006868394557386637, -0.04075227305293083, 0.1179635152220726, -0.05081845819950104, -0.05215673893690109, 0.1558830589056015, 0.0033830415923148394, -0.0771963894367218, -0.026749275624752045, -0.09797757863998413, 0.13898177444934845, 0.057956498116254807, 0.05725665017962456, 0.017317380756139755, 0.005291704088449478, -0.04607631266117096, -0.06689539551734924, -0.003777627367526293, -0.0021295405458658934, -0.03964300826191902, -0.06342793256044388, 0.002931303344666958, 0.03699071332812309, 0.038912948220968246, 0.04029173403978348, -0.0183235052973032, -0.08520349860191345, 0.12876500189304352, 0.13854765892028809, 0.13967053592205048, -0.0029712424147874117, -0.0690288096666336, -0.005518851801753044, -0.05831403657793999, -0.06628414243459702, -0.057134877890348434, -0.004273323807865381, 0.0020431734155863523, -0.0075027006678283215, 0.0683426558971405, 0.0013554433826357126, 0.12693867087364197, 0.00018285070837009698, -0.019530242308974266, 0.1180155873298645, 0.019167985767126083, -0.013465272262692451, -0.024561438709497452, 0.14306135475635529, 0.14426587522029877, -0.1156126856803894, 0.049000855535268784, 0.05208800360560417, 0.04058362916111946, 0.04349220544099808, -0.02463470958173275, -0.002908894559368491, -0.06037553399801254, -0.10633907467126846], metadata={'source': 'AAAMLP-569to.pdf', 'page': 211}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 212 length encoding and is a way to represent binary masks to save space. Going deep into RLE is beyond the scope of this chapter. So, let’s assume that we have an input image and corresponding mask. Let’s first design a dataset class which outputs image and mask images. Please note that we will create these scripts in such a way that they can be applied to almost any segmentation problem. The training dataset is a CSV file consisting only of image ids which are also filenames.  ═════════════════════════════════════════════════════════════════════════ # dataset.py import os import glob import torch  import numpy as np import pandas as pd  from PIL import Image, ImageFile  from tqdm import tqdm from collections import defaultdict from torchvision import transforms  from albumentations import (     Compose,     OneOf,     RandomBrightnessContrast,     RandomGamma,     ShiftScaleRotate, )  ImageFile.LOAD_TRUNCATED_IMAGES = True   class SIIMDataset(torch.utils.data.Dataset):     def __init__(         self,          image_ids,          transform=True,          preprocessing_fn=None     ):         \"\"\"         Dataset class for segmentation problem         :param image_ids: ids of the images, list         :param transform: True/False, no transform in validation         :param preprocessing_fn: a function for preprocessing image         \"\"\"'),\n",
       " VectorParams(vector=[-0.05609792470932007, -0.052903786301612854, 0.16858647763729095, 0.0852888971567154, 0.05846108868718147, -0.14341169595718384, 0.13530993461608887, -0.012565800920128822, -0.05560072138905525, -0.08456581830978394, 0.09040964394807816, -0.15979400277137756, 0.09066617488861084, -0.10107451677322388, -0.04729418456554413, 0.10211615264415741, -0.06997735798358917, 0.0961364135146141, -0.19643180072307587, -0.15484462678432465, 0.049329280853271484, -0.05495057255029678, 0.08699776977300644, -0.02108878083527088, 0.02180211991071701, 0.0363917239010334, 0.08969487994909286, 0.0024440798442810774, 0.016158059239387512, -0.13565540313720703, 0.08787456899881363, 0.0006704567349515855, 0.04353832080960274, 0.03977543115615845, 0.05684155970811844, 0.09034895896911621, -0.1324930638074875, -0.02248658426105976, -0.10415424406528473, 0.03352166339755058, -0.013297898694872856, 0.09189745783805847, -0.02097471058368683, -0.11677997559309006, 0.08871421217918396, 0.09643622487783432, -0.04262656345963478, -0.09991434961557388, 0.07848387956619263, -0.019294029101729393, -0.08021945506334305, -0.046023741364479065, -0.20605546236038208, 0.0651310607790947, -0.03825587406754494, 0.060306366533041, 0.025520212948322296, -0.07058388739824295, 0.08196885883808136, -0.08503958582878113, 0.07709252834320068, -0.008102906867861748, -0.047785937786102295, -0.033140879124403, -0.012478348799049854, -0.005358616355806589, -0.03693065047264099, -0.10317656397819519, 0.06460734456777573, 0.01847061514854431, -0.030834844335913658, 0.15820272266864777, 0.06372413039207458, 0.11362925171852112, -0.05764191225171089, -0.09332247823476791, 0.10004415363073349, -0.050389502197504044, 0.0027563213370740414, -0.18818870186805725, 0.056476883590221405, -0.1061398908495903, 0.18950828909873962, 0.012233471497893333, 0.272137850522995, -0.22796306014060974, -0.04481972008943558, 0.10770231485366821, -0.11148083955049515, 0.0062606483697891235, -0.07670227438211441, 0.004217898473143578, -0.09740577638149261, 0.02051866613328457, 0.10933978855609894, 0.08055977523326874, 0.09716736525297165, -0.12082308530807495, -0.030909156426787376, 0.14623960852622986, 0.00288002728484571, -0.12705197930335999, -0.044901736080646515, 0.06318574398756027, 0.09321629256010056, 0.09396661818027496, 0.14054957032203674, 0.015667440369725227, 0.0472094900906086, -0.11061951518058777, 0.09418344497680664, 0.01583157107234001, -0.09163061529397964, 0.02661069668829441, 0.07966911792755127, 0.10386073589324951, -0.028167258948087692, 0.1371072679758072, -0.14322996139526367, 0.09825436025857925, -0.03395905718207359, -0.007781027350574732, -0.03256947919726372, 0.07000059634447098, -0.018329374492168427, -0.16757415235042572, -0.04069698229432106, 1.5012185457105647e-32, -0.011080212891101837, -0.08235170692205429, -0.09552330523729324, -0.06114417314529419, 0.09730245172977448, 0.018318016082048416, 0.03328845277428627, -0.03408639878034592, -0.1241249069571495, -0.08861003071069717, -0.038610540330410004, 0.10782565176486969, -0.1833556443452835, 0.06561850011348724, 0.05368059128522873, -0.09760991483926773, 0.032071929425001144, 0.16232134401798248, 0.066521055996418, -0.016266651451587677, 0.0583014115691185, -0.07441438734531403, -0.06767234951257706, -0.0863482803106308, -0.2045527845621109, 0.03504146635532379, -0.0007409849786199629, -0.00814330205321312, -0.010143265128135681, 0.04517127946019173, -0.1429755836725235, 0.0797378346323967, -0.00511245708912611, 0.02847890369594097, -0.14867106080055237, -0.058694638311862946, 0.06546375900506973, 0.014485386200249195, -0.017819348722696304, -0.1194843277335167, -0.07552740722894669, 0.21267908811569214, -0.03536543250083923, -0.17720837891101837, -0.09131229668855667, 0.1551155149936676, -0.012864544987678528, 0.23370537161827087, -0.03198554739356041, 0.12881122529506683, 0.026252811774611473, -0.07782170921564102, -0.07925049215555191, -0.17718206346035004, -0.12234904617071152, 0.04912563040852547, 0.10870055854320526, 0.09622369706630707, 0.14172756671905518, -0.026365406811237335, 0.1253710687160492, 0.07991425693035126, 0.0002054472133750096, 0.15466056764125824, 0.1233413890004158, 0.040165167301893234, 0.10702888667583466, -0.060991134494543076, -0.08705122768878937, -0.004491003230214119, -0.15291735529899597, 0.08262933790683746, -0.06347136944532394, -0.15765489637851715, 0.10646896064281464, -0.08459373563528061, 0.05701018124818802, 0.002420810516923666, -0.2683391273021698, -0.012319348752498627, -0.1476178914308548, 0.24937647581100464, -0.07833503931760788, -0.25258535146713257, -0.1614989936351776, 0.07757166773080826, 0.06977535784244537, -0.020253797993063927, -0.20119772851467133, -0.02285867929458618, -0.0526723675429821, 0.06239930912852287, 0.0716666504740715, 0.030603166669607162, -0.06246938928961754, -1.3002842433584061e-32, 0.15014061331748962, 0.10884048044681549, 0.12014812976121902, 0.0397614911198616, 0.06825491786003113, 0.059264492243528366, 0.13867038488388062, 0.1409890204668045, 0.036215536296367645, -0.15537680685520172, 0.07392601668834686, -0.07029139995574951, -0.17135092616081238, -0.2435878962278366, -0.04124484211206436, -0.12697085738182068, 0.008235698565840721, 0.139522522687912, -0.11481212824583054, 0.025411229580640793, -0.1664627641439438, 0.30430272221565247, -0.046851303428411484, 0.06853193044662476, -0.2672806680202484, 0.1738891303539276, -0.031591787934303284, 0.1263100951910019, -0.06874274462461472, -0.027643514797091484, -0.17818430066108704, 0.14873677492141724, -0.13035723567008972, -0.09663005918264389, -0.059446658939123154, -0.009686884470283985, -0.01985573023557663, -0.13511572778224945, -0.237112358212471, 0.13739964365959167, 0.11788349598646164, 0.11961043626070023, -0.18194405734539032, -0.04039635881781578, -0.029361668974161148, -0.03529467061161995, 0.061710748821496964, 0.06467703729867935, 0.034570325165987015, 0.014113754965364933, 0.0331953726708889, -0.16171284019947052, -0.13390274345874786, 0.034765180200338364, 0.012895573861896992, 0.17719028890132904, -0.1470414400100708, -0.044569920748472214, -0.055141229182481766, 0.0065028187818825245, -0.10804549604654312, -0.055246733129024506, -0.063758984208107, -0.15818411111831665, 0.05857979506254196, 0.13202275335788727, -0.13953351974487305, -0.01919564977288246, 0.040935032069683075, 0.2060440182685852, 0.06539309024810791, 0.003445384558290243, 0.12238480150699615, 0.036159954965114594, 0.04020484536886215, 0.047989390790462494, 0.043790075927972794, -0.03163651004433632, 0.01922607421875, -0.03129852935671806, -0.1382453292608261, -0.04677967354655266, 0.04685065522789955, 0.17295749485492706, -0.02784990519285202, 0.09081269800662994, 0.06566884368658066, -0.030516166239976883, 0.17654962837696075, 0.00330419116653502, -0.06645851582288742, 0.00962537620216608, 0.19760364294052124, 0.053159523755311966, 0.08330057561397552, -1.0039913433956826e-07, -0.09881459176540375, 0.02956809476017952, 0.02374844253063202, 0.09234533458948135, 0.012260946445167065, -0.027067938819527626, 0.031055288389325142, 0.13963337242603302, 0.05428410694003105, -0.14718106389045715, 0.20285114645957947, 0.003547859378159046, 0.01194420550018549, 0.03495683893561363, -0.18291404843330383, 0.08629736304283142, -0.04004765301942825, 0.10284575819969177, -0.040078647434711456, 0.0437597781419754, -0.0910380631685257, -0.11990420520305634, 0.09980350732803345, -0.034610312432050705, -0.0294884592294693, -0.06844016909599304, -0.0176031943410635, -0.014578277245163918, 0.08964335918426514, 0.014289055950939655, -0.012172653339803219, -0.09146872162818909, 0.2181519716978073, 0.13495992124080658, 0.02083778940141201, -0.006663254462182522, -0.00747401500120759, 0.006034716498106718, -0.03353395685553551, 0.012661137618124485, -0.10724788904190063, -0.023833442479372025, 0.017251746729016304, 0.010260872542858124, 0.049925319850444794, 0.006928069982677698, 0.1850510537624359, -0.043391671031713486, 0.010402504354715347, 0.09261859953403473, -0.021469350904226303, -0.11099307984113693, -0.04242340102791786, 0.041350964456796646, 0.08721841126680374, -0.1428757607936859, 0.10738961398601532, 0.11613887548446655, -0.0443645603954792, 0.06528206169605255, 0.07003980875015259, -0.1115066185593605, -0.12130123376846313, -0.06253699213266373], metadata={'source': 'AAAMLP-569to.pdf', 'page': 212}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 213         # we create a empty dictionary to store iamge         # and mask paths         self.data = defaultdict(dict)          # for augmentations         self.transform = transform          # preprocessing function to normalize         # images         self.preprocessing_fn = preprocessing_fn          # albumentation augmentations         # we have shift, scale & rotate         # applied with 80% probability         # and then one of gamma and brightness/contrast         # is applied to the image         # albumentation takes care of which augmentation         # is applied to image and mask         self.aug = Compose(                 [                     ShiftScaleRotate(                         shift_limit=0.0625,                          scale_limit=0.1,                          rotate_limit=10, p=0.8                     ),                     OneOf(                         [                             RandomGamma(                                 gamma_limit=(90, 110)                             ),                             RandomBrightnessContrast(                                 brightness_limit=0.1,                                  contrast_limit=0.1                             ),                         ],                         p=0.5,                     ),                 ]             )                  # going over all image_ids to store         # image and mask paths         for imgid in image_ids:             files = glob.glob(os.path.join(TRAIN_PATH, imgid, \"*.png\"))             self.data[counter] = {                 \"img_path\": os.path.join(                     TRAIN_PATH, imgid + \".png\"'),\n",
       " VectorParams(vector=[0.011452669277787209, -0.04157954081892967, -0.010684097185730934, 0.05621693283319473, 0.09872611612081528, -0.11354897916316986, 0.044074151664972305, -0.05006696283817291, -0.1826184242963791, -0.13852711021900177, -0.006541000679135323, -0.11411873251199722, 0.06466829031705856, 0.0600777193903923, -0.04380551353096962, 0.10807043313980103, -0.16086265444755554, 0.1857423186302185, -0.16125348210334778, -0.12287012487649918, 0.04113910719752312, 0.034275252372026443, 0.13977909088134766, -0.061478618532419205, -0.08115646243095398, 0.011496550403535366, 0.15283234417438507, -0.09939640015363693, -0.031104406341910362, -0.06460798531770706, 0.09979894012212753, -0.07136279344558716, 0.0950481966137886, 0.07150625437498093, 0.03351149708032608, 0.09487763792276382, -0.07044117897748947, -0.014779698103666306, -0.06351883709430695, 0.022315746173262596, 0.059852756559848785, 0.11525383591651917, -1.2464211067708675e-05, -0.11253350973129272, 0.14640593528747559, 0.20986713469028473, 0.07184896618127823, -0.08856917917728424, 0.10628371685743332, -0.08724964410066605, -0.04751477390527725, -0.00758730061352253, -0.22591273486614227, 0.09870091080665588, -0.09234065562486649, -0.013636281713843346, 0.041939303278923035, -0.13151462376117706, -0.02178855612874031, -0.0664437785744667, -0.00853086356073618, -0.056944381445646286, -0.017956310883164406, -0.032080404460430145, 0.02138843573629856, -0.06862524896860123, -0.05347692221403122, -0.12815380096435547, 0.02413199655711651, -0.04605227708816528, 0.004922724794596434, 0.05911294370889664, -0.053802695125341415, 0.05460791289806366, -0.0923820212483406, 0.002856982173398137, 0.1861884593963623, 0.03661077097058296, 0.05883965641260147, -0.049854766577482224, -0.03806657716631889, -0.08446692675352097, 0.1853521317243576, -0.023231644183397293, 0.17208510637283325, -0.08611194789409637, -0.0883377268910408, 0.12594102323055267, -0.034210335463285446, -0.06443985551595688, -0.004659363068640232, 0.015208231285214424, -0.16852325201034546, 0.12403196096420288, 0.1806226670742035, 0.00422057555988431, 0.09571584314107895, 0.0044990424066782, -0.0992102101445198, 0.10751058906316757, -0.03168897330760956, -0.1548561304807663, -0.11821762472391129, 0.0485275462269783, 0.13705022633075714, 0.20839263498783112, 0.1425314098596573, 0.04236695170402527, 0.07453861087560654, -0.14469115436077118, 0.05023173615336418, -0.07893212139606476, -0.13451436161994934, -0.000330755632603541, 0.08258404582738876, 0.12442565709352493, -0.09168601036071777, 0.12142813205718994, -0.03616417571902275, 0.14975181221961975, -0.02373742312192917, 0.0036302010994404554, -0.00807346124202013, 0.04329535365104675, -0.07950489968061447, -0.13032205402851105, -0.2039075493812561, 1.7093412898915892e-32, -0.08517345786094666, 0.012962128035724163, 0.04912975803017616, -0.08737325668334961, 0.017112169414758682, 0.020044341683387756, 0.06447888165712357, -0.11190435290336609, -0.08188461512327194, -0.012708825059235096, -0.13212232291698456, 0.02259848080575466, -0.1404556781053543, 0.14145271480083466, -0.0464620441198349, -0.09862907230854034, 0.042424868792295456, 0.052575115114450455, 0.08045242726802826, -0.002925293054431677, 0.10091198235750198, 0.008555598556995392, -0.05779958888888359, -0.01212279498577118, -0.1363190859556198, -0.08483270555734634, -0.05664015933871269, -0.04614716395735741, 0.014243419282138348, -0.009627780877053738, -0.1359112709760666, 0.05482727661728859, 0.002947638276964426, 0.051921188831329346, -0.10213416069746017, -0.12358424812555313, 0.15136930346488953, 0.09842106699943542, -0.11513371020555496, -0.10594139993190765, 0.062266755849123, 0.11073371767997742, 0.03780573606491089, -0.15089449286460876, -0.10529440641403198, -0.012084408663213253, -0.035478707402944565, 0.16994792222976685, -0.0740976557135582, 0.11344899237155914, -0.01347206812351942, -0.05397789180278778, -0.09326736629009247, -0.09303910285234451, -0.11495763063430786, -0.1078459769487381, 0.12547162175178528, 0.09236215054988861, 0.1518794447183609, -0.11752988398075104, 0.11720740050077438, 0.06412950903177261, 0.06458470225334167, 0.13275420665740967, 0.005567637272179127, 0.031042885035276413, 0.14455196261405945, -0.0545831173658371, -0.09192817658185959, 0.07548598945140839, -0.1371564120054245, 0.16063563525676727, -0.0909694954752922, -0.15236294269561768, 0.04610900580883026, -0.15972548723220825, 0.047382280230522156, -0.08023394644260406, -0.20155860483646393, 0.018966440111398697, -0.14489862322807312, 0.22635455429553986, 0.0012056365376338363, -0.2938512861728668, -0.2526019513607025, 0.06971609592437744, 0.09921875596046448, -0.07223598659038544, -0.07109475135803223, -0.12533684074878693, -0.06380274891853333, 0.03097996488213539, 0.017441431060433388, 0.05076969042420387, -0.07074160873889923, -1.4574285893433513e-32, 0.099457748234272, 0.16809456050395966, -0.0074433861300349236, 0.07302385568618774, 0.0062912097200751305, -0.06232810392975807, 0.11751912534236908, 0.1367938071489334, 0.06301756203174591, -0.09556545317173004, 0.028666293248534203, -0.062132734805345535, -0.03884780779480934, -0.1422456055879593, 0.03613695129752159, -0.06923063099384308, -0.019529735669493675, 0.09030362218618393, -0.05402269586920738, -0.07127365469932556, -0.2587440013885498, 0.24881602823734283, -0.051664575934410095, -0.01823529414832592, -0.2952873110771179, 0.1922081559896469, 0.01829362101852894, 0.08452090620994568, 0.007948867976665497, 0.027431482449173927, -0.12771810591220856, 0.12792350351810455, -0.08603131026029587, 0.05132809653878212, -0.02607022412121296, 0.06036490201950073, 0.033824071288108826, -0.06451799720525742, -0.1324504315853119, 0.07552653551101685, 0.12674468755722046, 0.08651832491159439, -0.10757525265216827, 0.10014018416404724, -0.06880179047584534, -0.07928349077701569, 0.05341615155339241, 0.04081682860851288, 0.03492550924420357, 0.0315837562084198, -0.012499596923589706, -0.06881093978881836, -0.09186404943466187, -0.02427355945110321, 0.03644069656729698, 0.16211891174316406, -0.18021602928638458, -0.015932917594909668, 0.09555912762880325, -0.048464395105838776, -0.10711721330881119, -0.13028481602668762, -0.08308801800012589, -0.1016562432050705, 0.086934395134449, 0.07661896198987961, -0.19678503274917603, 0.06423923373222351, 0.007203206419944763, 0.21642422676086426, 0.005582897458225489, 0.11206117272377014, 0.15588949620723724, 0.08391643315553665, 0.005003193859010935, -0.003142960136756301, 0.015489726327359676, 0.05075030401349068, 0.0029710163362324238, 0.053209222853183746, -0.06116044148802757, -0.06730591505765915, 0.007725278381258249, 0.24273890256881714, 0.11754320561885834, 0.12976332008838654, 0.07334167510271072, 0.006651707459241152, 0.08998826891183853, -0.06944377720355988, 0.010705209337174892, -0.057916708290576935, 0.13068346679210663, 0.13746806979179382, 0.02895178832113743, -1.004238967539095e-07, -0.031655870378017426, -0.047925762832164764, 0.04334177076816559, 0.014701527543365955, 0.03184112161397934, 0.03762030974030495, 0.041151951998472214, 0.12493008375167847, 0.07123606652021408, -0.06069786846637726, 0.030372679233551025, -0.05277875438332558, -0.034288160502910614, -0.045298442244529724, -0.08459887653589249, 0.13465934991836548, -0.07370655238628387, 0.07210162281990051, 0.0698879286646843, 0.04200827330350876, -0.07498420029878616, -0.1497029960155487, -0.028707336634397507, 0.03131785988807678, -0.09083309024572372, -0.09651479870080948, -0.043302204459905624, 0.03735598176717758, 0.04048778489232063, 0.0787585973739624, 0.0005172817036509514, -0.1226421594619751, 0.20362958312034607, 0.13341180980205536, 0.04540373757481575, 0.02983105555176735, 0.0141923688352108, -0.04543593153357506, -0.1223321408033371, 0.0843057706952095, -0.18645499646663666, 0.0015513154212385416, 0.03691824525594711, -0.06697845458984375, 0.08894433826208115, -0.007744173984974623, 0.10990876704454422, -0.09225332736968994, -0.00756079750135541, 0.11797086894512177, 0.06366127729415894, 0.006733160000294447, -0.09838132560253143, 0.09582263976335526, 0.1775224208831787, -0.1595311015844345, 0.055343277752399445, 0.028854239732027054, 0.035301048308610916, 0.13625815510749817, -0.023802801966667175, -0.02870202623307705, -0.06785868108272552, -0.07385988533496857], metadata={'source': 'AAAMLP-569to.pdf', 'page': 213}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 214                 ),                 \"mask_path\": os.path.join(                     TRAIN_PATH, imgid + \"_mask.png\"                 ),             }      def __len__(self):         # return length of dataset         return len(self.data)      def __getitem__(self, item):         # for a given item index,          # return image and mask tensors         # read image and mask paths         img_path = self.data[item][\"img_path\"]         mask_path = self.data[item][\"mask_path\"]          # read image and convert to RGB         img = Image.open(img_path)         img = img.convert(\"RGB\")          # PIL image to numpy array         img = np.array(img)          # read mask image         mask = Image.open(mask_path)          # convert to binary float matrix         mask = (mask >= 1).astype(\"float32\")          # if this is training data, apply transforms         if self.transform is True:             augmented = self.aug(image=img, mask=mask)             img = augmented[\"image\"]             mask = augmented[\"mask\"]          # preprocess the image using provided          # preprocessing tensors. this is basically         # image normalization         img = self.preprocessing_fn(img)          # return image and mask tensors         return {             \"image\": transforms.ToTensor()(img),             \"mask\": transforms.ToTensor()(mask).float(),         } ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[-0.1477963626384735, -0.08962509781122208, -0.020452171564102173, 0.03263688459992409, 0.03196301311254501, -0.06115598604083061, -0.07981392741203308, -0.03412280231714249, -0.06791128218173981, -0.07238359749317169, 0.03202465549111366, -0.12957711517810822, -0.0676889419555664, -0.03207485005259514, -0.04629542678594589, 0.04480813443660736, -0.06193218007683754, -0.1370486468076706, -0.14466458559036255, -0.21882054209709167, 0.13419385254383087, 0.08741917461156845, 0.07682126760482788, 0.03268301114439964, -0.046442124992609024, -0.13128763437271118, 0.018748965114355087, 0.07924885302782059, 0.02642901800572872, -0.022136302664875984, 0.07035908102989197, 0.018922897055745125, -0.03214561939239502, 0.053321126848459244, 0.07793550938367844, 0.11059678345918655, -0.10756529122591019, -0.06542211771011353, -0.07974600046873093, 0.015809576958417892, 0.034167058765888214, -0.04706890136003494, -0.09669141471385956, -0.07516396045684814, 0.10459335148334503, 0.028311293572187424, 0.04449649155139923, 0.00480719143524766, -0.02655887044966221, -0.10921443998813629, -0.05666991323232651, 0.06638540327548981, -0.07552668452262878, 0.042726535350084305, -0.03248373046517372, -0.0959194079041481, 0.08820528537034988, -0.042617831379175186, -0.015252575278282166, -0.16278235614299774, -0.11132724583148956, -0.06463620066642761, -0.03709142282605171, -0.09688662737607956, -0.05079834908246994, -0.07672322541475296, 0.027898013591766357, 0.034005243331193924, 0.07171715795993805, 0.00690401392057538, 0.01788984052836895, 0.03187616914510727, -0.18517571687698364, 0.13333182036876678, -0.010019113309681416, 0.013182559981942177, 0.2011205106973648, 0.06117637827992439, 0.03974829986691475, -0.1966705620288849, -0.022978708148002625, -0.04451878368854523, 0.11795221269130707, -0.056797344237565994, 0.16154751181602478, -0.1260502189397812, -0.03836506977677345, 0.10289978235960007, -0.023023370653390884, -0.04841190204024315, 0.004368488676846027, -0.021063730120658875, -0.12565873563289642, 0.04380675032734871, 0.1803629994392395, 0.0695032998919487, 0.0958002582192421, 0.04082740843296051, -0.07047572731971741, 0.044359900057315826, 0.00485208909958601, -0.047016967087984085, -0.07463078200817108, 0.06699301302433014, 0.03516548499464989, 0.15616381168365479, 0.22369833290576935, 0.12741941213607788, 0.05698556825518608, -0.10887733101844788, 0.07489267736673355, 0.09469648450613022, -0.04306584224104881, -0.10259520262479782, 0.07950200885534286, 0.07763759791851044, -0.11167078465223312, 0.10735340416431427, -0.17465685307979584, 0.19314351677894592, -0.1789485216140747, 0.020270926877856255, -0.1636631041765213, 0.17569014430046082, -0.04368232935667038, -0.0947827473282814, -0.1557234227657318, 2.1992066670144935e-32, -0.01109918300062418, -0.06637509912252426, 0.00501708360388875, -0.219129279255867, 0.058860018849372864, -0.02226792648434639, 0.14822949469089508, -0.0053885746747255325, -0.14290831983089447, 0.005486322101205587, -0.19932670891284943, -0.0946643128991127, -0.018049925565719604, 0.07937504351139069, 0.002756727859377861, -0.065676748752594, 0.007526621222496033, -0.03448689356446266, 0.07744821161031723, -0.02226758748292923, 0.22946827113628387, -0.05863012745976448, -0.11963046342134476, -0.0849381685256958, -0.07917661219835281, 0.09493733197450638, -0.006589481607079506, -0.011803842149674892, -0.08405469357967377, 0.027623465284705162, -0.16805878281593323, 0.050391100347042084, 0.0561429038643837, -0.024824781343340874, 0.00562789523974061, -0.12027888000011444, 0.11983965337276459, 0.13276107609272003, -0.028273673728108406, -0.12436791509389877, 0.046295586973428726, 0.13970836997032166, 0.04322104901075363, -0.08046283572912216, -0.06807753443717957, 0.026753166690468788, 0.014496161602437496, 0.2014278769493103, -0.03975857049226761, 0.03506375849246979, -0.05612828582525253, 0.0067606475204229355, 0.03011298179626465, -0.047070570290088654, -0.04308905079960823, -0.04171549901366234, 0.23320655524730682, -0.013754473067820072, 0.11038673669099808, -0.01761479862034321, 0.13316042721271515, 0.028260117396712303, 0.03324495628476143, 0.08954504877328873, -0.03803592175245285, -0.11259784549474716, 0.023917604237794876, 0.014187595807015896, 0.011886018328368664, 0.07963496446609497, -0.1854909211397171, 0.11757602542638779, -0.01627175137400627, -0.043266069144010544, 0.23441994190216064, -0.13763192296028137, 0.05508546531200409, -0.055783748626708984, -0.16872809827327728, 0.050556473433971405, -0.051600463688373566, 0.10932333767414093, -0.06290049850940704, -0.1751670390367508, -0.08905180543661118, -0.10007677972316742, 0.0900694951415062, -0.09137686342000961, -0.04058953374624252, -0.04094746708869934, -0.1363041251897812, -0.07669141888618469, 0.05166684091091156, 0.07002802938222885, -0.08573197573423386, -2.0346401027616626e-32, 0.10082841664552689, 0.21045857667922974, 0.05783117190003395, 0.15144899487495422, 0.05578170716762543, -0.006275469437241554, 0.050931330770254135, 0.05156484246253967, -0.08818506449460983, -0.09308034926652908, 0.0795435830950737, -0.1036202535033226, -0.03302079066634178, -0.005709569435566664, 0.09772983193397522, 0.017600519582629204, -0.05294536054134369, 0.02563517540693283, 0.061695829033851624, 0.09281394630670547, -0.13569775223731995, 0.182378351688385, -0.2053697556257248, -0.06524374336004257, -0.13608931005001068, 0.08324076980352402, -0.013727040961384773, 0.12188073992729187, 0.007419407833367586, -0.03321070224046707, -0.08694477379322052, 0.019861474633216858, -0.23940345644950867, 0.01807885244488716, -0.032754212617874146, 0.12313562631607056, 0.1686410903930664, -0.06979333609342575, -0.05155564472079277, 0.19171275198459625, 0.28590139746665955, 0.13265371322631836, -0.14437399804592133, 0.18379949033260345, -0.04870820418000221, 0.007879575714468956, -0.026173202320933342, -0.018715210258960724, -0.14451278746128082, 0.04971814900636673, 0.061631835997104645, 0.03436015546321869, -0.10198479145765305, 0.09836927056312561, 0.07603224366903305, 0.038740213960409164, 0.026688192039728165, -0.016371235251426697, -0.09599485993385315, -0.014530288986861706, -0.053137991577386856, -0.08351565897464752, -0.06745409965515137, -0.04785966873168945, 0.0636730045080185, -0.00850952509790659, -0.09563226252794266, 0.1861003339290619, 0.08275576680898666, 0.006935303099453449, -0.13013680279254913, 0.05082162097096443, 0.1176048144698143, 0.045370981097221375, -0.09933551400899887, 0.07162018120288849, -0.07609105110168457, -0.00955275446176529, 0.029362907633185387, 0.07325487583875656, -0.09837683290243149, -0.052261900156736374, 0.014417441561818123, 0.09018836170434952, -0.018791433423757553, 0.16863970458507538, 0.1769791543483734, 0.13479186594486237, 0.021159835159778595, -0.07653576135635376, 0.0085294796153903, -0.08916297554969788, 0.19859199225902557, 0.22119149565696716, 0.0695340484380722, -1.0025718921724547e-07, -0.07560132443904877, -0.010542749427258968, -0.05078597366809845, 0.05842778831720352, 0.03536435216665268, -0.04467267543077469, -0.003844226710498333, 0.10338003188371658, -0.0558013916015625, 0.03265267238020897, 0.12173154950141907, -0.04168843850493431, -0.09938990324735641, -0.015778835862874985, -0.020116209983825684, 0.14383958280086517, 0.024474093690514565, 0.03746384382247925, 0.06027023121714592, -0.09152237325906754, -0.005634305067360401, -0.006198132410645485, -0.05260295048356056, -0.04110517352819443, -0.03828536719083786, -0.03862478584051132, -0.03632717207074165, 0.05365949124097824, 0.014614586718380451, -0.020560583099722862, -0.051603324711322784, -0.10153929144144058, 0.08329363167285919, 0.03563724085688591, 0.007118890527635813, 0.024819862097501755, -0.06797513365745544, 0.012301282957196236, 0.1087537631392479, -0.019480394199490547, -0.071251779794693, 0.017044970765709877, -0.0990745797753334, -0.06613834947347641, 0.0931323915719986, -0.022206855937838554, -0.003936293534934521, -0.04328855499625206, 0.035450663417577744, 0.02327021397650242, 0.0008904985734261572, -0.019047288224101067, 0.0224155206233263, 0.05177897587418556, 0.18330174684524536, -0.06977226585149765, -0.034048739820718765, -0.06909654289484024, 0.07010655105113983, -0.02661202847957611, -0.0024804333224892616, -0.04785233363509178, -0.12426573783159256, -0.10025066137313843], metadata={'source': 'AAAMLP-569to.pdf', 'page': 214}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 215 Once, we have the dataset class; we can create a training function.  ═════════════════════════════════════════════════════════════════════════ # train.py import os import sys import torch  import numpy as np import pandas as pd import segmentation_models_pytorch as smp import torch.nn as nn import torch.optim as optim  from apex import amp from collections import OrderedDict from sklearn import model_selection from tqdm import tqdm from torch.optim import lr_scheduler  from dataset import SIIMDataset  # training csv file path TRAINING_CSV = \"../input/train_pneumothorax.csv\"  # training and test batch sizes TRAINING_BATCH_SIZE = 16 TEST_BATCH_SIZE = 4  # number of epochs EPOCHS = 10  # define the encoder for U-Net # check: https://github.com/qubvel/segmentation_models.pytorch # for all supported encoders ENCODER = \"resnet18\"  # we use imagenet pretrained weights for the encoder ENCODER_WEIGHTS = \"imagenet\"  # train on gpu DEVICE = \"cuda\"  def train(dataset, data_loader, model, criterion, optimizer):     \"\"\"     training function that trains for one epoch     :param dataset: dataset class (SIIMDataset)'),\n",
       " VectorParams(vector=[-0.06395047903060913, -0.0004232005449011922, 0.009103123098611832, 0.044339992105960846, -0.03772670403122902, -0.14815016090869904, -0.04345310851931572, 0.09452292323112488, -0.11206657439470291, -0.021978093311190605, -0.01839502342045307, -0.10872568935155869, 0.018210897222161293, -0.05678640305995941, -0.11890171468257904, 0.034855637699365616, -0.041596975177526474, 0.08634115755558014, -0.12367258220911026, -0.21247892081737518, 0.026230579242110252, -0.009153340943157673, 0.059915799647569656, 0.06455971300601959, -0.019001122564077377, -0.08759415149688721, 0.037355534732341766, 0.02765602432191372, 0.035336993634700775, 0.008762892335653305, 0.015375775285065174, -0.03816545754671097, -0.11610373109579086, 0.06259933859109879, -0.031032171100378036, 0.10895945876836777, -0.13768547773361206, -0.0342567004263401, -0.055592022836208344, -0.007222585845738649, 0.018121417611837387, -0.009283468127250671, -0.060209378600120544, -0.10038794577121735, 0.1183289885520935, 0.014903328381478786, 0.010600777342915535, -0.08008436113595963, 0.0611368790268898, -0.11048242449760437, -0.003232744289562106, 0.04137737303972244, -0.05811966583132744, 0.0014506122097373009, -0.11805711686611176, 0.02812342718243599, 0.185650035738945, -0.08947671204805374, -0.047575078904628754, -0.0722295418381691, -0.016601437702775, -0.11214141547679901, -0.06007546931505203, -0.12090100347995758, 0.06964953243732452, -0.020871533080935478, -0.013534453697502613, -0.0504571869969368, 0.04852944612503052, 0.07453096657991409, -0.0013495845487341285, 0.11207710206508636, -0.021368008106946945, 0.02859330177307129, -0.1317135989665985, -0.06364098936319351, 0.18922360241413116, 0.07379505038261414, 0.010724366642534733, -0.15267729759216309, 0.040857937186956406, -0.07917701452970505, 0.06269506365060806, -0.0770593136548996, 0.07753340154886246, -0.12933674454689026, -0.01031741313636303, 0.06021255627274513, 0.10869712382555008, -0.050163544714450836, 0.017124785110354424, 0.0264345183968544, -0.11304138600826263, 0.008832874707877636, 0.1854521632194519, 0.005632470361888409, 0.019517187029123306, -0.048688046634197235, -0.07848669588565826, 0.054180677980184555, -0.014781376346945763, -0.02073545940220356, 0.025878118351101875, 0.08689795434474945, 0.0682043582201004, 0.07653313130140305, 0.17379780113697052, 0.137324258685112, 0.09323041141033173, -0.12456002086400986, 0.050578851252794266, 0.11405038088560104, -0.023984631523489952, 0.06366516649723053, 0.17671312391757965, 0.055283885449171066, -0.07526564598083496, 0.09213033318519592, -0.07615136355161667, 0.1701907217502594, -0.15910449624061584, 0.08804463595151901, -0.12668640911579132, 0.08588548004627228, 0.001608460326679051, -0.110032819211483, -0.11462318897247314, 2.2245826513128696e-32, -0.0034717724192887545, -0.008696169592440128, 0.0006379036931321025, -0.11478186398744583, -0.01581617258489132, 0.09168468415737152, 0.03807883709669113, -0.04118818789720535, -0.11569845676422119, 0.052175428718328476, -0.20182360708713531, -0.07573935389518738, -0.1147574931383133, 0.10493386536836624, 0.0044114114716649055, -0.10620429366827011, 0.0048195370472967625, 0.08838385343551636, 0.0770515501499176, 0.008550980128347874, 0.2502942979335785, -0.04903775826096535, -0.12154148519039154, -0.03347432240843773, -0.08053155988454819, 0.14442060887813568, -0.014163017272949219, 0.00704998942092061, -0.13653990626335144, 0.019290434196591377, -0.14891166985034943, -0.009365580044686794, 0.013596300035715103, -0.018219269812107086, 0.047751523554325104, -0.11895395815372467, 0.07958211749792099, 0.16867054998874664, 0.08176874369382858, -0.09201768785715103, -0.050894975662231445, 0.0867786705493927, 0.04692952334880829, -0.0770617350935936, -0.1878058761358261, -0.020389338955283165, 0.04313189536333084, 0.12718631327152252, 0.040084466338157654, 0.044863760471343994, -0.014251003041863441, -0.11955954134464264, -0.0941319614648819, -0.07753284275531769, -0.0056272391229867935, -0.10415535420179367, 0.1740880012512207, 0.07470355182886124, 0.2213851511478424, -0.005925691220909357, 0.11334483325481415, 0.042517710477113724, -0.08507879823446274, 0.06393402069807053, -0.02775527536869049, -0.0027591583784669638, 0.004584380425512791, 0.00109823327511549, -0.0362996831536293, 0.05497993528842926, -0.17349465191364288, 0.1142229437828064, 0.04788735508918762, -0.09765192121267319, 0.2443978488445282, -0.14320644736289978, 0.08372994512319565, -0.1417979896068573, -0.24399015307426453, 0.015759697183966637, -0.11874613910913467, 0.14717723429203033, -0.06690149009227753, -0.2827564477920532, -0.0867253988981247, -0.1299147605895996, 0.025276796892285347, -0.07721400260925293, -0.08894715458154678, -0.10681881010532379, -0.19120797514915466, -0.026192249730229378, 0.011848301626741886, 0.13400712609291077, -0.11265882849693298, -1.9723090739989292e-32, 0.02155507542192936, 0.169348806142807, 0.05594857037067413, 0.08377517014741898, 0.08708290755748749, 0.024633998051285744, 0.06361474096775055, 0.01708889566361904, -0.008879955857992172, -0.19716602563858032, 0.008673857897520065, -0.07413886487483978, -0.15699170529842377, -0.007373266387730837, 0.037986837327480316, -0.031215032562613487, 0.0046563223004341125, 0.06697746366262436, -0.0038490593433380127, -0.0067141298204660416, -0.15007929503917694, 0.15537822246551514, -0.20159602165222168, 0.012013602070510387, -0.13255397975444794, 0.10859257727861404, -0.006803824566304684, 0.16709363460540771, 0.0012499509612098336, -0.04346334561705589, -0.02505432441830635, 0.012372320517897606, -0.0741722509264946, 0.13352343440055847, 0.028745552524924278, 0.0938749611377716, 0.08326362073421478, -0.07555034011602402, -0.029483065009117126, 0.1028769314289093, 0.2656460106372833, 0.056108489632606506, -0.07095033675432205, 0.11458055675029755, -0.03463110700249672, -0.013152088038623333, -0.05856165662407875, -0.0975903794169426, -0.07048406451940536, 0.014614620245993137, 0.09514345228672028, -0.05545205622911453, -0.07043415307998657, 0.050960980355739594, -0.027421072125434875, 0.003587286453694105, 0.014830531552433968, -0.03231046348810196, -0.01697378233075142, 0.007054607849568129, -0.02471560426056385, -0.07632119953632355, 0.03314969688653946, -0.0747019499540329, -0.012448440305888653, 0.06015455350279808, -0.11035268753767014, 0.139126256108284, 0.040847763419151306, 0.16016319394111633, -0.0792948380112648, 0.10584771633148193, 0.12648098170757294, 0.04510868340730667, -0.055495359003543854, 0.0366540253162384, -0.1046031191945076, 0.0005672644474543631, 0.07991451025009155, 0.02107708714902401, -0.021990885958075523, 0.0042502377182245255, 0.049169786274433136, 0.08887480944395065, 0.02187206968665123, 0.18806956708431244, 0.04584202915430069, 0.1956804245710373, 0.0566680021584034, -0.06857310980558395, 0.011315244249999523, -0.1023043766617775, 0.18033289909362793, 0.17364007234573364, 0.10350173711776733, -1.009166794574412e-07, -0.006329243537038565, 0.014739428646862507, 0.03113291785120964, 0.15322764217853546, 9.521026368020102e-05, 0.0003228644491173327, 0.05163160711526871, 0.09413553774356842, -0.004255958367139101, -0.07837584614753723, 0.052546922117471695, -0.01768040470778942, -0.05441883206367493, 0.04836604744195938, -0.01574471965432167, 0.07922039926052094, 0.015561970882117748, -0.019717512652277946, 0.05961194261908531, -0.10493873804807663, -0.07504597306251526, -0.08780495077371597, -0.03333320841193199, -0.05574885010719299, -0.05240288004279137, -0.0804077535867691, -0.027945317327976227, 0.06531963497400284, 0.02775513008236885, -0.03451067954301834, 0.02236921526491642, -0.0928388461470604, -0.00047826595255173743, 0.1553993821144104, 0.07860025018453598, 0.1185787096619606, 0.035247236490249634, 0.07982537895441055, 0.06098461523652077, 0.08072470873594284, -0.17344261705875397, 0.08036889880895615, -0.05351608991622925, -0.09009008854627609, 0.052162446081638336, 0.009299566969275475, -0.018877573311328888, -0.07744002342224121, 0.055874668061733246, 0.09147098660469055, 0.0351407565176487, 0.035379376262426376, -0.16043442487716675, 0.13134345412254333, 0.11908788979053497, -0.1807572841644287, -0.08389295637607574, -0.06207532063126564, -0.019574100151658058, 0.007752450183033943, 0.0011491331970319152, -0.10365363210439682, -0.14158709347248077, -0.08207451552152634], metadata={'source': 'AAAMLP-569to.pdf', 'page': 215}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 216     :param data_loader: torch dataset loader     :param model: model     :param criterion: loss function     :param optimizer: adam, sgd, etc.     \"\"\"     # put the model in train mode     model.train()      # calculate number of batches     num_batches = int(len(dataset) / data_loader.batch_size)      # init tqdm to track progress     tk0 = tqdm(data_loader, total=num_batches)      # loop over all batches     for d in tk0:         # fetch input images and masks          # from dataset batch         inputs = d[\"image\"]         targets = d[\"mask\"]          # move images and masks to cpu/gpu device         inputs = inputs.to(DEVICE, dtype=torch.float)         targets = targets.to(DEVICE, dtype=torch.float)          # zero grad the optimizer         optimizer.zero_grad()          # forward step of model         outputs = model(inputs)          # calculate loss         loss = criterion(outputs, targets)          # backward loss is calculated on a scaled loss         # context since we are using mixed precision training         # if you are not using mixed precision training,         # you can use loss.backward() and delete the following         # two lines of code         with amp.scale_loss(loss, optimizer) as scaled_loss:             scaled_loss.backward()                  # step the optimizer         optimizer.step()      # close tqdm     tk0.close()'),\n",
       " VectorParams(vector=[-0.05861503630876541, -0.028030863031744957, -0.049727097153663635, 0.05922039598226547, 0.10307627171278, -0.06498873233795166, 0.00516017759218812, 0.1270134150981903, -0.11377202719449997, -0.059273917227983475, -0.0007407217635773122, -0.11113432049751282, 0.0005099813570268452, -0.10158481448888779, -0.12267174571752548, 0.028955139219760895, -0.17954552173614502, -0.014859619550406933, -0.14274410903453827, -0.17432472109794617, 0.08520057797431946, 0.022215425968170166, 0.1055210754275322, 0.08774473518133163, -0.07465275377035141, -0.025905493646860123, 0.032754085958004, 0.07138153910636902, -0.04701834172010422, -0.07527129352092743, 0.02066517062485218, 0.018104130402207375, -0.05868351832032204, 0.033377185463905334, 0.11378626525402069, 0.09498139470815659, -0.11328183859586716, 0.02584378607571125, -0.06052583083510399, 0.0507550984621048, -0.019389115273952484, -0.0882292091846466, -0.030041279271245003, -0.0423564538359642, 0.06347153335809708, 0.025186149403452873, 0.0031913723796606064, -0.09069256484508514, 0.0976259633898735, -0.0629621371626854, -0.06578250229358673, 0.06151135638356209, -0.13527129590511322, 0.03613852337002754, -0.05032885819673538, -0.08847150951623917, 0.12804698944091797, -0.09372331202030182, -0.07539843022823334, -0.07159697264432907, -0.04956221580505371, -0.05787389352917671, -0.0134363304823637, -0.09528303146362305, -0.023166080936789513, -0.026225518435239792, -0.040044452995061874, 0.013064154423773289, 0.03222796320915222, -0.004659449681639671, -0.07713394612073898, 0.14328795671463013, -0.07273818552494049, 0.11366768926382065, -0.13619405031204224, -0.03584327921271324, 0.18574069440364838, 0.03131706267595291, 0.08062082529067993, -0.19701044261455536, -0.08862722665071487, -0.037969302386045456, 0.10271912813186646, -0.12450286746025085, 0.11164824664592743, -0.13443711400032043, 0.03446855768561363, 0.07548844069242477, 0.07875481247901917, -0.06151651591062546, 0.0442720465362072, 0.026621095836162567, -0.06773295253515244, 0.08147970587015152, 0.14360164105892181, 0.07303465157747269, 0.08108451962471008, -0.029192106798291206, -0.06061927601695061, 0.07650592923164368, -0.03675162047147751, -0.042569905519485474, -0.07430002093315125, 0.05799376592040062, 0.04648903012275696, 0.06467698514461517, 0.17402848601341248, 0.10724349319934845, 0.04581606388092041, -0.10096998512744904, 0.08617182821035385, 0.10376783460378647, 0.0033288279082626104, 0.014971752651035786, 0.1002759113907814, 0.05945071205496788, -0.06001663953065872, 0.10035271942615509, -0.1562897115945816, 0.20330318808555603, -0.13363556563854218, 0.04412109777331352, -0.05104583874344826, 0.06275695562362671, -0.06933962553739548, -0.16983367502689362, -0.06909844279289246, 2.0344875823696434e-32, -0.05426580831408501, -0.057661835104227066, -0.04885111749172211, -0.09317050129175186, -0.07154915481805801, 0.03850023075938225, 0.09935829788446426, -0.03608044236898422, -0.09589661657810211, -0.007948258891701698, -0.2076764702796936, -0.0833825096487999, -0.0994148701429367, 0.0438874289393425, -0.002371639246121049, -0.01887708529829979, -0.029598895460367203, 0.06090926378965378, 0.08484992384910583, -0.03886719048023224, 0.2707558274269104, -0.027662307024002075, -0.09477123618125916, -0.038708217442035675, -0.09210804849863052, 0.07205843925476074, -0.0002993448870256543, 0.022139742970466614, -0.09732183068990707, 0.013488463126122952, -0.1574704498052597, -0.0035347333177924156, 0.02766304276883602, -0.03859464079141617, 0.06456136703491211, -0.10447193682193756, 0.07192502915859222, 0.13244931399822235, -0.011247599497437477, -0.11143530160188675, -0.07552710920572281, 0.09395217895507812, 0.057331595569849014, -0.08090250194072723, -0.1586924046278, -0.04524105787277222, 0.0014965850859880447, 0.13594183325767517, 0.033559806644916534, 0.0081017529591918, -0.11839617043733597, -0.1354084610939026, -0.002686253748834133, 0.03826228156685829, -0.09319029748439789, 0.015983078628778458, 0.08248863369226456, 0.018476517871022224, 0.16101883351802826, -0.06618306040763855, 0.08789309114217758, 0.08580075949430466, -0.07468218356370926, 0.05708222836256027, -0.053257666528224945, -0.041726090013980865, 0.06132073327898979, 0.027075862511992455, -0.005663038231432438, 0.008264920674264431, -0.1268959790468216, 0.052630189806222916, 0.010100092738866806, -0.0901990532875061, 0.14535078406333923, -0.20891696214675903, 0.057131536304950714, -0.06178097426891327, -0.18965637683868408, 0.04450567066669464, -0.007131734862923622, 0.13725081086158752, -0.09905106574296951, -0.254428505897522, -0.042905889451503754, -0.04045714810490608, 0.04939983785152435, -0.09242822229862213, -0.1597347855567932, -0.10673163831233978, -0.21686868369579315, -0.03783775493502617, 0.04221464321017265, -0.03373953327536583, -0.08295585960149765, -1.814468100674328e-32, 0.06318139284849167, 0.14997830986976624, 0.10016297549009323, 0.08932355046272278, 0.10011421144008636, 0.022946719080209732, 0.06520698964595795, 0.04014704003930092, -0.09856779873371124, -0.07252375036478043, 0.015265571884810925, -0.1332511603832245, -0.11900108307600021, -0.01978895254433155, 0.022811032831668854, -0.017540981993079185, -0.06950853019952774, 0.03507421165704727, -0.022222287952899933, 0.03335065767168999, -0.11504072695970535, 0.19956155121326447, -0.17635761201381683, -0.011401393450796604, -0.1744970828294754, 0.0810035690665245, -0.0016948574921116233, 0.15315362811088562, -0.0536980926990509, -0.027869032695889473, 0.018665507435798645, 0.011392570100724697, -0.1561112105846405, 0.13726212084293365, 0.005794106051325798, 0.0024677636101841927, 0.22108633816242218, -0.09114681929349899, -0.09712180495262146, 0.17415626347064972, 0.20547829568386078, 0.13817326724529266, -0.12349390983581543, 0.08113144338130951, -0.050623420625925064, 0.03365696221590042, 0.013348967768251896, -0.045927610248327255, -0.09205181151628494, 0.00971880741417408, 0.04537969455122948, -0.10856273025274277, -0.14039361476898193, 0.07865535467863083, 0.04372158274054527, -0.022477131336927414, 0.047195110470056534, -0.03196382895112038, -0.14489641785621643, -0.004213101230561733, -0.020651821047067642, -0.058263279497623444, -0.028548141941428185, -0.03136811777949333, 0.09827816486358643, 0.08733559399843216, -0.11310092359781265, 0.11838056147098541, 0.09207787364721298, 0.12359225004911423, -0.12304951250553131, 0.11204630136489868, 0.11964818090200424, 0.02249559760093689, -0.008674908429384232, 0.11424731463193893, -0.07808978110551834, 0.018725784495472908, 0.09784258902072906, 0.056534070521593094, -0.02812337875366211, -0.06744946539402008, 0.06438423693180084, 0.11987467110157013, 0.0021274895407259464, 0.16808931529521942, 0.12144836783409119, 0.12457933276891708, 0.0012778769014403224, -0.06252548098564148, 0.0005713568534702063, -0.07641785591840744, 0.20789344608783722, 0.14555852115154266, 0.02093840390443802, -1.0104361081175739e-07, -0.028153864666819572, 0.001538031967356801, 0.032852478325366974, 0.08312471956014633, -0.019642001017928123, -0.05697711929678917, -0.005380142945796251, 0.022464029490947723, 0.01530725508928299, -0.03217465057969093, 0.1435624659061432, -0.04250364750623703, -0.06649269163608551, 0.06918937712907791, -0.04050714150071144, 0.05583415925502777, 0.05015507712960243, 0.07612711936235428, 0.02656371332705021, -0.013860756531357765, 0.04924579709768295, -0.0781761184334755, 0.002054201904684305, -0.018994832411408424, 0.0716087594628334, -0.07769186049699783, -0.0069943577982485294, 0.04990103095769882, -0.010049013420939445, -0.014170111157000065, 0.04017547518014908, -0.13217693567276, 0.07998356968164444, 0.07526015490293503, 0.09753621369600296, 0.11555632948875427, 0.07726725190877914, 0.017169669270515442, 0.061844903975725174, 0.10754147917032242, -0.13505145907402039, 0.05811008810997009, -0.049297019839286804, -0.046207528561353683, 0.1440887153148651, -0.013843992725014687, -0.02448088675737381, -0.04768811911344528, 0.06871119141578674, 0.0569995641708374, -0.011451024562120438, -0.0381811149418354, -0.042931221425533295, 0.11274969577789307, 0.14834164083003998, -0.16303858160972595, -0.03682262450456619, 0.016361908987164497, 0.06083599850535393, -0.023456942290067673, 0.06253683567047119, -0.034535013139247894, -0.06458397954702377, -0.08685241639614105], metadata={'source': 'AAAMLP-569to.pdf', 'page': 216}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 217 def evaluate(dataset, data_loader, model):     \"\"\"     evaluation function to calculate loss on validation     set for one epoch     :param dataset: dataset class (SIIMDataset)     :param data_loader: torch dataset loader     :param model: model     \"\"\"     # put model in eval mode     model.eval()     # init final_loss to 0     final_loss = 0     # calculate number of batches and init tqdm     num_batches = int(len(dataset) / data_loader.batch_size)     tk0 = tqdm(data_loader, total=num_batches)      # we need no_grad context of torch. this save memory     with torch.no_grad():         for d in tk0:             inputs = d[\"image\"]             targets = d[\"mask\"]             inputs = inputs.to(DEVICE, dtype=torch.float)             targets = targets.to(DEVICE, dtype=torch.float)             output = model(inputs)             loss = criterion(output, targets)             # add loss to final loss             final_loss += loss     # close tqdm     tk0.close()     # return average loss over all batches     return final_loss / num_batches   if __name__ == \"__main__\":      # read the training csv file     df = pd.read_csv(TRAINING_CSV)      # split data into training and validation     df_train, df_valid = model_selection.train_test_split(         df, random_state=42, test_size=0.1     )      # training and validation images lists/arrays     training_images = df_train.image_id.values     validation_images = df_valid.image_id.values'),\n",
       " VectorParams(vector=[-0.07543732970952988, -0.13418374955654144, 0.027928970754146576, 0.13723450899124146, 0.08515479415655136, -0.16107749938964844, -0.048968277871608734, 0.06014123558998108, -0.24487143754959106, -0.15861546993255615, 0.03947104886174202, -0.1125158965587616, -0.0684705302119255, 0.00015550624812021852, -0.0516253262758255, 0.03094392642378807, -0.013594658114016056, 0.12992528080940247, -0.23131459951400757, -0.16441531479358673, 0.14070682227611542, -0.013719450682401657, 0.1115327998995781, -0.0026291003450751305, 0.027330787852406502, -0.0878702849149704, 0.06631463766098022, -0.01563938707113266, 0.07551422715187073, -0.06411053240299225, 0.09056031703948975, 0.00360358995385468, -0.006575681734830141, 0.10372063517570496, 0.15066108107566833, -0.08245595544576645, -0.1263938993215561, -0.12390507012605667, -0.021840453147888184, 0.029098443686962128, 0.02068840153515339, -0.03517168387770653, -0.13661514222621918, -0.14275851845741272, 0.022825203835964203, 0.040897250175476074, 0.06147707253694534, -0.05116058886051178, 0.009844325482845306, -0.15397262573242188, -0.0451824814081192, 0.02557731606066227, -0.08596723526716232, 0.054401643574237823, -0.06101975217461586, -0.11573630571365356, 0.11132030189037323, -0.10236465930938721, 0.009175656363368034, -0.10762403160333633, -0.04775914177298546, -0.048519209027290344, -0.07198679447174072, -0.04924953728914261, -0.10862286388874054, 0.0351482518017292, 0.04081261530518532, -0.06850694864988327, 0.1206124946475029, -0.039989735931158066, -0.001613990287296474, 0.0941133126616478, -0.0235991720110178, 0.1154593825340271, -0.003431218909099698, 0.01698506996035576, 0.22146320343017578, 0.1213153749704361, 0.044505055993795395, -0.2443474680185318, -0.06033658608794212, -0.03932580351829529, 0.15642791986465454, 0.012592623010277748, 0.20746633410453796, -0.08792606741189957, -0.06651856750249863, 0.12606145441532135, 0.017650056630373, 0.034575171768665314, -0.08158301562070847, 0.09698712080717087, -0.20710383355617523, 0.020605942234396935, 0.09627896547317505, -0.015958748757839203, 0.06259449571371078, -0.015106895007193089, -0.13230431079864502, 0.09535569697618484, -0.08419391512870789, -0.07002854347229004, -0.017296869307756424, 0.12260394543409348, 0.121424600481987, 0.11834091693162918, 0.15560686588287354, 0.10803309828042984, -0.007828197441995144, -0.08682640641927719, 0.13252459466457367, 0.04851450398564339, -0.05394181236624718, -0.048070937395095825, 0.13273881375789642, -0.0096916938200593, -0.08415044844150543, 0.07082907110452652, -0.15130272507667542, 0.13559845089912415, -0.08319544047117233, 0.045339666306972504, -0.13156989216804504, 0.06250368058681488, -0.037709955126047134, -0.12560375034809113, -0.14258413016796112, 2.3600790933330715e-32, -0.0637924075126648, -0.07260451465845108, -0.05275460705161095, -0.10772230476140976, -0.044788338243961334, 0.06168040633201599, 0.07298154383897781, -0.044487155973911285, -0.11098077148199081, -0.018171487376093864, -0.0857260450720787, -0.08305487036705017, -0.06395276635885239, 0.11561932414770126, -0.04109104722738266, -0.07722017914056778, 0.06850523501634598, 0.08073893189430237, 0.07332967966794968, 0.03305540978908539, 0.20564484596252441, -0.009413164108991623, -0.10066653788089752, -0.0372462160885334, -0.1405855268239975, 0.08410856872797012, -0.10134445875883102, -0.05048522353172302, -0.04472512751817703, 0.019968127831816673, -0.11490263044834137, 0.05273083597421646, 0.16593973338603973, 0.02240164391696453, -0.06121281534433365, -0.06519020348787308, 0.09450294077396393, 0.08027158677577972, -0.009166735224425793, 0.002876545302569866, 0.132053941488266, 0.12772923707962036, 0.0694538950920105, -0.16689810156822205, -0.13003359735012054, 0.02715081162750721, -0.04887954890727997, 0.15511959791183472, 0.019374597817659378, 0.029202193021774292, 0.00810566358268261, -0.038078632205724716, 0.027145547792315483, -0.13936962187290192, -0.009990415535867214, -0.0288142841309309, 0.17041704058647156, 0.057777225971221924, 0.17664574086666107, -0.10598605126142502, 0.021121157333254814, 0.012784586288034916, -0.046252503991127014, 0.10011178255081177, 0.016799306496977806, -0.05311259627342224, 0.0012382841669023037, -0.05366380885243416, -0.10738480091094971, 0.0032781343907117844, -0.18498481810092926, 0.17148225009441376, -0.04228349030017853, -0.050480592995882034, 0.07678937166929245, -0.16169783473014832, -0.024478590115904808, 0.007863697595894337, -0.267835408449173, 0.11958868056535721, -0.100110724568367, 0.240268737077713, -0.08404068648815155, -0.20339782536029816, -0.06879233568906784, 0.004843974020332098, 0.017498619854450226, -0.028870588168501854, -0.10355037450790405, -0.0237429216504097, -0.06449184566736221, -0.12356223911046982, 0.08014920353889465, 0.014960713684558868, -0.05140121281147003, -1.8517541937352356e-32, 0.06759938597679138, 0.21676841378211975, 0.015548670664429665, 0.13784189522266388, -0.07165107876062393, 0.05466056615114212, 0.056582801043987274, 0.13281460106372833, -0.12684266269207, -0.14699353277683258, 0.11942587792873383, -0.1326606720685959, -0.09293106198310852, -0.16434256732463837, 0.06209295615553856, -0.08370719105005264, -0.054981790482997894, 0.05340932309627533, 0.08097779750823975, 0.10148035734891891, -0.10333988815546036, 0.2553038001060486, -0.15873397886753082, 0.032970551401376724, -0.18194837868213654, 0.09719901531934738, -0.09433583170175552, 0.1919400542974472, 0.026509948074817657, -0.04076506197452545, 0.020609665662050247, 0.08492851257324219, -0.1369379311800003, -0.07423039525747299, -0.03936639055609703, 0.010696358047425747, 0.10363896936178207, -0.030984461307525635, -0.03859101980924606, 0.13782228529453278, 0.17614299058914185, 0.07519015669822693, -0.13571041822433472, 0.15777021646499634, -0.06960001587867737, -0.048708196729421616, 0.019240902736783028, -0.04734773188829422, -0.11111556738615036, 0.00358373299241066, 0.022523410618305206, -0.08514581620693207, -0.1694280058145523, -0.012948304414749146, 0.021606018766760826, 0.05845596268773079, 0.014859399758279324, -0.07172334939241409, -0.029294699430465698, -0.02939991094172001, -0.005749621894210577, -0.09250134974718094, 0.007707560900598764, -0.08288458734750748, 0.003783486085012555, 0.06617149710655212, -0.0882296934723854, 0.10854116827249527, 0.019584447145462036, 0.08325979858636856, -0.04665369912981987, 0.07988686114549637, 0.1341262012720108, 0.1273234486579895, 0.011101588606834412, 0.024876706302165985, -0.021535303443670273, 0.049549926072359085, 0.12445414811372757, 0.016061007976531982, -0.1483147293329239, -0.117738738656044, 0.04673193767666817, 0.11837665736675262, 0.11385554820299149, 0.2009516954421997, 0.0715106800198555, 0.12266718596220016, 0.061155010014772415, -0.11849013715982437, -0.04690023884177208, -0.139067143201828, 0.19662511348724365, 0.1948310136795044, 0.08473917096853256, -1.0056590582507852e-07, -0.047813404351472855, 0.019675293937325478, -0.029383886605501175, 0.1541946679353714, -0.06803109496831894, -0.034172311425209045, 0.07467988133430481, 0.050319015979766846, -0.0356469564139843, -0.04205501079559326, 0.0568074993789196, -0.03426627814769745, -0.0909041091799736, -0.021288014948368073, 0.004661419428884983, 0.13874056935310364, 0.08429877460002899, 0.10213963687419891, 0.05142097920179367, -0.05894467979669571, -0.07320475578308105, -0.06734278798103333, 0.018659453839063644, -0.018342889845371246, 0.03194331377744675, -0.021074792370200157, -0.06133078411221504, 0.0672076940536499, 0.04259651526808739, -0.045564208179712296, 0.0028713278006762266, -0.13661715388298035, 0.19054850935935974, 0.16240866482257843, 0.08891813457012177, 0.04377487301826477, -0.02419155463576317, -0.0013872318668290973, 0.06039715185761452, 0.0009525934001430869, 0.03754834085702896, 0.0663769543170929, -0.02213982865214348, -0.12980902194976807, 0.045438434928655624, 0.05352524295449257, 0.10747568309307098, -0.09619706869125366, 0.0010157099459320307, 0.04175909236073494, 0.022557729855179787, 0.03204019367694855, -0.10316910594701767, 0.1693122386932373, 0.11965734511613846, -0.1376374363899231, 0.08194243907928467, 0.01280900090932846, 0.05183300003409386, 0.10527795553207397, 0.013734240084886551, -0.020530443638563156, -0.19793477654457092, -0.07175037264823914], metadata={'source': 'AAAMLP-569to.pdf', 'page': 217}, content=\"Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 218     # fetch unet model from segmentation models     # with specified encoder architecture     model = smp.Unet(         encoder_name=ENCODER,         encoder_weights=ENCODER_WEIGHTS,         classes=1,         activation=None,     )     # segmentation model provides you with a preprocessing     # function that can be used for normalizing images     # normalization is only applied on images and not masks     prep_fn = smp.encoders.get_preprocessing_fn(         ENCODER,         ENCODER_WEIGHTS     )      # send model to device     model.to(DEVICE)     # init training dataset     # transform is True for training data     train_dataset = SIIMDataset(         training_images,         transform=True,         preprocessing_fn=prep_fn,     )      # wrap training dataset in torch's dataloader     train_loader = torch.utils.data.DataLoader(         train_dataset,         batch_size=TRAINING_BATCH_SIZE,          shuffle=True,         num_workers=12     )      # init validation dataset     # augmentations is disabled     valid_dataset = SIIMDataset(         validation_images,         transform=False,         preprocessing_fn=prep_fn,     )      # wrap validation dataset in torch's dataloader     valid_loader = torch.utils.data.DataLoader(         valid_dataset,          batch_size=TEST_BATCH_SIZE,          shuffle=True,\"),\n",
       " VectorParams(vector=[-0.11175992339849472, 0.022256115451455116, -0.02963600680232048, 0.11301226168870926, 0.0289989672601223, -0.12097997218370438, -0.07428949326276779, 0.09302696585655212, -0.22708576917648315, -0.15346182882785797, -0.0627060979604721, -0.10103264451026917, -0.011671704240143299, -0.008516385219991207, -0.051625967025756836, 0.026824820786714554, -0.08067410439252853, 0.04528552293777466, -0.11583220958709717, -0.15176548063755035, 0.15515504777431488, 0.016804782673716545, 0.05977386236190796, 0.005904680583626032, -0.04957086965441704, -0.034542057663202286, -0.02062349207699299, -0.027530375868082047, 0.04929863661527634, -0.04454558342695236, 0.13011430203914642, 0.021855875849723816, -0.04473697021603584, 0.09688510000705719, 0.07856288552284241, 0.040402501821517944, -0.127938911318779, -0.1240522563457489, -0.019134707748889923, 0.0026418950874358416, 0.07663881033658981, -0.004862949252128601, -0.062368396669626236, -0.07423046231269836, 0.1471910923719406, 0.02816757746040821, 0.014391670934855938, -0.042942266911268234, 0.03781236708164215, -0.07157286256551743, -0.03951793909072876, -0.051377903670072556, -0.08208734542131424, -0.004399764817208052, -0.035594694316387177, -0.06045848876237869, 0.06229395046830177, -0.17421092092990875, -0.026515211910009384, -0.062082044780254364, 0.09898923337459564, -0.1553492397069931, -0.12652979791164398, -0.02223331667482853, -0.0010888021206483245, -0.045215632766485214, 0.08069967478513718, -0.05670400336384773, 0.07556921243667603, 0.06963840126991272, 0.024654125794768333, 0.13801293075084686, -0.04474285989999771, 0.04085671901702881, -0.07720295339822769, -0.011442041024565697, 0.20839789509773254, 0.036186352372169495, 0.05835416540503502, -0.15169958770275116, -0.0557941198348999, -0.015214674174785614, 0.09606320410966873, -0.08156269788742065, 0.13104760646820068, -0.1208999752998352, 0.0907655656337738, 0.027845997363328934, 0.10573559254407883, -0.1133875697851181, 0.0058509912341833115, 0.06790987402200699, -0.07758146524429321, 0.0553281269967556, 0.062101516872644424, 0.0453047938644886, 0.08269043266773224, -0.04999517649412155, -0.1361973136663437, 0.16784076392650604, -0.04227456822991371, -0.048385679721832275, 0.05158873647451401, 0.07892941683530807, 0.046355970203876495, 0.09736765921115875, 0.10705503076314926, 0.10336597263813019, -0.016036147251725197, -0.03957194834947586, 0.12510520219802856, 0.09369994699954987, -0.027691619470715523, 0.041227009147405624, 0.12637649476528168, 0.0881849080324173, -0.07406708598136902, 0.0033546346239745617, -0.055049147456884384, 0.17949210107326508, -0.10252729058265686, 0.024993175640702248, -0.009061732329428196, 0.03877744451165199, -0.0009160488261841238, -0.09354794025421143, -0.13165560364723206, 1.8693711806342153e-32, -0.026207124814391136, -0.05354560166597366, -0.022389430552721024, -0.18423748016357422, 0.0907544270157814, 0.07283520698547363, 0.057247620075941086, 0.0440821498632431, -0.05185071751475334, -0.02441323734819889, -0.23961086571216583, 0.016590269282460213, -0.0746360719203949, 0.13057273626327515, 0.03443593531847, -0.10051775723695755, 0.00810554064810276, 0.09745881706476212, 0.11471924930810928, 0.06070231273770332, 0.17499853670597076, -0.1252976953983307, -0.13366684317588806, 0.006576322019100189, -0.12672743201255798, 0.0712815672159195, 0.009529815055429935, -0.024239350110292435, -0.11287704855203629, 0.020133687183260918, -0.09446947276592255, -0.01689988560974598, 0.029922418296337128, 0.00361939100548625, 0.042543575167655945, -0.11414381861686707, 0.059326864778995514, 0.13149507343769073, 0.024898426607251167, -0.08368340134620667, -0.015330520458519459, 0.1179920956492424, 0.02893827110528946, -0.13921035826206207, -0.11633098125457764, -0.04053758457303047, -0.006266909651458263, 0.08497335761785507, 0.018752487376332283, 0.05658460780978203, -0.02317076176404953, -0.05459756776690483, -0.04260082542896271, -0.09691636264324188, 0.024764737114310265, -0.0587645061314106, 0.09230264276266098, 0.11325301229953766, 0.16905829310417175, -0.04917677491903305, 0.0480569489300251, -0.012720917351543903, -0.0757717490196228, 0.004221690818667412, -0.00760244857519865, -0.01619129814207554, 0.04997040703892708, 0.04702496901154518, -0.018835334107279778, 0.06095349043607712, -0.2065763771533966, 0.09567540138959885, 0.042681824415922165, -0.1555277556180954, 0.19817307591438293, -0.15870365500450134, 0.11004316061735153, -0.03280266746878624, -0.19583162665367126, 0.005225741304457188, -0.049261562526226044, 0.21240739524364471, -0.08573659509420395, -0.1339212954044342, -0.11937233060598373, -0.03702931106090546, 0.0726223886013031, 0.0004519294307101518, -0.07235673069953918, -0.05156809836626053, -0.2042454034090042, -0.03289142623543739, 0.08125530183315277, -0.01097402349114418, -0.0014434868935495615, -1.3461036907223142e-32, 0.1223788782954216, 0.0715944766998291, 0.06984574347734451, 0.14167489111423492, 0.11432619392871857, -0.03312806412577629, 0.056479312479496, 0.021259041503071785, -0.07433536648750305, -0.14968150854110718, 0.03095274232327938, -0.05564657598733902, -0.033472947776317596, -0.06359579414129257, 0.002771110041067004, -0.0761665627360344, -0.1121208667755127, -0.021205319091677666, -0.021428845822811127, 0.07166816294193268, -0.07159586250782013, 0.1905488222837448, -0.14335615932941437, -0.04094693437218666, -0.0563984289765358, 0.05898546054959297, 0.04825279489159584, 0.11170344799757004, 0.008031917735934258, -0.08874493092298508, -0.016609949991106987, -0.021611981093883514, -0.1516033113002777, 0.059801384806632996, 0.10250432789325714, 0.0358111672103405, 0.12151245027780533, 0.02051836997270584, -0.055064450949430466, 0.2355111688375473, 0.2986242473125458, 0.11589686572551727, -0.08971256762742996, 0.09422527998685837, -0.008316117338836193, 0.06228620931506157, -0.0020185462199151516, -0.05322772264480591, -0.12725122272968292, 0.012359149754047394, 0.0430501252412796, -0.08040475100278854, -0.18883323669433594, 0.08398827910423279, 0.013774716295301914, -0.03912129998207092, 0.03435969352722168, -0.08290543407201767, -0.028073294088244438, 0.04919513314962387, -0.10721655935049057, -0.1237993910908699, 0.010514741763472557, -0.022958626970648766, 0.04540003463625908, -0.007955057546496391, -0.15588603913784027, 0.07993250340223312, -0.0055917538702487946, 0.22555504739284515, -0.06979113072156906, 0.055628690868616104, 0.0727832093834877, 0.07437702268362045, -0.15881414711475372, 0.02400791645050049, -0.004672605078667402, -0.065837562084198, 0.07721880078315735, -0.03184596449136734, -0.08384031057357788, -0.03938654065132141, 0.008372240699827671, 0.13491591811180115, 0.02912256494164467, 0.17703895270824432, 0.12193229049444199, 0.10652823746204376, 0.12566201388835907, -0.06036191061139107, -0.009292375296354294, -0.07722702622413635, 0.13414856791496277, 0.05617097020149231, 0.010637294501066208, -9.954693069857967e-08, -0.035898566246032715, 0.02289312519133091, 0.020132504403591156, 0.12108457833528519, 0.13405998051166534, 0.0016005313955247402, 0.01045265607535839, 0.028627701103687286, 0.07272395491600037, 0.01773904263973236, 0.2190074771642685, -0.011582087725400925, -0.08158951252698898, -0.017524540424346924, -0.012273860163986683, 0.13329987227916718, 0.0325065515935421, 0.08188516646623611, 0.003497002413496375, 0.017751695588231087, -0.016099870204925537, -0.06058275327086449, -0.010234257206320763, -0.020605044439435005, 0.0030121062882244587, -0.1197165697813034, 0.06588555872440338, 0.1137176975607872, 0.013962490484118462, -0.02607855387032032, -0.054411374032497406, -0.03280811756849289, 0.1551639288663864, 0.031398955732584, 0.0588373988866806, 0.04394911974668503, 0.02220817096531391, 0.07562162727117538, 0.0701473131775856, 0.05883340165019035, -0.038633402436971664, 0.08308049291372299, -0.060471974313259125, -0.10621050000190735, 0.09578493237495422, -0.034371133893728256, 0.00364030827768147, -0.07808833569288254, 0.0378447100520134, 0.10167844593524933, -0.07880629599094391, 0.0031288485042750835, -0.0511426143348217, 0.18083088099956512, -0.004768103361129761, -0.16363319754600525, -0.056855667382478714, -0.14687106013298035, -0.016047567129135132, 0.01963910274207592, 0.06353708356618881, -0.09177307039499283, -0.08248790353536606, -0.005733054596930742], metadata={'source': 'AAAMLP-569to.pdf', 'page': 218}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 219         num_workers=4     )      # NOTE: define the criterion here     # this is left as an excercise     # code won\\'t work without defining this     # criterion = ……      # we will use Adam optimizer for faster convergence     optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)     # reduce learning rate when we reach a plateau on loss     scheduler = lr_scheduler.ReduceLROnPlateau(         optimizer, mode=\"min\", patience=3, verbose=True     )     # wrap model and optimizer with NVIDIA\\'s apex     # this is used for mixed precision training     # if you have a GPU that supports mixed precision,     # this is very helpful as it will allow us to fit larger images     # and larger batches     model, optimizer = amp.initialize(         model, optimizer, opt_level=\"O1\", verbosity=0     )     # if we have more than one GPU, we can use both of them!     if torch.cuda.device_count() > 1:         print(f\"Let\\'s use {torch.cuda.device_count()} GPUs!\")         model = nn.DataParallel(model)      # some logging     print(f\"Training batch size: {TRAINING_BATCH_SIZE}\")     print(f\"Test batch size: {TEST_BATCH_SIZE}\")     print(f\"Epochs: {EPOCHS}\")     print(f\"Image size: {IMAGE_SIZE}\")     print(f\"Number of training images: {len(train_dataset)}\")     print(f\"Number of validation images: {len(valid_dataset)}\")     print(f\"Encoder: {ENCODER}\")      # loop over all epochs     for epoch in range(EPOCHS):         print(f\"Training Epoch: {epoch}\")         # train for one epoch         train(             train_dataset,              train_loader,              model,              criterion,              optimizer         )'),\n",
       " VectorParams(vector=[-0.04281947761774063, -0.013305828906595707, -0.012345925904810429, -0.035606011748313904, 0.1451248824596405, -0.08457089960575104, -0.07676642388105392, 0.0904746875166893, -0.010024665854871273, -0.07988566160202026, -0.10908810794353485, -0.16630327701568604, 0.08688987046480179, 0.14005416631698608, -0.15179894864559174, -0.06214122846722603, -0.1491290032863617, 0.09105358272790909, -0.16109608113765717, -0.005160307977348566, 0.1044430062174797, 0.23811905086040497, 0.03349696099758148, 0.025356745347380638, -0.07870582491159439, -0.12466276437044144, -0.07985096424818039, 0.05954211950302124, -0.007384429685771465, -0.02000107802450657, 0.06570055335760117, 0.052318114787340164, -0.03496463969349861, 0.011492419056594372, 0.011583192273974419, 0.09588146209716797, -0.03801684454083443, -0.0510706901550293, 0.006913056131452322, 0.09288810193538666, 0.05382698029279709, -0.02640891633927822, -0.055429086089134216, -0.021001892164349556, 0.07256590574979782, 0.07081009447574615, -0.0697161927819252, -0.056286413222551346, 0.06636354327201843, -0.03459781035780907, -0.047889478504657745, -0.09472432732582092, -0.15474358201026917, 0.10115677863359451, -0.070320263504982, -0.0502961166203022, 0.07420332729816437, -0.14110475778579712, -0.03265393152832985, -0.16334152221679688, 0.07417230308055878, -0.13997706770896912, -0.1062278300523758, -0.03268476203083992, -0.002230410696938634, -0.030419228598475456, -0.07671209424734116, -0.056221213191747665, 0.12084822356700897, 0.03061011992394924, -0.05122127756476402, 0.062112677842378616, -0.05725378915667534, 0.16319754719734192, -0.11522459983825684, 0.0296742245554924, 0.18445025384426117, 0.1096309944987297, 0.035259466618299484, -0.08641794323921204, 0.02550838701426983, 0.057945311069488525, 0.12369649112224579, -0.05661318451166153, 0.16521501541137695, 0.0030420112889260054, -0.050295598804950714, 0.11855711787939072, 0.028976881876587868, -0.018483979627490044, 0.1264515519142151, 0.06154616177082062, 0.008516020141541958, 0.07855545729398727, 0.06760098040103912, 0.09069833904504776, 0.14383061230182648, -0.14678855240345, -0.0006095097633078694, 0.09057408571243286, -0.1541188806295395, -0.1653374284505844, -0.0012754893396049738, -0.0232120119035244, 0.14584925770759583, 0.0007936385809443891, -0.02132553420960903, -0.07783354818820953, 0.14045386016368866, -0.12846119701862335, 0.07218284904956818, 0.0886484757065773, -0.11617135256528854, -0.0647728368639946, 0.12524199485778809, 0.11947239935398102, -0.11525987833738327, -0.05632420629262924, -0.08910233527421951, 0.109592966735363, -0.22030015289783478, -0.055645983666181564, -0.0667007565498352, 0.06449152529239655, 0.1609473079442978, -0.07206356525421143, -0.20202118158340454, 8.796354266265737e-33, -0.014815280213952065, -0.03046460822224617, 0.05617041513323784, -0.12942692637443542, 0.13082355260849, -0.05609745904803276, -0.013880990445613861, -0.03180038928985596, 0.05187532678246498, -0.0400066152215004, -0.18331117928028107, -0.036992207169532776, -0.04012627154588699, 0.06134296953678131, 0.09745366126298904, 0.0041749682277441025, -0.06776809692382812, 0.09318454563617706, -0.08551116287708282, 0.10502567142248154, 0.18876132369041443, -0.06497430801391602, 0.022205675020813942, -0.02739126980304718, -0.038311105221509933, 0.16378849744796753, 0.019896280020475388, -0.13091906905174255, 0.013350548222661018, 0.04055020585656166, -0.12100128829479218, -0.04594510421156883, 0.11719074100255966, -0.012640351429581642, -0.04373284801840782, -0.05156329646706581, -0.1296137422323227, 0.11737848073244095, -0.017138836905360222, -0.06929218769073486, -0.06461742520332336, 0.03629206120967865, 0.04677319899201393, -0.035607680678367615, 0.005229023285210133, -0.0378732830286026, 0.005415572784841061, 0.11113440245389938, -0.09163495153188705, 0.022575905546545982, 0.07956137508153915, -0.04192318022251129, 0.03417530283331871, -0.0446159802377224, -0.11340106278657913, 0.08069508522748947, 0.08886955678462982, 0.0511353500187397, 0.07656776160001755, -0.044035863131284714, 0.23851029574871063, 0.033775459975004196, 0.07735113054513931, 0.08023319393396378, -0.07367602735757828, -0.0847519189119339, 0.03598175570368767, 0.06045113503932953, -0.024313824251294136, 0.12482377886772156, -0.10525301843881607, 0.05072938650846481, 0.02348564751446247, -0.07856810837984085, 0.13133962452411652, -0.011128606274724007, 0.033013638108968735, 0.00761108985170722, -0.16893698275089264, 0.03767162933945656, 0.025127233937382698, 0.20883969962596893, 0.02024664171040058, -0.18057367205619812, -0.10614995658397675, -0.022494791075587273, 0.09601181745529175, -0.05624835193157196, -0.157696932554245, 0.02032989263534546, -0.12244462221860886, -0.017670566216111183, 0.021792098879814148, 0.09307052940130234, -0.05694461241364479, -6.537167265316567e-33, 0.08659727871417999, 0.12633416056632996, 0.028436560183763504, 0.08421570807695389, -0.06998806446790695, 0.054207365959882736, -0.0805201455950737, 0.11516871303319931, -0.04750808700919151, -0.07766710966825485, 0.07798963785171509, 0.09759186953306198, -0.09112626314163208, 0.03380570188164711, -0.06486718356609344, 0.025470353662967682, -0.058761849999427795, -0.010484586469829082, -0.08439356088638306, 0.010365800000727177, -0.028705211356282234, 0.1824265718460083, -0.23237796127796173, -0.03333695977926254, -0.1527627855539322, 0.08918378502130508, 0.03650239482522011, 0.02859196811914444, -0.013726611621677876, -0.12228703498840332, -0.09955507516860962, 0.023225530982017517, -0.05286248400807381, 0.0143178291618824, -0.00437420466914773, 0.03011126071214676, 0.04324209690093994, -0.16686470806598663, 0.05675665661692619, 0.1293513923883438, 0.22041362524032593, 0.10161063075065613, -0.14382566511631012, 0.11406616121530533, -0.006195249501615763, -0.017612390220165253, 0.02654251642525196, 0.0015629567205905914, 0.06442958861589432, 0.07523946464061737, -0.01632775366306305, -0.010231781750917435, -0.1875731199979782, 0.23616242408752441, 0.034872278571128845, 0.06231645122170448, -0.06318928301334381, -0.07352710515260696, -0.04804001748561859, 0.050366830080747604, -0.18748261034488678, -0.10614943504333496, -0.06238800659775734, 0.13697324693202972, 0.03383025899529457, 0.11160298436880112, -0.007024324033409357, 0.1235000342130661, 0.034156277775764465, 0.162331685423851, 0.01791156455874443, 0.17907288670539856, 0.035636335611343384, 0.03724774718284607, -0.07231520116329193, 0.04637731611728668, 0.010591171681880951, -0.0545010082423687, -0.07687175273895264, 0.057485610246658325, -0.074149489402771, -0.1398274451494217, 0.06494493782520294, 0.1777782440185547, 0.08941793441772461, 0.050761789083480835, 0.14622549712657928, -0.07259134948253632, 0.09747986495494843, -0.13048970699310303, -0.03855983912944794, 0.03010294772684574, 0.12050703912973404, 0.01588679477572441, 0.10549673438072205, -9.895389752045958e-08, -0.03990524634718895, 0.03881072998046875, -0.03496021032333374, -0.03448517620563507, 0.05027872696518898, -0.1636950671672821, -0.07355936616659164, 0.1524357795715332, -0.011981571093201637, 0.10691793262958527, 0.060996148735284805, -0.09219537675380707, -0.14634983241558075, -0.09395124018192291, 0.03337844833731651, 0.08064062148332596, 0.03934489190578461, 0.09705205261707306, -0.035026974976062775, 0.02674119547009468, -0.06395451724529266, -0.07817157357931137, 0.0996294692158699, -0.02664361521601677, 0.04478101432323456, -0.14667530357837677, -0.0036553042009472847, 0.06511883437633514, 0.04150877892971039, 0.0017570890486240387, -0.018794631585478783, 0.009539807215332985, -0.017400609329342842, 0.07227388769388199, -0.08390330523252487, 0.0909973755478859, -0.029639452695846558, -0.02576175145804882, 0.04600609838962555, 0.11115013062953949, 0.035425152629613876, -0.09152396023273468, -0.10920035094022751, -0.113615483045578, 0.07263413071632385, 0.10034019500017166, 0.04269171506166458, -0.10678107291460037, 0.0795968696475029, -0.0004188749589957297, 0.021229015663266182, 0.04885796085000038, 0.020488819107413292, 0.07016928493976593, -0.0012933273101225495, -0.03338003158569336, -0.03670278564095497, -0.15275166928768158, 0.0358584001660347, 0.11016452312469482, -0.026956401765346527, -0.09442959725856781, -0.006101518403738737, -0.021488182246685028], metadata={'source': 'AAAMLP-569to.pdf', 'page': 219}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 220         print(f\"Validation Epoch: {epoch}\")         # calculate validation loss         val_log = evaluate(             valid_dataset,             valid_loader,             model         )         # step the scheduler         scheduler.step(val_log[\"loss\"])         print(\"\\\\n\") ═════════════════════════════════════════════════════════════════════════  In segmentation problems you can use a variety of loss functions, for example, pixel-wise binary cross-entropy, focal loss, dice loss etc. I’m leaving it for the reader to decide the appropriate loss given the evaluation metric. When you train a model like this, you will create a model that tries to predict the location of pneumothorax, as shown in figure 9. In the above code, we used mixed precision training using NVIDIA apex. Please note that this is available natively in PyTorch from version 1.6.0+.   \\n Figure 9: Example of pneumothorax detection from the trained model (might not be correct prediction).  I have included some of the commonly used functions in a python package called Well That’s Fantastic Machine Learning (WTFML). Let’s see how this helps us to build a multi-class classification model for plant images from the plant pathology challenge of FGVC 202013.  13 Ranjita Thapa , Noah Snavely , Serge Belongie , Awais Khan. The Plant Pathology 2020 challenge dataset to classify foliar disease of apples. ArXiv e-prints'),\n",
       " VectorParams(vector=[-0.04688089340925217, -0.18673957884311676, 0.04574931412935257, 0.04769941046833992, 0.15355844795703888, -0.08182208985090256, -0.028911342844367027, 0.050078921020030975, -0.1007288321852684, -0.04074319079518318, 0.07186198979616165, -0.11551711708307266, -0.09903938323259354, -0.019743692129850388, -0.10427744686603546, 0.08587770164012909, -0.07513368129730225, 0.016454314813017845, -0.19060103595256805, -0.09560984373092651, 0.10708469152450562, 0.015517857857048512, 0.1390562802553177, 0.13783468306064606, -0.03504855930805206, -0.07932028919458389, -0.04720357060432434, 0.08749007433652878, 0.02206799015402794, -0.1707874983549118, -0.00666456762701273, 0.14050740003585815, -0.10897235572338104, 0.0403987318277359, 0.049894317984580994, 0.07935018092393875, -0.1465618759393692, -0.0048048235476017, -0.033670809119939804, 0.07215467095375061, 0.07653471827507019, -0.06212637946009636, 0.013332748785614967, -0.08006878197193146, -0.006706635933369398, 0.07013662159442902, -0.032640669494867325, -0.04650608077645302, 0.13337373733520508, -0.09280157834291458, -0.05326014757156372, 0.0024882699362933636, -0.10731333494186401, 0.07516033202409744, -0.0488368421792984, -0.08580987900495529, 0.06016220897436142, -0.1228705644607544, 0.03713512048125267, -0.041102442890405655, 0.042414505034685135, -0.0032696430571377277, -0.007335452362895012, -0.09149713069200516, 0.0283524077385664, -0.024800565093755722, -0.11017989367246628, 0.06360653042793274, 0.028113123029470444, 0.057406868785619736, -0.009674066677689552, 0.006682827603071928, -0.05656144395470619, 0.13710026443004608, -0.010500266216695309, -0.12340441346168518, 0.21884135901927948, 0.13513320684432983, 0.03411055728793144, -0.15011325478553772, -0.014818989671766758, 0.06583008915185928, 0.0726035088300705, -0.04433854669332504, 0.12292777001857758, -0.16446414589881897, 0.03384202718734741, 0.041262660175561905, 0.01783224381506443, -0.05758626013994217, 0.01461715716868639, -0.0321739986538887, -0.08419881761074066, 0.05690879747271538, 0.03289736434817314, 0.13183991611003876, 0.08545246720314026, -0.06501846760511398, -0.010418121702969074, 0.12779095768928528, -0.04568871483206749, -0.09129071235656738, 0.01086588203907013, 0.08776847273111343, 0.052239496260881424, 0.023987341672182083, 0.09058070182800293, 0.08410811424255371, 0.0904044657945633, -0.13048826158046722, 0.05016379803419113, -0.05453641340136528, -0.05348172411322594, 0.052746787667274475, 0.08205123245716095, -0.01029675267636776, -0.07202751189470291, 0.04471428692340851, -0.0714709609746933, 0.10974899679422379, -0.060929346829652786, 0.0664769634604454, -0.02790652960538864, 0.08885473012924194, 0.0217250045388937, -0.05697115138173103, -0.06278175115585327, 1.1821518365465665e-32, -0.040640827268362045, -0.05103541165590286, -0.09179037809371948, -0.10867542028427124, 0.02230476401746273, -0.041747089475393295, 0.01704668253660202, -0.032928258180618286, -0.08345631510019302, 0.03892577439546585, -0.20680691301822662, -0.035527393221855164, -0.06991694867610931, 0.01838834583759308, -0.011439763009548187, -0.048503048717975616, -0.03446172550320625, 0.10447447746992111, 0.02364603988826275, 0.015599974431097507, 0.12131794542074203, -0.04555099457502365, -0.027849147096276283, -0.12246889621019363, -0.11301088333129883, 0.06995082646608353, -0.023134689778089523, -0.08690019696950912, -0.058706820011138916, 0.02432309091091156, -0.10262030363082886, 0.01878899335861206, 0.029716307297348976, -0.025663727894425392, -0.045019716024398804, -0.044562771916389465, -0.007484177593141794, 0.055650562047958374, -0.018408991396427155, -0.11580391228199005, -0.09497181326150894, 0.15686869621276855, -0.028942320495843887, -0.10212608426809311, -0.02527311071753502, 0.08753373473882675, -0.040222879499197006, 0.19473426043987274, -0.07439576834440231, 0.1238958016037941, -0.01728879101574421, -0.06869156658649445, 0.021316412836313248, -0.010037369094789028, -0.034712158143520355, 0.06781050562858582, 0.153922900557518, 0.04174566641449928, 0.1121261715888977, -0.05354068800806999, 0.11678118258714676, 0.0713733360171318, 0.0022327019833028316, 0.05019652470946312, 0.006733886431902647, 0.02483215555548668, 0.0006575158331543207, 0.058586619794368744, 0.10271419584751129, 0.05633023753762245, -0.21165268123149872, 0.031076185405254364, -0.029374508187174797, -0.1258859634399414, 0.20651443302631378, -0.12373612076044083, 0.07277993857860565, -0.11127031594514847, -0.18417438864707947, 0.09538009017705917, -0.16613195836544037, 0.19625350832939148, -0.08295886218547821, -0.22861216962337494, -0.137860968708992, -0.008977659977972507, 0.012718545272946358, -0.08115855604410172, -0.16267657279968262, -0.03172936663031578, -0.17471234500408173, -0.007189363706856966, 0.03262602537870407, 0.08950737118721008, -0.04880601540207863, -1.0332090615841023e-32, 0.06015770137310028, 0.16718687117099762, 0.12257548421621323, 0.045768044888973236, 0.053079601377248764, 0.06129256263375282, 0.012394431047141552, 0.10040374845266342, -0.04793485254049301, -0.042503535747528076, 0.11122378706932068, -0.007180714514106512, -0.1346370428800583, -0.0246875062584877, 0.10296639055013657, 0.021877557039260864, -0.05291515216231346, 0.06801525503396988, -0.007593077607452869, 0.03732987120747566, -0.07685043662786484, 0.2773160934448242, -0.17968983948230743, 0.02259262464940548, -0.20669755339622498, 0.09731876850128174, 0.0235213004052639, 0.13388270139694214, -0.015926377847790718, -0.10205601155757904, 0.011121093295514584, -0.039625320583581924, -0.23390431702136993, 0.04832116886973381, -0.027196934446692467, 0.04111756011843681, 0.040101904422044754, -0.07342663407325745, -0.1681235283613205, 0.1384279727935791, 0.21376918256282806, 0.1464657038450241, -0.20563644170761108, 0.07822495698928833, -0.093194879591465, -0.014729657210409641, -0.014870492741465569, -0.03761003166437149, 0.05225363373756409, 0.04005832597613335, 0.030775174498558044, -0.13590306043624878, -0.061787452548742294, 0.0741553008556366, -0.05890556052327156, 0.052243687212467194, 0.029056662693619728, 0.09590372443199158, -0.12421649694442749, 0.03868018463253975, -0.10933783650398254, -0.11812836676836014, -0.0308644138276577, 0.035191651433706284, 0.014974941499531269, -0.005183761939406395, -0.11582471430301666, 0.10160388797521591, 0.04752925783395767, 0.10926439613103867, -0.04621841385960579, 0.23585060238838196, 0.09805016219615936, -0.01958196982741356, 0.0032289200462400913, 0.14298014342784882, -0.03336382284760475, -0.06502801179885864, -0.014941778033971786, 0.02396807074546814, -0.1260681003332138, -0.09043892472982407, 0.060521200299263, 0.18131142854690552, 0.004211814608424902, 0.05731036141514778, 0.08915942907333374, 0.10879401862621307, 0.08544225245714188, -0.13684330880641937, 0.0869426280260086, -0.0091591477394104, 0.177157923579216, 0.08583652973175049, 0.0003372610663063824, -9.924198707267351e-08, -0.08778858184814453, 0.03769687935709953, 0.004926084075123072, 0.07699839770793915, 0.07118239998817444, 0.000524618080817163, 0.012245646677911282, 0.14185084402561188, -0.07810749113559723, 0.026240801438689232, 0.06607088446617126, -0.0026354147121310234, -0.009709052741527557, 0.044754527509212494, 0.0018847162136808038, 0.062400657683610916, -0.0573006272315979, 0.08113377541303635, -0.03667072579264641, -0.04955383017659187, -0.031792182475328445, -0.12440618872642517, 0.05335313454270363, 0.010130875743925571, -0.06772395223379135, -0.08829964697360992, 0.01299025397747755, 0.005941576324403286, 0.01945815607905388, 0.045643098652362823, 0.1074766218662262, 0.0012649211566895247, 0.1114736795425415, 0.14708341658115387, 0.07473307102918625, 0.10138499736785889, -0.026597244665026665, 0.012024717405438423, -0.05206659063696861, 0.14053627848625183, -0.1604158878326416, 0.10330893099308014, -0.09140627086162567, -0.09666792303323746, 0.08644220232963562, 0.015476863831281662, 0.017151128500699997, -0.13294056057929993, 0.06947789341211319, 0.08373276144266129, 0.03187459707260132, -0.06588826328516006, -0.02961120568215847, 0.11200287938117981, 0.13148078322410583, -0.1279391497373581, -0.02383272349834442, -0.01928483135998249, -0.0033809072338044643, 0.028060998767614365, 0.007640834432095289, -0.046537116169929504, -0.00965152122080326, -0.03825019672513008], metadata={'source': 'AAAMLP-569to.pdf', 'page': 220}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 221 ═════════════════════════════════════════════════════════════════════════import os  import pandas as pd import numpy as np  import albumentations import argparse import torch import torchvision import torch.nn as nn import torch.nn.functional as F  from sklearn import metrics from sklearn.model_selection import train_test_split  from wtfml.engine import Engine from wtfml.data_loaders.image import ClassificationDataLoader   class DenseCrossEntropy(nn.Module):     # Taken from:      # https://www.kaggle.com/pestipeti/plant-pathology-2020-pytorch     def __init__(self):         super(DenseCrossEntropy, self).__init__()      def forward(self, logits, labels):         logits = logits.float()         labels = labels.float()          logprobs = F.log_softmax(logits, dim=-1)          loss = -labels * logprobs         loss = loss.sum(-1)          return loss.mean()   class Model(nn.Module):     def __init__(self):         super().__init__()         self.base_model = torchvision.models.resnet18(pretrained=True)         in_features = self.base_model.fc.in_features         self.out = nn.Linear(in_features, 4)      def forward(self, image, targets=None):         batch_size, C, H, W = image.shape'),\n",
       " VectorParams(vector=[0.054477181285619736, -0.08538871258497238, 0.07921101897954941, 0.06929510831832886, 0.13959139585494995, -0.14133940637111664, 0.041339125484228134, 0.1087203174829483, -0.1649278700351715, -0.09593559056520462, -0.04817180708050728, -0.12981455028057098, 0.13351598381996155, -0.07875824719667435, -0.13316132128238678, -0.01927041821181774, -0.2128346860408783, 0.1005522608757019, -0.12052566558122635, -0.025230590254068375, -0.031187400221824646, 0.11275947093963623, 0.047752294689416885, -0.0618455670773983, 0.004133383743464947, 0.047329895198345184, -0.037386324256658554, -0.06623747199773788, -0.18851736187934875, -0.0811237022280693, 0.02750166691839695, 0.06283483654260635, -0.029161274433135986, 0.053007930517196655, 0.08175501972436905, 0.029774561524391174, -0.04634549096226692, 0.0388200618326664, -0.1505333036184311, 0.10246101766824722, 0.007970035076141357, 0.052314549684524536, 0.06460884213447571, -0.096665158867836, 0.0823085755109787, 0.09975592792034149, -0.06429430097341537, -0.09349901974201202, 0.2332092523574829, -0.05845820531249046, -0.11094465106725693, 0.07546970993280411, -0.18042528629302979, 0.040373895317316055, -0.032538656145334244, -0.1398155838251114, 0.10952521115541458, -0.17959634959697723, -0.06348898261785507, -0.01353734452277422, 0.0625787153840065, -0.06814568489789963, 0.0523700937628746, -0.04757578298449516, 0.03048795647919178, -0.11502176523208618, -0.04441310837864876, 0.08419626206159592, -0.00939708761870861, 0.09929408878087997, -0.035037580877542496, 0.19290751218795776, -0.0797666609287262, 0.0368381030857563, -0.10085616260766983, -0.07523635774850845, 0.280852735042572, 0.052250079810619354, 0.14048178493976593, -0.15163244307041168, -0.09621550142765045, -0.11869435012340546, 0.019113285467028618, -0.07617776095867157, 0.11531999707221985, -0.18541987240314484, -0.014118715189397335, 0.06469552963972092, 0.017140256240963936, -0.07468458265066147, 0.05881297215819359, 0.07407708466053009, -0.1425698697566986, 0.0461437813937664, 0.10320544987916946, 0.14848120510578156, 0.10300265997648239, -0.1234043538570404, -0.06261865794658661, 0.15640898048877716, 0.003129859222099185, -0.15290851891040802, 0.04422500357031822, 0.03492222726345062, 0.11120709031820297, 0.08457593619823456, 0.13334906101226807, 0.1846245527267456, 0.05503176525235176, -0.19318142533302307, 0.02925247699022293, -0.04097575694322586, -0.0671844556927681, 0.04876090958714485, 0.12831047177314758, 0.0592665858566761, 0.02958819456398487, -0.013236651197075844, -0.1093956008553505, 0.0734749585390091, -0.09945053607225418, 0.021203136071562767, -0.043320365250110626, -0.055837348103523254, 0.06314831972122192, -0.078745037317276, -0.0944964587688446, 9.025391993683767e-33, -0.1310127079486847, -0.07814130932092667, 0.09275607019662857, -0.13717296719551086, 0.001998443156480789, 0.07469802349805832, 0.07729018479585648, -0.041014041751623154, -0.006851870566606522, -0.026868268847465515, -0.2812776565551758, -0.006283402908593416, -0.11487571150064468, 0.05853227153420448, 0.018587788566946983, -0.14582233130931854, -0.12723669409751892, 0.08870501816272736, 0.08691781759262085, 0.0138213150203228, 0.23850394785404205, -0.06005072593688965, -0.06705397367477417, -0.05396053567528725, -0.20228157937526703, -0.1485777497291565, -0.013518241234123707, -0.05260886251926422, -0.07688049972057343, 0.0014930026372894645, -0.1841902732849121, 0.074627585709095, -0.08582621812820435, -0.08495907485485077, -0.06955870985984802, -0.15514639019966125, 0.07498184591531754, 0.18908821046352386, 0.011265036650002003, -0.0031979912891983986, -0.034047067165374756, 0.11595138162374496, 0.03288193792104721, -0.06999866664409637, -0.006715400610119104, -0.03422220051288605, -0.018254298716783524, 0.14879217743873596, -0.12145540863275528, 0.1192590594291687, -0.051128141582012177, -0.15293170511722565, 0.038357920944690704, 0.008029785007238388, -0.1247861459851265, 0.08920037746429443, 0.060932938009500504, 0.10255476832389832, 0.06395767629146576, -0.08333487063646317, 0.0998300313949585, 0.061391353607177734, -0.14387854933738708, 0.08242451399564743, 0.05804527923464775, 0.015370965003967285, 0.2821402847766876, 0.015466711483895779, -0.024969488382339478, 0.05843597650527954, -0.06763362884521484, 0.15334977209568024, -0.010371350683271885, -0.15943259000778198, 0.15154077112674713, -0.1697506457567215, -0.04948125407099724, 0.050690799951553345, -0.17738032341003418, 0.01004153210669756, -0.0808199942111969, 0.3220447301864624, -0.04193609580397606, -0.2604229152202606, -0.11357235908508301, 0.06209798529744148, 0.10977820307016373, -0.11472543329000473, -0.23393096029758453, -0.1534433364868164, -0.12862776219844818, 0.05951623618602753, 0.07478177547454834, -0.04374523088335991, -0.045848701149225235, -7.311837144291656e-33, 0.05667111650109291, 0.09718888252973557, 0.19462525844573975, 0.05813469737768173, 0.11281290650367737, 0.07257616519927979, 0.10439656674861908, 0.07653700560331345, -0.003175106830894947, -0.21066318452358246, -0.010757732205092907, -0.13366280496120453, -0.052523571997880936, -0.09809096902608871, 0.09522146731615067, -0.009981328621506691, 0.00703614205121994, 0.05841166898608208, -0.09194441884756088, -0.028982939198613167, -0.13218402862548828, 0.20399878919124603, -0.022931266576051712, 0.07465741783380508, -0.2308548390865326, 0.08041521906852722, -0.01896493323147297, 0.11722201108932495, 0.03152484819293022, -0.20618702471256256, -0.09080646187067032, 0.08303087949752808, -0.1126965582370758, 0.1649242341518402, 0.05790664628148079, 0.01865788735449314, 0.053573127835989, -0.07526683062314987, -0.1335953027009964, 0.14338111877441406, 0.20235346257686615, 0.08937927335500717, -0.16775286197662354, 0.07398667931556702, 0.04613689333200455, 0.09181299060583115, -0.015519044362008572, 0.019363772124052048, -0.0648898333311081, 0.02363646775484085, -0.04935436695814133, -0.14449664950370789, -0.23475469648838043, 0.12993623316287994, 0.03987569361925125, 0.053722210228443146, -0.05664273723959923, -0.08222851157188416, -0.1324353963136673, 0.024085411801934242, -0.06898334622383118, -0.0884811282157898, -0.1494097113609314, -0.07875458896160126, 0.1469404548406601, 0.09439745545387268, -0.17229312658309937, 0.011874566785991192, 0.030153676867485046, 0.19241373240947723, -0.08080527186393738, 0.07498490810394287, 0.07080690562725067, -0.049570485949516296, 0.016247864812612534, 0.037610169500112534, -0.06747410446405411, 0.0371176078915596, 0.031505513936281204, 0.07731299847364426, -0.11161543428897858, -0.002671062247827649, 0.13426488637924194, 0.2229718565940857, 0.022194519639015198, 0.08669716119766235, 0.023073982447385788, 0.02850540727376938, 0.06614819169044495, -0.04114604741334915, -0.046278100460767746, -0.07303377985954285, 0.20399335026741028, 0.13337936997413635, -0.001560629578307271, -1.0003761019561352e-07, 0.12254564464092255, 0.08406102657318115, 0.04361338168382645, 0.05246668681502342, -0.015846414491534233, 0.04934386909008026, -0.15942874550819397, 0.10559573024511337, 0.10414813458919525, 0.007723778020590544, 0.07567610591650009, -0.06309273093938828, 0.0140230692923069, 0.020741745829582214, -0.09975341707468033, 0.10415924340486526, -0.05061646178364754, 0.045205265283584595, -0.014911983162164688, 0.0476255938410759, 0.03264002874493599, -0.12301778793334961, -0.08935248851776123, 0.02042282372713089, 0.039877306669950485, -0.05936494842171669, -0.022461269050836563, -0.05773339420557022, 0.13473370671272278, -0.0036305394023656845, -0.010698709636926651, -0.1888006180524826, 0.06679558008909225, 0.10364238172769547, 0.1609930694103241, 0.02790668047964573, 0.09379909187555313, -0.02421988546848297, -0.01416571345180273, 0.15204684436321259, -0.16193082928657532, 0.16629812121391296, -0.056091729551553726, -0.08404940366744995, 0.2287350594997406, -0.014354564249515533, 0.08441338688135147, -0.02134314551949501, 0.17636467516422272, -0.0337282232940197, 0.008417535573244095, -0.04209762439131737, -0.01110843475908041, 0.12018357217311859, 0.09743919223546982, -0.10091111063957214, 0.017789170145988464, -0.008260122500360012, 0.024928757920861244, 0.02872992865741253, 0.11076374351978302, -0.007925344631075859, -0.1580074578523636, 0.056227296590805054], metadata={'source': 'AAAMLP-569to.pdf', 'page': 221}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 222          x = self.base_model.conv1(image)         x = self.base_model.bn1(x)         x = self.base_model.relu(x)         x = self.base_model.maxpool(x)          x = self.base_model.layer1(x)         x = self.base_model.layer2(x)         x = self.base_model.layer3(x)         x = self.base_model.layer4(x)          x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)         x = self.out(x)          loss = None         if targets is not None:             loss = DenseCrossEntropy()(x, targets.type_as(x))          return x, loss   if __name__ == \"__main__\":     parser = argparse.ArgumentParser()     parser.add_argument(         \"--data_path\", type=str,     )     parser.add_argument(         \"--device\", type=str,     )     parser.add_argument(         \"--epochs\", type=int,     )     args = parser.parse_args()      df = pd.read_csv(os.path.join(args.data_path, \"train.csv\"))     images = df.image_id.values.tolist()     images = [         os.path.join(args.data_path, \"images\", i + \".jpg\")          for i in images     ]     targets = df[[\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]].values      model = Model()     model.to(args.device)      mean = (0.485, 0.456, 0.406)     std = (0.229, 0.224, 0.225)'),\n",
       " VectorParams(vector=[-0.06886877119541168, -0.06313776224851608, 0.039097871631383896, 0.05644257366657257, 0.04375634342432022, -0.073732890188694, -0.006146223284304142, 0.021364444866776466, -0.18738220632076263, -0.10451985895633698, 0.008833592757582664, -0.11072780191898346, -0.07042236626148224, -0.11774822324514389, -0.07633642852306366, 0.059238847345113754, -0.02290589176118374, -0.03894598409533501, -0.1456027776002884, -0.18696197867393494, 0.03144686669111252, -0.015593168325722218, 0.0790373906493187, 0.07235042005777359, -0.014080514200031757, 0.0037848309148103, 0.0059058950282633305, -0.04961688071489334, 0.07866351306438446, -0.1197933480143547, 0.13045261800289154, 0.028037982061505318, -0.04462311044335365, 0.022798899561166763, 0.08991291373968124, 0.0838363990187645, -0.198207288980484, -0.05416160821914673, -0.04773657023906708, 0.11686040461063385, 0.10155240446329117, -0.016569815576076508, -0.0584481805562973, -0.09126506745815277, -0.016403816640377045, 0.09790993481874466, -0.03993377462029457, -0.049845486879348755, 0.04484505578875542, -0.026348698884248734, -0.09616722166538239, -0.009660029783844948, -0.06136086583137512, 0.027533497661352158, -0.05896001309156418, -0.06441093236207962, 0.013370971195399761, -0.026714134961366653, 0.021116111427545547, 0.012534040957689285, -0.03055199608206749, -0.09106194972991943, -0.04079911857843399, -0.01946011558175087, 0.032329391688108444, -0.054545409977436066, -0.033732227981090546, -0.018334627151489258, 0.0614081509411335, 0.055228155106306076, 0.07108518481254578, 0.07295083999633789, -0.02372455969452858, 0.15737779438495636, -0.0251260194927454, -0.043343767523765564, 0.19596700370311737, 0.025495383888483047, 0.04626774042844772, -0.24497093260288239, -0.12889157235622406, -0.1169523075222969, 0.10578687489032745, -0.05236470326781273, 0.17371657490730286, -0.09377606213092804, 0.02562348172068596, 0.03244294598698616, 0.051538851112127304, -0.05146601423621178, 0.06115197762846947, 0.06089499592781067, -0.1013587936758995, 0.0232104305177927, 0.13989688456058502, 0.12282110005617142, 0.12812170386314392, -0.03439420461654663, -0.13242357969284058, 0.15449874103069305, -0.0516405925154686, -0.06789937615394592, 0.07065841555595398, 0.03719306364655495, -0.01431838795542717, 0.0015315760392695665, 0.11701516062021255, 0.06480349600315094, 0.01225095521658659, -0.15384642779827118, 0.045218098908662796, 0.030748074874281883, -0.02074873074889183, -0.03518952801823616, 0.11678105592727661, 0.06219461187720299, -0.10689923912286758, 0.05995561555027962, -0.1271035373210907, 0.10841052979230881, -0.03983442112803459, 0.047539398074150085, -0.032696641981601715, 0.08363074064254761, -0.1014421284198761, -0.13363811373710632, -0.10364723950624466, 1.0764200135151388e-32, -0.029911372810602188, -0.09301061183214188, -0.06330130249261856, -0.17330749332904816, 0.05035695433616638, -0.013357870280742645, 0.0013431626139208674, 0.04775742441415787, -0.06474374979734421, -0.02963259443640709, -0.11990229040384293, -0.12761135399341583, -0.07578518241643906, 0.09906738251447678, -0.029053060337901115, -0.0492732934653759, 0.04787274822592735, 0.1711612194776535, 0.045215532183647156, -0.0576750710606575, 0.12814275920391083, -0.12064425647258759, -0.101519875228405, -0.042424943298101425, -0.11682596802711487, 0.11394470185041428, 0.035612802952528, -0.06185462325811386, -0.03183956444263458, 0.021426532417535782, -0.11265794932842255, 0.0761241614818573, -0.003748622490093112, 0.01599280908703804, -0.021449413150548935, -0.0377972237765789, -0.00730963284149766, 0.13493414223194122, -0.0828246995806694, -0.12369072437286377, -0.04833748936653137, 0.08424817025661469, 0.0524243600666523, -0.05534571781754494, -0.040389057248830795, 0.022951172664761543, -0.05863754451274872, 0.11383722722530365, -0.008667420595884323, 0.13206259906291962, -0.005988083779811859, -0.05064547061920166, 0.0840374156832695, -0.05788106471300125, -0.019153587520122528, -0.015040024183690548, 0.09711495786905289, 0.10204814374446869, 0.16219983994960785, -0.015726836398243904, 0.1821935623884201, 0.11168224364519119, -0.05894739553332329, 0.09452459216117859, 0.04531428590416908, 0.06010958552360535, 0.06529785692691803, -0.04302903264760971, 0.11712373048067093, 0.08555477112531662, -0.12083567678928375, 0.037408072501420975, 0.084473617374897, -0.12313652783632278, 0.1949545443058014, -0.15735606849193573, 0.07702057808637619, -0.09680546820163727, -0.20705269277095795, 0.038097888231277466, -0.08147668838500977, 0.13211748003959656, -0.07846201211214066, -0.2463189959526062, -0.06306654959917068, -0.03919639810919762, 0.06440158188343048, -0.022641388699412346, -0.10628610849380493, 0.016326339915394783, -0.04371025413274765, -0.02266147918999195, 0.049155376851558685, 0.07864869385957718, -0.023684009909629822, -9.26564614126055e-33, 0.11905676871538162, 0.11293023079633713, 0.08396372944116592, 0.010927007533609867, 0.10494844615459442, 0.05068301036953926, 0.04475877434015274, 0.1168278157711029, -0.06230685114860535, -0.013057776726782322, 0.09826524555683136, -0.09033844619989395, -0.13026176393032074, -0.06885042041540146, 0.013307347893714905, -0.1163182407617569, 0.030315635725855827, 0.019690876826643944, 0.0186921339482069, 0.07785990834236145, -0.03960900381207466, 0.2734806537628174, -0.18469497561454773, 0.03850245475769043, -0.14988838136196136, 0.095299631357193, -0.0030657451134175062, 0.15528899431228638, 0.028936166316270828, -0.06800730526447296, -0.075620137155056, -0.007001596037298441, -0.23659302294254303, -0.014888000674545765, 0.028669875115156174, 0.08308716118335724, 0.01151998434215784, 0.05107634887099266, -0.13777293264865875, 0.19725753366947174, 0.15515819191932678, 0.04173567518591881, -0.13280874490737915, 0.09693212062120438, -0.022008750587701797, -0.027173787355422974, 0.01264824066311121, 0.05431697517633438, -0.11581262946128845, 0.03298506140708923, 0.02443750947713852, -0.12374670803546906, -0.15044640004634857, -0.010069388896226883, 0.06296060979366302, 0.011152113787829876, -0.0682244822382927, -0.050399623811244965, -0.1089632660150528, 0.03606065735220909, -0.07913736253976822, -0.09318958222866058, -0.00811355747282505, -0.09890979528427124, -0.02241157367825508, 0.04679897800087929, -0.12607312202453613, 0.11685895919799805, 0.018667001277208328, 0.17545358836650848, -0.07158927619457245, 0.08494735509157181, 0.15126696228981018, 0.05942195653915405, -0.08974866569042206, 0.059832144528627396, -0.04317513480782509, -0.02534157782793045, 0.03960101678967476, -0.045135438442230225, -0.19331827759742737, -0.04091522842645645, 0.06402929127216339, 0.19099561870098114, -0.005297448020428419, 0.15484830737113953, 0.10339217633008957, 0.15420491993427277, 0.13194149732589722, -0.06232188642024994, 0.1080930083990097, -0.031761374324560165, 0.21996790170669556, 0.25754082202911377, -0.006753794848918915, -1.0005236816823526e-07, -0.05139107629656792, 0.017309993505477905, 0.03998839855194092, 0.12149173766374588, 0.20009110867977142, -0.07661876827478409, 0.022820955142378807, 0.10875243693590164, -0.02268689125776291, -0.05987073481082916, 0.13515634834766388, -0.0186220221221447, -0.03569202125072479, 0.06175315007567406, 0.02370849996805191, -0.026783369481563568, -0.06650429964065552, 0.06880159676074982, -0.012205187231302261, -0.11323608458042145, -0.0693289041519165, -0.11233650892972946, 0.08859476447105408, -0.0639525055885315, -0.023049641400575638, -0.08489912748336792, 0.02104826644062996, 0.05177081376314163, 0.022352006286382675, -0.02430863492190838, 0.01855429820716381, 0.00800129771232605, 0.10288826376199722, 0.053868863731622696, 0.05546313151717186, 0.08056596666574478, -0.016860313713550568, 0.02308150753378868, -0.03412238880991936, 0.015175270847976208, -0.11517369747161865, 0.07433722168207169, 0.013762766495347023, -0.061141714453697205, 0.0970449298620224, -0.050398457795381546, 0.035593368113040924, -0.08777015656232834, 0.05542134866118431, 0.015683555975556374, -0.049087848514318466, -0.038553714752197266, -0.07960420846939087, 0.09682396054267883, 0.12961794435977936, -0.2322307974100113, -0.0230556707829237, -0.06607021391391754, -0.06195631995797157, 0.0709940493106842, 0.03584662079811096, -0.0961991623044014, -0.1386202573776245, -0.006766072008758783], metadata={'source': 'AAAMLP-569to.pdf', 'page': 222}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 223     aug = albumentations.Compose(         [             albumentations.Normalize(                 mean,                  std,                  max_pixel_value=255.0,                  always_apply=True             )         ]     )      (         train_images, valid_images,          train_targets, valid_targets     ) = train_test_split(images, targets)      train_loader = ClassificationDataLoader(         image_paths=train_images,         targets=train_targets,         resize=(128, 128),         augmentations=aug,     ).fetch(         batch_size=16,          num_workers=4,          drop_last=False,          shuffle=True,          tpu=False     )      valid_loader = ClassificationDataLoader(         image_paths=valid_images,         targets=valid_targets,         resize=(128, 128),         augmentations=aug,     ).fetch(         batch_size=16,          num_workers=4,          drop_last=False,          shuffle=False,          tpu=False     )      optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)     scheduler = torch.optim.lr_scheduler.StepLR(         optimizer, step_size=15, gamma=0.6     )'),\n",
       " VectorParams(vector=[-0.09831389784812927, 0.002083070809021592, -0.07229053974151611, 0.035424575209617615, 0.11273684352636337, -0.062353454530239105, -0.07834310084581375, 0.12265942245721817, -0.05146999657154083, -0.06823361665010452, 0.021053217351436615, -0.07204654812812805, 0.0050284890457987785, -0.017431553453207016, -0.09921357035636902, -0.027869295328855515, -0.15820716321468353, 0.07686008512973785, -0.11023791879415512, -0.12433522939682007, 0.005260273814201355, 0.0732019767165184, -0.019777992740273476, 0.034351449459791183, -0.06235286220908165, -0.028852099552750587, -0.03300821781158447, 0.03476917743682861, -0.05220997333526611, -0.07322605699300766, 0.06157095357775688, 0.03863978013396263, -0.04717913642525673, 0.0369742251932621, 0.05709359794855118, 0.06365376710891724, -0.04925321042537689, -0.041757140308618546, -0.07003667205572128, -0.004206226207315922, 0.06795322895050049, -0.02695563994348049, -0.040681954473257065, 0.032961342483758926, 0.049273911863565445, -0.0052862269803881645, -0.07295262813568115, -0.10399771481752396, 0.07846562564373016, -0.14667823910713196, -0.03354840725660324, 0.015924902632832527, -0.10272909700870514, 0.038809530436992645, 0.010915849357843399, -0.014323029667139053, 0.05283365771174431, -0.07916601747274399, -0.04033895209431648, -0.06676353514194489, 0.053073953837156296, -0.033905282616615295, -0.0387837179005146, -0.053114332258701324, 0.0239058006554842, -0.04747682809829712, -0.003967896103858948, 0.00820108037441969, 0.08047135174274445, 0.023080596700310707, 0.004448312800377607, 0.009540124796330929, -0.0665316954255104, 0.06996943801641464, -0.07574940472841263, -0.024586673825979233, 0.18100839853286743, 0.048007991164922714, 0.00043840036960318685, -0.07381417602300644, -0.09236254543066025, 0.012622750364243984, 0.045279376208782196, -0.013304132036864758, 0.11275386065244675, -0.04434585198760033, 0.004511711187660694, 0.1009850800037384, 0.05376456677913666, -0.027630211785435677, 0.0926833227276802, 0.02489309199154377, -0.10945963859558105, 0.08760768920183182, 0.09597416967153549, 0.15259861946105957, 0.15114440023899078, -0.0997486263513565, -0.09451867640018463, 0.07178525626659393, -0.056065917015075684, -0.08786818385124207, -0.02690303511917591, 0.03632424771785736, 0.11014892905950546, 0.052886493504047394, 0.02188893035054207, -0.037416309118270874, 0.05575172230601311, -0.08848627656698227, 0.09895776212215424, 0.02309557795524597, -0.04718926548957825, 0.0316498763859272, 0.14055873453617096, 0.006190233398228884, -0.08369351178407669, 0.06981953978538513, 0.010125630535185337, 0.16602221131324768, -0.16276055574417114, 0.0534706711769104, -0.04819106310606003, 0.080345518887043, -0.013529127463698387, -0.12895357608795166, -0.08296369016170502, 9.556564830041742e-33, -0.07944417744874954, -0.07786952704191208, -0.005787563510239124, -0.1648726612329483, 0.024174729362130165, -0.028773823752999306, -0.05781003087759018, 0.01972879096865654, 0.04646545276045799, 0.036740608513355255, -0.24605923891067505, -0.02717592753469944, -0.10753155499696732, -0.0004783332988154143, 0.04347807168960571, -0.05942489206790924, -0.0802355706691742, 0.07473788410425186, 0.020910505205392838, 0.0035653847735375166, 0.030206840485334396, -0.13278305530548096, -0.07548637688159943, -0.05231287702918053, -0.055327124893665314, 0.042898695915937424, 0.010012323036789894, -0.06060919165611267, -0.058674465864896774, 0.0361490324139595, -0.08538947999477386, 0.025601640343666077, -0.008713247254490852, -0.07116086035966873, -0.08091551810503006, -0.11432705819606781, 0.03422821685671806, 0.0681229680776596, -0.013903935439884663, -0.056716009974479675, -0.13767746090888977, 0.062238309532403946, 0.05987541005015373, -0.02294454723596573, 0.04316546022891998, -0.00089743867283687, 0.00598436314612627, 0.14565323293209076, -0.07288867980241776, 0.06243472918868065, -0.04034429043531418, -0.07099080085754395, 0.03631635010242462, -0.08186832070350647, 0.009530864655971527, 0.046582598239183426, 0.08766581863164902, 0.03441754728555679, 0.10060509294271469, 0.000920897233299911, 0.14865630865097046, 0.06126193702220917, 0.008305353112518787, 0.06736043095588684, 0.025256328284740448, 0.062310539186000824, -0.016026116907596588, -0.015170342288911343, -0.06565725803375244, 0.18082685768604279, -0.13604892790317535, 0.04093838110566139, 0.009637275710701942, -0.16558393836021423, 0.2001166045665741, -0.046985652297735214, 0.13238905370235443, 0.002770285354927182, -0.15039698779582977, -0.056282129138708115, -0.0316929891705513, 0.16914059221744537, -0.08752357214689255, -0.15736661851406097, -0.0939255878329277, -0.024917876347899437, -0.009411392733454704, -0.07116557657718658, -0.0954534038901329, 0.0032256930135190487, -0.12441025674343109, 0.022787725552916527, -0.01530552003532648, 0.03871642053127289, -0.030006956309080124, -8.295346084317801e-33, 0.08816076070070267, 0.1355385184288025, 0.06433934718370438, 0.05704052373766899, 0.04214628413319588, -0.017534669488668442, 0.04922609031200409, 0.0454719141125679, 0.01593191735446453, 0.042088013142347336, 0.021500295028090477, -0.01448713056743145, -0.1523006707429886, -0.04824370890855789, 0.032860320061445236, 0.03642156720161438, -0.04530065506696701, 0.005344887264072895, -0.010898414999246597, -0.04603157564997673, -0.12472803890705109, 0.2994578778743744, -0.15688607096672058, -0.04420030117034912, -0.06621912866830826, 0.02135946787893772, -0.026079364120960236, 0.08817493915557861, -0.04924105852842331, -0.1041182279586792, 0.004486189689487219, -0.06523764878511429, -0.1254241168498993, 0.06558660417795181, -0.05693063884973526, 0.11377162486314774, 0.07017398625612259, -0.06358502805233002, -0.046162135899066925, 0.0659894347190857, 0.20380114018917084, 0.13091300427913666, -0.14240527153015137, 0.06459389626979828, -0.027982160449028015, 0.017184415832161903, 0.07236715406179428, -0.02950659580528736, 0.041369277983903885, 0.02280912548303604, 0.11348477751016617, -0.014194326475262642, -0.09168805927038193, 0.11893980950117111, 0.048564884811639786, 0.044131048023700714, 0.013897180557250977, -0.07099401950836182, -0.14358459413051605, 0.021844107657670975, -0.06762351840734482, -0.18741737306118011, -0.0075537338852882385, 0.05383908748626709, -0.035075586289167404, 0.024724459275603294, -0.06380578130483627, 0.126416876912117, 0.017415126785635948, 0.09794306010007858, -0.03236008435487747, 0.10976588726043701, 0.059252019971609116, 0.023469673469662666, -0.06770063936710358, 0.07902316749095917, -0.05546845495700836, -0.047522902488708496, -0.01191311702132225, 0.0267949141561985, -0.07296210527420044, -0.09404163062572479, 0.05994131788611412, 0.1420416384935379, 0.0055832634679973125, 0.0592188686132431, 0.020678624510765076, 0.05388525873422623, 0.16878338158130646, -0.05262520909309387, 0.009718739427626133, 0.0017060315003618598, 0.08012476563453674, 0.09722224622964859, 0.03033546172082424, -1.0004892203596683e-07, -0.016288237646222115, 0.021452810615301132, 0.07062220573425293, -0.007514372002333403, 0.10690808296203613, -0.06392697989940643, -0.015148814767599106, 0.084735207259655, -0.023965848609805107, 0.021367263048887253, 0.08536364883184433, -0.034349702298641205, -0.1399223953485489, 0.058124080300331116, 0.013203144073486328, 0.1284346580505371, 0.06129055842757225, 0.03761175274848938, 0.01227934006601572, 0.024345071986317635, 0.03355288878083229, -0.06488649547100067, 0.007216854952275753, -0.017126433551311493, -0.018743664026260376, -0.10051952302455902, -0.05564804747700691, 0.07433539628982544, -0.010351770557463169, 0.02488233894109726, 0.0458943247795105, -0.08535245805978775, 0.12075728923082352, 0.13007335364818573, 0.049470577389001846, 0.07332949340343475, -0.010224481113255024, -0.001287270337343216, 0.002346243243664503, 0.1180645301938057, -0.06838667392730713, 0.01208007987588644, -0.036981627345085144, -0.012342564761638641, 0.10901607573032379, -0.025942949578166008, 0.09095795452594757, -0.08514255285263062, -0.0004571096505969763, 0.031213637441396713, 0.03137053921818733, 0.0035542717669159174, 0.00984276831150055, 0.059100307524204254, 0.053079552948474884, -0.1402544379234314, -0.02141590043902397, -0.084311842918396, -0.07819648087024689, 0.030970538035035133, 0.02611539512872696, 0.018179723992943764, 0.04777806997299194, 0.021643122658133507], metadata={'source': 'AAAMLP-569to.pdf', 'page': 223}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 224     for epoch in range(args.epochs):         train_loss = Engine.train(             train_loader, model, optimizer, device=args.device         )         valid_loss = Engine.evaluate(             valid_loader, model, device=args.device         )         print(             f\"{epoch}, Train Loss={train_loss} Valid Loss={valid_loss}\"         ) ═════════════════════════════════════════════════════════════════════════  Once you have the data14, you can run the script using:   ═════════════════════════════════════════════════════════════════════════❯ python plant.py --data_path ../../plant_pathology --device cuda -- epochs 2 100%|█████████████| 86/86 [00:12<00:00, 6.73it/s, loss=0.723] 100%|█████████████ 29/29 [00:04<00:00, 6.62it/s, loss=0.433] 0, Train Loss=0.7228777609592261 Valid Loss=0.4327834551704341 100%|█████████████| 86/86 [00:12<00:00, 6.74it/s, loss=0.271] 100%|█████████████ 29/29 [00:04<00:00, 6.63it/s, loss=0.568] 1, Train Loss=0.2708700496790021 Valid Loss=0.56841839541649 ═════════════════════════════════════════════════════════════════════════ As you can see, how this makes our life simple and code easy to read and understand. PyTorch without any wrappers work best. There is a lot more in images than just classification, and if I start writing about all of them, I’ll have to write another book. So, I have decided to do that instead: Approaching (Almost) Any Image Problem. \\n 14 https://www.kaggle.com/c/plant-pathology-2020-fgvc7'),\n",
       " VectorParams(vector=[-0.14879588782787323, -0.08193007111549377, 0.0034059686586260796, 0.009958392009139061, -0.00400309544056654, 0.11526911705732346, 0.11100918054580688, -0.002858249004930258, 0.01809293031692505, -0.0021163218189030886, -0.03963480889797211, -0.01883590780198574, 0.09382990747690201, 0.09193577617406845, -0.03720364719629288, 0.1856517344713211, 0.14046376943588257, 0.07572020590305328, -0.23665006458759308, -0.007566266693174839, 0.07913788408041, 0.09498801827430725, 0.026560457423329353, -0.004339232575148344, -0.16634532809257507, 0.0666513442993164, -0.019462862983345985, 0.02609369158744812, -0.1388711780309677, -0.06443630903959274, 0.04052112251520157, 0.08467037230730057, -0.08988147228956223, 0.23066212236881256, -0.09096312522888184, 0.07193626463413239, -0.07346287369728088, 0.07121706753969193, 0.021130718290805817, 0.0035661489237099886, -0.027611423283815384, -0.06006454676389694, -0.03401457518339157, -0.0274694561958313, 0.3320324122905731, -0.11354056000709534, -0.05764011666178703, -0.07629478722810745, 0.04452212527394295, 0.05865240469574928, -0.23265434801578522, 0.024137631058692932, -0.0068113780580461025, 0.11032985895872116, -0.06594451516866684, -0.04897676408290863, -0.014371776022017002, -0.012708115391433239, -0.0215879175812006, -0.10663270205259323, 0.02370726317167282, -0.21221360564231873, 0.05152716115117073, -0.08195663243532181, 0.07066535204648972, -0.024975793436169624, -0.11616027355194092, 0.050214216113090515, -0.07480332255363464, 0.057709984481334686, 0.00405085040256381, 0.13473588228225708, -0.010500665754079819, 0.04268104210495949, -0.15762163698673248, 0.05048641562461853, 0.1503845751285553, -0.014656766317784786, 0.10374167561531067, -0.10017366707324982, -0.02610807679593563, 0.044298749417066574, 0.07580313831567764, 0.1095353215932846, 0.06661704182624817, -0.09177805483341217, 0.030378125607967377, 0.0678587406873703, -0.12688085436820984, 0.04365826025605202, -0.06531155854463577, -0.13068576157093048, 0.16278834640979767, -0.05158434063196182, 0.1368202269077301, 0.13295623660087585, -0.09733971953392029, -0.152894988656044, 0.03301258385181427, 0.10749481618404388, 0.04401295632123947, 0.11891992390155792, 0.03541683405637741, -0.15012843906879425, -0.10188277065753937, 0.04611314833164215, 0.03989392891526222, 0.017580831423401833, 0.1042143777012825, -0.30262601375579834, -0.09405536204576492, 0.0946536585688591, -0.13518832623958588, -0.05686741694808006, 0.09618028253316879, -0.11905091255903244, -9.850200149230659e-05, -0.07270888239145279, 0.06450463086366653, 0.2049763798713684, -0.1203981339931488, 0.10482683777809143, -0.06905505061149597, -0.009144524112343788, 0.006956083700060844, -0.03723985701799393, -0.03889523819088936, 9.495855689609556e-33, -0.04919680580496788, 0.01620357297360897, 0.01169926393777132, 0.014614615589380264, 0.11955138295888901, -0.044745441526174545, -0.006075093988329172, 0.09191609919071198, -0.1584332436323166, -0.04006490483880043, -0.09128063172101974, 0.058740533888339996, -0.05953129008412361, 0.1055740937590599, 0.04748169705271721, -0.07573723793029785, -0.093871109187603, -0.021690160036087036, -0.012978973798453808, -0.04415616765618324, -0.026407798752188683, -0.0032760119065642357, 0.0774630457162857, -0.05359205603599548, -0.08185214549303055, -0.0943157896399498, 0.048761509358882904, -0.10181234031915665, -0.11104606091976166, 0.023858295753598213, -0.1158563643693924, 0.06092555820941925, 0.0739414319396019, -0.01362476497888565, 0.07506818324327469, -0.1228439137339592, -0.015205067582428455, 0.06911265105009079, 0.06391710788011551, -0.07702740281820297, -0.1379072219133377, 0.1452859491109848, -0.0037176033947616816, 0.0026398543268442154, -0.0057029761373996735, 0.1304282546043396, 0.006623286288231611, -0.09894581139087677, -0.011948731727898121, 0.013430358842015266, 0.054162729531526566, -0.08139841258525848, -0.006519366521388292, -0.025974655523896217, -0.015591650269925594, 0.04615306481719017, -0.02221301943063736, -0.14205367863178253, 0.07364949584007263, 0.027846110984683037, 0.010128142312169075, 0.09862419217824936, 0.01943085715174675, 0.012320720590651035, -0.0241506677120924, 0.10436232388019562, 0.05619090050458908, 0.1077551543712616, 0.12193024903535843, -0.09488268196582794, 0.01584126241505146, 0.06235523521900177, 0.044958870857954025, -0.12927669286727905, 0.14279983937740326, 0.04819812998175621, 0.006961358245462179, -0.11837426573038101, -0.11688970029354095, 0.08780228346586227, 0.034950800240039825, -0.0547771193087101, 0.12327691912651062, -0.1658400148153305, -0.189132958650589, 0.03165067732334137, 0.07358112186193466, -0.16724304854869843, 0.050062377005815506, 0.0851491242647171, -0.17213965952396393, 0.126117542386055, -0.056001804769039154, 0.04870516434311867, 0.14381864666938782, -9.064776931908068e-33, -0.07911282032728195, 0.04551006481051445, -0.15687274932861328, 0.01890343613922596, -0.062057074159383774, 0.11817692220211029, -0.07904631644487381, -0.0284050852060318, 0.035552140325307846, -0.0679147019982338, -0.08263672143220901, -0.08139131963253021, 0.010392983444035053, -0.037094637751579285, -0.07649808377027512, -0.006226651836186647, -0.05760931968688965, -0.023962747305631638, 0.012340220622718334, 0.13380888104438782, 0.026229439303278923, 0.2356588989496231, -0.223310187458992, 0.07799158990383148, -0.012417465448379517, 0.09881501644849777, -0.05615072697401047, 0.10394660383462906, 0.010091234929859638, -0.06904612481594086, -0.029293756932020187, -0.04970509558916092, -0.0973638966679573, 0.014115187339484692, -0.06421563029289246, -0.03736080974340439, 0.04517769441008568, -0.16956061124801636, 0.02480446919798851, 0.03247930854558945, 0.18850436806678772, 0.10017535835504532, -0.07169134169816971, -0.0645172968506813, -0.10059913992881775, -0.07515715062618256, -0.00020716513972729445, -0.042455002665519714, 0.005942195653915405, 0.03451581671833992, -0.05165451020002365, -0.024693958461284637, -0.10600113123655319, 0.033546578139066696, -0.058011751621961594, -0.05910588055849075, -0.023244354873895645, -0.0661940947175026, -0.0014842600794509053, 0.08223988115787506, -0.15334850549697876, 0.05022338777780533, 0.16578328609466553, -0.05755319818854332, 0.09723176807165146, -0.1311057060956955, 0.037683743983507156, 0.0651479959487915, -0.011306386440992355, 0.014136268757283688, -0.08998362720012665, 0.004855329170823097, 0.01119657326489687, 0.08985857665538788, -0.005494945682585239, 0.01985218934714794, -0.06263640522956848, -0.05396063253283501, -0.1632968634366989, -0.08600030839443207, 0.07207556813955307, -0.08783402293920517, -0.001012227381579578, 0.001719638705253601, 0.13403481245040894, 0.011417231522500515, 0.11551295965909958, 0.04984772950410843, 0.05223454535007477, -0.04126537963747978, -0.08934372663497925, -0.025324441492557526, -0.012890285812318325, 0.037606045603752136, 0.026865515857934952, -1.0020034579838466e-07, -0.16781939566135406, -0.06343631446361542, -0.008008872158825397, 0.1430017352104187, -0.0012486219638958573, -0.09455025941133499, 0.053694259375333786, 0.21263201534748077, -0.06333846598863602, 0.005243170075118542, 0.18082477152347565, 0.11154112219810486, -0.13903199136257172, 0.008992641232907772, -0.10535512864589691, 0.1430608183145523, 0.017518378794193268, -0.044100694358348846, 0.053580254316329956, 0.047900471836328506, 0.24383902549743652, 0.03212520480155945, 0.04502434656023979, 0.06083335354924202, 0.09631989151239395, -0.16177166998386383, 0.0004044333181809634, 0.01866692490875721, -0.05713501572608948, 0.054472099989652634, 0.03587476909160614, 0.020861271768808365, -0.14772140979766846, -0.01026125904172659, 0.1407794952392578, 0.004509130492806435, 0.14346855878829956, -0.13255423307418823, -0.05123744159936905, -0.04547253996133804, -0.0077498494647443295, 0.09522292762994766, -0.06540153920650482, -0.11906827986240387, 0.07889429479837418, -0.05005849897861481, -0.026864930987358093, -0.15930014848709106, 0.027782881632447243, 0.050952110439538956, 0.07560960948467255, 0.018755530938506126, -0.0014634494436904788, 0.1424500048160553, 0.11959126591682434, -0.03589071333408356, 0.025819221511483192, -0.1152028888463974, -0.0822935551404953, 0.15117715299129486, 0.07498161494731903, 0.09050095826387405, -0.004867712501436472, 0.06743322312831879], metadata={'source': 'AAAMLP-569to.pdf', 'page': 224}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 225 Approaching text classification/regression  Text problems are my favourite. In general, these problems are also known as Natural Language Processing (NLP) problems. NLP problems are also like images in the sense that, it’s quite different. You need to create pipelines you have never created before for tabular problems. You need to understand the business case to build a good model. By the way, that is true for anything in machine learning. Building models will take you to a certain level, but to improve and contribute to a business you are building the model for, you must understand how it impacts the business. Let’s not get too philosophical here.   There are many different types of NLP problems, and the most common type is the classification of strings. Many times, it is seen that people are doing well with tabular data or with images, but when it comes to text, they don’t even have a clue where to start from. Text data is no different than other types of datasets. For computers, everything is numbers.  Let’s say we start with a fundamental task of sentiment classification. We will try to classify sentiment from movie reviews. So, you have a text, and there is a sentiment associated with it. How will you approach this kind of problem? Apply a deep neural network right, or maybe muppets can come and save you? No, absolutely wrong. You start with the basics. Let’s see what this data looks like first.  We start with IMDB movie review dataset15 that consists of 25000 reviews for positive sentiment and 25000 reviews for negative sentiment.   The concepts that I will discuss here can be applied to almost any text classification dataset.  This dataset is quite easy to understand. One review maps to one target variable. Note that I wrote review instead of sentence. A review is a bunch of sentences. So, until now you must have seen classifying only a single sentence, but in this problem, we will be classifying multiple sentences. In simple words, it means that not only  15 Maas, Andrew L, Daly, Raymond E, Pham, Peter T, Huang, Dan, Ng, Andrew Y, and Potts, Christopher. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pp. 142–150. Association for Computational Linguistics, 2011.'),\n",
       " VectorParams(vector=[-0.166884645819664, -0.03518499433994293, -0.046754177659749985, 0.052570890635252, 0.01810535229742527, 0.06811126321554184, 0.09470143914222717, 0.015293133445084095, 0.0699269101023674, 0.0016070142155513167, 0.12651652097702026, -0.04596199467778206, 0.2110217958688736, 0.07338201999664307, 0.0022183768451213837, 0.15288656949996948, 0.06304316222667694, 0.017246419563889503, -0.0885624960064888, -0.16255372762680054, 0.06097320467233658, 0.14961940050125122, -0.023625029250979424, 0.0222933366894722, -0.05459463968873024, -0.04395797848701477, -0.024082019925117493, 0.11048056930303574, -0.11978095769882202, -0.046617306768894196, 0.029537126421928406, 0.06225977838039398, 0.029689490795135498, 0.19873584806919098, -0.04007444530725479, 0.016925428062677383, -0.05576013773679733, 0.030694536864757538, -0.02885943278670311, 0.008632530458271503, -0.12944395840168, -0.029922708868980408, -0.021357621997594833, -0.07022520154714584, 0.2191324532032013, 0.005820447113364935, -0.09090574085712433, -0.007604891899973154, 0.1242334246635437, -0.06920316070318222, -0.14190302789211273, 0.021074198186397552, -0.06913760304450989, 0.059594664722681046, -0.07896023988723755, -0.06329027563333511, 0.01656162552535534, -0.073207326233387, -0.03029610961675644, -0.18344636261463165, 0.02993733249604702, -0.12575596570968628, -0.014732103794813156, -0.130792498588562, -0.007059690076857805, -0.08802993595600128, -0.04886135086417198, 0.14947083592414856, -0.11518284678459167, 0.17104433476924896, -0.008059386163949966, 0.06006225198507309, 0.08595900982618332, 0.00704558240249753, -0.14797690510749817, 0.10506070405244827, 0.17863282561302185, -0.0796077623963356, 0.09247612208127975, -0.06252877414226532, -0.02487136982381344, -0.054478831589221954, 0.11394607275724411, 0.14747074246406555, 0.04822172597050667, -0.13730910420417786, 0.08744238317012787, 0.052272044122219086, -0.04695703089237213, 0.07355736196041107, -0.08048785477876663, -0.14383597671985626, 0.19513142108917236, -0.056448984891176224, 0.10610982030630112, 0.1319293975830078, -0.13533824682235718, -0.17515252530574799, -0.006336916703730822, 0.15001830458641052, 0.0036969692446291447, 0.1407259851694107, 0.05092016980051994, -0.2088453620672226, -0.032122716307640076, 0.03837938606739044, -0.02997456304728985, -0.05796341970562935, 0.02357061393558979, -0.20795029401779175, -0.14223138988018036, 0.054758328944444656, -0.04333777353167534, -0.0772213563323021, 0.12238269299268723, 0.025596803054213524, 0.05720534175634384, 0.09528928995132446, 0.012448453344404697, 0.1546853929758072, 0.0005311939748935401, 0.10443783551454544, 0.0002615122648421675, 0.0692301094532013, 0.03240102156996727, 0.02056754194200039, -0.0124363973736763, 8.25195932251292e-33, -0.01213726308196783, 0.0857609286904335, 0.03341119363903999, -0.00048410167801193893, 0.022115200757980347, -0.08709076792001724, -0.0792352631688118, 0.02313501574099064, -0.15247605741024017, -0.030651194974780083, -0.014027639292180538, 0.06756559759378433, -0.027035143226385117, 0.1240643858909607, 0.06487233191728592, -0.028669526800513268, -0.016046898439526558, -0.16808819770812988, 0.019261352717876434, 0.06583697348833084, -0.046230725944042206, 0.007293589413166046, 0.05972515419125557, -0.11854192614555359, -0.1046532467007637, -0.012694005854427814, 0.08093906939029694, -0.10134284198284149, -0.15116646885871887, -0.01334451138973236, -0.18903784453868866, 0.05097467824816704, 0.09368600696325302, 0.008039282634854317, 0.14860330522060394, -0.08651311695575714, -0.13588577508926392, 0.06685719639062881, 0.015387268736958504, -0.11181119084358215, -0.0783749595284462, 0.1037970781326294, -0.0017718952149152756, -0.02779771387577057, 0.03413758799433708, 0.10164710879325867, -0.04531203955411911, -0.021760208532214165, 0.0938909724354744, 0.18055354058742523, 0.08732038736343384, -0.11104244738817215, -0.03340727835893631, 0.09202650189399719, -0.10113408416509628, 0.010960114188492298, -0.023692920804023743, -0.02467915415763855, 0.1601315289735794, -0.09910418838262558, 0.041742097586393356, -0.006092710420489311, 0.06526307016611099, -0.16040103137493134, 0.0776040181517601, 0.13970956206321716, -0.05128288269042969, 0.10200323164463043, 0.0787181407213211, 0.0009721656097099185, -0.0137712387368083, 0.08464726060628891, -0.013094899244606495, -0.12950138747692108, 0.018716301769018173, -0.001818411867134273, 1.883901859400794e-05, -0.12497302144765854, -0.04135526716709137, 0.031101511791348457, 0.04057672247290611, -0.20767918229103088, 0.11332696676254272, -0.11261032521724701, -0.10303111374378204, -0.08373698592185974, 0.062049418687820435, -0.07983911782503128, 0.019455743953585625, 0.004164471756666899, -0.22601613402366638, 0.0758606493473053, -0.019139274954795837, 0.03423147276043892, 0.024063631892204285, -9.537294804211918e-33, -0.05253579467535019, -0.0230349563062191, -0.1552387923002243, 0.016275258734822273, -0.062072157859802246, -0.01550646498799324, -0.013754098676145077, 0.08455343544483185, 0.06836564838886261, -0.0044322144240140915, -0.11183937638998032, -0.03995992988348007, 0.11723420023918152, -0.03915192186832428, 0.015283740125596523, -0.002047512447461486, -0.07916666567325592, 0.09739980101585388, 0.02752920612692833, 0.1160096526145935, -0.13644908368587494, 0.1989651322364807, -0.15957006812095642, 0.042826663702726364, -0.009032954461872578, 0.08667665719985962, 0.04052622243762016, 0.008434013463556767, -0.08226548880338669, -0.019256947562098503, 0.018109044060111046, 0.07827083021402359, 0.007132964674383402, 0.10481058061122894, -0.10813096910715103, -0.0833473652601242, -0.014796712435781956, -0.15141312777996063, -0.03078051470220089, 0.04053059592843056, 0.16163679957389832, 0.1778760701417923, -0.018141884356737137, -0.10378684103488922, -0.09407498687505722, 0.010631290264427662, -0.13013440370559692, -0.004188911058008671, -0.007590475492179394, -0.021937433630228043, -0.04282056540250778, 0.07380173355340958, -0.11647581309080124, 0.1276201456785202, -0.045518774539232254, -0.12110675126314163, -0.10736905783414841, -0.10846051573753357, 0.019545650109648705, 0.06936505436897278, -0.18561574816703796, -0.00047998534864746034, 0.02400187961757183, -0.04401504620909691, 0.062441010028123856, -0.12333676218986511, -0.043359704315662384, 0.019419752061367035, -0.019960487261414528, 0.03017808496952057, -0.0025984649546444416, 0.1741013377904892, -0.07320491224527359, -0.05588649585843086, -0.04746639356017113, 0.019377494230866432, -0.024404874071478844, 0.020753836259245872, -0.13888365030288696, -0.01001930981874466, 0.0033583075273782015, -0.1072462946176529, 0.05033278465270996, -0.005047092214226723, -0.03000013343989849, -0.05239614099264145, 0.02240031771361828, 0.13767187297344208, 0.035341545939445496, 0.006030149757862091, -0.04635022580623627, 0.006992195267230272, 0.10262227058410645, 0.13443584740161896, 0.13244414329528809, -9.983536131130677e-08, -0.13800610601902008, -0.09647788107395172, -0.04491517320275307, 0.1173207014799118, -0.015998966991901398, -0.03238366171717644, 0.05673208460211754, 0.07080123573541641, -0.036461856216192245, 0.012431255541741848, 0.18557265400886536, 0.11467491090297699, -0.19224241375923157, -0.09175485372543335, -0.1871504783630371, 0.17558546364307404, 0.059778034687042236, 0.0882045179605484, 0.09301254153251648, 0.032502058893442154, 0.19933786988258362, -0.008999710902571678, 0.03189161792397499, 0.07032278180122375, 0.02742563933134079, -0.046121660619974136, -0.03155802562832832, -0.11353567242622375, -0.06689448654651642, -0.002783598843961954, 0.12618638575077057, -0.004997605923563242, -0.11024142056703568, -0.07580532878637314, 0.058524031192064285, 0.13464945554733276, -0.05338210612535477, -0.061563000082969666, 0.06874293833971024, 0.008146636188030243, 0.012977104634046555, 0.13120949268341064, -0.21309708058834076, -0.10322359949350357, 0.11029081046581268, -0.028167691081762314, 0.04383757710456848, -0.25932615995407104, 0.054595861583948135, 0.03105541132390499, 0.08298765122890472, 0.041429661214351654, -0.028041338548064232, 0.015242368914186954, 0.09118161350488663, 0.040609147399663925, -0.06139601394534111, -0.027055084705352783, -0.014803419820964336, 0.05446824058890343, 0.16173715889453888, -0.016073575243353844, -0.0084415627643466, 0.05201728641986847], metadata={'source': 'AAAMLP-569to.pdf', 'page': 225}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 226 one sentence contributes to the sentiment, but the sentiment score is a combination of score from multiple sentences. A snapshot of the data is presented in figure 1. \\n Figure 1. Snapshot of IMDB movie review dataset.  How would you start with such a problem?   A simple way would be just to create two handmade lists of words. One list will contain all the positive words you can imagine, for example, good, awesome, nice, etc. and another list will include all the negative words, such as bad, evil, etc. Let’s leave examples of bad words else I’ll have to make this book available only for 18+. Once you have these lists, you do not even need a model to make a prediction. These lists are also known as sentiment lexicons. A bunch of them for different languages are available on the internet.  You can have a simple counter that counts the number of positive and negative words in the sentence. If the number of positive words is higher, it is a positive sentiment, and if the number of negative words is higher, it is a sentence with a negative sentiment. If none of them are present in the sentence, you can say that the sentence has a neutral sentiment. This is one of the oldest ways, and some people still use it. It does not require much code either.  ═════════════════════════════════════════════════════════════════════════ def find_sentiment(sentence, pos, neg):     \"\"\"     This function returns sentiment of sentence     :param sentence: sentence, a string     :param pos: set of positive words     :param neg: set of negative words     :return: returns positive, negative or neutral sentiment     \"\"\"          # split sentence by a space'),\n",
       " VectorParams(vector=[-0.05067749321460724, 0.037350501865148544, 0.1491052657365799, 0.03677517920732498, -0.016873273998498917, -0.11495700478553772, 0.1510273963212967, 0.07439333200454712, -0.007094974629580975, 0.05274765193462372, 0.13883507251739502, -0.1072518602013588, 0.06196140497922897, 0.004614720586687326, 0.12991337478160858, 0.033104557543992996, 0.03911929950118065, 0.0573461577296257, -0.29135289788246155, -0.09469497948884964, 0.1351218819618225, 0.07592613250017166, -0.07295088469982147, 0.006416885182261467, 0.0225826408714056, 0.04212728887796402, -0.027490656822919846, 0.04986952617764473, -0.08648046851158142, 0.05416128784418106, 0.042442429810762405, -0.02112143486738205, 0.08022814244031906, 0.16917364299297333, -0.012850722298026085, 0.042464785277843475, -0.12523865699768066, -0.028388503938913345, -0.04634718596935272, -0.038291219621896744, -0.12528769671916962, -0.1019015908241272, -0.03869812563061714, 0.02465679869055748, 0.1939161866903305, 0.07366707175970078, -0.15977756679058075, 0.007946026511490345, 0.023700006306171417, -0.11181295663118362, -0.09680826216936111, 0.21418987214565277, -0.09001453220844269, 0.24000383913516998, -0.014809929765760899, -0.018155574798583984, 0.01567836105823517, -0.032310232520103455, 0.019062059000134468, -0.1088225319981575, -0.12036551535129547, -0.08121399581432343, -0.053836606442928314, -0.07925385236740112, 0.07437407225370407, -0.11642264574766159, -0.031691379845142365, 0.05706222727894783, 0.06775039434432983, 0.178060844540596, -0.14776954054832458, 0.16301508247852325, -0.05051135644316673, 0.062096185982227325, -0.20018328726291656, 0.18357178568840027, 0.16248510777950287, 0.03298074007034302, 0.1419873684644699, 0.02173367515206337, 0.04598376899957657, 0.044075120240449905, 0.09187464416027069, 0.07910075783729553, 0.06034266576170921, -0.18547680974006653, -0.1392236053943634, 0.08016109466552734, 0.013609947636723518, 0.009648430161178112, -0.08090290427207947, -0.1340586394071579, 0.1737932562828064, -0.08656839281320572, 0.11754103749990463, 0.06418502330780029, -0.07761912047863007, 0.004999868106096983, -0.011004753410816193, 0.20863811671733856, 0.06295756995677948, 0.07486380636692047, 0.08252038061618805, -0.24135923385620117, -0.07726064324378967, 0.008965380489826202, 0.10690608620643616, -0.15550978481769562, 0.2448841631412506, -0.14984893798828125, -0.019816981628537178, -0.015834897756576538, -0.04044061526656151, 0.016579849645495415, 0.11182738840579987, 0.02306489832699299, 0.08960220217704773, 0.06539247184991837, 0.12823615968227386, 0.16895753145217896, -0.06287533044815063, -0.020766640082001686, 0.02951265685260296, 0.12394186109304428, 0.08375972509384155, -0.053144268691539764, 0.03989202529191971, 7.958564748755308e-33, -0.18902532756328583, 0.0974026471376419, -0.0026890551671385765, -0.03030647337436676, -0.0920085459947586, -0.04928382486104965, -0.1074213907122612, 0.11672744154930115, -0.1136142835021019, -0.023563385009765625, 0.032083429396152496, 0.008955983445048332, 0.029839225113391876, 0.006572751794010401, 0.05058730021119118, 0.009935492649674416, 0.006858205888420343, -0.11126244068145752, -0.043942734599113464, 0.04034779593348503, -0.05616938695311546, 0.01030217856168747, 0.049044206738471985, 0.06971819698810577, -0.09638559073209763, -0.101485475897789, 0.00574120506644249, -0.29829543828964233, -0.026449570432305336, -0.009581165388226509, -0.267069011926651, -0.029970474541187286, 0.12227299064397812, 0.10261611640453339, 0.13413108885288239, 0.052607785910367966, -0.07413755357265472, 0.05080817639827728, -0.13800477981567383, -0.09043639153242111, -0.20094770193099976, -0.02595558390021324, 0.12081053853034973, -0.020605867728590965, 0.0179271399974823, -0.03800318390130997, -0.10669025778770447, 0.058035098016262054, 0.02272939868271351, 0.10386501252651215, 0.1139797642827034, -0.013826440088450909, -0.017839757725596428, 0.07802590727806091, -0.009866757318377495, -0.00212035677395761, 0.09757623076438904, 0.042865753173828125, 0.11224585771560669, 0.0033436070661991835, -0.03545159846544266, -0.033277783542871475, 0.08836936205625534, 0.07634929567575455, 0.009018287993967533, 0.07940805703401566, -0.0179954394698143, 0.12562556564807892, 0.06970392912626266, 0.03973473608493805, -0.11206557601690292, 0.004554708022624254, -0.13700510561466217, -0.033732570707798004, -0.06450577825307846, -0.011627456173300743, 0.18144822120666504, -0.059389568865299225, -0.1323796659708023, -0.06399156898260117, 0.09112517535686493, -0.0010826963698491454, 0.0002881932305172086, -0.07821621000766754, -0.15958766639232635, -0.21600621938705444, 0.09302378445863724, -0.05848841369152069, -0.034228596836328506, -0.144327312707901, 0.011153697036206722, 0.04152315855026245, -0.04674014076590538, 0.026384416967630386, 0.06947232037782669, -9.536136207592389e-33, 0.013532586395740509, 0.012764409184455872, -0.22301560640335083, -0.09050010144710541, -0.11018813401460648, -0.11709189414978027, 0.07557445764541626, 0.037436824291944504, 0.0015279501676559448, -0.1156148687005043, -0.08191085606813431, -0.025563929229974747, 0.12535136938095093, 0.020791012793779373, 0.012240239419043064, 0.04416429251432419, -0.032098300755023956, 0.28554967045783997, 0.11226604878902435, 0.13348209857940674, -0.01711653359234333, 0.1586691290140152, -0.1783181130886078, 0.036285221576690674, -0.08581899106502533, 0.12046356499195099, -0.07810342311859131, 0.007862095721065998, -0.06685958057641983, 0.0653856098651886, -0.1574777364730835, 0.053633466362953186, 0.011046592146158218, 0.060216426849365234, -0.0854293629527092, -0.12188192456960678, -0.081248439848423, -0.041524533182382584, -0.011940243653953075, -0.05164584517478943, 0.12667271494865417, 0.17885595560073853, -0.026441330090165138, 0.02966100536286831, -0.05506857857108116, -0.008278151974081993, -0.14850428700447083, 0.015802381560206413, -0.07873321324586868, 0.03833862766623497, 0.0021475839894264936, -0.025391340255737305, -0.0958840399980545, 0.07196903973817825, -0.1499709039926529, 0.022819923236966133, -0.061603132635354996, -0.072176992893219, -0.2296648770570755, -0.10173521935939789, -0.17400291562080383, 0.04580563306808472, 0.12262985855340958, 0.0057153115049004555, 0.14209452271461487, -0.061117008328437805, -0.08695238828659058, 0.14726482331752777, -0.04674253985285759, -0.1291865110397339, -0.12852223217487335, 0.07817937433719635, -0.10976153612136841, -0.0483594611287117, -0.09660907089710236, 0.12287593632936478, 0.10704171657562256, -0.19839812815189362, -0.19704191386699677, -0.05234744772315025, -0.06842977553606033, -0.10625586658716202, 0.0843888595700264, -0.017919087782502174, -0.16795508563518524, 0.0504770390689373, 0.008756568655371666, 0.16948433220386505, 0.057222697883844376, -0.03626721724867821, 0.01592962071299553, 0.019554758444428444, 0.029435014352202415, 0.19434545934200287, -0.025680482387542725, -1.0004398376395329e-07, -0.05147877708077431, 0.005271318834275007, -0.0820508673787117, 0.09070724248886108, 0.03492751345038414, 0.03394234925508499, -0.04088694602251053, -0.06496712565422058, -0.04186436906456947, -0.020311811938881874, -0.0026539782993495464, 0.049192674458026886, -0.27860918641090393, -0.11648133397102356, -0.09561716020107269, 0.14343492686748505, 0.01983443647623062, 0.07991669327020645, -0.07400768250226974, -0.040794435888528824, 0.04507321119308472, -0.03954793140292168, -0.06432481110095978, 0.17669440805912018, -0.07538255304098129, 0.035393018275499344, 0.02399025484919548, 0.07413174957036972, -0.05989532917737961, -0.09976949542760849, 0.041365306824445724, 0.056048035621643066, -0.11825990676879883, -0.025170860812067986, 0.006846751552075148, 0.21971729397773743, 0.03653453290462494, 0.01768428273499012, 0.11246616393327713, 0.05406583100557327, -0.007723161485046148, 0.0669013112783432, -0.11765018105506897, -0.017714569345116615, 0.013094001449644566, -0.052216384559869766, 0.030500197783112526, -0.14710816740989685, 0.20978528261184692, -0.056800033897161484, 0.03434997797012329, 0.060117825865745544, -0.07480508089065552, -0.10274136811494827, 0.015152214094996452, 0.12030206620693207, 0.05537187680602074, 0.12430048733949661, -0.060271378606557846, -0.08183443546295166, 0.15255782008171082, 0.059269558638334274, 0.08645779639482498, 0.018555395305156708], metadata={'source': 'AAAMLP-569to.pdf', 'page': 226}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 227     # \"this is a sentence!\" becomes:     # [\"this\", \"is\" \"a\", \"sentence!\"]     # note that im splitting on all whitespaces     # if you want to split by space use .split(\" \")     sentence = sentence.split()          # make sentence into a set     sentence = set(sentence)          # check number of common words with positive     num_common_pos = len(sentence.intersection(pos))          # check number of common words with negative     num_common_neg = len(sentence.intersection(neg))          # make conditions and return     # see how return used eliminates if else     if num_common_pos > num_common_neg:         return \"positive\"     if num_common_pos < num_common_neg:         return \"negative\"     return \"neutral\" ═════════════════════════════════════════════════════════════════════════  However, this kind of approach does not take a lot into consideration. And as you can see that our split() is also not perfect. If you use split(), a sentence like:  “hi, how are you?”  gets split into  [“hi,”, “how”, “are”, “you?”]  This is not ideal, because you see the comma and question mark, they are not split. It is therefore not recommended to use this method if you don’t have a pre-processing that handles these special characters before the split. Splitting a string into a list of words is known as tokenization. One of the most popular tokenization comes from NLTK (Natural Language Tool Kit).  ═════════════════════════════════════════════════════════════════════════ In [X]: from nltk.tokenize import word_tokenize  In [X]: sentence = \"hi, how are you?\"'),\n",
       " VectorParams(vector=[-0.04662201553583145, -0.07925863564014435, 0.004925495479255915, 0.07771135121583939, 0.12360240519046783, 0.04437912255525589, 0.11451102048158646, 0.06016277149319649, 0.0268233772367239, 0.014273942448198795, -0.015041875652968884, -0.09847445040941238, 0.07943111658096313, -0.04395049065351486, 0.09632058441638947, 0.10461006313562393, 0.08632795512676239, 0.02986743114888668, -0.1606290489435196, -0.09064272791147232, 0.10324688255786896, 0.11261364072561264, -0.02265247330069542, 0.07577372342348099, -0.023115290328860283, 0.1027032732963562, 0.003256923519074917, 0.018319908529520035, -0.11858459562063217, 0.015509497374296188, -0.0031421841122210026, 0.06414870917797089, -0.04897003993391991, 0.19684363901615143, -0.08927691727876663, 0.027963625267148018, 0.017702888697385788, 0.015409584157168865, -0.00010542956442805007, -0.04056315869092941, -0.11740044504404068, -0.11208435148000717, -0.05080406740307808, 0.0033236208837479353, 0.23562927544116974, 0.0552988275885582, -0.07017908245325089, 0.04164692386984825, 0.015656253322958946, 0.055187124758958817, -0.0995025560259819, 0.14814838767051697, 0.017618617042899132, 0.20344896614551544, -0.0469309501349926, -0.08209794014692307, -0.017905017361044884, -0.033098213374614716, 0.10923989862203598, -0.05536607652902603, -0.07662765681743622, -0.16678431630134583, 0.0023777105379849672, -0.05353083461523056, -0.11367959529161453, -0.11575396358966827, -0.021238187327980995, 0.04827854037284851, 0.03796520456671715, 0.07491954416036606, 0.032129764556884766, 0.15733419358730316, 0.0499306358397007, 0.09909412264823914, -0.1401919573545456, 0.009306647814810276, 0.1541629284620285, -0.010813070461153984, 0.17755453288555145, 0.007090553641319275, -0.06064969301223755, -0.011261407285928726, 0.0714435949921608, 0.08186753839254379, 0.03009422868490219, -0.16785162687301636, 0.031798623502254486, 0.04009508714079857, -0.1497127264738083, 0.03529181703925133, 0.0226393211632967, -0.09180786460638046, 0.10537917912006378, -0.1876644790172577, 0.119227334856987, 0.032185692340135574, -0.059906940907239914, -0.05119708180427551, 0.043263718485832214, 0.21668164432048798, 0.0893012136220932, 0.014597497880458832, -0.03723249211907387, -0.13941025733947754, -0.10708830505609512, 0.09330648183822632, -0.032043326646089554, -0.05580683797597885, 0.19186072051525116, -0.14705947041511536, -0.07743419706821442, 0.005268076900392771, -0.03868287429213524, 0.04612313583493233, 0.1753939688205719, -0.023065010085701942, 0.07175002992153168, 0.06381826847791672, 0.09275941550731659, 0.17493022978305817, -0.06357558816671371, 0.04681738093495369, 0.06381110101938248, 0.025512835010886192, 0.08036891371011734, 0.07046791911125183, 0.05578165128827095, 1.0234844172249403e-32, -0.10237517952919006, 0.0798630490899086, -0.02774704061448574, 0.007908491417765617, -0.044272929430007935, -0.10936694592237473, 0.033878691494464874, 0.11185762286186218, -0.10588781535625458, -0.03220613673329353, -0.0020194004755467176, 0.09597423672676086, 0.04603521525859833, 0.0834852010011673, 0.025248562917113304, -0.07360434532165527, -0.04206423833966255, -0.12482183426618576, -0.04161596670746803, -0.026970377191901207, -0.033623483031988144, -0.003418851410970092, 0.11233147978782654, 0.04060938209295273, -0.10794035345315933, -0.175447016954422, 0.03287626802921295, -0.18187950551509857, -0.09043082594871521, 0.0072715915739536285, -0.17463980615139008, -0.014097532257437706, 0.06624212861061096, 0.03862696886062622, 0.0368393175303936, -0.07763165235519409, -0.017129486426711082, 0.030920878052711487, -0.08110058307647705, -0.18630626797676086, -0.12429007887840271, 0.04709940031170845, 0.05490930378437042, -0.07082327455282211, -0.058817457407712936, 0.16473965346813202, -0.07564647495746613, -0.052180297672748566, 0.07295854389667511, 0.09742826223373413, 0.15430986881256104, -0.1080661341547966, -0.05390471592545509, 0.16731931269168854, 0.045213256031274796, 0.07981973886489868, 0.031027063727378845, -0.09511075913906097, 0.1509874314069748, -0.058985523879528046, 0.007352215237915516, -0.038676753640174866, 0.11347919702529907, -0.01952534168958664, 0.11189401149749756, 0.07945898175239563, -0.000538261083420366, 0.07738760113716125, -0.002802097238600254, -0.0304598156362772, -0.011088813655078411, 0.05378955602645874, -0.02492007240653038, -0.030484437942504883, -0.05162956193089485, 0.05882240831851959, 0.045707374811172485, -0.11054285615682602, -0.10656727105379105, 0.05893564969301224, 0.07348691672086716, -0.1246781274676323, 0.17095647752285004, -0.15311415493488312, -0.08581867814064026, -0.05500777065753937, 0.0704241693019867, -0.15612971782684326, -0.027919799089431763, -0.020821085199713707, -0.10071947425603867, 0.06281384825706482, -0.02347932755947113, -0.022319432348012924, -0.028004031628370285, -1.025197479836073e-32, -0.0704835057258606, -0.006996646523475647, -0.0831180289387703, 0.01818857528269291, -0.10005996376276016, 0.009329487569630146, -0.038404155522584915, 0.0598953440785408, 0.006574337370693684, -0.13466544449329376, -0.014792205765843391, 0.023733647540211678, 0.09957123547792435, 0.02953956089913845, 0.01341927982866764, -0.006609081290662289, -0.03185107186436653, 0.13716503977775574, -0.016923291608691216, 0.17884235084056854, -0.09491124004125595, 0.09355557709932327, -0.15138675272464752, 0.031830888241529465, -0.11129368096590042, 0.005641755647957325, -0.044688042253255844, 0.10977675020694733, 0.008046740666031837, -0.06927092373371124, -0.006782265845686197, 0.04797191545367241, 0.005399151239544153, 0.013028659857809544, 0.011644115671515465, -0.07119756937026978, -0.076405368745327, -0.14294204115867615, -0.056726615875959396, 0.09144698083400726, 0.1257925182580948, 0.19646954536437988, -0.1766144037246704, -0.04793303459882736, -0.12029644846916199, -0.02347620017826557, -0.14497044682502747, 0.06888629496097565, -0.06322310119867325, 0.07246854901313782, 0.028113655745983124, 0.0729588121175766, -0.12823498249053955, 0.1123497262597084, -0.051007431000471115, -0.0784963071346283, -0.0394679419696331, -0.11598982661962509, -0.12402291595935822, 0.015965791419148445, -0.19725055992603302, 0.033676303923130035, 0.09195616841316223, -0.05596493184566498, 0.1574307531118393, -0.09677445888519287, -0.021958496421575546, 0.10541073232889175, -0.0378577746450901, 0.06444204598665237, 0.008420285768806934, 0.07252237200737, -0.09237620234489441, 0.0006102370098233223, 0.011510532349348068, 0.08071024715900421, 0.03292471542954445, -0.10017678886651993, -0.18261750042438507, -0.08242925256490707, -0.03435562551021576, -0.06591172516345978, 0.030372759327292442, -0.0786820501089096, -0.07131747156381607, 0.09336815029382706, 0.05449080467224121, 0.055663954466581345, 0.028140801936388016, -0.03110448829829693, 0.0313631147146225, -0.02726992592215538, 0.06942126154899597, 0.1329609602689743, 0.07979556173086166, -1.0003142136838505e-07, -0.19501250982284546, -0.07235682755708694, -0.08512910455465317, 0.07746045291423798, 0.014055917039513588, -0.003284256439656019, 0.0291461031883955, 0.05799682065844536, -0.10896635800600052, -0.028671961277723312, 0.017924055457115173, 0.042475659400224686, -0.1689867079257965, -0.03427794203162193, -0.09786863625049591, 0.10673044621944427, 0.04960520938038826, 0.034386295825242996, -0.0026878700591623783, -0.06704487651586533, 0.1523384302854538, 0.006657755933701992, 0.03934309631586075, 0.0513264425098896, -0.011366085149347782, -0.08248977363109589, -0.035908959805965424, 0.006836675573140383, -0.0398939847946167, 0.0315675251185894, -0.03315798565745354, 0.030561497434973717, -0.21469217538833618, -0.01598564349114895, 0.15870901942253113, 0.1521325558423996, -0.049397699534893036, -0.06351733952760696, 0.01956806145608425, 0.03906402736902237, -0.03710459545254707, 0.0959041565656662, -0.1589232087135315, -0.046828482300043106, 0.07337107509374619, -0.03647231683135033, -0.0013660824624821544, -0.20962803065776825, 0.10469595342874527, -0.06809192150831223, 0.03859279304742813, 0.03919445723295212, -0.11321176588535309, -0.0010850147809833288, 0.06646236777305603, 0.08999483287334442, -0.12223442643880844, 0.08553452789783478, -0.00960620492696762, 0.016448672860860825, 0.051578789949417114, 0.014489838853478432, 0.016008900478482246, 0.013867678120732307], metadata={'source': 'AAAMLP-569to.pdf', 'page': 227}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 228 In [X]: sentence.split() Out[X]: [\\'hi,\\', \\'how\\', \\'are\\', \\'you?\\']  In [X]: word_tokenize(sentence) Out[X]: [\\'hi\\', \\',\\', \\'how\\', \\'are\\', \\'you\\', \\'?\\'] ═════════════════════════════════════════════════════════════════════════  As you can see, using NLTK’s word tokenize, the same sentence is split in a much better manner. Comparing using a list of words will also work much better now! This is what we will apply to our first model to detect sentiment.  One of the basic models that you should always try with a classification problem in NLP is bag of words. In bag of words, we create a huge sparse matrix that stores counts of all the words in our corpus (corpus = all the documents = all the sentences). For this, we will use CountVectorizer from scikit-learn. Let’s see how it works.  ═════════════════════════════════════════════════════════════════════════ from sklearn.feature_extraction.text import CountVectorizer  # create a corpus of sentences corpus = [     \"hello, how are you?\",     \"im getting bored at home. And you? What do you think?\",     \"did you know about counts\",     \"let\\'s see if this works!\",     \"YES!!!!\" ]  # initialize CountVectorizer ctv = CountVectorizer()  # fit the vectorizer on corpus ctv.fit(corpus)  corpus_transformed = ctv.transform(corpus) ═════════════════════════════════════════════════════════════════════════  If we print corpus_transformed, we get something like the following:  ═════════════════════════════════════════════════════════════════════════      (0, 2) 1   (0, 9) 1   (0, 11) 1   (0, 22) 1'),\n",
       " VectorParams(vector=[0.013464749790728092, -0.043203555047512054, -0.06195751950144768, 0.05227893963456154, 0.03396032750606537, 0.10121390223503113, 0.13957810401916504, -0.06119396910071373, 0.06407414376735687, 0.007752351462841034, 0.02451864257454872, -0.09503411501646042, 0.09238823503255844, -0.05868717283010483, -0.0492250993847847, 0.08236474543809891, 0.012076356448233128, -0.039508525282144547, -0.09504500031471252, -0.13889536261558533, 0.06716668605804443, 0.04841304197907448, 0.0344037190079689, -0.009153572842478752, 0.03990146517753601, 0.12842394411563873, -0.004398637916892767, 0.03307181969285011, -0.00261955545283854, -0.08154582232236862, -0.01576155796647072, 0.13461558520793915, -0.020922383293509483, 0.10858811438083649, -0.01777668483555317, -0.010642014443874359, -0.03611299768090248, 0.0509909950196743, -0.009826590307056904, 0.051488280296325684, -0.01231408677995205, 0.007748878560960293, 0.024950750172138214, 0.02702982723712921, 0.08699557185173035, 0.06228707358241081, -0.05762099474668503, 0.04600010812282562, -0.07082083076238632, 0.0025529232807457447, -0.12029610574245453, 0.1745469570159912, -0.06576772779226303, 0.05426684021949768, 0.04206947237253189, -0.11270420998334885, -0.08646111935377121, -0.09427095949649811, 0.028448855504393578, -0.017523296177387238, -0.060115281492471695, -0.13468271493911743, -0.001977243460714817, -0.07003793120384216, -0.03232599049806595, -0.049606770277023315, -0.002225577598437667, 0.03919538855552673, 0.054735779762268066, 0.07067649811506271, -0.02356046438217163, 0.08421487361192703, -0.025099225342273712, 0.03662726655602455, -0.14546561241149902, 0.01999061182141304, 0.12369043380022049, -0.10269516706466675, 0.20819950103759766, 0.03720385953783989, -0.03004349395632744, 0.004152602981775999, 0.08588334918022156, 0.05689084157347679, 0.002580056432634592, -0.19910384714603424, 0.04178095981478691, -0.0516713410615921, -0.018786806613206863, -0.016100170090794563, 0.047073666006326675, 0.0019156160997226834, 0.01309223286807537, 0.003983179572969675, 0.08372841775417328, 0.0828787088394165, 0.12091796100139618, 0.10072965919971466, 0.038045842200517654, 0.19986827671527863, 0.02528710477054119, -0.02485881745815277, 0.002253530314192176, -0.02188526652753353, -0.11445241421461105, 0.06492022424936295, -0.02035890333354473, 0.027416344732046127, 0.07038550823926926, -0.15113434195518494, 0.006042684894055128, -0.06847528368234634, -0.07444365322589874, 0.08300274610519409, 0.0651751235127449, -0.05856291577219963, 0.08567550778388977, 0.043258897960186005, 0.12067213654518127, 0.043417613953351974, 0.014037850312888622, 0.028687775135040283, 0.12115675210952759, 0.019754627719521523, -0.03724466636776924, -0.01778615638613701, -0.00532080652192235, 9.925372509192388e-33, -0.009664727374911308, 0.002970791421830654, -0.03641097620129585, -0.07442963868379593, 0.05734603852033615, -0.07441507279872894, 0.0784311592578888, 0.06559263169765472, -0.11101258546113968, 0.008106031455099583, -0.01167863979935646, 0.0872582197189331, 0.0072515569627285, 0.12068406492471695, 0.014770700596272945, -0.05669976770877838, 0.010540793649852276, -0.05284011363983154, -0.04824194312095642, -0.10800209641456604, 0.06684480607509613, 0.033312201499938965, 0.07218996435403824, -0.009721345268189907, -0.11079148948192596, -0.10154527425765991, 0.010080481879413128, -0.18922002613544464, -0.047592081129550934, 0.013636487536132336, -0.14368118345737457, 0.016082780435681343, 0.01099840272217989, -0.05798961967229843, 0.007696808781474829, -0.13774457573890686, 0.09466666728258133, -0.014854181557893753, 0.01822965405881405, -0.1723947525024414, -0.017478810623288155, 0.03144906461238861, 0.09444620460271835, -0.1138703003525734, -0.05074970796704292, 0.06269114464521408, 0.06477174907922745, 0.05153622105717659, -0.07422547787427902, 0.11261539906263351, 0.08275344967842102, -0.10271372646093369, -0.02008419670164585, 0.10165486484766006, 0.026995278894901276, 0.0610588900744915, 0.053878430277109146, -0.026942577213048935, 0.11109503358602524, 0.13550753891468048, -0.012780020013451576, 0.034333642572164536, 0.053718097507953644, 0.0629427433013916, 0.10714208334684372, 0.08835770189762115, 0.02289585955440998, 0.03051071986556053, 0.1677158623933792, -0.038650017231702805, -0.05189789459109306, 0.14123299717903137, 0.02399073727428913, -0.13571064174175262, -0.09936541318893433, -0.02991410158574581, 0.08034376055002213, -0.09943269938230515, -0.1758941113948822, -0.009049126878380775, 0.03546006232500076, -0.011640027165412903, 0.017628634348511696, -0.11758939921855927, -0.1031157597899437, -0.046595312654972076, 0.033323563635349274, -0.1504228264093399, -0.03653218597173691, -0.15196874737739563, 0.0233878493309021, -0.0806310847401619, 0.028141703456640244, -0.08664458990097046, -0.1034284457564354, -9.968544008594275e-33, -0.013134406879544258, -0.03793463110923767, 0.002957989228889346, -0.03323361277580261, 0.10660475492477417, -0.16178229451179504, 0.038469504565000534, -0.03073868528008461, 0.03068636544048786, -0.11803191900253296, -0.10572624951601028, 0.02450704760849476, 0.10916139930486679, 0.048814695328474045, 0.11655784398317337, 0.05506911128759384, -0.07976458221673965, 0.03521115332841873, -0.10756261646747589, 0.06484618782997131, -0.04994875565171242, 0.17772367596626282, -0.10869795083999634, 0.04717544838786125, -0.06566566228866577, 0.014356981962919235, 0.07881224900484085, -0.007361420430243015, 0.05899506062269211, -0.05970082804560661, 0.07988692820072174, -0.08614369481801987, -0.03106604889035225, -0.03097383864223957, 0.00029816979076713324, -0.0461747869849205, 0.022414876148104668, -0.07687659561634064, -0.14675037562847137, 0.030216358602046967, 0.06696638464927673, 0.0834214836359024, -0.06448568403720856, 0.019546445459127426, -0.005148161202669144, 0.06234417110681534, -0.03474874794483185, 0.013981396332383156, -0.08492697030305862, -0.006234352011233568, 0.03315234184265137, 0.012299902737140656, -0.06146220862865448, 0.0979003831744194, -0.0549161471426487, -0.031527504324913025, -0.10487651079893112, -0.07687269151210785, -0.0009362862911075354, -0.06423369795084, -0.02290106937289238, -0.03636235371232033, -0.027447354048490524, 0.025551006197929382, 0.2315623015165329, -0.007864240556955338, -0.16335023939609528, -0.04828489571809769, -0.09507371485233307, 0.1004108414053917, -0.05904603749513626, -0.06131730228662491, -0.07911165803670883, -0.06688427925109863, 0.0799168273806572, 0.08940993249416351, -0.03631874546408653, -0.0361991710960865, -0.1345081478357315, -0.011414515785872936, -0.16993652284145355, -0.08325941860675812, 0.062458235770463943, 0.0620628297328949, -0.04090272635221481, 0.03332166001200676, 0.12710274755954742, 0.08598419278860092, 0.0540178045630455, 0.03158045932650566, 0.03480112925171852, -0.01140601933002472, 0.029030919075012207, 0.14082340896129608, -0.018812071532011032, -1.0106267467335783e-07, -0.2001323401927948, -0.07409380376338959, -0.10758452862501144, -0.03268947824835777, 0.1556997299194336, -0.08272793889045715, 0.044258538633584976, 0.048975247889757156, -0.09878316521644592, -0.022153303027153015, 0.10498299449682236, -0.0543857105076313, -0.11074495315551758, -0.01060486026108265, -0.0001832264824770391, 0.07441926747560501, 0.01638856530189514, 0.02074442058801651, -0.03150506690144539, -0.023037301376461983, 0.056096989661455154, -0.02224591001868248, -0.002825006376951933, 0.055556803941726685, -0.0934959352016449, -0.035758327692747116, -0.014791853725910187, 0.08375807851552963, 0.10846863687038422, 0.02823742665350437, -0.019943388178944588, -0.0013127358397468925, 0.004157948773354292, -0.026624085381627083, 0.03880391642451286, 0.04368538782000542, -0.025305259972810745, -0.0989396721124649, -0.09107957035303116, 0.010023476555943489, -0.06689947843551636, -0.03787488490343094, -0.040937233716249466, 0.022778697311878204, 0.09881897270679474, -0.059656284749507904, -0.11358008533716202, -0.12158903479576111, 0.1157459169626236, -0.12770500779151917, -0.14382725954055786, -0.03893447294831276, -0.10034491866827011, 0.06522570550441742, 0.12085191905498505, 0.033046167343854904, -0.06961610913276672, 0.07339093089103699, 0.10741700977087021, 0.004401708487421274, 0.0622614249587059, 0.07090505212545395, -0.023526905104517937, 0.025729501619935036], metadata={'source': 'AAAMLP-569to.pdf', 'page': 228}, content=\"Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 229   (1, 1) 1   (1, 3) 1   (1, 4) 1   (1, 7) 1   (1, 8) 1   (1, 10) 1   (1, 13) 1   (1, 17) 1   (1, 19) 1   (1, 22) 2   (2, 0) 1   (2, 5) 1   (2, 6) 1   (2, 14) 1   (2, 22) 1   (3, 12) 1   (3, 15) 1   (3, 16) 1   (3, 18) 1   (3, 20) 1   (4, 21) 1 ═════════════════════════════════════════════════════════════════════════  We have already seen this representation in previous chapters. It is the sparse representation. So, our corpus is now a sparse matrix, where, for first sample, we have four elements, for sample 2 we have ten elements, and so on, for sample 3 we have five elements and so on. We also see that these elements have a count associated with them. Some are seen twice, some are seen only once. For example, in sample 2 (row 1), we see that column 22 has a value of two. Why is that? And what is column 22?  The way CountVectorizer works is it first tokenizes the sentence and then assigns a value to each token. So, each token is represented by a unique index. These unique indices are the columns that we see. The CountVectorizer stores this information.  ═════════════════════════════════════════════════════════════════════════ print(ctv.vocabulary_) {'hello': 9, 'how': 11, 'are': 2, 'you': 22, 'im': 13, 'getting': 8, 'bored': 4, 'at': 3, 'home': 10, 'and': 1, 'what': 19, 'do': 7, 'think': 17, 'did': 6, 'know': 14, 'about': 0, 'counts': 5, 'let': 15, 'see': 16, 'if': 12, 'this': 18, 'works': 20, 'yes': 21} ═════════════════════════════════════════════════════════════════════════\"),\n",
       " VectorParams(vector=[0.0034276102669537067, -0.059531982988119125, 0.008182751014828682, 0.08263125270605087, -0.010501588694751263, 0.0348358191549778, 0.13678908348083496, 0.0331423319876194, 0.0987943634390831, -0.0029064910486340523, 0.1329340785741806, -0.11597655713558197, 0.11442609131336212, 0.006715862080454826, 0.06681355834007263, 0.06623221188783646, 0.02886822074651718, 0.05738949775695801, -0.212488055229187, -0.10420118272304535, 0.08468315750360489, 0.10240288078784943, 0.04398711398243904, 0.02187798172235489, 0.08699814975261688, 0.0995795726776123, -0.07282310724258423, -0.01755567640066147, -0.013640478253364563, 0.016620827838778496, -0.0036229188553988934, 0.0905972346663475, 0.020753785967826843, 0.13779562711715698, 0.037721436470746994, -0.014042280614376068, -0.01660344749689102, 0.05086624622344971, 0.005185011774301529, -0.03640618920326233, -0.11848998069763184, -0.037844281643629074, -0.006588414777070284, 0.09415119886398315, 0.11618933826684952, -0.02252635732293129, -0.18536248803138733, 0.03630099818110466, 0.057098038494586945, 0.02412145957350731, -0.11164747923612595, 0.160067617893219, -0.05818789452314377, 0.1675272285938263, 0.015716513618826866, -0.03893522918224335, -0.039649948477745056, -0.025696109980344772, 0.061630189418792725, -0.09695693850517273, -0.06597196310758591, -0.08512123674154282, 0.00861547701060772, -0.05256308242678642, -0.08219354599714279, -0.11468351632356644, -0.060736607760190964, 0.07641571015119553, 0.07580374926328659, 0.09391403198242188, -0.06283102184534073, 0.0684424415230751, -0.0023363493382930756, 0.05463444069027901, -0.10220295190811157, 0.03609262779355049, 0.12633472681045532, -0.07111342251300812, 0.23436149954795837, 0.03377964347600937, -0.03225976228713989, -0.03502584248781204, 0.0844542384147644, 0.09287495166063309, 0.02446543052792549, -0.11961933970451355, 0.05454520881175995, -0.0019471962004899979, -0.0083392933011055, -0.04153280705213547, -0.03369046375155449, -0.16088156402111053, 0.08159373700618744, -0.10812970250844955, 0.014288602396845818, 0.04099581018090248, 0.015293119475245476, 0.03830122575163841, 0.006752115674316883, 0.2218363881111145, 0.031030546873807907, -0.039388902485370636, -0.0017868522554636002, -0.11362815648317337, -0.1159629225730896, 0.08594956994056702, 0.052722617983818054, -0.0750732272863388, 0.21485865116119385, -0.11449538916349411, -0.07112224400043488, -0.015239863656461239, -0.04283253848552704, 0.03611725568771362, 0.14844444394111633, 0.00023290514945983887, 0.10610095411539078, 0.05114905908703804, 0.09228821098804474, 0.12144052982330322, -0.08600421249866486, 0.06862451136112213, 0.04147898033261299, 0.06401262432336807, -0.005734582431614399, -0.06817302852869034, 0.07088568061590195, 9.238578914464928e-33, -0.05243929475545883, 0.022364672273397446, -0.014156346209347248, -0.02930675633251667, 0.029968159273266792, -0.07112939655780792, 0.01521771028637886, 0.13415062427520752, -0.08843635022640228, -0.00786711648106575, -0.006865477189421654, 0.031213989481329918, -0.027011211961507797, 0.1454356163740158, 0.059743285179138184, -0.0998094379901886, -0.04120860993862152, -0.10072842240333557, 0.020345008000731468, -0.06400000303983688, 0.012380557134747505, -0.023942487314343452, 0.09475643932819366, -0.05810203403234482, -0.1044609397649765, -0.12988166511058807, 0.044525276869535446, -0.2483310103416443, -0.05316396802663803, 0.0271608866751194, -0.18874996900558472, -0.026994042098522186, 0.04594556242227554, -0.011999133974313736, -0.041717998683452606, -0.12203656136989594, 0.04318676516413689, -0.004903390072286129, -0.05166977643966675, -0.12177635729312897, -0.10804503411054611, 0.025892363861203194, 0.015534757636487484, -0.12610659003257751, 0.00030809640884399414, 0.1155441552400589, 0.14513862133026123, 0.001466061919927597, -0.04572298750281334, 0.09401405602693558, 0.0911109447479248, -0.07591180503368378, -0.10954512655735016, 0.0651458129286766, 0.016017453745007515, 0.09790545701980591, 0.06635046005249023, -0.06505291908979416, 0.12041432410478592, 0.05783146619796753, -0.016679538413882256, 0.01559494063258171, 0.12041741609573364, 0.05417179316282272, 0.213495671749115, 0.03407933562994003, -0.01828356646001339, 0.08328618109226227, 0.039937037974596024, -0.011919585056602955, -0.08142417669296265, 0.060128048062324524, -0.03516802191734314, -0.05858005955815315, -0.07913878560066223, -0.001386475283652544, 0.07306864112615585, -0.10914652794599533, -0.19575344026088715, 0.025266146287322044, 0.07207567989826202, -0.15008589625358582, 0.027644004672765732, -0.18061980605125427, -0.09491576999425888, -0.048729151487350464, 0.10985323041677475, -0.17505380511283875, -0.01529879029840231, -0.15651348233222961, -0.0654885470867157, -0.05035829544067383, -0.012661859393119812, -0.07889346033334732, -0.09018997848033905, -1.0642805364174032e-32, -0.014175290241837502, -0.09441093355417252, -0.127781480550766, 0.00769401527941227, 0.0425773523747921, -0.09811757504940033, 0.042381443083286285, 0.07738450914621353, 0.0031047556549310684, -0.12341776490211487, -0.14270876348018646, 0.012203418649733067, 0.08671928942203522, 0.026634156703948975, 0.10295270383358002, 0.020674359053373337, -0.06740350276231766, 0.1695999801158905, -0.02538417838513851, 0.19809424877166748, -0.097618468105793, 0.10798356682062149, -0.2105417549610138, 0.05062677711248398, -0.05425018444657326, 0.05768505483865738, -0.05024529993534088, 0.08794215321540833, 0.0017818072810769081, -0.028746139258146286, -0.008986910805106163, 0.010808398947119713, -0.05978645384311676, 0.0022073788568377495, -0.05764494836330414, -0.10519508272409439, -0.030944176018238068, -0.09886164963245392, -0.1309071183204651, -0.02992519922554493, 0.12997440993785858, 0.12888392806053162, -0.1191844791173935, -0.018798934295773506, -0.09950000047683716, 0.01822635903954506, -0.11312344670295715, 0.015175905078649521, -0.06488937884569168, 0.03263123705983162, 0.05735892057418823, -0.0003120910841971636, -0.18221993744373322, 0.09195463359355927, -0.10690078139305115, -0.02215159311890602, -0.031449344009160995, -0.12238357216119766, -0.06424778699874878, -0.04331054165959358, -0.09277468919754028, -0.027124371379613876, 0.001535562565550208, -0.09859978407621384, 0.1922585666179657, -0.044378459453582764, -0.05860269069671631, 0.09105128794908524, -0.07710815966129303, -0.00032005831599235535, -0.025621462613344193, -0.006398391909897327, -0.021215803921222687, -0.022928107529878616, 0.04228471964597702, 0.06328912824392319, 0.016092007979750633, -0.1214122548699379, -0.13788141310214996, -0.05291774868965149, -0.09554147720336914, -0.0767773762345314, 0.06200278550386429, 0.07954682409763336, -0.019686933606863022, 0.09825925529003143, 0.025574704632163048, 0.10961252450942993, 0.07166054844856262, 0.03933127596974373, 0.009958703070878983, 0.007966448552906513, 0.06352280080318451, 0.17905282974243164, 0.07024366408586502, -1.0082938217692572e-07, -0.15450185537338257, -0.013367904350161552, -0.09555615484714508, -0.001415211707353592, 0.08445373922586441, -0.09026744961738586, -0.062433693557977676, -0.006057462655007839, -0.07925884425640106, -0.07961445301771164, 0.08062474429607391, -0.01474736724048853, -0.20262345671653748, 0.010730363428592682, -0.06147818639874458, 0.139673113822937, 0.06981374323368073, 0.07415690273046494, -0.00756505411118269, -0.0736936628818512, 0.0767974779009819, 0.03421694412827492, -0.028245672583580017, 0.050815533846616745, -0.07987134158611298, 0.05423330143094063, -0.0637008473277092, 0.10906536877155304, 0.021716373041272163, -0.020576588809490204, 0.04901231825351715, 0.043205440044403076, -0.122716024518013, -0.06428766995668411, 0.08294156193733215, 0.09386219084262848, -0.05104083567857742, -0.10357818007469177, -0.07060246169567108, 0.09598815441131592, -0.02181020751595497, 0.0590151883661747, -0.07633724063634872, -0.015427308157086372, 0.07404454052448273, -0.009359532967209816, -0.058824166655540466, -0.185855895280838, 0.17817407846450806, -0.11863334476947784, 0.017557159066200256, 0.018509723246097565, -0.06433197855949402, 0.017929045483469963, 0.14035296440124512, 0.07488460838794708, -0.04061787202954292, 0.1090693473815918, -0.01785169169306755, -0.01569601148366928, 0.09652348607778549, 0.035725902765989304, 0.010303274728357792, -0.019723888486623764], metadata={'source': 'AAAMLP-569to.pdf', 'page': 229}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 230 We see that index 22 belongs to “you” and in the second sentence, we have used “you” twice. Thus, the count is 2. I hope it’s clear now what is bag of words. But we are missing some special characters. Sometimes those special characters can be useful too. For example, “?” denotes a question in most sentences. Let’s integrate word_tokenize from scikit-learn in CountVectorizer and see what happens.  ═════════════════════════════════════════════════════════════════════════ from sklearn.feature_extraction.text import CountVectorizer from nltk.tokenize import word_tokenize   # create a corpus of sentences corpus = [     \"hello, how are you?\",     \"im getting bored at home. And you? What do you think?\",     \"did you know about counts\",     \"let\\'s see if this works!\",     \"YES!!!!\" ]  # initialize CountVectorizer with word_tokenize from nltk # as the tokenizer ctv = CountVectorizer(tokenizer=word_tokenize, token_pattern=None)  # fit the vectorizer on corpus ctv.fit(corpus)  corpus_transformed = ctv.transform(corpus) print(ctv.vocabulary_) ═════════════════════════════════════════════════════════════════════════  This changes our vocabulary to:  ═════════════════════════════════════════════════════════════════════════ {\\'hello\\': 14, \\',\\': 2, \\'how\\': 16, \\'are\\': 7, \\'you\\': 27, \\'?\\': 4, \\'im\\': 18, \\'getting\\': 13, \\'bored\\': 9, \\'at\\': 8, \\'home\\': 15, \\'.\\': 3, \\'and\\': 6, \\'what\\': 24, \\'do\\': 12, \\'think\\': 22, \\'did\\': 11, \\'know\\': 19, \\'about\\': 5, \\'counts\\': 10, \\'let\\': 20, \"\\'s\": 1, \\'see\\': 21, \\'if\\': 17, \\'this\\': 23, \\'works\\': 25, \\'!\\': 0, \\'yes\\': 26} ═════════════════════════════════════════════════════════════════════════  Now, we have more words in the vocabulary. Thus, we can now create a sparse matrix by using all the sentences in IMDB dataset and can build a model. The ratio to positive and negative samples in this dataset is 1:1, and thus, we can use accuracy as the metric. We will use StratifiedKFold and create a single script to train five'),\n",
       " VectorParams(vector=[-0.053991176187992096, -0.14249823987483978, -0.05061399191617966, 0.07118318229913712, 0.06018747389316559, -0.04306608438491821, 0.08244941383600235, 0.044282108545303345, -0.04269781708717346, 0.04002846032381058, 0.0829598680138588, -0.06403204798698425, -0.04603465646505356, -0.06736181676387787, 0.08585110306739807, 0.1092354953289032, 0.06356272101402283, 0.01382592972368002, -0.18633244931697845, -0.05257890000939369, 0.06089053675532341, 0.07925005257129669, -0.01002591010183096, 0.05090347304940224, 0.012029899284243584, -0.07308036088943481, 0.04157605022192001, 0.05115047097206116, -0.10917314141988754, -0.03260434418916702, -0.051567818969488144, 0.049303602427244186, 0.03625601530075073, 0.07774374634027481, -0.02947024628520012, 0.06210149824619293, -0.11355648934841156, 0.008411796763539314, 0.03462383151054382, 0.09886667877435684, -0.09271889925003052, -0.06786811351776123, -0.0635887086391449, 0.0007871754933148623, 0.1739722639322281, -0.033083830028772354, -0.056120261549949646, 0.03438475728034973, 0.1373419165611267, 0.000384797400329262, -0.08680037409067154, 0.10733897238969803, -0.09443726390600204, -0.031148681417107582, -0.18103960156440735, -0.1417710781097412, 0.04930644482374191, -0.07543550431728363, 0.03923870250582695, -0.02976261079311371, -0.022654138505458832, -0.12607444822788239, 0.017131276428699493, -0.1273476779460907, -0.005389419849961996, -0.13395480811595917, -0.0760161280632019, 0.056945521384477615, -0.054427620023489, 0.11373691260814667, -0.021361762657761574, 0.12239283323287964, -0.005122797563672066, 0.017157694324851036, -0.0665547251701355, -0.024849852547049522, 0.16870073974132538, -0.07750684022903442, 0.12458556890487671, 0.00671578012406826, -0.10012221336364746, 0.010400237515568733, 0.04525450989603996, 0.057236768305301666, -0.030068878084421158, -0.3079396188259125, 0.2188848853111267, 0.02081056497991085, 0.003075727727264166, -0.04339456558227539, 0.11028752475976944, -0.031343042850494385, 0.030668990686535835, -0.09148486703634262, -0.044086311012506485, 0.1383557766675949, -0.020879434421658516, 0.004856969229876995, 0.03709571063518524, 0.1703515201807022, 0.01861952617764473, 0.033359795808792114, -0.06772270798683167, -0.015008792281150818, -0.10265211015939713, -0.058258578181266785, 0.11599701642990112, 0.02703934907913208, 0.04589346423745155, -0.1284307986497879, -0.0287130456417799, 0.017232775688171387, -0.07115828990936279, 0.06773291528224945, 0.1451273262500763, 0.008248001337051392, -0.034412894397974014, 0.029221972450613976, -0.026011645793914795, 0.174311101436615, -0.026768360286951065, 0.07680193334817886, 0.05243188142776489, 0.03188086301088333, -0.003142392495647073, 0.08333886414766312, -0.006731552071869373, 1.6276081391213586e-32, -0.06010163947939873, 0.13313907384872437, 0.04508410394191742, -0.09020639210939407, -0.05743209272623062, -0.058922749012708664, -0.0017805428942665458, -0.0044787549413740635, -0.16642822325229645, 0.0721210390329361, -0.15096570551395416, 0.049267519265413284, 0.024915795773267746, 0.045562636107206345, -0.04259192943572998, -0.17515872418880463, -0.06403525173664093, 0.0006483031320385635, 0.025941859930753708, 0.012911926954984665, 0.15704020857810974, -0.022858815267682076, 0.057190410792827606, -0.1697387993335724, -0.06770019978284836, -0.19210964441299438, 0.026362987235188484, -0.0248832069337368, -0.19393382966518402, 0.0023009064607322216, -0.19463585317134857, 0.03494318574666977, 0.03716298192739487, -0.045845646411180496, 0.04030890017747879, -0.041979409754276276, 0.013220521621406078, 0.10142025351524353, -0.016182567924261093, -0.06044408679008484, -0.07581957429647446, 0.09016796201467514, 0.05521931126713753, -0.10076209902763367, -0.11196883022785187, 0.08395860344171524, 0.018835151568055153, 0.04154681786894798, -0.007209839764982462, 0.038367513567209244, 0.054714273661375046, -0.12085522711277008, 0.004621339961886406, 0.08622939139604568, -0.1263066679239273, 0.06566280871629715, 0.11331016570329666, -0.08252979069948196, 0.16909225285053253, 0.0009511762764304876, -0.044857386499643326, -0.0607239194214344, 0.03957897052168846, -0.03407067805528641, 0.03138488158583641, 0.026153460144996643, 0.1060853824019432, 0.0449240542948246, 0.0929723009467125, -0.10353298485279083, -0.024655058979988098, 0.05834805965423584, -0.017382489517331123, -0.18352629244327545, 0.07292946428060532, -0.018223032355308533, 0.08472409844398499, -0.014654609374701977, -0.12058399617671967, -0.05933823063969612, -0.0026215040124952793, 0.006100756581872702, -0.029898803681135178, -0.20777061581611633, -0.024838751181960106, -0.09260957688093185, 0.032330695539712906, -0.09678561240434647, -0.1553884744644165, -0.1293775886297226, -0.24249637126922607, 0.10065014660358429, 0.016923218965530396, -0.12915508449077606, 0.041680995374917984, -1.579038475786908e-32, 0.004884339869022369, -0.04703819751739502, 0.05140198394656181, 0.05054266378283501, 0.07607909291982651, 0.07698707282543182, -0.026162564754486084, 0.08375686407089233, -0.09299027174711227, -0.09731749445199966, 0.010609211400151253, -0.08332142978906631, 0.1987428516149521, 0.0234556682407856, 0.05209335684776306, 0.10689594596624374, -0.07524864375591278, 0.16029849648475647, -0.030120616778731346, 0.15224722027778625, -0.11139629781246185, 0.10759153217077255, -0.10937926173210144, 0.022659722715616226, -0.09952084720134735, 0.044663578271865845, -0.015501083806157112, 0.12142828106880188, 0.05619214475154877, -0.16419218480587006, -0.10877276957035065, 0.0032069857697933912, -0.14896953105926514, 0.04175486043095589, 0.02377011440694332, -0.028915585950016975, 0.042176950722932816, -0.1804184466600418, -0.06842903792858124, 0.12566758692264557, 0.14489896595478058, 0.12966607511043549, -0.107534259557724, 0.021013256162405014, -0.03718424215912819, 0.029301432892680168, -0.10381988435983658, 0.010638526640832424, -0.016518400982022285, 0.04014396667480469, -0.021115439012646675, 0.01577034592628479, -0.07008126378059387, 0.17380128800868988, -0.04609774798154831, -0.025325331836938858, -0.11741168051958084, -0.11816273629665375, -0.1272413432598114, 0.06699203699827194, -0.14373894035816193, 0.04190577194094658, -0.02361253835260868, -0.03199401870369911, 0.14277322590351105, -0.10042966157197952, -0.007678012829273939, 0.020123891532421112, -0.03716255724430084, 0.038621433079242706, -0.09836537390947342, 0.09073412418365479, 0.05281464755535126, -0.07564159482717514, 0.030423279851675034, 0.06822037696838379, -0.010213294997811317, 0.01989678665995598, -0.07317652553319931, 0.08947467803955078, 0.030755678191781044, -0.04759226366877556, -0.07760694622993469, 0.025085952132940292, -0.05423238128423691, 0.11762744188308716, 0.07959411293268204, 0.06414718180894852, 0.08870576322078705, -0.03174562379717827, 0.012562320567667484, -0.09128592163324356, 0.16262564063072205, 0.195431187748909, 0.056947559118270874, -1.0058970190129912e-07, -0.03094889223575592, -0.027541058138012886, 0.06396715342998505, 0.1389584094285965, 0.0007362841279245913, 0.061216969043016434, 0.010913298465311527, 0.039399582892656326, -0.07274125516414642, 0.010614684782922268, 0.13882456719875336, 0.04525085538625717, -0.16637791693210602, 0.06195473670959473, -0.08433087170124054, 0.09641315042972565, 0.002788633108139038, 0.049745336174964905, 0.05161823704838753, 0.014810827560722828, 0.11994514614343643, 0.02040444128215313, 0.09368658810853958, -0.035031840205192566, 0.07037036120891571, -0.1352408528327942, -0.004646618384867907, 0.008613178506493568, 0.003853257978335023, -0.03523736447095871, -0.01945328712463379, -0.051026277244091034, -0.12747958302497864, -0.030116397887468338, 0.1600874364376068, 0.06843039393424988, 0.009913266636431217, -0.044013746082782745, 0.033205024898052216, 0.09070830792188644, -0.06306499987840652, 0.11832480877637863, -0.16568003594875336, -0.08054154366254807, 0.05798571929335594, -0.02969232201576233, -0.014352861791849136, -0.03510765731334686, 0.15515068173408508, -0.014992183074355125, -0.07272829860448837, -0.03327218070626259, -0.0725216343998909, 0.05660630762577057, 0.11611055582761765, 0.14015991985797882, -0.10600826144218445, 0.08607885241508484, -0.02273441292345524, 0.012165632098913193, 0.04429014399647713, -0.02846802957355976, -0.042685702443122864, -0.032533902674913406], metadata={'source': 'AAAMLP-569to.pdf', 'page': 230}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 231 folds. Which model to use you ask? Which is the fastest model for high dimensional sparse data? Logistic regression. We will use logistic regression for this dataset to start with and to create our first actual benchmark.  Let’s see how this is done.  ═════════════════════════════════════════════════════════════════════════ # import what we need import pandas as pd  from nltk.tokenize import word_tokenize from sklearn import linear_model from sklearn import metrics from sklearn import model_selection from sklearn.feature_extraction.text import CountVectorizer   if __name__ == \"__main__\":     # read the training data     df = pd.read_csv(\"../input/imdb.csv\")      # map positive to 1 and negative to 0     df.sentiment = df.sentiment.apply(         lambda x: 1 if x == \"positive\" else 0     )      # we create a new column called kfold and fill it with -1     df[\"kfold\"] = -1          # the next step is to randomize the rows of the data     df = df.sample(frac=1).reset_index(drop=True)          # fetch labels     y = df.sentiment.values          # initiate the kfold class from model_selection module     kf = model_selection.StratifiedKFold(n_splits=5)          # fill the new kfold column     for f, (t_, v_) in enumerate(kf.split(X=df, y=y)):         df.loc[v_, \\'kfold\\'] = f      # we go over the folds created     for fold_ in range(5):         # temporary dataframes for train and test         train_df = df[df.kfold != fold_].reset_index(drop=True)'),\n",
       " VectorParams(vector=[-0.02906576171517372, -0.16177496314048767, -0.11073743551969528, 0.13871048390865326, 0.11371143162250519, -0.12700752913951874, -0.027570707723498344, 0.09618961811065674, 0.005835310090333223, 0.009851264767348766, 0.06674999743700027, -0.18398000299930573, -0.038470543920993805, -0.11830853670835495, -0.04883134365081787, 0.06663617491722107, -0.07749190926551819, -0.10954584181308746, -0.10912269353866577, -0.0711200013756752, 0.06444615125656128, 0.12990249693393707, 0.1484302133321762, 0.1369330734014511, 0.02192552015185356, -0.05354822799563408, -0.14360380172729492, 0.035546839237213135, -0.032352518290281296, -0.07077740132808685, 0.0027667449321597815, 0.059498969465494156, -0.07922579348087311, 0.2211739867925644, -0.052590273320674896, 0.08966705203056335, -0.0053976126946508884, -0.01720147207379341, 0.01084095612168312, 0.02304293029010296, -0.036915313452482224, -0.10998233407735825, 0.027519021183252335, 0.0450214184820652, 0.14009343087673187, 0.12057264149188995, -0.09221383929252625, -0.006309761665761471, 0.04614759236574173, 0.027806276455521584, -0.12204146385192871, 0.08976916968822479, -0.08473262190818787, -0.11603442579507828, -0.11917437613010406, -0.008531606756150723, 0.017000766471028328, 0.014379722997546196, 0.09076548367738724, -0.10510373115539551, -0.11799142509698868, -0.049549445509910583, 0.01571734994649887, -0.12843595445156097, -0.11142712086439133, -0.1038052886724472, -0.14103510975837708, 0.014890613965690136, -0.04483836144208908, 0.12859570980072021, 0.04481352120637894, 0.1321011185646057, -0.0416070781648159, 0.10326986014842987, -0.07575935125350952, -0.1002875566482544, 0.17957371473312378, -0.00514240050688386, 0.15481288731098175, -0.12016066908836365, -0.13201338052749634, -0.02784917689859867, 0.04295641556382179, 0.07403513789176941, 0.06271128356456757, -0.23905128240585327, 0.20506545901298523, -0.020796623080968857, -0.029651103541254997, -0.10371050238609314, 0.17697255313396454, -0.05633025988936424, -0.01696675829589367, 0.016674434766173363, 0.07688377052545547, 0.10542705655097961, 0.05970490351319313, 0.10811350494623184, -0.09153726696968079, 0.16670642793178558, -0.03826305270195007, 0.026637379080057144, 0.020226338878273964, 0.05002976581454277, -0.09865006804466248, -0.014005017466843128, 0.1220460906624794, 0.08130072802305222, 0.06511500477790833, -0.05239969491958618, 0.10529746860265732, 5.819188663735986e-05, -0.014256410300731659, 0.15887422859668732, 0.12618446350097656, 0.1442538946866989, -0.06662300229072571, 0.007478433661162853, -0.034207794815301895, 0.24657882750034332, -0.02300524339079857, 0.1218142881989479, 0.03671160340309143, 0.021590346470475197, -0.022828632965683937, 0.024093324318528175, 0.08782421052455902, 1.4401889361309854e-32, -0.22459769248962402, 0.02215311862528324, 0.04049728810787201, -0.1388895958662033, -0.08113051950931549, -0.029164038598537445, 0.013441029004752636, 0.12254804372787476, -0.13429677486419678, -0.008953875862061977, -0.17036956548690796, 0.04130750149488449, -0.018971296027302742, 0.025119520723819733, -0.0040583559311926365, -0.05743861570954323, 0.01601717621088028, -0.04185154661536217, -0.04624425619840622, 0.03122061863541603, 0.35172781348228455, -0.14064964652061462, -0.04564560204744339, -0.13625584542751312, -0.18198855221271515, -0.009430996142327785, 0.03207211196422577, -0.040729790925979614, -0.19027838110923767, 0.061162471771240234, -0.2664431631565094, 0.04959586635231972, 0.05761817842721939, -0.011281208135187626, 0.028829460963606834, -0.15438196063041687, 0.09945017844438553, 0.021379569545388222, -0.03626701608300209, -0.1905428022146225, -0.16610437631607056, 0.0747753456234932, -0.05635778233408928, -0.07919041067361832, -0.08235933631658554, -0.0013732186052948236, -0.04999095946550369, 0.14496703445911407, 0.00952322781085968, 0.24407930672168732, 0.10400974750518799, -0.05250049754977226, -0.07675261795520782, 0.11549291759729385, -0.06865592300891876, 0.09044238924980164, 0.1830749213695526, -0.027701670303940773, 0.06857523322105408, -0.05842028558254242, 0.04134151339530945, 0.03372754901647568, 0.05686121806502342, -0.10205823928117752, 0.11291369050741196, 0.014085047878324986, 0.08466868847608566, 0.0708189532160759, 0.05866172909736633, -0.048212867230176926, -0.10930029302835464, 0.03503241017460823, -0.03887299820780754, -0.04633915796875954, 0.03633702173829079, -0.13124129176139832, 0.053510867059230804, -0.04162418097257614, -0.2227989137172699, 0.045120902359485626, 0.07718974351882935, 0.09643472731113434, -0.05272752791643143, -0.25527071952819824, 0.047178205102682114, -0.14419353008270264, 0.07837199419736862, -0.03941494971513748, -0.19656600058078766, -0.0953645408153534, -0.18092069029808044, 0.00978218112140894, 0.05846669524908066, -0.06019407883286476, -0.12076682597398758, -1.5013646008836543e-32, -0.08128315210342407, -0.0033520341385155916, -0.004496545065194368, 0.15730160474777222, 0.08016218990087509, -0.01932499185204506, 0.029059508815407753, 0.08590129762887955, 0.0017635771073400974, -0.048934537917375565, 0.13336220383644104, -0.18019992113113403, 0.09040144085884094, 0.07339222729206085, 0.14460526406764984, 0.03011716529726982, -0.07445953041315079, 0.1840922087430954, -0.06767430901527405, 0.0941896066069603, -0.01982088014483452, 0.22857098281383514, -0.20601986348628998, 0.07702811807394028, -0.18638861179351807, 0.07836684584617615, -0.005670477636158466, 0.10295923799276352, 0.0414673313498497, -0.1599128097295761, -0.007015005219727755, 0.08998847752809525, -0.0828436091542244, 0.1091763824224472, 0.07137513905763626, -0.05340361222624779, -0.008442359045147896, -0.15206164121627808, -0.14049693942070007, 0.09359397739171982, 0.16517114639282227, 0.1638425886631012, -0.20093578100204468, -0.033644597977399826, -0.10219138860702515, 0.03884052112698555, 0.016332603991031647, -0.03945501521229744, 0.01987447775900364, -0.06734296679496765, 0.039236754179000854, -0.01724104769527912, -0.010371171869337559, 0.1848696768283844, -0.042222559452056885, 0.06147570163011551, -0.0953093096613884, -0.05462648347020149, -0.1562487930059433, 0.02978415973484516, -0.08673594892024994, 0.043410222977399826, 0.10212178528308868, -0.1414341777563095, 0.16270270943641663, -0.08659663051366806, -0.06606221944093704, 0.13790364563465118, 0.1381952315568924, 0.07602185755968094, -0.07462053000926971, 0.139876127243042, -0.0264865942299366, -0.02707636170089245, -0.09010998159646988, 0.15105141699314117, -0.08652573823928833, -0.027066553011536598, -0.08285920321941376, 0.03577197715640068, -0.02616073377430439, -0.03534720093011856, 0.07113330811262131, 0.07258696109056473, -0.05578375607728958, 0.053931575268507004, 0.13534995913505554, 0.13232100009918213, -0.06638143956661224, -0.04647107794880867, 0.14052586257457733, -0.0659099593758583, 0.04534592106938362, 0.1987990140914917, 0.0513218455016613, -1.0062050392889432e-07, -0.06813833117485046, -0.06807854771614075, -0.03250566124916077, 0.09604872763156891, 0.02272728458046913, -0.019188767299056053, -0.05435341224074364, -0.0004492820589803159, -0.1871216893196106, -0.04095712676644325, 0.11015324294567108, 0.0010370787931606174, -0.24282841384410858, 0.025214800611138344, -0.05747431516647339, -0.009637720882892609, 0.023480039089918137, 0.08643782138824463, 0.0008716286392882466, -0.0361226350069046, 0.030173374339938164, -0.09319188445806503, 0.04625241458415985, -0.13341063261032104, -0.08426725119352341, -0.14111976325511932, -0.026669899001717567, 0.1538626253604889, -0.010649462230503559, -0.0384124256670475, 0.04008343443274498, -0.024296769872307777, -0.08221005648374557, 0.0037191465962678194, -0.028385261073708534, 0.051986150443553925, 0.08120621740818024, -0.0561424195766449, 0.05923852697014809, 0.10079449415206909, 0.01138224545866251, 0.19018182158470154, -0.2169424593448639, 0.006961815059185028, 0.06588286906480789, -0.06455130875110626, 0.025804869830608368, -0.12244615703821182, 0.09685848653316498, -0.014584372751414776, 0.0612541027367115, 0.009628120809793472, -0.14974939823150635, -0.014201734215021133, 0.12955544888973236, 0.04830115661025047, -0.15152357518672943, -0.04263048619031906, -0.09304139763116837, 0.027592100203037262, 0.011537984944880009, -0.09788736701011658, 0.07041319459676743, 0.037507425993680954], metadata={'source': 'AAAMLP-569to.pdf', 'page': 231}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 232         test_df = df[df.kfold == fold_].reset_index(drop=True)          # initialize CountVectorizer with NLTK\\'s word_tokenize         # function as tokenizer         count_vec = CountVectorizer(             tokenizer=word_tokenize,             token_pattern=None         )          # fit count_vec on training data reviews         count_vec.fit(train_df.review)          # transform training and validation data reviews         xtrain = count_vec.transform(train_df.review)         xtest = count_vec.transform(test_df.review)          # initialize logistic regression model         model = linear_model.LogisticRegression()          # fit the model on training data reviews and sentiment         model.fit(xtrain, train_df.sentiment)          # make predictions on test data         # threshold for predictions is 0.5         preds = model.predict(xtest)          # calculate accuracy         accuracy = metrics.accuracy_score(test_df.sentiment, preds)          print(f\"Fold: {fold_}\")         print(f\"Accuracy = {accuracy}\")         print(\"\") ═════════════════════════════════════════════════════════════════════════  This piece of code takes time to run but should give you the following output:  ═════════════════════════════════════════════════════════════════════════ ❯ python ctv_logres.py Fold: 0 Accuracy = 0.8903  Fold: 1 Accuracy = 0.897  Fold: 2 Accuracy = 0.891'),\n",
       " VectorParams(vector=[-0.10023211687803268, -0.13450975716114044, -0.058143340051174164, -0.003686727024614811, 0.0349460132420063, -0.057071492075920105, 0.03198625519871712, -0.004852933343499899, -0.04808301106095314, 0.03524930775165558, 0.043390728533267975, -0.11425719410181046, -0.03101167641580105, -0.04262387380003929, 0.055117495357990265, 0.1526729166507721, 0.0693732500076294, -0.0057585835456848145, -0.19005028903484344, -0.03545251116156578, 0.0022541352082043886, 0.08158588409423828, 0.07310349494218826, -0.037982288748025894, 0.0352662168443203, 0.0005056228837929666, 0.07035822421312332, 0.0955754742026329, -0.10273758322000504, 0.021903306245803833, -0.062393635511398315, 0.13049069046974182, -0.06006162613630295, 0.1076035425066948, -0.022483617067337036, 0.04813166707754135, -0.019436120986938477, -0.0029441278893500566, 0.004871797282248735, 0.10757742077112198, 0.0075218952260911465, -0.06669917702674866, -0.014543779194355011, 0.10223978012800217, 0.15482808649539948, -0.005982636008411646, -0.1722128689289093, 0.00240403157658875, 0.186064213514328, -0.07574363797903061, -0.14580558240413666, -0.007678308989852667, 0.03843923285603523, 0.06174365058541298, -0.08611076325178146, -0.11227089911699295, 0.0027189275715500116, -0.07167336344718933, 0.04583043232560158, -0.15885324776172638, -0.033575475215911865, -0.07204148918390274, 0.03965987265110016, -0.07314302772283554, 0.014906910248100758, 0.022651951760053635, -0.11492934077978134, 0.03752206265926361, 0.021478716284036636, 0.1297479271888733, -0.008938654325902462, 0.19283533096313477, -0.018323341384530067, 0.03370821848511696, -0.15280219912528992, -0.14772500097751617, 0.16653992235660553, -0.0032030469737946987, 0.20779761672019958, 0.020690565928816795, -0.07348991930484772, 0.04795805737376213, 0.025254955515265465, 0.030594119802117348, 0.0849979966878891, -0.2546561062335968, 0.018657268956303596, -0.04383528605103493, -0.024066736921668053, 0.05451982468366623, 0.06937986612319946, -0.1260264366865158, 0.06374632567167282, -0.1039847657084465, -0.13072143495082855, 0.12585055828094482, -0.09984137117862701, -0.014545368030667305, -0.04611377418041229, 0.13067688047885895, 0.00896241795271635, 0.12449339777231216, 0.0012770532630383968, -0.006515915971249342, -0.08064937591552734, 0.06579988449811935, 0.07845164090394974, 0.10150112956762314, 0.1097276508808136, -0.02671511471271515, 0.02521166391670704, -0.0021119911689311266, -0.10957643389701843, 0.025605106726288795, 0.03421762213110924, 0.1439637988805771, 0.0034031341783702374, 0.11182314157485962, -0.029279664158821106, 0.2737692594528198, -0.06697114557027817, 0.13532692193984985, 0.052140187472105026, -0.00477991858497262, 0.0013674015644937754, 0.028504399582743645, 0.02161857858300209, 1.7283468294924778e-32, -0.016141975298523903, 0.16654056310653687, 0.02166099101305008, -0.060728274285793304, -0.00934164971113205, -0.053431134670972824, -0.06404062360525131, -0.04294789955019951, -0.15477676689624786, -0.03950401395559311, -0.09950603544712067, 0.04120523855090141, -0.04138029366731644, 0.03458692878484726, 0.03067953884601593, -0.06881674379110336, -0.08119148761034012, -0.010258420370519161, 0.05053769797086716, 0.10327837616205215, 0.1420528143644333, -0.017575694248080254, 0.1084587574005127, -0.1936974674463272, -0.06574913114309311, -0.004754752852022648, 0.18903310596942902, -0.026675662025809288, -0.06953626871109009, 0.06552565842866898, -0.11037936061620712, 0.06372997909784317, 0.040929559618234634, 0.03559131920337677, 0.018049519509077072, -0.09905734658241272, -0.046895746141672134, -0.00989679154008627, 0.030754856765270233, -0.1369491070508957, -0.1561037003993988, 0.035571422427892685, 0.05530690401792526, -0.05868878215551376, -0.033637139946222305, 0.0674578920006752, -0.05280553176999092, -0.05417432263493538, -0.03651388734579086, 0.034737005829811096, 0.08301765471696854, -0.14302004873752594, -0.0445612333714962, 0.17183279991149902, -0.09045667946338654, 0.032261233776807785, 0.05721929296851158, -0.04859910160303116, 0.07366381585597992, -0.09729375690221786, 0.080845408141613, -0.0028928054962307215, 0.1152113825082779, -0.06112242117524147, 0.14525632560253143, 0.10015196353197098, 0.1169486939907074, 0.10034956783056259, 0.004968380089849234, -0.016403846442699432, 0.0003484180779196322, 0.016573404893279076, -0.00014675095735583454, -0.08841817826032639, 0.02995079942047596, -0.004404671490192413, 0.18620805442333221, -0.10653562098741531, -0.036678627133369446, -0.006533915642648935, 0.056166213005781174, -0.04793442040681839, 0.16372482478618622, -0.1920688897371292, -0.03377826139330864, -0.04278939217329025, 0.05163860693573952, -0.12129625678062439, -0.09089777618646622, 0.018571428954601288, -0.1606014370918274, 0.13208118081092834, 0.03347603976726532, -0.050183698534965515, -0.09100936353206635, -1.5255179241203814e-32, -0.07218828052282333, -0.07166275382041931, 0.006421441677957773, 0.0634906217455864, -0.07047609239816666, -0.0038870072457939386, -0.0643630176782608, 0.06839754432439804, -0.07499720901250839, -0.05283793807029724, -0.05835108831524849, -0.059566039592027664, 0.03873346000909805, 0.004504380282014608, 0.12375711649656296, 0.11592169851064682, -0.01532457210123539, 0.18108156323432922, -0.006790187209844589, 0.05241069942712784, 0.008086467161774635, 0.10597337037324905, -0.19428908824920654, 0.09376005083322525, -0.1071576252579689, 0.002043307526037097, -0.054714228957891464, 0.10789382457733154, 0.04183851554989815, -0.1303664892911911, -0.08147832006216049, 0.03485004976391792, -0.13618087768554688, 0.02495214343070984, -0.004558283369988203, 0.07757309079170227, -0.06647889316082001, -0.1175585687160492, 0.011418509297072887, 0.07229392230510712, 0.029075928032398224, 0.1638854444026947, -0.30666404962539673, -0.12595270574092865, -0.1389770805835724, 0.0268706101924181, -0.08195998519659042, 0.04660091921687126, 0.07088153809309006, 0.02923901006579399, 0.022793754935264587, 0.045567162334918976, -0.0983382984995842, 0.2675570249557495, -0.08033395558595657, 0.03394951671361923, -0.031641390174627304, -0.19934995472431183, -0.09012851864099503, 0.00010222255514236167, -0.17538532614707947, 0.032285746186971664, 0.05677863955497742, -0.09531636536121368, 0.19192832708358765, -0.03756171837449074, 0.007096684072166681, 0.14627525210380554, 0.0003467125352472067, -0.004846937023103237, -0.03618388995528221, 0.16679447889328003, -0.0557795986533165, -0.008084218949079514, 0.04904578998684883, 0.1544666886329651, 0.05612575262784958, -0.010149329900741577, -0.10162797570228577, 0.00016658140521030873, -0.02958974801003933, 0.011879763565957546, -0.028192661702632904, 0.09795334190130234, 0.0140127157792449, 0.04953107610344887, 0.18813516199588776, 0.07339435070753098, 0.027495328336954117, -0.08259688317775726, 0.04959941655397415, 0.10772969573736191, 0.08516252785921097, 0.13592006266117096, -0.018516266718506813, -9.875108730739157e-08, -0.0637088418006897, -0.015886690467596054, -0.03272010758519173, 0.07386356592178345, 0.05044328048825264, -0.06989899277687073, -0.08501025289297104, 0.09437250345945358, -0.07743929326534271, -0.11000481247901917, 0.12005864828824997, 0.05117499455809593, -0.20981696248054504, -0.0009581669000908732, -0.031182795763015747, 0.06417249143123627, -0.03151419758796692, 0.0764608234167099, -0.010336758568882942, -0.03500618785619736, 0.15731164813041687, 0.01849157176911831, 0.09035997092723846, -0.013644175603985786, 0.011507001705467701, -0.10920737683773041, -0.06096472963690758, 0.07052972912788391, -0.0748768150806427, -0.04382551833987236, -0.09097670763731003, -0.07415663450956345, -0.24094639718532562, 0.0062597221694886684, 0.10849234461784363, 0.11092205345630646, -0.001734095043502748, -0.1315552294254303, 0.030439382418990135, 0.05010266974568367, -0.04394175112247467, 0.05052126571536064, -0.1597527712583542, -0.009553207084536552, 0.06933856010437012, -0.05944399908185005, -0.05995815247297287, -0.16791629791259766, 0.06176137179136276, 0.15016309916973114, 0.011965926736593246, 0.10377997159957886, -0.028453480452299118, 0.0347156748175621, 0.06371697783470154, 0.056788522750139236, -0.05804203078150749, -0.015075217932462692, -0.05594172328710556, 0.1306052953004837, 0.00604797201231122, -0.11050227284431458, -0.06358692049980164, 0.06863699853420258], metadata={'source': 'AAAMLP-569to.pdf', 'page': 232}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 233 Fold: 3 Accuracy = 0.8914  Fold: 4 Accuracy = 0.8931 ═════════════════════════════════════════════════════════════════════════  Wow, we are already at 89% accuracy, and all we did was use bag of words with logistic regression! This is super amazing! However, this model took a lot of time to train, let’s see if we can improve the time by using naïve bayes classifier. Naïve bayes classifier is quite popular in NLP tasks as the sparse matrices are huge and naïve bayes is a simple model. To use this model, we need to change one import and the line with the model. Let’s see how this model performs. We will use MultinomialNB from scikit-learn.  ═════════════════════════════════════════════════════════════════════════ # import what we need import pandas as pd  from nltk.tokenize import word_tokenize from sklearn import naive_bayes from sklearn import metrics from sklearn import model_selection from sklearn.feature_extraction.text import CountVectorizer . . . .         # initialize naive bayes model         model = naive_bayes.MultinomialNB()          # fit the model on training data reviews and sentiment         model.fit(xtrain, train_df.sentiment) . . . ═════════════════════════════════════════════════════════════════════════  Results are as follows:  ═════════════════════════════════════════════════════════════════════════ ❯ python ctv_nb.py Fold: 0 Accuracy = 0.8444'),\n",
       " VectorParams(vector=[0.008266554214060307, -0.10802310705184937, -0.031272225081920624, 0.005617059767246246, 0.1412542760372162, -0.018798774108290672, 0.0026982403360307217, 0.04668903350830078, 0.11092037707567215, 0.07440842688083649, 0.07932933419942856, -0.08810893446207047, 0.0064224437810480595, -0.039979610592126846, 0.0232858844101429, 0.07363534718751907, 0.021080000326037407, -0.01952645368874073, -0.039135027676820755, -0.0960337445139885, 0.006102284882217646, 0.13833396136760712, 0.08640951663255692, -0.05448545515537262, 0.03793793171644211, -0.04141144081950188, -0.11596038192510605, -0.01695045456290245, -0.031071146950125694, 0.10250711441040039, -0.07048162817955017, 0.28849101066589355, -0.09123790264129639, 0.069582998752594, -0.059249088168144226, -0.09399253875017166, -0.06941046565771103, 0.06136537715792656, 0.022427640855312347, 0.10394696146249771, -0.03216378390789032, -0.08899789303541183, -0.03195277228951454, 0.05322025716304779, 0.08004609495401382, 0.07402361184358597, -0.11242268979549408, 0.020031385123729706, 0.010596858337521553, 0.003867899300530553, -0.1440836787223816, 0.1313284933567047, -0.05444028973579407, 0.1145833432674408, 0.04092990979552269, -0.07642137259244919, 0.018492169678211212, -0.01150534301996231, 0.012188281863927841, -0.030213989317417145, -0.055796682834625244, -0.14372648298740387, -0.059961698949337006, -0.09925686568021774, 0.0021763381082564592, 0.15460579097270966, 0.039362408220767975, 0.017103536054491997, 0.00252735149115324, 0.17892204225063324, -0.08648773282766342, 0.21658888459205627, 0.022419868037104607, 0.12198402732610703, -0.078745536506176, -0.01922074519097805, 0.10739660263061523, -0.06548937410116196, 0.11144330352544785, -0.011190511286258698, -0.039815351366996765, 0.0490136556327343, 0.032785575836896896, -0.05070769041776657, 0.0656539723277092, -0.13906294107437134, 0.06721759587526321, -0.06721083074808121, 0.0030794970225542784, 0.06528601795434952, 0.13129161298274994, -0.16081172227859497, 0.11913575232028961, -0.1685202568769455, 0.08623024076223373, 0.08117641508579254, -0.01609051786363125, 0.0006217410555109382, 0.08091609925031662, 0.08370617032051086, 0.02302289754152298, 0.06540370732545853, -0.006195992697030306, -0.09221477806568146, -0.11404304951429367, 0.07497250288724899, -0.017425324767827988, -3.922385076293722e-05, 0.17769712209701538, -0.0767187625169754, 0.03683140128850937, 0.021463241428136826, -0.027563808485865593, -0.012992534786462784, 0.03034495748579502, 0.013037854805588722, 0.096323162317276, 0.05301970615983009, 0.09413661807775497, 0.18414488434791565, -0.03883234038949013, 0.11135035008192062, 0.031030554324388504, 0.0020925123244524, 0.002409480744972825, 0.047347020357847214, -0.01913508027791977, 9.881577997784566e-33, 0.016527796164155006, 0.09238885343074799, -0.019186366349458694, -0.034290410578250885, -0.06035655736923218, -0.0036554555408656597, -0.0429244302213192, 0.058653634041547775, -0.15102392435073853, 0.012206412851810455, -0.17955754697322845, 0.12781445682048798, -0.029246369376778603, 0.003683454589918256, 0.0698961615562439, -0.12297767400741577, -0.04098391905426979, 0.053930360823869705, -0.03982307016849518, -0.03240398317575455, 0.1302340030670166, -0.010324632748961449, 0.09565574675798416, -0.09497170150279999, -0.059853389859199524, -0.08186251670122147, 0.06140231713652611, -0.08639226853847504, -0.1049695760011673, 0.05276533588767052, -0.21454495191574097, -0.010644584894180298, 0.09964781999588013, -0.08454405516386032, 0.031588781625032425, -0.15597808361053467, -0.008383261039853096, -0.008285840973258018, -0.01639559306204319, -0.20692048966884613, -0.11239606142044067, 0.04346928372979164, 0.08289990574121475, -0.10590385645627975, -0.0723949745297432, 0.024124639108777046, -0.024363704025745392, -0.1078013926744461, 4.563518086797558e-05, 0.11429695785045624, 0.11812816560268402, -0.17298752069473267, -0.03823991119861603, 0.0985015332698822, 0.03892720118165016, 0.12421993911266327, 0.07976345717906952, 0.000805973366368562, 0.05953033268451691, 0.08002229779958725, -0.012792776338756084, 0.04252265393733978, 0.06856317073106766, -0.047154348343610764, 0.142412468791008, 0.12840569019317627, 0.00448440108448267, 0.07788374274969101, 0.018697122111916542, -0.04658368602395058, 0.05863463506102562, 0.12689213454723358, -0.02322564087808132, -0.10790233314037323, 0.10851260274648666, 0.001291501335799694, 0.15574748814105988, -0.09648475795984268, -0.1518040895462036, -0.04810793697834015, -0.05357504263520241, -0.023883776739239693, 0.19606517255306244, -0.13006286323070526, -0.10513181984424591, -0.021684976294636726, 0.003868996864184737, -0.037757664918899536, -0.14824143052101135, -0.17740215361118317, 0.022942308336496353, 0.004581310320645571, -0.016125358641147614, -0.0997941866517067, -0.01988411135971546, -9.842600074479237e-33, -0.08661721646785736, -0.10329718887805939, 0.014205779880285263, -0.018520040437579155, -0.015277929604053497, -0.02109501138329506, -0.05089769512414932, 0.04852702096104622, -0.13769738376140594, -0.20803360641002655, 0.005346138495951891, -0.09294958412647247, -0.06601694971323013, -0.06894604861736298, 0.10321201384067535, -0.07242143899202347, 0.016341792419552803, 0.07763916254043579, -0.06796056032180786, 0.1654646098613739, 0.07517910748720169, -0.012699836865067482, -0.10216345638036728, 0.09014453738927841, -0.042304426431655884, 0.03208400309085846, -0.03097943589091301, 0.08161430060863495, 0.0064039709977805614, -0.08700934052467346, -0.03649283945560455, -0.04573954641819, -0.0693529024720192, -0.022494761273264885, 0.0024753829929977655, -0.013494819402694702, -0.07737065851688385, -0.07761363685131073, -0.00640405947342515, 0.04639517888426781, 0.07319900393486023, 0.17314568161964417, -0.1316785216331482, -0.1755596101284027, -0.1326645314693451, -0.002552685094997287, -0.08280334621667862, -0.027822691947221756, 0.12925821542739868, -0.09287985414266586, 0.06943995505571365, 0.04844077304005623, -0.08490042388439178, 0.10605683922767639, -0.12090965360403061, 0.08397828042507172, -0.030393917113542557, -0.16447439789772034, -0.13534200191497803, 0.03568047657608986, -0.14020700752735138, 0.05003546178340912, 0.058019671589136124, -0.04671785607933998, 0.20827652513980865, -0.001643202849663794, -0.1062256246805191, 0.043698716908693314, -0.03468509390950203, -0.04172705113887787, -0.03676211088895798, 0.09735473990440369, -0.14772248268127441, -0.03490270674228668, -0.03140273690223694, 0.07139416038990021, 0.07462945580482483, -0.12211497128009796, -0.12583474814891815, -0.021281911060214043, -0.07240159809589386, -0.010296441614627838, -0.012330327183008194, 0.08746636658906937, -0.08626916259527206, 0.06827237457036972, 0.08953282982110977, 0.019111962988972664, 0.0888708233833313, -0.030695529654622078, 0.05328958481550217, 0.01911824755370617, -0.0299980491399765, 0.19019940495491028, 0.055279895663261414, -1.0082284518375673e-07, -0.1310310810804367, -0.05889926850795746, -0.06490577757358551, 0.0648258700966835, 0.12176604568958282, 0.014993692748248577, 0.04761459305882454, 0.1418209671974182, -0.15824735164642334, -0.23152783513069153, 0.08949202299118042, -0.052963294088840485, -0.2391347587108612, 0.006497697904706001, 0.008929159492254257, 0.054897285997867584, -0.11630558967590332, 0.007255816366523504, -0.04023800417780876, -0.057661958038806915, 0.10704959183931351, -0.06865201890468597, 0.026989668607711792, -0.022070851176977158, -0.12450698763132095, -0.01767757721245289, -0.029292352497577667, 0.09692984819412231, 0.14055654406547546, -0.030987998470664024, -0.08263080567121506, -0.03689666464924812, -0.24084486067295074, 0.07776809483766556, 0.09275366365909576, 0.17355909943580627, -0.04278627410531044, -0.10643808543682098, -0.14174839854240417, 0.17805421352386475, 0.021087046712636948, 0.12002719938755035, -0.12375474721193314, 0.08207997679710388, 0.06198933720588684, -0.019105220213532448, -0.067975252866745, -0.005840242840349674, 0.18601034581661224, -0.010007821023464203, 0.09243489056825638, 0.06512844562530518, -0.12938615679740906, 0.10511144995689392, 0.0021199900656938553, 0.0712435320019722, -0.024751977995038033, -0.026301104575395584, -0.08582337945699692, 0.05520632117986679, 0.06863657385110855, -0.07798117399215698, 0.11451968550682068, 0.15406771004199982], metadata={'source': 'AAAMLP-569to.pdf', 'page': 233}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 234 Fold: 1 Accuracy = 0.8499  Fold: 2 Accuracy = 0.8422  Fold: 3 Accuracy = 0.8443  Fold: 4 Accuracy = 0.8455 ═════════════════════════════════════════════════════════════════════════  We see that this score is low. But the naïve bayes model is superfast.   Another method in NLP that most of the people these days tend to ignore or don’t care to know about is called TF-IDF. TF is term frequencies, and IDF is inverse document frequency. It might seem difficult from these terms, but things will become apparent with the formulae for TF and IDF.                                        Number of times a term t appears in a document  TF(t) =               ──────────────────────────────────                                            Total number of terms in the document                                                         Total number of documents IDF(t) =     LOG(  ──────────────────────────────────  )         Number of documents with term t in it   And TF-IDF for a term t is defined as:  TF-IDF(t) = TF(t) * IDF(t)  Similar to CountVectorizer in scikit-learn, we have TfidfVectorizer. Let’s try using it the same way we used CountVectorizer.  ═════════════════════════════════════════════════════════════════════════ from sklearn.feature_extraction.text import TfidfVectorizer from nltk.tokenize import word_tokenize  # create a corpus of sentences corpus = ['),\n",
       " VectorParams(vector=[0.09296104311943054, -0.10150507092475891, 0.00959617830812931, -0.07984929531812668, 0.023667404428124428, -0.0800095796585083, 0.08398614823818207, -0.04169536381959915, -0.04528375715017319, 0.04937059059739113, 0.03443174809217453, -0.10875281691551208, 0.012811205349862576, -0.061506129801273346, -0.04808755964040756, 0.002072906121611595, -0.08495473861694336, -0.014043211936950684, -0.12436707317829132, -0.1500759720802307, -0.001984444446861744, 0.1465456783771515, 0.042722657322883606, -0.05806953087449074, 0.08996835350990295, 0.18903805315494537, -0.041565779596567154, -0.007009086664766073, -0.06901998817920685, -0.1036452054977417, 0.007277832366526127, 0.1079973578453064, 0.041848983615636826, 0.01447975542396307, 0.007856499403715134, -0.004903918132185936, -0.03608819469809532, 0.006439052522182465, 0.0836474746465683, 0.016072938218712807, 0.0013503488153219223, -0.053240515291690826, 0.09806555509567261, 0.043969400227069855, 0.07498959451913834, -0.018316203728318214, -0.12214738130569458, 0.029033098369836807, 0.00737048638984561, -0.10991133749485016, -0.13712728023529053, 0.08730901777744293, -0.01290355995297432, 0.14593446254730225, -0.12217196822166443, -0.09445101022720337, -0.038791656494140625, -0.08306311070919037, 0.11174529790878296, -0.017877494916319847, -0.1126725822687149, 0.04336452856659889, 0.019690053537487984, -0.01053543109446764, -0.0001606084406375885, -0.037456560879945755, -0.09070534259080887, 0.004623277112841606, 0.06257758289575577, 0.15124192833900452, -0.014421666041016579, 0.0630766823887825, -0.06747294962406158, 0.11114214360713959, -0.06773708015680313, 0.0671977773308754, 0.036405082792043686, -0.15861892700195312, 0.08516755700111389, -0.03587789088487625, -0.04838938266038895, -0.0710253044962883, 0.0801221951842308, 0.0550563670694828, -0.03217366337776184, -0.1465492844581604, -0.016901347786188126, 0.0013780654408037663, 6.811041384935379e-05, 0.002472285646945238, 0.008442413061857224, -0.05039246752858162, -0.026351716369390488, -0.035600997507572174, -0.0004118052311241627, 0.08293895423412323, 0.07947523891925812, 0.039748165756464005, -0.05810046195983887, 0.2227075845003128, -0.07309180498123169, -0.043620143085718155, -0.056064821779727936, -0.0045597669668495655, -0.02650381624698639, 0.032557323575019836, 0.007283335085958242, -0.01398434303700924, 0.15703828632831573, -0.19112160801887512, -0.067713662981987, -0.01572577841579914, 0.03519580885767937, 0.07824337482452393, 0.12425656616687775, -0.10472187399864197, -0.04310634732246399, 0.10226544737815857, 0.0684814453125, 0.13982820510864258, 0.017844080924987793, 0.07782402634620667, 0.004195950925350189, 0.16988718509674072, -0.09178850799798965, -0.0741242915391922, -0.04015480726957321, 1.1582330979012253e-32, -0.09051130712032318, 0.0704234391450882, 0.04262842237949371, -0.11302098631858826, -0.02505168318748474, -0.025350375100970268, -0.06815701723098755, 0.04779218137264252, -0.09904995560646057, 0.04245995730161667, -0.08889250457286835, -0.027277739718556404, -0.0010103746317327023, 0.09402614831924438, 0.0004404154606163502, -0.10048111528158188, -0.008278544060885906, -0.010089138522744179, -0.12043716013431549, -0.06305476278066635, 0.05080394446849823, 0.024405110627412796, 0.04686227813363075, -0.09760084748268127, -0.08859170228242874, 0.0035180808044970036, 0.0034153033047914505, -0.10606278479099274, -0.04545828700065613, 0.05358634516596794, -0.06783151626586914, 0.06555894762277603, -0.11508210003376007, -0.02838974818587303, -0.04106559976935387, -0.15595515072345734, 0.08545355498790741, 0.01423892192542553, -0.06382070481777191, -0.1257939338684082, -0.10684677213430405, 0.061852119863033295, 0.08526699244976044, -0.0533551350235939, -0.04294583201408386, 0.07210050523281097, 0.06555159389972687, 0.002922552404925227, -0.047911837697029114, 0.08996059000492096, 0.007537941448390484, -0.11080512404441833, -0.03979672119021416, 0.08488394320011139, 0.03945480287075043, -0.014747239649295807, 0.1023811548948288, -0.006971635855734348, 0.16588543355464935, 0.11614841222763062, 0.04015463590621948, -0.03989408165216446, -0.04146535322070122, -0.02835255116224289, 0.17275208234786987, -0.057624202221632004, -0.04313308373093605, -0.05339691415429115, 0.07569009065628052, 0.09116245806217194, 0.0018314868211746216, 0.0762379914522171, 0.06645256280899048, -0.053859636187553406, -0.03890259191393852, 0.03668889403343201, 0.06464338302612305, -0.08251947164535522, -0.12743288278579712, -0.025898855179548264, 0.018421269953250885, -0.010779637843370438, -0.015499895438551903, -0.28789615631103516, -0.025276128202676773, -0.1596491038799286, -0.001689031720161438, -0.15368950366973877, -0.14881688356399536, -0.02309712953865528, -0.1434389054775238, -0.012575375847518444, 0.010242987424135208, -0.05358969420194626, -0.23493491113185883, -1.404859159543434e-32, -0.07318037748336792, 0.051228709518909454, 2.9420480132102966e-05, 0.05807580053806305, -0.019983146339654922, 0.00926383025944233, 0.09671259671449661, 0.09183254837989807, 0.05617588758468628, 0.030188556760549545, 0.08924882858991623, -0.027863597497344017, 0.0605723112821579, -0.05098363757133484, 0.1942608654499054, -0.05872953310608864, 0.12327715009450912, 0.14474758505821228, -0.0310201533138752, 0.04030571132898331, -0.08619818091392517, 0.1375434845685959, -0.1906861513853073, 0.08493898808956146, -0.014645766466856003, 0.10181251168251038, 0.04196665808558464, 0.08033110946416855, -0.07309012115001678, -0.015433022752404213, -0.06383661180734634, -0.11161603033542633, -0.10799820721149445, 0.0728374570608139, -0.0019739740528166294, 0.039155423641204834, -0.0364643856883049, 0.019765377044677734, -0.07734258472919464, -0.034205228090286255, 0.07071053981781006, 0.08873153477907181, -0.16347789764404297, -0.0026315730065107346, -0.072505883872509, -0.007076926063746214, -0.030099734663963318, 0.09004773199558258, -0.0233372263610363, 0.0732879713177681, 0.036337096244096756, 0.06761018931865692, -0.17352080345153809, 0.022345010191202164, -0.050803251564502716, -0.04160211607813835, 0.007493414916098118, -0.12279777228832245, -0.09049426019191742, -0.10658034682273865, -0.054072193801403046, 0.019003260880708694, 0.11415134370326996, -0.07108679413795471, 0.1753045916557312, -0.045916616916656494, -0.13848239183425903, 0.03495797514915466, 0.02292196825146675, 0.047507427632808685, 0.035792961716651917, 0.015120388008654118, -0.13208165764808655, -0.10663984715938568, 0.006319365464150906, -0.006208082195371389, -0.04541073366999626, -0.044742651283741, -0.05856766551733017, -0.08291618525981903, -0.08977316319942474, -0.06037405505776405, 0.07510405778884888, 0.10334284603595734, 0.01789068430662155, 0.05584090203046799, 0.0438661128282547, 0.02456262707710266, 0.0778249204158783, 0.09547880291938782, 0.04437536001205444, 0.05998615175485611, 0.10899065434932709, 0.10483942180871964, 0.1035364493727684, -1.0286559870564815e-07, -0.12292170524597168, -0.09651259332895279, -0.02186623215675354, 0.12489979714155197, 0.17606264352798462, 0.017058387398719788, -0.09504350274801254, 0.002372431568801403, -0.12598566710948944, -0.12241138517856598, 0.10366860777139664, -0.09128300100564957, -0.12437183409929276, 0.020111817866563797, 0.04491201043128967, 0.021594921126961708, 0.03409437835216522, 0.06759867072105408, -0.11601325124502182, -0.11331624537706375, -0.01328712422400713, 0.11628485471010208, -0.04888678342103958, -0.04952686280012131, -0.07618515193462372, -0.0372353121638298, -0.08821243047714233, 0.02237444557249546, 0.03193642199039459, -0.010943597182631493, -0.0690336525440216, -0.01850595325231552, -0.05037233605980873, -0.058199699968099594, -0.041081055998802185, 0.1006917655467987, -0.09958593547344208, -0.03748521953821182, -0.09138522297143936, 0.028948115184903145, -0.0616697259247303, 0.0366029366850853, -0.02457038126885891, 0.08403580635786057, 0.09380921721458435, -0.05919667333364487, 0.035037606954574585, -0.09377100318670273, 0.17299354076385498, -0.15276652574539185, 0.015347236767411232, 0.0915784239768982, -0.11218877136707306, 0.012034913524985313, 0.15155920386314392, -0.04631332680583, -0.05601654201745987, 0.07052739709615707, -0.13986115157604218, 0.07178282737731934, 0.15694111585617065, -0.015770185738801956, 0.039129048585891724, -0.0260953139513731], metadata={'source': 'AAAMLP-569to.pdf', 'page': 234}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 235     \"hello, how are you?\",     \"im getting bored at home. And you? What do you think?\",     \"did you know about counts\",     \"let\\'s see if this works!\",     \"YES!!!!\" ]  # initialize TfidfVectorizer with word_tokenize from nltk # as the tokenizer tfv = TfidfVectorizer(tokenizer=word_tokenize, token_pattern=None)  # fit the vectorizer on corpus tfv.fit(corpus)  corpus_transformed = tfv.transform(corpus) print(corpus_transformed) ═════════════════════════════════════════════════════════════════════════  This gives the following output:  ═════════════════════════════════════════════════════════════════════════          (0, 27) 0.2965698850220162   (0, 16) 0.4428321995085722   (0, 14) 0.4428321995085722   (0, 7) 0.4428321995085722   (0, 4) 0.35727423026525224   (0, 2) 0.4428321995085722   (1, 27) 0.35299699146792735   (1, 24) 0.2635440111190765   (1, 22) 0.2635440111190765   (1, 18) 0.2635440111190765   (1, 15) 0.2635440111190765   (1, 13) 0.2635440111190765   (1, 12) 0.2635440111190765   (1, 9) 0.2635440111190765   (1, 8) 0.2635440111190765   (1, 6) 0.2635440111190765   (1, 4) 0.42525129752567803   (1, 3) 0.2635440111190765   (2, 27) 0.31752680284846835   (2, 19) 0.4741246485558491   (2, 11) 0.4741246485558491   (2, 10) 0.4741246485558491   (2, 5) 0.4741246485558491   (3, 25) 0.38775666010579296   (3, 23) 0.38775666010579296   (3, 21) 0.38775666010579296'),\n",
       " VectorParams(vector=[-0.03663378208875656, -0.06504344195127487, -0.04569346085190773, 0.030281241983175278, 0.1367981731891632, -0.02326752245426178, -0.030345764011144638, -0.013180471025407314, -0.005461426451802254, 0.009480612352490425, 0.05680495873093605, -0.11763681471347809, -0.06532078981399536, -0.029126465320587158, -0.017601268365979195, -0.02665378898382187, -0.12005162984132767, 0.03998935967683792, -0.11375924199819565, -0.04624224826693535, 0.06844858825206757, 0.12552739679813385, 0.07854463905096054, 0.09101222455501556, 0.02484912797808647, -0.03774842247366905, -0.01676109991967678, 0.008502727374434471, -0.1270308643579483, -0.038190338760614395, -0.00850129034370184, 0.1645708680152893, -0.0010306034237146378, 0.025646695867180824, -0.05355774238705635, -0.010712065733969212, -0.03189454227685928, 0.06709107756614685, -0.009135197848081589, 0.07187801599502563, -0.06631685793399811, -0.10843727737665176, 0.06788969039916992, 0.028532978147268295, 0.12198182940483093, 0.03853350877761841, -0.040332697331905365, -0.06937967240810394, 0.0745331421494484, 0.05567021295428276, -0.07306024432182312, 0.16027826070785522, -0.077560655772686, 0.03616440296173096, -0.0824844092130661, -0.14127522706985474, 0.06034306809306145, -0.12386591732501984, 0.09436780959367752, -0.018854999914765358, -0.08256103843450546, -0.013965215533971786, 0.05723585560917854, -0.12449830025434494, -0.05458961799740791, -0.06645127385854721, -0.06132766604423523, -0.0037709693424403667, -0.031746819615364075, 0.11769367754459381, -0.07240143418312073, 0.15393789112567902, 0.012876316905021667, 0.009554947726428509, -0.05763162672519684, -0.004483029246330261, 0.1683165729045868, -0.043553803116083145, 0.1063939705491066, -0.0634838193655014, -0.06711030006408691, 0.05496334657073021, 0.1274147927761078, -0.02303871512413025, -0.012566779740154743, -0.24834565818309784, 0.1934259682893753, 0.01748686656355858, 0.07133805751800537, -0.06374531239271164, 0.12058663368225098, -0.00494988402351737, -0.13089989125728607, -0.020551903173327446, -0.015194172970950603, 0.10696779191493988, 0.027010086923837662, 0.051308225840330124, 0.05091789364814758, 0.187090203166008, 0.02092669904232025, -0.047105442732572556, -0.011368307285010815, 0.04318258911371231, -0.020124245434999466, 0.025020502507686615, 0.15261751413345337, 0.11688613146543503, 0.10631446540355682, -0.06089901179075241, 0.05919242277741432, -0.08610065281391144, -0.034095149487257004, 0.10235656797885895, 0.11977722495794296, 0.05705371871590614, -0.10232236236333847, -0.047287557274103165, -0.006762778852134943, 0.1296546459197998, -0.003427500370889902, 0.11127161979675293, 0.05235137417912483, 0.10011498630046844, -0.01189772505313158, 0.06256332248449326, -0.08404719829559326, 2.1177640102857098e-32, -0.1444922685623169, 0.027329329401254654, 0.05042457580566406, -0.10286884754896164, -0.017215557396411896, -0.06074006110429764, -0.010178741998970509, 0.057916171848773956, 0.010100200772285461, 0.05647636950016022, -0.20085422694683075, 0.030730802565813065, -0.07660812139511108, 0.017561975866556168, -0.017336104065179825, -0.12371142208576202, -0.05714092776179314, 0.05513334274291992, -0.025326544418931007, -0.038321513682603836, 0.15599553287029266, -0.09787266701459885, -0.018083518370985985, -0.13689590990543365, -0.03901226818561554, -0.023789456114172935, -0.073738694190979, -0.04147663339972496, -0.13071563839912415, 0.037644799798727036, -0.1335224211215973, 0.035535141825675964, 0.005443786270916462, -0.12342711538076401, 0.041886795312166214, -0.08117194473743439, 0.09936003386974335, 0.0646677240729332, -0.01366287749260664, -0.09409180283546448, -0.04274841770529747, 0.09321558475494385, 0.007902966812252998, -0.08073492348194122, -0.03739021718502045, 0.07933897525072098, 0.07697752118110657, 0.14573121070861816, -0.018878070637583733, 0.11433124542236328, 0.015043261460959911, -0.09708704799413681, -0.035703979432582855, 0.037045855075120926, -0.08463618159294128, 0.07392162829637527, 0.07919669896364212, -0.059993453323841095, 0.09077340364456177, -0.03995433449745178, -0.006959713529795408, 0.046719346195459366, 0.0375223234295845, -0.12182770669460297, 0.03446679934859276, 0.062465865164995193, 0.10628081113100052, 0.06712274253368378, 0.10836301743984222, -0.031553179025650024, -0.0871901586651802, 0.08705964684486389, -0.008116135373711586, -0.09604915231466293, 0.031862773001194, -0.10564041882753372, 0.11857375502586365, -0.07795382291078568, -0.1368449479341507, -0.0507892407476902, 0.03434232994914055, 0.06332679092884064, 0.0035587698221206665, -0.26221296191215515, -0.040833380073308945, -0.11019742488861084, 0.022059962153434753, -0.07337287813425064, -0.18697665631771088, -0.20896214246749878, -0.14920753240585327, -0.01510754507035017, 0.05015150085091591, -0.06926509737968445, -0.03988242894411087, -1.89880497143163e-32, -0.07249777019023895, -0.009604218415915966, 0.04391520097851753, 0.0936703011393547, 0.10831452906131744, 0.037086036056280136, 0.015647990629076958, 0.1353115290403366, 0.01601126231253147, -0.10413244366645813, 0.01732567697763443, -0.12399643659591675, 0.00871702004224062, -0.034468431025743484, 0.09109895676374435, 0.02568947710096836, -0.07133172452449799, 0.07130078971385956, -0.034068118780851364, 0.10065221786499023, -0.05413252115249634, 0.10887657850980759, -0.07800997048616409, 0.035914305597543716, -0.14437280595302582, 0.07304126024246216, 0.004628101829439402, 0.08249907940626144, 0.030899522826075554, -0.06256596744060516, -0.06463512033224106, -0.08506732434034348, -0.06703294068574905, 0.07036535441875458, -0.005491363350301981, -0.06812570244073868, -0.0567525178194046, -0.058881763368844986, -0.12172506004571915, 0.11690785735845566, 0.15075218677520752, 0.09853361546993256, -0.12881134450435638, -0.011315789073705673, -0.06912920624017715, 0.09529805928468704, 0.0442560613155365, 0.002350322902202606, 0.0428946353495121, -0.022045772522687912, 0.04246994107961655, 0.0026847131084650755, -0.06749248504638672, 0.09622586518526077, -0.09183948487043381, 0.1085067167878151, -0.07746957987546921, -0.07287286221981049, -0.17508681118488312, -0.0108644999563694, -0.09922056645154953, 0.0278268214315176, 0.021483153104782104, -0.013451352715492249, 0.1862814873456955, 0.01236950047314167, -0.051123637706041336, 0.03292408213019371, 0.007108884863555431, 0.056127723306417465, -0.09849311411380768, -0.011026423424482346, -0.020435988903045654, -0.009886426851153374, -0.003113506129011512, 0.038973938673734665, -0.01672975718975067, -0.036879122257232666, -0.04399172589182854, 0.028695931658148766, -0.02560275048017502, -0.020891206339001656, 0.07585161924362183, 0.057470060884952545, -0.07320639491081238, 0.06079839542508125, 0.11851423978805542, 0.10608463734388351, -0.007689984515309334, -0.019236724823713303, 0.003580963471904397, 0.026099542155861855, 0.0692223533987999, 0.10559627413749695, -0.002558089094236493, -1.0043547860050239e-07, -0.007812113501131535, -0.06361899524927139, 0.03349662199616432, 0.0589737594127655, 0.034090861678123474, 0.01646510139107704, -0.0372563861310482, 0.0662742480635643, -0.09757229685783386, -0.06731873750686646, 0.10989554226398468, 0.013420192524790764, -0.1132059097290039, 0.016592631116509438, -0.05150623619556427, -0.0015109688974916935, 0.012511350214481354, 0.04664616659283638, -0.08518588542938232, -0.049546726047992706, -0.018642518669366837, -0.024767480790615082, 0.06274617463350296, -0.06041916832327843, -0.004531420301645994, -0.04129538685083389, -0.03725603222846985, 0.1158481314778328, 0.1152217909693718, 0.02933703362941742, 0.005716003477573395, -0.05188366025686264, -0.09440635144710541, 0.08346720784902573, 0.08350987732410431, 0.06667403131723404, -0.0371326208114624, -0.03548697382211685, -0.004754812456667423, 0.1238672211766243, -0.12740445137023926, 0.11278469115495682, -0.1283959001302719, -0.07230951637029648, 0.0754808560013771, -0.0308206956833601, -0.042566489428281784, -0.08290184289216995, 0.13417598605155945, 0.03982807695865631, 0.01561354286968708, 0.07349211722612381, -0.11226417124271393, 0.06986729055643082, 0.1134304478764534, -0.010256513953208923, -0.12032616883516312, 0.03839939460158348, -0.0583733431994915, 0.027411026880145073, 0.007290647830814123, -0.112616166472435, 0.059083715081214905, 0.0026393875014036894], metadata={'source': 'AAAMLP-569to.pdf', 'page': 235}, content=\"Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 236   (3, 20) 0.38775666010579296   (3, 17) 0.38775666010579296   (3, 1) 0.38775666010579296   (3, 0) 0.3128396318588854   (4, 26) 0.2959842226518677   (4, 0) 0.9551928286692534 ═════════════════════════════════════════════════════════════════════════  We see that instead of integer values, this time we get floats. Replacing CountVectorizer with TfidfVectorizer is also a piece of cake. Scikit-learn also offers TfidfTransformer. If you have count values, you can use TfidfTransformer and get the same behaviour as TfidfVectorizer.   ═════════════════════════════════════════════════════════════════════════ # import what we need import pandas as pd  from nltk.tokenize import word_tokenize from sklearn import linear_model from sklearn import metrics from sklearn import model_selection from sklearn.feature_extraction.text import TfidfVectorizer . . .     # we go over the folds created     for fold_ in range(5):         # temporary dataframes for train and test         train_df = df[df.kfold != fold_].reset_index(drop=True)         test_df = df[df.kfold == fold_].reset_index(drop=True)          # initialize TfidfVectorizer with NLTK's word_tokenize         # function as tokenizer         tfidf_vec = TfidfVectorizer(             tokenizer=word_tokenize,             token_pattern=None         )          # fit tfidf_vec on training data reviews         tfidf_vec.fit(train_df.review)          # transform training and validation data reviews         xtrain = tfidf_vec.transform(train_df.review)         xtest = tfidf_vec.transform(test_df.review)          # initialize logistic regression model\"),\n",
       " VectorParams(vector=[-0.0489758625626564, -0.11741890758275986, -0.07044034451246262, 0.004060826264321804, 0.11016125231981277, 0.007283208426088095, -0.008635108359158039, 0.03821868449449539, 0.02214127779006958, 0.07199879735708237, 0.013409039005637169, -0.0386873334646225, -0.025640102103352547, 0.07382034510374069, 0.05069918558001518, 0.044171515852212906, 0.05852619931101799, -0.007594821508973837, -0.10610049217939377, -0.09967934340238571, -0.035589396953582764, 0.18027347326278687, 0.08079972118139267, 0.02166362851858139, -0.00628573028370738, -0.12386161834001541, -0.12837086617946625, 0.049293022602796555, -0.08449442684650421, 0.06612841784954071, -0.08823899179697037, 0.09213908761739731, -0.05982767418026924, 0.1144312396645546, -0.16769303381443024, 0.01789921708405018, -0.07388345897197723, 0.08830881863832474, 0.0263153575360775, 0.0066016605123877525, -0.07535679638385773, -0.10808942466974258, -0.024308953434228897, -0.01470254361629486, 0.07048749178647995, 0.052648063749074936, -0.04341188818216324, 0.07739169150590897, 0.039273571223020554, 0.033253174275159836, -0.14557313919067383, 0.07595446705818176, 0.03380526974797249, -0.05524587258696556, -0.13628199696540833, -0.07336366921663284, 0.08603183925151825, -0.013100911863148212, -0.011518728919327259, -0.06274688243865967, -0.048519931733608246, -0.13972659409046173, -0.008039996027946472, -0.08926735818386078, 0.002562947804108262, -0.08543869107961655, -0.025500642135739326, 0.007922477088868618, -0.02539820410311222, 0.10584957152605057, -0.020992422476410866, 0.1233154684305191, 0.01632683537900448, 0.07170497626066208, -0.05222998186945915, 0.06284245103597641, 0.13180014491081238, -0.016036884859204292, 0.09778020530939102, -0.04812988266348839, 0.009870036505162716, 0.05381743609905243, 0.08757232129573822, 0.04502350091934204, 0.03486758843064308, -0.1702166348695755, 0.1420534998178482, -0.02146916650235653, -0.04185282066464424, 0.0033719108905643225, 0.09794072806835175, -0.10545378178358078, 0.07191218435764313, -0.09857458621263504, 0.039058610796928406, 0.09597129374742508, -0.051152121275663376, -0.04377540200948715, -0.0021116998977959156, 0.05424901098012924, 0.019092559814453125, 0.08906742930412292, 0.0008113282383419573, -0.09772013872861862, -0.022984445095062256, 0.04684077203273773, 0.023079270496964455, 0.02279786206781864, 0.09862807393074036, -0.0752587541937828, 0.07221176475286484, 0.0944957435131073, -0.0479666143655777, 0.018342943862080574, 0.12300177663564682, 0.02987411990761757, -0.0498584508895874, 0.04402240365743637, 0.052354712039232254, 0.14938218891620636, -0.06714650988578796, 0.06070864945650101, 0.0005266314838081598, 0.002510581398382783, 0.08088897168636322, 0.09261704981327057, -0.031129270792007446, 1.289764303602516e-32, 0.005690079648047686, 0.15659204125404358, 0.04994595795869827, -0.09224409610033035, -0.04269560053944588, -0.07629967480897903, -0.0606737844645977, 0.042372290045022964, -0.12831196188926697, -0.04337029904127121, -0.1255224198102951, 0.070609912276268, 0.05260196700692177, 0.08395563066005707, 0.03895394504070282, -0.0862036943435669, -0.068146251142025, -0.027680525556206703, 0.000717529677785933, 0.06244529411196709, 0.06527960300445557, 0.004399513825774193, 0.07804788649082184, -0.1290515959262848, -0.035644207149744034, -0.06805495917797089, 0.02850005030632019, -0.05623874440789223, -0.20100393891334534, 0.012600011192262173, -0.18717041611671448, -0.04189498722553253, 0.054093483835458755, 0.016214001923799515, 0.03923528268933296, -0.1145554929971695, -0.06411129236221313, -0.016209086403250694, -0.0020549215842038393, -0.14156019687652588, -0.07178029417991638, 0.0916755422949791, -0.018746621906757355, 0.0003911381936632097, -0.12690626084804535, 0.06489501148462296, -0.06946398317813873, -0.009618082083761692, -0.010433505289256573, 0.0846271887421608, 0.13379237055778503, -0.05686880648136139, -0.05863653123378754, 0.04237499088048935, -0.05764489248394966, 0.07548007369041443, 0.08100162446498871, -0.13315294682979584, 0.1077113077044487, -0.07726722210645676, 0.038742199540138245, -0.011260897852480412, 0.11495517939329147, -0.0874774307012558, 0.06098655238747597, 0.029445044696331024, 0.08861006051301956, 6.165778177091852e-05, 0.05891484022140503, -0.13844290375709534, -0.015583482570946217, 0.02521645836532116, 0.003675072221085429, -0.03060033917427063, 0.08448804914951324, 0.10051647573709488, 0.08500070869922638, -0.09915459156036377, 0.012283587828278542, -0.025494975969195366, 0.06403843313455582, 0.031731728464365005, 0.04183945432305336, -0.1717163324356079, -0.03223054111003876, -0.058991316705942154, 0.008834417909383774, -0.056595850735902786, -0.10074365139007568, -0.08708032220602036, -0.143480122089386, 0.06248002499341965, 0.004884881898760796, -0.008046231232583523, -0.03215956687927246, -1.308969089495869e-32, -0.07912978529930115, -0.02621695026755333, -0.04208618402481079, 0.07905591279268265, -0.04061298817396164, -0.03186188265681267, -0.0019473412539809942, 0.004445446655154228, -0.09968265146017075, -0.11536693572998047, 0.08829453587532043, -0.12928836047649384, 0.09587099403142929, -0.00905026588588953, 0.07190942019224167, -0.049799639731645584, -0.046652182936668396, 0.1401911824941635, -0.05881342664361, 0.10726971179246902, 0.05871734023094177, 0.07117567211389542, -0.12593697011470795, 0.07332930713891983, -0.002779209055006504, -0.014558671973645687, -0.013754291459918022, 0.007502427790313959, -0.021750951185822487, -0.13245022296905518, 0.043934110552072525, 0.0032182803843170404, 0.006731066387146711, 0.02664683572947979, 0.09901495277881622, -0.005294725764542818, -0.02454952895641327, -0.2126469910144806, 0.014514734037220478, 0.11400126665830612, 0.09446316212415695, 0.11734746396541595, -0.05665740370750427, -0.09163222461938858, -0.1361948847770691, 0.03472355008125305, -0.1042967438697815, -0.007821043021976948, 0.03423192724585533, -0.07758519798517227, 0.021415937691926956, 0.025496164336800575, -0.05829744040966034, 0.10963848978281021, -0.054517582058906555, 0.028134692460298538, -0.04846208170056343, -0.10242387652397156, -0.10782260447740555, 0.06663676351308823, -0.13337762653827667, 0.08631253242492676, 0.11053474247455597, -0.013382874429225922, 0.061985716223716736, -0.09801305830478668, -0.06442009657621384, 0.08507305383682251, -0.05586457625031471, -0.01830514706671238, -0.03170971944928169, 0.046538569033145905, 0.019946714863181114, 0.08161741495132446, -0.004070615861564875, 0.014662270434200764, 0.0499434731900692, -0.026590047404170036, -0.08422145247459412, 0.003085722681134939, 0.007233053911477327, -0.05915148928761482, -0.04102534055709839, 0.04792004078626633, 0.0026710741221904755, 0.04106798768043518, 0.10616361349821091, 0.00977663416415453, 0.08462269604206085, -0.009806627407670021, 0.07576925307512283, -0.01827920787036419, 0.02035876177251339, 0.13443152606487274, 0.10657674074172974, -1.0013440032707877e-07, -0.12838006019592285, -0.04440624639391899, -0.0076801166869699955, 0.13678085803985596, -0.03388452157378197, -0.005566754378378391, 0.046064913272857666, 0.074887715280056, -0.1416938602924347, -0.03737839683890343, 0.08346355706453323, 0.03503505885601044, -0.21479104459285736, 0.01089085265994072, -0.08014693856239319, 0.04916475713253021, 0.023041116073727608, 0.03999476879835129, 0.024255700409412384, 0.009082098491489887, 0.11511783301830292, -0.0038935246411710978, 0.05140800029039383, -0.09193767607212067, -0.00915982760488987, -0.06955065578222275, -0.04021715745329857, -0.009715020656585693, 0.03167925029993057, 0.013319358229637146, -0.001967991702258587, -0.00022674075444228947, -0.12330117076635361, 0.012514384463429451, 0.10617265850305557, 0.11672139167785645, -0.06743023544549942, -0.0693478137254715, -0.04590427130460739, 0.14285118877887726, 0.05518258363008499, 0.135054349899292, -0.18035095930099487, -0.028058715164661407, 0.05918346345424652, -0.07978861778974533, -0.02730358950793743, -0.01272236555814743, -0.022597098723053932, 0.0049422066658735275, 0.08602546900510788, 0.09748487919569016, -0.11552908271551132, 0.12748047709465027, 0.11033082753419876, 0.04719066247344017, -0.10919585824012756, -0.03300877660512924, -0.08041396737098694, 0.0804704949259758, 0.059881992638111115, -0.01705240271985531, 0.09519598633050919, 0.03809501230716705], metadata={'source': 'AAAMLP-569to.pdf', 'page': 236}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 237         model = linear_model.LogisticRegression()          # fit the model on training data reviews and sentiment         model.fit(xtrain, train_df.sentiment)          # make predictions on test data         # threshold for predictions is 0.5         preds = model.predict(xtest)          # calculate accuracy         accuracy = metrics.accuracy_score(test_df.sentiment, preds)          print(f\"Fold: {fold_}\")         print(f\"Accuracy = {accuracy}\")         print(\"\") ═════════════════════════════════════════════════════════════════════════  It would be interesting to see how TF-IDF performs with our old logistic regression model on the sentiment dataset.  ═════════════════════════════════════════════════════════════════════════ ❯ python tfv_logres.py Fold: 0 Accuracy = 0.8976  Fold: 1 Accuracy = 0.8998  Fold: 2 Accuracy = 0.8948  Fold: 3 Accuracy = 0.8912  Fold: 4 Accuracy = 0.8995 ═════════════════════════════════════════════════════════════════════════  We see that these scores are a bit higher than CountVectorizer, and thus, it becomes the new benchmark that we would want to beat.   Another interesting concept in NLP is n-grams. N-grams are combinations of words in order. N-grams are easy to create. You just need to take care of the order. To make things even more comfortable, we can use n-gram implementation from NLTK.'),\n",
       " VectorParams(vector=[-0.0432983860373497, -0.12335412204265594, -0.03590486943721771, -0.05923003703355789, 0.044112466275691986, 0.01043087337166071, 0.07419287413358688, 0.029721349477767944, 0.049737654626369476, -0.015016275458037853, 0.09683112055063248, -0.14082828164100647, 0.04071103036403656, -0.02536122128367424, 0.10323861986398697, -0.01718338578939438, 0.08877255022525787, 0.0757175013422966, -0.16483840346336365, -0.12981624901294708, 0.13292238116264343, 0.18611924350261688, 0.03094286285340786, -0.01983414776623249, -0.011205312795937061, 0.0768142119050026, -0.07225900888442993, -0.05868924409151077, 0.02699132263660431, 0.054467517882585526, 0.0751483216881752, 0.2223862111568451, -0.05208131670951843, 0.07706407457590103, -0.018145347014069557, -0.016618700698018074, -0.09535053372383118, 0.09907686710357666, -0.023971645161509514, 0.10482753813266754, -0.143534317612648, -0.019381141290068626, -0.017889976501464844, 0.11557713896036148, 0.09172952175140381, 0.08181855827569962, 0.021156588569283485, 0.05144569277763367, 0.05596955493092537, -0.11599971354007721, -0.1626519113779068, 0.18776266276836395, -0.1971469521522522, 0.15366005897521973, -0.04272850602865219, -0.1519775241613388, 0.037391334772109985, -0.046346552670001984, 0.05324837937951088, -0.017094260081648827, -0.10959812998771667, -0.09694065898656845, -0.025366144254803658, -0.08435972779989243, 0.04376504197716713, -0.05189809948205948, 0.041365690529346466, 0.012860382907092571, 0.019103361293673515, 0.21888689696788788, -0.09781621396541595, 0.18209350109100342, -0.030366579070687294, 0.10699297487735748, -0.23415108025074005, 0.10351357609033585, 0.2044057995080948, 0.0019425610080361366, 0.23817740380764008, -0.13960346579551697, 0.07595832645893097, 0.11042879521846771, 0.24069833755493164, -0.03619682416319847, 0.025397730991244316, -0.1800244152545929, -0.07580932229757309, 0.004689511843025684, 0.06632499396800995, 0.0636482760310173, 0.17414292693138123, -0.04003259912133217, 0.014754809439182281, -0.05517124384641647, 0.0423617884516716, -0.0634382888674736, -0.0036375478375703096, 0.04482750967144966, 0.0789112001657486, 0.09826981276273727, 0.11534345149993896, -0.10178957134485245, 0.06308035552501678, -0.05333169549703598, -0.14149653911590576, 0.14051365852355957, 0.042272210121154785, 0.08216143399477005, 0.2572765648365021, -0.024559907615184784, 0.018102163448929787, 0.10534894466400146, -0.04915473610162735, 0.014042657800018787, -0.02483537048101425, 0.01890047825872898, 0.043880656361579895, -0.002636100398376584, 0.112810879945755, 0.16832727193832397, -0.1259174346923828, -0.03258084878325462, 0.051818251609802246, 0.02997554838657379, -0.12563635408878326, 0.018851784989237785, -0.04974228888750076, 1.137758998514175e-32, -0.0631578117609024, 0.10824135690927505, -0.06995856016874313, 0.006813845131546259, -0.08765356242656708, -0.02626921236515045, -0.10166987031698227, 0.004397651646286249, -0.1119830384850502, -0.015750642865896225, -0.02749590203166008, 0.10745298862457275, -0.026058612391352654, 0.08334922045469284, 0.06503719091415405, -0.03391754999756813, -0.07988516241312027, 0.04633582383394241, -0.1065797209739685, -0.01525617390871048, 0.028826918452978134, 0.007974044419825077, 0.05166991055011749, -0.04907993972301483, -0.10919779539108276, -0.04971231520175934, 0.08732981979846954, -0.21385560929775238, -0.15117968618869781, 0.03953626751899719, -0.21910209953784943, -0.1837761551141739, 0.16307182610034943, -0.020244460552930832, 0.06361563503742218, -0.18203268945217133, 0.05439690500497818, -0.05182861536741257, -0.07894686609506607, -0.31491565704345703, -0.11285057663917542, 0.08969484269618988, 0.05679050832986832, -0.04143555834889412, -0.09933602809906006, 0.08269268274307251, -0.027163686230778694, 0.09568528085947037, -0.01470170821994543, 0.11147351562976837, 0.13945908844470978, -0.0876065343618393, 0.009634452871978283, -0.006734851747751236, 0.06846383959054947, 0.08850157260894775, 0.02991517074406147, -0.09129378944635391, 0.19275426864624023, 0.02261887677013874, -0.049347177147865295, 0.021212104707956314, 0.1585933268070221, 0.05332542583346367, 0.11389116942882538, 0.029475264251232147, -0.07145880907773972, 0.005796439480036497, 0.168969064950943, -0.04529966413974762, -0.09228801727294922, 0.09423505514860153, -0.017396489158272743, -0.018263015896081924, -0.018873143941164017, -0.05518500506877899, 0.16247433423995972, -0.11518558859825134, -0.20676055550575256, 0.04593989998102188, 0.03231086581945419, 0.06899618357419968, 0.06687502562999725, -0.1942349672317505, -0.11179730296134949, -0.049107182770967484, 0.053323108702898026, -0.11229928582906723, -0.14031128585338593, -0.22435256838798523, 0.032892901450395584, -0.07246025651693344, -0.05832561478018761, -0.04786631464958191, -0.09461656957864761, -1.0687070073322184e-32, -0.09116273373365402, -0.018916990607976913, -0.018094133585691452, -0.04395272210240364, 0.01738719642162323, -0.06428549438714981, 0.022424491122364998, 0.03327585384249687, -0.010662642307579517, -0.16708727180957794, 0.013487910851836205, -0.05771223083138466, 0.10238558799028397, -0.07103415578603745, 0.06475389748811722, 0.018516311421990395, -0.0929667130112648, 0.09595387428998947, -0.0911056324839592, 0.20487502217292786, 0.05652208253741264, 0.07509060949087143, -0.14617504179477692, 0.09872213006019592, -0.16447940468788147, 0.08888237178325653, -0.14599297940731049, 0.11859556287527084, 0.03607989847660065, -0.05199297145009041, 0.05456562340259552, -0.08668886125087738, -0.0326932929456234, 0.05738487094640732, -0.02598423697054386, -0.08480516821146011, 0.009170999750494957, -0.1344415545463562, -0.08579828590154648, 0.04278738424181938, 0.1983923763036728, 0.25819385051727295, -0.017635483294725418, -0.09144916385412216, -0.1953372061252594, 0.06625624746084213, -0.010547247715294361, -0.06262287497520447, 0.004847758915275335, -0.07848748564720154, 0.024129318073391914, -0.026871666312217712, -0.11712183803319931, 0.1619940549135208, -0.03889082372188568, 0.036170318722724915, 0.0184517540037632, -0.12841172516345978, -0.07845200598239899, -0.1507730931043625, -0.14170080423355103, 0.026117445901036263, 0.001846306724473834, -0.08020634204149246, 0.19370314478874207, 0.007558425888419151, -0.08209700882434845, 0.047671470791101456, -0.014143843203783035, -0.016104837879538536, -0.17670689523220062, 0.03681556507945061, -0.08439813554286957, 0.00492065167054534, -0.10023240745067596, 0.11844310909509659, 0.08148004114627838, -0.20473314821720123, -0.20052064955234528, -0.13529819250106812, -0.08716106414794922, -0.04762854799628258, 0.0973673015832901, 0.04803710803389549, -0.019739769399166107, 0.11917856335639954, 0.05314293131232262, 0.13701069355010986, 0.157614603638649, 0.16098971664905548, -0.0030046445317566395, -0.0604303777217865, 0.02642213925719261, 0.20050033926963806, 0.11478835344314575, -1.0046403531305259e-07, -0.17573760449886322, -0.002260177629068494, -0.11794662475585938, -0.02651859261095524, 0.057991161942481995, -0.058505091816186905, 0.014377498999238014, 0.09296829998493195, -0.06308566778898239, -0.05042733997106552, 0.05450841784477234, -0.004694159608334303, -0.20746497809886932, -0.022040771320462227, -0.0669078603386879, 0.12303764373064041, 0.019684022292494774, -0.024661779403686523, -0.009897169657051563, -0.04987770691514015, 0.08809737861156464, 0.01693904958665371, 0.12052009999752045, 0.049367982894182205, -0.05832020193338394, 0.025792358443140984, -0.01718032732605934, 0.014871174469590187, 0.0760137215256691, -0.06282985955476761, -0.04479873180389404, 0.06626889109611511, -0.15467755496501923, 0.0012335202191025019, -0.06546229869127274, 0.09595123678445816, 0.020525330677628517, -0.08018159866333008, -0.0886983871459961, 0.09407609701156616, 0.005164232105016708, 0.11398953944444656, -0.17597372829914093, 0.05490218102931976, 0.13587835431098938, -0.004254923202097416, -0.016575980931520462, -0.08596888184547424, 0.06276233494281769, -0.0410841628909111, -0.04130217805504799, 0.07755676656961441, -0.18387167155742645, 0.07637512683868408, 0.06565862149000168, -0.0005887135048396885, -0.15928205847740173, 0.11588180810213089, 0.0980469211935997, -0.038379278033971786, 0.05853534862399101, 0.0009594369330443442, 0.07331708073616028, -0.08021891117095947], metadata={'source': 'AAAMLP-569to.pdf', 'page': 237}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 238 ═════════════════════════════════════════════════════════════════════════ from nltk import ngrams from nltk.tokenize import word_tokenize  # let\\'s see 3 grams N = 3 # input sentence sentence = \"hi, how are you?\" # tokenized sentence tokenized_sentence = word_tokenize(sentence) # generate n_grams n_grams = list(ngrams(tokenized_sentence, N)) print(n_grams) ═════════════════════════════════════════════════════════════════════════  Which gives:  ═════════════════════════════════════════════════════════════════════════ [(\\'hi\\', \\',\\', \\'how\\'),  (\\',\\', \\'how\\', \\'are\\'),  (\\'how\\', \\'are\\', \\'you\\'),  (\\'are\\', \\'you\\', \\'?\\')] ═════════════════════════════════════════════════════════════════════════  Similarly, we can also create 2-grams, or 4-grams, etc. Now, these n-grams become a part of our vocab, and when we calculate counts or tf-idf, we consider one n-gram as one entirely new token. So, in a way, we are incorporating context to some extent. Both CountVectorizer and TfidfVectorizer implementations of scikit-learn offers n-grams by ngram_range parameter, which has a minimum and maximum limit. By default, this is (1, 1). When we change it to (1, 3), we are looking at unigrams, bigrams and trigrams. The code change is minimal. Since we had the best result till now with tf-idf, let’s see if including n-grams up to trigrams improves the model.  The only change required is in the initialization of TfidfVectorizer.  ═════════════════════════════════════════════════════════════════════════         tfidf_vec = TfidfVectorizer(             tokenizer=word_tokenize,             token_pattern=None,             ngram_range=(1, 3)         ) ═════════════════════════════════════════════════════════════════════════  Let’s see if we get any kind of improvements.'),\n",
       " VectorParams(vector=[-0.05003085359930992, -0.023138610646128654, 0.04975691810250282, -0.130544975399971, 0.030303025618195534, -0.06606153398752213, -0.015074823051691055, 0.1737147718667984, -0.08249331265687943, 0.09256220608949661, -0.033847443759441376, -0.08278433978557587, -0.007302469573915005, 0.07274998724460602, 0.09673896431922913, 0.07628659904003143, -0.0064028725028038025, 0.16180771589279175, -0.15574592351913452, -0.1392907202243805, 0.1396271139383316, 0.10582926869392395, -0.0030808018054813147, 0.02457224577665329, 0.006460261531174183, 0.04458624869585037, -0.046538095921278, 0.06488294899463654, 0.01026150956749916, 0.041830211877822876, 0.08622118085622787, 0.08853071182966232, 0.0157186146825552, 0.04632017761468887, -0.04480747878551483, 0.05391455441713333, -0.02757558785378933, 0.08999626338481903, 0.003011176362633705, 0.0628654733300209, -0.04786989837884903, 0.05644788220524788, 0.007661779876798391, 0.024055039510130882, 0.13035959005355835, 0.05794196203351021, -0.0784793570637703, 0.07049386203289032, -0.05998252332210541, -0.021469885483384132, -0.1400667279958725, 0.01154476311057806, -0.016783328726887703, 0.12358375638723373, -0.0710141509771347, -0.07167021930217743, 0.01370792742818594, -0.0008346263784915209, 0.00669668335467577, -0.06586585193872452, -0.09825212508440018, -0.07977501302957535, -0.053004033863544464, -0.06838151067495346, -0.05051079019904137, 0.044348590075969696, 0.08198463171720505, 0.0117200231179595, 0.058325543999671936, 0.17062152922153473, -0.09243325889110565, 0.13263870775699615, -0.06968141347169876, 0.09972945600748062, -0.12411946803331375, -0.057666048407554626, 0.11221208423376083, -0.056304410099983215, 0.11070971190929413, -0.05632561072707176, -0.03596894443035126, 0.10659036785364151, 0.05337310582399368, 0.041464075446128845, -0.0010125379776582122, -0.19562549889087677, 0.006614505313336849, 0.07049206644296646, 0.013495410792529583, -0.0859019085764885, 0.03503957763314247, -0.16311949491500854, 0.05926258862018585, -0.04486928507685661, 0.06890086084604263, 0.17807278037071228, -0.002493751235306263, -0.11444565653800964, 0.05413027107715607, 0.10473261773586273, 0.04051560163497925, 0.007698981557041407, -0.04432132467627525, -0.11801677942276001, -0.03342412784695625, 0.05737821012735367, -0.036030616611242294, -0.003505274187773466, 0.14273421466350555, -0.07540875673294067, 0.001423192792572081, 0.009942037984728813, -0.097927026450634, 0.06235622614622116, 0.10565941780805588, 0.012622862122952938, 0.03144373744726181, -0.046716369688510895, 0.06131914630532265, 0.0739763081073761, -0.10196462273597717, 0.056862927973270416, 0.07235489040613174, 0.03362201899290085, 0.005899494979530573, 0.00029671043739654124, -0.08505707234144211, 1.7380277601554686e-32, -0.003494181437417865, 0.16668908298015594, -0.04718741402029991, -0.019369667395949364, -0.009068749845027924, -0.041048966348171234, 0.023726681247353554, 0.017978306859731674, -0.1308010220527649, 0.05317941680550575, -0.06398772448301315, 0.09108194708824158, -0.05969047173857689, -0.07461844384670258, 0.06275345385074615, -0.09309693425893784, -0.10893554240465164, 0.035933420062065125, -0.1213398277759552, 0.05617654696106911, -7.918260234873742e-05, 0.019128911197185516, 0.1273903101682663, 0.009385991841554642, -0.04984869807958603, -0.018574079498648643, 0.057670049369335175, -0.10928374528884888, -0.08098137378692627, 0.005156709346920252, -0.08235042542219162, -0.06570500135421753, -0.0006336801452562213, 0.0600632019340992, 0.07641123235225677, -0.19024187326431274, -0.056349560618400574, -0.08800948411226273, -0.061138588935136795, -0.13264557719230652, -0.13171623647212982, 0.00105094606988132, 0.04143664613366127, -0.04626449570059776, 0.06713572144508362, 0.08622531592845917, -0.046173904091119766, 0.021913738921284676, -0.04436207562685013, 0.018737373873591423, 0.12647821009159088, -0.03071838989853859, -0.007463966496288776, -0.012571937404572964, 0.031318727880716324, 0.07368785887956619, 0.04656002297997475, -0.019557757303118706, 0.1463949829339981, 0.010313751175999641, 0.031229492276906967, -0.041609231382608414, 0.11236494034528732, 0.053607940673828125, 0.07441305369138718, 0.007693316787481308, 0.024408822879195213, 0.0036978309508413076, 0.03229331970214844, -0.07274691015481949, 0.0006355068180710077, 0.012641814537346363, -0.014726686291396618, 0.036277931183576584, 0.0679863914847374, 0.04968912899494171, 0.11112901568412781, -0.06291728466749191, -0.08578626811504364, 0.04320559650659561, 0.010670430958271027, -0.04435938969254494, 0.06429541110992432, -0.20189248025417328, -0.1032615527510643, -0.1632329225540161, -0.007945912890136242, -0.03408322483301163, -0.02427024208009243, -0.06366182118654251, -0.12882564961910248, 0.033501558005809784, -0.024734769016504288, -0.008701375685632229, 0.016491016373038292, -1.4214281932286556e-32, -0.0805656760931015, -0.011405542492866516, -0.056019995361566544, 0.04506448283791542, -0.062728650867939, -0.05346252769231796, 0.08238570392131805, 0.02239239402115345, 0.03795513138175011, -0.15353764593601227, -0.03313172608613968, -0.04654698446393013, 0.016406385228037834, -0.03155442699790001, 0.12017640471458435, 0.020417729392647743, 0.020492741838097572, 0.15138211846351624, 0.05580192804336548, 0.16872519254684448, 0.08687330782413483, 0.07292305678129196, -0.31191277503967285, 0.005013864021748304, -0.027364516630768776, 0.0632421225309372, -0.11795084178447723, 0.10060802102088928, 0.008011749014258385, -0.022449001669883728, -0.018487179651856422, -0.02834990806877613, -0.09730329364538193, -0.044039834290742874, -0.028439752757549286, -0.06367213279008865, 0.007615339010953903, -0.1546788066625595, 0.04385192319750786, -0.03987232968211174, 0.11100751906633377, 0.13060754537582397, -0.02257923223078251, -0.043655045330524445, -0.024704772979021072, -0.0374159999191761, -0.23254531621932983, -0.004205020610243082, 0.05632365122437477, 0.0019197858637198806, -0.02771962247788906, -0.00047924823593348265, -0.03945142775774002, 0.050637681037187576, -0.06781721860170364, -0.041710469871759415, 0.03976571932435036, -0.08923909813165665, -0.15168358385562897, -0.06057571619749069, -0.16207130253314972, -0.03635432571172714, 0.09722013026475906, 0.07896485179662704, 0.13910514116287231, -0.003804757259786129, -0.10965265333652496, -0.02582656592130661, -0.03616969659924507, -0.019856909289956093, -0.06310862302780151, -0.02714741788804531, 0.02177039161324501, -0.006973036099225283, -0.016885830089449883, 0.09234588593244553, -0.004445687402039766, -0.05889582261443138, -0.11601299047470093, -0.05742407217621803, 0.007192905526608229, 0.005342330317944288, 0.02985084243118763, 0.060763441026210785, -0.011454577557742596, 0.08216053247451782, 0.04892008751630783, 0.06851758807897568, 0.1534559279680252, -0.04206712543964386, -0.010002601891756058, 0.03572431951761246, 0.03215448185801506, 0.16589225828647614, 0.04709677770733833, -9.996045946536469e-08, -0.14988337457180023, -0.009875739924609661, -0.024981357157230377, 0.058155324310064316, 0.11409056186676025, 0.011200697161257267, -0.0765666514635086, 0.11831827461719513, -0.09585455805063248, -0.10986954718828201, 0.024281039834022522, 0.07469164580106735, -0.11283004283905029, -0.02906864881515503, -0.008303634822368622, 0.09264825284481049, 0.027803122997283936, -0.010120299644768238, -0.024218978360295296, -0.030761826783418655, 0.05842322111129761, -0.012572232633829117, 0.027437562122941017, 0.04524954780936241, -0.03849704936146736, -0.08200185745954514, -0.055737823247909546, 0.04085075110197067, 0.04871625453233719, 0.02354513853788376, -0.014517863281071186, 0.06335273385047913, -0.06276863068342209, -0.0072492738254368305, 0.08408042043447495, 0.12024517357349396, 0.03910413756966591, -0.0849805399775505, -0.03690081089735031, 0.026504380628466606, 0.03397104889154434, 0.1347244828939438, -0.11877921968698502, -0.031405672430992126, 0.16240611672401428, -0.04763658717274666, -0.011200849898159504, -0.13471005856990814, 0.06600384414196014, 0.008139879442751408, 0.045632973313331604, 0.07544589787721634, -0.09120944887399673, -0.01568634621798992, 0.011589769273996353, 0.08061840385198593, -0.058899328112602234, -0.042269837111234665, 0.03236434981226921, 0.004371180199086666, -0.016552910208702087, 0.03282475844025612, 0.15495958924293518, 0.1165631115436554], metadata={'source': 'AAAMLP-569to.pdf', 'page': 238}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 239 ═════════════════════════════════════════════════════════════════════════ ❯ python tfv_logres_trigram.py Fold: 0 Accuracy = 0.8931  Fold: 1 Accuracy = 0.8941  Fold: 2 Accuracy = 0.897  Fold: 3 Accuracy = 0.8922  Fold: 4 Accuracy = 0.8847 ═════════════════════════════════════════════════════════════════════════  This looks okay, but we do not see any improvements. Maybe we can get improvements by using only up to bigrams. I’m not showing that part here. Probably you can try to do it on your own.  There are a lot more things in the basics of NLP. One term that you must be aware of is stemming. Another is lemmatization. Stemming and lemmatization reduce a word to its smallest form. In the case of stemming, the processed word is called the stemmed word, and in the case of lemmatization, it is known as the lemma. It must be noted that lemmatization is more aggressive than stemming and stemming is more popular and widely used. Both stemming and lemmatization come from linguistics. And you need to have an in-depth knowledge of a given language if you plan to make a stemmer or lemmatizer for that language. Going into too much detail of these would mean adding one more chapter in this book. Both stemming and lemmatization can be done easily by using the NLTK package. Let’s take a look at some examples for both of them. There are many different types of stemmers and lemmatizers. I will show an example using the most common Snowball Stemmer and WordNet Lemmatizer.  ═════════════════════════════════════════════════════════════════════════ from nltk.stem import WordNetLemmatizer  from nltk.stem.snowball import SnowballStemmer  # initialize lemmatizer lemmatizer = WordNetLemmatizer()'),\n",
       " VectorParams(vector=[-0.018186397850513458, -0.04032132774591446, -0.05415111780166626, -0.06989855319261551, 0.1994122564792633, 0.035983968526124954, 0.023395173251628876, 0.10255236178636551, -0.12148312479257584, 0.048862673342227936, 0.05445171892642975, -0.029202790930867195, 0.09961365908384323, 0.21452277898788452, 0.041331857442855835, 0.10623659938573837, -0.013262880966067314, 0.06707705557346344, -0.18374471366405487, -0.060573846101760864, 0.13670359551906586, 0.15358656644821167, -0.0034233012702316046, -0.028493721038103104, 0.006484288722276688, 0.12221746891736984, -0.08034665137529373, 0.09126519411802292, -0.007599954027682543, 0.14187011122703552, 0.03755282983183861, 0.2703155279159546, 0.06557181477546692, 0.05184392258524895, -0.11751911044120789, 0.025137871503829956, -0.1281694620847702, 0.12514375150203705, 0.010963150300085545, 0.16739751398563385, -0.0567183755338192, -0.038233522325754166, -0.0640559047460556, 0.017013447359204292, 0.1790655553340912, -0.053400371223688126, -0.16961687803268433, 0.00042290633427910507, -0.05223279446363449, 0.05649954080581665, -0.22696183621883392, -0.00785840768367052, -0.18571902811527252, 0.08332142978906631, -0.04195323958992958, -0.06999944895505905, 0.07978314161300659, -0.06573928892612457, -0.023305196315050125, -0.09898629039525986, -0.04294538125395775, -0.16518492996692657, -0.038779210299253464, -0.02792874351143837, -0.04208967834711075, -0.048834238201379776, -0.008948981761932373, 0.033689867705106735, 0.0005473104538396001, 0.1117323637008667, 0.020355964079499245, 0.17602233588695526, 0.03392784669995308, 0.07267855107784271, -0.15812501311302185, 0.0027275884058326483, 0.09350544959306717, -0.015501261688768864, 0.16096046566963196, 0.09337819367647171, -0.09608116745948792, 0.013550211675465107, -0.09366945177316666, -0.06794686615467072, 0.016363391652703285, -0.025490129366517067, 0.045699428766965866, -0.12428714334964752, -0.08347223699092865, 0.0023361912462860346, -0.008751138113439083, -0.14888060092926025, 0.03129265829920769, -0.08088573813438416, 0.07471048086881638, 0.015489315614104271, 0.010000084526836872, -0.18517954647541046, 0.077210932970047, 0.12857043743133545, 0.007000466343015432, -0.06595829129219055, -0.07598572224378586, -0.17275185883045197, -0.12799783051013947, 0.005008985288441181, -0.05664566159248352, 0.0659012719988823, 0.14461885392665863, -0.1252952367067337, -0.08233693987131119, 0.10579101741313934, -0.1490335762500763, 0.07287684082984924, 0.04317426308989525, 0.004292465280741453, 0.13987331092357635, -0.06179317086935043, 0.13629023730754852, 0.07126057893037796, -0.12190838903188705, 0.08543885499238968, 0.1965930312871933, 0.02375832386314869, 0.06710990518331528, 0.05400563403964043, -0.12131045758724213, 1.0480646653162067e-32, 0.05000416561961174, 0.0073757171630859375, -0.166562020778656, -0.031214311718940735, 0.03852161765098572, -0.05412328243255615, -0.043934356421232224, 0.06911258399486542, 0.07267390936613083, -0.022992225363850594, -0.023176301270723343, 0.20881721377372742, -0.13047075271606445, -0.07119236886501312, 0.07975482195615768, -0.19110333919525146, -0.007098362781107426, -0.022042496129870415, -0.19540834426879883, -0.06679850071668625, 0.09456729143857956, -0.028260139748454094, 0.12884004414081573, -0.0656479001045227, -0.12667547166347504, -0.06124981865286827, 0.10511087626218796, -0.25682204961776733, -0.03775610402226448, 0.04877906292676926, -0.05266109108924866, -0.12298829108476639, 0.013020135462284088, -0.008398830890655518, 0.09733053296804428, -0.13000760972499847, 0.05254468321800232, -0.10885654389858246, -0.05715973302721977, -0.17613260447978973, -0.17329087853431702, -0.021148908883333206, 0.163373202085495, -0.22261223196983337, 0.03564321994781494, 0.1438736468553543, 0.08004693686962128, 0.00701286131516099, 0.019424255937337875, 0.04229535534977913, 0.14646759629249573, -0.16337041556835175, 0.09714964777231216, 0.02653425745666027, -0.047914642840623856, 0.1978653222322464, 0.06491509824991226, -0.052225466817617416, 0.12063302099704742, -0.08795914798974991, -0.11904836446046829, -0.07073710113763809, 0.09286025166511536, 0.03820672631263733, 0.13641324639320374, 2.8862043109256774e-05, 0.013041367754340172, 0.07334137707948685, 0.01392657682299614, -0.040300916880369186, 0.04437307268381119, 0.008846674114465714, -0.0034070496913045645, -0.007275324314832687, 0.05281984806060791, 0.08713915944099426, 0.09199080616235733, -0.06178712844848633, -0.1572110950946808, -0.0012421058490872383, -0.10379031300544739, 0.04247816652059555, 0.02855452336370945, -0.24896147847175598, -0.16803479194641113, 0.024694064632058144, 0.03867093473672867, -0.24610763788223267, 0.1733947992324829, -0.12446831166744232, -0.14259810745716095, 0.07472780346870422, 0.04023704305291176, -0.15219256281852722, 0.03791970759630203, -1.0869253330600407e-32, -0.18233852088451385, -0.13338333368301392, -0.05820653587579727, -0.0476825013756752, 0.06118043512105942, -0.1298222839832306, 0.12316913902759552, 0.07118871062994003, 0.10611411929130554, -0.23040702939033508, -0.1201263815164566, 0.03216225281357765, -0.09627293795347214, -0.04029453918337822, 0.058607615530490875, -0.01822992041707039, 0.012376897968351841, 0.1218109205365181, -0.013282403349876404, 0.2057904452085495, -0.04117102921009064, 0.07150810211896896, -0.2155260294675827, -0.0004554089391604066, 0.033204056322574615, 0.11304505914449692, 0.050642672926187515, 0.09461197257041931, -0.03494282439351082, 0.04628715664148331, 0.01733364351093769, 0.026497475802898407, -0.06568299233913422, -0.041081562638282776, -0.0675974115729332, -0.02378128282725811, -0.029934925958514214, -0.2126225233078003, -0.023053351789712906, -0.007567389402538538, 0.11855470389127731, 0.09717269241809845, -0.01753510907292366, -0.023661883547902107, -0.09868964552879333, -0.07561388611793518, -0.23734205961227417, 0.10372741520404816, 0.11964645981788635, 0.07762419432401657, -0.0052289096638560295, 0.06025354564189911, -0.02994670160114765, 0.019697576761245728, -0.042755864560604095, -0.09626450389623642, 0.12513099610805511, -0.18260419368743896, -0.10684378445148468, -0.04678012430667877, -0.09264755994081497, 0.04625146463513374, -0.03821338713169098, -0.0777093842625618, 0.11906032264232635, -0.09847260266542435, -0.08263938128948212, -0.0023436120245605707, -0.011209732852876186, 0.006613091100007296, -0.07638385891914368, 0.05900012329220772, -0.009607241488993168, -0.01105691771954298, -0.016475548967719078, 0.07381100952625275, -0.021567728370428085, 0.0013972356682643294, -0.04623790085315704, -0.08844099938869476, 0.10382703691720963, 0.025452664121985435, -0.02750726230442524, -0.013440434820950031, -0.03748347610235214, 0.013162526302039623, 0.028623202815651894, -0.005804393906146288, 0.10663942992687225, -0.15464496612548828, 0.0001961300877155736, -0.12131300568580627, 0.055007923394441605, 0.2350066900253296, 0.014978557825088501, -9.965209812889952e-08, -0.13197335600852966, 0.03730517625808716, -0.04582943022251129, 0.10787886381149292, 0.10484035313129425, -0.13320745527744293, -0.034087397158145905, 0.01908871717751026, -0.029169682413339615, -0.08783578872680664, 0.019051644951105118, 0.03920943662524223, -0.2346029430627823, -0.01086869090795517, 0.018264463171362877, 0.03146176412701607, 0.05274384841322899, 0.0386369414627552, -0.019470233470201492, -0.09152968227863312, 0.008188341744244099, -0.0079534612596035, -0.03750099614262581, 0.06453493982553482, 0.019843246787786484, -0.08351793140172958, -0.0101862084120512, 0.09936176240444183, 0.24082402884960175, 0.021688612177968025, -0.06615225225687027, 0.11092785745859146, -0.06134805828332901, 0.12105780839920044, 0.14344941079616547, 0.18358759582042694, 0.024196641519665718, -0.09056614339351654, -0.1093490868806839, 0.1708829402923584, 0.04750958830118179, 0.16618169844150543, 0.034095197916030884, -0.05649300292134285, 0.007680498994886875, 0.06637661904096603, -0.00032265533809550107, -0.019730133935809135, 0.16582858562469482, 0.07618632167577744, -0.05723176896572113, 0.10809820145368576, -0.046441420912742615, 0.05162089690566063, 0.030203336849808693, 0.11355256289243698, 0.02426227554678917, -0.054701417684555054, 0.049769606441259384, -0.020577270537614822, 0.014418882317841053, 0.060241952538490295, 0.24152147769927979, 0.15650998055934906], metadata={'source': 'AAAMLP-569to.pdf', 'page': 239}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 240 # initialize stemmer stemmer = SnowballStemmer(\"english\")  words = [\"fishing\", \"fishes\", \"fished\"]  for word in words:     print(f\"word={word}\")     print(f\"stemmed_word={stemmer.stem(word)}\")     print(f\"lemma={lemmatizer.lemmatize(word)}\")     print(\"\") ═════════════════════════════════════════════════════════════════════════  This will print:  ═════════════════════════════════════════════════════════════════════════ word=fishing stemmed_word=fish lemma=fishing  word=fishes stemmed_word=fish lemma=fish  word=fished stemmed_word=fish lemma=fished ═════════════════════════════════════════════════════════════════════════  As you can see, stemming and lemmatization are very different from each other. When we do stemming, we are given the smallest form of a word which may or may not be a word in the dictionary for the language the word belongs to. However, in the case of lemmatization, this will be a word. You can now try on your own to add stemming and lemmatizations and see if it improves your result.  One more topic that you should be aware of is topic extraction. Topic extraction can be done using non-negative matrix factorization (NMF) or latent semantic analysis (LSA), which is also popularly known as singular value decomposition or SVD. These are decomposition techniques that reduce the data to a given number of components. You can fit any of these on sparse matrix obtained from CountVectorizer or TfidfVectorizer.   Let’s apply it on TfidfVetorizer that we have used before.'),\n",
       " VectorParams(vector=[-0.017984339967370033, -0.035112861543893814, 0.06183691322803497, -0.0010001914342865348, 0.1994798630475998, 0.0033222034107893705, 0.0533287450671196, 0.06460114568471909, -0.03671908751130104, 0.0539349801838398, 0.014902988448739052, -0.04147365316748619, -0.0012170360423624516, -0.08787807077169418, 0.009162647649645805, 0.07468900084495544, -0.08375430107116699, 0.0888974741101265, -0.13098593056201935, -0.11739073693752289, 0.03711587190628052, 0.1499822586774826, 0.030045852065086365, 0.04260866716504097, -0.017464930191636086, 0.025393767282366753, -0.035994019359350204, 0.010491380468010902, -0.11098236590623856, 0.007759238127619028, 0.02255910262465477, 0.12727059423923492, -0.014166288077831268, 0.11738985776901245, -0.020427050068974495, 0.022199656814336777, -0.10675178468227386, 0.11106923967599869, -0.0006641759537160397, 0.05877545475959778, -0.05367569997906685, -0.03607502579689026, -0.0018912864616140723, -0.01905086636543274, 0.1653839647769928, 0.04665370658040047, -0.13432292640209198, -0.011679176241159439, 0.09808146953582764, 0.05749605596065521, -0.1733076274394989, 0.13437104225158691, -0.04947962984442711, 0.11331363022327423, -0.09830885380506516, -0.16735363006591797, 0.09188982844352722, -0.05055661126971245, 0.11782356351613998, -0.11605188995599747, -0.02456831932067871, -0.17352762818336487, -0.025601010769605637, -0.10029871761798859, -0.011629266664385796, -0.11210518330335617, 0.006223274860531092, 0.06776943802833557, -0.03084767423570156, 0.12885890901088715, -0.038055554032325745, 0.19949336349964142, 0.008783379569649696, 0.07567796856164932, -0.17161309719085693, 0.00458855414763093, 0.07956181466579437, -0.08520405739545822, 0.16050833463668823, -0.010911455377936363, -0.11468283087015152, 0.07339226454496384, 0.12670311331748962, 0.00524256331846118, 0.02463255636394024, -0.16986894607543945, 0.11058469116687775, -0.04589487239718437, -0.031813569366931915, 0.03365083038806915, -0.019492052495479584, -0.08374247699975967, 0.10975748300552368, -0.10114521533250809, 0.1078057661652565, 0.06631416082382202, 0.060478951781988144, -0.04854254424571991, 0.09370661526918411, 0.16751721501350403, -0.02144608646631241, -0.0016701188869774342, 0.007362722419202328, -0.11423710733652115, -0.07393603026866913, 0.0021226173266768456, 0.07385195791721344, 0.04308783635497093, 0.19782860577106476, -0.15912188589572906, -0.01648225076496601, -0.010596176609396935, -0.07124226540327072, 0.06592938303947449, 0.16469992697238922, 0.024566195905208588, 0.0809490755200386, 0.05589769035577774, 0.0691990777850151, 0.11551635712385178, -0.14902900159358978, 0.017790794372558594, -0.024576036259531975, 0.07956551760435104, -0.029426056891679764, 0.058016758412122726, 0.08666276931762695, 1.7801861303637407e-32, -0.0990304946899414, -0.005178456660360098, -0.07721772789955139, -0.05918745696544647, -0.03531648591160774, -0.013780428096652031, 0.06405101716518402, 0.04125151038169861, -0.050301481038331985, 0.00826534628868103, -0.13643397390842438, 0.015855252742767334, -0.022244075313210487, 0.03963721916079521, -0.01454234030097723, -0.14914588630199432, -0.026549365371465683, 0.007156962063163519, -0.06819909811019897, -0.053089164197444916, 0.18457508087158203, -0.004385663196444511, 0.04599929600954056, -0.08347907662391663, -0.16069148480892181, -0.1396392434835434, -0.05749443918466568, -0.14937597513198853, -0.08318404108285904, 0.0023945742286741734, -0.20171111822128296, 0.0023558693937957287, 0.11111356317996979, -0.04175744205713272, 0.02780856005847454, -0.15024548768997192, 0.16093383729457855, 0.01784309186041355, -0.018707754090428352, -0.16338692605495453, -0.04020174220204353, 0.06775772571563721, 0.04313255846500397, -0.09279312938451767, -0.033693961799144745, 0.1734398603439331, 0.0002515570668037981, 0.04727795720100403, 0.051768045872449875, 0.0649576261639595, -0.048630490899086, -0.12059570848941803, 0.018338747322559357, 0.024459604173898697, -0.025995668023824692, 0.08407694846391678, 0.07438187301158905, -0.04706988483667374, 0.139877051115036, -0.036331530660390854, -0.012298738583922386, 0.0006275477353483438, 0.07450666278600693, 0.03688903525471687, 0.14900758862495422, 0.019473545253276825, 0.14820496737957, 0.09188525378704071, 0.11301286518573761, -0.04916437715291977, -0.13768360018730164, 0.09149288386106491, -0.07188025116920471, -0.13518860936164856, 0.09512726217508316, 0.0354500375688076, 0.07133074849843979, -0.06513872742652893, -0.1849479079246521, -0.027809109538793564, -0.007779880426824093, 0.08217611163854599, -0.017886828631162643, -0.2781431972980499, 0.048358187079429626, -0.051882851868867874, 0.03955068066716194, -0.15873944759368896, -0.08371422439813614, -0.2655774652957916, -0.14407864212989807, 0.03509354218840599, 0.020578447729349136, -0.022843003273010254, 0.011826422065496445, -1.5789610400965475e-32, -0.028404302895069122, -0.07142606377601624, 0.06564037501811981, -0.0013444684445858002, 0.07545767724514008, -0.019502632319927216, -0.1079670712351799, 0.05160677805542946, -0.023261208087205887, -0.16596317291259766, -0.05536499619483948, -0.19908882677555084, 0.060548085719347, -0.05081029236316681, 0.08407799899578094, 0.06880497187376022, -0.026675235480070114, 0.17809413373470306, -0.06685285270214081, 0.18365319073200226, -0.0960712805390358, 0.060934219509363174, -0.11247152835130692, 0.08969691395759583, -0.1187959760427475, 0.087374247610569, 0.03739006444811821, 0.08221214264631271, 0.018808016553521156, -0.11652509868144989, -0.10746263712644577, 0.036143526434898376, -0.12070976197719574, 0.08894971758127213, -0.06371012330055237, -0.14117592573165894, -0.036228206008672714, -0.16853824257850647, -0.1373167335987091, 0.07090117782354355, 0.19787946343421936, 0.20557251572608948, -0.1580263376235962, -0.011857236735522747, -0.06706975400447845, -0.030341986566781998, -0.10391981899738312, 0.041154343634843826, -0.07060478627681732, -0.0013299916172400117, 0.06641675531864166, -0.00717628188431263, -0.06837639957666397, 0.043857499957084656, -0.03401467204093933, -0.006217951886355877, -0.012450503185391426, -0.031134124845266342, -0.15549923479557037, -0.11092403531074524, -0.08341356366872787, 0.046802401542663574, 0.01674114726483822, -0.032056208699941635, 0.2093847543001175, 0.035531025379896164, -0.07949673384428024, 0.06355210393667221, -0.0573292002081871, 0.06995099037885666, -0.1762077659368515, -0.012940088286995888, 0.0006202514632605016, -0.05926426872611046, -0.04256388172507286, 0.10209788382053375, 0.013091434724628925, -0.10066024214029312, -0.06310813874006271, -0.022840917110443115, -0.04469909518957138, 0.005945263896137476, 0.07480315119028091, 0.05160963162779808, 0.01495976373553276, 0.1290179342031479, 0.07129041105508804, 0.055322807282209396, 0.11000911891460419, 0.08627168089151382, 0.053416844457387924, -0.11195118725299835, 0.19445566833019257, 0.1575651615858078, 0.06485264003276825, -1.0097247127305309e-07, -0.10455843061208725, 0.013805272057652473, -0.11511915922164917, 0.06459841132164001, 0.03894256800413132, 0.008539631962776184, -0.07869978249073029, 0.07679038494825363, -0.08341895043849945, -0.019015535712242126, 0.10560288280248642, 0.030700819566845894, -0.17707403004169464, 0.0539831705391407, -0.05689419433474541, 0.08481109142303467, -0.05102012678980827, 0.04100443795323372, -0.044729672372341156, -0.04691196605563164, 0.02773747406899929, -0.056468017399311066, 0.07561927288770676, -0.013101032935082912, 0.014517632313072681, -0.06910473853349686, -0.018847238272428513, 0.0017159971175715327, 0.10538246482610703, -0.04977823421359062, -0.10192922502756119, -0.026898441836237907, -0.12000119686126709, -0.0516546294093132, 0.13901227712631226, 0.09972483664751053, 0.05332714691758156, -0.09507691115140915, -0.053432706743478775, 0.07022222876548767, -0.026615433394908905, 0.07585234194993973, -0.06594634801149368, -0.037151094526052475, 0.05680683255195618, -0.021897366270422935, 0.04657960683107376, -0.017770817503333092, 0.19430291652679443, -0.03359972685575485, -0.0655219554901123, -0.051456719636917114, -0.03832190856337547, 0.03306259214878082, 0.05340695381164551, 0.04870091378688812, -0.09959058463573456, 0.125560000538826, 0.03380321338772774, -0.08161371201276779, 0.056888747960329056, 0.027886351570487022, 0.11270172894001007, 0.03172977268695831], metadata={'source': 'AAAMLP-569to.pdf', 'page': 240}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 241 ═════════════════════════════════════════════════════════════════════════ import pandas as pd from nltk.tokenize import word_tokenize from sklearn import decomposition from sklearn.feature_extraction.text import TfidfVectorizer  # create a corpus of sentences # we read only 10k samples from training data # for this example corpus = pd.read_csv(\"../input/imdb.csv\", nrows=10000) corpus = corpus.review.values  # initialize TfidfVectorizer with word_tokenize from nltk # as the tokenizer tfv = TfidfVectorizer(tokenizer=word_tokenize, token_pattern=None)  # fit the vectorizer on corpus tfv.fit(corpus)  # transform the corpus using tfidf corpus_transformed = tfv.transform(corpus)  # initialize SVD with 10 components svd = decomposition.TruncatedSVD(n_components=10)  # fit SVD corpus_svd = svd.fit(corpus_transformed)  # choose first sample and create a dictionary # of feature names and their scores from svd # you can change the sample_index variable to # get dictionary for any other sample sample_index = 0 feature_scores = dict(     zip(         tfv.get_feature_names(),         corpus_svd.components_[sample_index]     ) )  # once we have the dictionary, we can now # sort it in decreasing order and get the  # top N topics N = 5 print(sorted(feature_scores, key=feature_scores.get, reverse=True)[:N]) ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[0.023353906348347664, -0.057792045176029205, 0.070805624127388, 0.012039868161082268, 0.09914926439523697, -0.023951591923832893, 0.15866200625896454, -0.03379911184310913, -0.025085976347327232, 0.030727826058864594, 0.06644128262996674, 0.11582332104444504, -0.061092548072338104, -0.04710492491722107, -0.025080600753426552, 0.062232621014118195, -0.06035701930522919, -0.021626995876431465, -0.05735331401228905, -0.21687306463718414, -0.012887467630207539, 0.16778233647346497, 0.06015588715672493, 0.12821708619594574, 0.023423202335834503, 0.10192472487688065, 0.009136528708040714, 0.10457366704940796, -0.020231924951076508, 0.04604589194059372, 0.011892556212842464, 0.10666999965906143, 0.10215853154659271, 0.04703519865870476, 0.026934219524264336, 0.057772912085056305, -0.06553100049495697, 0.0006460708100348711, -0.04191514104604721, 0.09649106115102768, -0.013143736869096756, -0.04381360113620758, -0.0020221073646098375, -0.03669625148177147, 0.09623496979475021, 0.05813250690698624, -0.21233108639717102, -0.09140996634960175, 0.1438279002904892, -0.003897282527759671, -0.09989986568689346, 0.13896223902702332, -0.11767034977674484, 0.09559842199087143, -0.04533100873231888, -0.17063315212726593, 0.097257100045681, -0.048692602664232254, 0.060728710144758224, -0.13194862008094788, -0.04730120673775673, -0.11399276554584503, 0.0323365293443203, -0.061561718583106995, 0.022269101813435555, -0.09585435688495636, -0.06859291344881058, 0.04113680124282837, -0.05131526663899422, 0.12530623376369476, -0.016262348741292953, 0.1094728484749794, -0.04188189283013344, 0.07722549140453339, -0.10062907636165619, 0.06109971925616264, -0.007802070118486881, -0.2288352996110916, 0.0723043754696846, 0.082407645881176, -0.08900215476751328, -0.0962304174900055, 0.09842618554830551, 0.10286228358745575, -0.004798701032996178, -0.12036553770303726, 0.00889609381556511, -0.12449020147323608, 0.004576598759740591, 0.009672444313764572, -0.004492904059588909, -0.07709702849388123, 0.180693581700325, -0.053491003811359406, 0.018052350729703903, 0.17051304876804352, 0.10716869682073593, -0.06015240401029587, -0.01832214742898941, 0.17800438404083252, -0.05806339532136917, -0.00431727385148406, -0.0019082316430285573, -0.10433340072631836, -0.053076114505529404, 0.07587035745382309, 0.09326579421758652, -0.03184749186038971, 0.1010526493191719, -0.11191602796316147, -0.014322204515337944, -0.05391938239336014, -0.1125093623995781, 0.05194853991270065, 0.04757034033536911, -0.03759009391069412, 0.008095962926745415, 0.14745083451271057, 0.021319646388292313, 0.13691085577011108, -0.10182677209377289, -0.014142265543341637, -0.08965697884559631, 0.06313707679510117, -0.07100196182727814, 0.07747605443000793, 0.11607929319143295, 6.0658245200215544e-33, -0.0823880061507225, -0.037489067763090134, -0.053888387978076935, -0.044143445789813995, 0.019311249256134033, 0.03132999315857887, -0.02797476202249527, 0.008455469273030758, -0.016677243635058403, 0.03949835151433945, -0.08143371343612671, 0.05469456687569618, -0.01710476540029049, 0.06018409878015518, -0.01228924561291933, -0.061571843922138214, 0.05159309506416321, -0.013034436851739883, -0.015162819065153599, -0.01623629219830036, 0.20034489035606384, 0.0205675158649683, 0.03803602606058121, -0.1007017195224762, -0.13667289912700653, -0.10850866138935089, -0.07002965360879898, -0.04676062613725662, -0.1185164824128151, -0.024093417450785637, -0.22835490107536316, 0.021522564813494682, 0.08633001893758774, 0.009132676757872105, 0.006298215594142675, -0.053599197417497635, 0.08768387883901596, -0.017661526799201965, -0.08570018410682678, -0.04364022612571716, -0.11190218478441238, -0.008480729535222054, -0.0538894385099411, -0.07694847881793976, -0.04770134761929512, 0.14037814736366272, -0.0728185623884201, -2.8128806661698036e-05, -0.009690157137811184, 0.13021370768547058, -0.06399769335985184, -0.04210638254880905, 0.07476463168859482, -0.018316684290766716, -0.11960195004940033, 0.06083671748638153, 0.12199945747852325, -0.1289014220237732, 0.04476376250386238, -0.12663491070270538, -0.04695455729961395, 0.07938486337661743, 0.006245946045964956, -0.038665201514959335, 0.07201725989580154, 0.030477486550807953, 0.2511763572692871, 0.058531925082206726, 0.10983236134052277, -0.10983045399188995, -0.09990978240966797, 0.04296253249049187, -0.12492610514163971, -0.16609981656074524, 0.009451458230614662, -0.06433860957622528, 0.03330516442656517, -0.08051237463951111, -0.0411730520427227, -0.018741730600595474, 0.0887015089392662, -0.06852509081363678, 0.06679780036211014, -0.18448564410209656, 0.10314388573169708, -0.002347600879147649, -0.06086405739188194, -0.13356269896030426, -0.026871103793382645, -0.14474214613437653, -0.17157185077667236, 0.011627650819718838, 0.006076878402382135, -0.07989367097616196, 0.010333731770515442, -1.1110197346424328e-32, 0.02538517862558365, -0.03679746761918068, -0.04738038033246994, 0.04166872054338455, 0.09941793978214264, 0.0073441495187580585, -0.03683942183852196, 0.10308925807476044, 0.01793939247727394, -0.11910654604434967, -0.01140114851295948, -0.13222463428974152, 0.03754851594567299, -0.09986447542905807, 0.14067964255809784, 0.18810002505779266, -0.08072702586650848, 0.19551981985569, -0.1304774433374405, 0.02730376645922661, -0.13082259893417358, 0.06074526906013489, 0.0134162288159132, 0.06409964710474014, -0.0929020494222641, -0.07565493136644363, 0.11641485244035721, -0.058586884289979935, 0.04108656197786331, -0.10147474706172943, -0.04923141747713089, 0.028136223554611206, -0.048850107938051224, 0.14004026353359222, -0.04144255444407463, -0.084775909781456, 0.03184519335627556, -0.16279074549674988, -0.17331789433956146, 0.14298346638679504, 0.15355801582336426, 0.23372547328472137, -0.15622031688690186, 0.027354750782251358, -0.06059277430176735, 0.01714397594332695, -0.17536446452140808, 0.038585081696510315, -0.06910713016986847, -0.04644378647208214, -0.007621957920491695, 0.006157548166811466, -0.14236949384212494, -0.0004891882999800146, -0.04852354899048805, -0.03405728191137314, -0.06474953144788742, 0.06863868981599808, -0.12049217522144318, 0.011974477209150791, 0.00018930301303043962, 0.016801394522190094, -0.043004777282476425, 0.07707277685403824, 0.14823570847511292, -0.013088474981486797, -0.10023695230484009, 0.004999957047402859, -0.05314987152814865, -0.08574065566062927, -0.08653842657804489, -0.1048845648765564, -0.018920740112662315, -0.12960021197795868, -0.1075323075056076, 0.0716538205742836, -0.06314215064048767, 0.045126188546419144, -0.06254231929779053, 0.025304514914751053, 0.09439033269882202, -0.0011070027248933911, 0.0822332426905632, 0.14329326152801514, -0.044577859342098236, 0.012832282111048698, 0.024801764637231827, 0.10148508101701736, 0.014075860381126404, 0.11249227076768875, 0.04365599527955055, -0.03502943739295006, 0.16820581257343292, 0.15469345450401306, 0.11705722659826279, -1.0136851358311105e-07, -0.06118261441588402, -0.0009871619986370206, -0.16119524836540222, 0.07853800058364868, -0.06995628774166107, -0.014787585474550724, -0.05981205031275749, 0.0916161984205246, -0.04528672620654106, -0.0061730314046144485, 0.1198996901512146, -0.009611664339900017, -0.2104988545179367, -0.012486651539802551, -0.058035124093294144, 0.1402389109134674, -0.0896112248301506, 0.08109361678361893, -0.04943336918950081, -0.036829087883234024, 0.13543887436389923, -0.015329654328525066, 0.10038454085588455, -0.01691371574997902, -0.09390982240438461, 0.0199594646692276, -0.024637771770358086, 0.020979786291718483, 0.047130484133958817, -0.01640198566019535, -0.009206977672874928, -0.08538231253623962, -0.09026719629764557, -0.10647184401750565, 0.14806538820266724, 0.008345300331711769, 0.005395511630922556, -0.11557679623365402, 0.04325689375400543, 0.12888401746749878, -0.13255393505096436, 0.11692428588867188, -0.1283942610025406, 0.01027601771056652, -0.012275018729269505, 0.0035210673231631517, 0.04007017984986305, -0.04669949412345886, 0.1457168608903885, 0.013660628348588943, -0.029360342770814896, -0.017394104972481728, -0.11967551708221436, 0.000516276340931654, 0.13351283967494965, 0.055950384587049484, 0.004978532437235117, 0.17947597801685333, -0.08303898572921753, -0.09473216533660889, 0.07922491431236267, 0.05949660390615463, 0.12151434272527695, -0.030308756977319717], metadata={'source': 'AAAMLP-569to.pdf', 'page': 241}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 242 You can run it for multiple samples by using a loop.  ═════════════════════════════════════════════════════════════════════════ N = 5  for sample_index in range(5):     feature_scores = dict(         zip(             tfv.get_feature_names(),             corpus_svd.components_[sample_index]         )     )     print(         sorted(             feature_scores,              key=feature_scores.get,              reverse=True         )[:N]     ) ═════════════════════════════════════════════════════════════════════════  This gives the following output.  ═════════════════════════════════════════════════════════════════════════ [\\'the\\', \\',\\', \\'.\\', \\'a\\', \\'and\\'] [\\'br\\', \\'<\\', \\'>\\', \\'/\\', \\'-\\'] [\\'i\\', \\'movie\\', \\'!\\', \\'it\\', \\'was\\'] [\\',\\', \\'!\\', \"\\'\\'\", \\'``\\', \\'you\\'] [\\'!\\', \\'the\\', \\'...\\', \"\\'\\'\", \\'``\\'] ═════════════════════════════════════════════════════════════════════════  You can see that it doesn’t make any sense at all. It happens. What can one do? Let’s try cleaning and see if it makes any sense.  To clean any text data, especially when it’s in pandas dataframe, you can make a function.  ═════════════════════════════════════════════════════════════════════════ import re import string  def clean_text(s):     \"\"\"     This function cleans the text a bit     :param s: string'),\n",
       " VectorParams(vector=[-0.037078842520713806, 0.014243894256651402, 0.04345819726586342, 0.053207751363515854, 0.0836961641907692, -0.05317789688706398, 0.13109765946865082, -0.041784681379795074, 0.05781245976686478, 0.04645143821835518, 0.027457457035779953, -0.011516285128891468, -0.06718108803033829, -0.11032194644212723, 0.0953746885061264, 0.051317691802978516, -0.012803628109395504, 0.01900826394557953, -0.19991080462932587, -0.09272804856300354, 0.01915203593671322, 0.1477057784795761, 0.10335816442966461, 0.05243371054530144, -0.005539050325751305, 0.06447932124137878, 0.0467437282204628, 0.0890425369143486, -0.11977417021989822, 0.025204533711075783, 0.04312821105122566, 0.08504436910152435, 0.06267251074314117, 0.10505801439285278, 0.08328182995319366, 0.11561410874128342, 0.020738711580634117, 0.1042703166604042, -0.09829816967248917, 0.07903795689344406, -0.10724685341119766, -0.04585934430360794, -0.01796947419643402, -0.040209922939538956, 0.15467846393585205, -0.049166783690452576, -0.18000085651874542, -0.07942739874124527, 0.0712638646364212, -0.041882775723934174, -0.12141027301549911, 0.044749174267053604, -0.1156575158238411, 0.19257506728172302, -0.045401398092508316, -0.0945931151509285, 0.16855476796627045, -0.03755548596382141, 0.15328380465507507, -0.17657925188541412, -0.06204334646463394, -0.10923277586698532, 0.03269810602068901, -0.04898924380540848, -0.011145798489451408, -0.12469514459371567, -0.14128872752189636, 0.13050948083400726, -0.04628696292638779, 0.10556067526340485, -0.15260301530361176, 0.1739269345998764, -0.14715635776519775, 0.11974141001701355, -0.17408061027526855, 0.07101397961378098, 0.03962011635303497, -0.1533297896385193, 0.22830796241760254, -0.01238524541258812, -0.0029835733585059643, -0.1066766083240509, 0.033224523067474365, 0.08590991795063019, -0.0007078223861753941, -0.0843753069639206, -0.08241423219442368, -0.06407903879880905, 0.0124350655823946, 0.015136525966227055, -0.050717372447252274, -0.06332831084728241, 0.19052517414093018, -0.10895588248968124, 0.022091694176197052, 0.078984335064888, 0.055133696645498276, -0.0009874339448288083, 0.035497035831213, 0.2060108780860901, 0.020557302981615067, -0.0003689310105983168, -0.007761779241263866, -0.27578604221343994, -0.1185608059167862, 0.11927548050880432, 0.08291630446910858, 0.04813527688384056, 0.17813652753829956, -0.1038261279463768, -0.03133121505379677, -0.028812415897846222, -0.17875583469867706, -0.014484400860965252, 0.1393316388130188, 0.025563327595591545, 0.18323729932308197, 0.03443768247961998, 0.009472845122218132, 0.10612281411886215, -0.08801671117544174, 0.025808192789554596, -0.046681471168994904, 0.12380211800336838, 0.01515671331435442, -0.029919559136033058, 0.04839235916733742, 1.1661888436675906e-32, -0.101298987865448, 0.03038662299513817, -0.10518623143434525, 0.0043152133002877235, -0.05147228389978409, 0.04421628266572952, -0.05999581143260002, 0.08309400826692581, 0.03650880232453346, -0.060725610703229904, -0.05363595485687256, 0.0361749529838562, 0.004806846845895052, -0.045811135321855545, 0.012447952292859554, 0.002977310447022319, -0.01564500480890274, -0.09564493596553802, -0.08143915235996246, -0.0426655113697052, 0.12035810947418213, 0.06615690141916275, 0.05203927680850029, 0.02926979772746563, -0.012227756902575493, -0.18719717860221863, -0.002224429277703166, -0.13820631802082062, -0.06147795170545578, -0.023562150076031685, -0.1918778121471405, 0.018144099041819572, -0.015452311374247074, 0.001162366010248661, 0.03072044625878334, 0.0320405587553978, 0.08328453451395035, 0.006109472364187241, -0.11489468067884445, -0.05330343544483185, -0.1584208607673645, -0.01622757874429226, 0.009220309555530548, -0.07589124143123627, -0.055231302976608276, 0.11600480228662491, 0.022276809439063072, 0.006656326353549957, 0.03635091707110405, 0.039989303797483444, 0.035082947462797165, 0.0009191504213958979, 0.0684254914522171, 0.0023093554191291332, -0.13368412852287292, 0.06274352967739105, 0.13731802999973297, -0.15004591643810272, 0.11638540774583817, -0.051637690514326096, 0.0016057557659223676, 0.07504504919052124, 0.07618539035320282, 0.09902793169021606, 0.09361080080270767, -0.003898050170391798, 0.2659560739994049, 0.14212164282798767, -0.03363163024187088, -0.08261297643184662, -0.12073897570371628, -0.009802863001823425, 0.014841098338365555, -0.10431336611509323, -0.044627465307712555, -0.06426124274730682, -0.001012645778246224, -0.05396777391433716, -0.1333140879869461, 0.024691689759492874, 0.10223142057657242, -0.04109029471874237, -0.016422614455223083, -0.18550550937652588, -0.027064058929681778, -0.09030745923519135, 0.07686389237642288, -0.15899965167045593, -0.0499114915728569, -0.1967950016260147, -0.00549057824537158, 0.0060861120000481606, 0.001972680911421776, -0.02641410566866398, 0.02854788675904274, -1.4931317323240827e-32, 0.057081207633018494, 0.058252714574337006, -0.12154951691627502, -0.02895658276975155, 0.025920018553733826, -0.018220510333776474, -0.05635419487953186, 0.10971657931804657, 0.028402632102370262, -0.18182383477687836, -0.10774338245391846, -0.1897190660238266, 0.01618722826242447, -0.036032479256391525, 0.025007225573062897, 0.08618400245904922, -0.08120037615299225, 0.20416536927223206, -0.14021839201450348, 0.057013291865587234, -0.06364476680755615, 0.16646306216716766, -0.09045236557722092, 0.08319845050573349, 0.0002474784851074219, 0.019138948991894722, 0.1074654832482338, -0.01148018054664135, 0.005802313331514597, 0.012775483541190624, -0.16539733111858368, 0.005445759743452072, -0.06561306864023209, 0.0949542447924614, -0.07746589183807373, -0.07985975593328476, 0.03021341934800148, -0.07190298289060593, -0.07415787130594254, -0.020404506474733353, 0.1260082721710205, 0.19303849339485168, -0.20881561934947968, 0.053297143429517746, -0.08871392160654068, -0.0334397628903389, -0.14489327371120453, 0.1686745285987854, -0.10329055786132812, -0.0028141855727881193, -0.048140835016965866, -0.09328853338956833, -0.12182369083166122, 0.056108783930540085, -0.03700930252671242, -0.021194785833358765, -0.025483332574367523, -0.02731640823185444, -0.2204698622226715, -0.08390094339847565, -0.17581728100776672, 0.0493333600461483, -0.0013160391245037317, -0.03416968882083893, 0.23075027763843536, -0.12970364093780518, -0.06342560052871704, 0.03980313614010811, -0.05761168524622917, -0.14075496792793274, -0.06646554172039032, -0.0669243112206459, -0.04653117433190346, -0.03209635242819786, 0.02431512624025345, 0.1133013367652893, 0.08852343261241913, -0.030795004218816757, -0.04571487009525299, 0.04292313754558563, -0.01570957712829113, -0.09486926347017288, 0.15021012723445892, 0.13199830055236816, -0.0784427598118782, 0.07022471725940704, -0.036452703177928925, 0.11380056291818619, 0.0026633788365870714, 3.569120599422604e-05, -0.026465153321623802, -0.05631274729967117, 0.22356927394866943, 0.11988042294979095, 0.03826073184609413, -1.0152244556138612e-07, -0.03272147849202156, 0.027726301923394203, -0.05638118460774422, 0.030996741726994514, 0.03179997205734253, 0.055220335721969604, -0.1444094330072403, 0.07524355500936508, -0.06163332238793373, 0.033633697777986526, -0.09961415082216263, 0.13872632384300232, -0.1515350341796875, -0.09665359556674957, -0.1649768352508545, 0.09269659966230392, -0.04215653985738754, 0.15403807163238525, -0.07836402952671051, 0.03177172690629959, 0.12711980938911438, 0.010748925618827343, -0.0395190604031086, 0.05994410440325737, -0.02036416158080101, -0.03713955730199814, -0.06651925295591354, 0.016505535691976547, 0.02137802541255951, 0.03118906542658806, -0.024601228535175323, -0.03499145433306694, -0.15010356903076172, -0.08203756809234619, 0.06485877931118011, 0.036836955696344376, 0.12906114757061005, -0.045138973742723465, 0.03778112307190895, 0.2049458771944046, -0.07370886951684952, 0.049969807267189026, -0.09562350809574127, -0.03977053984999657, -0.030457602813839912, -0.05710791051387787, 0.013040113262832165, -0.10942484438419342, 0.14194713532924652, -0.013216749764978886, -0.012600269168615341, -0.07586752623319626, -0.08011509478092194, -0.04352733492851257, 0.0324910543859005, 0.033391986042261124, 0.037265509366989136, 0.17337732017040253, -0.0231428612023592, -0.06689539551734924, 0.1524534672498703, 0.10045736283063889, 0.11500228941440582, -0.0036341818049550056], metadata={'source': 'AAAMLP-569to.pdf', 'page': 242}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 243     :return: cleaned string     \"\"\"     # split by all whitespaces     s = s.split()          # join tokens by single space     # why we do this?     # this will remove all kinds of weird space     # \"hi.   how are you\" becomes     # \"hi. how are you\"     s = \" \".join(s)          # remove all punctuations using regex and string module     s = re.sub(f\\'[{re.escape(string.punctuation)}]\\', \\'\\', s)          # you can add more cleaning here if you want     # and then return the cleaned string     return s ═════════════════════════════════════════════════════════════════════════  This function will convert a string like “hi, how are you????” to “hi how are you”. Let’s apply this function to the old SVD code and see if it brings any value to the extracted topics. With pandas, you can use the apply function to “apply” the clean-up code to any given column.  ═════════════════════════════════════════════════════════════════════════ import pandas as pd . corpus = pd.read_csv(\"../input/imdb.csv\", nrows=10000) corpus.loc[:, \"review\"] = corpus.review.apply(clean_text) . . ═════════════════════════════════════════════════════════════════════════  Note that we have added only one line of code to our main SVD script and that’s the beauty of using a function and apply from pandas. The topics generated this time look like the following.  ═════════════════════════════════════════════════════════════════════════ [\\'the\\', \\'a\\', \\'and\\', \\'of\\', \\'to\\'] [\\'i\\', \\'movie\\', \\'it\\', \\'was\\', \\'this\\'] [\\'the\\', \\'was\\', \\'i\\', \\'were\\', \\'of\\'] [\\'her\\', \\'was\\', \\'she\\', \\'i\\', \\'he\\'] [\\'br\\', \\'to\\', \\'they\\', \\'he\\', \\'show\\'] ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[-0.1759646236896515, -0.21377472579479218, 0.09022761881351471, 0.08530174940824509, 0.1268835812807083, 0.0892878845334053, 0.0525493398308754, -0.10089702159166336, 0.030841249972581863, -0.062977634370327, 0.02855778858065605, -0.028965480625629425, 0.15410828590393066, 0.06477760523557663, -0.04030493274331093, 0.05597810447216034, 0.169181227684021, 0.23863539099693298, -0.17912644147872925, -0.0789167657494545, 0.07811197638511658, 0.10047397017478943, 0.0536295510828495, -0.07557974010705948, 0.011526338756084442, 0.13010455667972565, -0.08150820434093475, -0.08383196592330933, -0.044544052332639694, 0.05397619307041168, 0.10836979001760483, 0.09454047679901123, 0.022223902866244316, 0.11971285939216614, -0.1575731635093689, 0.014383776113390923, -0.18528462946414948, 0.15266463160514832, 0.06198141723871231, -0.02056116797029972, -0.14039663970470428, -0.021715352311730385, -0.1523224413394928, 0.17072011530399323, 0.22192245721817017, 0.05492095649242401, -0.11594854295253754, -0.04392905905842781, 0.02635808289051056, 0.05519062280654907, -0.170559823513031, 0.03164134547114372, -0.07572981715202332, 0.22614553570747375, -0.020613718777894974, -0.12588606774806976, -0.04421050846576691, 0.05723342299461365, -0.00037993458681739867, -0.09074005484580994, 0.03136356547474861, -0.13801613450050354, 0.014483852311968803, -0.1078125387430191, 0.043251197785139084, -0.03355346992611885, 0.03800855949521065, 0.07257311046123505, 0.08162429928779602, 0.0655803456902504, -0.05400686711072922, 0.19568604230880737, -0.07700051367282867, 0.10600288212299347, -0.05408058688044548, 0.1588384211063385, 0.23000429570674896, -0.015835827216506004, 0.21110153198242188, -0.042440265417099, 0.01920284703373909, -0.005469242110848427, 0.16326546669006348, 0.05526217818260193, 0.09699058532714844, -0.08394946157932281, 0.06250143051147461, 0.03187412768602371, -0.018395809456706047, -0.0033841095864772797, -0.12103565037250519, -0.1750795543193817, 0.15497194230556488, -0.1317865401506424, 0.18591047823429108, -0.029132410883903503, -0.03337758034467697, 0.022259604185819626, -0.0010658185929059982, 0.1155916154384613, -0.03153776749968529, 0.08069080114364624, 0.03840968385338783, -0.23026102781295776, -0.05618468299508095, 0.1069667637348175, -0.08172878623008728, -0.014132291078567505, 0.1698589324951172, -0.13652676343917847, -0.08940392732620239, 0.1328379362821579, -0.1629790961742401, -0.025648897513747215, 0.17419739067554474, -0.011010175570845604, 0.07098563015460968, -0.0957343578338623, 0.08714798837900162, 0.18101921677589417, -0.15504007041454315, 0.1136356070637703, 0.007045871578156948, 0.023614002391695976, -0.14267486333847046, -0.058435745537281036, 0.016040807589888573, 9.597361830854968e-33, -0.05192708224058151, 0.01396240945905447, -0.07434297353029251, 0.010806078091263771, 0.01869344152510166, -0.04375183582305908, -0.023298176005482674, 0.12226540595293045, 0.03255300596356392, -0.08420486748218536, -0.12090447545051575, 0.04555096477270126, -0.026930075138807297, 0.15489783883094788, 0.1145889014005661, -0.13657671213150024, -0.04140596091747284, -0.1563812494277954, 0.07814892381429672, -0.04617639631032944, -0.0251561738550663, -0.025602905079722404, 0.059699200093746185, -0.0400468073785305, -0.08888495713472366, -0.03698085620999336, 0.20851647853851318, -0.2590593695640564, -0.0282795038074255, 0.01793622598052025, -0.2611384689807892, -0.1479557752609253, 0.12357281148433685, 0.06883994489908218, 0.0014019532827660441, -0.17558249831199646, 0.02406219206750393, -0.0390109121799469, -0.04941464215517044, -0.18920402228832245, -0.10754314064979553, 0.01608305051922798, 0.03694942593574524, -0.04723522067070007, -0.017020704224705696, -0.12825237214565277, -0.018757928162813187, -0.010099709965288639, -0.026707425713539124, 0.045989323407411575, 0.1844892054796219, -0.05038838088512421, -0.08904311060905457, -0.06252395361661911, -0.0585240013897419, 0.10273757576942444, 0.10275767743587494, -0.009489734657108784, 0.04144112020730972, 0.08068203181028366, 0.03479728102684021, 0.0890650600194931, 0.14753757417201996, 0.16061373054981232, 0.037859104573726654, 0.007204245775938034, -0.06006425619125366, 0.05102746933698654, -0.005625642836093903, -0.008595499210059643, -0.004519507754594088, 0.0302716214209795, 0.023793645203113556, -0.06341737508773804, 0.0025748126208782196, 0.0567350797355175, 0.08599891513586044, -0.18065090477466583, -0.09878339618444443, 0.14512468874454498, 0.08437550067901611, -0.10257040709257126, 0.052373822778463364, -0.198626309633255, -0.17407019436359406, -0.1472337543964386, 0.12787067890167236, -0.27774858474731445, 0.06454459577798843, -0.07981571555137634, -0.07268808037042618, -0.06047610193490982, -0.04143361747264862, 0.009542444720864296, 0.12592118978500366, -7.116240761786581e-33, -0.02369394525885582, -0.03125695884227753, -0.13471359014511108, 0.07700306922197342, -0.040645405650138855, -0.034118473529815674, 0.051473118364810944, 0.009152856655418873, -0.08142611384391785, -0.15257400274276733, -0.06772530823945999, -0.06159070134162903, 0.07233771681785583, 0.06677157431840897, 0.048229869455099106, 0.07807012647390366, -0.07597925513982773, 0.030536271631717682, -0.06951665878295898, 0.24486127495765686, 0.04716009646654129, 0.05702124908566475, -0.20778599381446838, 0.058071427047252655, -0.07443242520093918, 0.0855373740196228, 0.004954492673277855, 0.15726858377456665, -0.0803876742720604, 0.002768920734524727, -0.0298906397074461, 0.01879417523741722, -0.04522421583533287, -0.03252631425857544, -0.06745583564043045, -0.061290059238672256, 0.014377303421497345, -0.05381696671247482, -0.12962016463279724, -0.03933528810739517, 0.2660389244556427, 0.11135655641555786, -0.10804478824138641, -0.06280339509248734, -0.12718252837657928, 0.06235818192362785, -0.2511468827724457, -0.050015635788440704, 0.04776831716299057, 0.07734312117099762, 0.043850500136613846, 0.057128701359033585, -0.17526333034038544, -0.0009455550462007523, -0.043819114565849304, -0.08829168975353241, -0.06523694097995758, -0.07915163785219193, 0.03001904860138893, -0.05707003176212311, -0.051314253360033035, -0.053673893213272095, 0.11265546083450317, 0.02758081443607807, 0.16439661383628845, -0.14187943935394287, -0.06635343283414841, 0.07694598287343979, -0.08455352485179901, -0.07665170729160309, -0.003242645412683487, 0.08847847580909729, -0.004745744168758392, 0.0754881203174591, -0.01083312463015318, 0.05405773967504501, 0.03761252388358116, -0.10742560774087906, -0.058038339018821716, -0.1808643639087677, 0.09404009580612183, -0.07743269205093384, 0.0802171379327774, 0.005978479981422424, 0.06166578456759453, 0.12908509373664856, -0.035502124577760696, 0.15880554914474487, 0.14822477102279663, -0.027538521215319633, -0.018103158101439476, 0.00401401799172163, -0.042825937271118164, 0.11154939234256744, 0.019563207402825356, -9.89277495477836e-08, -0.16607412695884705, 0.031894899904727936, -0.0072266110219061375, -0.005313991568982601, 0.12032295018434525, -0.13639070093631744, -0.02656109631061554, 0.1867212951183319, -0.04800974205136299, -0.016905691474676132, 0.14694198966026306, 0.0517859160900116, -0.1733369082212448, -0.09241541475057602, -0.06631705164909363, 0.19673654437065125, 0.08302691578865051, -0.08058067411184311, 0.08632902055978775, 0.03866659849882126, 0.08431674540042877, 0.14183762669563293, -0.05611144006252289, 0.08952108770608902, 0.07052004337310791, -0.055935248732566833, -0.08946366608142853, 0.10306181013584137, 0.06697879731655121, -0.05583767220377922, 0.0061950390227139, 0.031922392547130585, -0.09054769575595856, -0.19562821090221405, 0.03403056412935257, 0.2376396507024765, 0.1506078839302063, -0.18197691440582275, -0.10943329334259033, 0.09851419180631638, 0.04901652783155441, 0.18280234932899475, -0.04208732768893242, -0.11632849276065826, 0.0998530238866806, -0.003252428025007248, 0.04081318527460098, -0.10213594883680344, 0.10836859792470932, 0.009871112182736397, -0.041758470237255096, 0.020545337349176407, -0.0758807435631752, -0.01863843947649002, 0.06797653436660767, -0.02402879297733307, -0.11547869443893433, 0.01455136202275753, 0.06036891043186188, 0.05860918015241623, -0.06641803681850433, 0.09102329611778259, 0.08114711195230484, 0.1283411830663681], metadata={'source': 'AAAMLP-569to.pdf', 'page': 243}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 244 Phew! At least this is better than what we had earlier. But you know what? You can make it even better by removing stopwords in your cleaning function. What are stopwords? These are high-frequency words that exist in every language. For example, in the English language, these words are “a”, “an”, “the”, “for”, etc. Removing stopwords is not always a wise choice and depends a lot on the business problem. A sentence like “I need a new dog” after removing stopwords will become “need new dog”, so we don’t know who needs a new dog.   We lose a lot of context information if we remove stopwords all the time. You can find stopwords for many languages in NLTK, and if it’s not there, you can find it by a quick search on your favourite search engine.  Let’s move to an approach most of us like to use these days: deep learning. But first, we must know what word embeddings are. You have seen that till now we converted the tokens into numbers. So, if there are N unique tokens in a given corpus, they can be represented by integers ranging from 0 to N-1. Now we will represent these integer tokens with vectors. This representation of words into vectors is known as word embeddings or word vectors. Google’s Word2Vec is one of the oldest approaches to convert words into vectors. We also have FastText from Facebook and GloVe (Global Vectors for Word Representation) from Stanford. These approaches are quite different from each other.   The basic idea is to build a shallow network that learns the embeddings for words by reconstruction of an input sentence. So, you can train a network to predict a missing word by using all the words around and during this process, the network will learn and update embeddings for all the words involved. This approach is also known as Continuous Bag of Words or CBoW model. You can also try to take one word and predict the context words instead. This is called skip-gram model. Word2Vec can learn embedding using these two methods.   FastText learns embeddings for character n-grams instead. Just like word n-grams, if we use characters, it is known as character n-grams, and finally, GloVe learns these embeddings by using co-occurrence matrices. So, we can say that all these different types of embeddings are in the end returning a dictionary where the key is a word in the corpus (for example English Wikipedia) and value is a vector of size N (usually 300).'),\n",
       " VectorParams(vector=[0.07828637212514877, -0.06216245889663696, 0.05439039319753647, -0.04293927177786827, 0.14009200036525726, 0.07291290909051895, -0.056585539132356644, -0.043680690228939056, 0.0694269984960556, -0.020114263519644737, -0.06420107185840607, -0.06974390894174576, 0.11700693517923355, 0.03642791509628296, -0.07852968573570251, 0.06302600353956223, 0.050056539475917816, 0.18402314186096191, -0.1653691679239273, -0.049621980637311935, 0.0955304428935051, -0.035538449883461, 0.026792587712407112, -0.09687668085098267, 0.14621873199939728, 0.0953676626086235, -0.08307452499866486, 0.030342349782586098, -0.007932762615382671, 0.05729293078184128, 0.13630688190460205, -0.021990031003952026, -0.03979196771979332, 0.1301683485507965, -0.12415262311697006, 0.07254871726036072, -0.03619024157524109, 0.1337921917438507, -0.03900609537959099, 0.056202471256256104, 0.05194913223385811, 0.02868730202317238, -0.042895007878541946, 0.1382731795310974, 0.1960974633693695, 0.025999119505286217, -0.12664146721363068, 0.03849959373474121, -0.06262851506471634, -0.027187256142497063, -0.10247743874788284, -0.03325942903757095, -0.10450375080108643, 0.12796153128147125, -0.15887333452701569, -0.12044775485992432, 0.011888374574482441, 0.03474362939596176, 0.0017138117691501975, -0.041343510150909424, 0.014177092351019382, -0.1729944348335266, 0.07489687204360962, -0.030320225283503532, 0.025863787159323692, -0.12487274408340454, 0.03124694526195526, 0.0887804701924324, -0.17837995290756226, 0.1873406320810318, -0.05798964574933052, 0.052923399955034256, -0.13128893077373505, -0.02093062549829483, -0.07747574895620346, 0.05882173776626587, 0.08958207815885544, -0.04538622498512268, 0.17875055968761444, -0.04619207978248596, 0.05351872742176056, 0.025919560343027115, 0.0403251014649868, -0.024951955303549767, 0.09132976084947586, 0.025552848353981972, 0.09325134754180908, -0.1202302798628807, -0.019630948081612587, -0.014967028982937336, -0.018405430018901825, -0.15637177228927612, 0.06305473297834396, -0.025501368567347527, 0.15719008445739746, -0.06650346517562866, -0.01775648631155491, 0.06564745306968689, 0.1421998143196106, 0.06444378942251205, 0.08541163802146912, 0.06926548480987549, 0.11573834717273712, -0.13159389793872833, -0.031041741371154785, -0.036862991750240326, -0.04278305917978287, 0.025758467614650726, 0.06498796492815018, -0.2440716028213501, -0.11899558454751968, 0.03774024918675423, -0.031404994428157806, 0.076057069003582, 0.024871913716197014, -0.02201031520962715, 0.0024376455694437027, -0.06663789600133896, 0.13193157315254211, 0.03880029916763306, -0.0761600062251091, 0.0843077078461647, 0.047346848994493484, 0.03560764342546463, -0.06645643711090088, -0.08729438483715057, 0.07259261608123779, 1.2239522687250132e-32, -0.031355369836091995, 0.07640094310045242, -0.05337737500667572, 0.19410468637943268, 0.016725411638617516, 0.015176121145486832, -0.11166533827781677, 0.08006442338228226, -0.028648393228650093, 0.08820140361785889, -0.030186284333467484, 0.01311158575117588, 0.11984289437532425, 0.19627022743225098, 0.06826075166463852, -0.025755414739251137, 0.029706168919801712, -0.09511502087116241, -0.06177950277924538, 0.025979338213801384, 0.03994135558605194, -0.016974126920104027, 0.07850991189479828, -0.0006767540471628308, -0.12939535081386566, -0.07266342639923096, 0.0976964458823204, -0.14320454001426697, -0.10784797370433807, -0.029770195484161377, -0.13898934423923492, -0.041307687759399414, -0.02188526839017868, -0.006525611504912376, -0.013196038082242012, -0.094081811606884, 0.1653273105621338, -0.05768129974603653, -0.024750765413045883, -0.07513050734996796, -0.002745341043919325, -0.03282032534480095, 0.05324892699718475, -0.032733622938394547, 0.003164607333019376, 0.07830668240785599, -0.05350261926651001, -0.011646782048046589, -0.06816107779741287, -0.02165103517472744, 0.04779021069407463, -0.008561539463698864, -0.059286464005708694, -0.042716916650533676, 0.16266383230686188, 0.03711485490202904, -0.04117542505264282, -0.057003699243068695, 0.05784733220934868, -0.005751762539148331, -0.07511214166879654, 0.05096915736794472, 0.14416374266147614, 0.0800037756562233, -0.0015004134038463235, 0.03790677711367607, -0.04097636044025421, 0.05312945321202278, 0.0698058232665062, 0.11752169579267502, -0.046153005212545395, 0.09572935104370117, -0.07805757969617844, -0.10627102106809616, 0.025133389979600906, 0.06578438729047775, 0.014794413931667805, -0.15488074719905853, -0.01976955123245716, 0.1319260597229004, -0.12623007595539093, -0.12388312816619873, 0.09489988535642624, -0.11741502583026886, -0.1367282271385193, -0.19473068416118622, 0.03651493787765503, -0.19695240259170532, 0.086468905210495, -0.056905120611190796, -0.07410769909620285, -0.04247153550386429, -0.05265520140528679, -0.026467714458703995, 0.05379638075828552, -1.1720977598955865e-32, -0.09168905764818192, 0.08381003886461258, -0.06337469071149826, -0.0029770720284432173, -0.10464319586753845, 0.021724417805671692, -0.002882057800889015, 0.023219680413603783, -0.12124283611774445, -0.08666247874498367, -0.13742968440055847, -0.03603178262710571, 0.08073487132787704, -0.03342372179031372, 0.023464873433113098, 0.12017782777547836, 0.0034072769340127707, 0.08679620176553726, -0.010516341775655746, 0.10223846137523651, 0.03443225473165512, 0.002321699634194374, -0.07927119731903076, 0.06871914118528366, 0.0704868733882904, 0.10207433998584747, 0.03615396469831467, -0.040361929684877396, -0.09738066792488098, -0.08956024795770645, -7.541413651779294e-05, -0.13025766611099243, -0.007755803409963846, 0.06614773720502853, -0.14901724457740784, 0.03138379007577896, 0.07661109417676926, -0.1283162534236908, 0.001642851741053164, -0.07380173355340958, 0.056516382843256, 0.05375421419739723, -0.10977152734994888, -0.08118202537298203, -0.07881322503089905, 0.004624856635928154, -0.18981075286865234, -0.015002170577645302, 0.0898912250995636, -0.024163834750652313, 0.02426714077591896, 0.04234521836042404, -0.12576569616794586, 0.10556282103061676, -0.04487511143088341, -0.0499340258538723, -0.08537683635950089, -0.057463228702545166, 0.08817974478006363, -0.07017896324396133, -0.039769984781742096, 0.004644521977752447, 0.08635948598384857, -0.025198830291628838, 0.08249109238386154, -0.09467598050832748, -0.03003881871700287, 0.04627814143896103, -0.03572433441877365, -0.06509663909673691, -0.011913587339222431, 0.014399085193872452, -0.06338989734649658, 0.015260378830134869, -0.022408844903111458, 0.08536409586668015, 0.11340738087892532, -0.029261132702231407, -0.1611136794090271, -0.13550880551338196, 0.05419109761714935, -0.1256117820739746, 0.07870454341173172, 0.028786325827240944, -0.03294355049729347, 0.1421968638896942, 0.08409202098846436, 0.001717427046969533, 0.09630203992128372, 0.015503722243010998, -0.017503641545772552, 0.06683556735515594, -0.10023508965969086, 0.19601207971572876, 0.10057670623064041, -9.973607006941165e-08, -0.13502655923366547, 0.0027794779743999243, 0.0049639977514743805, -0.03724740445613861, -0.054848067462444305, -0.0955425351858139, -0.003157008672133088, 0.10444224625825882, -0.15024112164974213, -0.06026814505457878, 0.009155496954917908, 0.05232815816998482, -0.10357498377561569, -0.07869302481412888, -0.008365461602807045, 0.10532953590154648, -0.0811876654624939, -0.07126931846141815, 0.08462440967559814, 0.08969676494598389, 0.01991882547736168, 0.11309574544429779, 0.017131708562374115, 0.06354226917028427, -0.023394210264086723, -0.031240323558449745, -0.06180737912654877, 0.09243706613779068, 0.11519428342580795, -0.04202352464199066, 0.03578564152121544, 0.11758571118116379, -0.06274022907018661, 0.011384478770196438, 0.014435752294957638, 0.0530979186296463, -0.00694523099809885, -0.1230553686618805, -0.0164021123200655, 0.026557939127087593, 0.05084807053208351, -0.030209781602025032, -0.038086965680122375, -0.057697929441928864, 0.23266413807868958, -0.00788747426122427, 0.01188473217189312, -0.15533512830734253, 0.004394927062094212, 0.02141053043305874, 0.01764841377735138, 0.02514304779469967, -0.03896654024720192, 0.11179878562688828, 0.06968951970338821, -0.03766367584466934, -0.06864096969366074, -0.01880570501089096, 0.0899011567234993, 0.03526027500629425, -0.024104256182909012, 0.09771454334259033, 0.004740697797387838, -0.06239762157201767], metadata={'source': 'AAAMLP-569to.pdf', 'page': 244}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 245  Figure 1: Visualizing word embeddings in two-dimensions.  Figure 1 shows a visualization of word embeddings in two-dimensions. Suppose, we have done it somehow and represented the words in two dimensions. Figure 1 shows that if you subtract the vector for Germany from the vector of Berlin (capital of Germany) and add the vector of France to it, you will get a vector close to the vector for Paris (capital of France). This shows that embeddings also work with analogies. This is not always true, but examples like these are useful for understanding the usefulness of word embeddings. A sentence like “hi, how are you ” can be represented by a bunch of vectors as follows.  hi ─>  [vector (v1) of size 300] ,  ─>   [vector (v2) of size 300] how ─>  [vector (v3) of size 300] are ─>  [vector (v4) of size 300] you ─>  [vector (v5) of size 300] ? ─>  [vector (v6) of size 300]  There are multiple ways to use this information. One of the simplest ways would be to use the embeddings as they are. As you can see in the example above, we have a 1x300 embedding vector for each word. Using this information, we can calculate the embedding for the whole sentence. There are multiple ways to do it. One such'),\n",
       " VectorParams(vector=[-0.004567095078527927, -0.1187341958284378, 0.026750804856419563, -0.02477278560400009, 0.1639494001865387, -0.021770406514406204, 0.003448750590905547, -0.052378930151462555, -0.05087394639849663, 0.028828369453549385, -0.02125377766788006, 0.01608600839972496, 0.0393359437584877, 0.05586353689432144, -0.10770772397518158, 0.210513174533844, 0.038451116532087326, 0.14374512434005737, -0.10258452594280243, -0.11715254932641983, 0.09642967581748962, 0.1626967042684555, 0.004952510353177786, 0.0016650365432724357, 0.0720469281077385, 0.10046054422855377, 0.015179281122982502, 0.03448693826794624, -0.041868146508932114, 0.007985500618815422, 0.09240952879190445, -0.0844518393278122, 0.06623683124780655, 0.20172186195850372, -0.10260447859764099, 0.039331063628196716, -0.15376128256320953, 0.015172893181443214, -0.011352776549756527, -0.008147221058607101, 0.0493730828166008, 0.034517161548137665, -0.06664911657571793, 0.07490899413824081, 0.2016751766204834, 0.16325397789478302, -0.16543669998645782, -0.04338879510760307, 0.06995400041341782, -0.00040013188845478, -0.0452992282807827, 0.05995500087738037, -0.16572323441505432, 0.1654808074235916, -0.15563422441482544, -0.1963028609752655, 0.04973791912198067, -0.1264408528804779, 0.06813722103834152, -0.1876174658536911, -0.010581881739199162, -0.16887618601322174, 0.09209206700325012, -0.09724119305610657, 0.003226486500352621, -0.07476179301738739, -0.02354568988084793, 0.15780344605445862, -0.08731716871261597, 0.15949870645999908, -0.028080133721232414, 0.12620225548744202, -0.03155193105340004, 0.03900419920682907, -0.1910182237625122, 0.05894235521554947, 0.26251494884490967, -0.07146596163511276, 0.18197333812713623, 0.06716428697109222, 0.0056573753245174885, -0.10283555090427399, 0.15640397369861603, 0.06239980831742287, 0.06355610489845276, -0.05678916722536087, 0.017988843843340874, -0.0350264236330986, 0.046235211193561554, -0.0022596220951527357, -0.18450090289115906, -0.14602623879909515, 0.13536521792411804, -0.1395217776298523, 0.11621984094381332, 0.015852471813559532, 0.005173737183213234, -0.039292871952056885, 0.0019898447208106518, 0.13974066078662872, 0.05078387260437012, -0.0004303455352783203, 0.08553988486528397, -0.18112371861934662, -0.04339317977428436, 0.11593625694513321, 0.07943831384181976, -0.03980666771531105, 0.05542711913585663, -0.17823243141174316, -0.0758066400885582, 0.027061495929956436, -0.06878580898046494, 0.10859543085098267, 0.137554332613945, -0.04098333790898323, 0.01446618977934122, 0.09153591096401215, 0.12356790155172348, 0.1182725727558136, 0.03396385908126831, 0.08099775016307831, 0.11161009222269058, 0.10752610117197037, -0.15284138917922974, -0.13900163769721985, 0.026427892968058586, 1.5463413657348167e-32, -0.21053120493888855, -0.009578951634466648, -0.09642709046602249, 0.049266234040260315, 0.04599710553884506, 0.065209299325943, -0.03513922542333603, 0.10643927752971649, -0.15251599252223969, -0.05203406512737274, -0.1286287009716034, 0.005092431791126728, 0.027725670486688614, 0.15814760327339172, 0.03497573733329773, -0.09821851551532745, 0.13168956339359283, -0.09824510663747787, 0.041337814182043076, -0.0259979497641325, 0.06575735658407211, -0.08489636331796646, 0.027912922203540802, 0.020576994866132736, -0.21693336963653564, -0.15173731744289398, 0.10376522690057755, -0.19188395142555237, -0.08268919587135315, -0.06294139474630356, -0.21415340900421143, -0.07447636127471924, 0.0745111033320427, 0.01383708044886589, 0.04824664443731308, -0.04052126780152321, 0.08829645812511444, -0.01680232770740986, -0.021614812314510345, -0.1692599654197693, -0.06580095738172531, 0.0152065958827734, 0.028304804116487503, -0.0966685339808464, -0.08408733457326889, 0.0734434500336647, -0.03141310438513756, 0.037716928869485855, 0.0034892288967967033, 0.09077479690313339, -0.042426519095897675, -0.08926823735237122, -0.04872085899114609, -0.015597635880112648, -0.012877585366368294, -0.013220004737377167, 0.0882953330874443, 0.041782647371292114, 0.05685682222247124, -0.07778934389352798, 0.006686238572001457, 0.027844050899147987, 0.12694357335567474, 0.040749963372945786, 0.07124887406826019, 0.030609166249632835, -0.024171877652406693, 0.09575707465410233, 0.0751085877418518, 0.08868095278739929, -0.036567363888025284, 0.1343189775943756, -0.08740857988595963, -0.05836334452033043, -0.01419676560908556, 0.03393206745386124, 0.1264631152153015, -0.15165460109710693, -0.129084050655365, 0.07409495860338211, 0.06174692139029503, -0.02828931249678135, 0.06086722016334534, -0.1813751757144928, -0.10236179083585739, -0.15125679969787598, 0.05660219490528107, -0.16079044342041016, 0.007808060850948095, -0.16801394522190094, -0.12469707429409027, -0.02887861244380474, -0.05298549309372902, 0.07176303118467331, -0.01132398284971714, -1.558296584093061e-32, -0.0832803025841713, 0.07904847711324692, -0.055707044899463654, 0.03236611559987068, -0.025260942056775093, 0.011316478252410889, -0.0155990831553936, 0.08743393421173096, 0.03972373902797699, -0.1253175288438797, -0.07134599983692169, -0.1379258632659912, 0.14750875532627106, -0.07830140739679337, 0.07350508123636246, 0.09595261514186859, -0.14229099452495575, 0.16195614635944366, 0.05066484585404396, 0.1736346185207367, -0.11802428960800171, 0.12603634595870972, -0.040003906935453415, 0.007737085223197937, -0.07624669373035431, 0.12328076362609863, 0.042016852647066116, 0.014970555901527405, -0.0733494982123375, -0.12496806681156158, -0.02627893164753914, 0.0871962308883667, -0.04568404331803322, 0.03988078236579895, -0.12872548401355743, 0.004777577240020037, 0.07808490842580795, -0.059008389711380005, -0.07297658920288086, -0.08371900767087936, 0.23971137404441833, 0.15613722801208496, -0.10621701925992966, -0.014606405049562454, -0.0646146684885025, 0.05619364604353905, -0.16002371907234192, -0.03277035430073738, 0.07861588150262833, 0.05294971540570259, -0.06070591136813164, 0.0003382926224730909, -0.12813137471675873, 0.08660567551851273, -0.03755395486950874, -0.05137746408581734, -0.11720825731754303, -0.03493538126349449, -0.061046626418828964, -0.20032015442848206, -0.13827231526374817, -0.05729552358388901, 0.013436534442007542, -0.06918182224035263, 0.14618884027004242, -0.07853702455759048, -0.07735520601272583, 0.10698065161705017, -0.10659918934106827, 0.026331789791584015, 0.03495947644114494, 0.08250241726636887, -0.056005705147981644, -0.013536096550524235, -0.048329271376132965, 0.08464641124010086, 0.06150028109550476, -0.18058271706104279, -0.18595163524150848, -0.03477534279227257, 0.026725705713033676, -0.07765976339578629, 0.13966168463230133, 0.02875354140996933, 0.005576922558248043, 0.07671069353818893, 0.11736711114645004, 0.12856723368167877, 0.10190499573945999, 0.11615496873855591, -0.04842277988791466, 0.014659347012639046, 0.05763096362352371, 0.1403195858001709, 0.06178667023777962, -1.004080445454747e-07, -0.10134278237819672, -0.06068636476993561, -0.08885733783245087, -0.032068539410829544, 0.014573993161320686, -0.04252747446298599, 0.054668013006448746, 0.014745298773050308, -0.10276888310909271, -0.07136304676532745, 0.006066650152206421, 0.00044650124618783593, -0.1786571443080902, -0.014649171382188797, -0.14169132709503174, 0.29106584191322327, -0.011447174474596977, -0.022302497178316116, 0.14594455063343048, -0.011808081530034542, 0.09036241471767426, 0.006340510211884975, 0.007380722556263208, 0.07542974501848221, -0.11457429081201553, -0.020187167450785637, -0.09468581527471542, -0.006005198694765568, 0.08198398351669312, -0.0834871456027031, 0.002227625111117959, -0.007270175963640213, 0.03874576836824417, -0.12519678473472595, -0.01939552277326584, 0.14142678678035736, 0.002148550236597657, -0.09000416100025177, -0.0063018533401191235, 0.12337659299373627, -0.044790804386138916, 0.1270284503698349, -0.06455216556787491, -0.007301230914890766, 0.13217580318450928, 0.02847675047814846, -0.0405445359647274, -0.18053972721099854, 0.1350792944431305, -0.06373145431280136, 0.0837356448173523, -0.04965494945645332, -0.07511401176452637, -0.031442657113075256, 0.06297512352466583, 0.005786765832453966, -0.14289413392543793, 0.05326046422123909, 0.15906837582588196, -0.04777985066175461, 0.016130926087498665, 0.03875273838639259, 0.07278890162706375, -0.0941251814365387], metadata={'source': 'AAAMLP-569to.pdf', 'page': 245}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 246 method is shown as follows. In this function, we take all the individual word vectors in a given sentence and create a normalized word vector from all word vectors of the tokens. This provides us with a sentence vector.  ═════════════════════════════════════════════════════════════════════════ import numpy as np  def sentence_to_vec(s, embedding_dict, stop_words, tokenizer):     \"\"\"     Given a sentence and other information,     this function returns embedding for the whole sentence     :param s: sentence, string     :param embedding_dict: dictionary word:vector     :param stop_words: list of stop words, if any     :param tokenizer: a tokenization function     \"\"\"     # convert sentence to string and lowercase it     words = str(s).lower()          # tokenize the sentence     words = tokenizer(words)          # remove stop word tokens     words = [w for w in words if not w in stop_words]          # keep only alpha-numeric tokens     words = [w for w in words if w.isalpha()]          # initialize empty list to store embeddings     M = []     for w in words:         # for every word, fetch the embedding from         # the dictionary and append to list of          # embeddings         if w in embedding_dict:             M.append(embedding_dict[w])          # if we dont have any vectors, return zeros     if len(M) == 0:         return np.zeros(300)      # convert list of embeddings to array     M = np.array(M)          # calculate sum over axis=0     v = M.sum(axis=0)'),\n",
       " VectorParams(vector=[-0.008171319030225277, -0.023808887228369713, 0.019363390281796455, 0.031303439289331436, 0.15971961617469788, 0.06754319369792938, 0.04201676324009895, -0.0524771511554718, -0.07618856430053711, -0.041779424995183945, 0.01166923251003027, -0.027774628251791, -0.01313032303005457, 0.0012511559762060642, -0.030695483088493347, 0.0400514081120491, 0.055182281881570816, 0.11131788790225983, -0.030342746526002884, -0.01770336553454399, 0.02813573181629181, 0.11071568727493286, 0.06310749053955078, 0.043602075427770615, 0.051135364919900894, 0.05773117020726204, -0.01937861368060112, 0.04674548655748367, -0.03745022788643837, 0.012573959305882454, 0.009899893775582314, 0.050810907036066055, 0.02659626677632332, 0.07152251154184341, -0.0448751375079155, 0.09908230602741241, -0.10581137984991074, 0.051868993788957596, -0.01944330334663391, 0.07783975452184677, 0.02143264375627041, -0.06718944013118744, -0.030093492940068245, 0.06084956228733063, 0.17622129619121552, -0.010724895633757114, -0.07493802160024643, -0.06438641995191574, 0.1335437148809433, -0.0325629897415638, -0.18521547317504883, 0.06844598054885864, -0.1314576119184494, 0.011502626352012157, -0.055069003254175186, -0.08150206506252289, 0.054024919867515564, -0.02963661216199398, 0.08247143030166626, -0.11684171855449677, 0.013838082551956177, -0.0746651366353035, 0.14504005014896393, -0.045711539685726166, 0.04301656037569046, -0.05382946506142616, -0.01587606966495514, 0.07008381932973862, -0.052407123148441315, 0.08379141986370087, -0.13041716814041138, 0.14895941317081451, -0.0628320723772049, 0.07330866158008575, -0.08027447015047073, 0.007339542265981436, 0.06086244806647301, -0.03718075528740883, 0.07802222669124603, -0.01349466759711504, -0.09268998354673386, -0.05738227814435959, 0.05808054655790329, 0.012264027260243893, 0.0063986582681536674, -0.0980803519487381, 0.0544285885989666, -0.06975031644105911, -0.02504575252532959, -0.05950795114040375, 0.08915188908576965, -0.1216994971036911, 0.12649190425872803, -0.05003969371318817, -0.004353544674813747, 0.09095092862844467, -0.03201676905155182, -0.027990926057100296, 0.010625996626913548, 0.11615444719791412, 0.06951788067817688, -0.029446613043546677, 0.01850317232310772, -0.06151705980300903, -0.05646296963095665, 0.045747265219688416, 0.14410912990570068, 0.016111576929688454, 0.08018199354410172, -0.12095386534929276, -0.013740957714617252, 0.05726417154073715, -0.12386364489793777, 0.035859689116477966, 0.056932128965854645, -0.05534952133893967, -0.02208385057747364, -0.059478625655174255, 0.05073614791035652, 0.18602009117603302, -0.13043735921382904, 0.006897991988807917, 0.0103993508964777, 0.07042843848466873, -0.047518614679574966, -0.019612083211541176, 0.009294993244111538, 1.579023341297141e-32, -0.14041884243488312, 0.026183031499385834, 0.011644812300801277, -0.04415009915828705, -0.06421201676130295, 0.0481119342148304, 0.0005392447346821427, -0.007934958674013615, 0.005062608048319817, -0.015091583132743835, -0.1344735026359558, -0.040121495723724365, -0.03994307667016983, 0.07675601541996002, -0.012727481313049793, -0.14061082899570465, -0.003947571385651827, 0.017929088324308395, 0.07569461315870285, -0.03349044546484947, 0.05890057235956192, -0.10056281089782715, 0.024390865117311478, -0.09500161558389664, -0.08398304879665375, -0.07137830555438995, 0.04799624904990196, -0.05498557165265083, -0.09472567588090897, -0.03157294541597366, -0.1957079917192459, -0.04675586149096489, 0.06490455567836761, 0.014277845621109009, -0.025513816624879837, -0.10128215700387955, 0.12990589439868927, -0.02334187552332878, -0.028183991089463234, -0.09311671555042267, -0.10826602578163147, 0.04546027630567551, 0.05840691924095154, -0.1317225694656372, -0.08767230808734894, 0.18036577105522156, -0.10795174539089203, 0.04380689188838005, -0.0381939634680748, -0.0348924957215786, -0.024563536047935486, -0.0022606796119362116, -0.09787807613611221, 0.06066226214170456, -0.04837995767593384, 0.038179341703653336, 0.013686278834939003, 0.005185343325138092, 0.09341875463724136, -0.01999594271183014, 0.0022280290722846985, 0.06553017348051071, 0.05964066460728645, 0.010159644298255444, 0.021660814061760902, 0.01722186617553234, 0.12435031682252884, 0.08772329986095428, 0.06730318814516068, -0.046994756907224655, -0.05371703952550888, 0.0040934719145298, -0.07009971141815186, -0.1071992889046669, 0.12033314257860184, -0.03733770176768303, 0.039170991629362106, -0.12775054574012756, -0.040114667266607285, 0.02062080055475235, 0.020041273906826973, 0.01101149432361126, 0.09419255703687668, -0.20403891801834106, -0.03315839171409607, -0.04018854349851608, 0.026676258072257042, -0.24278391897678375, 0.030894631519913673, -0.0958091989159584, -0.13593143224716187, 0.017033763229846954, -0.054799921810626984, -0.027298999950289726, -0.05932096764445305, -1.4871934287373163e-32, -0.015512039884924889, -0.06503307819366455, 0.03148072957992554, 0.06324765086174011, 0.04614853113889694, 0.04382133111357689, -0.06128562614321709, 0.04607701674103737, -0.04152162745594978, -0.08101345598697662, 0.010819178074598312, -0.18205496668815613, -0.004072194453328848, -0.13556011021137238, 0.09406609833240509, 0.12191975116729736, -0.022093312814831734, 0.07306235283613205, 0.015040412545204163, 0.13936828076839447, -0.05098821595311165, 0.05256694555282593, -0.05563903599977493, 0.06934697926044464, -0.07046741992235184, 0.03490762040019035, 0.061477020382881165, 0.09053873270750046, -0.07810799777507782, -0.10014528036117554, -0.03486156091094017, 0.007740707136690617, -0.12111659348011017, 0.10176054388284683, -0.06991734355688095, -0.04466573894023895, 0.03463156893849373, -0.10889483243227005, -0.05247870087623596, 0.11548887193202972, 0.2720499038696289, 0.09294610470533371, -0.12055724859237671, -0.032604195177555084, -0.11350691318511963, 0.0977255254983902, -0.107688307762146, -0.011706712655723095, 0.008451554924249649, 0.04254651442170143, 0.01523161493241787, 0.013310082256793976, -0.08641064912080765, 0.08886861801147461, -0.05928424745798111, -0.03130725026130676, -0.03932790830731392, -0.04711628705263138, -0.041616179049015045, -0.10328274965286255, -0.169901505112648, -0.030943164601922035, -0.013578965328633785, -0.0352519229054451, 0.2514876127243042, -0.07000721246004105, -0.012737913057208061, 0.0670456737279892, -0.024922151118516922, 0.02495005913078785, -0.015254748985171318, -0.04072366654872894, -0.025470390915870667, 0.06711278110742569, -0.05779969319701195, 0.09035421162843704, 0.031121818348765373, -0.09827342629432678, -0.07866650819778442, -0.021985705941915512, 0.07288296520709991, 0.02452603168785572, 0.11825448274612427, 0.11295784264802933, -0.01335468702018261, 0.10674145817756653, 0.08480799198150635, 0.0603206604719162, 0.08705750107765198, 0.031549420207738876, -0.016502339392900467, 0.016999907791614532, 0.0667305514216423, 0.10060777515172958, 0.04699205979704857, -1.0034728603613985e-07, -0.12846069037914276, -0.019679931923747063, -0.06783263385295868, 0.05704287812113762, -0.027902288362383842, -0.04359624534845352, -0.09464234113693237, 0.12286064028739929, -0.08833469450473785, -0.04311370477080345, -0.02356850355863571, -0.052175212651491165, -0.0733867734670639, -0.017364339902997017, -0.008691740222275257, 0.12977334856987, 0.006693955045193434, 0.055227093398571014, 0.03766636922955513, -0.046677205711603165, 0.13347922265529633, 0.09104161709547043, 0.0686471238732338, 0.04368400201201439, -0.0033543449826538563, 0.011059504933655262, -0.04215967655181885, 0.0631399005651474, 0.08402332663536072, -0.08142542093992233, -0.01684732548892498, -0.032971058040857315, -0.0959332063794136, -0.0007628549938090146, 0.09581602364778519, 0.07956638187170029, 0.04700903967022896, -0.09535382688045502, -0.009880012832581997, 0.14298062026500702, -0.09044865518808365, 0.09866690635681152, -0.0822494849562645, -0.06075887754559517, 0.06242618337273598, -0.020934725180268288, -0.031836893409490585, -0.13203828036785126, 0.12473580986261368, -0.05914974957704544, 0.04115051403641701, -0.023988014087080956, -0.02828754112124443, 0.03014872968196869, 0.07417909801006317, -0.019479550421237946, -0.03649609535932541, 0.07994280755519867, 0.0014105591690167785, -0.008378449827432632, 0.040158770978450775, 0.026161933317780495, 0.0896608978509903, -0.061633508652448654], metadata={'source': 'AAAMLP-569to.pdf', 'page': 246}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 247     # return normalized vector     return v / np.sqrt((v ** 2).sum()) ═════════════════════════════════════════════════════════════════════════  We can use this method to convert all our examples to one vector. Can we use fastText vectors to improve the previous results? We have 300 features for every review.  ═════════════════════════════════════════════════════════════════════════ # fasttext.py  import io import numpy as np import pandas as pd  from nltk.tokenize import word_tokenize from sklearn import linear_model from sklearn import metrics from sklearn import model_selection from sklearn.feature_extraction.text import TfidfVectorizer  def load_vectors(fname):     # taken from: https://fasttext.cc/docs/en/english-vectors.html     fin = io.open(               fname,                \\'r\\',                encoding=\\'utf-8\\',                newline=\\'\\\\n\\',                errors=\\'ignore\\'     )     n, d = map(int, fin.readline().split())     data = {}     for line in fin:         tokens = line.rstrip().split(\\' \\')         data[tokens[0]] = list(map(float, tokens[1:]))     return data   def sentence_to_vec(s, embedding_dict, stop_words, tokenizer): . . . if __name__ == \"__main__\":     # read the training data     df = pd.read_csv(\"../input/imdb.csv\")'),\n",
       " VectorParams(vector=[-0.07381734997034073, -0.13004478812217712, 0.013574064709246159, 0.04719524830579758, 0.15001113712787628, 0.01971966214478016, 0.05825889855623245, -0.07227631658315659, -0.03776733949780464, 0.02917693741619587, 0.04921441152691841, -0.06623324751853943, 0.02054094895720482, -0.1386004239320755, -0.05556456372141838, 0.17110490798950195, 0.073653444647789, -0.0007288005435839295, -0.11695663630962372, -0.11959226429462433, 0.027163615450263023, 0.19349458813667297, 0.10420670360326767, 0.020962538197636604, -0.027818972244858742, -0.06318387389183044, 0.006558080203831196, 0.13271377980709076, -0.03941934183239937, -0.0348571352660656, 0.05812375992536545, 0.020287679508328438, -0.03879876062273979, 0.16622579097747803, -0.036263950169086456, 0.061182357370853424, -0.17239327728748322, -0.02690770849585533, 0.016019057482481003, 0.11313274502754211, -0.0509037971496582, -0.018695039674639702, -0.05355379357933998, 0.05165914073586464, 0.15671180188655853, -0.005409111734479666, -0.059126585721969604, -0.07125255465507507, 0.16720491647720337, 0.04815229773521423, -0.1397583931684494, 0.056552041321992874, -0.06217659264802933, -0.0778958648443222, -0.1641671061515808, -0.14064161479473114, 0.12094102054834366, -0.08128244429826736, 0.03556795045733452, -0.09492512047290802, 0.02218838781118393, -0.1381555050611496, 0.08035613596439362, -0.09908454120159149, -0.043013300746679306, -0.14485667645931244, -0.11195012927055359, 0.10533860325813293, -0.094560407102108, 0.11094415187835693, -0.0013619946548715234, 0.11655854433774948, -0.0028875325806438923, 0.029993852600455284, -0.1378607451915741, 0.05601523444056511, 0.0920623242855072, -0.12670142948627472, 0.16198624670505524, -0.04016106575727463, -0.18313853442668915, -0.07850602269172668, 0.1648365557193756, 0.09408194571733475, 0.01876414753496647, -0.2784358859062195, 0.24872179329395294, -0.06368990242481232, -0.023333746939897537, -0.0234131570905447, 0.042271196842193604, -0.09773184359073639, 0.06463102251291275, -0.05592580512166023, 0.053064510226249695, 0.0927000343799591, -0.006586622912436724, -0.05545026808977127, 0.01851707324385643, 0.15731403231620789, 0.055473893880844116, 0.07787661254405975, 0.030534539371728897, -0.02631279267370701, -0.15472500026226044, -0.07471302896738052, 0.02725759707391262, 0.06179206445813179, 0.01924956776201725, -0.17094923555850983, -0.1131109669804573, 0.12441125512123108, -0.03236878663301468, 0.11960231512784958, 0.13124382495880127, -0.0640774816274643, -0.011578414589166641, 0.042839329689741135, -0.007929394021630287, 0.19212689995765686, -0.03882860019803047, 0.1624416708946228, -0.020934857428073883, 0.04206647351384163, -0.08565075695514679, -0.0022910921834409237, 0.041157834231853485, 1.6635812049923976e-32, -0.029750656336545944, 0.024251248687505722, 0.043282400816679, -0.0019619108643382788, -0.004839909262955189, 0.014235882088541985, 0.012797278352081776, 0.014014439657330513, -0.12599699199199677, -0.046116359531879425, -0.16636964678764343, -0.012611930258572102, 0.07714313268661499, 0.06975250691175461, -0.06740929931402206, -0.14158764481544495, -0.05191724747419357, -0.01599804125726223, 0.050172679126262665, 0.05183154344558716, 0.1861397624015808, -0.027489539235830307, 0.04813786968588829, -0.18208104372024536, -0.1540755331516266, -0.11672394722700119, 0.004324490204453468, -0.015845615416765213, -0.22168467938899994, 0.03129188343882561, -0.32332342863082886, 0.047432687133550644, 0.06978783756494522, -0.02253560535609722, 0.02568289451301098, -0.07926653325557709, 0.08738451451063156, 0.12626485526561737, -0.10577890276908875, -0.21662965416908264, 0.008708269335329533, 0.08195620030164719, 0.06763478368520737, -0.12786659598350525, -0.09872306138277054, 0.06493137031793594, 0.02908027358353138, 0.07841025292873383, -0.0021803223062306643, 0.08256996423006058, 0.07425537705421448, -0.08675336092710495, 0.008905886672437191, 0.06601766496896744, -0.03522497043013573, 0.03148404136300087, 0.10580645501613617, -0.0517682209610939, 0.14477376639842987, -0.07575114816427231, -0.04707818478345871, 0.04270161688327789, 0.10514245182275772, -0.06611030548810959, 0.08867234736680984, 0.09556809067726135, 0.06115090474486351, 0.0052082897163927555, 0.12766042351722717, -0.016467269510030746, -0.008983263745903969, 0.06125115603208542, -0.022587744519114494, -0.13546407222747803, -0.030722757801413536, -0.08071144670248032, -0.055769793689250946, -0.050682857632637024, -0.07268054783344269, 0.011391046456992626, 0.041412774473428726, -0.11832693964242935, -0.06089426204562187, -0.23936250805854797, -0.09467655420303345, -0.1625409573316574, 0.07458867877721786, -0.17650090157985687, -0.09005515277385712, -0.0982237309217453, -0.16619756817817688, 0.0013540349900722504, 0.06877955049276352, -0.059609826654195786, 0.09772305935621262, -1.7720747785326853e-32, -0.11742238700389862, -0.012733258306980133, -0.009689727798104286, 0.03902843967080116, 0.042742036283016205, 0.03531859070062637, -0.002831903286278248, 0.11156366765499115, 0.017851632088422775, -0.07382962852716446, -0.04689021781086922, -0.17467550933361053, 0.12699495255947113, -0.031222475692629814, 0.03489995002746582, 0.08062087744474411, -0.03690757229924202, 0.199925035238266, -0.041979435831308365, 0.11427919566631317, -0.10508226603269577, 0.18609705567359924, -0.11541363596916199, 0.08525670319795609, 0.04745344817638397, 0.07929641753435135, 0.1260603666305542, 0.1146705374121666, -0.03427340090274811, -0.15139833092689514, -0.05375930666923523, 0.04517170414328575, -0.17502368986606598, 0.14146412909030914, -0.031331147998571396, -0.08004476130008698, 0.08210436999797821, -0.17458873987197876, -0.08943592756986618, 0.07466389238834381, 0.18276703357696533, 0.14438897371292114, -0.10470593720674515, 0.02099224552512169, -0.025822674855589867, 0.021633917465806007, -0.13375119864940643, 0.03597794845700264, 0.015007742680609226, -0.04558752104640007, -0.09272019565105438, 0.024285871535539627, -0.11410437524318695, 0.11498115956783295, -0.07987067848443985, -0.04647749662399292, -0.15340718626976013, -0.024531809613108635, -0.1150188222527504, 0.08857744932174683, -0.15358616411685944, 0.06953701376914978, -0.0012595177395269275, -0.139667347073555, 0.15355339646339417, -0.15222439169883728, -0.03362797573208809, 0.058268364518880844, 0.06776654720306396, 0.012535171583294868, -0.07092905789613724, 0.13719819486141205, 0.04274448752403259, -0.027093224227428436, 0.0649171844124794, 0.0504501610994339, -0.01410439983010292, -0.025800829753279686, -0.07597891241312027, -0.005778159946203232, 0.08590321987867355, -0.08616843074560165, 0.04904155433177948, 0.04944143071770668, 0.021365338936448097, 0.006085261236876249, 0.07264025509357452, 0.11759209632873535, 0.0323428139090538, -0.07038293033838272, 0.04675538092851639, -0.10555829852819443, 0.05489294230937958, 0.21547146141529083, 0.09719211608171463, -1.0036324482598502e-07, -0.07441169768571854, -0.004773289430886507, 0.01546707283705473, 0.22276179492473602, 0.0070633664727211, 0.033309146761894226, 0.05376335233449936, 0.06585277616977692, -0.06625400483608246, -0.05614102631807327, 0.156470388174057, 0.10045354813337326, -0.16606831550598145, -0.0101231150329113, -0.08489780873060226, 0.08167508244514465, -0.09872077405452728, 0.03943093866109848, 0.09832466393709183, 0.028706327080726624, 0.1184493750333786, -0.044384703040122986, 0.038522060960531235, -0.019032686948776245, 0.006577232852578163, -0.11636067181825638, 0.03146159648895264, -0.0067553105764091015, 0.010023151524364948, 0.029905663803219795, 0.013163113966584206, -0.06664059311151505, -0.09325312823057175, -0.010040093213319778, 0.06104772165417671, 0.08454805612564087, 0.08426059782505035, -0.11636678874492645, 0.02869531512260437, 0.030819471925497055, -0.06321963667869568, 0.12000579386949539, -0.1692299097776413, -0.12862348556518555, 0.04806802421808243, 0.031356677412986755, -0.008473207242786884, -0.04132365807890892, 0.1490037888288498, 0.001259591314010322, -0.015531004406511784, -0.06012844294309616, -0.06772664934396744, 0.038148991763591766, 0.15773189067840576, 0.03178916499018669, -0.12001805752515793, 0.05823678895831108, -0.06788764148950577, 0.053328365087509155, 0.049030058085918427, 0.04851922020316124, 0.001521462225355208, -0.07120734453201294], metadata={'source': 'AAAMLP-569to.pdf', 'page': 247}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 248     # map positive to 1 and negative to 0     df.sentiment = df.sentiment.apply(         lambda x: 1 if x == \"positive\" else 0     )      # the next step is to randomize the rows of the data     df = df.sample(frac=1).reset_index(drop=True)      # load embeddings into memory     print(\"Loading embeddings\")     embeddings = load_vectors(\"../input/crawl-300d-2M.vec\")      # create sentence embeddings     print(\"Creating sentence vectors\")     vectors = []     for review in df.review.values:         vectors.append(             sentence_to_vec(                 s = review,                 embedding_dict = embeddings,                 stop_words = [],                  tokenizer = word_tokenize             )         )          vectors = np.array(vectors)      # fetch labels     y = df.sentiment.values          # initiate the kfold class from model_selection module     kf = model_selection.StratifiedKFold(n_splits=5)          # fill the new kfold column     for fold_, (t_, v_) in enumerate(kf.split(X=vectors, y=y)):         print(f\"Training fold: {fold_}\")         # temporary dataframes for train and test         xtrain = vectors[t_, :]         ytrain = y[t_]          xtest = vectors[v_, :]         ytest = y[v_]          # initialize logistic regression model         model = linear_model.LogisticRegression()          # fit the model on training data reviews and sentiment'),\n",
       " VectorParams(vector=[-0.0997382327914238, -0.0745488852262497, 0.0258194450289011, 0.09774116426706314, 0.11369921267032623, 0.008356052450835705, 0.03987940028309822, 0.051350969821214676, 0.039141230285167694, -0.09295712411403656, 0.03848564997315407, -0.023873070254921913, 0.004932790528982878, 0.006537078879773617, -0.02089068479835987, 0.07414781302213669, 0.07050435245037079, -0.06404797732830048, -0.10387009382247925, -0.04278712719678879, 0.08052118122577667, 0.10721869766712189, 0.17677944898605347, 0.047872357070446014, 0.003169524483382702, 0.05495124310255051, -0.09160033613443375, 0.07579521834850311, 0.016081560403108597, 0.005986601114273071, 0.03479049727320671, 0.03830293193459511, -0.027986429631710052, 0.07772687822580338, -0.06925810128450394, 0.11231231689453125, -0.03232572227716446, 0.039594970643520355, 0.019449273124337196, 0.04210621118545532, 0.05511237680912018, -0.07893446832895279, 0.09014032781124115, 0.16173328459262848, 0.12128804624080658, 0.03182276710867882, -0.10473792999982834, -0.01166435144841671, -0.041912052780389786, 0.04053286090493202, -0.152995303273201, 0.04239542409777641, -0.004397848155349493, -0.04089843109250069, -0.08917582780122757, -0.02261274680495262, -0.0690729171037674, 0.062444500625133514, 0.0722198337316513, -0.0740639790892601, -0.0022234513889998198, -0.06870276480913162, 0.03416812792420387, -0.06706806272268295, 0.008682405576109886, 0.008484813384711742, -0.006083232816308737, 0.041183952242136, -0.05932840704917908, 0.10759908705949783, 0.02132672816514969, 0.14304591715335846, -0.039459556341171265, 0.10348501056432724, -0.044326771050691605, -0.021272854879498482, 0.05626579001545906, -0.10417409241199493, 0.056310612708330154, -0.05340179428458214, -0.034382835030555725, -0.09482116997241974, 0.09472943842411041, 0.10694774985313416, 0.025896526873111725, -0.11876534670591354, 0.16263914108276367, 0.006923116277903318, -0.09967589378356934, -0.040373533964157104, 0.1117565780878067, -0.21147817373275757, 0.05800240486860275, 0.0663699060678482, 0.005943194031715393, 0.20637382566928864, 0.004671216011047363, 0.04472357779741287, -0.10042501986026764, 0.07131705433130264, 0.05154229700565338, 0.10980410873889923, 0.021115347743034363, 0.04335277900099754, -0.018383143469691277, -0.0230152178555727, 0.09835273772478104, -0.053664132952690125, 0.07098732888698578, -0.05666584521532059, 0.011904709041118622, 0.04067844897508621, -0.15012629330158234, 0.067014679312706, 0.0504135899245739, 0.02010013721883297, -0.10634519159793854, 0.036064740270376205, -0.10416669398546219, 0.2559950053691864, -0.14439335465431213, 0.16263297200202942, -0.001235141884535551, 0.04221130162477493, -0.03322676941752434, -0.033431537449359894, 0.041884806007146835, 1.5468609342378802e-32, -0.13237066566944122, 0.045913659036159515, -0.0018192979041486979, -0.06265782564878464, -0.0073714726604521275, -0.07134796679019928, -0.131556898355484, 0.05352254956960678, -0.06740062683820724, 0.05017287656664848, -0.15082857012748718, -0.01283660065382719, 0.02018802799284458, 0.0818936824798584, 0.06662756949663162, -0.0450916551053524, -0.10732287913560867, -0.0029516059439629316, 0.023405373096466064, 0.06255576014518738, 0.0756160169839859, -0.0781608298420906, 0.06306808441877365, -0.1630958467721939, -0.14372211694717407, 0.06709468364715576, 0.05827146768569946, -0.03307599574327469, -0.11656685918569565, 0.027046531438827515, -0.3277260661125183, 0.0032507400028407574, 0.07732755690813065, -0.013963188044726849, 0.027899060398340225, -0.07183345407247543, 0.10239950567483902, -0.02025136724114418, -0.05700382590293884, -0.03796255216002464, -0.09372087568044662, 0.02244788408279419, 0.04854782298207283, -0.1260770857334137, -0.04368501156568527, 0.02539878524839878, -0.02362423576414585, 0.04703632742166519, -0.08674944937229156, 0.12325172871351242, -0.003804176114499569, -0.00016709972987882793, -0.04889500141143799, -0.013867374509572983, -0.07415610551834106, 0.009434725157916546, 0.0848875492811203, -0.01650821603834629, 0.06285577267408371, -0.016647329553961754, 0.08845203369855881, -0.014641732908785343, 0.11695421487092972, -0.02178601734340191, -0.026384083554148674, 0.012028775177896023, 0.04785876348614693, -0.022442536428570747, 0.09820444136857986, 0.046255916357040405, -0.05662747472524643, 0.06441978365182877, -0.10509901493787766, -0.06109035387635231, 0.08686280995607376, -0.0012098500737920403, 0.08301680535078049, -0.06635699421167374, -0.023128315806388855, 0.10578647255897522, 0.13017147779464722, -0.06915320456027985, 0.09527413547039032, -0.21350204944610596, -0.15088841319084167, -0.14318981766700745, 0.07278500497341156, -0.12231938540935516, -0.004770329222083092, 0.019045528024435043, -0.13139845430850983, -0.012468665838241577, 0.03673382103443146, -0.06585074216127396, -0.03379539027810097, -1.3583010609168278e-32, -0.01623711548745632, 0.035552386194467545, -0.06356123089790344, 0.05447257682681084, 0.061619289219379425, 0.04188805818557739, 0.03277735039591789, 0.1941681206226349, -0.07430892437696457, -0.04257580265402794, 0.04477924853563309, -0.13937810063362122, -0.014751464128494263, -0.0786399096250534, 0.04652014002203941, 0.07534095644950867, -0.0016013316344469786, 0.0994710847735405, 0.006632547825574875, -0.051197078078985214, 0.048934608697891235, 0.12332408875226974, -0.16853931546211243, 0.10775542259216309, -0.002652466297149658, 0.08235105127096176, 0.04444020241498947, 0.04397016391158104, -0.05406263843178749, -0.07786388695240021, -0.04017357528209686, -0.03229580447077751, -0.012279974296689034, 0.039330240339040756, -0.04774903506040573, -0.014623499475419521, 0.060469917953014374, -0.1512281894683838, 0.03664231672883034, 0.0062364209443330765, 0.27376046776771545, 0.15664613246917725, -0.257885605096817, -0.0019354106625542045, -0.10384204238653183, 0.03903186321258545, -0.1888304203748703, -0.005602976772934198, 0.05997149273753166, -0.003951328806579113, 0.057417407631874084, 0.04822976514697075, -0.10564623028039932, 0.021650824695825577, -0.10906028747558594, -0.01574002578854561, -0.13291040062904358, -0.06614120304584503, -0.08043424785137177, 0.07468167692422867, -0.12642055749893188, 0.03729519620537758, 0.05167854204773903, -0.07088332623243332, 0.19612060487270355, -0.12641383707523346, -0.013062558136880398, 0.01846068911254406, 0.04639815166592598, -0.0025588953867554665, 0.002817214000970125, -0.04952933266758919, -0.04230807349085808, 0.057436566799879074, 0.02497076615691185, 0.08395906537771225, 0.008382478728890419, -0.024115459993481636, -0.11049969494342804, -0.043517809361219406, 0.04422220215201378, -0.003096785396337509, 0.07843907922506332, 0.16607840359210968, -0.030609190464019775, 0.08954618871212006, 0.03268890082836151, 0.11300334334373474, 0.07176071405410767, 0.0065128980204463005, 0.02400227077305317, 0.044570885598659515, 0.0009229158167727292, 0.22208067774772644, 0.01985090970993042, -9.99331746243115e-08, -0.11009334027767181, -0.041787952184677124, -0.07441546767950058, 0.1987706571817398, -0.10636812448501587, -0.008058954030275345, -0.06990996748209, 0.029817434027791023, -0.11821179836988449, -0.08796896040439606, 0.11127450317144394, -0.0981728732585907, -0.25662198662757874, -0.03270621970295906, 0.0037930053658783436, 0.01825469359755516, -0.04845969006419182, 0.07354206591844559, -0.014242931269109249, -0.06977085024118423, 0.1377270221710205, 0.059832438826560974, 0.06915774196386337, -0.03647926077246666, -0.07752367109060287, 0.0357670858502388, -0.10355792194604874, 0.19453856348991394, -0.028513435274362564, -0.013773785904049873, 0.03226394206285477, -0.0360834002494812, -0.10970734059810638, -0.08673522621393204, -0.15631085634231567, 0.07538186013698578, 0.09507838636636734, -0.14585602283477783, 0.06467080116271973, 0.12064821273088455, -0.01161240879446268, 0.06800834834575653, -0.14222849905490875, -0.05422361195087433, 0.07141730934381485, -0.07163447141647339, 0.029434828087687492, -0.15063607692718506, 0.06404326111078262, -0.01889217458665371, 0.021049337461590767, -0.017579063773155212, -0.06809967011213303, 0.02157885767519474, 0.1354716271162033, -0.015268919989466667, -0.09089287370443344, -0.004401703365147114, -0.13488371670246124, -0.01800019107758999, 0.019480418413877487, -0.05056561902165413, 0.030393630266189575, 0.008510446175932884], metadata={'source': 'AAAMLP-569to.pdf', 'page': 248}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 249         model.fit(xtrain, ytrain)          # make predictions on test data         # threshold for predictions is 0.5         preds = model.predict(xtest)          # calculate accuracy         accuracy = metrics.accuracy_score(ytest, preds)         print(f\"Accuracy = {accuracy}\")         print(\"\") ═════════════════════════════════════════════════════════════════════════  This gives the following results.  ═════════════════════════════════════════════════════════════════════════ ❯ python fasttext.py Loading embeddings Creating sentence vectors Training fold: 0 Accuracy = 0.8619  Training fold: 1 Accuracy = 0.8661  Training fold: 2 Accuracy = 0.8544  Training fold: 3 Accuracy = 0.8624  Training fold: 4 Accuracy = 0.8595 ═════════════════════════════════════════════════════════════════════════  Wow! That’s quite unexpected. We get excellent results, and all we did was to use the FastText embeddings. Try changing the embeddings to GloVe and see what happens. I’m leaving it as an exercise for you.  When we talk about text data, we must keep one thing in our mind. Text data is very similar to the time series data. Any sample in our reviews is a sequence of tokens at different timestamps which are in increasing order, and each token can be represented as a vector/embedding, as shown in figure 2.'),\n",
       " VectorParams(vector=[-0.2038353532552719, -0.17105485498905182, 0.06932886689901352, 0.025394782423973083, 0.1341247856616974, -0.022635558620095253, -0.0016899011097848415, 0.016699906438589096, -0.04058567434549332, -0.0791180208325386, 0.006944738328456879, -0.1529371440410614, -0.005819082260131836, -0.020805800333619118, -0.020523270592093468, 0.2163148671388626, -0.047165703028440475, 0.028246769681572914, -0.05393579974770546, -0.07401396334171295, 0.0404353030025959, 0.00654592365026474, -0.09484835714101791, 0.10852649062871933, -0.02407783269882202, 0.002841432113200426, 0.07513200491666794, 0.09058652073144913, -0.005978137720376253, -0.037865180522203445, 0.12641477584838867, 0.060181956738233566, -0.09164279699325562, 0.09193497896194458, 0.014788500033318996, 0.11498158425092697, -0.16486398875713348, 0.04267231747508049, -0.013114764355123043, 0.0738266110420227, 0.014135121367871761, -0.06506761908531189, -0.019699007272720337, -0.030473314225673676, 0.12173869460821152, 0.04606327414512634, 0.04168810695409775, -0.06255927681922913, 0.10579381138086319, 0.08331936597824097, -0.07076084613800049, 0.0870739296078682, -0.10648064315319061, 0.041338127106428146, -0.11593935638666153, -0.1354742795228958, 0.012222686782479286, -0.03052421659231186, 0.0070757679641246796, -0.051723867654800415, -0.02531430311501026, -0.10129527002573013, 0.001292529283091426, -0.10273689776659012, -0.01567162200808525, -0.04612243175506592, -0.0958135649561882, 0.13914863765239716, -0.048006635159254074, 0.11727265268564224, -0.041856229305267334, 0.13254718482494354, -0.03388227894902229, 0.016643770039081573, -0.06655889004468918, -0.007096028421074152, 0.24089470505714417, -0.10970628261566162, 0.07196478545665741, -0.08199206739664078, -0.07235842943191528, 0.07838351279497147, 0.046635907143354416, 0.05523785948753357, 0.07726380228996277, -0.11441890150308609, 0.026418589055538177, 0.07105810940265656, -0.0816037580370903, -0.08390692621469498, 0.0972827821969986, -0.12024213373661041, 0.17181353271007538, -0.04283389821648598, 0.0825970470905304, 0.14963765442371368, -0.03965364396572113, -0.035306211560964584, 0.06204298511147499, 0.17469079792499542, -0.05364172160625458, 0.09036654233932495, 0.0032779935281723738, -0.04034142196178436, 0.08831560611724854, -0.03626502677798271, 0.07598181813955307, 0.008084815926849842, 0.12382813543081284, -0.13684667646884918, 0.021946894004940987, 0.007605972234159708, -0.02035941742360592, 0.017907410860061646, 0.1083812490105629, -0.03911370038986206, -0.04936526343226433, -0.012067755684256554, 0.018204879015684128, 0.1678442806005478, -0.06583169847726822, 0.04033416509628296, 0.01755843497812748, 0.05569376423954964, -0.026241907849907875, -0.02592424489557743, -0.030490966513752937, 1.355850449068951e-32, -0.11292441189289093, 0.05362590029835701, 0.07066666334867477, -0.05872627720236778, -0.03906787931919098, -0.033632513135671616, -0.08875274658203125, -0.0002629485388752073, -0.12833820283412933, 0.020601341500878334, -0.11022790521383286, 0.04974287003278732, -0.027998454868793488, 0.0019385861232876778, -0.021426448598504066, -0.13453388214111328, -0.05302411690354347, -0.058995503932237625, 0.03361079841852188, -0.04907989874482155, 0.010606500320136547, -0.0672975406050682, 0.0866648256778717, -0.027656981721520424, -0.10645675659179688, -0.16416887938976288, 0.06352923065423965, -0.06463118642568588, -0.07235481590032578, 0.0033568318467587233, -0.21467585861682892, 0.0020338178146630526, 0.04045439511537552, -0.047165337949991226, 0.11482509970664978, 0.0015760438982397318, -0.003763994202017784, 0.05512725189328194, 0.005729385651648045, -0.014927074313163757, -0.040594540536403656, 0.06695616990327835, 0.028854111209511757, -0.015811260789632797, -0.06615540385246277, -0.01581570878624916, 0.03894180804491043, 0.005126131232827902, -0.022034961730241776, 0.0475301593542099, 0.02731860615313053, -0.09464243054389954, -0.08703839033842087, -0.059320878237485886, -0.10420168191194534, 0.03761647269129753, 0.028748948127031326, -0.014849897474050522, 0.1353129744529724, -0.1039225310087204, 0.012164036743342876, 0.043078094720840454, -0.0005338107002899051, -0.030923711135983467, -0.0331139974296093, 0.03822636231780052, 0.09365878254175186, 0.07789549231529236, 0.020783407613635063, -0.0790916308760643, -0.07134192436933517, 0.06886918842792511, -0.06550095975399017, -0.11134934425354004, 0.0721299797296524, -0.07134783267974854, 0.0677700862288475, 0.03346716985106468, -0.10675179958343506, 0.04700527712702751, 0.08964104950428009, -0.045850738883018494, 0.0576331689953804, -0.17934279143810272, 0.02140311896800995, -0.07060342282056808, 0.09477551281452179, -0.1729355752468109, -0.1989220827817917, -0.0747470110654831, -0.20653186738491058, 0.055773019790649414, 0.042488548904657364, 0.02400999329984188, -0.017692409455776215, -1.4515475911061874e-32, 0.028083613142371178, 0.02112387679517269, 0.05783669650554657, -0.006266541313380003, -0.001701817731373012, 0.000683373014908284, -0.11780768632888794, 0.16848699748516083, -0.08414827287197113, 0.047093991190195084, -0.035708483308553696, -0.14451007544994354, 0.09435935318470001, -0.06242040917277336, -0.031175555661320686, -0.008833091706037521, -0.03476449474692345, 0.14532943069934845, -0.007360705174505711, 0.02271152473986149, -0.11447383463382721, 0.14878058433532715, -0.2009756714105606, 0.04942408576607704, -0.11669281870126724, 0.08024430274963379, 0.05694354698061943, 0.07020757347345352, 0.01744925230741501, -0.04771607741713524, -0.18576356768608093, -0.023487774655222893, -0.03804832696914673, 0.10811328142881393, -0.06424707174301147, 0.012628022581338882, 0.00819858442991972, -0.13292908668518066, 0.00697781378403306, 0.10509556531906128, 0.15934047102928162, 0.18473532795906067, -0.11840381473302841, -0.0623873770236969, -0.1222924068570137, 0.044395189732313156, -0.18137198686599731, 0.11900828033685684, -0.06376981735229492, -0.01384666282683611, -0.0032894841860979795, 0.04202290251851082, -0.07246582210063934, 0.02836683951318264, -0.021775254979729652, 0.010800343006849289, -0.05332746356725693, -0.01969921588897705, -0.10447777807712555, 0.058662299066782, -0.1545296609401703, -0.07872292399406433, 0.024039849638938904, -0.0617963932454586, 0.08439566195011139, 0.00024621401098556817, -0.0432794950902462, -0.038821425288915634, 0.0496402345597744, -0.03218647092580795, 0.0621926449239254, 0.13864374160766602, -0.03869768977165222, -0.10464172065258026, -0.006410935427993536, 0.02381114847958088, -0.00039669638499617577, -0.04375256970524788, -0.06429922580718994, -0.04639662429690361, -0.056977611035108566, -0.11426402628421783, 0.07642821222543716, 0.16052472591400146, -0.05331339314579964, 0.13460655510425568, 0.08329396694898605, 0.10154736042022705, 0.03825398162007332, -0.08745964616537094, 0.03131789714097977, -0.01855669915676117, 0.15628747642040253, 0.13562582433223724, 0.0880560427904129, -9.982797166685486e-08, -0.04312366992235184, 0.0097186379134655, 0.1026163399219513, 0.12621422111988068, 0.000590613461099565, -0.004593511112034321, 0.01940181478857994, -0.07562638074159622, -0.00039738885243423283, 0.07668603956699371, 0.15178465843200684, -0.007034194190055132, -0.21248666942119598, 0.03970383107662201, -0.08237349987030029, 0.09918948262929916, 0.029322171583771706, 0.11232834309339523, 0.026981662958860397, 0.11517401039600372, 0.17107293009757996, 0.013377533294260502, 0.0736619383096695, 0.058113642036914825, 0.09442847967147827, -0.11079913377761841, -0.11768580973148346, 0.0716245174407959, -0.05040682107210159, 0.03764883428812027, 0.020145822316408157, -0.03953253850340843, -0.14796441793441772, 0.0072725568898022175, 0.03412115201354027, 0.0300415251404047, -0.008908010087907314, -0.013585073873400688, 0.010500410571694374, 0.0907110646367073, -0.0614786297082901, 0.24594280123710632, -0.22578836977481842, -0.04183092340826988, 0.04855946823954582, -0.02225799858570099, 0.06633497774600983, -0.15444758534431458, 0.037316132336854935, 0.02723444625735283, 0.06040637195110321, -0.04806629940867424, 0.08725423365831375, 0.1037190780043602, 0.08740533888339996, 0.06419243663549423, -0.07423276454210281, 0.07269863784313202, 0.009388299658894539, -0.01626528427004814, 0.007125627249479294, -0.04029937461018562, -0.0444442480802536, -0.00019434030400589108], metadata={'source': 'AAAMLP-569to.pdf', 'page': 249}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 250  Figure 2: Representing tokens as embeddings and treating it as a time series  This means that we can use models that are widely used for time series data such as Long Short Term Memory (LSTM) or Gated Recurrent Units (GRU) or even Convolutional Neural Networks (CNNs). Let’s see how to train a simple bi-directional LSTM model on this dataset.   First of all, we will create a project. Feel free to name it whatever you want. And then our first step will be splitting the data for cross-validation.  ═════════════════════════════════════════════════════════════════════════ # create_folds.py # import pandas and model_selection module of scikit-learn import pandas as pd from sklearn import model_selection  if __name__ == \"__main__\":     # Read training data     df = pd.read_csv(\"../input/imdb.csv\")      # map positive to 1 and negative to 0     df.sentiment = df.sentiment.apply(         lambda x: 1 if x == \"positive\" else 0     )      # we create a new column called kfold and fill it with -1     df[\"kfold\"] = -1'),\n",
       " VectorParams(vector=[-0.08788497000932693, -0.1329365074634552, -0.015110766515135765, 0.0830325186252594, 0.17041952908039093, 0.011163153685629368, 0.12266578525304794, -0.02348751574754715, -0.06326194107532501, -0.041357845067977905, 0.03345523029565811, -0.0739893838763237, -0.04494206979870796, -0.10062739998102188, -0.05796094238758087, 0.14974632859230042, -0.010383269749581814, 0.012540589086711407, -0.18038351833820343, -0.08998370170593262, 0.06512174755334854, 0.07317236065864563, 0.12009861320257187, 0.08102183789014816, -0.0666605606675148, -0.06657499819993973, 0.0955309197306633, 0.12614990770816803, -0.09135638922452927, -0.07110447436571121, 0.03846188634634018, 0.07273398339748383, -0.012581503950059414, 0.08265261352062225, 0.0087614506483078, 0.02125205472111702, -0.1552557647228241, 0.045691587030887604, -0.018405454233288765, 0.1365492045879364, 0.00958428904414177, 0.0254577174782753, -0.0972227156162262, 0.005037331487983465, 0.04839770495891571, 0.03778702765703201, 0.01640092022716999, -0.09990744292736053, 0.14955180883407593, 0.04022960737347603, -0.09557167440652847, 0.07937487214803696, -0.1636144369840622, -0.02138541266322136, -0.08349061012268066, -0.1335960030555725, 0.0495133176445961, -0.11578765511512756, 0.003609271487221122, -0.08545181155204773, 0.056797269731760025, -0.1423448771238327, 0.025733890011906624, -0.0923849567770958, -0.016876162961125374, -0.11192774027585983, -0.06533768773078918, 0.06358794867992401, -0.011323989368975163, -0.023222550749778748, -0.022432977333664894, 0.14112581312656403, -0.009817053563892841, 0.12267020344734192, -0.029765311628580093, -0.027512582018971443, 0.15374943614006042, -0.1258421540260315, 0.0993405431509018, -0.07242307811975479, -0.1770811378955841, -0.041359998285770416, 0.09080363065004349, 0.02977578528225422, 0.07550079375505447, -0.22320689260959625, 0.10565989464521408, 0.045675069093704224, 0.028059091418981552, -0.0417146310210228, 0.037431199103593826, -0.027434173971414566, 0.018237577751278877, 0.01435103639960289, 0.043230511248111725, 0.13156691193580627, 0.1103324219584465, -0.059329282492399216, 0.03077474795281887, 0.12238925695419312, -0.025865735486149788, -0.037124522030353546, -0.039874181151390076, 0.04230990260839462, -0.04412075877189636, -0.08644724637269974, 0.06084846705198288, -0.0009431419894099236, 0.01885857619345188, -0.17483794689178467, -0.007698359899222851, 0.03552108630537987, -0.0980035588145256, 0.061742477118968964, 0.13426947593688965, 0.04261603206396103, -0.05753890424966812, 0.07181254774332047, -0.056221652776002884, 0.13809071481227875, -0.04522862285375595, 0.11757107079029083, 0.024139033630490303, 0.1014787033200264, -0.07871691882610321, -0.051440220326185226, -0.027647530660033226, 1.3434413429544956e-32, -0.04590238258242607, 0.017542604357004166, 0.03076501190662384, -0.048644475638866425, -0.047520603984594345, -0.05522232502698898, 0.05774989724159241, -0.016625257208943367, -0.058081403374671936, 0.053087469190359116, -0.18961676955223083, 0.020844243466854095, 0.041495393961668015, -0.036882687360048294, -0.033610399812459946, -0.07580254971981049, -0.08544411510229111, 0.07275506108999252, -0.004256293643265963, 0.0016384579939767718, 0.259255588054657, 0.06804875284433365, 0.035543885082006454, -0.07602687925100327, -0.1874402016401291, -0.08403139561414719, -0.10179715603590012, 0.04240576550364494, -0.08851157128810883, 0.040132034569978714, -0.29175418615341187, 0.05318513140082359, 0.044414520263671875, -0.08217378705739975, 0.03205624222755432, -0.03444076329469681, 0.02820579893887043, 0.10753773897886276, -0.06177639216184616, -0.14747202396392822, 0.014661768451333046, 0.09740456193685532, 0.07133182883262634, -0.0530492439866066, -0.14407522976398468, 0.056706883013248444, -0.023553164675831795, 0.12057795375585556, -0.062075305730104446, 0.050750087946653366, -0.021115465089678764, -0.10603219270706177, 0.04355764016509056, 0.07389036566019058, -0.14332690834999084, 0.0759006217122078, 0.176759734749794, -0.029659759253263474, 0.16771215200424194, -0.09610046446323395, 0.024489611387252808, 0.04262746870517731, -0.03435814380645752, 0.05195537209510803, 0.003343299264088273, 0.07902440428733826, 0.14328929781913757, 0.022280985489487648, 0.11284948885440826, -0.06414800137281418, -0.1241980716586113, 0.17450660467147827, -0.12404979020357132, -0.1493891179561615, 0.011285088956356049, -0.12538829445838928, -0.009146371856331825, -0.05691467598080635, -0.11742155998945236, -0.006909084971994162, -0.03498430550098419, 0.056073207408189774, -0.0987265482544899, -0.27688854932785034, -0.06940805912017822, -0.03409233316779137, 0.05658357962965965, -0.10954180359840393, -0.14832088351249695, -0.14200057089328766, -0.19666416943073273, 0.013625533320009708, 0.09912616014480591, -0.14900808036327362, 0.07970583438873291, -1.4268350264320566e-32, 0.06449750810861588, 0.031053293496370316, 0.09628190845251083, 0.08139652013778687, 0.07018184661865234, 0.07289527356624603, -0.021365156397223473, 0.07637656480073929, -0.0472155325114727, -0.11955593526363373, -0.05118256434798241, -0.1198716014623642, 0.08617740869522095, -0.07137185335159302, 0.06256051361560822, 0.09063060581684113, -0.1617165505886078, 0.1246873214840889, -0.0428260937333107, 0.03258012607693672, -0.1176103875041008, 0.12604092061519623, -0.10104729235172272, -0.003969214856624603, -0.15019597113132477, 0.05520366504788399, 0.06488428264856339, 0.07469622790813446, 0.12038058042526245, -0.09506217390298843, -0.04079022631049156, -0.011242145672440529, -0.1871298998594284, 0.1114516407251358, -0.04488395154476166, 0.01901880092918873, 0.08751623332500458, -0.1896732747554779, -0.06475576758384705, 0.2003336399793625, 0.1441277265548706, 0.17234964668750763, -0.11424610018730164, 0.10560991615056992, -0.035744015127420425, 0.003771185874938965, -0.057278141379356384, 0.09432718902826309, -0.04076528549194336, -0.036459874361753464, -0.016803190112113953, -0.014096295461058617, -0.175194650888443, 0.03309723362326622, -0.033048249781131744, 0.060169048607349396, -0.12909792363643646, -0.020453551784157753, -0.08384635299444199, 0.09420238435268402, -0.14233766496181488, -0.005670106969773769, -0.022190168499946594, -0.08308016508817673, 0.09112951159477234, -0.034252818673849106, -0.06790915876626968, 0.012543226592242718, 0.06844580173492432, 0.06615962088108063, -0.034667789936065674, 0.09517595916986465, 0.10778383910655975, -0.09141907095909119, 0.03882165253162384, 0.01871413178741932, -0.05061166733503342, 0.03825635835528374, 0.02448245696723461, 0.06521311402320862, -0.004782672505825758, -0.10749554634094238, 0.0835707038640976, 0.08432959765195847, 0.02386169694364071, 0.01713103987276554, 0.13543881475925446, 0.10431510955095291, 0.06677355617284775, -0.12291105836629868, 0.001042167074047029, -0.12759898602962494, 0.22590400278568268, 0.21751061081886292, -0.00754493847489357, -1.0073392076037635e-07, -0.059211429208517075, 0.05324924364686012, -0.0058277677744627, 0.1859501153230667, 0.038364559412002563, 0.005008764564990997, -0.04209107905626297, 0.0702720582485199, -0.0034506621304899454, -0.027842745184898376, 0.13719290494918823, 0.022380536422133446, -0.0868576318025589, 0.04111117869615555, -0.0588102862238884, 0.051012516021728516, -0.031056595966219902, 0.09247318655252457, 0.044142045080661774, 0.0632704496383667, 0.09496109932661057, -0.10881177335977554, 0.05902253836393356, -0.011908086948096752, 0.03608297184109688, -0.04585101827979088, -0.05426850542426109, -0.005944012198597193, 0.02850409597158432, 0.06861481815576553, 0.033086687326431274, -0.13501548767089844, 0.011056794784963131, 0.06222408637404442, 0.09125502407550812, 0.08632389456033707, 0.03036271408200264, -0.062138624489307404, 0.021916372701525688, 0.09231727570295334, -0.09760452806949615, 0.0258584376424551, -0.14494307339191437, -0.044294703751802444, -0.0011805561371147633, 0.02224874123930931, -0.04035364091396332, -0.08363243192434311, 0.13095048069953918, 0.060123324394226074, -0.06930387765169144, -0.06640150398015976, -0.13498280942440033, 0.05151357129216194, 0.1366405487060547, 0.04144003614783287, -0.059084344655275345, 0.03474370762705803, -0.013996130786836147, -0.055397454649209976, -0.0008408028515987098, -0.006633111275732517, -0.08272388577461243, -0.02198605053126812], metadata={'source': 'AAAMLP-569to.pdf', 'page': 250}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 251     # the next step is to randomize the rows of the data     df = df.sample(frac=1).reset_index(drop=True)          # fetch labels     y = df.sentiment.values          # initiate the kfold class from model_selection module     kf = model_selection.StratifiedKFold(n_splits=5)          # fill the new kfold column     for f, (t_, v_) in enumerate(kf.split(X=df, y=y)):         df.loc[v_, \\'kfold\\'] = f          # save the new csv with kfold column     df.to_csv(\"../input/imdb_folds.csv\", index=False) ═════════════════════════════════════════════════════════════════════════  Once we have the dataset divided into folds, we create a simple dataset class in dataset.py. Dataset class returns one sample of the training or validation data.  ═════════════════════════════════════════════════════════════════════════ # dataset.py import torch   class IMDBDataset:     def __init__(self, reviews, targets):         \"\"\"         :param reviews: this is a numpy array         :param targets: a vector, numpy array         \"\"\"         self.reviews = reviews         self.target = targets      def __len__(self):         # returns length of the dataset         return len(self.reviews)          def __getitem__(self, item):         # for any given item, which is an int,         # return review and targets as torch tensor         # item is the index of the item in concern         review = self.reviews[item, :]         target = self.target[item]           return {'),\n",
       " VectorParams(vector=[-0.03264571726322174, -0.24091880023479462, 0.04009963199496269, 0.06736515462398529, 0.12668706476688385, 0.08754900842905045, -0.05183020234107971, -0.004407125059515238, -0.16796092689037323, -0.14796462655067444, -0.006323750130832195, -0.04481160640716553, -0.03397717699408531, 0.011579059064388275, -0.1102607250213623, 0.16096210479736328, 0.008528334088623524, 0.00539433816447854, -0.14968577027320862, -0.066783607006073, 0.19269928336143494, 0.015063623897731304, 0.12129365652799606, 0.008846315555274487, 0.01000947505235672, -0.035102590918540955, 0.07234328985214233, 0.11451715975999832, 0.04452197253704071, -0.02083243429660797, 0.14440350234508514, 0.08268897235393524, -0.136271670460701, 0.13303028047084808, -0.04432866349816322, -0.016036737710237503, -0.20879508554935455, -0.08865956217050552, -0.08387871831655502, 0.11497540771961212, 0.08623816072940826, 0.030221989378333092, -0.07089968770742416, -0.039304472506046295, 0.12371377646923065, 0.04994428902864456, 0.016215762123465538, 0.0008996148826554418, -0.005178202409297228, -0.015746770426630974, -0.01702185533940792, 0.015425273217260838, -0.0910378247499466, 0.07589560002088547, -0.1952400654554367, -0.21223881840705872, 0.04731426760554314, -0.08606308698654175, -0.06527576595544815, -0.20988020300865173, -0.02471066080033779, -0.018144212663173676, 0.029159191995859146, -0.08399666845798492, -0.0716700628399849, -0.015048333443701267, -0.03332642838358879, 0.10312119871377945, -0.0037810769863426685, 0.13783162832260132, -0.02029973268508911, 0.046161483973264694, -0.07209079712629318, 0.180025115609169, -0.044626690447330475, -0.09095286577939987, 0.21698087453842163, -0.011925616301596165, 0.08084837347269058, -0.07948519289493561, -0.01772349141538143, -0.06484474986791611, 0.061075158417224884, 0.030552782118320465, 0.1163601279258728, -0.19737645983695984, 0.10308384150266647, 0.11428072303533554, 0.017385929822921753, -0.08366300910711288, -0.008284852840006351, -0.09466590732336044, -0.07203029096126556, 0.07228226959705353, 0.1556483954191208, 0.062430884689092636, 0.12222816050052643, -0.014951679855585098, -0.14618930220603943, 0.07193507999181747, 0.021824367344379425, -0.03230690583586693, -0.05260518938302994, 0.11846555024385452, 0.005372123327106237, 0.11218565702438354, 0.061177805066108704, 0.1069745197892189, 0.0037167395930737257, -0.23175078630447388, 0.0674608126282692, -0.018415488302707672, -0.03290615603327751, 0.0007682573632337153, 0.12910602986812592, -0.08205115050077438, -0.06917615979909897, -0.05582751706242561, -0.01087875571101904, 0.18441854417324066, -0.11185258626937866, 0.09070540219545364, 0.01084250956773758, 0.13679149746894836, -0.10810883343219757, -0.037743184715509415, -0.17515653371810913, 1.5775873280108178e-32, -0.021230727434158325, 0.04749166592955589, -0.134196937084198, -0.06477703154087067, 0.06770103424787521, 0.04709470644593239, 0.16706153750419617, 0.06525875627994537, -0.14871326088905334, 0.015874622389674187, -0.19397136569023132, -0.008236115798354149, 0.016630176454782486, 0.1059555634856224, -0.13920797407627106, -0.051213279366493225, 0.024067293852567673, 0.03442925587296486, -0.03755683824419975, -0.03980572149157524, 0.08179228752851486, 0.03340594843029976, -0.010000418871641159, -0.09059228748083115, -0.22021371126174927, -0.0003224324027542025, 0.01354745589196682, -0.10524854809045792, -0.11736921966075897, 0.009750684723258018, -0.23341788351535797, -0.026961082592606544, 0.13678833842277527, -0.02650078386068344, 0.05033620446920395, -0.17408715188503265, 0.08700508624315262, -0.027279796078801155, 0.04129328206181526, -0.3749474287033081, 0.012487613596022129, 0.12519119679927826, 0.06054404377937317, -0.16502849757671356, -0.20965814590454102, 0.04803662374615669, -0.06939035654067993, 0.1188087910413742, -0.12983641028404236, -0.003853349946439266, 0.073027104139328, -0.06646843254566193, -0.12104672938585281, 0.04215436056256294, 0.004677176009863615, -0.11982632428407669, 0.09217985719442368, 0.14925043284893036, 0.22142383456230164, -0.11359524726867676, 0.06081252917647362, 0.06818550080060959, 0.10559292882680893, 0.09898236393928528, 0.03769883140921593, 0.06640844792127609, -0.02831241674721241, 0.08501937985420227, 0.1079355999827385, -0.07733450829982758, -0.14847025275230408, 0.057656459510326385, -0.059666506946086884, -0.0737391859292984, 0.06948210299015045, -0.142745241522789, 0.12991903722286224, -0.1735314428806305, -0.11797932535409927, 0.1771579086780548, -0.028780629858374596, 0.07114582508802414, -0.012875811196863651, -0.24097178876399994, -0.2241332232952118, -0.1476116180419922, 0.0979098230600357, -0.22352522611618042, -0.04781137779355049, -0.0568842887878418, -0.16375304758548737, -0.09653247892856598, 0.13923481106758118, -0.020214073359966278, -0.02231019362807274, -1.5424817769706856e-32, -0.015238617546856403, 0.14841867983341217, -0.04157745838165283, 0.11433618515729904, -0.0015585849760100245, -0.0801619365811348, 0.02223055437207222, 0.1189822182059288, -0.009094513021409512, 0.005596899893134832, 0.07020416110754013, -0.11632939428091049, 0.02243216708302498, -0.13850849866867065, 0.19057485461235046, 0.0019642848055809736, -0.023435089737176895, 0.08091738075017929, 0.042843837291002274, 0.019893093034625053, -0.11153388023376465, 0.1963362693786621, -0.18364371359348297, 0.08928218483924866, -0.19629128277301788, 0.12095780670642853, 0.03428734838962555, 0.08555997163057327, 0.0025578567292541265, -0.05994242802262306, -0.009319384582340717, -0.007211759220808744, -0.17399443686008453, 0.04593239724636078, -0.11938922852277756, 0.08605626225471497, 0.14374087750911713, -0.06131383404135704, -0.03542734682559967, 0.03243239223957062, 0.2512684166431427, 0.07700633257627487, -0.08607688546180725, 0.052195075899362564, -0.0609438493847847, 0.0006016532424837351, -0.11425630003213882, -0.04680577293038368, 0.035008661448955536, -0.01222154963761568, -0.03744801506400108, -0.11732413619756699, -0.04208359867334366, 0.0002657122677192092, -0.05133964866399765, -0.052654873579740524, -0.07501813024282455, 0.01530532818287611, -0.0004239447589498013, -0.024406317621469498, -0.056371986865997314, -0.10298582166433334, -0.003639036789536476, -0.11840838938951492, 0.06278108060359955, -0.0021937580313533545, -0.08708524703979492, 0.12448228895664215, 0.047650810331106186, 0.09600184857845306, -0.004940956365317106, 0.23076079785823822, 0.09481710940599442, 0.08355217427015305, -8.103087748168036e-05, 0.05339222773909569, -0.07722292095422745, 0.021262265741825104, 0.01058067288249731, -0.058147743344306946, -0.08154814690351486, -0.04745356738567352, -0.008362583816051483, 0.11964792758226395, 0.09997053444385529, 0.0951315313577652, 0.06366727501153946, 0.18626873195171356, 0.004634391516447067, -0.1374957263469696, 0.11031270027160645, -0.06505871564149857, 0.1136118695139885, 0.1329881250858307, 0.15830524265766144, -1.0040275100209328e-07, -0.12707650661468506, 0.06057422235608101, 0.018366647884249687, 0.09641114622354507, -0.01626351848244667, -0.1159915179014206, 0.11151125282049179, 0.14354883134365082, 0.0688486322760582, -0.0809265598654747, 0.17434202134609222, -0.05700501799583435, -0.06565648317337036, 0.02780442126095295, -0.06033805012702942, 0.12394111603498459, -0.08569652587175369, 0.013952188193798065, 0.049704499542713165, -0.026817303150892258, 0.04752519726753235, -0.08155719190835953, 0.03310935199260712, 0.07124552130699158, -0.021861203014850616, -0.08123589307069778, 0.020251726731657982, 0.08687660098075867, 0.03131229430437088, 0.05873545631766319, 0.002508570207282901, -0.04765830561518669, 0.06819059699773788, 0.044228632003068924, 0.033946942538022995, 0.1762441098690033, 0.0005790764698758721, -0.02825864404439926, -0.0370577909052372, 0.09826182574033737, -0.11821292340755463, 0.1347995400428772, -0.07693014293909073, -0.0836271271109581, 0.12907983362674713, 0.02253531850874424, -0.02728317119181156, -0.22810442745685577, 0.06465020030736923, 0.008279478177428246, 0.058857258409261703, 0.09122642874717712, -0.09790939092636108, 0.09959782660007477, 0.13980472087860107, -0.0748632550239563, -0.06309617310762405, 0.07414582371711731, 0.052843403071165085, -0.05397846922278404, -0.0254322849214077, 0.06083948537707329, -0.07815618813037872, -0.02773650735616684], metadata={'source': 'AAAMLP-569to.pdf', 'page': 251}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 252             \"review\": torch.tensor(review, dtype=torch.long),             \"target\": torch.tensor(target, dtype=torch.float)         } ═════════════════════════════════════════════════════════════════════════  Once the dataset class is done, we can create lstm.py which consists of our LSTM model.  ═════════════════════════════════════════════════════════════════════════ # lstm.py  import torch import torch.nn as nn   class LSTM(nn.Module):     def __init__(self, embedding_matrix):         \"\"\"         :param embedding_matrix: numpy array with vectors for all words         \"\"\"         super(LSTM, self).__init__()         # number of words = number of rows in embedding matrix         num_words = embedding_matrix.shape[0]          # dimension of embedding is num of columns in the matrix         embed_dim = embedding_matrix.shape[1]          # we define an input embedding layer         self.embedding = nn.Embedding(             num_embeddings=num_words,              embedding_dim=embed_dim         )          # embedding matrix is used as weights of          # the embedding layer         self.embedding.weight = nn.Parameter(             torch.tensor(                 embedding_matrix,                  dtype=torch.float32             )         )          # we dont want to train the pretrained embeddings         self.embedding.weight.requires_grad = False          # a simple bidirectional LSTM with         # hidden size of 128'),\n",
       " VectorParams(vector=[-0.03832707554101944, -0.14736463129520416, 0.06363828480243683, 0.10508948564529419, 0.01920790784060955, -0.09558914601802826, 0.008721047081053257, 0.0643283948302269, -0.11032005399465561, -0.18086110055446625, -0.0740417093038559, -0.017641501501202583, -0.0015230001881718636, -0.07816245406866074, -0.21074214577674866, 0.18472948670387268, 0.018302608281373978, 0.026662003248929977, -0.2058344930410385, -0.15378481149673462, 0.2433825433254242, -0.02364123985171318, 0.07827188819646835, 0.0539960153400898, 0.02193536050617695, 0.01282395888119936, -0.07934936881065369, 0.030334625393152237, 0.15857133269309998, -0.14896823465824127, 0.16283059120178223, 0.07936279475688934, -0.11114546656608582, 0.0886935144662857, 0.0033571384847164154, 0.03325425460934639, -0.24177156388759613, -0.12009145319461823, -0.1244388148188591, 0.040229953825473785, 0.08229249715805054, 0.04223339632153511, -0.06066807359457016, -0.007002873346209526, 0.05849039927124977, 0.20841063559055328, 0.025697631761431694, -0.11139815300703049, 0.029672689735889435, -0.047353245317935944, 0.01609380915760994, 0.12294606864452362, -0.16330520808696747, 0.022099999710917473, -0.042963992804288864, -0.14715826511383057, 0.03757379204034805, -0.06254342943429947, -0.10609206557273865, -0.06750373542308807, -0.03524628281593323, -0.053669318556785583, 0.13381169736385345, -0.011663312092423439, -0.014108819887042046, -0.13262975215911865, 0.015401536598801613, 0.16449692845344543, -0.023382660001516342, 0.1421108841896057, 0.009747443720698357, 0.15911205112934113, -0.13603909313678741, -0.0007337670540437102, 0.08298274129629135, -0.1139056459069252, 0.1743391752243042, 0.010711364448070526, -0.042026691138744354, -0.14033642411231995, 0.0012405451852828264, -0.04598494619131088, 0.13344717025756836, -0.09871441125869751, 0.13360442221164703, -0.18158835172653198, 0.041367046535015106, 0.04622834175825119, 0.1269969791173935, 0.04845450818538666, -0.057133398950099945, -0.000527043011970818, -0.17398732900619507, 0.10207312554121017, 0.1879701316356659, 0.09268860518932343, 0.11520233750343323, -0.04622112587094307, -0.14753945171833038, 0.13914476335048676, 0.010638262145221233, 0.020335543900728226, 0.07444154471158981, 0.11952584236860275, 0.14288802444934845, 0.0556221604347229, 0.12783081829547882, 0.16871213912963867, 0.07064110785722733, -0.3360806107521057, 0.10037018358707428, -0.037177346646785736, 0.010116571560502052, 0.0608295276761055, 0.1370408982038498, -0.059514328837394714, -0.009274281561374664, 0.038113344460725784, -0.06788168102502823, 0.1993492990732193, -0.14088256657123566, 0.10154444724321365, -0.07097528129816055, 0.2409108430147171, -0.015034204348921776, -0.07378783077001572, -0.03919310122728348, 1.5430996461888365e-32, -0.11701659113168716, -0.08373497426509857, -0.0897553414106369, -0.14535251259803772, -0.0027988534420728683, 0.1663547158241272, 0.22255297005176544, -0.011778565123677254, -0.0818023532629013, 0.004512731451541185, -0.15714162588119507, -0.06412740051746368, -0.02989947609603405, 0.04423593729734421, -0.031748007982969284, -0.0674523264169693, 0.03036418743431568, 0.0962696522474289, -0.03966701030731201, -0.08982928842306137, 0.21439285576343536, 0.03006439469754696, -0.03995324298739433, -0.19158935546875, -0.2678754925727844, -0.07320661842823029, -0.0011174428509548306, -0.09154816716909409, -0.17042580246925354, 0.02458925172686577, -0.13396568596363068, 0.05370016396045685, 0.03266831114888191, 0.034280840307474136, 0.012290745973587036, -0.018055181950330734, 0.16968128085136414, 0.04834781959652901, 0.06905987858772278, -0.21014180779457092, -0.06846392154693604, 0.13647699356079102, 0.06860920786857605, -0.09201237559318542, -0.23011581599712372, -0.0721346065402031, -0.05200817063450813, 0.1974804848432541, -0.14376765489578247, 0.06474879384040833, -0.10648908466100693, -0.0859876349568367, -0.03165438026189804, -0.021150927990674973, 0.07802615314722061, -0.05178666487336159, 0.0749923437833786, 0.15963926911354065, 0.10101886093616486, -0.03227362409234047, 0.13656434416770935, 0.05971556529402733, -0.12015237659215927, 0.12980438768863678, 0.04549473151564598, 0.08944237977266312, 0.13589303195476532, 0.11810335516929626, 0.07942358404397964, -0.0016947061521932483, -0.16553165018558502, 0.10190283507108688, -0.07818679511547089, -0.09931665658950806, 0.09218080341815948, -0.14245498180389404, 0.06009640544652939, -0.15258704125881195, -0.1871800720691681, 0.0831800177693367, 0.03700949251651764, 0.2396003156900406, -0.05152612924575806, -0.26199302077293396, -0.12663324177265167, -0.052180372178554535, 0.03352527692914009, -0.15216700732707977, -0.08835776150226593, -0.06590603291988373, -0.21588829159736633, -0.1616559624671936, 0.2415812462568283, -0.000983518548309803, -0.12040325254201889, -1.5873501024679846e-32, 0.012729999609291553, 0.224817156791687, 0.024807320907711983, 0.14963065087795258, 0.046091873198747635, 0.013051497749984264, 0.0509456992149353, 0.04690871387720108, -0.0738435760140419, -0.023552309721708298, -0.09623643755912781, -0.050732214003801346, -0.03883134201169014, -0.03472131863236427, 0.15085744857788086, -0.04223952814936638, -0.015240155160427094, 0.0543280765414238, 0.13816460967063904, -0.10633906722068787, -0.225619375705719, 0.30219823122024536, -0.10085761547088623, 0.12188102304935455, -0.21553368866443634, 0.09892824292182922, -0.08968590199947357, 0.07573292404413223, 0.014675818383693695, -0.15283776819705963, -0.114392951130867, -0.05058565363287926, -0.14856421947479248, 0.08878542482852936, -0.146794855594635, 0.05360030010342598, 0.15286095440387726, -0.012410666793584824, -0.04930892586708069, 0.0911879688501358, 0.27024441957473755, 0.005129012279212475, -0.10992910712957382, 0.06623926013708115, 0.009501786902546883, 0.05788185074925423, -0.16412268579006195, -0.10304126143455505, 0.02478751353919506, 0.012389196082949638, -0.046994149684906006, -0.10008902847766876, -0.19917601346969604, -0.013926541432738304, -0.16619163751602173, -0.019658653065562248, -0.09860337525606155, 0.07901136577129364, -0.04487013816833496, -0.035218246281147, -0.053762659430503845, -0.10781034827232361, -0.00156430434435606, -0.09282560646533966, -0.04156580567359924, 0.019518550485372543, -0.13441990315914154, 0.07383221387863159, 0.11685515195131302, 0.04242706671357155, 0.013072031550109386, 0.2189873605966568, 0.043887194246053696, -0.008417136035859585, -0.02489289827644825, 0.05320991203188896, 0.004784376360476017, -0.12200042605400085, -0.006642409134656191, 0.010367872193455696, -0.18746201694011688, 0.06836322695016861, 0.08198149502277374, 0.11776832491159439, 0.08509884029626846, 0.060810644179582596, 0.17439065873622894, 0.1809149831533432, 0.0071366894990205765, -0.1754947453737259, 0.11103435605764389, -0.013546689413487911, 0.10364016890525818, 0.14004595577716827, 0.08283952623605728, -1.0099696368115474e-07, -0.040571700781583786, -0.006679778452962637, -0.041728124022483826, 0.16579146683216095, 0.045752882957458496, -0.04110737144947052, 0.05082220956683159, 0.16930513083934784, -0.06646596640348434, -0.11196570098400116, 0.122093565762043, -0.09530777484178543, -0.07396485656499863, 0.009115435183048248, 0.010664040222764015, 0.063852958381176, -0.12997888028621674, -0.08772885054349899, 0.0036766764242202044, -0.06569591909646988, -0.044049765914678574, -0.11287686973810196, -0.008602815680205822, 0.04358288273215294, -0.036773353815078735, -0.12280380725860596, -0.005615783855319023, -0.019136138260364532, -0.0017157872207462788, -0.09462898969650269, -0.022090889513492584, -0.09455280005931854, 0.1216685101389885, 0.11743029952049255, 0.13334377110004425, 0.13063345849514008, -0.03866099193692207, 0.016958553344011307, 0.018602320924401283, 0.04424470290541649, -0.20986613631248474, 0.16270487010478973, 0.11213479191064835, -0.053377244621515274, 0.1787608414888382, -0.0009728788863867521, 0.04595058038830757, -0.24824845790863037, 0.10457850247621536, -0.05138922482728958, 0.12371629476547241, 0.03186221793293953, -0.07481644302606583, 0.14493341743946075, 0.235770583152771, -0.17868849635124207, -0.09448103606700897, -0.03547349572181702, -0.04333227500319481, 0.008678549900650978, -0.038790907710790634, 0.0265897698700428, -0.12776196002960205, -0.07793634384870529], metadata={'source': 'AAAMLP-569to.pdf', 'page': 252}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 253         self.lstm = nn.LSTM(             embed_dim,             128,             bidirectional=True,             batch_first=True,         )          # output layer which is a linear layer         # we have only one output         # input (512) = 128 + 128 for mean and same for max pooling         self.out = nn.Linear(512, 1)      def forward(self, x):         # pass data through embedding layer         # the input is just the tokens         x = self.embedding(x)          # move embedding output to lstm         x, _ = self.lstm(x)          # apply mean and max pooling on lstm output         avg_pool = torch.mean(x, 1)         max_pool, _ = torch.max(x, 1)                  # concatenate mean and max pooling         # this is why size is 512         # 128 for each direction = 256         # avg_pool = 256 and max_pool = 256         out = torch.cat((avg_pool, max_pool), 1)          # pass through the output layer and return the output         out = self.out(out)          # return linear output         return out ═════════════════════════════════════════════════════════════════════════  Now, we create engine.py which consists of our training and evaluation functions.  ═════════════════════════════════════════════════════════════════════════ # engine.py import torch import torch.nn as nn   def train(data_loader, model, optimizer, device):     \"\"\"'),\n",
       " VectorParams(vector=[-0.12594200670719147, -0.10161706060171127, -0.04536072164773941, 0.09958934783935547, 0.06876584887504578, -0.09647022187709808, -0.035814013332128525, 0.07875850051641464, -0.1789216697216034, -0.09427723288536072, -0.04197798669338226, -0.13236239552497864, -0.0021061948500573635, -0.1435467153787613, -0.07210447639226913, 0.13467998802661896, 0.0033534825779497623, -0.006066590081900358, -0.14142227172851562, -0.12165890634059906, 0.14943112432956696, 0.10174579173326492, 0.09085062146186829, 0.1216341108083725, -0.05333049222826958, -0.08183176070451736, 0.05179157108068466, 0.06885602325201035, 0.009740357287228107, -0.10587943345308304, 0.1466304063796997, -0.031770817935466766, -0.1492835432291031, 0.1509774625301361, -0.03757350891828537, 0.061817992478609085, -0.1593102663755417, -0.08820081502199173, -0.06920191645622253, 0.028163349255919456, 0.04072956740856171, 0.05973118171095848, -0.08700812608003616, -0.016587167978286743, 0.09810171276330948, 0.003220274345949292, 0.01754310168325901, -0.05586855486035347, 0.09860944002866745, -0.029084615409374237, -0.022247834131121635, -0.012335001491010189, -0.023381821811199188, 0.04253855347633362, -0.05885836109519005, -0.09019343554973602, 0.07982663810253143, -0.09036235511302948, 0.04934093356132507, -0.18621207773685455, -0.006652177777141333, -0.07444450259208679, -0.059269294142723083, -0.09302603453397751, -0.08857770264148712, -0.10277322679758072, -0.040260832756757736, 0.03816794231534004, 0.05934589356184006, 0.08991086483001709, 0.04025370255112648, 0.08789869397878647, 0.031968854367733, 0.07531801611185074, -0.032401252537965775, -0.0220132227987051, 0.2306840419769287, 0.048181064426898956, 0.003817121498286724, -0.15285584330558777, -0.07041461020708084, -0.07763559371232986, 0.088134765625, -0.009139935486018658, 0.13327401876449585, -0.244132861495018, 0.09080937504768372, 0.060950540006160736, 0.13654257357120514, -0.05000915005803108, 0.042720045894384384, -0.011433513835072517, -0.08996764570474625, 0.01756727695465088, 0.11627141386270523, 0.08762631565332413, 0.11675948649644852, -0.09509769827127457, -0.15563882887363434, 0.16462169587612152, -0.05555019900202751, 0.020364783704280853, -0.013943549245595932, 0.07741717249155045, -0.044508300721645355, 0.04918904975056648, 0.08111973106861115, 0.06266313791275024, 0.032271724194288254, -0.12909948825836182, 0.10332611948251724, 0.09526091814041138, -0.003150829579681158, 0.046873196959495544, 0.1832190901041031, -0.002601102227345109, -0.12729641795158386, 0.016048314049839973, -0.0313069224357605, 0.22530603408813477, -0.12340083718299866, 0.06456969678401947, -0.06628446280956268, 0.12023307383060455, -0.05986086651682854, -0.04024631157517433, -0.09921823441982269, 1.5447495994470095e-32, -0.03702018782496452, -0.01799449324607849, -0.1345386654138565, -0.09457173943519592, -0.031188255175948143, 0.06616169959306717, 0.09267149120569229, 0.04872448742389679, -0.17166119813919067, -0.03352764993906021, -0.20629890263080597, 0.004451827611774206, -0.08154863864183426, 0.07820191234350204, -0.027638312429189682, -0.05607474967837334, 0.028919054195284843, 0.08110086619853973, 0.03780348598957062, 0.023882566019892693, 0.2146485447883606, -0.04059819132089615, -0.15966615080833435, -0.12812069058418274, -0.10821618884801865, 0.0903937965631485, 0.00642396742478013, -0.025266848504543304, -0.13711535930633545, 0.06283886730670929, -0.20582202076911926, 0.011647677980363369, 0.059811703860759735, -0.004296102095395327, 0.00189312850125134, -0.05617129057645798, 0.027569234371185303, 0.05733129009604454, 0.0422099269926548, -0.20684780180454254, -0.015640249475836754, 0.09492848068475723, -0.004868172109127045, -0.09225953370332718, -0.1730632334947586, -0.015648378059267998, -0.03786830976605415, 0.12776406109333038, -0.01936621218919754, 0.04184354469180107, -0.05529585853219032, -0.09746560454368591, -0.04157470166683197, -0.037219639867544174, -0.07725844532251358, -0.05591809004545212, 0.08011485636234283, 0.011022356338799, 0.24532389640808105, -0.08147880434989929, 0.12998805940151215, 0.11230204999446869, -0.0007699402049183846, 0.012024416588246822, 0.01907395012676716, 0.06014344096183777, -0.01776072010397911, 0.10340433567762375, 0.102829709649086, 0.023043017834424973, -0.21364575624465942, 0.057954009622335434, 0.010412177070975304, -0.10973111540079117, 0.17042438685894012, -0.15568584203720093, 0.0784747526049614, -0.1914501190185547, -0.15640971064567566, 0.07106668502092361, 0.005466569680720568, 0.16364534199237823, -0.13072903454303741, -0.229579895734787, -0.1004127562046051, -0.14546585083007812, 0.012256049551069736, -0.10508587956428528, -0.12234722822904587, -0.05305657535791397, -0.25538426637649536, -0.0017058999510481954, 0.08202078193426132, 0.02623678930103779, -0.07333989441394806, -1.526925578605491e-32, -0.03197663649916649, 0.06306979805231094, 0.04415373504161835, 0.08925221115350723, 0.02662237361073494, -0.034811634570360184, -0.033126406371593475, 0.02752968855202198, 0.04084721580147743, -0.06618393212556839, 0.016253430396318436, -0.18924272060394287, -0.08790983259677887, -0.026264403015375137, 0.13039980828762054, 0.04522227495908737, -0.10479041934013367, 0.044465579092502594, 0.005308807361871004, -0.036046527326107025, -0.12433347851037979, 0.27313485741615295, -0.23783515393733978, 0.022779647260904312, -0.13778084516525269, 0.020182469859719276, 0.06715207546949387, 0.17315387725830078, 0.06847276538610458, -0.0850839912891388, 0.00014031970931682736, 0.03463344648480415, -0.11508925259113312, 0.1029350608587265, -0.06919748336076736, 0.08133187890052795, 0.1442527174949646, -0.13126638531684875, -0.06608523428440094, 0.09113141894340515, 0.30545228719711304, 0.11653537303209305, -0.13051745295524597, 0.04786849766969681, -0.015832586213946342, 0.01940217614173889, -0.04762434959411621, 0.04836205020546913, -0.013067173771560192, -0.030347956344485283, 0.05457901582121849, -0.06610139459371567, -0.12271744757890701, 0.07055561989545822, -0.08613190054893494, -0.03805936500430107, 0.02382414974272251, -0.0619257315993309, -0.04523273557424545, 0.004605648573487997, -0.10388897359371185, -0.06702857464551926, 0.06907840818166733, -0.05439916253089905, -0.029735112562775612, 0.007533784955739975, -0.07515332847833633, 0.14071202278137207, 0.10806898772716522, 0.14912615716457367, -0.09062731266021729, 0.20201720297336578, 0.1267981380224228, 0.014032675884664059, -0.003888846840709448, 0.10482662916183472, -0.09633489698171616, -0.047335099428892136, 0.026188476011157036, -0.015582628548145294, -0.015906449407339096, -0.012725231237709522, 0.08120980858802795, 0.10897445678710938, 0.06384015828371048, 0.05079587921500206, 0.11088003218173981, 0.25069335103034973, 0.005284163169562817, -0.12853282690048218, 0.04236498102545738, -0.15462644398212433, 0.17607194185256958, 0.1511763334274292, 0.04333089292049408, -1.0070118605653988e-07, -0.08381299674510956, 0.07517362385988235, 0.05458592250943184, 0.2515469789505005, 0.002650809707120061, -0.0011978658149018884, 0.054651014506816864, 0.03949024900794029, 0.019327526912093163, -0.06142222136259079, 0.13144098222255707, 0.0025019897148013115, -0.08376532793045044, 0.006357945967465639, -0.0012243660166859627, 0.1703115552663803, 0.0246980432420969, 0.029360316693782806, 0.0254866573959589, 0.008059029467403889, 0.058964818716049194, -0.0786743313074112, 0.03390684351325035, 0.020026562735438347, 0.03645719215273857, -0.0812368392944336, 0.0040290504693984985, 0.039961233735084534, -0.034665923565626144, 0.033288776874542236, -0.017284536734223366, -0.06184393912553787, -0.002753856359049678, 0.09391093999147415, 0.07129222899675369, 0.14011439681053162, 0.09891669452190399, 0.05639144405722618, 0.038627222180366516, 0.12303423881530762, -0.10419193655252457, 0.08965819329023361, -0.09957627207040787, -0.06362156569957733, 0.029772209003567696, -0.03218887746334076, -0.03171916678547859, -0.170586958527565, 0.056458182632923126, 0.07131607830524445, 0.021011492237448692, -0.016563480719923973, -0.11297695338726044, 0.07902016490697861, 0.11262345314025879, -0.13336847722530365, -0.10743303596973419, -0.123726487159729, -0.0927562341094017, -0.010472973808646202, 0.09256386011838913, -0.019891412928700447, -0.06628379970788956, 0.015852484852075577], metadata={'source': 'AAAMLP-569to.pdf', 'page': 253}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 254     This is the main training function that trains model     for one epoch     :param data_loader: this is the torch dataloader     :param model: model (lstm model)     :param optimizer: torch optimizer, e.g. adam, sgd, etc.     :param device: this can be \"cuda\" or \"cpu\"     \"\"\"     # set model to training mode     model.train()      # go through batches of data in data loader     for data in data_loader:         # fetch review and target from the dict         reviews = data[\"review\"]         targets = data[\"target\"]          # move the data to device that we want to use         reviews = reviews.to(device, dtype=torch.long)         targets = targets.to(device, dtype=torch.float)          # clear the gradients         optimizer.zero_grad()          # make predictions from the model         predictions = model(reviews)          # calculate the loss         loss = nn.BCEWithLogitsLoss()(             predictions,             targets.view(-1, 1)         )          # compute gradient of loss w.r.t.         # all parameters of the model that are trainable         loss.backward()          # single optimization step         optimizer.step()   def evaluate(data_loader, model, device):     # initialize empty lists to store predictions     # and targets     final_predictions = []     final_targets = []      # put the model in eval mode'),\n",
       " VectorParams(vector=[-0.1305197924375534, -0.2069339156150818, -0.04844972491264343, 0.08524439483880997, 0.1292247325181961, -0.025077717378735542, -0.013082537800073624, 0.0024584492202848196, -0.15249128639698029, -0.10581059008836746, -0.019244804978370667, -0.13103431463241577, -0.09323693811893463, -0.028160572052001953, -0.08301761746406555, 0.13518713414669037, -0.049061957746744156, 0.018014946952462196, -0.10106395930051804, -0.16726936399936676, 0.14893527328968048, 0.014552272856235504, 0.10326229780912399, 0.12810632586479187, 0.012004652060568333, -0.06416406482458115, 0.03904886543750763, 0.10781075805425644, -0.04157128557562828, -0.056475527584552765, 0.08489498496055603, -0.03181532770395279, -0.09793087095022202, 0.08673547953367233, -0.0552002489566803, 0.06337492167949677, -0.21212731301784515, -0.06733954697847366, -0.06709108501672745, 0.12822242081165314, 0.009203949943184853, -0.02835848368704319, 0.03281070664525032, 0.0324321873486042, 0.05629193037748337, 0.05986030027270317, 0.023013737052679062, -0.06484116613864899, 0.05385205149650574, -0.0045516337268054485, -0.029592426493763924, -0.03434053808450699, -0.06969749182462692, 0.08060409128665924, -0.10717935115098953, -0.09554069489240646, 0.1332862824201584, -0.08816308528184891, 0.0284566693007946, -0.18960170447826385, -0.08053948730230331, -0.01694122701883316, -0.021672822535037994, -0.13052351772785187, -0.025546876713633537, -0.06843669712543488, -0.07150112837553024, -0.007145773619413376, -0.023666584864258766, 0.08825702220201492, 0.04283110797405243, 0.04699984937906265, -0.02718202956020832, 0.03369612991809845, 0.025097765028476715, -0.10378557443618774, 0.25349223613739014, 0.0780683308839798, -0.01483478955924511, -0.16000311076641083, -0.035491473972797394, -0.10912265628576279, 0.1046249270439148, -0.02296077460050583, 0.04143286868929863, -0.2081366777420044, 0.050035618245601654, 0.06623762845993042, 0.11655125021934509, -0.03274074196815491, 0.0502469427883625, -0.018087977543473244, -0.12129734456539154, 0.022026514634490013, 0.08657500892877579, 0.11977466940879822, 0.06637794524431229, -0.06158124655485153, -0.13741855323314667, 0.08777319639921188, -0.017553722485899925, -0.03445403650403023, -0.016667649149894714, 0.13621073961257935, 0.01625661551952362, 0.09921745210886002, 0.11153127253055573, 0.09303393959999084, 0.03584108129143715, -0.19158950448036194, 0.13240283727645874, 0.06045689806342125, -0.0030274733435362577, 0.012285202741622925, 0.1481606513261795, -0.024418272078037262, -0.13409453630447388, 0.039925191551446915, -0.10642631351947784, 0.3011992573738098, -0.1479540318250656, 0.0946335569024086, -0.022171711549162865, 0.10410004109144211, -0.05092983320355415, -0.07804188132286072, -0.16154447197914124, 1.535049420064024e-32, -0.09285809844732285, 0.007571413181722164, -0.018135149031877518, -0.10318615287542343, -0.048769790679216385, -0.021426016464829445, 0.034574318677186966, 0.01830769143998623, -0.13288280367851257, 0.015559309162199497, -0.2039613276720047, 0.005467054899781942, -0.0788913145661354, 0.13361868262290955, -0.044707536697387695, -0.13148729503154755, 0.11137960106134415, 0.02170703560113907, 0.01834738254547119, 0.029217982664704323, 0.15344345569610596, 0.0212914627045393, -0.08805519342422485, -0.11589175462722778, -0.10971280187368393, 0.06890878826379776, -0.02385055087506771, 0.01690651662647724, -0.12673668563365936, 0.05145253613591194, -0.2383062243461609, 0.0013863779604434967, 0.033000487834215164, -0.04665065556764603, -0.02597026340663433, -0.0740390419960022, 0.04335883632302284, 0.0304525438696146, -0.006638998165726662, -0.1941596418619156, 0.05899758264422417, 0.13996896147727966, 0.037518225610256195, -0.12514883279800415, -0.13185036182403564, 0.056838393211364746, 0.01135387271642685, 0.15421967208385468, -0.04533444717526436, 0.05425402522087097, -0.03296799957752228, -0.06447513401508331, -0.0947844609618187, -0.03394010663032532, -0.06148804351687431, -0.03963090106844902, 0.04656721279025078, 0.0339992493391037, 0.2251824140548706, -0.13233567774295807, 0.15045030415058136, 0.059782058000564575, -0.005257661920040846, -0.0506635457277298, -0.02703450620174408, 0.05207385495305061, 0.06817303597927094, 0.12273555994033813, 0.08146554231643677, 0.010647221468389034, -0.15990714728832245, 0.06950268894433975, 0.03265484794974327, -0.08818020671606064, 0.08069311827421188, -0.07801777124404907, 0.05441275238990784, -0.21785640716552734, -0.14496497809886932, 0.029071060940623283, -0.04211799055337906, 0.13775718212127686, -0.008407440036535263, -0.275138795375824, -0.07197805494070053, -0.059043314307928085, -0.03265805169939995, -0.10335197299718857, -0.11486756056547165, -0.03789530321955681, -0.3017256259918213, 0.018748663365840912, 0.09824377298355103, 0.013412795960903168, -0.12159574776887894, -1.6753840498954165e-32, -0.03972553089261055, 0.12476953864097595, -0.021509487181901932, 0.04443245381116867, 0.0468597337603569, 0.006081892643123865, -0.04097484424710274, 0.014972762204706669, 0.02647200971841812, -0.0014163624728098512, 0.0311315655708313, -0.1844773143529892, -0.12009511142969131, -0.08159472793340683, 0.15699446201324463, 0.04360790178179741, -0.08909996598958969, 0.09357723593711853, 0.0025522178038954735, -0.04779668524861336, -0.09893009811639786, 0.18300409615039825, -0.23544073104858398, 0.06488611549139023, -0.18193161487579346, 0.018575729802250862, 0.029111739248037338, 0.12741023302078247, 0.044076357036828995, -0.0176420658826828, -0.03036665916442871, -0.04991890862584114, -0.08587294816970825, 0.08428819477558136, -0.016886413097381592, 0.10876523703336716, 0.16884109377861023, -0.04398965463042259, -0.03494041785597801, 0.11031188815832138, 0.25072890520095825, 0.1118132695555687, -0.059115611016750336, 0.07443244010210037, -0.08595018088817596, 0.004405854735523462, -0.03131384402513504, 0.010247349739074707, 0.0022885717917233706, -0.016636671498417854, 0.023873191326856613, -0.08164513856172562, -0.16720585525035858, -0.0027352673932909966, -0.1432848423719406, 0.02616785652935505, -0.009680848568677902, -0.050230056047439575, 0.027303608134388924, -0.05904262140393257, -0.045549601316452026, -0.0653722807765007, -0.03751938417553902, -0.03530867025256157, 0.0032512671314179897, 0.038973912596702576, -0.1046656146645546, 0.10299211740493774, 0.11244434118270874, 0.1214214488863945, -0.08779535442590714, 0.15180203318595886, 0.1407514214515686, 0.029036957770586014, -0.08364496380090714, 0.08433511853218079, 0.03927634283900261, -0.022878224030137062, 0.05770407244563103, -0.014219723641872406, -0.0005780262290500104, -0.06602266430854797, 0.07747089117765427, 0.09805256873369217, 0.05834626033902168, 0.004570396151393652, 0.14819097518920898, 0.22413504123687744, -0.011427396908402443, -0.14910054206848145, 0.047759972512722015, -0.05153146758675575, 0.21308033168315887, 0.1490737497806549, 0.02123003639280796, -1.0007740769424345e-07, -0.015484452247619629, -0.003171357559040189, 0.06129768490791321, 0.19289074838161469, -0.029744775965809822, 0.049975086003541946, 0.06062627583742142, 0.06176707521080971, 0.03598501905798912, -0.027698993682861328, 0.042247846722602844, -0.05902484059333801, -0.03562559932470322, 0.042520634829998016, 0.043807514011859894, 0.17843155562877655, -0.024973487481474876, 0.09371284395456314, -0.003918018192052841, -0.013205164112150669, 0.04260614514350891, -0.04761984571814537, 0.03634300455451012, 0.05165731906890869, 0.01981017366051674, -0.052769698202610016, -0.03808470070362091, 0.0721292793750763, -0.011445589363574982, 0.095816969871521, -0.025658922269940376, -0.04280795529484749, 0.016995640471577644, 0.05040920525789261, 0.14693273603916168, 0.11167293041944504, 0.07590438425540924, 0.04185635223984718, 0.06457866728305817, 0.15389513969421387, -0.19802208244800568, 0.1217486709356308, -0.11526656150817871, -0.06308374553918839, 0.11398465931415558, -0.02444833144545555, -0.08479967713356018, -0.18734505772590637, 0.03590823709964752, 0.1544714868068695, 0.03327341377735138, 0.04977499693632126, -0.06432359665632248, 0.14503316581249237, 0.21742020547389984, -0.0828557014465332, -0.06724961847066879, -0.07604139298200607, -0.07507767528295517, -0.03196115046739578, 0.06634509563446045, -0.027192872017621994, -0.042921025305986404, -0.04697384685277939], metadata={'source': 'AAAMLP-569to.pdf', 'page': 254}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 255     model.eval()      # disable gradient calculation     with torch.no_grad():         for data in data_loader:             reviews = data[\"review\"]             targets = data[\"target\"]             reviews = reviews.to(device, dtype=torch.long)             targets = targets.to(device, dtype=torch.float)              # make predictions             predictions = model(reviews)              # move predictions and targets to list             # we need to move predictions and targets to cpu too             predictions = predictions.cpu().numpy().tolist()             targets = data[\"target\"].cpu().numpy().tolist()             final_predictions.extend(predictions)             final_targets.extend(targets)      # return final predictions and targets     return final_predictions, final_targets ═════════════════════════════════════════════════════════════════════════  These functions will help us in train.py which is used for training multiple folds.  ═════════════════════════════════════════════════════════════════════════ # train.py import io import torch  import numpy as np import pandas as pd  # yes, we use tensorflow # but not for training the model! import tensorflow as tf  from sklearn import metrics  import config import dataset import engine import lstm  def load_vectors(fname):     # taken from: https://fasttext.cc/docs/en/english-vectors.html'),\n",
       " VectorParams(vector=[-0.08765651285648346, -0.1512109637260437, -0.023699456825852394, -0.00663835508748889, 0.10779009014368057, -0.03309014067053795, -0.0337519608438015, -0.05646364018321037, -0.09365405887365341, 0.007086056750267744, 0.04165688529610634, -0.019640468060970306, 0.04651068150997162, 0.009778935462236404, -0.09863030910491943, 0.12863753736019135, -0.04127468168735504, 0.11971105635166168, -0.1622292846441269, -0.09916845709085464, 0.08211442828178406, 0.13141575455665588, 0.03470994904637337, -0.029975803568959236, -0.014419975690543652, 0.018695294857025146, 0.07960686087608337, 0.11180271953344345, -0.09853900223970413, 0.012530436739325523, 0.13484175503253937, 0.02001456916332245, 0.0219954252243042, 0.07905209809541702, 0.012296444736421108, 0.14511460065841675, -0.0673590824007988, -0.018035976216197014, -0.0011133109219372272, 0.07761400938034058, -0.02413773722946644, 0.0215538889169693, -0.03436507284641266, 0.051929257810115814, 0.19702871143817902, 0.04093364253640175, -0.08863965421915054, -0.04123598709702492, 0.09400895982980728, 0.004406238440424204, -0.0997929722070694, 0.09115812182426453, -0.10109356790781021, 0.08241912722587585, -0.12330430001020432, -0.27929002046585083, -0.010083958506584167, -0.11006277799606323, -0.00850904081016779, -0.11684084683656693, -0.0143806217238307, -0.12571154534816742, 0.10397672653198242, -0.0801946222782135, -0.10186794400215149, -0.07807256281375885, -0.09643623977899551, 0.02637149766087532, -0.02735736221075058, 0.09085427969694138, -0.09054704010486603, 0.12823520600795746, -0.14356356859207153, 0.03734984248876572, -0.11956405639648438, 0.02151944488286972, 0.2410113364458084, -0.1263289600610733, 0.17501334846019745, 0.038962554186582565, -0.029952427372336388, -0.04240010306239128, 0.12748317420482635, -0.021365083754062653, 0.048782940953969955, -0.13581593334674835, 0.10462655127048492, 0.015951791778206825, 0.034552186727523804, -0.07967513054609299, 0.02822394110262394, -0.10683001577854156, 0.04048805311322212, -0.0231686569750309, 0.11491475999355316, 0.05455692857503891, 0.0278095081448555, 0.06485224515199661, -0.04932822287082672, 0.1452215313911438, -0.052409715950489044, -0.04071462154388428, -0.018323160707950592, -0.002739256015047431, -0.0552561990916729, 0.08140378445386887, 0.14204414188861847, 0.04717099666595459, 0.01770017296075821, -0.18472078442573547, 0.018632983788847923, -0.05049297213554382, -0.08925028145313263, 0.10911744087934494, 0.07066632807254791, 0.028379924595355988, -0.04665212333202362, 0.04538974165916443, 0.04900885000824928, 0.21819627285003662, -0.08922555297613144, 0.06637763977050781, 0.14584539830684662, 0.05958767980337143, -0.13140122592449188, -0.09293405711650848, -0.06836888194084167, 1.5365130574675916e-32, -0.14081542193889618, 0.06660356372594833, 0.0038479857612401247, -0.060226138681173325, 0.09986063092947006, -0.07300958782434464, -0.027166226878762245, 0.033225223422050476, -0.12919187545776367, -0.023070987313985825, -0.15397708117961884, 0.0593826062977314, 0.003095508785918355, 0.1278233677148819, -0.056905291974544525, -0.05744313821196556, 0.07497679442167282, -0.08951971679925919, 0.02046441286802292, -0.04502158612012863, 0.21606361865997314, -0.04676536098122597, 0.02142978459596634, -0.08796008676290512, -0.14828535914421082, -0.12260113656520844, 0.013993578962981701, -0.16416004300117493, -0.05208389088511467, -0.0020422309171408415, -0.32547661662101746, -0.13608480989933014, 0.07410820573568344, -0.043406661599874496, -0.011587859131395817, -0.10129152238368988, 0.11826306581497192, 0.05729175731539726, -0.07016807049512863, -0.18697762489318848, -0.009671052917838097, 0.0366673544049263, 0.07229877263307571, -0.10731126368045807, -0.1034257784485817, -0.018860194832086563, 0.009371494874358177, 0.11344321817159653, -0.07935567200183868, 0.061821453273296356, -0.02109638974070549, -0.06825843453407288, -0.06636174023151398, -0.03154166415333748, -0.06854423880577087, -0.030396105721592903, 0.10703281313180923, 0.01621859334409237, 0.1792885810136795, -0.01741478405892849, -0.027856433764100075, -0.03502314165234566, 0.03619575873017311, 0.09504562616348267, 0.02233661711215973, -0.023167332634329796, 0.13999389111995697, 0.06945431977510452, 0.08036026358604431, 0.036031149327754974, -0.065937839448452, 0.05730859935283661, -0.07453854382038116, -0.07563328742980957, -0.021430645138025284, -0.09942059218883514, 0.025679731741547585, -0.1402064710855484, -0.07441665977239609, 0.050243623554706573, 0.08123815804719925, 0.00817921943962574, -0.061883050948381424, -0.20203323662281036, -0.10984214395284653, -0.16146963834762573, 0.03352240473031998, -0.182020902633667, -0.052587490528821945, -0.1419287919998169, -0.17637813091278076, -0.03580673784017563, -0.0160274188965559, -0.10671805590391159, 0.06623819470405579, -1.6649416927666806e-32, 0.02928684465587139, 0.03738636150956154, -0.017087141051888466, 0.06738201528787613, 0.01920941472053528, -0.039967842400074005, 0.12930288910865784, 0.14002496004104614, 0.03498822823166847, -0.10277573764324188, -0.07881690561771393, -0.12438181042671204, 0.08948404341936111, -0.03807678073644638, 0.06639740616083145, 0.05587846040725708, -0.19007931649684906, 0.180070161819458, 0.013156997971236706, 0.08881521224975586, -0.17249126732349396, 0.07904624938964844, -0.016327733173966408, 0.061338696628808975, -0.03771853446960449, 0.13576410710811615, 0.12263970822095871, 0.08707526326179504, -0.020091155543923378, -0.05338897556066513, -0.10595593601465225, 0.02377084270119667, -0.122942715883255, 0.12285374104976654, -0.05223255231976509, 0.02308916673064232, 0.07983894646167755, -0.0930706039071083, -0.1614469438791275, 0.029651323333382607, 0.164540097117424, 0.1995638906955719, -0.14992853999137878, 0.003391813486814499, -0.04386906325817108, 0.02706265263259411, -0.12324101477861404, 0.0612889900803566, 0.049426671117544174, -0.04304320365190506, -0.0014654238475486636, 0.037724804133176804, -0.05803993344306946, 0.04562334716320038, -0.010663357563316822, -0.018709134310483932, -0.07550641894340515, 0.035391952842473984, -0.0797380730509758, -0.022215500473976135, -0.07459288835525513, -0.09937457740306854, -0.017960654571652412, -0.0398133248090744, 0.20328237116336823, -0.03361457213759422, -0.1531328409910202, 0.1017494946718216, -0.027860376983880997, 0.050081126391887665, -0.016770001500844955, 0.03263521566987038, 0.024938901886343956, -0.045232754200696945, 0.01709390990436077, 0.11887218803167343, -0.05544031038880348, -0.05398796871304512, -0.03989110887050629, 0.05278869345784187, -0.007256201934069395, -0.08669677376747131, 0.08624201267957687, 0.16934317350387573, -0.009374612011015415, 0.1156783476471901, 0.16405276954174042, 0.08690252900123596, 0.04136138781905174, -0.044269535690546036, 0.07454463094472885, -0.04053850099444389, 0.006398271303623915, 0.23791438341140747, 0.039959799498319626, -1.0047547505109833e-07, -0.09922361373901367, 0.018000198528170586, 0.010026512667536736, -0.0206818338483572, 0.0012858054833486676, -0.056427258998155594, 0.052964452654123306, -0.006818309426307678, -0.044869255274534225, -0.10300356149673462, 0.15602000057697296, -0.032347165048122406, -0.17411942780017853, -0.013713437132537365, -0.07292647659778595, 0.15191468596458435, -0.015008829534053802, 0.034970857203006744, 0.07020679861307144, 0.024113887920975685, 0.06146960332989693, 0.026056179776787758, 0.06410011649131775, 0.008764748461544514, -0.06925788521766663, -0.0822349414229393, -0.0996195524930954, 0.04260379076004028, 0.10054425895214081, -0.013501962646842003, -0.011558759026229382, -0.13196764886379242, 0.0886099636554718, -0.07217638194561005, -0.02372748591005802, 0.05839429050683975, 0.06072062626481056, -0.10283570736646652, -0.04222741723060608, 0.1101950854063034, -0.04346948862075806, 0.15866707265377045, -0.09819972515106201, -0.10599216818809509, 0.11271077394485474, 0.04083753749728203, -0.021465381607413292, -0.0032370169647037983, 0.12519249320030212, 0.003994579892605543, 0.01652524434030056, 0.02080243080854416, -0.10080768167972565, 0.0512419193983078, 0.09840625524520874, -0.029605263844132423, -0.1226530522108078, 0.06771375983953476, 0.08852077275514603, -0.007639260496944189, 0.05143096670508385, 0.02888132818043232, 0.11526104062795639, -0.027840951457619667], metadata={'source': 'AAAMLP-569to.pdf', 'page': 255}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 256     fin = io.open(         fname,          \\'r\\',          encoding=\\'utf-8\\',          newline=\\'\\\\n\\',          errors=\\'ignore\\'     )     n, d = map(int, fin.readline().split())     data = {}     for line in fin:         tokens = line.rstrip().split(\\' \\')         data[tokens[0]] = list(map(float, tokens[1:]))     return data   def create_embedding_matrix(word_index, embedding_dict):     \"\"\"     This function creates the embedding matrix.     :param word_index: a dictionary with word:index_value     :param embedding_dict: a dictionary with word:embedding_vector     :return: a numpy array with embedding vectors for all known words     \"\"\"     # initialize matrix with zeros     embedding_matrix = np.zeros((len(word_index) + 1, 300))     # loop over all the words     for word, i in word_index.items():         # if word is found in pre-trained embeddings,          # update the matrix. if the word is not found,         # the vector is zeros!         if word in embedding_dict:             embedding_matrix[i] = embedding_dict[word]     # return embedding matrix     return embedding_matrix   def run(df, fold):     \"\"\"     Run training and validation for a given fold     and dataset     :param df: pandas dataframe with kfold column     :param fold: current fold, int     \"\"\"      # fetch training dataframe     train_df = df[df.kfold != fold].reset_index(drop=True)      # fetch validation dataframe'),\n",
       " VectorParams(vector=[-0.05796188861131668, -0.14014911651611328, 0.016562413424253464, 0.007090735714882612, 0.038979433476924896, 0.05803266540169716, -0.000365217070793733, 0.06147148460149765, -0.1690623015165329, -0.1379106193780899, -0.007943173870444298, -0.05228152498602867, -0.09062138199806213, -0.03920980542898178, -0.11345291882753372, -0.009347731247544289, -0.0034301618579775095, 0.07315576821565628, -0.1584801822900772, -0.07351430505514145, 0.15277507901191711, 0.1093154177069664, 0.10029921680688858, 0.09623268246650696, -0.030726358294487, 0.007293535862118006, -0.04820753633975983, -0.02399124577641487, -0.05146951228380203, -0.026194978505373, 0.042454369366168976, 0.08655938506126404, 0.025227466598153114, 0.09556343406438828, 0.12806840240955353, -0.04405132308602333, -0.13634037971496582, -0.01863917149603367, 0.04758678376674652, 0.0543668232858181, 0.013463280163705349, -0.05183708667755127, -0.007385046221315861, 0.024578334763646126, 0.06596500426530838, 0.010560373775660992, 0.04289646074175835, -0.06641257554292679, 0.1553298532962799, 0.02776803821325302, -0.09646790474653244, 0.1147148460149765, -0.021081969141960144, 0.016699619591236115, -0.10242196172475815, -0.1572631150484085, 0.052204471081495285, 0.007806164678186178, 0.07026688754558563, -0.045943792909383774, 0.05824438855051994, -0.06767734885215759, 0.0176080334931612, -0.08151345700025558, -0.03278280422091484, -0.09550084918737411, -0.09098801761865616, 0.009223130531609058, -0.025539755821228027, 0.12427618354558945, -0.044799692928791046, 0.13244962692260742, -0.08082631975412369, 0.13179323077201843, -0.12418552488088608, 0.03574195131659508, 0.18427684903144836, -0.03781396523118019, 0.09158919751644135, -0.09347694367170334, -0.07221376895904541, -0.10428253561258316, 0.2662651538848877, 0.030596721917390823, 0.04112816974520683, -0.2210482507944107, 0.12338636070489883, 0.031356535851955414, 0.08363838493824005, 0.010675719007849693, 0.0769069492816925, -0.014295400120317936, 0.012378346174955368, 0.04411686211824417, 0.12809377908706665, 0.06186242029070854, 0.011050373315811157, 0.025489836931228638, -0.050711508840322495, 0.14876408874988556, -0.049893781542778015, -0.08101068437099457, -0.02212672494351864, 0.036460667848587036, 0.0025277300737798214, 0.041406817734241486, 0.08734987676143646, 0.035033561289310455, 0.06319256126880646, -0.09817291051149368, 0.0968708023428917, 0.10447061061859131, 0.016385618597269058, 0.021756906062364578, 0.21191594004631042, 0.06773078441619873, -0.07454244047403336, 0.08560330420732498, -0.09834819287061691, 0.209866464138031, -0.11259832233190536, 0.025107143446803093, -0.045814938843250275, 0.03943441063165665, -0.04909000173211098, -0.042370617389678955, -0.048793043941259384, 1.8691052250373418e-32, -0.10891024768352509, 0.0022777391131967306, 0.02775505930185318, -0.13093335926532745, -0.07000936567783356, -0.02405930683016777, -0.017725307494401932, 0.04813613370060921, -0.0781978890299797, -0.015642886981368065, -0.12211515009403229, -0.0728905126452446, -0.034452520310878754, 0.020104525610804558, -0.06664003431797028, -0.15299688279628754, -0.05350179225206375, -0.00040870593511499465, 0.022521190345287323, 0.026689989492297173, 0.12378369271755219, -0.08858592808246613, -0.062156833708286285, -0.0679803192615509, -0.16378095746040344, -0.06101604923605919, -0.014046425931155682, -0.017553919926285744, -0.08313829451799393, 0.024219004437327385, -0.31982818245887756, -0.027963787317276, 0.12221817672252655, 0.0016662835841998458, 0.005320866126567125, -0.12105916440486908, 0.04449706897139549, 0.07905430346727371, -0.011460398323833942, -0.15991124510765076, -0.062035609036684036, 0.1337800920009613, -0.04342541843652725, -0.05836847797036171, -0.08935772627592087, 0.014243929646909237, 0.05182400345802307, 0.04665611684322357, 0.021604524925351143, 0.03898600488901138, 0.0012848839396610856, -0.09623905271291733, 0.03208368644118309, -0.016454476863145828, -0.14802835881710052, 0.04225127398967743, 0.11525269597768784, 0.012865849770605564, 0.14837674796581268, -0.06259477883577347, 0.009991748258471489, 0.0030348459258675575, 0.024546030908823013, 0.03890297934412956, 0.044250939041376114, -0.002577523235231638, 0.038573313504457474, 0.02749553695321083, 0.040104251354932785, -0.07551727443933487, -0.20365893840789795, 0.07899018377065659, -0.008984575048089027, -0.10414062440395355, 0.03435855358839035, -0.221278578042984, 0.06812715530395508, -0.0192677341401577, -0.2296505868434906, 0.0016445746878162026, 0.015304832719266415, 0.08089234679937363, 0.015538213774561882, -0.22573579847812653, -0.05729372426867485, -0.0998287945985794, 0.016354689374566078, -0.058275140821933746, -0.010969103313982487, -0.0977693423628807, -0.140223428606987, -0.08047547936439514, 0.05405943840742111, 0.003912406042218208, 0.011818100698292255, -1.6113917537413836e-32, 0.061445996165275574, 0.041883017867803574, -0.012055309489369392, 0.052268460392951965, 0.020670240744948387, 0.05058516934514046, 0.07784992456436157, 0.11697248369455338, 0.04298589378595352, -0.10345824807882309, 0.03750641644001007, -0.1908399909734726, 0.0008775731548666954, -0.11304248124361038, -0.03603939712047577, -0.07296283543109894, -0.10988985747098923, 0.12047749012708664, -0.023478427901864052, 0.033947523683309555, -0.021722937002778053, 0.04602707549929619, -0.20648884773254395, 0.062212105840444565, -0.16527825593948364, 0.09647487848997116, -0.02407599240541458, 0.1576310247182846, 0.052054695785045624, -0.04530836269259453, 0.017119964584708214, 0.005486405920237303, -0.08201025426387787, 0.10847055912017822, 0.00944935530424118, -0.08672214299440384, 0.1044686883687973, -0.07060956954956055, -0.054343003779649734, 0.2055542767047882, 0.2496018409729004, 0.19149915874004364, -0.06953494250774384, 0.08337879925966263, -0.0620284304022789, 0.027900613844394684, -0.026302315294742584, 0.06219840422272682, -0.10982250422239304, -0.06003572419285774, -0.00897318683564663, -0.032133620232343674, -0.12728282809257507, 0.020886605605483055, -0.06066351756453514, -0.023580456152558327, 0.014042556285858154, -0.04052354767918587, -0.08229842782020569, 0.08375721424818039, -0.09603789448738098, -0.010588504374027252, 0.016474343836307526, -0.17485150694847107, 0.12392190843820572, -0.028515009209513664, -0.09656478464603424, 0.13576862215995789, 0.026494808495044708, 0.07438290864229202, -0.06837080419063568, 0.05923370644450188, 0.04357985407114029, 0.05882254242897034, 0.05991489440202713, 0.056896235793828964, -0.042482275515794754, -0.02314116805791855, 0.08548574894666672, -0.01764591969549656, -0.06383834779262543, -0.04324031621217728, 0.08384918421506882, 0.06643795967102051, 0.10714355111122131, 0.1941366046667099, 0.07614544034004211, 0.19798573851585388, 0.0057514687068760395, -0.06128348037600517, 0.03851757571101189, -0.1433992087841034, 0.22939524054527283, 0.13736821711063385, 0.010716643184423447, -1.0071305922565443e-07, -0.07742141932249069, -0.037402451038360596, -0.015258547849953175, 0.15819662809371948, -0.02492687478661537, -0.009000306017696857, 0.057158395648002625, 0.11320860683917999, 0.07038824260234833, -0.06781807541847229, 0.051779311150312424, 0.05242142081260681, -0.15799348056316376, -0.049960870295763016, -0.08109037578105927, 0.03857451677322388, -0.07904120534658432, 0.08349879086017609, -0.013130385428667068, 0.09081989526748657, 0.06935203820466995, -0.09881958365440369, 0.00025193727924488485, -0.0437563955783844, 0.03763016313314438, -0.11509868502616882, 0.013656605035066605, 0.07068642228841782, -0.07410641759634018, -0.024556921795010567, -0.0021803677082061768, -0.07273738831281662, 0.019403865560889244, -0.05332041159272194, 0.03263263404369354, 0.11266137659549713, 0.09116511046886444, -0.0845223069190979, 0.02965576946735382, 0.17750631272792816, -0.06002615764737129, 0.10740802437067032, -0.1137886494398117, -0.13568821549415588, 0.020872609689831734, -0.009774522855877876, 0.06991078704595566, -0.06255199015140533, 0.14376488327980042, -0.05091431736946106, -0.01532386802136898, 0.062470272183418274, -0.10689661651849747, 0.09005236625671387, 0.13100965321063995, -0.053134918212890625, -0.14380429685115814, 0.0799541100859642, -0.023243095725774765, 0.03246929869055748, 0.06629449129104614, 0.02780056931078434, 0.005451058968901634, -0.053513869643211365], metadata={'source': 'AAAMLP-569to.pdf', 'page': 256}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 257     valid_df = df[df.kfold == fold].reset_index(drop=True)      print(\"Fitting tokenizer\")     # we use tf.keras for tokenization     # you can use your own tokenizer and then you can      # get rid of tensorflow     tokenizer = tf.keras.preprocessing.text.Tokenizer()     tokenizer.fit_on_texts(df.review.values.tolist())      # convert training data to sequences     # for example : \"bad movie\" gets converted to     # [24, 27] where 24 is the index for bad and 27 is the     # index for movie     xtrain = tokenizer.texts_to_sequences(train_df.review.values)      # similarly convert validation data to     # sequences     xtest = tokenizer.texts_to_sequences(valid_df.review.values)      # zero pad the training sequences given the maximum length     # this padding is done on left hand side     # if sequence is > MAX_LEN, it is truncated on left hand side too     xtrain = tf.keras.preprocessing.sequence.pad_sequences(         xtrain, maxlen=config.MAX_LEN     )      # zero pad the validation sequences     xtest = tf.keras.preprocessing.sequence.pad_sequences(         xtest, maxlen=config.MAX_LEN     )      # initialize dataset class for training     train_dataset = dataset.IMDBDataset(         reviews=xtrain,         targets=train_df.sentiment.values     )      # create torch dataloader for training     # torch dataloader loads the data using dataset     # class in batches specified by batch size     train_data_loader = torch.utils.data.DataLoader(         train_dataset,         batch_size=config.TRAIN_BATCH_SIZE,         num_workers=2     )      # initialize dataset class for validation'),\n",
       " VectorParams(vector=[-0.10849925875663757, -0.18218952417373657, -0.025791330263018608, 0.0934080258011818, 0.06164272129535675, -0.09163134545087814, -0.04028993099927902, 0.09380195289850235, -0.19348691403865814, -0.11500822752714157, -0.006231334991753101, -0.16342169046401978, -0.02666443958878517, -0.08704861253499985, -0.11462479084730148, 0.13851051032543182, 0.06560312211513519, -0.035858914256095886, -0.16432102024555206, -0.14831630885601044, 0.11790435761213303, 0.04896467924118042, 0.12182676047086716, 0.03705436736345291, 0.009350243955850601, -0.0774955227971077, -0.045331649482250214, 0.05797558277845383, 0.04908093810081482, -0.043312400579452515, 0.149321511387825, 0.004606793634593487, -0.0947539210319519, 0.14637359976768494, 0.11595728993415833, -0.026220742613077164, -0.13511615991592407, -0.16273373365402222, -0.09169089049100876, 0.07431872934103012, 0.06720145046710968, -0.036246586591005325, -0.10607322305440903, -0.002121350262314081, 0.04324829950928688, -0.0029453220777213573, 0.00746319442987442, -0.03218745440244675, 0.10618707537651062, -0.03542204573750496, -0.10925322771072388, 0.015779295936226845, -0.008169583044946194, 0.012654789723455906, -0.09560280293226242, -0.14178384840488434, 0.09210211038589478, -0.07893198728561401, 0.05545147508382797, -0.14851389825344086, 0.04512748867273331, -0.0636659488081932, 0.01512854639440775, -0.0525989830493927, -0.07302484661340714, -0.08000056445598602, -0.0952853187918663, -0.016126180067658424, 0.037758637219667435, 0.07691966742277145, 0.1070924773812294, 0.08455690741539001, -0.10167442262172699, 0.0969381332397461, -0.11369144171476364, 0.02174011990427971, 0.2076282650232315, -0.024278026074171066, 0.07624770700931549, -0.17520715296268463, -0.132597416639328, -0.07330461591482162, 0.14687593281269073, 0.025404345244169235, 0.12281009554862976, -0.19564493000507355, 0.16567187011241913, 0.07652782648801804, 0.03783087059855461, -0.0008311898563988507, 0.027281900867819786, -0.016765860840678215, -0.09206223487854004, 0.0500585176050663, 0.1657499521970749, 0.05916738882660866, 0.0673937126994133, -0.04219777137041092, -0.1791401356458664, 0.11161641031503677, -0.056177228689193726, -0.011813129298388958, -0.05598241090774536, 0.08875168114900589, -0.053608205169439316, 0.05998707935214043, 0.12327894568443298, 0.11730559915304184, -0.02943258173763752, -0.11726056039333344, 0.10155929625034332, 0.10906189680099487, -0.0535656213760376, 0.016278743743896484, 0.16952581703662872, -0.009554574266076088, -0.07389670610427856, 0.05683330073952675, -0.08719851076602936, 0.22426821291446686, -0.08897162973880768, 0.08079324662685394, -0.09948912262916565, 0.0852576419711113, -0.05777495726943016, -0.05196498706936836, -0.07587122172117233, 1.9068831155472746e-32, -0.05798474699258804, -0.03567420691251755, -0.11311991512775421, -0.15438894927501678, -0.01837027259171009, 0.07673809677362442, 0.014502272009849548, 0.08628611266613007, -0.17182780802249908, -0.009608819149434566, -0.2477281242609024, 0.02351168543100357, -0.056063853204250336, 0.04016999527812004, -0.1021420881152153, -0.06085924804210663, 0.03041241504251957, 0.02690848708152771, 0.0824088379740715, 0.025340164080262184, 0.1859976351261139, -0.10146514326334, -0.09669211506843567, -0.07925095409154892, -0.18483759462833405, 0.11188139021396637, -0.024647550657391548, -0.06480517983436584, -0.09708573669195175, 0.046327587217092514, -0.2270672768354416, -0.010281170718371868, 0.09380383044481277, 0.014663460664451122, -0.020350418984889984, -0.1198512464761734, 0.08034201711416245, 0.08307529985904694, 0.006835956126451492, -0.1627061814069748, -0.05569864436984062, 0.10706400871276855, 0.03174961358308792, -0.1456385999917984, -0.13649822771549225, 0.014255273155868053, -0.06326326727867126, 0.09087824821472168, -0.008656419813632965, 0.03813784942030907, -0.006404570769518614, -0.05026915669441223, -0.012391248717904091, -0.03158342093229294, -0.05503060668706894, -0.053191691637039185, 0.12817861139774323, 0.050290338695049286, 0.24097603559494019, -0.10091044008731842, 0.09243100136518478, 0.04223316162824631, -0.002702297642827034, -0.01547140721231699, 0.06473340094089508, 0.03888712450861931, 0.03854060918092728, 0.02195572853088379, 0.007890298031270504, 0.048094768077135086, -0.18556803464889526, 0.05128968507051468, 0.054585929960012436, -0.10051363706588745, 0.12778516113758087, -0.16950391232967377, 0.040845952928066254, -0.12580467760562897, -0.21648943424224854, 0.06057983636856079, -0.052007511258125305, 0.06752761453390121, -0.07476992160081863, -0.2631613314151764, -0.10245520621538162, -0.15179118514060974, 0.03662495315074921, -0.022584620863199234, -0.08441463112831116, -0.01778125762939453, -0.16511522233486176, -0.08947991579771042, 0.10278840363025665, 0.014254378154873848, -0.10284226387739182, -1.694689046682177e-32, -0.04164598509669304, 0.1257956624031067, 0.07352814823389053, 0.09968648850917816, 0.07040531933307648, -0.0334697961807251, 0.043747302144765854, 0.059497419744729996, -0.05312521755695343, -0.037938397377729416, 0.08159007132053375, -0.18390440940856934, -0.027638468891382217, -0.07641130685806274, 0.08420687913894653, -0.049319684505462646, -0.10062211751937866, 0.05108095332980156, 0.03365791216492653, 0.09373576194047928, -0.16721594333648682, 0.2182139754295349, -0.23636923730373383, 0.08459150791168213, -0.1409107893705368, 0.07490133494138718, 0.0056169056333601475, 0.07422398775815964, 0.014779875054955482, -0.13057446479797363, 0.006350983865559101, 0.07197801768779755, -0.1743965893983841, 0.09924008697271347, 0.020591625943779945, 0.0547061413526535, 0.148350790143013, -0.1263301521539688, -0.03578408434987068, 0.12976372241973877, 0.32505932450294495, 0.1594671607017517, -0.1650044322013855, 0.11883313208818436, -0.05317486450076103, 0.04749833419919014, -0.06947305798530579, 0.07343587279319763, -0.055665358901023865, -0.03150865063071251, 0.06352799385786057, -0.038979265838861465, -0.05162174254655838, 0.06668589264154434, 0.0067499130964279175, -0.03347655385732651, 0.003583835670724511, -0.06131478771567345, -0.09675624966621399, 0.07058661431074142, -0.055323708802461624, -0.07449564337730408, 0.015304388478398323, -0.13525213301181793, 0.04280335083603859, 0.011135631240904331, -0.09016618877649307, 0.21548599004745483, 0.02819892391562462, 0.11908774077892303, -0.10503467917442322, 0.15313665568828583, 0.17006443440914154, 0.05028945952653885, -0.051604099571704865, 0.09100310504436493, -0.11868030577898026, -0.07255245000123978, 0.08430080115795135, -0.004107870161533356, -0.0880400538444519, -0.005643699783831835, 0.08380020409822464, 0.11152984201908112, 0.13599544763565063, 0.14257600903511047, 0.054719775915145874, 0.20204846560955048, 0.06931108981370926, -0.0905178040266037, 0.05684051662683487, -0.07294167578220367, 0.1233610138297081, 0.1872577667236328, 0.08102975785732269, -1.008861971740771e-07, -0.056681402027606964, 0.010225438512861729, 0.06445088982582092, 0.1655639111995697, 0.06877340376377106, -0.002544860355556011, 0.028700705617666245, 0.07177535444498062, 0.05133150890469551, 0.002085922984406352, 0.17246219515800476, -0.026125818490982056, -0.11921070516109467, -0.029037509113550186, -0.00799378752708435, 0.13110242784023285, 0.021739911288022995, 0.010364537127315998, 0.09765351563692093, -0.05476000905036926, 0.012889574281871319, -0.02945396490395069, -0.0017662724712863564, -0.03434678167104721, -0.022906962782144547, -0.11823390424251556, -0.03345966711640358, 0.06962762773036957, -0.10183601081371307, -0.01955818571150303, 0.01857973262667656, -0.07544708997011185, 0.08458568155765533, 0.0049824160523712635, 0.059349630028009415, 0.15625040233135223, 0.08542516082525253, 0.04509422555565834, 0.060931116342544556, 0.037293560802936554, -0.043246474117040634, 0.1718686819076538, -0.09006354957818985, -0.17361445724964142, 0.03562857210636139, 0.03910604864358902, -0.014949674718081951, -0.09709865599870682, 0.058394912630319595, 0.06390315294265747, 0.007711546495556831, -0.02845204807817936, -0.09972680360078812, 0.15730880200862885, 0.11002764850854874, -0.18984787166118622, -0.1025395616889, -0.06998159736394882, -0.03304653242230415, 0.024361010640859604, 0.08840763568878174, 0.02398018166422844, -0.044822681695222855, -0.06061761826276779], metadata={'source': 'AAAMLP-569to.pdf', 'page': 257}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 258     valid_dataset = dataset.IMDBDataset(         reviews=xtest,         targets=valid_df.sentiment.values     )          # create torch dataloader for validation     valid_data_loader = torch.utils.data.DataLoader(         valid_dataset,         batch_size=config.VALID_BATCH_SIZE,         num_workers=1     )      print(\"Loading embeddings\")     # load embeddings as shown previously     embedding_dict = load_vectors(\"../input/crawl-300d-2M.vec\")     embedding_matrix = create_embedding_matrix(         tokenizer.word_index, embedding_dict     )      # create torch device, since we use gpu, we are using cuda     device = torch.device(\"cuda\")      # fetch our LSTM model     model = lstm.LSTM(embedding_matrix)      # send model to device     model.to(device)          # initialize Adam optimizer     optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)      print(\"Training Model\")     # set best accuracy to zero     best_accuracy = 0     # set early stopping counter to zero     early_stopping_counter = 0     # train and validate for all epochs     for epoch in range(config.EPOCHS):         # train one epoch         engine.train(train_data_loader, model, optimizer, device)         # validate         outputs, targets = engine.evaluate(                                valid_data_loader, model, device         )          # use threshold of 0.5          # please note we are using linear layer and no sigmoid'),\n",
       " VectorParams(vector=[-0.0733216404914856, -0.08990449458360672, -0.030396396294236183, -0.009400365874171257, 0.11253207176923752, -0.10630224645137787, -0.03862273693084717, 0.10341376811265945, -0.18794962763786316, -0.03728056699037552, -0.0049100336618721485, -0.118365079164505, -0.08091326057910919, -0.08255454152822495, -0.1197851300239563, 0.06563569605350494, -0.13506309688091278, 0.02921615168452263, -0.06256576627492905, -0.1454198807477951, 0.03800215199589729, 0.05646537244319916, 0.0798768550157547, 0.06189149245619774, -0.11772064119577408, -0.043857719749212265, -0.07212032377719879, -0.027253037318587303, -0.10154770314693451, -0.021241212263703346, 0.02938704378902912, 0.019757186993956566, 0.039595697075128555, 0.05828163027763367, 0.09249427169561386, 0.10279244184494019, -0.11998321861028671, -0.06670629233121872, -0.07446775585412979, 0.07253704220056534, 0.040886763483285904, -0.02624340169131756, 0.008007113821804523, 0.011837014928460121, 0.034379974007606506, 0.05984393134713173, -0.08397454023361206, 0.003463472006842494, 0.06430408358573914, 0.02431461401283741, -0.11665867269039154, 0.10561716556549072, -0.06877362728118896, -0.007850530557334423, -0.11044478416442871, -0.06074304133653641, 0.11371095478534698, 0.019380735233426094, 0.008032353594899178, -0.019846241921186447, -0.03316721320152283, -0.09879617393016815, -0.09646743535995483, -0.13061538338661194, 0.044205442070961, -0.010736612603068352, -0.02487100660800934, -0.007542511448264122, 0.02514168992638588, 0.10418636351823807, 0.004511458799242973, 0.11332118511199951, -0.11793949455022812, 0.025690702721476555, -0.07401219755411148, -0.13549456000328064, 0.20341192185878754, -0.09971454739570618, 0.03428193926811218, -0.10562577843666077, -0.08957353979349136, -0.06851593405008316, 0.04449520260095596, -0.0890226736664772, 0.01494584884494543, -0.09677057713270187, 0.07899056375026703, 0.09059089422225952, 0.01612059772014618, -0.05768778547644615, 0.07685969024896622, -0.08199712634086609, -0.14805035293102264, 0.032757461071014404, 0.08155760169029236, 0.19805116951465607, 0.04005805402994156, -0.021402519196271896, -0.013850673101842403, 0.0327068567276001, 0.017588581889867783, -0.06610742956399918, 0.04321792349219322, 0.04003975912928581, 0.128851518034935, 0.011959747411310673, 0.22571223974227905, 0.07058403640985489, -0.016281679272651672, -0.07504461705684662, 0.14144696295261383, 0.014897221699357033, 0.025951365008950233, 0.0033882942516356707, 0.19409340620040894, 0.16022492945194244, -0.01912509836256504, 0.13787543773651123, -0.12228859961032867, 0.1667405515909195, -0.17233505845069885, 0.09425318986177444, -0.01847868412733078, 0.039989400655031204, -0.10298585146665573, -0.005097739398479462, -0.04733360558748245, 1.2981032605272492e-32, -0.12586955726146698, -0.09660283476114273, 0.027512026950716972, -0.13370953500270844, -0.0058930255472660065, 0.011823233217000961, -0.04878964275121689, 0.0507332943379879, -0.1057700514793396, 0.06198141723871231, -0.2324245274066925, -0.06231531500816345, -0.08788780122995377, -0.0051438407972455025, 0.05331946536898613, -0.17125678062438965, 0.0808267593383789, -0.031225191429257393, 0.027600321918725967, 0.004418164025992155, 0.2612827718257904, -0.10334092378616333, -0.02740945853292942, -0.043000075966119766, -0.010713677853345871, 0.028521070256829262, -0.08599396795034409, 0.05984263867139816, -0.13034483790397644, 0.009043697267770767, -0.19721871614456177, 0.006366606801748276, -0.046328525990247726, -0.03248491510748863, 0.0009369130712002516, -0.15773113071918488, 0.07053695619106293, 0.11209001392126083, -0.03192159906029701, -0.0878402441740036, -0.1338786482810974, 0.10558151453733444, 0.0816500335931778, -0.05661185458302498, -0.133432999253273, -0.036478765308856964, 0.03139166161417961, 0.1617755889892578, 0.019276123493909836, 0.07451712340116501, 0.01192555669695139, -0.03652350977063179, 0.005130245815962553, -0.07137409597635269, -0.07522479444742203, 0.0533943846821785, 0.14478467404842377, -0.04249344393610954, 0.0694945901632309, -0.0374719500541687, 0.14728373289108276, -0.016896218061447144, -0.03530093654990196, 0.019934358075261116, -0.0001818903983803466, 0.03305145353078842, 0.1598077118396759, 0.08177303522825241, 0.07350403815507889, 0.018227718770503998, -0.1824781447649002, 0.09492691606283188, -0.0297536738216877, -0.12767021358013153, 0.16962365806102753, -0.016557779163122177, 0.1422080546617508, -0.012344972230494022, -0.045656315982341766, -0.015000327490270138, 0.06183178350329399, 0.16853664815425873, -0.026552846655249596, -0.21273498237133026, -0.023276085034012794, 0.010938853956758976, 0.05826389044523239, 0.03566857427358627, -0.14712265133857727, -0.09627160429954529, -0.20169588923454285, -0.01609788089990616, 0.07884929329156876, -0.009997503831982613, -0.16898874938488007, -1.3263267329536985e-32, 0.08226440101861954, 0.07096492499113083, 0.0752616673707962, 0.028438637033104897, 0.10376012325286865, 0.06325390934944153, 0.0072595952078700066, 0.042312003672122955, -0.12710517644882202, -0.04203205555677414, 0.005628692451864481, -0.12690231204032898, 0.033954933285713196, -0.002292164135724306, 0.015924863517284393, -0.001585683785378933, -0.04448625072836876, 0.15855184197425842, -0.04351840540766716, 0.01645040512084961, -0.04029488191008568, 0.08557649701833725, -0.15282675623893738, 0.03719229996204376, -0.12221433967351913, 0.0168289877474308, -0.07257483899593353, 0.024571247398853302, -0.005336044356226921, -0.12247712910175323, -0.08580322563648224, 0.03182797133922577, -0.10253433138132095, 0.14469099044799805, 0.11504082381725311, 0.0040570590645074844, 0.03955794870853424, -0.07843910157680511, -0.011573239229619503, 0.15121467411518097, 0.2165749967098236, 0.20470775663852692, -0.21388985216617584, 0.11875242739915848, 0.03257380798459053, 0.027050642296671867, -0.02605666033923626, 0.10246572643518448, -0.18432201445102692, -0.03688054531812668, -0.08639837801456451, -0.02199212647974491, -0.05307086184620857, 0.021349770948290825, -0.011830690316855907, 0.04286697506904602, -0.0028666711878031492, -0.01603170856833458, -0.11729416996240616, 0.01699071191251278, -0.09185203164815903, -0.08531241118907928, -0.10430418699979782, -0.04042939469218254, 0.11901429295539856, 0.09986930340528488, -0.18607670068740845, 0.10645230859518051, 0.040898337960243225, 0.050752099603414536, -0.041117943823337555, 0.014628235250711441, 0.04882676154375076, -0.09392175823450089, -0.13727910816669464, 0.0505550317466259, -0.15119348466396332, -0.07462387531995773, 0.020398445427417755, 0.11037042737007141, -0.0434812493622303, -0.0394003763794899, 0.1021595373749733, 0.24296747148036957, -0.04399414733052254, 0.15900327265262604, 0.08073253184556961, -0.021738693118095398, 0.18139521777629852, 0.06486992537975311, -0.008180850185453892, 0.015508265234529972, 0.1244993731379509, 0.16726230084896088, -0.06560322642326355, -1.0017875951007227e-07, 0.03945270925760269, 0.0567014180123806, 0.03636758029460907, 0.07778690755367279, 0.0607190765440464, 0.07990914583206177, -0.04991968721151352, 0.06910524517297745, -0.008407053537666798, 0.05844529718160629, 0.09084627777338028, -0.05691182240843773, -0.1614990383386612, 0.0992605984210968, -0.05019797757267952, 0.05382104590535164, 0.08780867606401443, 0.10660433769226074, 0.014289544895291328, 0.03392352536320686, 0.06459320336580276, 0.006579069420695305, 0.02511095441877842, -0.009862889535725117, -0.06395942717790604, -0.08995835483074188, -0.0875048041343689, 0.06607189774513245, -0.04051131382584572, 0.00789449829608202, -0.02980443835258484, -0.0933552160859108, -0.0009862607112154365, 0.020282505080103874, 0.017755484208464622, 0.10752030462026596, 0.03158463165163994, -0.0023435570765286684, 0.06689835339784622, 0.11905238777399063, -0.06987538188695908, 0.12454664707183838, -0.1273336559534073, 0.009114922024309635, 0.01932954229414463, -0.05296529084444046, 0.04355820640921593, -0.04762857407331467, 0.10705410689115524, 0.006218979135155678, 0.017504511401057243, -0.05675309896469116, -0.047042179852724075, 0.13417035341262817, 0.145369753241539, -0.05302271246910095, -0.1438603550195694, 0.008716955780982971, -0.05678486451506615, 0.019617287442088127, -0.058478932827711105, -0.005971065256744623, 0.011698677204549313, -0.048547517508268356], metadata={'source': 'AAAMLP-569to.pdf', 'page': 258}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 259         # you should do this 0.5 threshold after sigmoid         outputs = np.array(outputs) >= 0.5          # calculate accuracy         accuracy = metrics.accuracy_score(targets, outputs)         print(           f\"FOLD:{fold}, Epoch: {epoch}, Accuracy Score = {accuracy}\"         )          # simple early stopping         if accuracy > best_accuracy:             best_accuracy = accuracy         else:             early_stopping_counter += 1          if early_stopping_counter > 2:             break   if __name__ == \"__main__\":      # load data     df = pd.read_csv(\"../input/imdb_folds.csv\")      # train for all folds     run(df, fold=0)     run(df, fold=1)     run(df, fold=2)     run(df, fold=3)     run(df, fold=4) ═════════════════════════════════════════════════════════════════════════  And finally, we have config.py.  ═════════════════════════════════════════════════════════════════════════ # config.py # we define all the configuration here MAX_LEN = 128 TRAIN_BATCH_SIZE = 16 VALID_BATCH_SIZE = 8 EPOCHS = 10 ═════════════════════════════════════════════════════════════════════════  Let’s see what this gives us.'),\n",
       " VectorParams(vector=[-0.08213439583778381, -0.20086313784122467, 0.000838832464069128, 0.008964483626186848, 0.007345439866185188, 0.12063691020011902, -0.15277764201164246, 0.09796718508005142, -0.1075325608253479, -0.09490261971950531, -0.007755330763757229, -0.00558115541934967, 0.027005832642316818, 0.07209176570177078, -0.08601757138967514, 0.06186036765575409, 0.018894672393798828, 0.18170768022537231, -0.15625646710395813, -0.0259216520935297, 0.19110514223575592, 0.031086165457963943, 0.10561423003673553, -0.08505880832672119, -0.019031569361686707, -0.050464481115341187, 0.010760755278170109, 0.06263022869825363, -0.03813634812831879, -0.006641101092100143, 0.16813449561595917, 0.12175486981868744, 0.014235075563192368, 0.10737667977809906, -0.1296994835138321, 0.08151143789291382, -0.1229422464966774, -0.09643256664276123, -0.06380077451467514, 0.037979647517204285, 0.040302760899066925, 0.03670961782336235, -0.06503959745168686, 0.012859009206295013, 0.18464575707912445, -0.06650878489017487, -0.07275894284248352, -0.06402399390935898, 0.035427432507276535, 0.05206344276666641, -0.0683571845293045, 0.06641463935375214, -0.1383683830499649, 0.059592217206954956, -0.18366652727127075, -0.18833014369010925, 0.02414487674832344, -0.007217527367174625, -0.05756397545337677, -0.09889493137598038, -0.018688473850488663, -0.05228211730718613, -0.005866070277988911, -0.08478222787380219, -0.035765986889600754, -0.040469586849212646, 0.024563131853938103, 0.05708732455968857, 0.08503913879394531, 0.09937085956335068, -0.09313037246465683, 0.11542031168937683, -0.031765908002853394, -0.028768809512257576, -0.08475956320762634, -0.002133849309757352, 0.2088789939880371, -0.06700561195611954, 0.04815176874399185, -0.10460568219423294, 0.09424404054880142, 0.0036139870062470436, 0.09392548352479935, 0.0014189919456839561, 0.0641876608133316, -0.1051599457859993, 0.0713166743516922, 0.10208665579557419, -0.04084676131606102, -0.1478409469127655, 0.09406423568725586, -0.13403742015361786, -0.07057055830955505, -0.007122742477804422, 0.13763025403022766, 0.1739341765642166, 0.07231296598911285, -0.01903577893972397, -0.0680423155426979, 0.036067213863134384, 0.01114264503121376, -0.0023959968239068985, 0.03393050655722618, 0.07013407349586487, 0.0871424525976181, 0.1018553301692009, 0.10617229342460632, -0.0061668409034609795, 0.019616520032286644, -0.13031134009361267, 0.07789096236228943, -0.049894701689481735, -0.09822069853544235, -0.09541843831539154, 0.18750736117362976, 0.09366972744464874, -0.0007526581175625324, -0.01042431965470314, 0.03087908960878849, 0.24555213749408722, -0.1317194104194641, 0.09256206452846527, 0.08937494456768036, 0.0025295810773968697, -0.04958108440041542, -0.06669002026319504, -0.10783335566520691, 1.5745523485337885e-32, -0.01632285676896572, -0.023483533412218094, -0.028381410986185074, -0.01297721266746521, 0.12463539838790894, -0.12899377942085266, 0.05985073000192642, 0.0669521689414978, -0.1793994903564453, 0.0003599533811211586, -0.1860049068927765, 0.12145080417394638, -0.06322325766086578, 0.12673231959342957, 0.05021363124251366, -0.06572065502405167, -0.11224649101495743, -0.05738764628767967, 0.06776392459869385, 0.019682709127664566, 0.023725666105747223, -0.0815138965845108, 0.07971742749214172, -0.03273319825530052, -0.0587843656539917, 0.021275967359542847, 0.0999905988574028, -0.1611500382423401, -0.11725303530693054, -0.024251529946923256, -0.18814241886138916, -0.09428605437278748, 0.04733700305223465, -0.06098323315382004, -0.06931665539741516, -0.1637382060289383, -0.014397362247109413, 0.06472751498222351, -0.07290591299533844, -0.26130494475364685, -0.024459654465317726, 0.007460941094905138, 0.12973423302173615, -0.1553153544664383, -0.08100409060716629, -0.012589389458298683, 0.040956705808639526, 0.13877660036087036, -0.09612756967544556, 0.07815754413604736, 0.16792404651641846, -0.015230130404233932, -0.1664838045835495, -0.06945396959781647, -0.09752288460731506, -0.03391459956765175, 0.16004905104637146, 0.08714352548122406, 0.1271483451128006, -0.025334486737847328, 0.046345338225364685, 0.04014047607779503, 0.09604916721582413, 0.13382194936275482, 0.04455708712339401, -0.01969897747039795, 0.07324577867984772, 0.0541502870619297, 0.059860944747924805, 0.022171182557940483, -0.16712847352027893, 0.04596280679106712, -0.053759004920721054, -0.10295204073190689, 0.0441705659031868, -0.01470198854804039, 0.07512618601322174, -0.15464526414871216, -0.09633129835128784, 0.10905592143535614, 0.08883063495159149, 0.03213542327284813, 0.023278523236513138, -0.17113107442855835, -0.12414398789405823, -0.1415673941373825, 0.11522972583770752, -0.22404760122299194, -0.0046710725873708725, -0.07326491922140121, -0.1323401778936386, -0.03627818077802658, 0.07808482646942139, -0.0440523587167263, -0.03297927975654602, -1.322669182281115e-32, 0.08725204318761826, 0.05858288332819939, -0.04798606038093567, 0.06418796628713608, 0.1039225310087204, -0.03941532224416733, 0.17655989527702332, 0.21097493171691895, -0.13214290142059326, -0.07160509377717972, -0.007072174921631813, -0.11138363182544708, 0.0831189751625061, -0.08586354553699493, 0.12337683141231537, 0.06665512174367905, -0.14489981532096863, 0.019915960729122162, 0.030813593417406082, 0.10196702927350998, -0.04871506989002228, 0.13639315962791443, -0.06043758615851402, 0.03858434781432152, -0.07799473404884338, 0.053314320743083954, 0.019588612020015717, 0.06313326209783554, 0.04564661532640457, -0.11012248694896698, -0.057616546750068665, -0.02279893308877945, -0.08476541936397552, 0.06819094717502594, -0.10920852422714233, 0.05338206887245178, 0.08353251963853836, -0.13467516005039215, -0.005358322523534298, 0.034802693873643875, 0.2642151117324829, 0.19987225532531738, -0.14400023221969604, -0.03348470479249954, 0.0012092707911506295, 0.030685894191265106, -0.2342519760131836, 0.000997026450932026, -0.03122873231768608, -0.0373149998486042, -0.02948569878935814, 0.06692682951688766, -0.1059650331735611, -0.019095584750175476, 0.030616600066423416, -0.06802878528833389, -0.09773261845111847, -0.1228427141904831, 4.2168423533439636e-05, -0.008922452107071877, -0.0867452546954155, -0.08927536010742188, -0.044338129460811615, -0.12734247744083405, 0.12849944829940796, 0.005325839854776859, -0.1435982584953308, -0.018187372013926506, -0.10520195960998535, 0.11506173014640808, -0.015833353623747826, 0.050467077642679214, 0.052860796451568604, 0.038195542991161346, 0.0024416763335466385, 0.08920641243457794, -0.09993462264537811, 0.04327889159321785, 0.01353597640991211, -0.10700661689043045, -0.007383417803794146, -0.046624697744846344, -0.0320010706782341, 0.19476360082626343, 0.042112983763217926, 0.18696489930152893, 0.05262375250458717, 0.13555458188056946, 0.20659416913986206, 0.0030881501734256744, 0.04771386459469795, 0.09351344406604767, 0.10576075315475464, 0.16694800555706024, 0.09466031938791275, -9.961414093595522e-08, -0.08313080668449402, 0.12800246477127075, 0.05871079862117767, 0.08224376291036606, -0.0422944538295269, -0.12631793320178986, 0.0659254863858223, 0.10863728821277618, -0.019408486783504486, -0.03326679766178131, 0.15453390777111053, -0.031515538692474365, -0.2456778585910797, 0.03227533772587776, -0.09223733097314835, 0.1459583342075348, 0.009571894071996212, 0.06693833321332932, 0.05539952218532562, 0.007082479540258646, 0.14688235521316528, 0.10075268149375916, -0.004279693588614464, 0.08063945174217224, -0.03165271878242493, -0.057499904185533524, -0.09899251163005829, 0.010549570433795452, -0.021779075264930725, 0.018373120576143265, 0.05187185853719711, -0.03631330281496048, -0.02102498710155487, -0.055912502110004425, -0.07180389016866684, 0.10331965982913971, -0.026484224945306778, -0.11561711877584457, -0.0646338015794754, 0.18491807579994202, 0.09419796615839005, 0.09566451609134674, -0.07973550260066986, -0.1243615448474884, 0.07251395285129547, -0.03290248289704323, 0.0062494222074747086, -0.2383539080619812, 0.09361328184604645, 0.04168824851512909, -0.019983995705842972, 0.0020199865102767944, -0.12937042117118835, 0.004606885369867086, 0.09674602746963501, 0.05096115916967392, -0.04459597170352936, 0.05049800127744675, 0.043115317821502686, 0.017814073711633682, -0.12209290266036987, 0.06143824756145477, 0.04735226556658745, 0.09272502362728119], metadata={'source': 'AAAMLP-569to.pdf', 'page': 259}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 260 ═════════════════════════════════════════════════════════════════════════ ❯ python train.py  FOLD:0, Epoch: 3, Accuracy Score = 0.9015 FOLD:1, Epoch: 4, Accuracy Score = 0.9007 FOLD:2, Epoch: 3, Accuracy Score = 0.8924 FOLD:3, Epoch: 2, Accuracy Score = 0.9 FOLD:4, Epoch: 1, Accuracy Score = 0.878 ═════════════════════════════════════════════════════════════════════════  This is by far the best score we have obtained. Please note that I have only shown the epochs with best accuracies in each fold.  You must have noticed that we used pre-trained embeddings and a simple bi-directional LSTM. If you want to change the model, you can just change model in lstm.py and keep everything as it is. This kind of code requires minimal changes for experiments and is easily understandable. For example, you can learn the embeddings on your own instead of using pretrained embeddings, you can use some other pretrained embeddings, you can combine multiple pretrained embeddings, you can use GRU, you can use spatial dropout after embedded, you can add a GRU layer after LSTM, you can add two LSTM layers, you can have LSTM-GRU-LSTM config, you can replace LSTM with a convolutional layer, etc. without making many changes to the code. Most of what I mention requires changes only to model class.  When you use pretrained embeddings, try to see for how many words you are not able to find embeddings and why. The more words for which you have pre-trained embeddings, the better are the results. I present to you the following un-commented (!) function that you can use to create embedding matrix for any kind of pre-trained embedding which is in the same format as glove or fastText (some changes might be needed).  ═════════════════════════════════════════════════════════════════════════ def load_embeddings(word_index, embedding_file, vector_length=300):     \"\"\"     A general function to create embedding matrix     :param word_index: word:index dictionary     :param embedding_file: path to embeddings file     :param vector_length: length of vector     \"\"\"     max_features = len(word_index) + 1     words_to_find = list(word_index.keys())     more_words_to_find = []'),\n",
       " VectorParams(vector=[-0.03925974294543266, -0.15981736779212952, 0.02627507969737053, 0.030950535088777542, 0.10847322642803192, 0.0038656508550047874, -0.12359379231929779, 0.03306044265627861, -0.07949241995811462, 0.01669013686478138, 0.046148572117090225, 0.0221831277012825, 0.16210763156414032, 0.011155793443322182, -0.09517712891101837, 0.12202610820531845, -0.0009171478450298309, 0.1276862919330597, -0.1343105584383011, -0.08462615311145782, 0.1223955899477005, 0.2103804498910904, 0.05591539666056633, -0.03589409589767456, 0.0676657184958458, 0.06417971849441528, -0.06305117905139923, -0.0025129837449640036, -0.10318867862224579, 0.04265950620174408, 0.12908151745796204, 0.11323095858097076, 0.033396750688552856, 0.13705387711524963, -0.04566654562950134, -0.027263754978775978, -0.14779561758041382, -0.05165870115160942, -0.03320913761854172, 0.015169133432209492, -0.055439263582229614, 0.022406743839383125, -0.08420935273170471, 0.03288758918642998, 0.1590607762336731, 0.0288066565990448, -0.10488001257181168, -0.08262090384960175, 0.07451237738132477, 0.017733413726091385, -0.09289609640836716, 0.0020548950415104628, -0.09064248204231262, 0.2255449891090393, -0.156347393989563, -0.19331663846969604, 0.04500545188784599, -0.10074777901172638, -0.04432838410139084, -0.08933007717132568, 0.0242062509059906, -0.12344636023044586, 0.07191234827041626, -0.09351218491792679, -0.08944021165370941, -0.03553611785173416, 0.022590721026062965, 0.03296491876244545, -0.03520716354250908, 0.030290547758340836, 0.01566009223461151, 0.18369567394256592, -0.11662378907203674, 0.09184761345386505, -0.07809136807918549, -0.03296389430761337, 0.2659911513328552, -0.016398277133703232, 0.175850972533226, -0.002086674328893423, -0.023099269717931747, 0.005657532252371311, 0.12617763876914978, 0.017152585089206696, 0.06276340782642365, -0.17408515512943268, 0.032992418855428696, -0.0154715646058321, -0.04364369064569473, -0.06675910949707031, -0.053314387798309326, -0.21675147116184235, 0.007065356243401766, -0.10873426496982574, 0.10930745303630829, 0.019441571086645126, -0.05807230621576309, 0.08459632098674774, -0.0419047474861145, 0.038160815834999084, -0.03357287496328354, -0.10558204352855682, 0.0697082132101059, -0.12492181360721588, -0.045299164950847626, 0.10522741079330444, 0.06027275323867798, -0.009881284087896347, 0.16277150809764862, -0.22697772085666656, -0.057601869106292725, -0.03230235353112221, -0.07859950512647629, -0.0872713029384613, 0.14745542407035828, 0.01796100288629532, 0.07195382565259933, 0.010037179104983807, 0.04327233135700226, 0.1907220035791397, -0.04018309339880943, 0.07697512209415436, 0.09497570991516113, -0.02445938251912594, -0.026741567999124527, 0.0008613280951976776, -0.06501540541648865, 1.0246121571177604e-32, -0.04778246581554413, -0.007013976573944092, -0.07917182147502899, -0.06633562594652176, 0.1802227944135666, -0.02661292254924774, 0.11881929636001587, 0.11908438801765442, -0.08209087699651718, -0.09336866438388824, -0.20385268330574036, 0.14627262949943542, -0.014621586538851261, 0.12560072541236877, -0.010286446660757065, -0.1951744556427002, 0.04882289096713066, -0.03522974252700806, 0.05505727231502533, -0.11419610679149628, 0.08103834092617035, -0.08475382626056671, 0.07347069680690765, -0.0504913404583931, -0.1411381959915161, -0.14664025604724884, 0.07015970349311829, -0.24788546562194824, -0.06572245061397552, -0.052546124905347824, -0.2617241144180298, -0.01820526458323002, 0.14389179646968842, 0.009579699486494064, 0.019607877358794212, -0.16876065731048584, 0.08073824644088745, -0.004210036247968674, -0.015155170112848282, -0.298561155796051, -0.07896706461906433, 0.004493314307183027, 0.016710372641682625, -0.12028935551643372, 0.04604586586356163, 0.12008703500032425, 0.007348021492362022, 0.028341863304376602, -0.09995101392269135, 0.12538635730743408, 0.15295135974884033, -0.06439049541950226, -0.1094260960817337, 0.08680273592472076, 0.06730278581380844, 0.04336695000529289, 0.10193110257387161, 0.0697653740644455, 0.13665741682052612, -0.02379470132291317, 0.033171456307172775, 0.009913628920912743, 0.11526492238044739, 0.12746256589889526, 0.12774132192134857, 0.04485107213258743, 0.06165611743927002, 0.05773838609457016, 0.09110687673091888, 0.10277971625328064, -0.031040966510772705, -0.017957014963030815, -0.05867224559187889, -0.04149405658245087, 0.04799890145659447, -0.08112724870443344, 0.036750733852386475, -0.14939531683921814, -0.13328365981578827, 0.05192141979932785, -0.01559228915721178, 0.020788120105862617, 0.022998597472906113, -0.12637516856193542, -0.19306081533432007, -0.07148599624633789, 0.14912816882133484, -0.20907467603683472, 0.05392543226480484, -0.073407381772995, -0.08988126367330551, -0.0014225617051124573, -0.036053817719221115, 0.0379997193813324, 0.06598252058029175, -9.745431507388359e-33, 0.00016462616622447968, -0.002929879352450371, -0.06142525374889374, -0.04847995191812515, -0.030008589848876, -0.07140415906906128, 0.08037784695625305, 0.14110787212848663, 0.03481481224298477, -0.1125541478395462, 0.0640130266547203, -0.15015050768852234, 0.04932088404893875, -0.08988024294376373, 0.1658358871936798, 0.028257351368665695, -0.062146276235580444, 0.11744318902492523, 0.031928882002830505, 0.2086385041475296, -0.05233372002840042, 0.10920313000679016, -0.20028087496757507, 0.025771673768758774, -0.05665808171033859, 0.05796516686677933, -0.01413697935640812, 0.0853438600897789, 0.023219991475343704, -0.07747457921504974, -0.19965627789497375, 0.07234705984592438, -0.11842698603868484, 0.04563901945948601, -0.07639878988265991, -0.03364454582333565, 0.026820465922355652, -0.12474620342254639, -0.031668126583099365, 0.030984636396169662, 0.12022946774959564, 0.17106321454048157, -0.08483133465051651, -0.005446293391287327, -0.036557894200086594, -0.036209434270858765, -0.24257656931877136, -0.020188285037875175, 0.03873135522007942, -0.029109790921211243, 0.09674453735351562, -0.01264426950365305, -0.12141291797161102, 0.04841998592019081, -0.009784608148038387, -0.03333465754985809, -0.016437463462352753, -0.06948348879814148, -0.07068222761154175, -0.0812467634677887, -0.08059878647327423, 0.00839785486459732, -0.00910617783665657, -0.06895513832569122, 0.14505735039710999, 0.03157441318035126, -0.1355370730161667, 0.038978178054094315, -0.037391141057014465, 0.10644561052322388, -0.02312760427594185, 0.11575198173522949, 0.03550027310848236, 0.023380614817142487, -0.031757645308971405, 0.12789104878902435, -0.08322171866893768, -0.06892942637205124, -0.12383854389190674, -0.050902917981147766, -0.03826601058244705, -0.018963191658258438, 0.0614403560757637, 0.11089766770601273, -0.014416234567761421, 0.07362829148769379, 0.050787486135959625, 0.0709449052810669, 0.12085455656051636, -0.03393637388944626, 0.031655505299568176, -0.07293055951595306, 0.07366316020488739, 0.18257296085357666, 0.0472131110727787, -9.978857917758432e-08, -0.12457627058029175, 0.0235330518335104, -0.014527097344398499, -0.09425318241119385, 0.09286054968833923, -0.08970082551240921, 0.05910784378647804, 0.11371694505214691, -0.03619132563471794, -0.019047586247324944, 0.14577224850654602, 0.013221465982496738, -0.13551989197731018, 0.005331016145646572, -0.05808058753609657, 0.10689395666122437, 0.036867544054985046, -0.052353061735630035, 0.10116194188594818, 0.02545357309281826, 0.05655430257320404, 0.021562550216913223, -0.0013757012784481049, 0.11576414853334427, -0.019542457535862923, -0.08848453313112259, -0.05614452064037323, 0.09733906388282776, 0.05132286623120308, 0.020887073129415512, 0.02717382274568081, -0.026599548757076263, -0.057763367891311646, -0.021347526460886, 0.06298777461051941, 0.17960704863071442, 0.07067454606294632, -0.1073717474937439, -0.14095506072044373, 0.18539395928382874, -0.0020966739393770695, 0.0817241370677948, -0.05044376105070114, -0.09557566791772842, 0.1524309664964676, 0.018677234649658203, 0.017666660249233246, -0.12916892766952515, 0.13038134574890137, -0.08854199945926666, 0.055907346308231354, 0.028099004179239273, -0.11448116600513458, 0.023127637803554535, 0.0031730770133435726, -0.018610171973705292, -0.004274195991456509, 0.051304928958415985, -0.05161990970373154, -0.0777360126376152, -0.007902149111032486, 0.09337083995342255, 0.1526777446269989, 0.07696918398141861], metadata={'source': 'AAAMLP-569to.pdf', 'page': 260}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 261     for wtf in words_to_find:         more_words_to_find.append(wtf)         more_words_to_find.append(str(wtf).capitalize())     more_words_to_find = set(more_words_to_find)      def get_coefs(word, *arr):         return word, np.asarray(arr, dtype=\\'float32\\')      embeddings_index = dict(         get_coefs(*o.strip().split(\" \"))          for o in open(embedding_file)          if o.split(\" \")[0]          in more_words_to_find          and len(o) > 100     )      embedding_matrix = np.zeros((max_features, vector_length))     for word, i in word_index.items():         if i >= max_features:             continue         embedding_vector = embeddings_index.get(word)         if embedding_vector is None:             embedding_vector = embeddings_index.get(                 str(word).capitalize()             )         if embedding_vector is None:             embedding_vector = embeddings_index.get(                 str(word).upper()             )         if (embedding_vector is not None              and len(embedding_vector) == vector_length):             embedding_matrix[i] = embedding_vector     return embedding_matrix ═════════════════════════════════════════════════════════════════════════  Read and run the function above and see what’s happening. The function can also be modified to use stemmed words or lemmatized words. In the end, you want to have the least number of unknown words in your training corpus. One more trick is to learn the embedding layer, i.e., make it trainable and then train the network.  So far, we have built a lot of models for a classification problem. However, it is the era of muppets, and more and more people are moving towards transformer-based models. Transformer based networks are able to handle dependencies which are long term in nature. LSTM looks at the next word only when it has seen the previous word. This is not the case with transformers. It can look at all the words in the whole'),\n",
       " VectorParams(vector=[-0.16107815504074097, -0.13691116869449615, 0.004329290706664324, 0.038402821868658066, 0.02837991714477539, 0.08756891638040543, -0.07698372006416321, 0.1686042845249176, -0.09208226203918457, -0.07925134152173996, -0.08162274211645126, -0.013951719738543034, 0.017027005553245544, 0.06290754675865173, 0.07157811522483826, 0.05210417881608009, 0.03945847600698471, 0.07023590803146362, -0.1684626340866089, -0.1037825345993042, 0.14486919343471527, 0.12472815066576004, 0.06295810639858246, 0.039171718060970306, -0.012047691270709038, -0.054835911840200424, 0.015747733414173126, -0.08033768832683563, -0.0752771720290184, 0.08738094568252563, -0.00722467340528965, 0.03030453808605671, -0.13762983679771423, 0.12568561732769012, -0.026435665786266327, 0.10932464152574539, -0.10677929222583771, -0.06785980612039566, 0.052102405577898026, -0.002205529483035207, 0.026954466477036476, -0.05423738807439804, -0.08287422358989716, -0.08804319053888321, 0.1553245484828949, -0.036900732666254044, 0.055068355053663254, 0.020531805232167244, -0.012689108029007912, -0.04652895778417587, -0.07541477680206299, -0.0013263924047350883, -0.05624833703041077, 0.16706812381744385, -0.16607099771499634, -0.10471964627504349, 0.07508210092782974, -0.0547008141875267, 0.023892762139439583, -0.1583435833454132, -0.11121559143066406, -0.14300094544887543, -0.02675454691052437, -0.07366245985031128, -0.20317970216274261, -0.014425050467252731, 0.0184392798691988, 0.12237585335969925, 0.060640521347522736, 0.04505724087357521, -0.05177595466375351, 0.15388071537017822, -0.0993872806429863, 0.07387559860944748, -0.04724857211112976, -0.05399814620614052, 0.2665380835533142, -0.024183591827750206, 0.07937543094158173, -0.12902532517910004, 0.03108816035091877, -0.06909073889255524, 0.11399369686841965, -0.0029501360841095448, 0.09503885358572006, -0.16544008255004883, 0.07108910381793976, 0.10460937768220901, -0.08469512313604355, -0.0544905923306942, 0.06069684401154518, -0.11736491322517395, 0.13605745136737823, -0.07989316433668137, 0.09142167866230011, 0.116273432970047, 0.00520772859454155, -0.03948083519935608, -0.02660244330763817, 0.0823187306523323, -0.015889430418610573, -0.014600539579987526, 0.07922207564115524, -0.04205739498138428, 0.041190557181835175, 0.08839909732341766, 0.06871013343334198, -0.00038708216743543744, 0.1044609472155571, -0.17876780033111572, 0.11418034881353378, 0.02951960265636444, -0.04655499383807182, -0.04003792256116867, 0.11968303471803665, 0.056370459496974945, -0.06398332118988037, -0.06938778609037399, -0.04497009515762329, 0.23812392354011536, -0.06782103329896927, -0.003752510529011488, -0.01952679641544819, 0.10400483012199402, 0.03026123344898224, -0.003718814579769969, -0.08795464783906937, 1.0523403790805289e-32, -0.10445191711187363, 0.06691667437553406, 0.006781542208045721, -0.06489034742116928, 0.09427554905414581, -0.00015102652832865715, 0.0998149961233139, 0.11883477121591568, -0.04841367527842522, 0.01250728964805603, -0.1582004725933075, 0.13237260282039642, -0.08600416034460068, 0.0409683883190155, -0.0032191756181418896, -0.06763513386249542, -0.09153928607702255, 0.0482904389500618, 0.06954850256443024, 0.02359825372695923, 0.16135217249393463, -0.004637512844055891, 0.012800510041415691, -0.047680288553237915, -0.06781898438930511, -0.06553200632333755, 0.13758696615695953, -0.15629981458187103, -0.09399713575839996, 0.02778206765651703, -0.20743988454341888, -0.04572146385908127, 0.05897817015647888, 0.025415048003196716, 0.01758512295782566, -0.09013869613409042, -0.018220975995063782, -0.0011016338830813766, 0.013799917884171009, -0.2041463702917099, -0.10712651908397675, 0.0680733174085617, -0.010794680565595627, -0.08239827305078506, -0.060914698988199234, 0.03316223621368408, -0.0010333770187571645, -0.06637178361415863, 0.0026244150940328836, 0.03505915030837059, 0.07696624845266342, -0.07150393724441528, -0.12992283701896667, 0.022407110780477524, 0.01777617633342743, 0.025658683851361275, 0.0348985455930233, 0.041342467069625854, 0.12983126938343048, -0.033240921795368195, 0.08545215427875519, -0.04251493886113167, 0.04896073043346405, 0.12698569893836975, 0.1085992157459259, -0.0514507032930851, 0.06580697745084763, 0.11219718307256699, 0.02541443146765232, -0.033480364829301834, -0.08353754878044128, -0.03684255853295326, 0.0753893032670021, -0.04974658414721489, 0.1722153127193451, -0.03154902160167694, 0.15498971939086914, -0.048303745687007904, -0.219419464468956, 0.07913147658109665, -0.01223649363964796, 0.06389021873474121, 0.00850113108754158, -0.08379681408405304, -0.061838630586862564, -0.03099174052476883, 0.09565185755491257, -0.09813205897808075, -0.0908229649066925, -0.06203959509730339, -0.07696026563644409, 0.013507276773452759, 0.014586302451789379, 0.04877033829689026, -0.04187716543674469, -9.804924011167444e-33, 0.1106310784816742, 0.03539126366376877, -0.013213856145739555, 0.04553266242146492, 0.008746752515435219, -0.08088438212871552, -0.022653046995401382, 0.0969482958316803, -0.07677078247070312, -0.10941220074892044, -0.008246096782386303, -0.10251928865909576, 0.07631342113018036, -0.08007203787565231, 0.03528129681944847, -0.03380758315324783, -0.023282695561647415, 0.08402014523744583, 0.043512579053640366, 0.14186015725135803, -0.045210178941488266, 0.09966666251420975, -0.1929706335067749, -0.0018940430600196123, -0.08951664716005325, 0.0895865336060524, -0.14957590401172638, 0.06479393690824509, 0.025292688980698586, -0.03539400175213814, -0.14781410992145538, 0.07694712281227112, -0.05045950040221214, -0.027620600536465645, -0.10254973918199539, 0.06746099144220352, 0.07020393759012222, -0.05692407488822937, 0.035224657505750656, 0.13993613421916962, 0.20240524411201477, 0.047065168619155884, -0.09070316702127457, 0.06523046642541885, -0.05077916011214256, 0.013253161683678627, -0.1629621535539627, -0.023671960458159447, -0.050861187279224396, -0.02504509687423706, -0.005950796417891979, -0.029270440340042114, -0.1611124724149704, -0.020301291719079018, -0.03085910528898239, -0.14201383292675018, 0.029736479744315147, -0.09179183095693588, -0.1523497849702835, -0.04493279755115509, -0.12667402625083923, 0.03132255747914314, 0.12618018686771393, -0.13469591736793518, 0.04034857451915741, -0.012999799102544785, -0.08380676805973053, 0.06812649965286255, 0.0506172850728035, 0.0832318440079689, -0.07137583941221237, -0.009832355193793774, 0.03574303537607193, 0.07897493988275528, -0.09293611347675323, 0.09480457007884979, -0.05420875549316406, -0.1948603093624115, -0.05828600376844406, -0.03367402404546738, -0.07501434534788132, 0.013148217462003231, -0.029203083366155624, 0.11378616094589233, -0.029513267800211906, 0.1652233600616455, 0.12864473462104797, 0.11158826947212219, 0.16456349194049835, -0.010691932402551174, -0.04553913697600365, 0.03125852346420288, 0.15875183045864105, 0.13064318895339966, 0.04622086137533188, -1.0063548216976415e-07, -0.03429482504725456, 0.08757747709751129, -0.011028433218598366, 0.057100240141153336, -0.06260662525892258, -0.02663479931652546, -0.14319737255573273, 0.1476079374551773, -0.008367544040083885, 0.03635456785559654, 0.07902830839157104, -0.014085221104323864, -0.13510297238826752, 0.03987863287329674, -0.10441021621227264, 0.11355630308389664, -0.045878030359745026, -0.0050225649029016495, 0.015604842454195023, 0.019345596432685852, 0.09398745745420456, 0.041899167001247406, 0.06601343303918839, -0.02848810702562332, 0.053323861211538315, -0.11677166819572449, 0.0015445878962054849, 0.008781653828918934, -0.047329626977443695, 0.04839453101158142, -0.08177577704191208, -0.01684635691344738, -0.1626635193824768, 0.028514910489320755, 0.05495588108897209, 0.0831444188952446, 0.0156693197786808, -0.08181427419185638, -0.026393461972475052, 0.04694820195436478, 0.08945348113775253, 0.09344599395990372, -0.1680210530757904, -0.003325892612338066, 0.06778664886951447, -0.06440494954586029, -0.0021271980367600918, -0.18007966876029968, 0.11406474560499191, 0.051719360053539276, -0.025425903499126434, 0.029954316094517708, -0.06653115153312683, 0.12004587054252625, 0.01370947528630495, 0.03226442635059357, -0.08642127364873886, -0.033469680696725845, 0.03454012796282768, -0.009976414032280445, -0.029994795098900795, 0.05273155868053436, 0.02616080269217491, 0.03727496787905693], metadata={'source': 'AAAMLP-569to.pdf', 'page': 261}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 262 sentence simultaneously. Due to this, one more advantage is that it can easily be parallelized and uses GPUs more efficiently.  Transformers is a very broad topic, and there are too many models: BERT, RoBERTa, XLNet, XLM-RoBERTa, T5, etc. I will show you a general approach that you can use for all these models (except T5) for the classification problem that we have been discussing. Please note that these transformers are hungry in terms of computational power needed to train them. Thus, if you do not have a high-end system, it might take much longer to train a model compared to LSTM or TF-IDF based models.  The first thing we do is to create a config file.  ═════════════════════════════════════════════════════════════════════════ # config.py import transformers  # this is the maximum number of tokens in the sentence MAX_LEN = 512  # batch sizes is small because model is huge! TRAIN_BATCH_SIZE = 8 VALID_BATCH_SIZE = 4  # let\\'s train for a maximum of 10 epochs EPOCHS = 10  # define path to BERT model files BERT_PATH = \"../input/bert_base_uncased/\"  # this is where you want to save the model MODEL_PATH = \"model.bin\"  # training file TRAINING_FILE = \"../input/imdb.csv\"  # define the tokenizer # we use tokenizer and model  # from huggingface\\'s transformers TOKENIZER = transformers.BertTokenizer.from_pretrained(     BERT_PATH,      do_lower_case=True ) ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[-0.060128819197416306, -0.05128686502575874, -0.06548839807510376, 0.10340992361307144, 0.040285199880599976, 0.05634354054927826, 0.12204889208078384, 0.1186334416270256, -0.14654627442359924, -0.0676594153046608, 0.004140777047723532, -0.06646537780761719, -0.03892865031957626, -0.027611032128334045, -0.011346113868057728, 0.19359105825424194, 0.07423170655965805, 0.0007981337257660925, -0.26596882939338684, -0.09108897298574448, 0.2835492491722107, 0.08893804997205734, 0.21555034816265106, 0.05469975247979164, -0.059642840176820755, -0.07303853332996368, -0.009733134880661964, 0.03636038675904274, -0.01682908833026886, -0.017509255558252335, 0.07390941679477692, 0.01490719523280859, -0.04060718044638634, 0.1524752676486969, 0.10546652972698212, 0.01921677403151989, -0.11499162763357162, 0.013977257534861565, -0.005248680245131254, 0.021137366071343422, -0.009604841470718384, 0.053083810955286026, -0.12818709015846252, -0.018062913790345192, 0.07548671960830688, 0.03194708004593849, 0.013928220607340336, -0.09088941663503647, 0.06609227508306503, -0.02499723620712757, -0.10250748693943024, 0.02990417741239071, 0.015543084591627121, 0.006682749837636948, 0.04424247145652771, -0.15259191393852234, 0.008485891856253147, -0.10264191031455994, 0.05584380403161049, -0.22745400667190552, -0.006854088976979256, -0.10140031576156616, 0.06056961789727211, -0.07680417597293854, -0.17749349772930145, -0.0405699647963047, -0.13605351746082306, 0.0969415083527565, 0.07251611351966858, 0.09796073287725449, -0.0806480348110199, 0.13374288380146027, -0.0032231672666966915, 0.14929451048374176, 0.04732083901762962, -0.0475458949804306, 0.18246380984783173, -0.04678318649530411, 0.022591320797801018, -0.18851789832115173, -0.08367831259965897, -0.044829871505498886, 0.2016514539718628, 0.08867784589529037, 0.17303143441677094, -0.1974216103553772, 0.13117770850658417, 0.07837045937776566, 0.05822056904435158, -0.06348810344934464, -0.07072026282548904, -0.13662129640579224, 0.06555281579494476, -0.0842542052268982, 0.062107522040605545, 0.08013065904378891, 0.06733468174934387, -0.1325947642326355, -0.10071635991334915, 0.16207179427146912, -0.001073366031050682, -0.012201632373034954, -0.026895776391029358, -0.078946053981781, 0.019992420449852943, 0.04927036911249161, 0.025296417996287346, 0.03941456973552704, 0.10331380367279053, -0.15594720840454102, 0.022205933928489685, 0.044674091041088104, -0.043551813811063766, -0.020660558715462685, 0.12700262665748596, -0.03785451874136925, -0.04572264105081558, 0.10060127824544907, 0.05662026256322861, 0.26704326272010803, 0.10152477025985718, 0.0286773219704628, -0.045621201395988464, 0.12037237733602524, -0.049231089651584625, 0.005498118232935667, -0.010223266668617725, 1.1383823043936986e-32, -0.07889655232429504, 0.05043203756213188, -0.08310205489397049, -0.0839867815375328, -0.07104793190956116, 0.031415291130542755, 0.13065703213214874, 0.06407789885997772, -0.07815535366535187, -0.028109146282076836, -0.12267731875181198, 0.035641029477119446, -0.06900440156459808, 0.09363339841365814, -0.06454161554574966, -0.01286192238330841, -0.054107796400785446, 0.14642798900604248, 0.009188994765281677, -0.08944325149059296, 0.03578877076506615, -0.032298605889081955, -0.068137988448143, -0.11145323514938354, -0.19247868657112122, -0.0700211450457573, 0.008869856595993042, -0.08267279714345932, -0.08265224099159241, 0.018385712057352066, -0.2772483825683594, 0.1094893142580986, 0.03579610213637352, -0.029176458716392517, 0.008851822465658188, -0.052714601159095764, 0.060600027441978455, -0.034695062786340714, -0.017151396721601486, -0.24245251715183258, -0.011165447533130646, 0.11579492688179016, 0.03127145394682884, -0.03625461086630821, -0.054041989147663116, 0.07497964799404144, -0.0388973094522953, 0.07978498190641403, -0.0931972861289978, -0.0036022854037582874, -0.01731349527835846, -0.020240724086761475, 0.029591890051960945, 0.09012549370527267, -0.08910257369279861, -0.06907514482736588, 0.0796833485364914, -0.01784822717308998, 0.23544634878635406, -0.04219531640410423, 0.005849425680935383, 0.061064425855875015, 0.06827419251203537, 0.04879876971244812, 0.017459237948060036, 0.06122342869639397, 0.049854546785354614, 0.07873138785362244, 0.03666408360004425, -0.02592594549059868, -0.1607087254524231, 0.06852472573518753, -0.12253778427839279, -0.09463637322187424, -0.07676688581705093, -0.19437037408351898, 0.12452612072229385, -0.17007434368133545, -0.20470331609249115, -9.16674398467876e-05, 0.04370081052184105, 0.04231413081288338, -0.07146276533603668, -0.15905332565307617, -0.12832212448120117, -0.0951845645904541, 0.11212815344333649, -0.19325219094753265, -0.1338280886411667, -0.1628529131412506, -0.1597466915845871, -0.043581049889326096, 0.012047645635902882, -0.1063045859336853, -0.0186176635324955, -1.1478882333352107e-32, 0.022274205461144447, 0.049183063209056854, 0.022082960233092308, 0.08045173436403275, 0.0012206723913550377, -0.10476638376712799, -0.061708178371191025, 0.14092662930488586, 0.027939114719629288, -0.12708121538162231, -0.02328270673751831, -0.27215924859046936, 0.03349281847476959, -0.1583683043718338, 0.08972861617803574, 0.08980820327997208, -0.2550116181373596, 0.10344008356332779, 0.056088123470544815, -0.003634063759818673, -0.0553915910422802, 0.19028858840465546, -0.15036793053150177, 0.08146189898252487, -0.21171703934669495, 0.15565752983093262, 0.023254290223121643, 0.03463045880198479, 0.09774381667375565, -0.02672750875353813, -0.00936728622764349, 0.04811696708202362, -0.1760784536600113, 0.14910100400447845, -0.12404560297727585, -0.02317836508154869, 0.1553424596786499, -0.10276182740926743, -0.05871598795056343, 0.2080068290233612, 0.25453317165374756, 0.1330888420343399, -0.006091829389333725, 0.06340143829584122, -0.03467428311705589, 0.023615729063749313, -0.11112261563539505, 0.06751628965139389, -0.03348637744784355, -0.0740361213684082, 0.007520711049437523, -0.08312702924013138, -0.18843330442905426, 0.046962372958660126, -0.11418431997299194, -0.07094357907772064, 0.00824340246617794, -0.06901241838932037, -0.12143635749816895, -0.0024151147808879614, -0.16452017426490784, -0.056318774819374084, 0.13020506501197815, 0.004969101864844561, 0.07386104762554169, -0.03952954337000847, -0.017054781317710876, 0.02797762304544449, 0.019327210262417793, 0.09238752722740173, -0.07129774242639542, 0.07232130318880081, 0.09282663464546204, 0.06735015660524368, -0.03274793550372124, 0.13289713859558105, 0.008445139043033123, -0.1647501140832901, -0.005170946475118399, 0.042188022285699844, -0.14597848057746887, -0.08530906587839127, 0.1521022915840149, 0.06942640990018845, -0.05823506414890289, 0.019479624927043915, 0.08678003400564194, 0.22377072274684906, 0.037481699138879776, -0.08833669126033783, -0.00352658424526453, -0.1075657308101654, 0.21124356985092163, 0.15049181878566742, 0.015237740240991116, -1.0086814228316143e-07, -0.05558926612138748, -0.015634896233677864, -0.05097455903887749, 0.17392301559448242, 0.02673407644033432, 0.020726487040519714, -0.0483323410153389, 0.07793597877025604, -0.04408648610115051, -0.07762971520423889, 0.18601088225841522, 0.09912557154893875, -0.09638196229934692, -0.03818598389625549, -0.09436200559139252, 0.10697831958532333, -0.009033048525452614, 0.08800112456083298, -0.003387002507224679, 0.03389143571257591, 0.04223752021789551, 0.0019456928130239248, -0.005362420342862606, -0.03713652864098549, 0.034240975975990295, -0.036425553262233734, -0.035832323133945465, 0.09185370802879333, -0.08080526441335678, 0.09369633346796036, 0.07426317781209946, -0.058497354388237, 0.03183063864707947, 0.09068761765956879, 0.041591331362724304, 0.07466264069080353, -0.12987887859344482, -0.049591075628995895, -0.06223231181502342, 0.12327678501605988, 0.01912752538919449, 0.06220410019159317, -0.1993594765663147, -0.020201418548822403, 0.0442119799554348, -0.056305695325136185, 0.038930751383304596, -0.16539733111858368, 0.07362035661935806, 0.09885905683040619, 0.017918601632118225, -0.0072455997578799725, -0.012646446004509926, 0.059092409908771515, -0.025309693068265915, 0.012565536424517632, -0.15742988884449005, 0.041154008358716965, -0.005811686161905527, -0.031624481081962585, 0.06995492428541183, 0.029967308044433594, 0.03501284867525101, 0.11119445413351059], metadata={'source': 'AAAMLP-569to.pdf', 'page': 262}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 263 The config file here is the only place where we define tokenizer and other parameters we would like to change frequently—this way we can do many experiments without requiring a lot of changes.  Next step is to build a dataset class.  ═════════════════════════════════════════════════════════════════════════ # dataset.py import config import torch   class BERTDataset:     def __init__(self, review, target):         \"\"\"         :param review: list or numpy array of strings         :param targets: list or numpy array which is binary         \"\"\"         self.review = review         self.target = target         # we fetch max len and tokenizer from config.py         self.tokenizer = config.TOKENIZER         self.max_len = config.MAX_LEN      def __len__(self):         # this returns the length of dataset         return len(self.review)      def __getitem__(self, item):         # for a given item index, return a dictionary         # of inputs         review = str(self.review[item])         review = \" \".join(review.split())          # encode_plus comes from hugginface\\'s transformers         # and exists for all tokenizers they offer         # it can be used to convert a given string         # to ids, mask and token type ids which are         # needed for models like BERT         # here, review is a string         inputs = self.tokenizer.encode_plus(             review,             None,             add_special_tokens=True,             max_length=self.max_len,             pad_to_max_length=True,'),\n",
       " VectorParams(vector=[-0.039354220032691956, -0.020713934674859047, 0.04417835921049118, 0.19297416508197784, 0.11367125809192657, 0.05760222300887108, 0.15687520802021027, 0.025201348587870598, -0.074386827647686, -0.12853533029556274, 0.031150223687291145, -0.0703122466802597, 0.011150691658258438, -0.026749921962618828, 0.04132212698459625, 0.17979790270328522, -0.04833470657467842, 0.07121197879314423, -0.19430258870124817, -0.13035564124584198, 0.260490357875824, 0.16324083507061005, 0.06048891320824623, 0.07156365364789963, -0.0922260582447052, 0.026921972632408142, 0.01773940399289131, -0.03634535148739815, 0.026453297585248947, 0.07972655445337296, 0.02892921306192875, 0.06249845772981644, -0.06753426790237427, 0.16762442886829376, 0.07742253690958023, 0.06999059021472931, -0.11189936846494675, 0.06829433143138885, 0.06498455256223679, -0.0066892048344016075, 0.006959497928619385, -0.04127541929483414, -0.059421464800834656, -0.05966871231794357, 0.1939711570739746, -0.011302913539111614, 0.009866669774055481, -0.010707037523388863, 0.02312331087887287, -0.15876612067222595, -0.08306412398815155, -0.02010580711066723, -0.07132390886545181, 0.10391677170991898, -0.04135650768876076, -0.08386694639921188, 0.019816512241959572, -0.03260870650410652, 0.035589639097452164, -0.196763813495636, -0.06896864622831345, -0.10081464797258377, 0.03939894959330559, -0.12923170626163483, -0.03421303257346153, -0.03023661859333515, -0.05406375974416733, 0.056240957230329514, -0.018944192677736282, 0.07454641908407211, -0.07048157602548599, 0.18101361393928528, -0.06755517423152924, 0.11763229966163635, -0.0036617617588490248, -0.01060548983514309, 0.2155093103647232, -0.04222860187292099, 0.12982068955898285, -0.18849757313728333, -0.05374366417527199, -0.12222692370414734, 0.18377098441123962, 0.08980393409729004, 0.16517159342765808, -0.16038191318511963, 0.1154353991150856, 0.006228306330740452, 0.07965517789125443, -0.05462425574660301, -0.09266837686300278, -0.2522067427635193, 0.09104091674089432, 0.09166660159826279, 0.21742159128189087, 0.04366576671600342, 0.015915479511022568, -0.025971589609980583, -0.023146018385887146, 0.2274189591407776, -0.053916171193122864, -0.015020995400846004, -0.03204277902841568, -0.0525645948946476, -0.0016775447875261307, 0.1278902143239975, 0.04606756195425987, 0.01812080852687359, 0.021968921646475792, -0.2416602075099945, -0.0009403314907103777, 0.013900043442845345, -0.025410141795873642, 0.04324762895703316, 0.08814261853694916, 0.016859237104654312, -0.053149882704019547, 0.131741002202034, 0.03543047234416008, 0.22482168674468994, 0.05463006719946861, 0.016636760905385017, 0.031159184873104095, 0.18281424045562744, -0.10427042841911316, -0.056678593158721924, -0.01332568284124136, 1.0487323461074737e-32, -0.1269524097442627, 0.042705655097961426, -0.146614208817482, -0.03207259997725487, -0.03461221605539322, 0.03618982061743736, 0.08910682797431946, 0.0683237835764885, -0.09329620748758316, 0.035625848919153214, -0.19171899557113647, -0.03306373208761215, -0.10618942230939865, 0.05872245505452156, -0.07703638821840286, -0.01337114442139864, -0.01306916307657957, 0.1246258020401001, -0.03841366246342659, -0.0452544242143631, 0.0798984244465828, 0.13220611214637756, -0.059034258127212524, -0.11919597536325455, -0.06024141237139702, -0.01812620274722576, 1.7488432604295667e-06, -0.10446029901504517, -0.1142372190952301, 0.010412781499326229, -0.22472208738327026, -0.03456147760152817, 0.06659895926713943, -0.02636127546429634, -0.02497696317732334, 0.024164807051420212, 0.17921176552772522, -0.06088443845510483, -0.04144393280148506, -0.20675532519817352, -0.021142812445759773, 0.17586562037467957, 0.01136578619480133, -0.11252725124359131, -0.11162109673023224, -0.015441986732184887, -0.12193083018064499, 0.09641736000776291, -0.05859086662530899, 0.013572962023317814, 0.01080094650387764, 0.04096244275569916, -0.09810620546340942, 0.023318901658058167, -0.021105291321873665, -0.08888241648674011, 0.10030403733253479, 0.06156514212489128, 0.2393953800201416, -0.07114938646554947, 0.05696536600589752, 0.03638385981321335, -0.010691485367715359, 0.10905113816261292, 0.02460348978638649, 0.1284264773130417, 0.005592369940131903, 0.04457422345876694, 0.14848119020462036, -0.0640382394194603, -0.13385945558547974, 0.06777358055114746, -0.15693651139736176, -0.04535660147666931, -0.02796303853392601, -0.15900124609470367, 0.038599658757448196, -0.1890338659286499, -0.13670670986175537, 0.0611727349460125, -0.07139793783426285, 0.0894891768693924, -0.0688876211643219, -0.1238209530711174, -0.22965580224990845, -0.019639495760202408, -0.006933026015758514, -0.13580641150474548, -0.07304561883211136, -0.16961322724819183, -0.10937932878732681, -0.00821998342871666, 0.021497709676623344, -0.03352157771587372, 0.030569322407245636, -1.0971782886615004e-32, -0.03525866940617561, 0.157535582780838, -0.048555269837379456, -0.016500497236847878, -0.02336011454463005, -0.06824417412281036, -0.017970282584428787, -0.021888315677642822, 0.010886089876294136, -0.048132799565792084, -0.013206709176301956, -0.17981895804405212, -0.009833620861172676, -0.1021905392408371, 0.17202040553092957, 0.0828758105635643, -0.10661724954843521, 0.11607538163661957, -0.002532029990106821, 0.07869093865156174, -0.0733821764588356, 0.20108872652053833, -0.19493144750595093, 0.0827324390411377, -0.22578014433383942, 0.1459629386663437, 0.004401918966323137, 0.12973156571388245, 0.035933997482061386, -0.02752339467406273, -0.06702405959367752, 0.03520721569657326, -0.1932496279478073, 0.17204530537128448, -0.1309746354818344, -0.01583974063396454, 0.07109866291284561, -0.06642647832632065, -0.09558863937854767, 0.127416729927063, 0.23352673649787903, 0.08453048020601273, -0.11347749829292297, 0.14398394525051117, -0.12295562028884888, -0.03900250419974327, 0.01713746041059494, 0.0382581502199173, 0.06598469614982605, -0.1006087213754654, -0.006390134338289499, -0.10150548070669174, -0.17752139270305634, -0.05468595027923584, -0.16291292011737823, -0.013436810113489628, 0.005324704572558403, -0.07245811074972153, -0.08825962245464325, -0.038127351552248, -0.07097461074590683, -0.032736632972955704, 0.06134665757417679, -0.028313226997852325, 0.07927456498146057, -0.11206257343292236, -0.15741057693958282, 0.0608840174973011, 0.062334995716810226, 0.004433640278875828, -0.05844131112098694, 0.1146504282951355, 0.04462563991546631, 0.01883924938738346, -0.01916610449552536, 0.12593711912631989, -0.008615500293672085, -0.0493396632373333, -0.015753617510199547, 0.0004996823845431209, -0.11112844944000244, -0.07002286612987518, 0.10255391895771027, 0.13241684436798096, -0.08070556074380875, 0.10883058607578278, 0.1449711173772812, 0.19668573141098022, 0.004481032956391573, -0.06013384833931923, -0.023812508210539818, -0.06640129536390305, 0.16728277504444122, 0.13189111649990082, 0.005555061623454094, -1.003170950752974e-07, -0.12808534502983093, -0.0440051443874836, -0.0970766618847847, 0.17426186800003052, -0.08457332849502563, -0.021638138219714165, -0.09466203302145004, 0.08276475220918655, -0.015170927159488201, -0.14247941970825195, -0.05024679750204086, 0.07001131027936935, -0.02022692561149597, -0.04362921416759491, -0.07716872543096542, 0.08058267086744308, -0.14627762138843536, 0.004127240739762783, -0.02895534783601761, -0.018656350672245026, 0.0832291841506958, -0.04550189897418022, -0.003959714435040951, -0.03416484221816063, 0.008328640833497047, -0.0893789678812027, 0.03562517091631889, 0.1352827399969101, -0.0659881979227066, 0.12497032433748245, 0.015758506953716278, 0.01664106920361519, -0.06994867324829102, 0.05757733806967735, 0.16664928197860718, 0.11672817170619965, 0.1640235334634781, -0.04786152020096779, 0.025763044133782387, 0.0978822186589241, -0.04976935312151909, 0.04356307163834572, -0.10158799588680267, 0.010649289935827255, 0.11960755288600922, -0.027335958555340767, 0.005077778361737728, -0.18148960173130035, 0.14535057544708252, 0.04339434579014778, -0.006122593302279711, -0.028306620195508003, -0.08759623020887375, 0.08386199921369553, 0.0007201086264103651, 0.008934768848121166, -0.07379402965307236, 0.09180010110139847, -0.05777604132890701, 0.0037474539130926132, 0.008570182137191296, 0.05882812291383743, 0.007119394838809967, -0.05934677645564079], metadata={'source': 'AAAMLP-569to.pdf', 'page': 263}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 264         )         # ids are ids of tokens generated         # after tokenizing reviews         ids = inputs[\"input_ids\"]         # mask is 1 where we have input         # and 0 where we have padding         mask = inputs[\"attention_mask\"]         # token type ids behave the same way as          # mask in this specific case         # in case of two sentences, this is 0         # for first sentence and 1 for second sentence         token_type_ids = inputs[\"token_type_ids\"]          # now we return everything         # note that ids, mask and token_type_ids         # are all long datatypes and targets is float         return {             \"ids\": torch.tensor(                 ids, dtype=torch.long             ),             \"mask\": torch.tensor(                 mask, dtype=torch.long             ),             \"token_type_ids\": torch.tensor(                 token_type_ids, dtype=torch.long             ),             \"targets\": torch.tensor(                 self.target[item], dtype=torch.float             )         } ═════════════════════════════════════════════════════════════════════════  And now we come to the heart of the project, i.e. the model.  ═════════════════════════════════════════════════════════════════════════ # model.py import config import transformers import torch.nn as nn   class BERTBaseUncased(nn.Module):     def __init__(self):         super(BERTBaseUncased, self).__init__()         # we fetch the model from the BERT_PATH defined in          # config.py         self.bert = transformers.BertModel.from_pretrained('),\n",
       " VectorParams(vector=[-0.13671119511127472, -0.06513886153697968, 0.04799732193350792, 0.15679584443569183, 0.09877864271402359, 0.06771983951330185, 0.11320782452821732, 0.06812908500432968, -0.03187702223658562, -0.11538707464933395, -0.09555306285619736, -0.10458012670278549, -0.025645067915320396, -0.051529936492443085, -0.06449539959430695, 0.14784885942935944, 0.0014316175365820527, 0.07825592160224915, -0.16336438059806824, -0.14317205548286438, 0.1915738880634308, 0.05274445191025734, 0.03493834659457207, 0.05984978377819061, 0.006399127189069986, -0.09720174968242645, -0.010216153226792812, -0.04612099751830101, 0.046187207102775574, -0.004263696726411581, 0.1393897533416748, 0.0016140176448971033, -0.0068959807977080345, 0.09033047407865524, 0.049331292510032654, 0.05177829787135124, -0.1532401293516159, 0.0233004130423069, 0.007970568723976612, 0.05551401525735855, 0.012677074410021305, 0.06288834661245346, -0.08539649099111557, -0.07857491075992584, 0.043238092213869095, 0.07337609678506851, -0.031923312693834305, 0.022844934836030006, 0.047631196677684784, -0.13673186302185059, 0.019125796854496002, 0.09142130613327026, -0.0069335284642875195, 0.12607166171073914, 0.00032869528513401747, -0.09207756817340851, -0.0036031592171639204, -0.09449271112680435, -0.19280287623405457, -0.024866094812750816, -0.13197815418243408, -0.11603596061468124, 0.08746017515659332, -0.144118070602417, -0.017759591341018677, 0.07784698158502579, -0.06680142879486084, 0.06857013702392578, 0.020703498274087906, 0.13131991028785706, -0.06971163302659988, 0.11219542473554611, -0.0323956236243248, 0.0748363584280014, 0.06775475293397903, -0.17496009171009064, 0.22304002940654755, -0.015518851578235626, -0.048875436186790466, -0.10417705774307251, -0.02750709280371666, 0.003473334712907672, 0.07307760417461395, 0.04091612249612808, 0.1536673754453659, -0.1484193503856659, 0.08003515005111694, 0.013781257905066013, 0.0036191828548908234, -0.047953374683856964, -0.10433895885944366, -0.11471779644489288, 0.0649234801530838, -0.013375915586948395, 0.2023613452911377, 0.047989070415496826, 0.09117407351732254, -0.09642253071069717, -0.015911776572465897, 0.1278815120458603, 0.006244963966310024, 0.03420046344399452, 0.07362537086009979, -0.042570728808641434, 0.15855418145656586, 0.23564235866069794, 0.09277132898569107, 0.09975185245275497, 0.162977933883667, -0.18334628641605377, 0.06094398722052574, 0.025585180148482323, 0.03176654502749443, 0.05388418957591057, 0.12460458278656006, 0.03080538474023342, 0.03093622624874115, 0.042872026562690735, -0.0008156969561241567, 0.1939328908920288, -0.0022066598758101463, 0.07948262244462967, -0.009202612563967705, 0.11974259465932846, -0.09311985224485397, 0.020572837442159653, 0.03883505240082741, 1.4378113518696535e-32, -0.08647050708532333, -0.012476058676838875, -0.1558952033519745, -0.10945639759302139, -0.0669136717915535, 0.08349467068910599, 0.09201468527317047, -0.07142824679613113, -0.06698174774646759, -0.0017887840513139963, -0.20087063312530518, -0.06250980496406555, -0.14192591607570648, 0.033673245459795, -0.003452559234574437, 0.0024487082846462727, 0.0682472288608551, 0.1692456305027008, 0.100282683968544, -0.11925800144672394, 0.0765720009803772, 0.07911934703588486, -0.07972093671560287, -0.16567900776863098, -0.03572484850883484, 0.003152464982122183, 0.023903390392661095, -0.1485031098127365, -0.10684733092784882, 0.03048618510365486, -0.15356341004371643, 0.16140776872634888, -0.0123436339199543, -0.04414329677820206, 0.0030325890984386206, -0.05590806156396866, 0.011791490018367767, 0.04282907396554947, 0.09402743726968765, -0.08528786152601242, -0.08273816853761673, 0.12717662751674652, -0.019304662942886353, -0.08820071816444397, -0.1035534217953682, -0.1232268437743187, 0.02193341962993145, 0.12321057170629501, -0.04893363267183304, -0.007076093461364508, 0.05503087490797043, -0.07702800631523132, -0.08766251057386398, -0.012623888440430164, 0.0041664959862828255, -0.13247358798980713, 0.1453363597393036, 0.028693949803709984, 0.25448039174079895, 0.024200547486543655, 0.10307254642248154, -0.016277018934488297, -0.06390371173620224, 0.08624278008937836, -0.002214583335444331, -0.007350039202719927, 0.041806865483522415, 0.039614688605070114, -0.036546193063259125, 0.014874549582600594, -0.10421466082334518, 0.11289912462234497, -0.016687026247382164, -0.05265544727444649, 0.06146858632564545, -0.16989633440971375, 0.09763623774051666, -0.22537340223789215, -0.12190526723861694, 0.07043692469596863, 0.046506352722644806, 0.1397850513458252, -0.1409439742565155, -0.16580431163311005, -0.12628069519996643, -0.0157934483140707, 0.10340937972068787, -0.15314652025699615, -0.1423851102590561, -0.068478062748909, -0.1000538319349289, -0.19007056951522827, 0.10768769681453705, -0.028792090713977814, -0.11532142758369446, -1.3109420098269303e-32, 0.005200567655265331, 0.20965799689292908, -0.02074713073670864, -0.012023056857287884, -0.08190758526325226, -0.05049124360084534, 0.09837766736745834, 0.2239859253168106, -0.08605936914682388, -0.04851161688566208, -0.06891307979822159, -0.08826031535863876, -0.036752887070178986, -0.04821908846497536, 0.09892228990793228, 0.09178321063518524, -0.027533192187547684, 0.11241763830184937, -0.019306739792227745, -0.008802643977105618, -0.0856814756989479, 0.07155999541282654, -0.14970239996910095, 0.08261620998382568, -0.1330522745847702, 0.0598287358880043, -0.12946635484695435, 0.15601405501365662, 0.061642538756132126, -0.12219583988189697, -0.11553805321455002, 0.02500639297068119, -0.15571410953998566, 0.052346643060445786, -0.04707803949713707, 0.019299935549497604, -0.0267033688724041, -0.020564541220664978, -0.08827817440032959, 0.042381495237350464, 0.15691784024238586, 0.0019812274258583784, -0.12512879073619843, 0.09697552025318146, -0.003157795872539282, 0.08201014250516891, -0.18369002640247345, -0.05158607289195061, -0.022775370627641678, 0.021133102476596832, 0.015833359211683273, -0.06838469207286835, -0.1386021077632904, 0.015568286180496216, -0.1699836701154709, -0.0046653649769723415, 0.03191903233528137, 0.02642650716006756, -0.1333535611629486, 0.004503118339926004, -0.0649077296257019, -0.12883253395557404, 0.09109978377819061, 0.03782478719949722, 0.020759033039212227, 0.02974739670753479, -0.150551900267601, 0.18427301943302155, 0.01004868932068348, 0.04258536174893379, 0.026640668511390686, 0.08512488007545471, 0.12019002437591553, 0.06531113386154175, 0.018922440707683563, 0.09486845135688782, -0.0861244648694992, -0.15245665609836578, -0.007907788269221783, 0.1016673669219017, -0.16652774810791016, -0.03844371810555458, 0.06593742221593857, 0.06838013976812363, -0.01931724138557911, 0.12043067067861557, 0.11212122440338135, 0.09835811704397202, 0.04548051208257675, -0.07158607989549637, 0.0042973412200808525, -0.010738338343799114, 0.12762360274791718, 0.07296909391880035, 0.03324059396982193, -1.0028794861227652e-07, -0.04051727056503296, -0.001039692317135632, 0.02695019356906414, 0.15093852579593658, -0.01824825629591942, -0.04184594750404358, -0.040770549327135086, 0.06143207103013992, -0.060375429689884186, -0.0899643674492836, 0.03746512159705162, 0.040222760289907455, -0.03118671104311943, 0.002669654320925474, -0.004669475834816694, 0.08604497462511063, -0.044760413467884064, -0.08363089710474014, 0.031516604125499725, -0.05932474508881569, -0.020305825397372246, -0.014992551878094673, -0.01225354429334402, 0.04240487888455391, -0.07921113818883896, -0.15630580484867096, -0.007399877067655325, 0.13599951565265656, -0.07290436327457428, -0.0275664534419775, 0.030876941978931427, 0.0001317594142165035, -0.058527860790491104, 0.14580291509628296, 0.13655763864517212, 0.19811275601387024, -0.06321202963590622, -0.00950591079890728, -0.03982197865843773, 0.09789210557937622, -0.051706086844205856, 0.05829082429409027, -0.031932324171066284, -0.053769540041685104, 0.147187277674675, -0.04794906824827194, 0.0077076139859855175, -0.23689784109592438, 0.09066442400217056, -0.049471884965896606, 0.14780917763710022, -0.12350354343652725, -0.06882358342409134, 0.18594063818454742, 0.053821224719285965, -0.1108880564570427, -0.17188984155654907, 0.02693655714392662, -0.03596283495426178, 0.0008934997022151947, -0.10211409628391266, 0.0639486163854599, -0.04166816920042038, 0.060708705335855484], metadata={'source': 'AAAMLP-569to.pdf', 'page': 264}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 265             config.BERT_PATH         )         # add a dropout for regularization         self.bert_drop = nn.Dropout(0.3)         # a simple linear layer for output         # yes, there is only one output         self.out = nn.Linear(768, 1)      def forward(self, ids, mask, token_type_ids):         # BERT in its default settings returns two outputs         # last hidden state and output of bert pooler layer         # we use the output of the pooler which is of the size         # (batch_size, hidden_size)         # hidden size can be 768 or 1024 depending on         # if we are using bert base or large respectively         # in our case, it is 768         # note that this model is pretty simple         # you might want to use last hidden state         # or several hidden states         _, o2 = self.bert(             ids,              attention_mask=mask,              token_type_ids=token_type_ids         )         # pass through dropout layer         bo = self.bert_drop(o2)         # pass through linear layer         output = self.out(bo)         # return output         return output ═════════════════════════════════════════════════════════════════════════  This model returns a single output. We can use binary cross-entropy loss with logits which first applies sigmoid and then calculates the loss. This is done in engine.py.  ═════════════════════════════════════════════════════════════════════════ # engine.py  import torch import torch.nn as nn   def loss_fn(outputs, targets):     \"\"\"     This function returns the loss.'),\n",
       " VectorParams(vector=[-0.11828906834125519, -0.09152614325284958, 0.0205239150673151, 0.12065543979406357, 0.04212319850921631, -0.09457027912139893, 0.0052238390780985355, 0.08815298229455948, -0.07924775034189224, -0.10200570523738861, -0.061645086854696274, -0.10210015624761581, -0.05053329840302467, -0.08197775483131409, -0.01627524569630623, 0.08456749469041824, -0.040461111813783646, 0.042109616100788116, -0.11217424273490906, -0.13363689184188843, 0.14188635349273682, 0.10606160014867783, 0.03988006338477135, 0.08237092196941376, -0.017674598842859268, -0.08219276368618011, 0.029830100014805794, -0.023328376933932304, -0.00786606501787901, -0.021089553833007812, 0.11892030388116837, -0.03925516828894615, -0.09312674403190613, 0.09341735392808914, 0.04970448836684227, 0.0869441032409668, -0.14862655103206635, -0.04517175629734993, -0.031887661665678024, 0.0727902427315712, 0.00818902999162674, -0.010470694862306118, -0.04606790840625763, -0.081727534532547, 0.060491643846035004, -0.008544040843844414, -0.00040243001421913505, -0.014563657343387604, 0.045526690781116486, -0.0629240870475769, 0.011382751166820526, 0.0034328442998230457, -0.02911299653351307, 0.028968336060643196, -0.02964756079018116, -0.0417819507420063, 0.09839823842048645, -0.10852120816707611, 0.0027173899579793215, -0.12886282801628113, -0.05313177406787872, -0.07678462564945221, -0.04275006800889969, -0.09093523025512695, -0.09442077577114105, 0.0035146463196724653, -0.025015823543071747, 0.024027537554502487, 0.05363588407635689, 0.1325472891330719, 0.0220671147108078, 0.12351800501346588, -0.03279326111078262, 0.054776232689619064, -0.026506971567869186, -0.07860809564590454, 0.23092183470726013, 0.04734964668750763, 0.00292861252091825, -0.21681253612041473, -0.03041481226682663, -0.05581675469875336, 0.04973769187927246, -0.04689252749085426, 0.15967802703380585, -0.1750652939081192, 0.12872928380966187, 0.03503726050257683, 0.14436940848827362, -0.02828364074230194, -0.00727810338139534, -0.009325157850980759, 0.02464144676923752, -0.016720153391361237, 0.11475659161806107, 0.09785472601652145, 0.10928057879209518, -0.05108465626835823, -0.09734714031219482, 0.1517024040222168, -0.04180983826518059, -0.004078948404639959, 0.00017007344285957515, 0.045587342232465744, 0.03902178257703781, 0.0991997942328453, 0.07790882140398026, 0.08050869405269623, 0.033783551305532455, -0.14998860657215118, 0.1432192176580429, 0.10759585350751877, -0.002885486464947462, -0.008149306289851665, 0.11089510470628738, 0.04356982186436653, -0.06911570578813553, 0.025035638362169266, -0.025958247482776642, 0.25363674759864807, -0.1485898643732071, 0.062020350247621536, -0.060850150883197784, 0.1505168229341507, -0.06919904053211212, -0.0705425888299942, -0.10539349913597107, 1.9149027788189658e-32, -0.11895107477903366, -0.033445872366428375, -0.07516555488109589, -0.21786166727542877, -0.006084201391786337, 0.05214281380176544, 0.05233965441584587, 0.023461876437067986, -0.017385218292474747, -0.010537881404161453, -0.21951855719089508, -0.0705486536026001, -0.12391069531440735, 0.04568008705973625, -0.001736422418616712, -0.023564433678984642, 0.005436920095235109, 0.12083973735570908, 0.1414881944656372, -0.012412069365382195, 0.1976320892572403, -0.07284796237945557, -0.18201535940170288, -0.139484703540802, -0.08864914625883102, 0.13157416880130768, 0.034496232867240906, -0.08346980065107346, -0.12939245998859406, 0.01881687343120575, -0.15353262424468994, 0.06350188702344894, 0.023046283051371574, -0.039694782346487045, -0.019656952470541, -0.05586215853691101, 0.08753450959920883, 0.08485029637813568, 0.053087055683135986, -0.07345692068338394, -0.11034438014030457, 0.09747618436813354, -0.017821190878748894, -0.10547490417957306, -0.12550413608551025, -0.05958970636129379, -0.006469592452049255, 0.10430742800235748, -0.0008452691254206002, 0.018808934837579727, -0.04225438833236694, -0.11919417977333069, 0.002604121807962656, -0.03169138357043266, -0.03099200688302517, -0.09846088290214539, 0.09680135548114777, 0.035508982837200165, 0.26487997174263, 0.004801822826266289, 0.10537702590227127, -0.0221801046282053, -0.061159126460552216, 0.04539091885089874, 0.013902721926569939, 0.014594082720577717, 0.03970430791378021, 0.04101121798157692, 0.04986744746565819, 0.021097570657730103, -0.18407295644283295, 0.04487745836377144, 0.026617497205734253, -0.12449182569980621, 0.1912773698568344, -0.16522161662578583, 0.0876915380358696, -0.1546863168478012, -0.20609207451343536, 0.0758899450302124, 0.005641222931444645, 0.2060108482837677, -0.09543431550264359, -0.2402469664812088, -0.07906389236450195, -0.09938567876815796, -0.004556357394903898, -0.09894789010286331, -0.13758864998817444, -0.0673709362745285, -0.17106351256370544, -0.0762246623635292, 0.015702707692980766, 0.05749504268169403, -0.11077389866113663, -1.651265109868451e-32, -0.0026566325686872005, 0.1106986254453659, 0.06322252750396729, 0.08254212886095047, 0.0791541263461113, -0.03378504514694214, 0.029939115047454834, 0.03872431814670563, -0.024516765028238297, -0.09678290039300919, -0.07120764255523682, -0.1765969693660736, -0.11258208006620407, -0.040506646037101746, 0.09109650552272797, 0.0378766730427742, -0.06312695890665054, 0.0776098221540451, 0.02477642148733139, 0.02817877195775509, -0.13337822258472443, 0.24731236696243286, -0.21317170560359955, -0.014255371876060963, -0.10105440020561218, 0.07777243107557297, -0.03329619765281677, 0.23097218573093414, 0.03210701048374176, -0.09761770069599152, -0.017359215766191483, 0.050539322197437286, -0.15990418195724487, 0.05358729884028435, -0.046472758054733276, 0.11841380596160889, 0.10235201567411423, 0.0006745796999894083, -0.06267926096916199, 0.11385016143321991, 0.29442358016967773, 0.07894537597894669, -0.09101404994726181, 0.13904333114624023, 0.008601872250437737, 0.0643736943602562, -0.05330745503306389, -0.026476221159100533, -0.05929265171289444, 0.001219330821186304, 0.008833256550133228, -0.12283200770616531, -0.2058304399251938, 0.021760115399956703, -0.05213834345340729, -0.08527582883834839, 0.058746758848428726, -0.07497122138738632, -0.10154321044683456, 0.02107998915016651, -0.06634127348661423, -0.09195302426815033, 0.09325328469276428, -0.01857960782945156, 0.02529604732990265, 0.02048248052597046, -0.05955566465854645, 0.1619197279214859, 0.0322875902056694, 0.1608714908361435, -0.07152869552373886, 0.09880270063877106, 0.10367609560489655, 0.05074060335755348, -0.09819934517145157, 0.11191027611494064, -0.05070365592837334, -0.06818341463804245, -0.0036101045552641153, 0.045927733182907104, -0.06891154497861862, -0.05494837835431099, 0.0646367222070694, 0.14218972623348236, -0.008659400045871735, 0.17024318873882294, 0.11791922897100449, 0.18892443180084229, 0.07651110738515854, -0.08850177377462387, -0.015838779509067535, -0.1203903928399086, 0.15404212474822998, 0.1898587942123413, 0.034000545740127563, -1.0077189216417537e-07, 0.003936247434467077, 0.08521531522274017, 0.0027124492917209864, 0.1466742306947708, 0.03423062339425087, -0.03948826342821121, -0.03987200930714607, 0.04793992638587952, -0.006114289164543152, -0.0722188875079155, 0.11743655800819397, -0.03798037767410278, -0.016598543152213097, 0.07047075033187866, 0.000835966260638088, 0.15748581290245056, -0.006315779872238636, -0.0041283308528363705, 0.0013450928963720798, -0.08724086731672287, 0.002945160726085305, -0.02161908894777298, 0.013573931530117989, -0.03167654946446419, 0.027039784938097, -0.14974157512187958, 0.03611237183213234, 0.11054861545562744, 0.03331458568572998, 0.017556510865688324, -0.08524181693792343, -0.05159468948841095, -0.024337420240044594, 0.11754540354013443, 0.12542426586151123, 0.08939338475465775, 0.024379923939704895, 0.031062956899404526, 0.02647005394101143, 0.11133303493261337, -0.09959077835083008, 0.06911952048540115, -0.06857146322727203, -0.06349189579486847, 0.08627032488584518, -0.005856113974004984, -0.05513623729348183, -0.11085078865289688, 0.10719031095504761, 0.04570222273468971, 0.010971357114613056, -0.0350881963968277, -0.11033128201961517, 0.11575356870889664, 0.08230667561292648, -0.15914922952651978, -0.14233985543251038, -0.061527594923973083, -0.0073159863241016865, -0.026753302663564682, 0.016643760725855827, -0.027272703126072884, -0.1223125159740448, 0.0024431943893432617], metadata={'source': 'AAAMLP-569to.pdf', 'page': 265}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 266     :param outputs: output from the model (real numbers)     :param targets: input targets (binary)     \"\"\"     return nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))   def train_fn(data_loader, model, optimizer, device, scheduler):     \"\"\"     This is the training function which trains for one epoch     :param data_loader: it is the torch dataloader object     :param model: torch model, bert in our case     :param optimizer: adam, sgd, etc     :param device: can be cpu or cuda     :param scheduler: learning rate scheduler     \"\"\"     # put the model in training mode     model.train()      # loop over all batches     for d in data_loader:         # extract ids, token type ids and mask         # from current batch         # also extract targets         ids = d[\"ids\"]         token_type_ids = d[\"token_type_ids\"]         mask = d[\"mask\"]         targets = d[\"targets\"]          # move everything to specified device         ids = ids.to(device, dtype=torch.long)         token_type_ids = token_type_ids.to(device, dtype=torch.long)         mask = mask.to(device, dtype=torch.long)         targets = targets.to(device, dtype=torch.float)          # zero-grad the optimizer         optimizer.zero_grad()         # pass through the model         outputs = model(             ids=ids,             mask=mask,             token_type_ids=token_type_ids         )         # calculate loss         loss = loss_fn(outputs, targets)         # backward step the loss         loss.backward()         # step optimizer'),\n",
       " VectorParams(vector=[-0.11061123758554459, -0.10812187939882278, 0.007665322627872229, 0.1693216860294342, 0.11718688905239105, -0.15739844739437103, 0.028850771486759186, 0.07492918521165848, -0.1440800577402115, -0.1579577922821045, -0.0632709413766861, -0.06263863295316696, -0.03843593969941139, -0.032223425805568695, 0.00920087844133377, 0.0901007205247879, -0.07556236535310745, 0.0014601008733734488, -0.06676242500543594, -0.1413228064775467, 0.17337395250797272, 0.08119036257266998, 0.04626114293932915, 0.0847180187702179, -0.0492476262152195, -0.08952918648719788, 0.09457091987133026, 0.01991954818367958, -0.04236342012882233, -0.01539194118231535, 0.14447540044784546, -0.057688578963279724, -0.1379183530807495, 0.07805435359477997, 0.1566898077726364, 0.04916134476661682, -0.18274758756160736, -0.016439901664853096, -0.07044991850852966, 0.10015217214822769, 0.04617398977279663, -0.054806385189294815, -0.03979608416557312, -0.05478408560156822, 0.017632557079195976, -0.01785888895392418, 0.06757466495037079, -0.04122314974665642, 0.03893633559346199, -0.1027144193649292, -0.002349056303501129, 0.010022521018981934, -0.09513060748577118, 0.024551935493946075, -0.047918323427438736, -0.11275660991668701, 0.14838920533657074, -0.2414800375699997, 0.04350389912724495, -0.26261934638023376, -0.0505734458565712, -0.05798189342021942, -0.027234261855483055, -0.08618519455194473, -0.1292654424905777, 0.006777779199182987, -0.009076371788978577, 0.03076389990746975, 0.06547573953866959, 0.121348075568676, 0.011237083934247494, 0.14931850135326385, -0.031739573925733566, 0.11439373344182968, -0.021236540749669075, -0.06563398241996765, 0.24280238151550293, 0.017695430666208267, 0.04130008444190025, -0.20101264119148254, -0.08208008110523224, -0.11000906676054001, 0.06842063367366791, -0.02235851064324379, 0.14909960329532623, -0.17484673857688904, 0.09160414338111877, 0.07793731987476349, 0.13272567093372345, -0.051922570914030075, 0.01641095243394375, -0.021175391972064972, 0.04360697418451309, -0.012724128551781178, 0.13562586903572083, 0.035641588270664215, 0.11541970074176788, -0.13319045305252075, -0.12941889464855194, 0.14979760348796844, -0.08019344508647919, -0.022972838953137398, -0.04083837941288948, 0.04357898235321045, -0.0018105448689311743, 0.13621032238006592, 0.06007762253284454, 0.097257599234581, -0.014074205420911312, -0.1526966392993927, 0.1386149376630783, 0.11076271533966064, 0.016723591834306717, 0.028888598084449768, 0.1375589668750763, 0.05401570722460747, -0.11160629987716675, 0.05329154431819916, -0.0377362035214901, 0.2631503641605377, -0.11227000504732132, 0.05671091005206108, 0.02378220483660698, 0.11391159147024155, -0.08759062737226486, -0.10474102944135666, -0.1105286031961441, 1.5208318158908284e-32, -0.1515498161315918, -0.020476993173360825, -0.06408248096704483, -0.16690407693386078, -0.029412921518087387, 0.028694085776805878, 0.11259375512599945, -0.023257579654455185, -0.07014807313680649, 0.040203824639320374, -0.2105572372674942, 0.007508037146180868, -0.1328568160533905, 0.10482771694660187, 0.03034559078514576, 0.002377876080572605, 0.09736499935388565, 0.17928777635097504, 0.13410234451293945, 0.03610381484031677, 0.20658639073371887, -0.06190294772386551, -0.1599147766828537, -0.12242475897073746, -0.11475346237421036, 0.09373267740011215, -0.09505760669708252, -0.04771917685866356, -0.10786957293748856, 0.0116275018081069, -0.19944335520267487, 0.09953030198812485, 0.09211555868387222, 0.009458712302148342, -0.00022035895381122828, -0.07911287993192673, 0.07091319561004639, 0.04124652221798897, 0.08928034454584122, -0.07082724571228027, 0.011723785661160946, 0.10127051174640656, 0.03556545078754425, -0.13583433628082275, -0.09550265967845917, 0.0020231008529663086, -0.05608664080500603, 0.09282128512859344, -0.004494149703532457, 0.05058969557285309, -0.06139034032821655, -0.08616884797811508, -0.051269881427288055, -0.007898501120507717, -0.06927873939275742, -0.10165750980377197, 0.05652035027742386, 0.026287276297807693, 0.33944615721702576, -0.05726476386189461, 0.04719523712992668, -0.010015229694545269, -0.1423657089471817, 0.04205081984400749, 0.006204068195074797, 0.02313162013888359, 0.04000803083181381, 0.08134045451879501, 0.052428919821977615, 0.05072116106748581, -0.17431962490081787, 0.0503174252808094, 0.01221019309014082, -0.08337815850973129, 0.1497322916984558, -0.1743294596672058, 0.05292069911956787, -0.18833796679973602, -0.2995620369911194, 0.04013390839099884, 0.02080526202917099, 0.21980635821819305, -0.10520008951425552, -0.22557474672794342, -0.06906088441610336, -0.09696364402770996, -0.0645405575633049, -0.09339260309934616, -0.17288048565387726, -0.06781835854053497, -0.25557926297187805, -0.10630518943071365, 0.033330898731946945, -0.010631986893713474, -0.1691882610321045, -1.3683187707113292e-32, 0.03392650559544563, 0.09033943712711334, 0.11953968554735184, 0.07498974353075027, 0.08628013730049133, -0.045741595327854156, 0.035890158265829086, -0.029428284615278244, -0.03871626406908035, -0.12523503601551056, -0.11139029264450073, -0.2163432240486145, -0.06603125482797623, -0.001350003876723349, 0.06399628520011902, 0.09792975336313248, -0.10421214252710342, 0.07548020780086517, -0.016174418851733208, -0.003493149997666478, -0.13907791674137115, 0.21897906064987183, -0.14101891219615936, -0.051180072128772736, -0.21204131841659546, 0.1089811772108078, 0.005645838100463152, 0.17599451541900635, 0.04136791080236435, -0.05118068680167198, -0.025803644210100174, 0.0909617692232132, -0.1184900552034378, 0.07088334113359451, 0.005345082841813564, 0.10547206550836563, 0.1626005321741104, -0.028528092429041862, -0.05314634367823601, 0.12989965081214905, 0.31889164447784424, 0.09484080225229263, -0.07416065782308578, 0.09597057849168777, -0.03341080993413925, 0.05212234705686569, -0.012320607900619507, 0.009875047951936722, -0.07690609991550446, -0.026319285854697227, 0.0030487035401165485, -0.09455765783786774, -0.19046936929225922, 0.051454246044158936, -0.044107623398303986, -0.10006149113178253, 0.10757163912057877, -0.09453654289245605, -0.07664095610380173, -0.039558008313179016, -0.047491833567619324, -0.06763731688261032, 0.07127242535352707, -0.03545234352350235, 0.0684116929769516, 0.040875766426324844, -0.058064159005880356, 0.16929306089878082, 0.04817715287208557, 0.1360994130373001, -0.14363740384578705, 0.06051114574074745, 0.12497337907552719, 0.020202340558171272, -0.13687564432621002, 0.11530283838510513, -0.029493236914277077, -0.10374782979488373, 0.07433059066534042, 0.03012665919959545, -0.09997810423374176, -0.11881337314844131, 0.047197721898555756, 0.06659477204084396, 0.028881099075078964, 0.12674209475517273, 0.11492740362882614, 0.19779352843761444, 0.04876525700092316, -0.13687777519226074, -0.042225029319524765, -0.1459168791770935, 0.24687188863754272, 0.21362027525901794, 0.06628680229187012, -1.0042343490113126e-07, 0.027692794799804688, 0.1047833114862442, 0.014414318837225437, 0.17187722027301788, -0.040665049105882645, -0.07070799171924591, 0.011709999293088913, 0.011833314783871174, 0.08613280951976776, -0.04786621779203415, 0.12945501506328583, -0.07425118237733841, 0.07338082790374756, 0.09380942583084106, 0.06136852502822876, 0.21777129173278809, 0.028265027329325676, 0.006443435791879892, 0.012987704947590828, -0.09323783963918686, -0.017402278259396553, -0.0542735792696476, 0.001700555207207799, -0.05739128217101097, 0.02119428850710392, -0.1279747188091278, 0.027058284729719162, 0.08045133203268051, 0.012263531796634197, 0.08872728794813156, -0.08567443490028381, -0.10088656097650528, -0.011319208890199661, 0.13403569161891937, 0.25637537240982056, 0.05472496524453163, 0.0517260916531086, 0.0026479242369532585, 0.09663387387990952, 0.13582883775234222, -0.08940371870994568, 0.1460442841053009, -0.10086674988269806, -0.0552360974252224, 0.0886388048529625, 8.68144525156822e-06, -0.14984340965747833, -0.11311069130897522, 0.08577702194452286, 0.1179308071732521, -0.05299035459756851, 0.02442452684044838, -0.10979797691106796, 0.12499859929084778, 0.13036136329174042, -0.09363953769207001, -0.1583157330751419, -0.01239780243486166, -0.009837732650339603, -0.057085759937763214, 0.06851014494895935, -0.016208374872803688, -0.09600211679935455, -0.0436834879219532], metadata={'source': 'AAAMLP-569to.pdf', 'page': 266}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 267         optimizer.step()         # step scheduler         scheduler.step()   def eval_fn(data_loader, model, device):     \"\"\"     this is the validation function that generates     predictions on validation data     :param data_loader: it is the torch dataloader object     :param model: torch model, bert in our case     :param device: can be cpu or cuda     :return: output and targets     \"\"\"     # put model in eval mode     model.eval()     # initialize empty lists for     # targets and outputs     fin_targets = []     fin_outputs = []     # use the no_grad scope     # its very important else you might     # run out of gpu memory     with torch.no_grad():         # this part is same as training function         # except for the fact that there is no         # zero_grad of optimizer and there is no loss         # calculation or scheduler steps.         for d in data_loader:             ids = d[\"ids\"]             token_type_ids = d[\"token_type_ids\"]             mask = d[\"mask\"]             targets = d[\"targets\"]              ids = ids.to(device, dtype=torch.long)             token_type_ids = token_type_ids.to(device, dtype=torch.long)             mask = mask.to(device, dtype=torch.long)             targets = targets.to(device, dtype=torch.float)              outputs = model(                 ids=ids,                  mask=mask,                  token_type_ids=token_type_ids             )             # convert targets to cpu and extend the final list             targets = targets.cpu().detach()             fin_targets.extend(targets.numpy().tolist())'),\n",
       " VectorParams(vector=[-0.16666074097156525, -0.1916532963514328, 0.04057467728853226, 0.11939190328121185, 0.15531402826309204, -0.013784579001367092, 0.04163755849003792, 0.03679623454809189, -0.07682379335165024, -0.07594150304794312, 0.032644469290971756, -0.11155255883932114, -0.07994312047958374, -0.10804133117198944, -0.05765799805521965, 0.07609065622091293, -0.016872012987732887, -0.1108044758439064, -0.13104763627052307, -0.12369831651449203, 0.15525870025157928, 0.08010439574718475, 0.04039525240659714, 0.09021397680044174, -0.03166315704584122, 0.007928137667477131, 0.009404425509274006, 0.0905342698097229, -0.04342539981007576, 0.0006178360199555755, 0.02867037057876587, -0.000570225587580353, -0.026667248457670212, 0.03367971256375313, 0.055611684918403625, 0.0835949257016182, -0.07804601639509201, 0.009890176355838776, -0.09323833882808685, 0.12653204798698425, 0.019129907712340355, -0.08871014416217804, 0.004915094934403896, -0.05414543300867081, 0.1051105409860611, -0.027553969994187355, -0.0013176490319892764, -0.04615747556090355, 0.08266359567642212, -0.08765094727277756, -0.05303946137428284, 0.04004190117120743, -0.03563564270734787, 0.054951172322034836, -0.03960690274834633, -0.018889805302023888, 0.06867627799510956, -0.1451137661933899, 0.0329233855009079, -0.2180154174566269, -0.08760656416416168, -0.038797102868556976, -0.00016666806186549366, -0.14891406893730164, -0.011900080367922783, -0.04034532606601715, -0.09572432190179825, 0.058784160763025284, -0.038055580109357834, 0.059840235859155655, 0.013422827236354351, 0.07857446372509003, -0.022939814254641533, 0.13303986191749573, -0.029064422473311424, -0.06399957090616226, 0.24309462308883667, -0.10758215188980103, 0.12754926085472107, -0.1165294274687767, -0.16667212545871735, -0.08599080890417099, 0.11576163023710251, 0.03320738300681114, 0.07810991257429123, -0.14234299957752228, 0.10809918493032455, 0.025780564174056053, 0.05250535532832146, 0.007675287779420614, -0.014483941718935966, -0.05752229690551758, -0.010840211994946003, -0.04272664338350296, 0.10170929878950119, 0.1439265012741089, 0.003303641453385353, 0.0031943682115525007, -0.06989297270774841, 0.18386289477348328, 0.013602758757770061, 0.03682853654026985, -0.058601900935173035, 0.010723377577960491, -0.0196540430188179, 0.13947667181491852, 0.08628879487514496, 0.08666719496250153, 0.04601631313562393, -0.18591724336147308, 0.029118884354829788, 0.04956649988889694, -0.01683405227959156, -0.024037083610892296, 0.0736016184091568, 0.06359998136758804, -0.0829906314611435, 0.09353702515363693, -0.14888858795166016, 0.29007312655448914, -0.060911018401384354, 0.12386759370565414, -0.03342951089143753, 0.24504084885120392, 0.00512014189735055, -0.01810411922633648, -0.05072617530822754, 1.4546974751560095e-32, -0.1322900354862213, -0.0032868613488972187, -0.030002053827047348, -0.18185898661613464, -0.07718879729509354, 0.03979937732219696, 0.01816158927977085, 0.0370730496942997, -0.0931839793920517, 0.025497453287243843, -0.17584803700447083, 0.016173923388123512, -0.08263635635375977, 0.029647424817085266, -0.06610768288373947, -0.1196439117193222, 0.06342506408691406, 0.013752852566540241, 0.09130477905273438, 0.0073361992835998535, 0.23842087388038635, 0.03392826020717621, -0.08181405812501907, -0.20243418216705322, -0.22368548810482025, -0.01814936473965645, -0.07282038778066635, -0.0003550833207555115, -0.14810970425605774, 0.028939470648765564, -0.24089863896369934, 0.11077029258012772, 0.04123933985829353, -0.04509107396006584, 0.03273575380444527, -0.09498979151248932, 0.035903364419937134, 0.04448198527097702, -0.014501883648335934, -0.08909494429826736, -0.03421026095747948, 0.14337782561779022, -0.0010472839931026101, -0.07792055606842041, -0.041772954165935516, 0.0811922550201416, -0.002304760506376624, 0.04894721508026123, 0.08296097069978714, 0.03148922324180603, -0.01715661771595478, -0.0935111865401268, 0.012291845865547657, 0.03610793128609657, -0.10849452018737793, 2.2072166757425293e-05, 0.10419358313083649, -0.030458232387900352, 0.20234835147857666, -0.10653114318847656, 0.015470626763999462, 0.020136864855885506, -0.06397610902786255, -0.07459418475627899, -0.016201069578528404, -0.012210394255816936, 0.06846123188734055, 0.1011485829949379, 0.04624968022108078, -0.06310714781284332, -0.10311024636030197, 0.039332326501607895, 0.015449265949428082, -0.028967948630452156, 0.13321831822395325, -0.14873801171779633, 0.0675368532538414, -0.12546947598457336, -0.1260662078857422, -0.050181906670331955, 0.05762777850031853, 0.0737234503030777, -0.08080428838729858, -0.25202617049217224, 0.01933746226131916, -0.03200117126107216, 0.022926172241568565, -0.06081145256757736, -0.13841547071933746, 4.6131866838550195e-05, -0.17340175807476044, -0.03754537180066109, 0.07029036432504654, -0.058619625866413116, -0.11160677671432495, -1.49850638636963e-32, -0.04099744185805321, 0.13839685916900635, -0.05944204330444336, 0.05411270260810852, -0.019900955259799957, 0.07149163633584976, 0.046656008809804916, 0.08497848361730576, -0.01884559728205204, -0.08272058516740799, 0.02063640207052231, -0.19832338392734528, -0.060824841260910034, -0.10736533254384995, 0.05317317321896553, 0.03319649025797844, -0.12083058059215546, 0.1520962417125702, 0.003926544915884733, 0.03065112605690956, -0.1752912700176239, 0.23591700196266174, -0.25844523310661316, 0.05395791679620743, -0.1609363853931427, 0.10531269758939743, -0.015188534744083881, 0.2660141885280609, 0.02276664413511753, -0.04485711455345154, -0.04039015620946884, 0.04377181455492973, -0.19262877106666565, 0.11337845772504807, 0.011230183765292168, 0.0358002595603466, 0.07449834048748016, -0.09494668245315552, -0.0725896805524826, 0.18763233721256256, 0.18704068660736084, 0.09143541753292084, -0.12737290561199188, 0.18503715097904205, -0.06096389889717102, 0.0615006759762764, -0.051899682730436325, -0.007711637765169144, -0.05506149306893349, -0.029558641836047173, 0.06413890421390533, -0.03721672669053078, -0.13985112309455872, 0.057040128856897354, -0.06957599520683289, -0.029562298208475113, 0.013685714453458786, -0.018350720405578613, -0.11790595948696136, 0.05591500923037529, -0.09308281540870667, -0.06497642397880554, 0.03970012068748474, -0.08404617011547089, 0.07022358477115631, -0.03394657373428345, -0.07051302492618561, 0.17457950115203857, 0.11287344247102737, 0.06518733501434326, -0.13213016092777252, 0.14303334057331085, 0.1594392955303192, -0.10954180359840393, -0.05522564426064491, 0.11627854406833649, -0.01727084256708622, -0.06479724496603012, -0.0039634015411138535, 0.026243584230542183, -0.15315911173820496, -0.05062739551067352, 0.054514266550540924, 0.03628777340054512, -0.00879240408539772, 0.10308573395013809, 0.19794581830501556, 0.13563306629657745, 0.011395717971026897, -0.148324653506279, 0.03644147515296936, -0.09318982064723969, 0.1946229636669159, 0.19499990344047546, 0.06952608376741409, -1.0038147024715727e-07, -0.030594272539019585, -0.002840199042111635, -0.023259785026311874, 0.15791185200214386, 0.00959564559161663, -0.0012317384826019406, -0.02068265713751316, -0.008417630568146706, -0.025553859770298004, 0.0035370048135519028, 0.14375631511211395, 0.025854192674160004, -0.09849923849105835, 0.03109310381114483, 0.01781073957681656, 0.11556913703680038, -0.015800761058926582, 0.06611249595880508, 0.017351502552628517, -0.05531995743513107, 0.08885341882705688, 0.010056335479021072, -0.03378450125455856, -0.04772336781024933, 0.034437842667102814, -0.1560198813676834, -0.037066664546728134, 0.12310098111629486, -0.017462527379393578, 0.06689520925283432, -0.029550466686487198, -0.10970503836870193, -0.023635542020201683, 0.04524266719818115, 0.17183484137058258, 0.10168617218732834, 0.03901662677526474, -0.03411082550883293, 0.06741519272327423, 0.031704433262348175, -0.05794693902134895, 0.16955381631851196, -0.18757250905036926, -0.06115531921386719, 0.09486111253499985, -0.052711717784404755, 0.009128143079578876, -0.0640525221824646, 0.10742057859897614, 0.08682581782341003, 0.009837274439632893, -0.0059149363078176975, -0.07333975285291672, 0.1055188849568367, 0.15702109038829803, -0.157021164894104, -0.14503538608551025, -0.029001150280237198, -0.1191973090171814, 0.035203590989112854, 0.018279485404491425, -0.02366415411233902, -0.04466191679239273, -0.021975452080368996], metadata={'source': 'AAAMLP-569to.pdf', 'page': 267}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 268              # convert outputs to cpu and extend the final list             outputs = torch.sigmoid(outputs).cpu().detach()             fin_outputs.extend(outputs.numpy().tolist())     return fin_outputs, fin_targets ═════════════════════════════════════════════════════════════════════════  And finally, we are ready to train. Let’s look at the training script!  ═════════════════════════════════════════════════════════════════════════ # train.py import config import dataset import engine import torch import pandas as pd import torch.nn as nn import numpy as np  from model import BERTBaseUncased from sklearn import model_selection from sklearn import metrics from transformers import AdamW from transformers import get_linear_schedule_with_warmup   def train():     # this function trains the model          # read the training file and fill NaN values with \"none\"     # you can also choose to drop NaN values in this      # specific dataset     dfx = pd.read_csv(config.TRAINING_FILE).fillna(\"none\")      # sentiment = 1 if its positive     # else sentiment = 0     dfx.sentiment = dfx.sentiment.apply(         lambda x: 1 if x == \"positive\" else 0     )      # we split the data into single training     # and validation fold     df_train, df_valid = model_selection.train_test_split(         dfx,          test_size=0.1,          random_state=42,          stratify=dfx.sentiment.values'),\n",
       " VectorParams(vector=[-0.15858164429664612, -0.17037156224250793, -0.031422365456819534, 0.1599801480770111, 0.03617960587143898, -0.026426618918776512, 0.056395839899778366, 0.11582989245653152, -0.1584918200969696, -0.06789377331733704, -0.02705138921737671, -0.12593479454517365, -0.08679936826229095, -0.04999551922082901, -0.062442123889923096, 0.107114277780056, 0.054099760949611664, -0.05422563478350639, -0.1665022373199463, -0.09148514270782471, 0.1478486806154251, 0.13524657487869263, 0.10354761779308319, 0.03328491747379303, 0.047909289598464966, -0.1451522409915924, -0.013321087695658207, 0.0295424647629261, 0.03489750251173973, 0.01998152956366539, 0.124109648168087, -0.023184344172477722, -0.0609557144343853, 0.1569788157939911, 0.10358862578868866, 0.025663360953330994, -0.10100079327821732, -0.058148663491010666, -0.05794653668999672, 0.13499955832958221, -0.009052472189068794, 0.02334960177540779, -0.1592615693807602, -0.05660540983080864, 0.08413168042898178, -0.021265622228384018, 0.00031577525078319013, -0.03067476861178875, 0.11814666539430618, -0.07284439355134964, -0.08335676044225693, 0.04977380484342575, 0.0308828204870224, -0.019989244639873505, -0.05059663578867912, -0.061193082481622696, 0.14086508750915527, -0.09399545937776566, 0.01312562171369791, -0.19267134368419647, -0.05118583142757416, -0.09741581231355667, 0.0006938318838365376, -0.08185910433530807, -0.1315629780292511, 0.02369234524667263, -0.08514974266290665, 0.009609486907720566, 0.048592016100883484, 0.05475476384162903, -0.009461312554776669, 0.17960931360721588, -0.05548861622810364, 0.08801748603582382, -0.05993293970823288, -0.06416743993759155, 0.22841200232505798, -0.09346511214971542, 0.09414667636156082, -0.1935819536447525, -0.1375122219324112, -0.08145149797201157, 0.14089414477348328, 0.04571366682648659, 0.19696667790412903, -0.23234961926937103, 0.16097436845302582, 0.03705593943595886, 0.09018796682357788, -0.03028242662549019, 0.10074727982282639, -0.018940268084406853, -0.005420652683824301, 0.003966891206800938, 0.11291445046663284, 0.09027571976184845, 0.05354980379343033, -0.053179219365119934, -0.10114041715860367, 0.14684370160102844, -0.03552785515785217, -0.05090513080358505, -0.02359633520245552, 0.08510063588619232, -0.0003299047821201384, 0.1334792971611023, 0.11934163421392441, 0.09552774578332901, 0.01174844242632389, -0.11678048223257065, 0.04235103353857994, 0.05598945543169975, 0.015128434635698795, -0.03963961824774742, 0.12609870731830597, 0.05258515849709511, -0.0572270005941391, 0.047870587557554245, -0.14381898939609528, 0.2260631024837494, -0.0933861956000328, -0.004724561236798763, -0.036785174161195755, 0.06469719856977463, -0.0901046097278595, -0.01669597066938877, -0.06436951458454132, 1.8770246774156254e-32, -0.0694735199213028, -0.04379735141992569, -0.07295328378677368, -0.16468586027622223, -0.08553757518529892, 0.035492055118083954, 0.08914151787757874, 0.0613379068672657, -0.09458576142787933, -0.045949846506118774, -0.20475028455257416, 0.01925244741141796, -0.1319013237953186, 0.024854963645339012, -0.06810184568166733, -0.0524151436984539, -0.036995358765125275, 0.14485810697078705, 0.10695990175008774, 0.02911326102912426, 0.2718765437602997, 0.006345952395349741, -0.0739978477358818, -0.13825835287570953, -0.23104621469974518, 0.07537047564983368, 0.0184551402926445, -0.03111303597688675, -0.15732811391353607, 0.05905398726463318, -0.2898046374320984, 0.03983435407280922, 0.05085276439785957, -0.040696971118450165, -0.04942203313112259, -0.08588115870952606, 0.037558332085609436, 0.02708839252591133, 0.030183346942067146, -0.14500395953655243, -0.04672810807824135, 0.1378510743379593, 0.04944451525807381, -0.10915810614824295, -0.1069156751036644, -0.03000020794570446, -0.013716940768063068, 0.12155330926179886, 0.032803431153297424, 0.05428558588027954, -0.05674617365002632, -0.07403714209794998, 0.017510317265987396, 0.09451843798160553, -0.06527894735336304, -0.058235932141542435, 0.11012823134660721, -0.0006535379798151553, 0.2724478542804718, -0.09972582012414932, 0.054551318287849426, 0.015060841105878353, -0.0367094911634922, -0.017398620024323463, 0.06803467869758606, 0.003855509450659156, 0.022442413493990898, 0.05583063140511513, -0.0004018566687591374, -0.011132546700537205, -0.15992876887321472, 0.06023595854640007, 0.0033207444939762354, -0.08927660435438156, 0.10698357224464417, -0.20890778303146362, 0.014791281893849373, -0.12734651565551758, -0.2500304877758026, -0.0018028508638963103, 0.03324452042579651, 0.15518911182880402, -0.12656916677951813, -0.2751442492008209, -0.09594913572072983, -0.09933541715145111, 0.06120602786540985, -0.0935852900147438, -0.135308638215065, -0.047562334686517715, -0.18668290972709656, -0.09183837473392487, 0.09244239330291748, -0.04043234884738922, -0.09071876108646393, -1.5791228175065794e-32, -0.06174227595329285, 0.08628005534410477, 0.024591712281107903, 0.08943378180265427, -0.023277312517166138, -0.04791233316063881, 0.030192555859684944, 0.10181012749671936, 0.02485787123441696, -0.1106182336807251, 0.04809986427426338, -0.26592135429382324, -0.05952448770403862, -0.0712500661611557, 0.13847754895687103, 0.04555888473987579, -0.14671002328395844, 0.14292748272418976, 0.00027030930505134165, 0.0629022940993309, -0.15033882856369019, 0.13384495675563812, -0.20797216892242432, 0.10684811323881149, -0.14595149457454681, 0.1415739804506302, -0.03194371610879898, 0.11888974159955978, 0.10977278649806976, -0.0844670757651329, -0.012636860832571983, 0.12463590502738953, -0.1903974711894989, 0.13959059119224548, -0.0019039683975279331, 0.06383511424064636, 0.16290326416492462, -0.131923109292984, -0.0925818383693695, 0.1524898260831833, 0.3374350666999817, 0.1533302515745163, -0.07181376218795776, 0.124931700527668, -0.041693877428770065, 0.025011802092194557, -0.11165262758731842, -0.006365623790770769, -0.07850558310747147, -0.11800749599933624, 0.06636648625135422, -0.11064852029085159, -0.078720822930336, 0.09367690235376358, -0.03956511989235878, -0.0853348895907402, 0.07654757052659988, -0.036545757204294205, -0.10853446274995804, 0.00860248040407896, -0.05676275119185448, -0.07761427760124207, 0.032133202999830246, -0.08688434958457947, 0.014102863147854805, 0.006656976882368326, -0.05817636102437973, 0.18359830975532532, 0.02432975545525551, 0.10393933951854706, -0.17091423273086548, 0.11670270562171936, 0.21446532011032104, 0.022357556968927383, -0.048083193600177765, 0.1492646038532257, -0.10193676501512527, -0.0888911634683609, 0.07365402579307556, 0.058893222361803055, -0.0329597070813179, -0.07847081869840622, 0.10873440653085709, 0.005047901067882776, 0.005138481501489878, 0.1289868950843811, 0.09091492742300034, 0.2217019647359848, -7.106229168130085e-05, -0.1119951531291008, -0.03665176406502724, -0.13423384726047516, 0.2155170738697052, 0.20654670894145966, 0.08984531462192535, -1.0105895142942245e-07, -0.003349835751578212, 0.03847311809659004, 0.062268633395433426, 0.1848486214876175, -0.0740780308842659, -0.07919231802225113, 0.010981489904224873, 0.0441010482609272, -0.054257262498140335, -0.08347220718860626, 0.187331423163414, 0.08996322751045227, -0.07966938614845276, 0.012029689736664295, -0.02059604972600937, 0.1207607164978981, -0.06203758716583252, 0.046263568103313446, 0.06077057123184204, -0.06403076648712158, 0.002636650810018182, -0.01752544194459915, 0.006566585041582584, -0.04569077864289284, 0.05581800267100334, -0.1280599981546402, 0.02859373204410076, 0.10080975294113159, -0.038313716650009155, 0.03948317468166351, 0.016687368974089622, -0.0981803685426712, -0.047338247299194336, 0.08359035104513168, 0.1697615385055542, 0.16358321905136108, 0.018227150663733482, -0.018434055149555206, 0.046793583780527115, 0.12382657080888748, -0.05423472449183464, 0.18041358888149261, -0.1652422547340393, -0.09667769819498062, 0.14276079833507538, 0.00922185555100441, -0.0800376683473587, -0.046435847878456116, 0.11544827371835709, 0.04320479929447174, -0.035087790340185165, 0.01807338185608387, -0.13840891420841217, 0.11993317306041718, -0.013316239230334759, -0.11548427492380142, -0.18221473693847656, -0.010813686065375805, -0.07957037538290024, -0.038448791950941086, 0.04617774486541748, 0.02728612720966339, -0.05079811066389084, 0.010399685241281986], metadata={'source': 'AAAMLP-569to.pdf', 'page': 268}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 269     )      # reset index     df_train = df_train.reset_index(drop=True)     df_valid = df_valid.reset_index(drop=True)      # initialize BERTDataset from dataset.py     # for training dataset     train_dataset = dataset.BERTDataset(         review=df_train.review.values,          target=df_train.sentiment.values     )      # create training dataloader     train_data_loader = torch.utils.data.DataLoader(         train_dataset,          batch_size=config.TRAIN_BATCH_SIZE,          num_workers=4     )      # initialize BERTDataset from dataset.py     # for validation dataset     valid_dataset = dataset.BERTDataset(         review=df_valid.review.values,          target=df_valid.sentiment.values     )      # create validation data loader     valid_data_loader = torch.utils.data.DataLoader(         valid_dataset,          batch_size=config.VALID_BATCH_SIZE,          num_workers=1     )      # initialize the cuda device     # use cpu if you dont have GPU     device = torch.device(\"cuda\")     # load model and send it to the device     model = BERTBaseUncased()     model.to(device)      # create parameters we want to optimize     # we generally dont use any decay for bias     # and weight layers      param_optimizer = list(model.named_parameters())     no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]     optimizer_parameters = ['),\n",
       " VectorParams(vector=[-0.15076248347759247, -0.010816545225679874, -0.029202135279774666, 0.12507472932338715, -0.044106874614953995, -0.15380968153476715, -0.15023081004619598, 0.15223878622055054, -0.22973160445690155, -0.12177477031946182, -0.10653332620859146, -0.0811668261885643, -0.017683736979961395, -0.08887064456939697, -0.04314588010311127, 0.025306476280093193, -0.06874336302280426, -0.0016070622950792313, -0.10671596229076385, -0.18713293969631195, 0.11265958845615387, 0.11475324630737305, -0.014122363179922104, 0.11265897750854492, -0.010950298048555851, -0.11249689757823944, 0.0059271203354001045, 0.02317921258509159, 0.02957543544471264, 0.053596630692481995, 0.10333171486854553, -0.10810975730419159, -0.035859182476997375, 0.06312887370586395, 0.026011327281594276, 0.08951275795698166, -0.17306777834892273, -0.1407642811536789, -0.05316423997282982, 0.04666488617658615, 0.09576365351676941, -0.026280658319592476, -0.09531126171350479, -0.07279571890830994, 0.1460951864719391, 0.0181205403059721, -0.07167652249336243, 0.0020500975660979748, 0.11349788308143616, -0.060840435326099396, 0.007468749303370714, -0.08895756304264069, -0.043235693126916885, -0.005392506252974272, -0.11470606923103333, 0.007017096038907766, 0.08876045793294907, -0.12376292794942856, 0.04521264135837555, -0.1297086775302887, -0.08050935715436935, -0.058279965072870255, -0.05087284371256828, -0.057879526168107986, -0.09888502955436707, 0.023030418902635574, 0.04715299606323242, -0.01583769917488098, 0.017192017287015915, 0.10950946062803268, 0.060391660779714584, 0.11056262254714966, -0.05183611810207367, 0.0002362345694564283, -0.047608599066734314, -0.0308631993830204, 0.22423595190048218, 0.04284502565860748, -0.002779464703053236, -0.17545944452285767, -0.03758099675178528, -0.0907207801938057, 0.03641649708151817, -0.07910411804914474, 0.031868040561676025, -0.18049108982086182, 0.08718936890363693, 0.025253307074308395, 0.17741432785987854, -0.06942275166511536, 0.12657085061073303, 0.1856253296136856, -0.10994382202625275, 0.027300948277115822, 0.07791068404912949, 0.14201144874095917, 0.03361310437321663, -0.011611176654696465, -0.12816482782363892, 0.09146285802125931, -0.054341889917850494, -0.12032737582921982, 0.0964072197675705, 0.11132930964231491, -0.006599630229175091, 0.09538682550191879, 0.07472126185894012, 0.08822217583656311, -0.00511009618639946, -0.04978225380182266, 0.08943475782871246, 0.05539538711309433, 0.02519550360739231, 0.028496935963630676, 0.13303886353969574, 0.1706199198961258, -0.03897193819284439, 0.005099644418805838, -0.10841816663742065, 0.22907060384750366, -0.08144639432430267, -0.005293285008519888, 0.0030358857475221157, 0.05263253673911095, -0.021794645115733147, -0.06737107783555984, -0.12035948783159256, 1.7639266925031668e-32, -0.0864163488149643, -0.1701532006263733, 0.01793716289103031, -0.2492145150899887, 0.05151672288775444, -0.03444793447852135, 0.034571751952171326, 0.05185330659151077, -0.05684157460927963, -0.08887016773223877, -0.2589772939682007, -0.008718296885490417, -0.064117431640625, -0.015664251521229744, 0.039260007441043854, -0.10592036694288254, 0.06256452947854996, 0.07323967665433884, 0.09848205745220184, 0.017524845898151398, 0.23013843595981598, -0.19236086308956146, -0.07962647825479507, -0.09407036751508713, -0.060650791972875595, 0.16631048917770386, 0.024844635277986526, -0.024684667587280273, -0.1542762815952301, 0.03223891928792, -0.13128361105918884, 0.014400303363800049, -0.044639863073825836, -0.020509932190179825, 0.0029987599700689316, -0.15723496675491333, 0.0557900108397007, 0.1649983525276184, 0.048922348767519, -0.08345305919647217, -0.1021808385848999, 0.036774344742298126, 0.099995918571949, -0.13237430155277252, -0.05423929914832115, -0.05013127997517586, 0.10589511692523956, 0.10800043493509293, 0.018002856522798538, 0.10211354494094849, 0.052212342619895935, -0.09567368030548096, -0.03231415897607803, -0.10342536866664886, -0.07680956274271011, 0.023717863485217094, 0.10858360677957535, 0.1240934506058693, 0.16215787827968597, 0.05830737203359604, 0.073353111743927, -0.013962727040052414, 0.0192672461271286, -0.019773822277784348, 0.08175204694271088, 0.05780400335788727, -0.05191315710544586, 0.015047878958284855, 0.04652637988328934, 0.06559818983078003, -0.10168983787298203, 0.018325060606002808, 0.11687543988227844, -0.07271022349596024, 0.21362139284610748, -0.20266318321228027, 0.17019879817962646, -0.016147766262292862, -0.2371276170015335, -0.010884313844144344, -0.0531071200966835, 0.17441824078559875, -0.04962465912103653, -0.16464418172836304, -0.05754443258047104, -0.07764627784490585, 0.0638272687792778, 0.0204818956553936, -0.09080144762992859, -0.025994446128606796, -0.20673897862434387, -0.07768724858760834, 0.022249316796660423, 0.08241117000579834, -0.042703066021203995, -1.4845272606128575e-32, 0.10835963487625122, 0.04977380856871605, 0.08541135489940643, 0.1319471299648285, 0.14581942558288574, -0.007916802540421486, 0.09295076876878738, 0.026417607441544533, -0.002351281465962529, -0.09356976300477982, 0.038943350315093994, -0.10995810478925705, 0.03174222260713577, 0.014779599383473396, 0.07971712946891785, -0.0306333489716053, 0.03274589776992798, 0.03307180479168892, -0.0037531766574829817, 0.08593378961086273, -0.09370339661836624, 0.19462506473064423, -0.32724788784980774, -0.12357618659734726, -0.03101242706179619, 0.019519079476594925, -0.0323452427983284, 0.1708654761314392, 0.05145658925175667, -0.06218321993947029, -0.10846874117851257, 0.07616018503904343, -0.08902156352996826, 0.008686095476150513, 0.09761597216129303, 0.11460808664560318, 0.09468923509120941, -0.004176486283540726, -0.01607700064778328, 0.16885656118392944, 0.3489580750465393, 0.0945855900645256, -0.034651558846235275, 0.07354124635457993, -0.003955435939133167, 0.07139299064874649, -0.055707816034555435, -0.055722225457429886, -0.16024573147296906, -0.0004275278770364821, 0.0033274220768362284, -0.11106754839420319, -0.14862601459026337, 0.17831766605377197, 0.05157483369112015, -0.0011639866279438138, 0.037000350654125214, -0.06898455321788788, -0.09981100261211395, -0.07731855660676956, -0.06377137452363968, -0.1070081889629364, 0.00010053316509583965, -0.05092605948448181, 0.05094721168279648, 0.04630017653107643, -0.0910838320851326, 0.015060137026011944, 0.014713785611093044, 0.1258963942527771, -0.1288888305425644, 0.07466203719377518, 0.10466013103723526, 0.09598545730113983, -0.16012725234031677, 0.07983790338039398, -0.038421157747507095, -0.04367269575595856, -0.04429680109024048, 0.04087405651807785, -0.10476554930210114, -0.022941650822758675, 0.03173312544822693, 0.08751479536294937, -0.03061630018055439, 0.11843282729387283, 0.03717762231826782, 0.20427295565605164, 0.12933045625686646, -0.09025117009878159, 0.044181521981954575, -0.08570622652769089, 0.0693853497505188, 0.20547188818454742, 0.0246942937374115, -1.0044583120816242e-07, 0.011578481644392014, 0.10049722343683243, 0.04724260792136192, 0.08935751020908356, 0.18284747004508972, -0.06462202221155167, 0.08656173199415207, -0.0014825736870989203, -0.01886201649904251, 0.02188270166516304, 0.13612909615039825, -8.575386164011434e-05, -0.012019803747534752, -0.0005496952217072248, -0.027791744098067284, 0.05237864330410957, -0.06416072696447372, 0.01749424636363983, 0.02150760591030121, -0.07498889416456223, -0.022040177136659622, -0.08717970550060272, -0.03909654542803764, -0.09914252161979675, 0.11907870322465897, -0.1361061930656433, 0.02380775287747383, 0.05536515265703201, 0.06314575672149658, -0.011989408172667027, -0.08485934138298035, -0.04129729047417641, 0.06440147757530212, 0.021940479055047035, 0.06014353409409523, 0.09166430681943893, 0.0811474546790123, 0.14300476014614105, 0.10529660433530807, 0.08990229666233063, -0.025690698996186256, 0.08799095451831818, -0.09653912484645844, -0.09963319450616837, 0.13224977254867554, 0.01558118499815464, -0.05085987597703934, -0.0758955329656601, 0.16572034358978271, 0.022757036611437798, -0.022545211017131805, -0.056638896465301514, -0.08308485895395279, 0.07940661907196045, 0.06581873446702957, -0.2203354686498642, -0.10473868995904922, -0.15910309553146362, -0.05347755178809166, -0.012638001702725887, 0.0020343309734016657, -0.1369587779045105, -0.1654479056596756, -0.027126112952828407], metadata={'source': 'AAAMLP-569to.pdf', 'page': 269}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 270         {             \"params\": [                 p for n, p in param_optimizer if                  not any(nd in n for nd in no_decay)             ],             \"weight_decay\": 0.001,         },         {             \"params\": [                 p for n, p in param_optimizer if                  any(nd in n for nd in no_decay)             ],             \"weight_decay\": 0.0,         },     ]      # calculate the number of training steps     # this is used by scheduler     num_train_steps = int(         len(df_train) / config.TRAIN_BATCH_SIZE * config.EPOCHS     )      # AdamW optimizer     # AdamW is the most widely used optimizer     # for transformer based networks     optimizer = AdamW(optimizer_parameters, lr=3e-5)      # fetch a scheduler     # you can also try using reduce lr on plateau     scheduler = get_linear_schedule_with_warmup(         optimizer,          num_warmup_steps=0,          num_training_steps=num_train_steps     )      # if you have multiple GPUs     # model model to DataParallel     # to use multiple GPUs     model = nn.DataParallel(model)      # start training the epochs     best_accuracy = 0     for epoch in range(config.EPOCHS):         engine.train_fn(             train_data_loader, model, optimizer, device, scheduler         )         outputs, targets = engine.eval_fn('),\n",
       " VectorParams(vector=[-0.13780248165130615, -0.09325550496578217, -0.0031846489291638136, 0.025043757632374763, 0.043558016419410706, -0.021405572071671486, -0.039541661739349365, 0.12059450149536133, -0.03582187369465828, 0.04139866307377815, -0.14945995807647705, -0.0257651936262846, -0.028078023344278336, 0.08149120956659317, 0.029994269832968712, 0.07342173159122467, 0.06286141276359558, 0.10964102298021317, -0.14685478806495667, -0.05948702618479729, 0.08777084201574326, 0.042100850492715836, 0.015490776859223843, -0.016956103965640068, -0.012276478111743927, 0.002667487133294344, -0.0053826551884412766, -0.021726837381720543, -0.06302786618471146, -0.024461038410663605, -0.004106250125914812, 0.05258530378341675, -0.11912117898464203, 0.10601145774126053, -0.07629085332155228, 0.06012936681509018, -0.05767892673611641, -0.020196612924337387, 0.01817978359758854, 0.013089628890156746, 0.0018168985843658447, 0.00010006912634707987, -0.029618067666888237, -0.03343122825026512, 0.08164643496274948, 0.01640637218952179, -0.03603557124733925, -0.03761749342083931, 0.005925703793764114, -0.05196413770318031, -0.08024844527244568, -0.018574420362710953, -0.053792353719472885, 0.11557914316654205, -0.06772404909133911, 0.01987975463271141, 0.11957494169473648, -0.08391381800174713, -0.0894143208861351, -0.13253024220466614, -0.07457039505243301, -0.0384412445127964, -0.032030876725912094, -0.030330972746014595, -0.03813585266470909, 0.04536076635122299, -0.015977106988430023, 0.018793251365423203, 0.04099580645561218, 0.03792863339185715, -0.047916363924741745, 0.0735362246632576, -0.001766568748280406, 0.03962312638759613, 0.02874935045838356, -0.1281815767288208, 0.20561790466308594, 0.005360364448279142, 0.07591884583234787, -0.05064177140593529, 0.02367849461734295, 0.07921727001667023, 0.029204782098531723, 0.026748135685920715, 0.13981004059314728, -0.08132325112819672, 0.039945002645254135, 0.044257987290620804, 0.001892325235530734, -0.06437526643276215, -0.02998138777911663, -0.10619589686393738, 0.07388423383235931, -0.012095748446881771, 0.05984976515173912, 0.15260480344295502, 0.050809282809495926, -0.05117180570960045, -0.06439974159002304, 0.022259561344981194, 0.00634638499468565, 0.011072410270571709, 0.039274245500564575, -0.12031152099370956, -0.004858026280999184, 0.03488985821604729, 0.06638216227293015, 0.06264311820268631, 0.055206235498189926, -0.09311562776565552, 0.042864564806222916, 0.060482535511255264, -0.09309157729148865, -0.04443853348493576, 0.07050420343875885, -0.005389668047428131, -0.017207248136401176, -0.0011131217470392585, -0.004335553850978613, 0.18119767308235168, -0.10649404674768448, 0.06768877804279327, 0.0038662005681544542, 0.09677103161811829, 0.0499248243868351, -0.01937406323850155, -0.05325997248291969, 7.265825356664594e-33, -0.1060018464922905, 0.07354936748743057, -0.08761074393987656, -0.06096528843045235, 0.05668811500072479, 0.0035696884151548147, 0.07760508358478546, 0.0812758058309555, 0.020518064498901367, -0.006639046594500542, -0.09369364380836487, 0.09280616790056229, -0.0873672217130661, 0.08722354471683502, 0.09577519446611404, 0.00821185763925314, -0.10900096595287323, 0.08920207619667053, 0.03678587079048157, 0.01944727823138237, 0.10696347802877426, 0.023009635508060455, 0.011270294897258282, -0.012772048823535442, -0.05993674695491791, 0.00242786668241024, 0.053494516760110855, -0.047154441475868225, -0.1341715008020401, -0.01661386340856552, -0.11573086678981781, 0.017947783693671227, 0.10179810971021652, -0.04746418073773384, 0.006785890087485313, -0.16249114274978638, -0.02932523936033249, -0.03260289132595062, -0.05659593269228935, -0.16005560755729675, -0.08390437811613083, 0.12201319634914398, 0.011474239639937878, -0.00750504806637764, -0.03302137553691864, 0.052289173007011414, -0.04100559651851654, -0.006057897582650185, 0.03181232511997223, -0.0026917133945971727, 0.009560503996908665, -0.0540129616856575, -0.07525724172592163, 0.005356279667466879, 0.004309279378503561, -0.0014076073421165347, 0.03818345442414284, -0.04869600012898445, 0.15301565825939178, 0.005182231776416302, -0.03072439879179001, 0.0530112087726593, 0.013679765164852142, 0.0315975546836853, 0.0577189065515995, -0.01435566321015358, 0.028966937214136124, 0.048904795199632645, 0.07451517879962921, 0.0030956484843045473, -0.14727938175201416, -0.010254418477416039, -0.028334107249975204, -0.07514873147010803, 0.14228135347366333, -0.06560226529836655, 0.12540829181671143, -0.12618835270404816, -0.11919382214546204, 0.022777797654271126, 0.004640656057745218, 0.08319364488124847, -0.05817047134041786, -0.1443653702735901, -0.02199028991162777, 0.002439632313326001, 0.04398432746529579, -0.06631770730018616, -0.045414671301841736, 0.0067979684099555016, -0.0423198863863945, -0.0034502935595810413, -0.0382893942296505, -0.014967330731451511, -0.08924762159585953, -6.054638221905542e-33, -0.03145105391740799, 0.055029723793268204, -0.08681755512952805, 0.15210750699043274, -0.04108899459242821, -0.09402023255825043, 0.014392943121492863, 0.034262511879205704, -0.03986649960279465, -0.08892606943845749, -0.05767970159649849, -0.05625004693865776, 0.00015461898874491453, 0.02026957832276821, 0.06667085736989975, 0.022488530725240707, -0.1267372965812683, 0.008306345902383327, 0.05953317508101463, 0.07696859538555145, 0.010142825543880463, 0.21879474818706512, -0.21371139585971832, -0.03164760023355484, -0.13694988191127777, 0.05475616082549095, -0.18505723774433136, 0.12167788296937943, 0.033445458859205246, -0.08275918662548065, -0.003257011529058218, 0.02621397003531456, -0.06414320319890976, -0.02673809416592121, -0.07605216652154922, 0.027358559891581535, 0.04255491495132446, -0.08598098158836365, 0.0018812206108123064, 0.08690870553255081, 0.1448829472064972, 0.03817208483815193, -0.16657239198684692, 0.049497585743665695, -0.048686012625694275, -0.027717700228095055, -0.09922994673252106, -0.06361009180545807, 0.0059262532740831375, 0.004874845501035452, 0.03719372674822807, -0.06668073683977127, -0.14646433293819427, -0.017174888402223587, 0.011001531966030598, -0.0963781476020813, 0.02588282711803913, -0.09583159536123276, -0.015518385916948318, 0.023073844611644745, -0.08470828831195831, 0.023592039942741394, 0.11983346194028854, -0.011529512703418732, 0.057851724326610565, 0.04729004576802254, -0.061247169971466064, 0.06466706842184067, 0.09196817874908447, 0.11462312191724777, -0.11668633669614792, 0.06304945051670074, 0.11151663213968277, 0.032856956124305725, -0.03186728060245514, 0.047697704285383224, -0.024021580815315247, -0.026284411549568176, -0.06274718046188354, 0.022044483572244644, -0.07676302641630173, -0.018316270783543587, -0.008784167468547821, 0.08788006752729416, -0.0330873467028141, 0.11743167042732239, 0.10504378378391266, 0.04391021281480789, 0.06467626243829727, -0.0353006012737751, -0.042521245777606964, 0.09025542438030243, 0.07200690358877182, 0.1014118567109108, -0.02211521379649639, -9.973348369385349e-08, -0.06310055404901505, 0.09114324301481247, 0.015653163194656372, 0.0574362650513649, 0.002045384841039777, -0.05416584759950638, -0.0697137862443924, 0.1396142542362213, -0.07050613313913345, 0.07578698545694351, 0.16884452104568481, 0.013169321231544018, -0.105741947889328, 0.0736430361866951, 0.006570061668753624, 0.14658032357692719, 0.017389321699738503, 0.047334928065538406, -0.022822625935077667, -0.021715693175792694, 0.1353887915611267, 0.05903830751776695, -0.0009903251193463802, 0.00980894360691309, 0.08212438225746155, -0.09038267284631729, 0.020118433982133865, 0.09267863631248474, -0.015391981229186058, 0.03425437584519386, -0.06686466932296753, -0.0019498055335134268, -0.008439995348453522, 0.04314185678958893, 0.12144607305526733, 0.043242111802101135, 0.03424578160047531, -0.08437899500131607, 0.003928180318325758, 0.08306414633989334, 0.06526787579059601, 0.13694822788238525, -0.1508990377187729, 0.01755467988550663, 0.08582683652639389, -0.1086980551481247, -0.013839289546012878, -0.1294252574443817, 0.040947865694761276, 0.039306703954935074, 0.04344910755753517, -0.0029728394001722336, -0.15243341028690338, 0.11039463430643082, 0.06363141536712646, -0.07886572182178497, -0.10194636136293411, -0.1014627069234848, -0.06533853709697723, 0.053892266005277634, -0.018733331933617592, 0.05772189795970917, 0.009715912863612175, 0.09240991622209549], metadata={'source': 'AAAMLP-569to.pdf', 'page': 270}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 271             valid_data_loader, model, device         )         outputs = np.array(outputs) >= 0.5         accuracy = metrics.accuracy_score(targets, outputs)         print(f\"Accuracy Score = {accuracy}\")         if accuracy > best_accuracy:             torch.save(model.state_dict(), config.MODEL_PATH)             best_accuracy = accuracy   if __name__ == \"__main__\":     train() ═════════════════════════════════════════════════════════════════════════  It might look like a lot at first, but it isn’t once you understand the individual components. You can easily change it to any other transformer model you want to use just by changing a few lines of code.   This model gives an accuracy of 93%! Whoa! That’s much better than any other model. But is it worth it?  We were able to achieve 90% using LSTMs, and they are much simpler, easier to train and faster when it comes to inference. We could improve that model probably by a percent by using different data processing or by tuning the parameters such as layers, nodes, dropout, learning rate, changing the optimizer, etc. Then we will have ~2% benefit from BERT. BERT, on the other hand, took much longer to train, has a lot of parameters and is also slow when it comes to inference. In the end, you should look at your business and choose wisely. Don’t choose BERT only because it’s “cool”.  It must be noted that the only task we discussed here is classification but changing it to regression, multi-label or multi-class will require only a couple of lines of code changes. For example, the same problem in multi-class classification setting will have multiple outputs and Cross-Entropy loss. Everything else should remain the same. Natural language processing is huge, and we discussed only a small fraction of it. Apparently, this is a huge fraction as most of the industrial models are classification or regression models. If I start writing in detail about everything I might end up writing a few hundred pages, and that’s why I have decided to include everything in a separate book: Approaching (Almost) Any NLP Problem!'),\n",
       " VectorParams(vector=[-0.10122834891080856, -0.14585590362548828, 0.01524098590016365, -0.010043984279036522, 0.05605655163526535, -0.03237142786383629, -0.10438802093267441, 0.04527917504310608, -0.04779882729053497, 0.014338716864585876, -0.10266466438770294, -0.070980966091156, 0.1312764286994934, -0.014510538429021835, -0.053547605872154236, 0.0562572218477726, 0.09429551661014557, 0.1370782107114792, -0.17912408709526062, 0.07216756790876389, 0.05949339643120766, -0.07560185343027115, -0.003694046987220645, 0.001096150605008006, 0.12256709486246109, -0.007974361069500446, -0.08555850386619568, 0.07822243869304657, -0.1316688060760498, -0.03280175104737282, -0.03290616720914841, -0.10954325646162033, 0.00773568544536829, 0.02121916227042675, -0.10288703441619873, -0.054516687989234924, -0.08335459232330322, -0.01544019766151905, 0.03578880801796913, -0.03265344351530075, -0.06344304233789444, 0.06549347192049026, -0.06385983526706696, -0.1285078227519989, 0.09521865844726562, 0.051861900836229324, 0.0064854403026402, -0.01971779391169548, 0.0708228275179863, -0.05780769884586334, -0.07070673257112503, -0.016994042322039604, -0.14747405052185059, 0.02032136172056198, -0.07476547360420227, -0.061196811497211456, -0.0040650758892297745, -0.07466789335012436, -0.12615966796875, -0.04717877507209778, 0.05199746415019035, -0.08522829413414001, -0.033091168850660324, 0.0683506429195404, 0.11197096109390259, -0.03156844899058342, 0.05802333354949951, 0.18480612337589264, -0.007707939483225346, 0.10740037262439728, 0.03484339267015457, 0.022463100031018257, -0.08643309026956558, 0.07022391259670258, 0.10176356881856918, 0.08975254744291306, 0.1514059603214264, 0.002904105931520462, 0.04936303198337555, 0.04104835167527199, -0.07919695973396301, 0.10540873557329178, -0.019086964428424835, -0.09905576705932617, 0.19618774950504303, -0.08310317993164062, -0.03891252726316452, 0.08841483294963837, 0.07269709557294846, -0.13468889892101288, -0.06638908386230469, 0.11052033305168152, 0.02418745495378971, -0.08164842426776886, 0.1166749894618988, 0.09957217425107956, 0.037121377885341644, -0.0232357457280159, 0.07485944777727127, 0.10142654925584793, -0.06456109881401062, 0.025966426357626915, 0.14142851531505585, -0.19942684471607208, 0.1349903792142868, 0.018016619607806206, 0.08510957658290863, 0.0784677118062973, 0.08531995117664337, -0.19466601312160492, -0.0007489516865462065, -0.06332238763570786, -0.030386226251721382, 0.02104059047996998, -0.014069059863686562, 0.18952181935310364, -0.013218462467193604, 0.05049721896648407, 0.04197144880890846, 0.1853209137916565, -0.15643885731697083, 0.01619735173881054, 0.10680177807807922, -0.07945773005485535, 0.12262172251939774, 0.08788575232028961, -0.10929566621780396, 9.793714203164415e-33, -0.030864818021655083, -0.08318588137626648, 0.009611847810447216, 0.0074034519493579865, 0.14849421381950378, -0.0058882469311356544, 0.08216600120067596, 0.012961791828274727, 0.013532512821257114, 0.06675286591053009, -0.09725506603717804, 0.15063829720020294, 0.1305314302444458, 0.117660753428936, 0.16009630262851715, -0.017956886440515518, -0.10137377679347992, 0.0003953289706259966, -0.025313181802630424, -0.052356135100126266, 0.11702099442481995, -0.04527150094509125, 0.08673883229494095, 0.029144490137696266, -0.013553694821894169, -0.06591817736625671, 0.09431850910186768, 0.041079916059970856, -0.09509076178073883, 0.029818300157785416, -0.012372268363833427, -0.07711252570152283, -0.0667971521615982, -0.021292004734277725, -0.0056124497205019, -0.112732894718647, 0.0056049153208732605, -0.08028272539377213, -0.010111779905855656, -0.03984500840306282, -0.02562323957681656, -0.0026589203625917435, -0.06262398511171341, -0.05072473734617233, -0.053270306438207626, 0.025648685172200203, -0.05188162624835968, 0.048111189156770706, -0.032009802758693695, -0.046013250946998596, 0.04517311602830887, -0.08161243051290512, 0.01891992799937725, -0.05044976621866226, -0.050576794892549515, 0.09896008670330048, 0.04432867467403412, 0.0338834710419178, 0.02825695276260376, 0.03710417076945305, -0.19887083768844604, 0.027379799634218216, -0.015175179578363895, 0.057140909135341644, 0.10216633230447769, 0.009378531947731972, 0.039788492023944855, 0.09590603411197662, 0.08108340203762054, -0.08414207398891449, 0.07651475071907043, -0.00862814486026764, 0.03131198137998581, -0.0945298820734024, 0.09842950105667114, -0.07849569618701935, 0.07328660041093826, -0.07884674519300461, -0.06543736904859543, 0.06697027385234833, 0.001320742885582149, 0.18405306339263916, -0.05757671594619751, -0.129205122590065, -0.06654901802539825, 0.06425199657678604, 0.020702285692095757, -0.0388307124376297, -0.027501525357365608, 0.12375622242689133, -0.15341605246067047, 0.03859717398881912, 0.03074534609913826, -0.13120189309120178, -0.0718444287776947, -6.991463505814734e-33, -0.020963873714208603, -0.04657864570617676, 0.0333554670214653, 0.10905984789133072, 0.04602988809347153, -0.005270806606858969, -0.0718110129237175, -0.16167637705802917, -0.11481577903032303, -0.07547347247600555, -0.033178362995386124, -0.052605558186769485, 0.23547904193401337, -0.061376266181468964, 0.08134450763463974, -0.030661500990390778, -0.06702704727649689, 0.001870824140496552, 0.12706047296524048, 0.029993727803230286, 0.13290435075759888, 0.054399825632572174, 0.01964280754327774, -0.04211666062474251, -0.040430374443531036, 0.011147791519761086, -0.16327325999736786, 0.11778178066015244, 0.05332450568675995, -0.05676424875855446, -0.026193251833319664, -0.051354892551898956, -0.061932481825351715, -0.0026371555868536234, -0.03269962966442108, 0.07520340383052826, 0.04414650425314903, -0.1088281199336052, 0.04288497567176819, -0.018926020711660385, -0.012446089647710323, 0.011173427104949951, -0.08293196558952332, -0.0599493682384491, 0.029062962159514427, -0.09834218770265579, -0.13099779188632965, -0.07609597593545914, 0.02822604775428772, -0.018004996702075005, 0.0035595542285591364, -0.052707623690366745, -0.21977387368679047, 0.05053406208753586, -0.07257051020860672, -0.01643451303243637, -0.03010646067559719, -0.042046766728162766, -0.007138012908399105, 0.03238352760672569, -0.07793726772069931, -0.09803149104118347, 0.040075115859508514, 0.09230522066354752, 0.0509704053401947, 0.08090713620185852, 0.027666784822940826, -0.002340211533010006, 0.011770137585699558, 0.1447412669658661, -0.0868973508477211, 0.033763691782951355, 0.06228732317686081, 0.04441799968481064, -0.0945032387971878, 0.1330559253692627, 0.05022565275430679, 0.09045805782079697, -0.015860149636864662, -0.06447107344865799, -0.08291506767272949, -0.11746528744697571, 0.001908512320369482, 0.04175013676285744, -0.03570202365517616, 0.04061605781316757, 0.1180487871170044, 0.04122049733996391, 0.054286982864141464, -0.11561349779367447, 0.026059094816446304, 0.061623938381671906, 0.21049143373966217, 0.13326413929462433, -0.02846057340502739, -9.916621479533205e-08, 0.18643169105052948, 0.06204554811120033, 0.08512559533119202, -0.007156949024647474, 0.06725503504276276, -0.003869284177199006, -0.10233358293771744, 0.09106972813606262, 0.017434637993574142, 0.02957083098590374, 0.17370034754276276, -0.027210783213377, -0.04816601052880287, 0.05887455865740776, 0.08896338194608688, 0.026634080335497856, -0.08381602168083191, 0.049314841628074646, -0.0866137221455574, -0.07996939867734909, 0.06731082499027252, -0.05815676599740982, 0.057181667536497116, 0.06550344079732895, 0.04901903495192528, 0.06213555485010147, -0.04358622059226036, -0.013013603165745735, 0.01543710008263588, 0.032925888895988464, -0.12254591286182404, -0.04170529544353485, -0.10770433396100998, -0.06242499127984047, 0.15073059499263763, 0.10766122490167618, 0.018309546634554863, 0.021473750472068787, -0.12680058181285858, 0.0649023950099945, 0.03465576469898224, -0.01883649453520775, -0.0036625356879085302, -0.029457852244377136, 0.11992719024419785, -0.11991103738546371, -0.03259461745619774, -0.09766173362731934, 0.10695722699165344, 0.027481311932206154, -0.06207123026251793, 0.00916899275034666, -0.057902075350284576, 0.04254201427102089, -0.0707952156662941, 0.08218037337064743, 0.023800570517778397, -0.147751122713089, 0.017965711653232574, 0.1234569326043129, 0.05228705331683159, -0.1346108466386795, -0.14091528952121735, 0.04901585727930069], metadata={'source': 'AAAMLP-569to.pdf', 'page': 271}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 272 Approaching ensembling and stacking  When we hear these two words, the first thing that comes to our mind is that it’s all about online/offline machine learning competitions. This used to be the case a few years ago, but now with the advancements in computing power and cheaper virtual instances, people have started using ensemble models even in industries. For example, it’s very easy to deploy multiple neural networks and serve them in real-time with a response time of less than 500ms. Sometimes, a huge neural network or a large model can also be replaced by a few other models which are small in size, perform similar to the large model and are twice as fast. If this is the case, which model(s) will you choose? I, personally, would prefer multiple small models, which are faster and give the same performance as a much larger and slower model. Please remember that smaller models are also easier and faster to tune.  Ensembling is nothing but a combination of different models. The models can be combined by their predictions/probabilities. The simplest way to combine models would be just to do an average.  Ensemble Probabilities = (M1_proba + M2_proba + … + Mn_Proba) / n  This is simple and yet the most effective way of combining models. In simple averaging, the weights are equal to all models. One thing that you should keep in mind for any method of combining is that you should always combine predictions/probabilities of models which are different from each other. In simple words, the combination of models which are not highly correlated works better than the combination of models which are very correlated with each other.  If you do not have probabilities, you can combine predictions too. The most simple way of doing this is to take a vote. Suppose we are doing a multi-class classification with three classes: 0, 1 and 2.  [0, 0, 1] : Highest voted class: 0  [0, 1, 2] : Highest voted class: None (Choose one randomly)  [2, 2, 2] : Highest voted class: 2  The following simple functions can accomplish these simple operations.'),\n",
       " VectorParams(vector=[-0.028797106817364693, -0.1997450292110443, -0.07586591690778732, -0.11662042886018753, 0.05112949013710022, -0.06495284289121628, -0.03557993844151497, 0.06133667752146721, -0.09047075361013412, 0.06197981536388397, -0.1100839376449585, -0.038060981780290604, 0.17624346911907196, 0.02964835613965988, -0.028426794335246086, 0.11602461338043213, 0.046382125467061996, -0.029572678729891777, -0.10093500465154648, -0.013361100107431412, 0.05423953756690025, 0.05105041339993477, 0.041328947991132736, 0.014703548513352871, 0.10396663099527359, -0.1685541421175003, 0.15891599655151367, 0.2171872854232788, -0.14891067147254944, -0.06719674915075302, 0.019657861441373825, -0.14416977763175964, 0.10120779275894165, 0.02173462137579918, -0.15918931365013123, -0.03177517652511597, -0.17075686156749725, -0.07620010524988174, -0.011956525966525078, -0.018167635425925255, 0.029444891959428787, 0.14715999364852905, -0.017027782276272774, -0.10916148126125336, 0.038205601274967194, 0.13415610790252686, 0.033237241208553314, -0.1507224291563034, 0.17070525884628296, 0.00021370653121266514, -0.02262655831873417, 0.08976254612207413, -0.10327738523483276, 0.05351996421813965, -0.04538292810320854, -0.11017696559429169, -0.023554839193820953, -0.207526296377182, 0.11097533255815506, -0.2193303257226944, 0.023933080956339836, -0.07747581601142883, 0.005193427205085754, -0.027737483382225037, 0.03821146860718727, -0.054817866533994675, -0.08237846940755844, 0.1583712100982666, -0.11040336638689041, 0.1783289611339569, 0.00893255602568388, 0.06661485135555267, 0.022576281800866127, -0.01358615793287754, 0.06651591509580612, 0.04505322501063347, 0.13346517086029053, 0.007631748449057341, -0.06868342310190201, -0.021246805787086487, -0.08174851536750793, 0.08062034100294113, 0.0894087553024292, -0.013149352744221687, 0.08141350746154785, -0.10577428340911865, -0.0034312012139707804, 0.04747180640697479, 0.1433328241109848, -0.10266082733869553, -0.055500924587249756, 0.07939654588699341, -0.038820575922727585, -0.006461573764681816, 0.02248576655983925, 0.06956715881824493, 0.07298549264669418, -0.14117367565631866, 0.028695764020085335, 0.09631683677434921, -0.06659135967493057, -0.09314624220132828, 0.06464974582195282, -0.17148466408252716, 0.22427242994308472, 0.012127187103033066, -0.04978880658745766, 0.0012562344782054424, 0.05198613181710243, -0.15461668372154236, -0.018508706241846085, -0.15704397857189178, -0.10170164704322815, 0.09906116873025894, 0.02471785619854927, 0.20392270386219025, -0.029326528310775757, 0.10566713660955429, -0.08628033846616745, 0.041590265929698944, -0.02315250225365162, 0.06881058216094971, 0.19628585875034332, 0.05791148543357849, 0.112159363925457, -0.022291269153356552, -0.049974825233221054, 1.474471788062336e-32, -0.09154646098613739, -0.08985698223114014, -0.02390328235924244, -0.0010840039467439055, 0.08921494334936142, 0.16002069413661957, 0.01994244009256363, -0.07111603766679764, -0.0014451871393248439, -0.045310527086257935, -0.17025890946388245, 0.07439649105072021, -0.0023044031113386154, 0.0543806329369545, 0.11067210137844086, 0.0026694710832089186, 0.09538495540618896, -0.02646530792117119, -0.07056805491447449, 8.672665717313066e-05, 0.025194579735398293, 0.012547355145215988, 0.0579783134162426, -0.06136847287416458, -0.07198315858840942, -0.0028620045632123947, 0.016799727454781532, -0.00015416859241668135, -0.15346401929855347, -0.011398272588849068, -0.17771820724010468, 0.0421651266515255, -0.03779682144522667, -0.079684317111969, 0.01841677352786064, -0.0025468668900430202, 0.023039378225803375, 0.06455128639936447, -0.031240174546837807, -0.040979333221912384, -0.0017733295680955052, 0.056437961757183075, 0.0099411616101861, 0.003594461129978299, -0.0834919884800911, -0.017013274133205414, -0.10443185269832611, 0.21382193267345428, -0.009115532971918583, 0.10665563493967056, -0.07333490252494812, -0.16323933005332947, 0.12380647659301758, 0.02034617029130459, -0.15193511545658112, 0.03645213320851326, 0.031224142760038376, -0.00980563834309578, 0.014706781134009361, -0.17644742131233215, -0.021584268659353256, -0.1125672236084938, -0.0873606950044632, -0.007689305115491152, 0.04746619611978531, 0.09483158588409424, 0.00947844423353672, 0.17830312252044678, 0.24599511921405792, 0.10813089460134506, 0.004372409079223871, 0.10890410095453262, -0.1057191863656044, -0.049273811280727386, -0.0735529288649559, 0.03552502021193504, 0.0680006742477417, -0.07132256776094437, 0.026358680799603462, -0.024554619565606117, -0.07174576073884964, 0.12426650524139404, -0.15472212433815002, -0.22318023443222046, 0.0019401188474148512, 0.07401582598686218, 0.08474083989858627, -0.049949321895837784, -0.22021061182022095, -0.02232365868985653, -0.16265460848808289, 0.07875047624111176, -0.020453570410609245, 0.026548609137535095, -0.1538946032524109, -1.5039553904328667e-32, -0.0434456393122673, 0.08437633514404297, 0.14765377342700958, 0.08278776705265045, 0.12144187837839127, -0.0040252795442938805, -0.03925555571913719, -0.06892820447683334, -0.05423547327518463, -0.13128367066383362, -0.07155394554138184, -0.17193613946437836, 0.2613823413848877, -0.06294025480747223, 0.20926474034786224, 0.028960781171917915, -0.2119968682527542, 0.05518794804811478, 0.09383318573236465, -0.06077053025364876, -0.021106915548443794, 0.09484851360321045, -0.1497061848640442, 0.021677512675523758, -0.20061078667640686, 0.040745753794908524, 0.04754692316055298, 0.018862860277295113, -0.04187007248401642, -0.08556074649095535, -0.0870007649064064, 0.024774225428700447, -0.2090759128332138, 0.034909266978502274, -0.05442484840750694, 0.06148960068821907, 0.0878821462392807, -0.16682524979114532, -0.10883428156375885, 0.028286637738347054, 0.06410706788301468, 0.06305674463510513, -0.12959535419940948, -0.031544990837574005, 0.0014199335128068924, 0.02880288101732731, -0.08570477366447449, -0.008640355430543423, -0.030665036290884018, -0.030149564146995544, -0.11656858772039413, 0.07599765062332153, -0.08667191863059998, 0.07289012521505356, -0.16590413451194763, -0.08566854894161224, -0.22195594012737274, 0.045628808438777924, 0.06227674335241318, -0.08508236706256866, -0.014961306937038898, -0.020978698506951332, -0.029289964586496353, 0.10832976549863815, 0.06704634428024292, 0.018851548433303833, -0.09340232610702515, -0.08190223574638367, -0.008820406161248684, 0.2608124017715454, -0.03397985175251961, 0.012814564630389214, 0.0710327997803688, -0.08383390307426453, -0.002007110742852092, 0.024614546447992325, -0.0004844109062105417, -0.04568867012858391, 0.002731204964220524, 0.012998923659324646, -0.05828724801540375, -0.06822550296783447, 0.156244695186615, 0.15887762606143951, -0.07295185327529907, 0.01976643316447735, 0.19381386041641235, 0.15790677070617676, 0.15548370778560638, -0.005284138023853302, 0.010677694343030453, 0.09255266934633255, 0.1113334447145462, 0.106671541929245, -0.06799238175153732, -1.0066662525787251e-07, 0.012470041401684284, 0.10254909843206406, -0.041608382016420364, 0.06858447194099426, 0.010266385041177273, 0.07526488602161407, -0.13871802389621735, 0.03332526609301567, -0.034327298402786255, -0.06674529612064362, 0.13053637742996216, 0.011835210025310516, -0.05346949025988579, -0.05586899444460869, -0.08412718027830124, 0.16650725901126862, -0.05027693137526512, 0.057124897837638855, -0.0284323301166296, -0.061656683683395386, -0.0326116606593132, -0.06767420470714569, 0.00571514293551445, 0.08269868046045303, 0.02720874734222889, -0.0157725028693676, -0.014634902589023113, 0.045922499150037766, -0.03435337170958519, 0.14206446707248688, -0.0691099539399147, -0.1698862910270691, 0.09076020866632462, 0.025547174736857414, 0.12627169489860535, 0.06559140235185623, 0.020476706326007843, 0.02473612129688263, 0.03791871666908264, 0.08976133167743683, -0.051885608583688736, 0.04765394702553749, -0.10956506431102753, -0.003559809410944581, 0.09103178977966309, 0.06985422223806381, 0.11149942874908447, -0.010622427798807621, 0.13750843703746796, 0.02153918147087097, -0.026775294914841652, -0.03699585422873497, -0.012068607844412327, -0.008623669855296612, 0.015100906603038311, 0.0281656626611948, -0.1344357430934906, 0.0807812511920929, 0.02754754014313221, 0.01585491932928562, 0.03090997040271759, -0.0669262558221817, -0.11619110405445099, -0.006002876441925764], metadata={'source': 'AAAMLP-569to.pdf', 'page': 272}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 273 ═════════════════════════════════════════════════════════════════════════ import numpy as np   def mean_predictions(probas):     \"\"\"     Create mean predictions     :param probas: 2-d array of probability values     :return: mean probability     \"\"\"     return np.mean(probas, axis=1)   def max_voting(preds):     \"\"\"     Create mean predictions     :param probas: 2-d array of prediction values     :return: max voted predictions     \"\"\"     idxs = np.argmax(preds, axis=1)     return np.take_along_axis(preds, idxs[:, None], axis=1) ═════════════════════════════════════════════════════════════════════════  Please note that probas have a single probability (i.e. binary classification, usually class 1) in each column. Each column is thus a new model. Similarly, for preds, each column is a prediction from different models. Both these functions assume a 2-dimensional numpy array. You can modify it according to your requirements. For example, you might have a 2-d array of probabilities for each model. In that case, the function will change a bit.  Another way of combining multiple models is by ranks of their probabilities. This type of combination works quite good when the concerned metric is the area under curve as AUC is all about ranking samples.  ═════════════════════════════════════════════════════════════════════════ def rank_mean(probas):     \"\"\"     Create mean predictions using ranks     :param probas: 2-d array of probability values     :return: mean ranks     \"\"\"      ranked = []     for i in range(probas.shape[1]):         rank_data = stats.rankdata(probas[:, i])         ranked.append(rank_data)'),\n",
       " VectorParams(vector=[-0.06008119881153107, -0.17269618809223175, 0.046842120587825775, 0.1911061555147171, 0.1789737045764923, -0.1065673679113388, -0.046946268528699875, 0.12868209183216095, 0.0012577059678733349, 0.13471698760986328, -0.12364224344491959, -0.14745227992534637, 0.09977955371141434, -0.06221558526158333, -0.10368320345878601, 0.17562665045261383, -0.06683635711669922, 0.04634447023272514, -0.12413819879293442, 0.039480600506067276, -0.005006171762943268, 0.08821508288383484, 0.10831010341644287, 0.05278722941875458, 0.09961359947919846, -0.17303466796875, -0.0781942680478096, 0.1606030911207199, -0.06592889875173569, 9.434650564799085e-05, -0.032239705324172974, -0.12201352417469025, 0.1440608948469162, -0.1040404662489891, -0.13382378220558167, -0.0692824199795723, -0.09432531893253326, 0.0028149220161139965, -0.025177251547574997, 0.03177542984485626, 0.03483293205499649, 0.13615953922271729, -0.061235178261995316, -0.10470709204673767, -0.07603557407855988, 0.05199924856424332, -0.06180856004357338, -0.054720357060432434, 0.03709067776799202, -0.03399645909667015, -0.04894369840621948, 0.0031983857043087482, -0.2083435207605362, 0.012143047526478767, -0.12824709713459015, -0.1322062909603119, -0.0751718282699585, -0.18956369161605835, 0.12647420167922974, -0.0926235169172287, -0.029053781181573868, -0.07075407356023788, 0.015394577756524086, -0.07184372842311859, 0.2550331652164459, -0.09821703284978867, -0.07027310132980347, 0.1088898628950119, -0.07256735861301422, 0.1159486174583435, 0.00855505932122469, -0.11120910197496414, -0.024819325655698776, 0.029370563104748726, 0.08269764482975006, 0.040451761335134506, 0.1265963613986969, 0.04935305938124657, 0.03239088132977486, 0.04240105301141739, -0.06782959401607513, 0.03765682503581047, 0.07054097205400467, -0.05619746819138527, 0.12040048837661743, -0.05152047052979469, -0.019017402082681656, 0.03878156840801239, -0.047713857144117355, -0.10219238698482513, 0.04435702785849571, -0.14795678853988647, -0.056793540716171265, 0.07088714092969894, 0.07814548909664154, 0.06451404094696045, 0.11564009636640549, -0.10194956511259079, 0.10811091959476471, 0.0890258401632309, -0.06340054422616959, -0.004859800450503826, 0.1420629322528839, -0.1668243110179901, 0.06016138568520546, -0.089793860912323, 0.03263832628726959, 0.04909442737698555, 0.05670005455613136, -0.09200329333543777, 0.043436791747808456, -0.08655383437871933, -0.1119047999382019, 0.15820060670375824, -0.032785963267087936, 0.24910277128219604, 0.0488981232047081, 0.05717470869421959, -0.04580535739660263, 0.038259293884038925, -0.11131034046411514, -0.023261887952685356, 0.17626789212226868, -0.05734698101878166, 0.12492838501930237, 0.09159735590219498, 0.005229290574789047, 1.1350744632904847e-32, 0.08405731618404388, -0.12913207709789276, -0.06557714194059372, -0.05132624879479408, 0.15695255994796753, 0.004552577622234821, -0.04429027810692787, -0.09249310195446014, -0.02733555994927883, 0.09101910144090652, -0.08228058367967606, 0.07819744944572449, 0.14373080432415009, -0.009370867162942886, -0.0244920551776886, 0.0477202832698822, -0.013975189067423344, 0.0420411080121994, -0.12951864302158356, -0.03669483959674835, 0.1622559130191803, 0.007569385692477226, 0.05093240737915039, -0.09199228137731552, -0.05639710649847984, 0.006146200001239777, 0.0017244763439521194, -0.010764425620436668, -0.06935855001211166, 0.0250504519790411, -0.11183036863803864, -0.05802049860358238, -0.0946437418460846, -0.016278691589832306, -0.0013541722437366843, -0.04092011973261833, -0.00292210909537971, -0.07694356143474579, 0.020510248839855194, -0.03304537013173103, 0.02559046633541584, 0.028327440842986107, -0.011054148897528648, -0.019657565280795097, -0.029147382825613022, 0.09884878247976303, -0.14097565412521362, 0.1801394373178482, -0.1561870127916336, 0.1487538069486618, -0.05343768373131752, -0.046623602509498596, 0.1271248608827591, 0.10512030124664307, -0.050582922995090485, 0.07912859320640564, 0.025083182379603386, -0.06807392835617065, 0.05946628376841545, -0.18307733535766602, 0.00841758493334055, -0.034629978239536285, -0.01894640550017357, -0.04435092583298683, 0.06051179766654968, 0.0803210660815239, 0.006271806545555592, 0.1185646504163742, 0.1077624261379242, 0.051628466695547104, 0.10679028183221817, 0.03688407689332962, -0.06338270008563995, -0.022369010373950005, -0.014681045897305012, 0.03824335336685181, 0.14258822798728943, 0.014784500002861023, 0.06179989501833916, 0.06813265383243561, 0.07003315538167953, 0.18663839995861053, -0.08510122448205948, -0.20469419658184052, -0.09821014106273651, -0.031238822266459465, -0.024028368294239044, 0.0134726632386446, -0.14579971134662628, 0.014610820449888706, -0.0743720754981041, 0.046127427369356155, 0.017460066825151443, -0.01573837175965309, -0.1268250048160553, -1.1325240813595819e-32, -0.04789959639310837, -0.05975827947258949, 0.1258644014596939, -0.010652540251612663, -0.03260570019483566, -0.05888676270842552, -0.043493565171957016, -0.10977011919021606, -0.1262706220149994, -0.12360706180334091, 0.027188168838620186, -0.003191161435097456, 0.1887616068124771, -0.027226995676755905, 0.23593232035636902, 0.02046259120106697, -0.06408501416444778, 0.03630358725786209, 0.1090635433793068, -0.07437419891357422, 0.14121563732624054, -0.03530873730778694, -0.06328368932008743, 0.10497159510850906, -0.11386770009994507, -0.00892169214785099, -0.06695783138275146, -0.005610637366771698, -0.12378134578466415, -0.09671822190284729, 0.018327070400118828, -0.09846174716949463, -0.09341693669557571, -0.001986613031476736, -0.06278475373983383, 2.738548027991783e-05, -0.04540592059493065, -0.13333824276924133, -0.07185323536396027, 0.060262322425842285, -0.02006499283015728, 0.05215039104223251, -0.15359942615032196, -0.07040277868509293, 0.0699615627527237, -0.02318769134581089, -0.10305923223495483, -0.05487416312098503, 0.11068996042013168, -0.1051105260848999, -0.03136410191655159, -0.0025011650286614895, -0.05982106924057007, 0.08823129534721375, -0.1347007304430008, 0.08557577431201935, -0.05917859822511673, 0.08312345296144485, -0.014351338148117065, -0.001251362031325698, -0.009952063672244549, -0.04502371326088905, -0.005039931274950504, 0.07978349924087524, -0.08681454509496689, 0.08831148594617844, 0.027175985276699066, -0.022171415388584137, 0.008902357891201973, 0.1385432630777359, -0.030316082760691643, -0.051682960242033005, 0.1262235939502716, 0.021298034116625786, 0.012543464079499245, 0.12122082710266113, 0.061719492077827454, -0.018633639439940453, -0.05461243912577629, -0.12231199443340302, -0.06818387657403946, -0.07991252094507217, 0.09492550790309906, 0.08127422630786896, -0.06705325096845627, 0.04592456296086311, 0.19089600443840027, 0.08734852820634842, 0.005670520476996899, -0.03647221252322197, 0.07375102490186691, -0.01127539575099945, 0.1198514997959137, 0.07976911216974258, -0.11651187390089035, -9.9660532271173e-08, 0.045074574649333954, 0.13315027952194214, 0.011124754324555397, 0.03741336241364479, -0.022043224424123764, 0.06044500321149826, -0.12739956378936768, 0.02451700158417225, -0.07910029590129852, 0.04380234703421593, 0.12486203014850616, -0.016728121787309647, -0.055487196892499924, 0.014486861415207386, 0.033784396946430206, 0.11907186359167099, -0.05624283850193024, 0.10822511464357376, -0.030032940208911896, -0.14674511551856995, 0.03218204155564308, -0.04808655381202698, 0.19181527197360992, 0.02242960035800934, 0.05153588950634003, 0.1561545580625534, -0.03098631091415882, 0.039859525859355927, 0.00019668065942823887, 0.055909812450408936, -0.05200964957475662, 0.014164138585329056, -0.004821539856493473, -0.0016798945143818855, 0.10233668237924576, 0.23592571914196014, 0.017307624220848083, -0.05093729868531227, -0.11958221346139908, -0.06453710794448853, -0.008562385104596615, -0.07554727047681808, -0.05415986105799675, 0.007670631632208824, 0.1366298645734787, 0.03826559707522392, -0.01078544370830059, 0.025098437443375587, 0.10883446037769318, -0.043500445783138275, 0.034426867961883545, -0.061869289726018906, -0.04008308798074722, 0.09704422205686569, 0.09459758549928665, 0.023960139602422714, -0.10479255765676498, -0.053256258368492126, 0.0013446637894958258, -0.01756877638399601, 0.06577935069799423, -0.1456957757472992, -0.1559315174818039, 0.021127134561538696], metadata={'source': 'AAAMLP-569to.pdf', 'page': 273}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 274     ranked = np.column_stack(ranked)     return np.mean(ranked, axis=1) ═════════════════════════════════════════════════════════════════════════  Please note that in scipy’s rankdata, ranks start at 1.  Why do these kinds of ensembles work? Let’s look at figure 1.  \\n Figure 1: Three people guessing the height of an elephant  Figure 1 shows that if three people are guessing the height of an elephant, the original height will be very close to the average of the three guesses. Let’s assume these people can guess very close to the original height of the elephant. Close estimate means an error, but this error can be minimized when we average the three predictions. This is the main idea behind the averaging of multiple models.  Probabilities can also be combined by weights.  Final Probabilities = w1*M1_proba + w2*M2_proba + … + wn*Mn_proba  Where (w1 + w2 + w3 + … + wn) = 1.0 For example, if you have a random forest model that gives very high AUC and a logistic regression model with a little lower AUC, you can combine them with 70%'),\n",
       " VectorParams(vector=[-0.1258096694946289, -0.13614332675933838, -0.07236451655626297, 0.09106732904911041, 0.18157146871089935, -0.1018262654542923, 0.0804254487156868, 0.0228619035333395, -0.0962866023182869, 0.10608389973640442, -0.09851421415805817, -0.20230010151863098, 0.0485578253865242, 0.03803594410419464, 0.009960325434803963, 0.11289170384407043, -0.004732110537588596, 0.01935698091983795, -0.24140845239162445, 0.13590142130851746, 0.06184402480721474, -0.06367995589971542, 0.06911832094192505, 0.07139337807893753, -0.030452188104391098, -0.10864253342151642, -0.03967120498418808, -0.019312739372253418, -0.11874344944953918, -0.03592975437641144, 0.01262599602341652, -0.12004856765270233, 0.10344886779785156, -0.05755550414323807, -0.09531527757644653, -0.08183743059635162, -0.10521897673606873, -0.06998105347156525, -0.009942972101271152, -0.0641818642616272, -0.04524286463856697, 0.01177932322025299, -0.08950742334127426, -0.10286743938922882, 0.04682537913322449, 0.09116639196872711, -0.07334752380847931, 0.020945630967617035, 0.04987238347530365, -0.05071321129798889, 0.05078066140413284, -0.0031399205327033997, -0.1921660304069519, 0.013544077053666115, -0.09302249550819397, 0.03868027403950691, 0.05748838186264038, -0.18125057220458984, 0.026715055108070374, -0.038375258445739746, 0.13826173543930054, -0.10331185162067413, -0.12182004004716873, 0.01431586779654026, 0.14928418397903442, -0.1582755744457245, -0.05111353099346161, -0.0289009939879179, 0.07108122855424881, 0.12453593313694, 0.057378821074962616, -0.04264068230986595, -0.051118478178977966, 0.03213391825556755, 0.13018500804901123, 0.16482794284820557, 0.248179093003273, 0.08138790726661682, 0.018304355442523956, -0.04843194782733917, -0.10753042995929718, 0.07975640147924423, 0.10727474093437195, -0.02002255991101265, 0.1095237284898758, -0.18639585375785828, 0.024749696254730225, 0.014929285272955894, 0.06501494348049164, 0.03022916056215763, 0.07205557823181152, 0.0015853308141231537, -0.016776956617832184, -0.018928522244095802, 0.1364438533782959, 0.04259590059518814, 0.13857294619083405, -0.0293508879840374, 0.05179770290851593, 0.05121808126568794, -0.10516393929719925, 0.1209082156419754, 0.18270759284496307, -0.17364755272865295, 0.16017605364322662, -0.12071281671524048, 0.030133040621876717, 0.06612170487642288, 0.1548691838979721, -0.1188194677233696, 0.005241040140390396, -0.0028337864205241203, 0.04181010276079178, 0.0925881564617157, 0.014889718033373356, 0.14337089657783508, 0.01688004657626152, 0.0910026803612709, -0.0701010525226593, 0.17069244384765625, -0.07501872628927231, -0.004602733999490738, 0.0641724243760109, -0.04016730561852455, 0.15567606687545776, -0.07615148276090622, -0.10484325885772705, 1.0673913352800605e-32, -0.03319763392210007, -0.0378243625164032, -0.024436183273792267, -0.08665594458580017, 0.13783948123455048, 0.014606240205466747, 0.007735680788755417, 0.08332440257072449, 0.06473041325807571, 0.11427614837884903, -0.188735231757164, 0.11639942973852158, -0.0018263701349496841, 0.0758548378944397, 0.07773862779140472, 0.034842297434806824, -0.18452560901641846, 0.019062796607613564, -0.12607377767562866, -0.03691619634628296, 0.16431806981563568, 0.04012388363480568, 0.058027297258377075, -0.09147492051124573, -0.04614069312810898, -0.0017394209280610085, 0.052059419453144073, -0.026547644287347794, -0.11666640639305115, 0.06486275047063828, -0.12260640412569046, -0.04114557057619095, -0.07642167806625366, -0.009672286920249462, -0.03671061992645264, -0.026765644550323486, 0.08569281548261642, -0.04314393177628517, -0.039364248514175415, 0.007213495671749115, 0.012247806414961815, 0.034086551517248154, 0.024509774520993233, -0.10471824556589127, -0.04217306897044182, 0.005680792964994907, 0.0040907361544668674, 0.14273449778556824, -0.017461908981204033, 0.09107358753681183, 0.02835952118039131, -0.094175785779953, -0.031175946816802025, 0.015177830122411251, 0.021787717938423157, 0.09831804037094116, 0.11119788885116577, -0.0033903629519045353, 0.021495677530765533, 0.06903338432312012, 0.07572589069604874, -0.08002159744501114, -0.009924190118908882, 0.01705825887620449, 0.00784357264637947, -0.022035028785467148, 0.1387050300836563, -0.01882757619023323, -0.026114122942090034, -0.1052674651145935, -0.1485223025083542, 0.006413162685930729, 0.07989852875471115, -0.07453561574220657, 0.061758704483509064, -0.05543902888894081, 0.15511074662208557, 0.011576863005757332, 0.002349092159420252, -0.0702824741601944, -0.032926980406045914, 0.31698906421661377, -0.031401969492435455, -0.10032276064157486, -0.029059292748570442, -0.004494231194257736, 0.06106260418891907, -0.06924811005592346, -0.2545052170753479, 0.05637839436531067, -0.12585650384426117, -0.02829197235405445, -0.014007951132953167, -0.09710994362831116, -0.0017890240997076035, -8.705035987622108e-33, -0.016984470188617706, -0.08924093842506409, -0.012986572459340096, 0.08535689115524292, 0.0640990361571312, -0.00426055584102869, -0.06060367822647095, -0.16307196021080017, -0.11306276172399521, -0.18353620171546936, 0.02725253999233246, 0.042382560670375824, 0.14624664187431335, 0.07165221869945526, -0.003536549862474203, -0.041523177176713943, -0.04288342967629433, 0.019173722714185715, -0.07213122397661209, 0.013451908715069294, 0.10527797788381577, 0.13783210515975952, -0.10307059437036514, -0.09921298921108246, -0.13018560409545898, -0.02351056970655918, -0.09045424312353134, 0.15534478425979614, 0.06578933447599411, 0.033127304166555405, -0.06546568125486374, 0.10058718919754028, -0.11262179911136627, 0.048474155366420746, -0.0813535749912262, -0.0893508568406105, -0.03433971107006073, -0.05778251588344574, -0.015278276056051254, 0.10113184154033661, 0.062330782413482666, 0.06097298115491867, -0.18150381743907928, 0.006207526195794344, 0.08077292144298553, -0.07176348567008972, -0.06209003925323486, -0.028155555948615074, 0.0113710667937994, 0.026020506396889687, 0.05901031196117401, -0.1509828269481659, -0.20713621377944946, 0.07327865064144135, -0.15191802382469177, 0.03501835837960243, -0.07687447965145111, -0.037217918783426285, 0.03272807225584984, 0.07999829947948456, -0.08845154941082001, 0.15557004511356354, 0.05400215834379196, 0.04164949059486389, -0.05968744307756424, 0.019580848515033722, 0.01644698716700077, 0.1219230443239212, 0.06064055114984512, 0.04656033217906952, -0.12220412492752075, -0.046159934252500534, 0.05388791859149933, 0.002531964797526598, -0.007443757727742195, 0.20174533128738403, 0.04493226110935211, -0.054420288652181625, 0.0634198784828186, -0.10526268184185028, -0.11665038764476776, 0.02155478484928608, 0.10230831801891327, 0.22127501666545868, -0.08604206889867783, 0.11196932941675186, 0.11668109893798828, 0.1440901905298233, 0.09627366811037064, -0.05105256661772728, 0.006909324787557125, -0.010421114973723888, 0.23054185509681702, 0.1946537047624588, -0.05209480598568916, -9.938260348008043e-08, -0.056442368775606155, 0.13343310356140137, 0.02962614968419075, 0.07045596837997437, 0.019458862021565437, 0.11183598637580872, -0.07902616262435913, 0.1165308728814125, -0.12409534305334091, 0.036855701357126236, 0.18088489770889282, 0.010670045390725136, -0.14096538722515106, 0.0895761251449585, -0.035261839628219604, 0.06875575333833694, 0.05298934504389763, 0.09316124022006989, -0.10105384886264801, -0.026547225192189217, -0.024191003292798996, -0.025650421157479286, 0.11357538402080536, 0.007486458867788315, 0.08266288787126541, -0.03981703519821167, -0.07932756841182709, 0.10089954733848572, -0.026786822825670242, 0.13232488930225372, -0.04132110998034477, -0.038908518850803375, -0.08422558009624481, 0.09936479479074478, -0.0012065600603818893, 0.11402103304862976, -0.045159757137298584, -0.12498845160007477, -0.0538937933743, 0.07311178743839264, 0.08800455182790756, 0.005734676029533148, -0.09509873390197754, -0.06030839681625366, 0.01453101634979248, 0.049021705985069275, -0.027090447023510933, -0.07112228870391846, 0.0056299022398889065, 0.006721319630742073, -0.10551426559686661, -0.12669964134693146, -0.06666158884763718, -0.002605295041576028, 0.09596392512321472, 0.05412086099386215, -0.12368247658014297, -0.0913793295621872, 0.0019506905227899551, 0.11530160903930664, -0.07180050015449524, -0.06999409198760986, -0.0698891282081604, 0.045735687017440796], metadata={'source': 'AAAMLP-569to.pdf', 'page': 274}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 275 for random forest and 30% for logistic regression. So, how did I come up with these numbers? Let’s add another model, let’s say now we also have an xgboost model that gives an AUC higher than random forest. Now I will combine them with a ratio of 3:2:1 for xgboost : random forest : logistic regression. Easy right? Arriving at these numbers is a piece of cake. Let’s see how.  Assume that we have three monkeys with three knobs with values that range between 0 and 1. These monkeys turn the knobs, and we calculate the AUC score at each value they turn the knob to. Eventually, the monkeys will find a combination that gives the best AUC. Yes, it is a random search! Before doing these kinds of searches, you must remember the two most important rules of ensembling.  The first rule of ensembling is that you always create folds before starting with ensembling.  The second rule of ensembling is that you always create folds before starting with ensembling.  YES. These are the two most important rules, and no, there is no mistake in what I wrote. The first step is to create folds. For simplicity, let’s say we divide the data into two parts: fold 1 and fold 2. Please note that this is only done for simplicity in explaining. In a real-world scenario, you should create more folds.   Now, we train our random forest model, logistic regression model and our xgboost model on fold 1 and make predictions on fold 2. After this, we train the models from scratch on fold 2 and make predictions on fold 1. Thus, we have created predictions for all of the training data. Now to combine these models, we take fold 1 and all the predictions for fold 1 and create an optimization function that tries to find the best weights so as to minimize error or maximize AUC against the targets for fold 2. So, we are kind of training an optimization model on fold 1 with the predicted probabilities for the three models and evaluating it on fold 2. Let’s first look at a class we can use to find the best weights of multiple models to optimize for AUC (or any kind of prediction-metric combination in general).  ═════════════════════════════════════════════════════════════════════════ import numpy as np  from functools import partial from scipy.optimize import fmin from sklearn import metrics'),\n",
       " VectorParams(vector=[-0.08864430338144302, -0.13490040600299835, -0.0976358950138092, 0.060011230409145355, 0.09815295785665512, -0.11565067619085312, 0.011818083934485912, 0.05892965570092201, -0.11607275903224945, 0.004447069484740496, -0.1362105756998062, -0.17386071383953094, 0.06613918393850327, -0.029709473252296448, -0.04916807636618614, 0.02940939925611019, 0.022254804149270058, -0.007385208271443844, -0.0855490192770958, 0.055419571697711945, 0.10097471624612808, 0.15269580483436584, -0.08287551254034042, 0.09655054658651352, 0.06149962171912193, -0.14366261661052704, 0.09814751148223877, 0.11449217796325684, -0.1942276954650879, -0.11089654266834259, 0.04893597215414047, -0.08332701027393341, 0.0255709420889616, 0.05298307538032532, -0.12680654227733612, 0.061437204480171204, -0.10494928061962128, 0.013391068205237389, -0.09786919504404068, -0.027630029246211052, -0.09638552367687225, 0.11465924233198166, 0.010590673424303532, 0.01692437008023262, 0.004147548694163561, 0.04804536700248718, -0.01784878969192505, -0.03845863789319992, 0.1402364820241928, -0.03459986671805382, 0.011441540904343128, 0.14975719153881073, -0.2052055448293686, -0.030768007040023804, -0.07258535921573639, -0.05931052565574646, 0.10193637758493423, -0.1903846263885498, 0.10643546283245087, -0.13144424557685852, -0.016316121444106102, -0.1274249106645584, 0.005902407690882683, -0.009097006171941757, 0.04841386899352074, -0.0913819670677185, -0.00306706759147346, 0.0683140903711319, 0.023408319801092148, 0.1545407623052597, 0.03926778957247734, -0.011745641939342022, -0.037893544882535934, 0.10618064552545547, 0.09843791276216507, 0.07004058361053467, 0.2303691804409027, 0.053468625992536545, -0.0265694297850132, 0.06669658422470093, -0.15629155933856964, 0.08087456971406937, 0.08338257670402527, -0.029519574716687202, 0.10763692855834961, -0.14336925745010376, 0.07852715253829956, 0.03377141058444977, 0.16051168739795685, -0.00014793766604270786, 0.09917405247688293, 0.03842030093073845, 0.010260487906634808, -0.05810185894370079, 0.05780128389596939, 0.07241741567850113, 0.12856467068195343, -0.16798026859760284, 0.059119146317243576, 0.060353752225637436, 0.008961638435721397, 0.028453610837459564, 0.0885901227593422, -0.07292576879262924, 0.11355346441268921, 0.009634649381041527, 0.11396690458059311, -0.006807893980294466, 0.09703134745359421, -0.10628599673509598, -0.04678097367286682, -0.12075576186180115, -0.09951454401016235, 0.012518594041466713, 0.1526772826910019, 0.18257664144039154, 0.053374242037534714, 0.07879795134067535, -0.05608155578374863, 0.1903170943260193, -0.15475037693977356, 0.028013331815600395, 0.0601147785782814, 0.07916171103715897, 0.07317109405994415, -0.015868211165070534, -0.22756800055503845, 1.4737063943031567e-32, -0.17238172888755798, -0.03132655471563339, -0.06267474591732025, -0.08750022947788239, -0.07541868835687637, 0.048347413539886475, 0.07176000624895096, 0.05048021301627159, -0.04266633465886116, -0.0006927958456799388, -0.14803171157836914, 0.0972481369972229, -0.06613954901695251, 0.09192027151584625, 0.09179069101810455, -0.01543972548097372, -0.04164024442434311, -0.05337630584836006, 0.007478616666048765, 0.03589007258415222, 0.17443959414958954, -0.03687595576047897, 0.05914861336350441, -0.1119571328163147, -0.04687148332595825, -0.06947647780179977, 0.06609661877155304, -0.06277690827846527, -0.22206264734268188, 0.01929764822125435, -0.2236720621585846, 0.015979185700416565, -0.01390316616743803, -0.0807826966047287, 0.0336059108376503, -0.08971979469060898, -0.012584738433361053, 0.10028613358736038, -0.034719038754701614, -0.14190733432769775, -0.014041689224541187, 0.03809399902820587, 0.044485948979854584, -0.06668473035097122, -0.031037498265504837, -0.09726002812385559, 0.010655943304300308, 0.2025107443332672, 0.03897560387849808, 0.0728347972035408, -0.0349884033203125, -0.20842742919921875, -0.04500465840101242, 0.07073161751031876, -0.10119543969631195, 0.07716848701238632, 0.05645698308944702, -0.012474550865590572, 0.12790945172309875, -0.06200888380408287, 0.016607478260993958, -0.06338745355606079, 0.004072797950357199, -0.05550120398402214, 0.01727745495736599, 0.058336298912763596, 0.08305291086435318, -0.006129625719040632, 0.07374174147844315, 0.08939185738563538, -0.0677727684378624, 0.03247198462486267, 0.045570991933345795, -0.07493377476930618, 0.1439802199602127, -0.10801686346530914, 0.13544857501983643, -0.17628826200962067, -0.1213124543428421, -0.013700513169169426, -0.08251943439245224, 0.2686546742916107, -0.09954240918159485, -0.1209997832775116, -0.12652891874313354, -0.06809306889772415, 0.17975696921348572, -0.07059836387634277, -0.2899036705493927, -0.09121958911418915, -0.1835315227508545, -0.022565124556422234, -0.01346837729215622, 0.06723368912935257, -0.14559011161327362, -1.6388648199616267e-32, -0.040567848831415176, -0.040489137172698975, 0.05742769315838814, 0.050220709294080734, 0.07919993251562119, 0.03610996529459953, -0.06878186017274857, 0.024224283173680305, -0.0157223679125309, -0.19132587313652039, -0.027852829545736313, -0.13748309016227722, 0.10557457059621811, 0.09560049325227737, 0.054517775774002075, 0.1332363337278366, -0.08557906001806259, 0.0538090243935585, 0.016370778903365135, -0.024121541529893875, -0.12385445088148117, 0.12090300023555756, -0.06034456193447113, -0.07920141518115997, -0.09055393934249878, -0.04240144416689873, 0.04203054681420326, 0.15872980654239655, -0.0007997185457497835, -0.07327557355165482, -0.14881481230258942, 0.2173718512058258, -0.14803166687488556, 0.09254304319620132, 0.001723772962577641, 0.004663420841097832, -0.01958000659942627, -0.0930149182677269, -0.023709988221526146, 0.017866546288132668, 0.16439750790596008, 0.1617247462272644, -0.14812837541103363, -0.023197827860713005, 0.06616534292697906, -0.04340808838605881, 0.01784789189696312, -0.08710848540067673, 0.030883951112627983, 0.01567966304719448, -0.014546534977853298, -0.08358188718557358, -0.1516236960887909, 0.13285642862319946, -0.11227423697710037, 0.007690356578677893, -0.10819055885076523, 0.03411966934800148, 0.05177600681781769, -0.007475600112229586, -0.1430940330028534, 0.02273821085691452, 0.06491165608167648, 0.07250630855560303, -0.006648598704487085, 0.020436707884073257, -0.06562527269124985, 0.03945055231451988, 0.027540316805243492, 0.23246951401233673, -0.07032445818185806, 0.08403252810239792, 0.10667334496974945, 0.019955921918153763, -0.0724993497133255, 0.002267145086079836, 0.0051589650101959705, -0.018623461946845055, -0.0802876353263855, 0.014245405793190002, -0.0014429803704842925, 0.10299471020698547, 0.06215793639421463, 0.15389157831668854, -0.0162948127835989, 0.10817694664001465, 0.1827458143234253, 0.2267066240310669, 0.03523271530866623, 0.019899114966392517, 0.028847210109233856, 0.08986271172761917, 0.14162136614322662, 0.08501694351434708, -0.027927851304411888, -1.0119700277755328e-07, 6.133994611445814e-05, 0.040804456919431686, 0.07506466656923294, 0.07111379504203796, -0.010748354718089104, 0.10976484417915344, -0.06927112489938736, -0.028951462358236313, -0.08571673929691315, -0.0062033249996602535, 0.1246127039194107, 0.01579909212887287, -0.062428999692201614, 0.06321065872907639, -0.19057196378707886, 0.18193601071834564, -0.023272495716810226, -0.0034583869855850935, -0.013109341263771057, -0.11048509180545807, 0.025338556617498398, -0.09511987864971161, 0.02820644900202751, -0.034706469625234604, -0.02031741663813591, -0.11994072049856186, -0.0280202217400074, -0.08300930261611938, -0.022351330146193504, 0.0854872316122055, -0.09648049622774124, -0.08585795760154724, -0.053432125598192215, -0.04392952844500542, 0.04784798249602318, 0.1621306836605072, 0.08773846924304962, -0.12067819386720657, -0.07844121754169464, 0.12168379873037338, -0.16228711605072021, 0.12161460518836975, -0.15655480325222015, -0.1401723027229309, 0.19320237636566162, -0.01622653938829899, 0.09253600984811783, -0.08053316920995712, 0.1394348442554474, -0.04482481628656387, 0.0575031116604805, -0.05683320388197899, -0.08926304429769516, -0.06542222946882248, 0.09994931519031525, -0.03215876594185829, -0.2562652826309204, -0.08925487101078033, 0.02200789749622345, 0.012151872739195824, -0.08495184034109116, 0.021350078284740448, -0.031701136380434036, -0.024474723264575005], metadata={'source': 'AAAMLP-569to.pdf', 'page': 275}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 276 class OptimizeAUC:     \"\"\"     Class for optimizing AUC.     This class is all you need to find best weights for      any model and for any metric and for any types of predictions.     With very small changes, this class can be used for optimization of      weights in ensemble models of _any_ type of predictions     \"\"\"     def __init__(self):         self.coef_ = 0      def _auc(self, coef, X, y):         \"\"\"         This functions calulates and returns AUC.         :param coef: coef list, of the same length as number of models         :param X: predictions, in this case a 2d array         :param y: targets, in our case binary 1d array         \"\"\"         # multiply coefficients with every column of the array         # with predictions.         # this means: element 1 of coef is multiplied by column 1         # of the prediction array, element 2 of coef is multiplied          # by column 2 of the prediction array and so on!         x_coef = X * coef          # create predictions by taking row wise sum         predictions = np.sum(x_coef, axis=1)                  # calculate auc score         auc_score = metrics.roc_auc_score(y, predictions)          # return negative auc         return -1.0 * auc_score      def fit(self, X, y):         # remember partial from hyperparameter optimization chapter?         loss_partial = partial(self._auc, X=X, y=y)                  # dirichlet distribution. you can use any distribution you want         # to initialize the coefficients         # we want the coefficients to sum to 1         initial_coef = np.random.dirichlet(np.ones(X.shape[1]), size=1)          # use scipy fmin to minimize the loss function, in our case auc         self.coef_ = fmin(loss_partial, initial_coef, disp=True)      def predict(self, X):'),\n",
       " VectorParams(vector=[-0.05534306541085243, -0.22118736803531647, 0.05320706591010094, 0.05959457531571388, 0.26066988706588745, -0.14391960203647614, -0.04254250228404999, 0.08562179654836655, -0.1551845818758011, -0.028271671384572983, -0.06816650927066803, -0.28380826115608215, 0.053811755031347275, -0.07738372683525085, 0.009710379876196384, 0.17380253970623016, -0.07566621154546738, -0.04882396385073662, -0.19278118014335632, 0.12019557505846024, 0.12710309028625488, 0.020817749202251434, 0.042412783950567245, 0.09221412986516953, 0.07967851310968399, -0.0476720817387104, -0.02460557408630848, 0.05727541819214821, -0.17338158190250397, -0.04833952337503433, -0.006153383757919073, -0.020555661991238594, 0.026293355971574783, 0.05085199326276779, -0.021240927278995514, -0.050292156636714935, -0.08770875632762909, -0.011691851541399956, -0.08640041947364807, -0.06271126866340637, -0.011127034202218056, 0.050830941647291183, 0.004795404151082039, -0.07733159512281418, 0.11116113513708115, 0.11111319065093994, -0.0754704624414444, 0.015305130742490292, 0.05467420816421509, -0.11078860610723495, -0.03933132067322731, -0.0629301443696022, -0.22243823111057281, -0.07309631258249283, -0.11348432302474976, -0.09067701548337936, 0.034366585314273834, -0.11013253033161163, 0.10507742315530777, -0.05352100729942322, 0.04621418938040733, -0.11846989393234253, -0.028652019798755646, -0.016885587945580482, 0.046616483479738235, -0.06433235108852386, -0.03604089841246605, 0.0937981903553009, -0.08007214963436127, 0.14146021008491516, -0.08404914289712906, 0.06109626591205597, -0.042107366025447845, 0.07213706523180008, 0.019130321219563484, 0.06792503595352173, 0.21446572244167328, 0.10512549430131912, -0.03479471802711487, -0.03573831915855408, -0.3231867551803589, -0.006357036996632814, 0.06832841038703918, -0.07236578315496445, 0.0003475331759545952, -0.19478365778923035, 0.09021058678627014, 0.02062940038740635, -0.07010935992002487, -0.056733451783657074, 0.1327645480632782, 0.07280460000038147, -0.058025892823934555, 0.016951020807027817, 0.058765560388565063, 0.09994690865278244, 0.135577991604805, -0.023073866963386536, 0.14932700991630554, 0.08117938041687012, -0.09617700427770615, 0.12851382791996002, 0.1737033724784851, -0.10072747617959976, 0.10200581699609756, -0.07166717201471329, 0.13954731822013855, 0.0022676915396004915, 0.09572599828243256, -0.12630398571491241, 0.0249724630266428, -0.07507617026567459, -0.060099054127931595, 0.2102515995502472, 0.10503950715065002, 0.19256514310836792, -0.019347982481122017, 0.07755307108163834, -0.1704007238149643, 0.200626403093338, -0.10402815043926239, 0.011891382746398449, 0.2104824334383011, 0.03988107293844223, 0.026402752846479416, -0.09956779330968857, -0.10197433084249496, 1.5912630292882843e-32, -0.11745326220989227, -0.1094745323061943, -0.03268834948539734, -0.04939594119787216, 0.07739376276731491, 0.057448629289865494, 0.0025945319794118404, 0.07829265296459198, 0.03731855750083923, 0.11343199014663696, -0.17246077954769135, 0.07500814646482468, 0.05039649084210396, -0.09002890437841415, 0.032496776431798935, 0.021955324336886406, -0.1180981695652008, -0.018320269882678986, -0.05254999175667763, 0.03994571790099144, 0.24353201687335968, -0.01934962533414364, 0.06645340472459793, -0.10341383516788483, -0.1650526523590088, -0.06606806069612503, 0.05717199295759201, -0.001899296068586409, -0.0861738994717598, 0.02702241577208042, -0.14382758736610413, -0.006712561938911676, -0.042938508093357086, 0.007994412444531918, -0.10131929814815521, -0.057371363043785095, 0.028765732422471046, 0.0024963216856122017, -0.05039485543966293, -0.01927240937948227, 0.027163812890648842, -0.053014807403087616, 0.006619347725063562, -0.12367741763591766, 0.017604446038603783, -0.12040599435567856, -0.045301198959350586, 0.16799035668373108, -0.06568633764982224, 0.08626959472894669, -0.008516594767570496, -0.18044371902942657, -0.07099159061908722, 0.019035091623663902, -0.07302920520305634, 0.13223569095134735, 0.11785911023616791, 0.05597638711333275, 0.07473446428775787, 0.048882097005844116, -0.037688691169023514, -0.011324627324938774, -0.05695127323269844, -0.05329097807407379, 0.013968922197818756, 0.13445155322551727, 0.12840326130390167, 0.040071506053209305, -0.004201065748929977, 0.0889260545372963, -0.054487444460392, 0.0007803297485224903, -0.053940124809741974, -0.027843128889799118, 0.1439134180545807, -0.16476869583129883, 0.09385687857866287, 0.031210925430059433, -0.023172572255134583, 0.028734073042869568, -0.003978358581662178, 0.2836821973323822, -0.08936663717031479, -0.18731087446212769, -0.05405476689338684, -0.03589613363146782, 0.0223089586943388, -0.036269377917051315, -0.3185657560825348, 0.009597789496183395, -0.22742903232574463, 0.007522269617766142, 0.006439703516662121, -0.08278759568929672, 0.05367442965507507, -1.5671033877694215e-32, 0.044429946690797806, -0.038084954023361206, 0.20327496528625488, 0.13942702114582062, 0.10555514693260193, 0.055972564965486526, -0.013209689408540726, -0.13426996767520905, -0.0677214190363884, -0.17731422185897827, -0.053282301872968674, -0.10218121856451035, 0.19263410568237305, 0.07165233790874481, 0.09507463127374649, 0.015284092165529728, -0.01229803916066885, 0.08931925147771835, -0.0064434451051056385, 0.0972094014286995, 0.030029460787773132, 0.1494896113872528, -0.0535171814262867, -0.044517405331134796, -0.21880634129047394, 0.071001797914505, 0.0007152638281695545, 0.13849963247776031, 0.07007478922605515, -0.07384935021400452, -0.048430971801280975, 0.11067651957273483, -0.17057883739471436, 0.04304595664143562, 0.022102849557995796, -0.1400867998600006, -0.09775397181510925, -0.029428426176309586, -0.040959347039461136, 0.11674286425113678, 0.11572622507810593, 0.10422670841217041, -0.19492611289024353, -0.04037564620375633, 0.03593641147017479, 0.007172032725065947, -0.1098833978176117, -0.035469453781843185, 0.028585830703377724, -0.03579849749803543, -0.009935099631547928, -0.09552711993455887, -0.18250219523906708, 0.05141785368323326, -0.11000419408082962, 0.14767281711101532, -0.16430217027664185, -0.007439705543220043, -0.014741008169949055, 0.0073036253452301025, -0.10438413918018341, 0.02185969240963459, 0.004649554379284382, 0.06320136040449142, 0.09513390064239502, 0.08072744309902191, -0.0007622894481755793, 0.07877322286367416, 0.07723861187696457, 0.19539250433444977, -0.10621581971645355, 0.0336618535220623, -0.03960422798991203, -0.14560142159461975, -0.053502406924963, 0.1946188509464264, 0.003983124624937773, -0.04208418354392052, 0.03552016615867615, 0.033044856041669846, -0.06195702776312828, 0.020466653630137444, 0.10238411277532578, 0.15714924037456512, -0.0395011305809021, 0.1363925188779831, 0.12167521566152573, 0.23923763632774353, 0.06669141352176666, -0.13991034030914307, 0.028879975900053978, 0.06106657162308693, 0.18311721086502075, 0.17712901532649994, 0.0005161372828297317, -1.0029995678451087e-07, 0.02281763404607773, 0.053271688520908356, 0.130207821726799, 0.13309670984745026, 0.048098187893629074, 0.02103160321712494, -0.23749208450317383, 0.04374076798558235, -0.11214159429073334, 0.0021016348619014025, 0.062378160655498505, -0.05966639891266823, -0.07056809961795807, 0.07610079646110535, -0.022376839071512222, -0.043609846383333206, -0.06480389088392258, -0.0255676731467247, -0.07047098129987717, 0.030148036777973175, -0.03757009655237198, -0.16319791972637177, 0.18743088841438293, -0.025808027014136314, 0.047151338309049606, -0.0926092267036438, -0.04728454723954201, 0.0806882306933403, 0.03239390254020691, 0.048560287803411484, 0.032675135880708694, -0.09623067080974579, -0.07837865501642227, -0.014602739363908768, 0.033031102269887924, 0.015799514949321747, 0.13084568083286285, -0.09013304114341736, 0.05334072187542915, 0.10235708951950073, -0.019197313115000725, 0.023931004106998444, -0.066465824842453, -0.012218606658279896, 0.10758893936872482, -0.010804502293467522, 0.09555809199810028, -0.07428137212991714, 0.15017151832580566, 0.02009219489991665, -0.05671738088130951, -0.06168167293071747, -0.060469597578048706, 0.024891380220651627, 0.037198878824710846, 0.05766155198216438, -0.17756913602352142, -0.053003694862127304, 0.0054845348931849, 0.09827747195959091, -0.08826512843370438, -0.20345579087734222, -0.08855742961168289, -0.08096318691968918], metadata={'source': 'AAAMLP-569to.pdf', 'page': 276}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 277         # this is similar to _auc function         x_coef = X * self.coef_         predictions = np.sum(x_coef, axis=1)         return predictions ═════════════════════════════════════════════════════════════════════════  Let’s see how to use this and compare it with simple averaging.  ═════════════════════════════════════════════════════════════════════════ import xgboost as xgb from sklearn.datasets import make_classification from sklearn import ensemble from sklearn import linear_model from sklearn import metrics from sklearn import model_selection   # make a binary classification dataset with 10k samples # and 25 features X, y = make_classification(n_samples=10000, n_features=25)  # split into two folds (for this example) xfold1, xfold2, yfold1, yfold2 = model_selection.train_test_split(     X,     y,     test_size=0.5,     stratify=y )  # fit models on fold 1 and make predictions on fold 2 # we have 3 models: # logistic regression, random forest and xgboost logreg = linear_model.LogisticRegression() rf = ensemble.RandomForestClassifier() xgbc = xgb.XGBClassifier()  # fit all models on fold 1 data logreg.fit(xfold1, yfold1) rf.fit(xfold1, yfold1) xgbc.fit(xfold1, yfold1)  # predict all models on fold 2 # take probability for class 1 pred_logreg = logreg.predict_proba(xfold2)[:, 1] pred_rf = rf.predict_proba(xfold2)[:, 1] pred_xgbc = xgbc.predict_proba(xfold2)[:, 1]'),\n",
       " VectorParams(vector=[-0.03140397369861603, -0.22159937024116516, -0.027550488710403442, 0.09467153251171112, 0.2152692675590515, -0.1074659526348114, 0.019152555614709854, 0.08121434599161148, -0.13768167793750763, -0.005057862028479576, -0.038298413157463074, -0.21830487251281738, 0.03264752775430679, -0.03199443593621254, -0.020359935238957405, 0.17488086223602295, -0.24532708525657654, 0.020885001868009567, -0.1293974369764328, 0.17430317401885986, 0.14860503375530243, 0.05625954270362854, 0.009282727725803852, 0.12569263577461243, 0.03010442480444908, 0.0005442043766379356, -0.03307412564754486, 0.0982649028301239, -0.1389608234167099, -0.03160092234611511, 0.04192369803786278, 0.0014554113149642944, 0.11732442677021027, 0.043235018849372864, -0.04398860037326813, -0.0143816526979208, -0.17309466004371643, 0.09540533274412155, -0.09610140323638916, -0.047023192048072815, -0.07946747541427612, 0.054672032594680786, 0.043603554368019104, 0.018426721915602684, 0.0785127505660057, 0.04965949058532715, -0.037411563098430634, -0.06390783935785294, 0.09908966720104218, -0.05401036515831947, 0.014733565039932728, 0.04267852380871773, -0.19142428040504456, -0.08804532140493393, -0.11346150934696198, 0.002004389651119709, 0.011894835159182549, -0.13175928592681885, 0.13868647813796997, -0.042164310812950134, 0.06445183604955673, -0.0808265432715416, -0.028193853795528412, -0.04932774603366852, 0.09221118688583374, -0.04854622110724449, -0.0391649454832077, 0.12094032019376755, -0.062440816313028336, 0.22941309213638306, -0.06863543391227722, 0.10146228969097137, -0.050130344927310944, -0.010181238874793053, 0.08785349130630493, 0.1694803237915039, 0.2002989798784256, -0.062121227383613586, -0.05826149135828018, -0.04048290476202965, -0.32061654329299927, 0.014481524005532265, 0.1025211438536644, -0.028182607144117355, 0.0725230947136879, -0.21853207051753998, 0.18733295798301697, 0.0504387803375721, 0.009383917786180973, -0.0952477902173996, 0.1343560814857483, 0.013024995103478432, 0.007327522151172161, 0.007411092985421419, 0.02297911047935486, 0.08621165156364441, 0.19014424085617065, -0.07213592529296875, 0.21110430359840393, 0.06336983293294907, -0.097236767411232, 0.12987712025642395, 0.14708207547664642, -0.09841899573802948, 0.04458574205636978, -0.1514849066734314, 0.10610498487949371, 0.03774689510464668, 0.03897692635655403, -0.09117690473794937, 0.06341180205345154, 0.0028926990926265717, -0.03221335634589195, 0.18675623834133148, 0.14957848191261292, 0.20069995522499084, -0.012422917410731316, 0.0267350934445858, -0.09324599802494049, 0.21401791274547577, -0.06421326100826263, 0.0665130764245987, 0.22844210267066956, 0.038300078362226486, 0.03482286259531975, -0.12884633243083954, -0.08909182995557785, 1.4096344584068556e-32, -0.20854586362838745, -0.06576619297266006, -0.07673350721597672, -0.001148393377661705, 0.06408162415027618, 0.0746079757809639, -0.025032244622707367, -0.030485574156045914, 0.007332177367061377, 0.13968881964683533, -0.21861761808395386, 0.17315581440925598, 0.02152339369058609, -0.010850617662072182, 0.016358518972992897, 0.002703086007386446, -0.07503880560398102, 0.008942418731749058, -0.11193963885307312, 0.039797697216272354, 0.18853455781936646, 0.020264271646738052, 0.09270365536212921, -0.08195625990629196, -0.04948443919420242, -0.09515388309955597, 0.03570070490241051, 0.03353264927864075, -0.007072863169014454, -0.0015995949506759644, -0.12406480312347412, 0.034384604543447495, -0.07615607976913452, -0.08247873187065125, 0.0006216205656528473, -0.041292428970336914, 0.10943298786878586, 0.06872580945491791, -0.05302019417285919, -0.0056162029504776, 0.05355510115623474, -0.022154148668050766, 0.06790623813867569, -0.13559216260910034, -0.012371913529932499, -0.24555350840091705, -0.035204723477363586, 0.2703099250793457, -0.08993523567914963, 0.05766274780035019, 0.03903375193476677, -0.18341687321662903, -0.08706378936767578, -0.022026609629392624, -0.048690974712371826, 0.04727168381214142, 0.10491983592510223, -0.004689282737672329, 0.11786156892776489, 0.028733201324939728, -0.0515211746096611, 0.030192725360393524, -0.0906868427991867, -0.057642169296741486, -0.036207165569067, 0.1325017213821411, 0.20162206888198853, -0.028058193624019623, 0.034221284091472626, 0.06880325824022293, -0.060700029134750366, -0.004557648207992315, -0.04734756797552109, -0.08914659917354584, 0.01148722879588604, -0.10746864974498749, 0.042276203632354736, -0.0750487670302391, -0.07909999787807465, -0.04430163651704788, -0.04602551832795143, 0.2696806788444519, -0.09741180390119553, -0.15675801038742065, -0.04713578522205353, -0.10305897891521454, 0.03908974677324295, -0.12087500840425491, -0.43553775548934937, 0.015952177345752716, -0.25312450528144836, -0.0064028422348201275, 0.128081813454628, -0.13973405957221985, -0.04958755522966385, -1.3934459910177126e-32, 0.05795875936746597, -0.04962422326207161, 0.24151235818862915, 0.02738925628364086, 0.0849902331829071, 0.04208238050341606, 0.01165540050715208, -0.10313902795314789, -0.1303229033946991, -0.23150430619716644, -0.08520650118589401, -0.17662306129932404, 0.16507306694984436, 0.08174820989370346, 0.18062818050384521, 0.08330553770065308, -0.03660646826028824, 0.11469301581382751, -0.0500173345208168, 0.013772130012512207, 0.012772462330758572, 0.13113443553447723, 0.017414165660738945, 0.020562876015901566, -0.24005793035030365, 0.04313928633928299, 0.11080490052700043, 0.1478281319141388, 0.04804370924830437, -0.16389553248882294, -0.11715324968099594, -0.006644420325756073, -0.13883079588413239, 0.060803331434726715, 0.01888391003012657, -0.10284449905157089, -0.05601901561021805, -0.11812940984964371, -0.03718945011496544, 0.09368851035833359, 0.11444792151451111, 0.09975316375494003, -0.20865914225578308, -0.017837107181549072, 0.024429798126220703, -0.04277640953660011, -0.0319877527654171, 0.01874963752925396, 0.001954615581780672, -0.13281893730163574, -0.06431155651807785, -0.1285446435213089, -0.20114478468894958, 0.032781172543764114, -0.15945635735988617, 0.20042750239372253, -0.1624024361371994, -0.09243066608905792, 0.06104113906621933, -0.02198997139930725, -0.08184441924095154, -0.027609506621956825, 0.051271192729473114, 0.022555597126483917, 0.12339256703853607, -0.00013760104775428772, -0.04153217747807503, -0.054531991481781006, -0.022533144801855087, 0.1849144697189331, -0.1110033467411995, -0.01694103144109249, -0.037440527230501175, -0.11586743593215942, -0.02838684618473053, 0.140459343791008, -0.006937041878700256, -0.051750604063272476, 0.09420473873615265, -0.07050520181655884, -0.08551648259162903, -0.0047262441366910934, 0.15997004508972168, 0.20680919289588928, -0.1356915980577469, 0.11608749628067017, 0.17257758975028992, 0.1945038139820099, 0.11480481922626495, -0.07618860900402069, -0.0004387900116853416, 0.11598590761423111, 0.2578579783439636, 0.17794251441955566, 0.009706987999379635, -9.999327943432945e-08, 0.00325222359970212, 0.02140737697482109, 0.18319639563560486, 0.19767478108406067, 0.01283054519444704, 0.06018280237913132, -0.1343308836221695, 0.008166260085999966, -0.13297657668590546, 0.012404636479914188, 0.07799682021141052, -0.016179095953702927, -0.11967001855373383, 0.033962830901145935, -0.02824418991804123, -0.022093500941991806, -0.020848924294114113, 0.05922834947705269, -0.09259633719921112, -0.006403793580830097, -0.01998450607061386, -0.06726553291082382, 0.12287967652082443, -0.022120725363492966, -0.006232713349163532, -0.14793086051940918, -0.048691026866436005, 0.05226689949631691, 0.0371093824505806, 0.036792535334825516, 0.06193264573812485, -0.0726909413933754, 0.024823706597089767, 0.024119969457387924, -0.00467144139111042, -0.04211249202489853, 0.1594802439212799, -0.05593467876315117, -0.0110054612159729, 0.1432155966758728, -0.04828609898686409, 0.040666911751031876, -0.11850964277982712, -0.00520697608590126, 0.11469575017690659, -0.04190419614315033, 0.061584651470184326, -0.01997898705303669, 0.21543188393115997, 0.00617806613445282, -0.0397556871175766, -0.11669446527957916, -0.05355818569660187, 0.025996200740337372, 0.057413533329963684, 0.0297946035861969, -0.16190668940544128, 0.02117435820400715, 0.0317922942340374, 0.11186857521533966, -0.1651664674282074, -0.21106582880020142, -0.12323417514562607, -0.015580027364194393], metadata={'source': 'AAAMLP-569to.pdf', 'page': 277}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 278 # create an average of all predictions # that is the simplest ensemble avg_pred = (pred_logreg + pred_rf + pred_xgbc) / 3  # a 2d array of all predictions fold2_preds = np.column_stack((     pred_logreg,     pred_rf,     pred_xgbc,     avg_pred ))  # calculate and store individual AUC values aucs_fold2 = [] for i in range(fold2_preds.shape[1]):     auc = metrics.roc_auc_score(yfold2, fold2_preds[:, i])     aucs_fold2.append(auc)  print(f\"Fold-2: LR AUC = {aucs_fold2[0]}\") print(f\"Fold-2: RF AUC = {aucs_fold2[1]}\") print(f\"Fold-2: XGB AUC = {aucs_fold2[2]}\") print(f\"Fold-2: Average Pred AUC = {aucs_fold2[3]}\")  # now we repeat the same for the other fold # this is not the ideal way, if you ever have to repeat code,  # create a function! # fit models on fold 2 and make predictions on fold 1 logreg = linear_model.LogisticRegression() rf = ensemble.RandomForestClassifier() xgbc = xgb.XGBClassifier()  logreg.fit(xfold2, yfold2) rf.fit(xfold2, yfold2) xgbc.fit(xfold2, yfold2)  pred_logreg = logreg.predict_proba(xfold1)[:, 1] pred_rf = rf.predict_proba(xfold1)[:, 1] pred_xgbc = xgbc.predict_proba(xfold1)[:, 1] avg_pred = (pred_logreg + pred_rf + pred_xgbc) / 3  fold1_preds = np.column_stack((     pred_logreg,     pred_rf,     pred_xgbc,     avg_pred ))'),\n",
       " VectorParams(vector=[-0.095126673579216, -0.1173589825630188, -0.127201646566391, 0.1026940643787384, 0.2430318295955658, -0.15953552722930908, 0.012528941966593266, 0.182486891746521, -0.11366654187440872, 0.07788412272930145, 0.04688059538602829, -0.2033209204673767, -0.10187225043773651, 0.0236537903547287, -0.03961141034960747, 0.19566619396209717, -0.27301013469696045, -0.03352852910757065, -0.10788857191801071, 0.14317983388900757, 0.13249096274375916, 0.05941810458898544, -0.1205597072839737, 0.04082275554537773, 0.08824975043535233, -0.0047862594947218895, -0.04330062121152878, 0.1663254350423813, -0.13500194251537323, -0.004510838538408279, 0.06620664894580841, 0.01854938454926014, 0.2455943077802658, -0.02305476926267147, -0.06932526081800461, 0.021443050354719162, -0.12721207737922668, -0.021516602486371994, -0.1354118138551712, -0.08012297749519348, -0.12694589793682098, 0.030338378623127937, 0.09635227173566818, 0.05827055126428604, 0.030774716287851334, 0.08457228541374207, -0.13051562011241913, -0.03862626850605011, -0.02238667756319046, -0.015689322724938393, 0.10127342492341995, 0.07817040383815765, -0.30509087443351746, -0.04856076091527939, -0.11322442442178726, -0.016501720994710922, -0.050754837691783905, -0.11588513106107712, 0.11981713026762009, -0.05481157451868057, 0.019891908392310143, -0.08008769154548645, -0.07553605735301971, -0.04845234379172325, 0.11210369318723679, 0.033932365477085114, -0.03654175251722336, -0.03908857703208923, -0.12831687927246094, 0.16406987607479095, -0.0717695951461792, -0.043674152344465256, -0.05236436054110527, -0.04034233093261719, 0.15782716870307922, 0.1515483856201172, 0.24585242569446564, -0.045091405510902405, -0.05558672919869423, -0.03694324567914009, -0.18212151527404785, 0.08990450948476791, 0.03985120356082916, -0.038752809166908264, 0.05320383608341217, -0.17216670513153076, 0.11862625181674957, -0.04114348441362381, 0.09310703724622726, -0.07790032029151917, 0.21452127397060394, -0.016521109268069267, -0.19661831855773926, -0.024956634268164635, -0.04618075489997864, 0.039302483201026917, 0.11004321277141571, -0.00017843861132860184, 0.06987521797418594, 0.16125386953353882, 0.007116368506103754, 0.09711244702339172, 0.12714362144470215, -0.0787765383720398, 0.03168598189949989, -0.047755248844623566, 0.12604528665542603, 0.04979242384433746, 0.15361762046813965, 0.0063532693311572075, -0.019962523132562637, -0.06371079385280609, -0.008673859760165215, 0.06046023219823837, 0.09509089589118958, 0.19041676819324493, 0.01714625023305416, 0.12617945671081543, -0.026229601353406906, 0.22734224796295166, -0.10207194089889526, -0.01450565829873085, 0.18796443939208984, 0.03466099873185158, -0.030271019786596298, -0.10859407484531403, -0.21907296776771545, 1.3447625986048199e-32, -0.2972105145454407, -0.062094248831272125, -0.034164778888225555, -0.10927033424377441, -0.022033926099538803, -0.048253294080495834, -0.01012748759239912, -0.06028369814157486, -0.05108913034200668, 0.15574654936790466, -0.229966402053833, 0.19919627904891968, -0.009497600607573986, 0.0762680321931839, 0.029526717960834503, -0.06869402527809143, 0.08683756738901138, 0.034360114485025406, -0.09391751885414124, -0.060776595026254654, 0.20371408760547638, 0.08639487624168396, 0.16514262557029724, -0.04878157377243042, 0.0622161328792572, -0.09628847986459732, 0.06870104372501373, -0.02740119770169258, -0.1051904484629631, 0.02424517832696438, -0.16129079461097717, -0.09217314422130585, -0.07567569613456726, -0.12265821546316147, 0.04948888719081879, -0.014589119702577591, 0.08994963765144348, 0.04140734672546387, -0.008598300628364086, 0.04666706547141075, 0.06048332154750824, 0.08126358687877655, 0.17459452152252197, -0.08078579604625702, -0.03190361708402634, -0.19781199097633362, 0.021409763023257256, 0.30738773941993713, -0.028678016737103462, 0.13364659249782562, -0.041553694754838943, -0.22611042857170105, -0.07834026217460632, 0.10850369185209274, -0.04191005229949951, 0.07577858865261078, 0.059957124292850494, 0.019772198051214218, 0.11871813237667084, -0.02896769344806671, 0.05027416720986366, -0.0036978363059461117, -0.0879809632897377, -0.10107814520597458, 0.02016204223036766, 0.09788845479488373, 0.12458594143390656, -0.13933956623077393, 0.05876991152763367, 0.13927552103996277, -0.21921487152576447, 0.023477140814065933, 0.032744936645030975, -0.06682930886745453, 0.05474938452243805, -0.09824981540441513, 0.1443767249584198, -0.038211315870285034, -0.09619166702032089, -0.09518692642450333, -0.11153917014598846, 0.3790309429168701, -0.11859487742185593, -0.2516995072364807, -0.12806978821754456, -0.12428200244903564, 0.09185555577278137, -0.14936494827270508, -0.3520374596118927, -0.14104771614074707, -0.1931155025959015, 0.002844389993697405, 0.029603347182273865, -0.09112969040870667, -0.16270722448825836, -1.2935198611165993e-32, 0.06345787644386292, -0.1208328902721405, 0.12813657522201538, 0.007397579029202461, 0.054575685411691666, -0.005698004737496376, 0.07716047763824463, -0.11658725142478943, -0.14769187569618225, -0.18745562434196472, 0.02233276329934597, -0.12419155240058899, 0.1177620217204094, 0.030200716108083725, 0.23686978220939636, 0.10723599046468735, 0.05160444974899292, 0.13890856504440308, 0.0276369396597147, 0.040423743426799774, 0.018793851137161255, 0.17472591996192932, 0.04856085777282715, -0.01686198264360428, -0.17447036504745483, -0.01614433340728283, 0.14703255891799927, 0.11879695951938629, 0.06428667902946472, -0.07246481627225876, -0.20544087886810303, 0.06673923879861832, -0.19261914491653442, 0.2052508294582367, -0.048874080181121826, -0.017859144136309624, -0.1258811503648758, -0.028024272993206978, -0.041566312313079834, 0.06568290293216705, 0.10056756436824799, 0.20494085550308228, -0.2490304857492447, -0.02181963250041008, -0.012026657350361347, -0.06950611621141434, -0.006131088361144066, 0.020831873640418053, -0.06014994904398918, -0.2057725489139557, 0.016340205445885658, -0.07640644907951355, -0.17177420854568481, 0.10227334499359131, -0.15629929304122925, 0.17196692526340485, -0.11767347157001495, -0.06262392550706863, -0.013357128947973251, -0.050970643758773804, -0.026803109794855118, -0.01832122914493084, -0.0030537769198417664, -0.05965056270360947, 0.09870906919240952, 0.08392758667469025, -0.044473785907030106, -0.04642167687416077, -0.02329729124903679, 0.2063237875699997, -0.09802620112895966, -0.020352086052298546, 0.02333148941397667, -0.1185777336359024, -0.0659874975681305, 0.11031777411699295, 0.0913940817117691, 0.014415044337511063, 0.05852517485618591, -0.10525404661893845, -0.03461067005991936, 0.034476615488529205, 0.15653353929519653, 0.28466877341270447, -0.1532110571861267, 0.07166142761707306, 0.13767680525779724, 0.24560916423797607, 0.11813366413116455, -0.04676075279712677, 0.06912854313850403, 0.09514978528022766, 0.29479220509529114, 0.2463151514530182, 0.007307735271751881, -1.0069368272525026e-07, 0.0016407351940870285, -0.05013930797576904, 0.12214809656143188, 0.08866032212972641, -0.021844983100891113, 0.06940881907939911, -0.07502459734678268, -0.05860317498445511, -0.17651331424713135, -0.0027408357709646225, 0.07737366855144501, 0.014576446264982224, -0.2235947549343109, -0.02455543354153633, -0.07792595028877258, 0.06746289134025574, -0.0799674540758133, 0.21664604544639587, -0.10402580350637436, -0.0526106134057045, -0.0349600650370121, -0.027651775628328323, 0.061395879834890366, -0.10102254152297974, 0.00034049805253744125, -0.17079216241836548, -0.06116695702075958, -0.019335538148880005, -0.0538586750626564, 0.09758511185646057, 0.02703734114766121, -0.041842058300971985, 0.0013028171379119158, -0.08833791315555573, 0.060827530920505524, 0.060583386570215225, 0.05346805974841118, -0.04257746785879135, -0.06463368237018585, 0.2250611037015915, -0.012325050309300423, 0.21069136261940002, -0.20720544457435608, -0.004632864147424698, 0.1858176290988922, -0.0344347208738327, 0.10369404405355453, 0.04030095785856247, 0.12265419960021973, -0.06492534279823303, 0.11808928847312927, -0.0514536052942276, -0.15154564380645752, -0.007200200110673904, 0.009880993515253067, -0.01654711365699768, -0.16221588850021362, 0.0308822188526392, -0.05134843289852142, 0.08032646030187607, -0.09180527925491333, -0.11977903544902802, -0.01471329852938652, -0.01522293034940958], metadata={'source': 'AAAMLP-569to.pdf', 'page': 278}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 279 aucs_fold1 = [] for i in range(fold1_preds.shape[1]):     auc = metrics.roc_auc_score(yfold1, fold1_preds[:, i])     aucs_fold1.append(auc)  print(f\"Fold-1: LR AUC = {aucs_fold1[0]}\") print(f\"Fold-1: RF AUC = {aucs_fold1[1]}\") print(f\"Fold-1: XGB AUC = {aucs_fold1[2]}\") print(f\"Fold-1: Average prediction AUC = {aucs_fold1[3]}\")  # find optimal weights using the optimizer opt = OptimizeAUC() # dont forget to remove the average column opt.fit(fold1_preds[:, :-1], yfold1) opt_preds_fold2 = opt.predict(fold2_preds[:, :-1]) auc = metrics.roc_auc_score(yfold2, opt_preds_fold2) print(f\"Optimized AUC, Fold 2 = {auc}\") print(f\"Coefficients = {opt.coef_}\")  opt = OptimizeAUC() opt.fit(fold2_preds[:, :-1], yfold2) opt_preds_fold1 = opt.predict(fold1_preds[:, :-1]) auc = metrics.roc_auc_score(yfold1, opt_preds_fold1) print(f\"Optimized AUC, Fold 1 = {auc}\") print(f\"Coefficients = {opt.coef_}\") ═════════════════════════════════════════════════════════════════════════  Let’s look at the output.  ═════════════════════════════════════════════════════════════════════════ ❯ python auc_opt.py Fold-2: LR AUC = 0.9145446769443348 Fold-2: RF AUC = 0.9269918948683287 Fold-2: XGB AUC = 0.9302436595508696 Fold-2: Average Pred AUC = 0.927701495890154  Fold-1: LR AUC = 0.9050872233256017 Fold-1: RF AUC = 0.9179382818311258 Fold-1: XGB AUC = 0.9195837242005629 Fold-1: Average prediction AUC = 0.9189669233123695  Optimization terminated successfully.          Current function value: -0.920643          Iterations: 50          Function evaluations: 109 Optimized AUC, Fold 2 = 0.9305386199756128 Coefficients = [-0.00188194  0.19328336  0.35891836]'),\n",
       " VectorParams(vector=[-0.11471106857061386, -0.09558480978012085, -0.14442500472068787, 0.09593746066093445, 0.1669982671737671, -0.03135427087545395, 0.013675902038812637, 0.03834919631481171, -0.038075920194387436, 0.046518102288246155, -0.13461703062057495, -0.09695932269096375, 0.029162997379899025, -0.028476392850279808, -0.00859580747783184, 0.09816738963127136, -0.03322974592447281, 0.06413418799638748, -0.1405821442604065, 0.05068780481815338, 0.04278511181473732, -0.011191791854798794, -0.01805252581834793, 0.06688246130943298, -0.03535662591457367, -0.051851965487003326, -0.038458652794361115, -0.003121990244835615, -0.1455158293247223, -0.04262637346982956, -0.017329394817352295, -0.02658529207110405, 0.07395469397306442, 0.02464023046195507, -0.16727885603904724, -0.06471261382102966, -0.08424244821071625, 0.03663083165884018, -0.03810063377022743, -0.07592498511075974, -0.03719015046954155, 0.03933534398674965, -0.057613737881183624, -0.030929340049624443, 0.013679035007953644, -0.020028041675686836, -0.03798428922891617, -0.08229590952396393, 0.0473315566778183, -0.04816414788365364, -0.012251891195774078, 0.08703041076660156, -0.1812523603439331, 0.04532598331570625, -0.07508483529090881, -0.02899174392223358, -0.05600106716156006, -0.06463295966386795, 0.001578070572577417, -0.06606000661849976, -0.01601000875234604, -0.038911234587430954, 0.016964349895715714, -0.03694610297679901, 0.12197238206863403, -0.16843128204345703, -0.056516099721193314, 0.06834684312343597, 0.05137582868337631, 0.13454404473304749, 0.02962077036499977, -0.015207665041089058, 0.025636542588472366, 0.0463617667555809, 0.06596580892801285, 0.10377363860607147, 0.16893073916435242, 0.1246921494603157, 0.08549502491950989, 0.04675512760877609, -0.12503840029239655, 0.09938566386699677, 0.07787741720676422, -0.05589011684060097, 0.10972920805215836, -0.14334920048713684, -0.036101724952459335, 0.03638394922018051, -0.02046162262558937, -0.03175792470574379, 0.0889042466878891, 0.0029463511891663074, 0.009461764246225357, 0.028126582503318787, 0.05172431841492653, 0.012356467545032501, 0.11578261107206345, -0.041531190276145935, 0.02338922955095768, 0.019299376755952835, -0.06629052013158798, 0.01890663243830204, 0.0853591188788414, -0.12265028059482574, 0.12540264427661896, -0.10447315871715546, -0.018116720020771027, 0.04325087368488312, 0.10436283051967621, -0.1418185979127884, 0.0018393078353255987, -0.014568778686225414, -0.12040956318378448, -0.023897502571344376, -0.0009166109375655651, 0.13072505593299866, -0.06751173734664917, 0.05070869252085686, -0.014190628193318844, 0.1493987739086151, -0.12769173085689545, -0.027558300644159317, 0.08044089376926422, -0.01953471265733242, 0.11253324151039124, -0.015908293426036835, -0.09888549149036407, 1.1070884407229015e-32, -0.037056516855955124, -0.006203900091350079, -0.0910123735666275, -0.12153586745262146, 0.09874281287193298, 0.0004995139315724373, 0.09421997517347336, 0.06779128313064575, 0.057043179869651794, 0.07320231199264526, -0.10060559213161469, 0.10357211530208588, 0.0314108245074749, 0.08181267231702805, 0.0698552131652832, 0.0579991415143013, -0.126424640417099, -0.03198852390050888, -0.10280236601829529, 0.04025722295045853, 0.17324194312095642, 0.029645614326000214, 0.09152673184871674, -0.006615685764700174, -0.022290943190455437, 0.05616059899330139, 0.07780476659536362, 0.044742900878190994, -0.15720373392105103, 0.08122240006923676, -0.07604493200778961, -0.002651100978255272, -0.020147278904914856, -0.037250928580760956, 0.01971103623509407, -0.009754784405231476, 0.017641078680753708, -0.018571536988019943, -0.05875783786177635, -0.08458314090967178, -0.04403580725193024, -0.042943499982357025, -0.00758025236427784, -0.08511866629123688, -0.020301105454564095, 0.08891429007053375, -0.04781787842512131, 0.1430824100971222, -0.08995148539543152, 0.08952666819095612, 0.010220380499958992, -0.11413376033306122, -0.014752093702554703, 0.07735492289066315, -0.0016871355473995209, 0.041986387223005295, 0.06311739981174469, 0.007422388531267643, 0.03167354315519333, -0.02795996144413948, -0.06417462974786758, -0.11557817459106445, -0.017799459397792816, -0.009153440594673157, 0.009551610797643661, -0.058427952229976654, 0.11161728203296661, 0.04117811843752861, -0.009599234908819199, 0.009244665503501892, 0.02583090215921402, -0.01038425788283348, 0.00623749103397131, -0.06257641315460205, 0.030886827036738396, -0.035263095051050186, 0.15882864594459534, 0.020534157752990723, -0.003982214257121086, -0.018184173852205276, -0.007346686907112598, 0.22381329536437988, 0.014812245965003967, -0.15200631320476532, -0.11976370960474014, 0.029991360381245613, 0.04857026785612106, 0.005031765438616276, -0.17172196507453918, 0.022989165037870407, -0.14605826139450073, 0.017429348081350327, 0.07226072251796722, 0.01106702908873558, -0.06249053031206131, -1.0324979609702517e-32, -0.02338763140141964, -0.05943000689148903, -0.03432256355881691, 0.08863706886768341, 0.08803412318229675, 0.04490911215543747, -0.004216571804136038, -0.15487399697303772, -0.1158091127872467, -0.17685118317604065, 0.00205075740814209, 0.023477502167224884, 0.11669755727052689, 0.09426259249448776, 0.06807852536439896, 0.017032748088240623, -0.0714682936668396, 0.01744973100721836, -0.000700940378010273, 0.020204240456223488, -0.014338883571326733, 0.18696776032447815, -0.06901310384273529, -0.040677521377801895, -0.08542121946811676, -0.05321621894836426, -0.07338947057723999, 0.10397681593894958, 0.05002458393573761, -0.02972332015633583, -0.015267417766153812, 0.08401095867156982, -0.13773168623447418, -0.015437711961567402, -0.03720588982105255, -0.04762620851397514, 0.01331273466348648, -0.0770275890827179, -0.0031605642288923264, 0.1045297235250473, 0.035628389567136765, 0.04331411421298981, -0.09332925081253052, -0.03991176187992096, 0.058414310216903687, -0.009347940795123577, -0.054353080689907074, -0.000696883536875248, 0.09461794048547745, 0.03261911869049072, 0.019635789096355438, -0.08371427655220032, -0.10363539308309555, 0.13395550847053528, -0.10458454489707947, 0.08777253329753876, -0.07709851115942001, 0.03537656366825104, 0.008269527927041054, 0.07299739122390747, -0.12218036502599716, 0.0684950053691864, 0.1143636479973793, 0.005444292910397053, 0.006972886621952057, -0.025807823985815048, 0.033075690269470215, 0.01441047340631485, 0.02344578690826893, 0.09579476714134216, -0.024008357897400856, -0.0308757983148098, 0.0013473909348249435, 0.10599581897258759, -0.13105034828186035, 0.09246116876602173, 0.08089429140090942, -0.01003662683069706, -0.029885917901992798, -0.10392087697982788, -0.08473971486091614, 0.012998607009649277, 0.1302548199892044, 0.13448551297187805, -0.05500227212905884, 0.1253165453672409, 0.13723301887512207, 0.12211382389068604, 0.0931122675538063, -0.05829399824142456, 0.019008511677384377, 0.04403391480445862, 0.09601232409477234, 0.1383237987756729, -0.09411557018756866, -9.957015834061167e-08, -0.03420328348875046, 0.11372160911560059, -0.0577659010887146, -0.0008390694856643677, 0.07160642743110657, -0.01744195632636547, -0.09635604918003082, 0.15361610054969788, -0.025717316195368767, 0.05230382829904556, 0.1376829445362091, -0.027459537610411644, -0.11831706762313843, 0.010942794382572174, 0.0033110552467405796, 0.0746789202094078, -0.010734680108726025, 0.0382193848490715, -0.04686163365840912, 0.014122098684310913, 0.027636326849460602, -0.08889733254909515, 0.02212602086365223, -0.0017424803227186203, 0.024630684405565262, -0.07419504970312119, 0.08594642579555511, 0.06552857160568237, 0.06485281139612198, 0.01605350524187088, -0.10375023633241653, 0.029740815982222557, 0.016916129738092422, 0.028865668922662735, 0.07219500839710236, 0.14137253165245056, 0.1307258903980255, -0.11841298639774323, -0.10105714201927185, 0.025527697056531906, 0.05457686632871628, -0.0456199124455452, 0.02950238063931465, -0.08125529438257217, 0.007533300668001175, -0.003266550600528717, -0.01743745617568493, -0.056042566895484924, 0.043003179132938385, 0.044829752296209335, -0.03868895396590233, -0.046234130859375, -0.12168616056442261, -0.0421668216586113, 0.05904069542884827, -0.003997654188424349, -0.11153040826320648, -0.1370185911655426, 0.10447170585393906, 0.0569772869348526, -0.010018706321716309, -0.17044419050216675, -0.09548839181661606, 0.0616825670003891], metadata={'source': 'AAAMLP-569to.pdf', 'page': 279}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 280 Optimization terminated successfully.          Current function value: -0.931232          Iterations: 56          Function evaluations: 113 Optimized AUC, Fold 1 = 0.9192523637234037 Coefficients = [-0.15655124  0.22393151  0.58711366] ═════════════════════════════════════════════════════════════════════════  We see that average is better but using the optimizer to find the threshold is even better! Sometimes, the average is the best choice. As you can see, the coefficients do not add up to 1.0, but that’s okay as we are dealing with AUC and AUC cares only about ranks.  Even random forest is an ensemble model. Random forest is just a combination of many simple decision trees. Random forest comes in a category of ensemble models which is popularly known as bagging. In bagging, we create small subsets of data and train multiple simple models. The final result is obtained by a combination of predictions, such as average, of all such small models.  And the xgboost model that we used is also an ensemble model. All gradient boosting models are ensemble models and come under the umbrella name: boosting. Boosting models work similar to bagging models, except for the fact that consecutive models in boosting are trained on error residuals and tend to minimize the errors of preceding models. This way, boosting models can learn the data perfectly and are thus susceptible to overfitting.  What we saw in the code snippets till now considers only one column. This is not always the case, and there will be many times when you have to deal with multiple columns for predictions. For example, you might have a problem where you are predicting one class out of multiple classes, i.e., multi-class classification problem. For a multi-class classification problem, you can easily choose the voting approach. But voting might not always be the best approach. If you want to combine the probabilities, you will have a two-dimensional array instead of a vector as we had previously when we were optimizing for AUC. With multiple classes, you can try optimizing for log-loss instead (or some other business-relevant metric). To combine, you can use a list of numpy arrays instead of a numpy array in the fit function (X) and subsequently, you would also need to change the optimizer and the predict function. I’m going to leave it as an exercise for you.  And now we can move to the next interesting topic which is quite popular and is known as stacking. Figure 2 shows how you can stack models.'),\n",
       " VectorParams(vector=[-0.12674060463905334, -0.17662496864795685, 0.09577835351228714, 0.06136413663625717, 0.021635491400957108, -0.08964261412620544, -0.18619036674499512, 0.13458888232707977, -0.22253412008285522, -0.07880783826112747, -0.05216693878173828, -0.08881402760744095, 0.006997448392212391, -0.03737105801701546, -0.07249592989683151, 0.16582009196281433, -0.09908255934715271, 0.13404560089111328, -0.12538014352321625, -0.02226286567747593, 0.12020910531282425, -0.06852056831121445, 0.008748602122068405, 0.10185214877128601, -0.08528587967157364, 0.07630880922079086, -0.10070522874593735, 0.02552894502878189, 0.05177244916558266, -0.06912817806005478, 0.2763340175151825, -0.0724421888589859, -0.03792556747794151, -0.08166785538196564, -0.02425716072320938, 0.041373856365680695, -0.0771704763174057, -0.048606302589178085, -0.02889355458319187, 0.09267619252204895, -0.0490226186811924, -0.1150430217385292, 0.032967064529657364, 0.014841736294329166, 0.15272760391235352, 0.03819767013192177, 0.027143040671944618, -0.04733622074127197, 0.017173832282423973, 0.09734826534986496, -0.06282199919223785, -0.10817994922399521, -0.01896318979561329, -0.04908595234155655, -0.08672671765089035, 0.0121723972260952, 0.018006619065999985, 0.018337156623601913, -0.017539530992507935, 0.017017843201756477, -0.07433393597602844, -0.057275012135505676, -0.11578831076622009, -0.02357608452439308, 0.047831419855356216, 0.014970912598073483, -0.02794303372502327, 0.12996771931648254, -0.05745186656713486, 0.16263653337955475, -0.032305020838975906, 0.16162921488285065, -0.05614954233169556, 0.01604968123137951, 0.12071382999420166, 0.14624981582164764, 0.036110881716012955, -0.05142226070165634, -0.04054262861609459, 0.010008281096816063, 0.012195758521556854, 0.06851880997419357, 0.0355084091424942, -0.06241893395781517, -0.034762777388095856, -0.04657149687409401, 0.06986705213785172, -0.001304563251323998, -0.030051346868276596, -0.0039029100444167852, 0.10168319940567017, -0.11714030802249908, 0.07045654952526093, 0.08524700254201889, 0.05583835765719414, 0.1662694811820984, 0.06910806149244308, -0.12709830701351166, 0.07581726461648941, 0.05455341935157776, -0.11160968244075775, 0.12079398334026337, 0.08420293778181076, -0.02189628779888153, 0.06414387375116348, -0.007400644943118095, 0.04004385322332382, -0.033824577927589417, 0.013328084722161293, -0.25401362776756287, 0.28644949197769165, -0.0749005526304245, -0.04524626582860947, -0.024383408948779106, 0.05027236416935921, 0.11975425481796265, -0.003256376599892974, -0.021600967273116112, -0.1682220995426178, 0.14017120003700256, -0.1031695082783699, 0.029720978811383247, 0.15728305280208588, -0.03894583880901337, -0.04057181999087334, 0.005078294314444065, -0.12156496942043304, 9.954729745920206e-33, -0.021003948524594307, 0.026655469089746475, 0.036553263664245605, 0.06942375749349594, 0.052045051008462906, -0.07975002378225327, -0.0066071562469005585, -0.03688573092222214, -0.1184501126408577, 0.06813500821590424, 0.019290126860141754, -0.07185588032007217, -0.031757745891809464, 0.01813754253089428, 0.02512308955192566, -0.12232604622840881, 0.08977591246366501, -0.02563401497900486, -0.050891853868961334, -0.00927651021629572, 0.07978704571723938, -0.1257479041814804, -0.009452939964830875, -0.07774434983730316, 0.07951512187719345, 0.04782985895872116, 0.0075545115396380424, -0.017054200172424316, -0.13548409938812256, 0.029710320755839348, -0.030927535146474838, 0.0008116969256661832, -0.12704889476299286, 0.09176158159971237, 0.012463678605854511, 0.04380695894360542, 0.05255806818604469, -0.05212752893567085, 0.0936536192893982, 0.0798858031630516, 0.08835671097040176, -0.02000100165605545, 0.06770473718643188, 0.052624624222517014, 0.0019929201807826757, -0.059086211025714874, -0.0018088333308696747, -0.031691212207078934, -0.1376194804906845, 0.017716707661747932, 0.024038491770625114, -0.024623459205031395, -0.12528114020824432, -0.1096036359667778, -0.10621242970228195, 0.12464733421802521, -0.030764294788241386, -0.029225755482912064, 0.14631813764572144, 0.11880619078874588, 0.09550121426582336, -0.09505432844161987, -0.07838618010282516, 0.08692797273397446, -0.12492591887712479, -0.055284272879362106, -0.03300704434514046, -0.10392843186855316, 0.08126594871282578, 0.02721364237368107, -0.08545282483100891, -0.011584415100514889, -0.11165039986371994, 0.07421958446502686, 0.01625301130115986, -0.021281613036990166, 0.09283801168203354, 0.0845571979880333, 0.04859239235520363, -0.04871363937854767, 0.09699786454439163, 0.13880112767219543, -0.0047803097404539585, -0.23431994020938873, 0.07924918085336685, -0.016467439010739326, -0.0710352435708046, -0.09551028907299042, -0.14822518825531006, 0.16437312960624695, -0.3292469382286072, -0.016229592263698578, 0.1316860318183899, -0.21061497926712036, 0.007022242061793804, -8.343522250918314e-33, 0.04264278709888458, 0.11380410194396973, 0.04929252713918686, 0.05897250026464462, -0.10741303861141205, -0.15023039281368256, 0.023637039586901665, -0.06455424427986145, -0.25212761759757996, -0.032187193632125854, -0.10368094593286514, -0.003019923809915781, 0.07942189276218414, -0.030976664274930954, -0.06173143535852432, -0.029244352132081985, 0.022853035479784012, 0.026834610849618912, 0.09680110961198807, 0.0041459850035607815, -0.02842606045305729, 0.0711403340101242, -0.06474640220403671, 0.10575240105390549, -0.07840617001056671, 0.0293797068297863, -0.13368530571460724, 0.11552744358778, 0.23807838559150696, 0.008157028816640377, -0.08640541881322861, -0.14088641107082367, 0.11924942582845688, -0.014071207493543625, 0.0051806773990392685, 0.12799151241779327, 0.0373847596347332, -0.10734114795923233, 0.21053752303123474, 0.05210479721426964, 0.07040553539991379, -0.06747087836265564, -0.1864406317472458, -0.0712105929851532, 0.07296997308731079, -0.14079971611499786, -0.2505694329738617, 0.022995976731181145, -0.024949824437499046, -0.19593362510204315, -0.1969011127948761, 0.10971839725971222, -0.06735574454069138, 0.06079650670289993, -0.0415545329451561, 0.058486294001340866, 0.018519962206482887, -0.05196497216820717, 0.05402235686779022, -0.027254927903413773, 0.003577428637072444, -0.044141735881567, 0.08403925597667694, 0.043168578296899796, 0.13524961471557617, 0.01410756353288889, -0.009653253480792046, -0.06177697330713272, -0.052324309945106506, 0.10283733904361725, -0.1524631232023239, 0.00649729510769248, 0.056865256279706955, -0.04351323843002319, 0.09978967905044556, -0.03535236790776253, -0.0939812958240509, 0.04289868474006653, 0.11804216355085373, -0.07996287196874619, -0.14244680106639862, -0.09593771398067474, -0.05141943693161011, 0.18438605964183807, 0.035873301327228546, 0.1691710501909256, 0.20223265886306763, 0.160428985953331, 0.04566098004579544, -0.09651043266057968, -0.0009880434954538941, -0.02868822030723095, 0.04294722527265549, 0.1302035003900528, 0.03371523693203926, -9.864351113719749e-08, 0.04516792297363281, -0.1398235559463501, 0.180293470621109, 0.17443062365055084, 0.015451651066541672, -0.04471544921398163, -0.0075168125331401825, 0.021998777985572815, -0.05584591627120972, -0.06265905499458313, -0.029217371717095375, 0.04192105680704117, -0.04804593697190285, 0.09206560254096985, 0.12423701584339142, 0.13508418202400208, -0.007764163427054882, 0.2201874554157257, -0.09018342941999435, 0.1404389888048172, -0.0022771544754505157, -0.02576589398086071, 0.23804597556591034, 0.19628280401229858, 0.14223146438598633, -0.0353660024702549, -0.04480668902397156, 0.09856953471899033, 0.10010893642902374, -0.031212028115987778, 0.03176622465252876, -0.08972214162349701, -0.044770047068595886, 0.06281673163175583, 0.06745311617851257, 0.07654249668121338, 0.10092787444591522, 0.008922167122364044, -0.10002487897872925, 0.11302056908607483, 0.049306098371744156, 0.09053624421358109, -0.010524807497859001, 0.05745311081409454, 0.15240566432476044, -0.07334790378808975, -0.04011979699134827, -0.05281494930386543, 0.02022312767803669, -0.09194543957710266, -0.10135616362094879, 0.034651052206754684, -0.013087141327559948, 0.1406680941581726, -0.015744471922516823, 0.03942050039768219, -0.06263706833124161, 0.11338293552398682, -0.02950386516749859, 0.11604594439268112, -0.021730313077569008, -0.13568922877311707, -0.09156619757413864, -0.0026505107525736094], metadata={'source': 'AAAMLP-569to.pdf', 'page': 280}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 281  \\n Figure 2: Stacking  Stacking is not rocket science. It’s straightforward. If you have correct cross-validation and keep the folds same throughout the journey of your modelling task, nothing should overfit.  Let me describe the idea to you in simple points.  - Divide the training data into folds. - Train a bunch of models: M1, M2…..Mn. - Create full training predictions (using out of fold training) and test predictions using all these models. - Till here it is Level – 1 (L1). - Use the fold predictions from these models as features to another model. This is now a Level – 2 (L2) model. - Use the same folds as before to train this L2 model. - Now create OOF (out of fold) predictions on the training set and the test set. - Now you have L2 predictions for training data and also the final test set predictions.'),\n",
       " VectorParams(vector=[-0.13393020629882812, -0.23347389698028564, 0.06056844815611839, 0.02886083535850048, 0.021010592579841614, -0.038540083914995193, -0.10015859454870224, -0.013801004737615585, -0.1688685119152069, -0.154078871011734, -0.06407955288887024, -0.06006428226828575, 0.07808680832386017, -0.020945409312844276, 0.06602399796247482, 0.2509234547615051, -0.10530102998018265, 0.18034827709197998, -0.10246077179908752, -0.030532870441675186, 0.034277137368917465, 0.02141868881881237, -0.04533467814326286, 0.07440654188394547, 0.021414685994386673, -0.008566274307668209, -0.01794673316180706, 0.01702767051756382, 0.168162539601326, -0.11856646090745926, 0.22047406435012817, 0.05370752140879631, -0.023356452584266663, 0.03725874051451683, -0.031717341393232346, 0.0427478551864624, -0.1346246898174286, 0.10194049030542374, -0.03829896077513695, 0.13367031514644623, -0.027788780629634857, -0.03098139353096485, 0.02057420089840889, -0.1298893243074417, 0.04794967547059059, 0.018553240224719048, -0.06816133111715317, -0.0645521730184555, 0.03529844805598259, 0.02234906330704689, 0.040229279547929764, -0.1717245727777481, -0.11501814424991608, 0.018550358712673187, -0.07659590989351273, 0.04294116422533989, -0.0385759137570858, 0.05091463774442673, -0.059032175689935684, 0.11719813942909241, -0.00041638396214693785, -0.047170355916023254, -0.04376361519098282, -0.03802121430635452, 0.09513011574745178, 0.07300466299057007, -0.050122808665037155, 0.08891038596630096, -0.05099320784211159, 0.23398452997207642, -0.08805913478136063, 0.08450358361005783, -0.09917179495096207, 0.05499119311571121, 0.0924648866057396, 0.04685011878609657, 0.10040000081062317, -0.17518265545368195, 0.03845629841089249, 0.10164512693881989, -0.021163437515497208, 0.07099912315607071, -0.11854702234268188, 0.00764441816136241, -0.06932985037565231, -0.22941242158412933, -0.09279195219278336, -0.018314385786652565, -0.14358676970005035, -0.0414922758936882, -0.06338748335838318, -0.06527593731880188, 0.1447274386882782, 0.011416119523346424, -0.06018064543604851, 0.038181107491254807, 0.09317194670438766, -0.1579805463552475, 0.18960389494895935, 0.012459803372621536, -0.2547130286693573, 0.058548908680677414, 0.11788922548294067, -0.04433572292327881, -0.06560979038476944, -0.11640328913927078, 0.10226479917764664, -0.03716075420379639, -0.004552766215056181, -0.25069692730903625, 0.07447563856840134, -0.1593860387802124, -0.01828630082309246, -0.07584895193576813, -0.01501079648733139, 0.010375813581049442, 0.17710724472999573, -0.05705153942108154, 0.023100711405277252, 0.14278633892536163, -0.09268927574157715, -0.04719269275665283, 0.14660672843456268, 0.024888869374990463, 0.005836509633809328, -0.055812910199165344, -0.08329974859952927, 5.343919276377017e-33, -0.005582625512033701, 0.004748437087982893, -0.05897735804319382, 0.07344046980142593, 0.13367262482643127, -0.055524397641420364, -0.06809064000844955, -0.11723644286394119, -0.03815273940563202, 0.09824539721012115, 0.021287014707922935, 0.07885012775659561, -0.06420837342739105, 0.0831577330827713, 0.02944892831146717, -0.10207787901163101, 0.10592199116945267, 0.14033666253089905, -0.07861834019422531, -0.12804748117923737, -0.11019840836524963, -0.06268197298049927, 0.10837235301733017, -0.10230468958616257, -0.022500991821289062, 0.0542280450463295, 0.0647350624203682, -0.04323838651180267, 0.06877956539392471, -0.0006666266126558185, -0.04935174807906151, 0.11505566537380219, -0.048191316425800323, 0.025800757110118866, 0.004315441474318504, 0.05872969329357147, 0.10060889273881912, 0.038520440459251404, 0.136042520403862, 0.07610055059194565, -0.04901885241270065, 0.028372788801789284, 0.18557310104370117, -0.008326178416609764, 0.010778162628412247, 0.08298692107200623, 0.022678861394524574, 0.09262441843748093, -0.2060418426990509, 0.0818101242184639, -0.06621671468019485, -0.022561267018318176, 0.013857640326023102, -0.12955354154109955, -0.004844721406698227, -0.030986981466412544, -0.05587727949023247, -0.06273084878921509, 0.015738217160105705, 0.04095406457781792, 0.08109954744577408, 0.02509935386478901, -0.19344809651374817, 0.08653900027275085, -0.018984101712703705, 0.03842161223292351, 0.10030490159988403, -0.030023351311683655, 0.10372820496559143, 0.005595742724835873, -0.10106492042541504, -0.032892536371946335, -0.02086765691637993, -0.08494962006807327, 0.0454695001244545, -0.010109077207744122, 0.036166127771139145, -0.018192609772086143, 0.029906943440437317, -0.05666227266192436, -0.15270854532718658, 0.06424206495285034, -0.0009652184671722353, -0.15316422283649445, 0.0036982144229114056, 0.010777389630675316, -0.027772679924964905, -0.10008600354194641, -0.04012923687696457, 0.10659540444612503, -0.32795149087905884, 0.006614390294998884, 0.2235715687274933, -0.051915574818849564, 0.07692446559667587, -6.144972758714327e-33, -0.012357358820736408, 0.03065314143896103, 0.011786012910306454, 0.04136853292584419, 0.04377041012048721, 0.020924171432852745, -0.09834122657775879, -0.026854267343878746, -0.01675540953874588, 0.1326751410961151, -0.04950700327754021, 0.056209102272987366, 0.05845823138952255, -0.09204571694135666, -0.09241431206464767, -0.048254966735839844, 0.0023757959716022015, 0.011348246596753597, 0.06596647948026657, 0.06980564445257187, 0.016263766214251518, 0.05090529844164848, -0.04306963458657265, 0.07746010273694992, -0.034773632884025574, 0.030946895480155945, -0.20001734793186188, 0.025246266275644302, 0.2064490020275116, 0.06534763425588608, -0.1112523227930069, -0.2104191929101944, 0.1831449568271637, -0.12785927951335907, -0.057172078639268875, 0.08478425443172455, -0.000323087238939479, -0.08933129906654358, 0.12716789543628693, -0.04964463785290718, 0.03473668545484543, -0.15089446306228638, -0.1641126424074173, -0.04939723387360573, -0.003397459862753749, -0.24196036159992218, -0.13040363788604736, -0.03748507797718048, -0.10096863657236099, -0.14042335748672485, -0.22376224398612976, 0.15592320263385773, -0.13740892708301544, -0.03065495565533638, 0.042371682822704315, 0.2199666053056717, -0.10251837968826294, 0.03021947480738163, -0.010083929635584354, 0.06589466333389282, 0.013870530761778355, -0.025772547349333763, 0.0003986408410128206, 0.03324682638049126, 0.17069675028324127, -0.08495146781206131, 0.058560919016599655, 0.010795380920171738, -0.12102483958005905, 0.10553153604269028, 0.07167802006006241, 0.024891376495361328, 0.0920611023902893, -0.011415132321417332, -0.03182022646069527, -0.09999474138021469, -0.1326068490743637, -0.042946647852659225, 0.026611844077706337, 0.004933934658765793, -0.04825450852513313, -0.15168532729148865, -0.028169194236397743, 0.1370517462491989, 0.09827644377946854, 0.030580732971429825, 0.11284781247377396, 0.1859184056520462, 0.2165599763393402, -0.10557670891284943, -0.0053215017542243, 0.007052410393953323, 0.03571236506104469, 0.20480722188949585, -0.040467437356710434, -9.897456720864284e-08, 0.026909930631518364, -0.01739363744854927, 0.09516015648841858, 0.04939992353320122, 0.007130957208573818, -0.03429419919848442, -0.08087319135665894, 0.08938296884298325, -0.09434953331947327, 0.09042206406593323, -0.0012331429170444608, 0.09549760073423386, -0.05836845934391022, 0.02862352319061756, 0.06735702604055405, 0.05839860811829567, -0.0757419690489769, 0.2775684595108032, -0.05768023058772087, 0.16221801936626434, 0.017107151448726654, 0.021878059953451157, 0.1153717190027237, -0.04135933890938759, 0.04511198773980141, -0.18023931980133057, 0.010823308490216732, 0.10656588524580002, 0.08688610047101974, -0.0336928591132164, -0.03873136267066002, 0.0599290207028389, -0.005463318899273872, 0.0746416226029396, 0.08155690878629684, 0.10597826540470123, 0.04724480211734772, 0.00364878517575562, -0.1836538016796112, 0.001899780472740531, 0.041680607944726944, -0.022557690739631653, 0.0301072858273983, 0.07846923172473907, 0.13867345452308655, 0.06524378806352615, 0.03473940119147301, -0.07009097188711166, 0.12700380384922028, -0.04696912690997124, -0.10234567523002625, 0.023037519305944443, -0.009343922138214111, 0.042117342352867126, 0.11728887259960175, 0.07711281627416611, -0.06221678480505943, 0.144416943192482, 0.10126662999391556, 0.036119215190410614, 0.005380695685744286, -0.032377470284700394, -0.0640164241194725, 0.04976074397563934], metadata={'source': 'AAAMLP-569to.pdf', 'page': 281}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 282  You can keep repeating the L1 part and can create as many levels as you want.  Sometimes, you will also come across a term called blending. If you do, don’t worry about it much. It is nothing but stacking with a holdout set instead of multiple folds.  It must be noted that what I have described in this chapter can be applied to any kind of problem: classification, regression, multi-label classification, etc.'),\n",
       " VectorParams(vector=[-0.11921850591897964, -0.0990264043211937, -0.0735069140791893, 0.007260588463395834, -0.04429154470562935, -0.15082593262195587, -0.037883415818214417, 0.0997130498290062, -0.0725923627614975, 0.04677841439843178, 0.03905659168958664, 0.028853055089712143, 0.1221257895231247, -0.05453849956393242, 0.014186994172632694, -0.0976419746875763, -0.005376807879656553, 0.07410140335559845, -0.034816913306713104, -0.06145113334059715, 0.020349958911538124, 0.05558188259601593, -0.028496768325567245, 0.013802158646285534, -0.08121821284294128, -0.010516030713915825, 0.04343387112021446, -0.02356288954615593, -0.03182147443294525, -0.005819844547659159, 0.0698629692196846, 0.06596335768699646, 0.0035391163546591997, 0.06374473124742508, 0.10645393282175064, 0.1438252478837967, 0.010468251071870327, -0.0949774906039238, -0.09994735568761826, -0.09363338351249695, -0.001992699457332492, 0.07886781543493271, -0.07253540307283401, -0.02212703414261341, 0.05014490708708763, -0.15470771491527557, -0.03177705779671669, -0.1506321281194687, 0.0301233921200037, -0.03854193910956383, -0.16563090682029724, -0.05323315039277077, 0.07074994593858719, -0.0025105446111410856, -0.013709312304854393, -0.0816667377948761, 0.181918203830719, -0.019174087792634964, -0.11153610050678253, -0.08426198363304138, -0.027494650334119797, 0.04940398409962654, -0.05925785005092621, -0.01652124524116516, 0.040405768901109695, 0.021622810512781143, -0.03992793709039688, 0.164491206407547, 0.10242530703544617, -0.1707400381565094, -0.09424130618572235, 0.0249633826315403, -0.09455086290836334, 0.044144853949546814, -0.036665741354227066, -0.020768161863088608, 0.10109174996614456, 0.08509574830532074, 0.03533504530787468, -0.04961608722805977, -0.057534392923116684, 0.07769151777029037, 0.06880955398082733, -0.013958001509308815, -0.08782505989074707, 0.015604193322360516, 0.07983460277318954, 0.23011286556720734, 0.11560013890266418, -0.08179643750190735, 0.07410550862550735, -0.025504333898425102, 0.02730109728872776, -0.08421524614095688, 0.09552859514951706, 0.009389933198690414, 0.11751017719507217, 0.010156745091080666, -0.06003614515066147, 0.10222312062978745, -0.10308312624692917, -0.09921776503324509, 0.11056963354349136, -0.02582494542002678, 0.1328018605709076, 0.1455332487821579, 0.07835248857736588, -0.11618775129318237, 0.08894660323858261, -0.10731483995914459, -0.059574734419584274, -0.03499721735715866, -0.2364838868379593, -0.0360722690820694, 0.00795358419418335, 0.06139056012034416, -0.06205044314265251, -0.0432007871568203, -0.044495224952697754, 0.10277720540761948, -0.024539288133382797, -0.036840230226516724, 0.07250280678272247, -0.023644527420401573, 0.01975846104323864, -0.13171499967575073, -0.14394299685955048, 9.005036839631341e-33, -0.00157504016533494, -0.12965606153011322, 0.0429721362888813, 0.0891038328409195, 0.2758004069328308, -0.12181403487920761, 0.12276273965835571, -0.008005213923752308, -0.13921794295310974, -0.06906277686357498, -0.08829722553491592, 0.10978353023529053, -0.06575439870357513, 0.08724243938922882, 0.09609019011259079, -0.012558482587337494, -0.1295740306377411, 0.05713633447885513, 0.08300162106752396, -0.033479075878858566, 0.06272314488887787, -0.1129852682352066, -0.011500822380185127, -0.04000159353017807, 0.0009549076203256845, -0.04897715523838997, 0.05771700292825699, -0.1295907199382782, 0.07113897800445557, 0.029137061908841133, -0.028152141720056534, -0.05893951281905174, 0.07303068041801453, -0.02462676912546158, 0.0036659869365394115, -0.07085437327623367, -0.0219204593449831, -0.012877581641077995, -0.025599397718906403, -0.024562053382396698, 0.08270952850580215, -0.07635498046875, 0.13891668617725372, -0.08341461420059204, 0.07789675891399384, -0.02971375733613968, 0.03351264446973801, 0.03217606991529465, -0.017211953178048134, 0.0545799694955349, 0.10256783664226532, -0.02681249938905239, -0.043378859758377075, -0.015573647804558277, -0.04305204004049301, 0.06048702076077461, 0.014401777647435665, -0.127702534198761, 0.14547918736934662, 0.0254674069583416, -0.10532467067241669, -0.010802154429256916, 0.0390084944665432, 0.11653205752372742, 0.10178922861814499, -0.022122584283351898, 0.013919798657298088, 0.018692675977945328, 0.13945947587490082, 0.09977646172046661, -0.1171078309416771, -0.03909570351243019, -0.07848753035068512, -0.0326944962143898, 0.03811375051736832, -0.09762027859687805, 0.10175793617963791, -0.05249132215976715, -0.08371137082576752, 0.017385436221957207, -0.037196286022663116, 0.01443861797451973, -0.12635591626167297, -0.061162568628787994, -0.08523208647966385, 0.04957800358533859, 0.0023370508570224047, 0.04037686809897423, -0.07151122391223907, 0.04102008044719696, 0.015819722786545753, -0.033128801733255386, -0.03416043519973755, -0.024748774245381355, -0.03448454663157463, -1.1831315376195799e-32, -0.02537432871758938, -0.019187770783901215, -0.0798557698726654, 0.0067297485657036304, 0.0691833645105362, -0.008581810630857944, 0.021381717175245285, 0.006484611425548792, -0.08404324948787689, -0.05213378369808197, -0.19834426045417786, -0.07756885886192322, 0.09158075600862503, 0.020164480432868004, -0.009445082396268845, 0.08259159326553345, -0.118393674492836, -0.027478087693452835, 0.08903353661298752, 0.13207657635211945, -0.1454983502626419, 0.1101829931139946, 0.03526623919606209, 0.07074107229709625, -0.011083395220339298, -0.0276674535125494, -0.10224732756614685, 0.08527642488479614, 0.0361272394657135, -0.031164061278104782, 0.003867360297590494, 0.01395726390182972, -0.2183917909860611, -0.09028473496437073, -0.01964876987040043, 0.059362802654504776, -0.0015314329648390412, 0.05756381154060364, -0.016831515356898308, 0.06567581743001938, 0.11923981457948685, -0.025517163798213005, -0.20840518176555634, -0.06071275845170021, -0.05889631807804108, -0.03657062351703644, -0.06844401359558105, -0.09048070758581161, -0.029441237449645996, -0.0869055986404419, 0.037117812782526016, -0.0826554074883461, 0.0695432797074318, -0.049785226583480835, -0.0378442145884037, -0.0059085628017783165, 0.13156133890151978, 0.07033735513687134, -0.07225847244262695, 0.04137306660413742, 0.060224514454603195, -0.19783875346183777, 0.11576122045516968, -0.01324649341404438, -0.04009561240673065, -0.033559758216142654, -0.13831186294555664, 0.07956092804670334, -0.17516830563545227, 0.07613877207040787, -0.0839817225933075, 0.003338237525895238, 0.04468029364943504, 0.08847685903310776, -0.03567223995923996, 0.039224810898303986, -0.05941571295261383, -0.04583597183227539, -0.04421348497271538, 0.00418659346178174, 0.006578416563570499, 0.04803294688463211, 0.016877036541700363, 0.07713036984205246, -0.05093403160572052, 0.0032865770626813173, 0.18878425657749176, 0.06482583284378052, 0.045450638979673386, -0.0850292518734932, -0.05393102392554283, 0.05401470512151718, -0.007946950383484364, 0.08063573390245438, 0.04338346794247627, -1.0017192408895426e-07, 0.01277607399970293, 0.08559048920869827, 0.003496715798974037, 0.0419212244451046, -0.03316951170563698, 0.06645990163087845, 0.029398655518889427, 0.021331990137696266, -0.05120566859841347, 0.06984119117259979, 0.0380539707839489, -0.056437425315380096, -0.13070109486579895, 0.07554451376199722, -0.047612302005290985, 0.2893733084201813, -0.03740230202674866, 0.007140760775655508, -0.06822840869426727, -0.08999320864677429, 0.10297827422618866, 0.06439799070358276, 0.07980290800333023, 0.09300921112298965, -0.006863701622933149, -0.014508808963000774, 0.06696450710296631, 0.04953838512301445, -0.10106414556503296, 0.014634624123573303, 0.10462553054094315, -0.08063262701034546, -0.12048368901014328, 0.08321522176265717, 0.15519586205482483, -0.04574081301689148, -0.00984413456171751, -0.046103693544864655, 0.08305869251489639, -0.0007659534458070993, -0.0739411786198616, 0.11255700141191483, -0.0407949835062027, -0.07705669105052948, 0.06826882064342499, -0.019239777699112892, -0.07503639161586761, -0.08719596266746521, -0.07901035994291306, 0.06798607110977173, 0.03274165466427803, 0.016853822395205498, -0.08458663523197174, 0.11936977505683899, 0.09603043645620346, 0.09831120818853378, -0.03226744011044502, -0.0014922409318387508, 0.04475965350866318, 0.03762444853782654, -0.031739458441734314, 0.1664673388004303, 0.10573908686637878, 0.11405234783887863], metadata={'source': 'AAAMLP-569to.pdf', 'page': 282}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 283 Approaching reproducible code & model serving  We have now reached a stage where we should be able to distribute our models/training code to others so that they can use it. You can distribute or share the code with others in a floppy disk, but that’s not ideal. Is it? May be many years ago, it was ideal but not anymore. The preferred way of sharing code and collaborating with others is by using a source code management system. Git is one of the most popular source code management systems. So, let’s say you have learned git and formatted the code properly, have written proper documentation and have open-sourced your project. Is that enough? No. It’s not. It’s because you wrote code on your computer and that might not work on someone else’s computer because of many different reasons. So, it would be nice if when you distribute the code, you could replicate your computer and others can too when they install your software or run your code. To do this, the most popular way these days is to use Docker Containers. To use docker containers, you need to install docker.  Let’s install docker using the following commands.   ═════════════════════════════════════════════════════════════════════════ $ sudo apt install docker.io $ sudo systemctl start docker $ sudo systemctl enable docker  $ sudo groupadd docker $ sudo usermod -aG docker $USER ═════════════════════════════════════════════════════════════════════════  These commands work in Ubuntu 18.04. The best thing about docker is that it can be installed on any machine: Linux, Windows, OSX. So, it doesn’t matter which machine you have if you work inside the docker container all the time!  Docker containers can be considered as small virtual machines. You can create a container for your code, and then everyone will be able to use it and access it. Let’s see how we can create containers that can be used for training a model. We will use the BERT model that we trained in the natural language processing chapter and try to containerize the training code.  First and foremost, you need a file with requirements for your python project. Requirements are contained in a file called requirements.txt. The filename is the'),\n",
       " VectorParams(vector=[-0.119387187063694, -0.041622620075941086, -0.01632530428469181, -0.07507327944040298, 0.09943369776010513, -0.10948852449655533, -0.05330765247344971, 0.06386169791221619, -0.04452385753393173, -0.024127135053277016, 0.029874389991164207, -0.08866733312606812, 0.0024401131086051464, -0.017301136627793312, -0.004086790140718222, 0.021803945302963257, 0.026900403201580048, 0.014249829575419426, -0.007812050636857748, -0.1194617748260498, -0.015348023734986782, 0.09384038299322128, 0.07710814476013184, -0.03126728534698486, -0.07119469344615936, -0.05285489186644554, -0.009625621140003204, -0.007440428249537945, -0.038997408002614975, -0.058683667331933975, 0.1120501160621643, 0.11780118942260742, -0.004028825089335442, 0.04331201687455177, 0.1303669810295105, 0.13289640843868256, -0.043884579092264175, -0.012073619291186333, -0.13463297486305237, 0.028023896738886833, 0.00655741011723876, 0.019793450832366943, -0.0034138357732445, -0.056359343230724335, 0.03796745464205742, -0.09975392371416092, -0.108082614839077, -0.09259091317653656, 0.11176444590091705, -0.0732026994228363, -0.15018638968467712, -0.058583490550518036, -0.05252908915281296, 0.006499805487692356, -0.002517519285902381, 0.02477838657796383, 0.049394410103559494, -0.002958999713882804, -0.0567195750772953, -0.14636333286762238, 0.004923931788653135, 0.003404744900763035, -0.055237676948308945, 0.0029978833626955748, -0.043291427195072174, 0.012023908086121082, -0.08111537247896194, -0.00672077527269721, 0.13378523290157318, -0.024959811940789223, -0.057742394506931305, 0.030662426725029945, 0.014954102225601673, -0.0465938001871109, -0.14122989773750305, 0.0020461606327444315, 0.1555027812719345, 0.025515787303447723, 0.03386807069182396, -0.13819825649261475, -0.0727602019906044, -0.012579786591231823, 0.1132218986749649, -0.03169211372733116, 0.055988773703575134, -0.016920454800128937, 0.029684504494071007, 0.025557199493050575, 0.08761147409677505, -0.10893189907073975, 0.04945523664355278, -0.1263088434934616, 0.02016458287835121, 0.0020128823816776276, 0.08831225335597992, 0.05757470056414604, 0.09398167580366135, 0.03529016301035881, -0.11337427794933319, 0.20485904812812805, -0.09889660030603409, -0.11302802711725235, 0.021600529551506042, 0.03370851278305054, 0.10485177487134933, 0.15693676471710205, 0.057145752012729645, -0.09387298673391342, 0.11476019769906998, -0.06898705661296844, -0.0045150816440582275, -0.06518623977899551, -0.06070229038596153, -0.09369979798793793, 0.011039369739592075, -0.026973864063620567, -0.08243470638990402, -0.0055970423854887486, -0.07421170920133591, 0.07608038932085037, 0.03161418065428734, -0.04173531010746956, 0.054054562002420425, 0.023841548711061478, -0.02947385050356388, -0.0293431393802166, 0.0015769071178510785, 7.660181670846394e-33, 0.02541455067694187, -0.06548004597425461, 0.025556515902280807, -0.008684983476996422, 0.16989630460739136, -0.05536451190710068, 0.09550697356462479, -0.020707787945866585, -0.16391801834106445, -0.02604459784924984, -0.09999972581863403, 0.10343660414218903, -0.20212946832180023, 0.09813090413808823, 0.06026070564985275, -0.07271435856819153, -0.15230299532413483, 0.1083417534828186, 0.05405104532837868, 0.008322593756020069, 0.15735283493995667, 0.024842519313097, -0.08373505622148514, -0.13301344215869904, -0.032988931983709335, -0.035419952124357224, 0.07095947861671448, -0.005515569355338812, -0.033166900277137756, 0.00499073276296258, -0.08082074671983719, -0.023549756035208702, 0.029281867668032646, -0.010385284200310707, -0.01567935012280941, -0.12774157524108887, -0.03485635668039322, 0.035995565354824066, 0.001989334123209119, -0.03589102625846863, 0.07813148945569992, 0.09953326731920242, 0.03413788974285126, -0.16463254392147064, 0.089149110019207, 0.021387051790952682, 0.01376185193657875, 0.00965231005102396, 0.017904940992593765, 0.06445751339197159, 0.060387466102838516, -0.04737066477537155, -0.004909961950033903, 0.06612478196620941, -0.025551635771989822, -0.11459147930145264, 0.09040498733520508, -0.00974089652299881, 0.20186667144298553, -0.09655598551034927, 0.022366205230355263, -0.009839845821261406, 0.03678598999977112, -0.055449239909648895, 0.10845481604337692, 0.012594111263751984, 0.016628770157694817, 0.09374690055847168, 0.06621306389570236, 0.03737248107790947, -0.2270505279302597, 0.02481820248067379, -0.03609886020421982, -0.07259342819452286, 0.169892817735672, -0.12984678149223328, -0.04079971835017204, -0.06676917523145676, -0.05293521285057068, -0.022462964057922363, -0.04919838160276413, 0.05645301565527916, -0.05264705792069435, -0.09497310221195221, -0.03777972608804703, -0.024996943771839142, 0.03339635580778122, 0.007021649274975061, -0.07165110111236572, -0.03444110229611397, -0.04150398075580597, -0.02124839648604393, -0.08055702596902847, 0.04143679887056351, 0.00018576090224087238, -7.730295500769128e-33, -0.0061323330737650394, 0.04722309857606888, -0.01847999356687069, 0.07620453834533691, 0.004600914195179939, -0.008839534595608711, 0.008319689892232418, 0.035002563148736954, 0.007202892564237118, -0.11019866913557053, 0.020468492060899734, -0.020990822464227676, -0.014514799229800701, -0.04990149661898613, 0.07825353741645813, 0.13634976744651794, -0.12054561823606491, 0.05151267349720001, -0.06077088043093681, 0.04027380421757698, -0.17056667804718018, 0.10342101007699966, -0.1513480246067047, 0.0033368172589689493, -0.024948319420218468, 0.08880358189344406, 0.09812330454587936, 0.10902705043554306, -0.0014639785513281822, -0.04771049693226814, -0.015996167436242104, 0.07907259464263916, -0.2602466642856598, 0.1325223445892334, -0.028169333934783936, 0.04028308019042015, 0.0697723999619484, -0.005131133366376162, -0.03790662810206413, 0.11830778419971466, 0.29395464062690735, 0.035738348960876465, -0.1429859697818756, 0.04231257736682892, -0.08561308681964874, -0.03405255451798439, -0.03746088966727257, 0.04142019897699356, -0.014054265804588795, -0.1043347418308258, 0.08533412963151932, -0.08954517543315887, -0.05470670014619827, 0.04958367720246315, -0.06905359774827957, 0.03484092652797699, 0.15412269532680511, 0.1160382479429245, -0.08938515186309814, 0.04004734754562378, -0.05393656715750694, -0.07236307859420776, 0.03721880540251732, -0.12802578508853912, -0.015288290567696095, -0.01852349191904068, -0.17287632822990417, 0.12746381759643555, -0.01290698442608118, 0.08326157927513123, -0.11393196880817413, 0.12283527851104736, 0.06408270448446274, -0.10206331312656403, 0.010046056471765041, 0.11611365526914597, -0.032399971038103104, -0.04244896024465561, 0.048122938722372055, -0.020372940227389336, -0.09152802079916, -0.05213205888867378, 0.14061835408210754, 0.11413254588842392, -0.010399237275123596, 0.0918930321931839, 0.12471020221710205, 0.02488723397254944, 0.10256744921207428, -0.037356361746788025, 0.03129097446799278, 0.02283334545791149, 0.04608345404267311, 0.12391874194145203, 0.09449158608913422, -9.996204397566544e-08, 0.005412273108959198, -0.04394325986504555, -0.04797827824950218, 0.0605621375143528, 0.06729433685541153, 0.11533284187316895, -0.02647213637828827, 0.005707291420549154, -0.04643351584672928, -0.00541355786845088, 0.13501116633415222, 0.036781903356313705, -0.15278255939483643, 0.07231979072093964, -0.06270606815814972, 0.25026604533195496, -0.004257450345903635, 0.12170930951833725, -0.030807992443442345, -0.06691231578588486, 0.009513573721051216, 0.0056812958791852, 0.05473549664020538, -0.010030471719801426, -0.07933633774518967, -0.07852471619844437, 0.05808383598923683, 0.02927408181130886, -0.06760352849960327, 0.027865175157785416, 0.02086859755218029, -0.06370843201875687, -0.1322101652622223, 0.04391780495643616, 0.23410561680793762, 0.04307757318019867, -0.03209155797958374, -0.034753113985061646, 0.1448982208967209, -0.024851778522133827, -0.024535510689020157, 0.13590848445892334, -0.0852990448474884, -0.0628608763217926, 0.035866908729076385, -0.00651553925126791, -0.008181263692677021, -0.13676410913467407, -0.10476008802652359, 0.07830005884170532, -0.00959425512701273, 0.013307386077940464, -0.07690079510211945, 0.05967826768755913, 0.020852329209446907, -0.007305103354156017, -0.09808933734893799, -0.06980228424072266, -0.10956580936908722, -0.04318828880786896, 0.04450712725520134, 0.019186202436685562, 0.17247840762138367, 0.08481863886117935], metadata={'source': 'AAAMLP-569to.pdf', 'page': 283}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 284 standard. The file consists of all the python libraries that you are using in your project. That is the python libraries that can be downloaded via PyPI (pip). For training our BERT model to detect positive/negative sentiment, we use torch, transformers, tqdm, scikit-learn, pandas and numpy. Let’s write them in requirements.txt. You can just write the names, or you can also include the version. It’s always the best to include version, and that’s what you should do. When you include version, it makes sure that others have the same version as yours and not the latest version as the latest version might change something and if that’s the case, model won’t be trained the same way as was done by you.   The following snippet shows requirements.txt.  ═════════════════════════════════════════════════════════════════════════ # requirements.txt pandas==1.0.4 scikit-learn==0.22.1 torch==1.5.0 transformers==2.11.0 ═════════════════════════════════════════════════════════════════════════  Now, we will create a docker file called Dockerfile. No extension. There are several elements to Dockerfile. Let’s take a look.  ═════════════════════════════════════════════════════════════════════════ # Dockerfile # First of all, we include where we are getting the image # from. Image can be thought of as an operating system. # You can do \"FROM ubuntu:18.04\" # this will start from a clean ubuntu 18.04 image. # All images are downloaded from dockerhub # Here are we grabbing image from nvidia\\'s repo # they created a docker image using ubuntu 18.04 # and installed cuda 10.1 and cudnn7 in it. Thus, we don\\'t have to  # install it. Makes our life easy. FROM nvidia/cuda:10.1-cudnn7-runtime-ubuntu18.04  # this is the same apt-get command that you are used to # except the fact that, we have -y argument. Its because # when we build this container, we cannot press Y when asked for RUN apt-get update && apt-get install -y \\\\     git \\\\     curl \\\\     ca-certificates \\\\     python3 \\\\'),\n",
       " VectorParams(vector=[-0.07188652455806732, -0.02838916704058647, -0.01163279265165329, -0.12995727360248566, 0.008273346349596977, -0.1868027001619339, 0.04782416298985481, 0.13320079445838928, -0.13308408856391907, 0.057337112724781036, 0.004044461064040661, -0.1648777574300766, 0.05215132609009743, -0.05906452611088753, 0.05831025540828705, 0.048768412321805954, -0.03600948303937912, 0.09755424410104752, -0.0875151976943016, -0.1003933846950531, -0.019291138276457787, 0.111811563372612, 0.08933678269386292, 0.020323751494288445, -0.01548665203154087, -0.06235240399837494, 0.019762802869081497, -0.1181047335267067, -0.1104247123003006, -0.030138567090034485, 0.0643315538764, -0.004125233273953199, 0.05968857556581497, -0.0751996636390686, 0.1388322412967682, 0.18262061476707458, 0.04044561833143234, 0.009883544407784939, -0.038777630776166916, -0.10088197141885757, 0.09241771697998047, 0.06304924190044403, -0.04966855049133301, 0.0010765868937596679, -0.19947506487369537, 0.018007153645157814, -0.07345248013734818, -0.10601984709501266, 0.10495384782552719, 0.08008666336536407, -0.14483149349689484, 0.06746440380811691, -0.020802147686481476, -0.010807515121996403, 0.03209909796714783, 0.16179339587688446, 0.0013193364720791578, 0.1258484572172165, 0.06061313673853874, -0.04859784245491028, -0.009404032491147518, 0.13759085536003113, 0.021873019635677338, 0.006550047546625137, 0.045837949961423874, -0.09142259508371353, -0.07469195127487183, -0.017014048993587494, 0.14013220369815826, 0.03888349607586861, -0.004324998706579208, -0.014487890526652336, -0.10085081309080124, -0.055735912173986435, 0.010631225071847439, -0.14562951028347015, 0.0680520087480545, 0.17513859272003174, -0.15869151055812836, -0.06812684237957001, -0.12629081308841705, 0.04290269315242767, 0.0220947228372097, 0.001927408273331821, -0.1635722815990448, -0.014590220525860786, 0.0030723693780601025, 0.02256806753575802, 0.05558788403868675, -0.15655799210071564, 0.21216121315956116, -0.23028136789798737, 0.03448968008160591, -0.09678290039300919, 0.12972310185432434, 0.07913205027580261, 0.04825831204652786, 0.14831401407718658, -0.10759790986776352, 0.15241271257400513, -0.17646433413028717, -0.2009667009115219, 0.002301395870745182, 0.02692079171538353, 0.11513491719961166, 0.06565336138010025, 0.03651580587029457, -0.1484079360961914, -0.04580065608024597, -0.08045201003551483, -0.003803856438025832, -0.13767191767692566, -0.01226101629436016, -0.0001576609502080828, 0.05287877097725868, -0.019517455250024796, -0.1329142302274704, -0.07890909165143967, -0.013307929039001465, 0.14229756593704224, 0.14113105833530426, -0.018050653859972954, 0.20372261106967926, -0.002087072702124715, 0.04141400381922722, -0.040267184376716614, -0.0018036417895928025, 1.0293963456572102e-32, -0.0337458960711956, -0.0650821104645729, 0.029549475759267807, 0.09893167018890381, 0.163529634475708, -0.05583349987864494, 0.09251350164413452, 0.09326236695051193, -0.15348969399929047, -0.03160138428211212, -0.027714841067790985, 0.12070810049772263, -0.07698628306388855, 0.025695621967315674, 0.04679723456501961, -0.03291005641222, -0.15591742098331451, 0.028576528653502464, 0.009855355136096478, -0.013139763846993446, 0.15821261703968048, 0.01435489859431982, -0.0738869160413742, 0.003940709866583347, -0.028226681053638458, -0.15371401607990265, 0.1287662237882614, -0.008291687816381454, 0.05410192906856537, 0.04067767783999443, -0.0402032844722271, 0.007025867700576782, -0.009638291783630848, 0.08023260533809662, -0.13244925439357758, -0.04713430255651474, -0.11780045181512833, -0.038781002163887024, -0.12174569815397263, 0.02609916403889656, 0.06401626765727997, 0.042383380234241486, 0.0388556644320488, -0.05176925286650658, 0.07797875255346298, -0.12079177051782608, 0.06287597864866257, 0.007194878533482552, 0.00827394612133503, 0.15174701809883118, 0.07215626537799835, -0.1546631157398224, 0.041542429476976395, -0.010739224031567574, -0.0883820429444313, -0.011590106412768364, -0.06326204538345337, -0.12537255883216858, 0.1384820193052292, -0.11184334009885788, -0.04037533700466156, 0.0385119765996933, 0.042507071048021317, 0.1635156273841858, 0.017726851627230644, -0.08492139726877213, 0.028220953419804573, 0.10144799202680588, 0.18552879989147186, 0.04202548786997795, -0.08413869142532349, -0.027056116610765457, -0.0015993744600564241, 0.0729592815041542, -0.06058470532298088, 0.03609815239906311, 0.046416644006967545, -0.08898190408945084, -0.14223580062389374, -0.02342580445110798, 0.003066894831135869, 0.019677741453051567, -0.07216539978981018, -0.1157648041844368, 0.024773787707090378, -0.019244754686951637, -0.019851762801408768, 0.03446139022707939, -0.07784447073936462, -0.0025040563195943832, 0.021564386785030365, 0.011055526323616505, -0.09603814780712128, -0.0066546304151415825, -0.09881173819303513, -1.3766132057875251e-32, 0.10142875462770462, -0.028676990419626236, 0.0032581540290266275, -0.047829750925302505, 0.06942066550254822, 0.048291295766830444, 0.09665568917989731, -0.06213059648871422, 0.05824187770485878, -0.1644486039876938, -0.16861629486083984, 0.08601515740156174, 0.1374567449092865, 0.022182481363415718, -0.012644153088331223, 0.19602172076702118, -0.11456779390573502, -0.04127831012010574, 0.002149679698050022, -0.026558784767985344, -0.12707573175430298, 0.16153967380523682, -0.08885420113801956, 0.07340143620967865, -0.09804720431566238, -0.07178661972284317, 0.00010410901450086385, 0.06804068386554718, -0.03133928030729294, 0.07372613996267319, -0.013667403720319271, 0.048206429928541183, -0.23641151189804077, -0.0014068271266296506, -0.0763164535164833, -0.0025826056953519583, -0.05069141834974289, 0.10626961290836334, -0.17499622702598572, -0.0020155785605311394, 0.16484612226486206, -0.018411213532090187, -0.0864444449543953, -0.11650625616312027, -0.018296584486961365, -0.016812123358249664, 0.059525903314352036, -0.11901550740003586, -0.13639092445373535, -0.038902830332517624, 0.11344850063323975, -0.12474361062049866, 0.030799685046076775, -0.005008267238736153, -0.014348321594297886, 0.12036445736885071, 0.22623701393604279, 0.10514252632856369, -0.04860350862145424, 0.014726714231073856, -0.016370777040719986, 0.005618188995867968, 0.23500710725784302, -0.012475271709263325, -0.08550063520669937, -0.0163858775049448, -0.16572308540344238, 0.013908692635595798, -0.1439347267150879, 0.04393193498253822, -0.06392236799001694, 0.00786640215665102, 0.004396218340843916, -0.05707831680774689, 0.043230243027210236, 0.08505391329526901, 0.011190295219421387, -0.04239353537559509, -0.05153669789433479, 0.012620925903320312, -0.13978669047355652, 0.05935891717672348, -0.04942081496119499, 0.01194407045841217, -0.12184063345193863, -0.11480913311243057, 0.0579008124768734, 0.02102138288319111, 0.05662745609879494, -0.06303759664297104, 0.06589771062135696, -0.012938786298036575, 0.036038193851709366, -0.027354294434189796, 0.08732681721448898, -1.0059367383519202e-07, 0.05482728034257889, 0.046766191720962524, -0.07835466414690018, 0.15190455317497253, 0.14659178256988525, 0.02213682234287262, 0.034336015582084656, 0.09694330394268036, -0.03255291283130646, -0.016140958294272423, -0.08908801525831223, 0.034174565225839615, -0.14019392430782318, 0.0866914913058281, -0.12004292011260986, 0.16287380456924438, 0.03394404426217079, 0.054584477096796036, -0.07914304733276367, -0.09057823568582535, 0.019851433113217354, -0.006713752169162035, 0.04151822626590729, 0.09285008162260056, -0.04344905912876129, 0.005140568129718304, 0.045465029776096344, -0.06564506143331528, -0.08276738226413727, 0.053038813173770905, 0.03400382027029991, -0.06678623706102371, -0.0797039195895195, 0.06372223794460297, 0.20730304718017578, -0.08317197114229202, -0.05624235048890114, 0.02672429010272026, 0.045326653867959976, -0.0022218767553567886, -0.11892657727003098, 0.05182037875056267, 0.135085791349411, -0.08492951095104218, 0.02243294008076191, -0.09148037433624268, -0.11978704482316971, -0.030468864366412163, -0.06011470407247543, 0.04576028138399124, 0.04605000466108322, -0.03419481962919235, -0.08128964900970459, 0.044289227575063705, 0.24197329580783844, 0.056718356907367706, -0.02888423390686512, -0.020438048988580704, 0.02331061288714409, -0.03365498408675194, 0.0867949053645134, 0.16098587214946747, 0.13046708703041077, 0.0885273665189743], metadata={'source': 'AAAMLP-569to.pdf', 'page': 284}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 285     python3-pip \\\\     sudo \\\\     && rm -rf /var/lib/apt/lists/*  # We add a new user called \"abhishek\" # this can be anything. Anything you want it # to be. Usually, we don\\'t use our own name, # you can use \"user\" or \"ubuntu\" RUN useradd -m abhishek  # make our user own its own home directory RUN chown -R abhishek:abhishek /home/abhishek/  # copy all files from this direrctory to a  # directory called app inside the home of abhishek # and abhishek owns it. COPY --chown=abhishek *.* /home/abhishek/app/  # change to user abhishek USER abhishek RUN mkdir /home/abhishek/data/  # Now we install all the requirements # after moving to the app directory # PLEASE NOTE that ubuntu 18.04 image # has python 3.6.9 and not python 3.7.6 # you can also install conda python here and use that # however, to simplify it, I will be using python 3.6.9 # inside the docker container!!!! RUN cd /home/abhishek/app/ && pip3 install -r requirements.txt # install mkl. its needed for transformers RUN pip3 install mkl  # when we log into the docker container, # we will go inside this directory automatically WORKDIR /home/abhishek/app ═════════════════════════════════════════════════════════════════════════  Once we have created the docker file, we need to build it. Building the docker container is a very simple command.  ═════════════════════════════════════════════════════════════════════════  docker build -f Dockerfile -t bert:train .  ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[-0.0817558765411377, 0.01672256365418434, -0.012780744582414627, -0.011088993400335312, 0.05687491595745087, -0.051133088767528534, 0.004796442110091448, 0.05694412812590599, -0.04373893514275551, 0.020113695412874222, -0.03765137121081352, -0.13736508786678314, 0.04941883310675621, -0.0344339981675148, 0.05435902625322342, -0.026112345978617668, 0.003928348422050476, 0.05570802092552185, -0.05038077011704445, -0.07713500410318375, -0.07560446113348007, 0.1157345101237297, 0.0449032224714756, -0.04277640953660011, -0.08432506769895554, -0.03704746067523956, -0.018251964822411537, -0.11373081058263779, -0.054461024701595306, -0.072884202003479, 0.11108385771512985, 0.09875236451625824, 0.016150610521435738, -0.03826935589313507, 0.1382828950881958, 0.20407363772392273, -0.02344917505979538, 0.0048103975132107735, -0.030563578009605408, -0.044720884412527084, 0.07996906340122223, -0.00947481207549572, -0.03898134455084801, -0.028631558641791344, -0.01683608442544937, -0.05276264622807503, -0.09856525808572769, -0.1676882952451706, 0.051648225635290146, -0.0715813934803009, -0.11647871881723404, -0.002012169687077403, 0.010805371217429638, 0.041004352271556854, -0.059675756841897964, 0.1010674461722374, 0.03780755773186684, 0.09925274550914764, 0.006823995150625706, -0.05026920139789581, -0.024592526257038116, 0.013357403688132763, 0.01531829684972763, -0.04650444537401199, -0.010935584083199501, -0.049388810992240906, -0.05973946303129196, -0.04072198644280434, 0.1457698792219162, 0.026149574667215347, -0.002980679040774703, 0.012433615513145924, -0.026067228987812996, -0.14245405793190002, -0.05338294059038162, -0.05742764100432396, 0.1377633512020111, 0.025560088455677032, -0.07370249927043915, 0.01922951638698578, -0.10523699969053268, 0.015183812007308006, 0.08917135000228882, -0.0721171423792839, -0.03748331964015961, 0.06729483604431152, 0.10112515091896057, -0.017292387783527374, 0.10450327396392822, -0.13646015524864197, 0.08494557440280914, -0.1205810084939003, -0.01579345390200615, 0.05302129313349724, 0.15220144391059875, 0.0076746391132473946, 0.017490066587924957, 0.08469132333993912, -0.1004691794514656, 0.1498866230249405, -0.009436791762709618, -0.04131956025958061, 0.04087142273783684, 0.06801030784845352, 0.08343090116977692, 0.11890784651041031, -0.011672161519527435, -0.08325935155153275, 0.02654930017888546, -0.10758160799741745, 0.005291471257805824, -0.10142877697944641, -0.023249849677085876, 0.0740545317530632, -0.038910117000341415, 0.10870727896690369, -0.12990616261959076, -0.07959988713264465, -0.05115480720996857, 0.15856939554214478, 0.09938492625951767, -0.07507334649562836, 0.10110777616500854, -0.0064554596319794655, -0.1433151215314865, -0.07492145895957947, 0.06624065339565277, 1.3321376423401946e-32, -0.002261368790641427, -0.1844492256641388, 0.017905868589878082, -0.09579960256814957, 0.23299811780452728, -0.024012528359889984, 0.08183308690786362, 0.05543623864650726, -0.023784635588526726, 0.013753636740148067, -0.15549764037132263, 0.05495966970920563, -0.09521762281656265, 0.07383661717176437, 0.020602673292160034, -0.0678367167711258, -0.17060238122940063, 0.08881591260433197, -0.00014596915571019053, 0.04521309584379196, 0.20087793469429016, 0.013134405948221684, -0.12419554591178894, -0.19251391291618347, 0.06523961573839188, -0.03349030390381813, 0.09395495802164078, -0.023607851937413216, 0.005730342119932175, 0.06919918209314346, -0.05677029862999916, 0.013420706614851952, -0.05443669855594635, 0.050783101469278336, 0.011765170842409134, -0.11237137019634247, 0.01932055689394474, 0.06668347865343094, -0.05226405709981918, 0.009761926718056202, 0.05955535173416138, 0.012341280467808247, -0.01515616662800312, -0.02824700064957142, 0.10045052319765091, -0.13423769176006317, 0.044267818331718445, -0.011273769661784172, -0.05028996244072914, 0.11583749204874039, 0.09500869363546371, -0.06754928827285767, -0.08091163635253906, -0.047177754342556, -0.0673961341381073, -0.10806234925985336, 0.008026872761547565, 0.023262720555067062, 0.11699368059635162, -0.07299461215734482, -0.056770868599414825, -0.02139056846499443, 0.04002527520060539, 0.06885824352502823, 0.06791988760232925, 0.013754834420979023, -0.004567415453493595, 0.09597361087799072, 0.0712224692106247, 0.08723326772451401, -0.12682181596755981, -0.018331291154026985, 0.08108887076377869, 0.0104916887357831, 0.14545148611068726, -0.01679726131260395, -0.01840035431087017, -0.04674042761325836, -0.10840477794408798, 0.029265958815813065, 0.0916876420378685, 0.0974494144320488, -0.10515980422496796, -0.03528812900185585, 0.018096933141350746, -0.020141534507274628, 0.0547868013381958, 0.01133571658283472, -0.07947945594787598, 0.03395490720868111, -0.04138180613517761, 0.025353221222758293, -0.10126049816608429, -0.0061494228430092335, -0.0642995536327362, -1.38384278991867e-32, 0.11869063973426819, 0.05066445469856262, -0.04397115111351013, -0.010037418454885483, -0.005584336817264557, -0.06041530892252922, 0.1168360784649849, -0.0029369357507675886, 0.013385646976530552, -0.09920614957809448, -0.10649586468935013, 0.026866786181926727, 0.02409680373966694, 0.09140578657388687, -0.054294586181640625, 0.12744039297103882, -0.12793543934822083, 0.054595958441495895, -0.10558266937732697, -0.007198865059763193, -0.04773891344666481, -0.02028343640267849, -0.11604244261980057, 0.07693546265363693, -0.07631610333919525, 0.01831723190844059, 0.15501585602760315, 0.05334281921386719, -0.012786493636667728, 0.04126491770148277, -0.014974609948694706, 0.029527908191084862, -0.18732959032058716, 0.19591975212097168, -0.037779368460178375, 0.06910759210586548, 0.047231465578079224, 0.08878680318593979, -0.11753492057323456, 0.0055328854359686375, 0.1724281907081604, -0.037998080253601074, -0.09867232292890549, 0.02411622740328312, -0.02237958461046219, -0.046012017875909805, -0.011031672358512878, -0.021213948726654053, -0.07182628661394119, -0.0616690032184124, 0.05920500308275223, -0.058154623955488205, -0.10139547288417816, 0.007420673500746489, -0.047283660620450974, -0.025232259184122086, 0.16921347379684448, 0.06862352043390274, -0.17124046385288239, 0.027333516627550125, 0.07625938206911087, -0.0006662122323177755, 0.09559556841850281, -0.03345812112092972, 0.009938942268490791, -0.0558011569082737, -0.2134200930595398, 0.11291566491127014, -0.08197947591543198, 0.05882497876882553, -0.020429132506251335, 0.0727943554520607, 0.0029895161278545856, 0.0033823703415691853, -0.022563129663467407, 0.10104150325059891, -0.08683041483163834, -0.13537359237670898, 0.04316115751862526, 0.027171622961759567, -0.11155545711517334, -0.07227296382188797, 0.08142951875925064, -0.025031154975295067, -0.05064334347844124, 0.07675505429506302, 0.12737035751342773, 0.04049502685666084, 0.12645721435546875, -0.11872247606515884, 0.07616132497787476, -0.0637504905462265, -0.016505585983395576, 0.08855267614126205, 0.04664798453450203, -9.993951266551448e-08, 0.03110157698392868, -0.05014955997467041, -0.04320604354143143, 0.17272724211215973, 0.05753900110721588, 0.03821038827300072, -0.02167118526995182, 0.07870087027549744, -0.07123927026987076, -0.07611775398254395, -0.03893734887242317, -0.018566004931926727, -0.1747933328151703, 0.09531991928815842, 0.04368868097662926, 0.17725394666194916, 0.007052172441035509, 0.053621236234903336, 0.029585838317871094, -0.16163435578346252, -0.00585041381418705, -0.003441407112404704, 0.09587525576353073, 0.005854295566678047, -0.1260206550359726, -0.04374704882502556, 0.054877717047929764, 0.07390226423740387, -0.018131999298930168, -0.006998984143137932, 0.04198692739009857, -0.09727039933204651, -0.14630228281021118, 0.05659559369087219, 0.13023942708969116, 0.002023233100771904, 0.023005129769444466, -0.0888819769024849, 0.06892614811658859, -0.01181131973862648, -0.05557171255350113, 0.0491039901971817, 0.06181808561086655, -0.08728519082069397, 0.003884656820446253, 0.049436233937740326, -0.026448050513863564, -0.07276139408349991, -0.03961007297039032, 0.017258411273360252, 0.08020275831222534, -0.029526973143219948, -0.07012259215116501, 0.02994237095117569, 0.09657325595617294, 0.03231886029243469, -0.14155854284763336, -0.12380541115999222, -0.08907913416624069, -0.01123519241809845, -0.01967543363571167, 0.064305879175663, 0.1444554328918457, 0.08433010429143906], metadata={'source': 'AAAMLP-569to.pdf', 'page': 285}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 286  This command builds a container from the provided Dockerfile. The name of the docker container is bert:train. This produces the following output:  ═════════════════════════════════════════════════════════════════════════ ❯ docker build -f Dockerfile -t bert:train . Sending build context to Docker daemon  19.97kB Step 1/7 : FROM nvidia/cuda:10.1-cudnn7-ubuntu18.04  ---> 3b55548ae91f Step 2/7 : RUN apt-get update && apt-get install -y   git  curl     ca-certificates     python3 python3-pip     sudo     && rm -rf /var/lib/apt/lists/* . . . . Removing intermediate container 8f6975dd08ba  ---> d1802ac9f1b4 Step 7/7 : WORKDIR /home/abhishek/app  ---> Running in 257ff09502ed Removing intermediate container 257ff09502ed  ---> e5f6eb4cddd7 Successfully built e5f6eb4cddd7 Successfully tagged bert:train ═════════════════════════════════════════════════════════════════════════  Please note that I have removed many lines from the output. Now, you can log into the container using the following command.  ═════════════════════════════════════════════════════════════════════════  $ docker run -ti bert:train /bin/bash  ═════════════════════════════════════════════════════════════════════════  You need to remember that whatever you do in this shell will be lost once you exit the shell. And you can run the training inside the docker container using:  ═════════════════════════════════════════════════════════════════════════  $ docker run -ti bert:train python3 train.py  ═════════════════════════════════════════════════════════════════════════  Which gives the following output:'),\n",
       " VectorParams(vector=[-0.11892040073871613, -0.05729932337999344, -0.054549142718315125, -0.003947083838284016, 0.000142611563205719, -0.09036921709775925, -0.03954315930604935, 0.13503974676132202, -0.0619967021048069, -0.02586064115166664, 0.15557271242141724, -0.043469078838825226, 0.09831929206848145, -0.014425782486796379, -0.013054292649030685, 0.08245709538459778, -0.13632342219352722, 0.039270784705877304, -0.13816659152507782, 0.05649036169052124, 0.11424677073955536, 0.1953984797000885, 0.01729641854763031, -0.026612188667058945, 0.0716281458735466, -0.039370857179164886, -0.03009750507771969, -0.000380638986825943, -0.19009879231452942, -0.007825994864106178, 0.04580104723572731, 0.20414192974567413, 0.013816563412547112, 0.006567288190126419, 0.241130530834198, 0.1312543749809265, -0.06358443945646286, -0.06388884037733078, 0.012039165943861008, 0.039089690893888474, -0.012582567520439625, 0.016024397686123848, -0.04062635824084282, -0.024194080382585526, -0.03657713159918785, -0.09111641347408295, -0.052797023206949234, -0.07830646634101868, -0.0632229745388031, -0.10421596467494965, -0.20190595090389252, -0.09466050565242767, -0.09648237377405167, 0.13980716466903687, 0.0169939324259758, -0.04121476039290428, -0.03634502738714218, 0.08292941749095917, -0.07869960367679596, -0.13507971167564392, -0.12941783666610718, 0.056249938905239105, 0.0058919587172567844, -0.07626250386238098, -0.09390173852443695, -0.030638139694929123, -0.0818917378783226, 0.09844960272312164, 0.09931880235671997, 0.03390757367014885, -0.07916462421417236, 0.10810449719429016, -0.09784412384033203, 0.1983242928981781, -0.04961736872792244, 0.025478597730398178, 0.19179299473762512, 0.13789385557174683, 0.08528709411621094, -0.26650097966194153, -0.06870684027671814, -0.09744855761528015, 0.06503569334745407, -0.006416875869035721, 0.08406119793653488, -0.04705985635519028, 0.016135089099407196, -0.0065357014536857605, 0.053261466324329376, -0.08844241499900818, -0.03426619619131088, -0.2321486622095108, 0.03590185195207596, -0.05429813638329506, 0.046985141932964325, -0.0076339393854141235, 0.0502164326608181, 0.22761857509613037, -0.013372044079005718, 0.11061917990446091, -0.03433016687631607, -0.07128746807575226, 0.06142130494117737, 0.03644246235489845, -0.02865060418844223, 0.1520765870809555, 0.03357075899839401, -0.026112891733646393, 0.12424574792385101, -0.2236378937959671, -0.11462190002202988, -0.06818641722202301, 0.038578812032938004, -0.16477066278457642, 0.07766975462436676, -0.0461370013654232, 0.016148481518030167, -0.02928822673857212, 0.01762709952890873, 0.2352238893508911, -0.03431963920593262, -0.022597745060920715, 0.08826932311058044, 0.047999076545238495, -0.12448073923587799, -0.08556274324655533, -0.023155340924859047, 4.247985321954259e-33, -0.0627032145857811, -0.13589376211166382, -0.03672930598258972, -0.037127215415239334, 0.172846719622612, -0.11044910550117493, 0.0961260125041008, 0.06691724061965942, -0.11060895025730133, -0.0510784387588501, -0.10873155295848846, 0.052088819444179535, -0.05555722117424011, 0.029732340946793556, -0.004573815502226353, -0.0326843298971653, -0.042202629148960114, 0.062226902693510056, -0.018887745216488838, -0.05090890824794769, 0.21601183712482452, 0.11821509897708893, -0.07267720252275467, -0.060760125517845154, -0.13860608637332916, 0.040338870137929916, 0.16104987263679504, -0.09741345047950745, 0.07564134895801544, 0.0359802171587944, -0.042464472353458405, -0.04548356682062149, 0.02106008119881153, 0.06875163316726685, -0.03691474720835686, 0.00027714669704437256, 0.07497207075357437, -0.07001970708370209, -0.08380922675132751, -0.14372599124908447, -0.06010214984416962, 0.012080670334398746, 0.01608804427087307, -0.011351021006703377, 0.008761333301663399, -0.05917453020811081, -0.135918989777565, 0.016860077157616615, -0.023304730653762817, 0.02291841432452202, 0.07326292991638184, -0.0218526441603899, 0.042170606553554535, 0.029392477124929428, -0.10310690104961395, 0.1180458813905716, -0.028889209032058716, 0.08801961690187454, 0.11434447020292282, -0.0027194302529096603, 0.04734677076339722, 0.1579582393169403, 0.043134383857250214, 0.10938891023397446, 0.05218963697552681, -0.04149162024259567, 0.042691681534051895, -0.016347868368029594, 0.06538418680429459, 0.07281377166509628, -0.09304380416870117, -0.07446639239788055, 0.08764258772134781, -0.013920141384005547, 0.11530129611492157, -0.17387759685516357, 0.018067527562379837, -0.10138153284788132, -0.18758559226989746, -0.12170763313770294, -0.058004409074783325, -0.02771357260644436, -0.09141522645950317, -0.16318030655384064, -0.07055920362472534, -0.07616310566663742, 0.09467507898807526, -0.14563237130641937, -0.061124496161937714, -0.10789649188518524, 0.033790603280067444, -0.009180216118693352, -0.16992802917957306, 0.021040450781583786, 0.005630210041999817, -6.247502682070908e-33, 0.15986745059490204, 0.04556332528591156, 0.004650575574487448, -0.024472687393426895, 0.003983637783676386, 0.030181242153048515, 0.06446576118469238, 0.05429833382368088, 0.001975804567337036, -0.10761483013629913, -0.03971800208091736, -0.014487220905721188, 0.04129738360643387, -0.14467719197273254, 0.11542844772338867, 0.08059804141521454, -0.06675616651773453, -0.03670068085193634, -0.044644080102443695, 0.10504978895187378, -0.08013057708740234, 0.07175455242395401, -0.1455315798521042, 0.16176103055477142, -0.0696367621421814, 0.05806346610188484, -0.034604839980602264, 0.1055455356836319, 0.12366309762001038, 0.04379141703248024, -0.0996573269367218, 0.09724937379360199, -0.25628381967544556, 0.013527173548936844, -0.1498396098613739, -0.029582438990473747, -0.004113560076802969, -0.00802943017333746, -0.03505348414182663, 0.004413846880197525, 0.09722208976745605, 0.11335022002458572, -0.1175747960805893, 0.05382461100816727, 0.04593701660633087, -0.03103780373930931, 0.018664460629224777, 0.01783585548400879, 0.03794220834970474, -0.1348414421081543, 0.11534133553504944, -0.10730858147144318, -0.09660576283931732, 0.040231481194496155, -0.010214912705123425, 0.14124390482902527, 0.11047383397817612, -0.09635655581951141, -0.12267828732728958, -0.07108504325151443, -0.025933662429451942, 0.021174997091293335, -0.043599165976047516, -0.11925631761550903, 0.05060933530330658, -0.004553600214421749, -0.1974319964647293, 0.015893245115876198, 0.05055892467498779, -0.07214150577783585, -0.16383017599582672, 0.13897523283958435, 0.08104321360588074, -0.021247966215014458, 0.07131217420101166, 0.18292725086212158, -0.09224602580070496, -0.03200719878077507, -0.05042556673288345, 0.05817826837301254, -0.14380384981632233, -0.006048817187547684, 0.07149607688188553, 0.06652332097291946, 0.0458470843732357, 0.01401907205581665, 0.004647611640393734, 0.20745804905891418, 0.06149712949991226, -0.10074439644813538, 0.08419764786958694, 0.018359538167715073, 0.14076218008995056, 0.18026025593280792, 0.08852797746658325, -1.0034780473233695e-07, -0.0515265055000782, 0.0677548199892044, -0.07243707776069641, 0.04821760579943657, 0.0833912193775177, 0.05670397728681564, -0.06846605241298676, 0.059876155108213425, 0.055428922176361084, 0.04113629087805748, -0.04143089801073074, 0.04890510439872742, -0.21354427933692932, 0.02850821055471897, -0.18568992614746094, 0.09975366294384003, -0.0022862860932946205, 0.10632343590259552, -0.0396338552236557, 0.06144310161471367, 0.08757322281599045, 0.031835366040468216, -0.07083135843276978, 0.057329870760440826, 0.0358864888548851, -0.04955486208200455, -0.028419513255357742, 0.049903735518455505, -0.1910993903875351, -0.013497136533260345, -0.02281525731086731, 0.03781118616461754, -0.06773176044225693, -0.08875523507595062, 0.11204023659229279, 0.18836218118667603, 0.106997549533844, -0.03487881273031235, -0.05827464163303375, 0.09004171192646027, 0.0049585942178964615, 0.027904462069272995, -0.014956419356167316, -0.020961152389645576, 0.14640817046165466, -0.08948353677988052, -0.10092782974243164, 0.042673259973526, 0.0485704243183136, -0.013077188283205032, 0.008168332278728485, 0.02759518474340439, -0.1366381049156189, 0.022665422409772873, 0.01811540126800537, 0.05890047550201416, -0.011249345727264881, -0.028422566130757332, -0.10436467826366425, -0.08088769018650055, 0.1058962345123291, 0.012678220868110657, 0.14146190881729126, 0.16297641396522522], metadata={'source': 'AAAMLP-569to.pdf', 'page': 286}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 287  ═════════════════════════════════════════════════════════════════════════ Traceback (most recent call last):   File \"train.py\", line 2, in <module>     import config   File \"/home/abhishek/app/config.py\", line 28, in <module>     do_lower_case=True   File \"/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\", line 393, in from_pretrained     return cls._from_pretrained(*inputs, **kwargs)   File \"/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\", line 496, in _from_pretrained     list(cls.vocab_files_names.values()), OSError: Model name \\'../input/bert_base_uncased/\\' was not found in tokenizers model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). We assumed \\'../input/bert_base_uncased/\\' was a path, a model identifier, or url to a directory containing vocabulary files named [\\'vocab.txt\\'] but couldn\\'t find such vocabulary files at this path or url. ═════════════════════════════════════════════════════════════════════════  Oops, it’s an error!   And why would I print an error in a book?   Because it’s very important to understand this error. This error says that the code was unable to find the directory “../input/bert_base_cased”. Why does this happen?  We were able to train without docker, and we can see that the directory and all the files exist. It happens because docker is like a virtual machine! It has its own filesystem and the files from your local machine are not shared to the docker container. If you want to use a path from your local machine and want to modify it too, you would need to mount it to the docker container when running it. When we look at this folder path, we know that it is one level up in a folder called input. Let’s change the config.py file a bit!'),\n",
       " VectorParams(vector=[-0.12650161981582642, -0.049659617245197296, -0.003521908074617386, 0.07316914200782776, 0.02500850521028042, -0.11000526696443558, -0.04192271828651428, 0.16840247809886932, -0.07470330595970154, -0.032410986721515656, -0.019805585965514183, -0.04839639738202095, 0.011002589948475361, 0.039599258452653885, -0.00841810554265976, -0.013624856248497963, -0.04902977868914604, 0.059787947684526443, -0.1680430918931961, -0.02662971056997776, 0.0598355308175087, 0.14246656000614166, 0.09588328003883362, 0.03590550646185875, -0.027294691652059555, -0.04757789894938469, 0.019843656569719315, -0.1126418262720108, -0.07099005579948425, 0.027842609211802483, 0.08662410080432892, 0.04103921726346016, 0.01640365459024906, 0.00888675544410944, 0.29153627157211304, 0.14860618114471436, -0.007532653398811817, -0.06387700885534286, -0.06879162788391113, -0.04256296902894974, 0.13523639738559723, 0.014582114294171333, -0.06940573453903198, -0.020923340693116188, 0.019149821251630783, -0.047726280987262726, 0.0028921307530254126, -0.13287536799907684, 0.10569547861814499, -0.019405225291848183, -0.15855653584003448, 0.04578092321753502, -0.05683138221502304, 0.07274076342582703, -0.0754336342215538, 0.09729001671075821, 0.0928598940372467, -0.05057390034198761, 0.006994655821472406, -0.1444021314382553, -0.0453975684940815, -0.029369143769145012, -0.02980782464146614, -0.01845015026628971, -0.07962913066148758, -0.08547722548246384, -0.0728049948811531, 0.05548194795846939, 0.13009785115718842, 0.04746951535344124, 0.0006922577158547938, 0.07294224947690964, -0.12213155627250671, -0.02011221833527088, -0.03623609617352486, -0.14478467404842377, 0.24190017580986023, -0.008038555271923542, -0.0044194962829351425, -0.11178316920995712, -0.043403733521699905, -0.17631949484348297, 0.13997571170330048, -0.05105835571885109, -0.01018741074949503, -0.14754618704319, 0.07986832410097122, 0.049073122441768646, 0.02783198468387127, -0.18908488750457764, 0.027048837393522263, -0.18499071896076202, 0.06504322588443756, -0.037239622324705124, 0.07267215102910995, 0.11538421362638474, 0.04076259210705757, 0.06564084440469742, 0.031862206757068634, 0.12964823842048645, -0.06780391931533813, -0.06824060529470444, 0.08703197538852692, 0.07213792204856873, 0.12812773883342743, 0.10771313309669495, 0.12088318169116974, -0.042383864521980286, 0.005207172594964504, -0.09575608372688293, -0.025506174191832542, -0.024934791028499603, -0.029835669323801994, 0.004520706366747618, 0.10950946062803268, 0.04211514815688133, -0.1451132595539093, -0.013409617356956005, -0.17267538607120514, 0.22384969890117645, 0.05758336931467056, -0.11976392567157745, 0.13985176384449005, 0.06843246519565582, -0.019529692828655243, 0.018873650580644608, -0.012461776845157146, 1.0203540757687005e-32, -0.09290773421525955, -0.14453652501106262, 0.11075519025325775, -0.05068885535001755, 0.17603421211242676, 0.0317402258515358, 0.1455380767583847, 0.10465927422046661, -0.025494791567325592, 0.02112896367907524, -0.2318539172410965, 0.09205538034439087, -0.1532404124736786, 0.04123089835047722, -0.03647562861442566, -0.03762023523449898, -0.13399988412857056, 0.0959504172205925, 0.030457831919193268, 0.000712292268872261, 0.3274078071117401, -0.019407659769058228, -0.11646298319101334, -0.11953861266374588, -0.10813578963279724, -0.10694874823093414, 0.0862698033452034, -0.03362225741147995, -0.05161792039871216, 0.03069520927965641, -0.13462510704994202, 0.00787938479334116, 0.00867473240941763, 0.054100893437862396, -0.013804802671074867, -0.028268493711948395, 0.03437584638595581, 0.054790157824754715, -0.07109915465116501, -0.08940723538398743, -0.06037985160946846, 0.059222377836704254, 0.027971642091870308, -0.10144684463739395, -0.0430893711745739, -0.08786606788635254, 0.03818121552467346, 0.015352282673120499, -0.10408084094524384, 0.1478969007730484, 0.09431213140487671, -0.06158345565199852, -0.09506829082965851, 0.01529432088136673, -0.11418609321117401, 0.004283223766833544, 0.06336633116006851, -0.01794445514678955, 0.20563329756259918, -0.15372565388679504, 0.019622668623924255, -0.05967274308204651, 0.04483582824468613, 0.05341606214642525, 0.10145486146211624, -0.028984881937503815, 0.2136722058057785, 0.17208221554756165, 0.03657371923327446, 0.08261027187108994, -0.1120162233710289, 0.06544820964336395, -0.008286076597869396, -0.09959645569324493, 0.19202664494514465, -0.11616326123476028, 0.0851135179400444, -0.02867739647626877, -0.2552987039089203, 0.014939583837985992, 0.0450589582324028, 0.01243774313479662, -0.06616508960723877, -0.11507587879896164, -0.010086426511406898, -0.12374947965145111, 0.07699001580476761, -0.0070318542420864105, -0.10513539612293243, -0.10637079179286957, -0.015705531463027, -0.047812625765800476, -0.013314739800989628, -0.053200989961624146, -0.1065933108329773, -1.2028813120813329e-32, 0.16705694794654846, 0.028074517846107483, 0.0006117401644587517, -0.0021156612783670425, 0.04310476407408714, 0.0077538155019283295, 0.06164448708295822, 0.16174030303955078, -0.07025481760501862, -0.21828827261924744, -0.1495077908039093, -0.05107617750763893, 0.12826117873191833, -0.05405031517148018, 0.041313786059617996, 0.12422021478414536, -0.09124550968408585, 0.08001309633255005, -0.0532262958586216, -0.015450387261807919, -0.10130377858877182, 0.012056893669068813, -0.1315574049949646, 0.08046753704547882, -0.0722607970237732, 0.047902461141347885, -0.06613928824663162, 0.07085486501455307, 0.00796161312609911, 0.015595302917063236, -0.11836928129196167, 0.050474073737859726, -0.16664424538612366, 0.1077120378613472, -0.04856698960065842, 0.06311462819576263, 0.04934818297624588, 0.022441526874899864, -0.08509190380573273, 0.11906658858060837, 0.2257436364889145, 0.020768415182828903, -0.13066336512565613, 0.059774503111839294, 0.030037328600883484, 0.058971576392650604, -0.0678146705031395, -0.06403440237045288, -0.060282252728939056, -0.04483683779835701, 0.05225072801113129, -0.1197953075170517, -0.1553422510623932, 0.009678300470113754, -0.017328882589936256, -0.017651109024882317, 0.11138058453798294, -0.06983087211847305, -0.1656285971403122, -0.03483930602669716, -0.05321954935789108, -0.08111037313938141, 0.05640935152769089, -0.0786692425608635, -0.09622420370578766, -0.03874918073415756, -0.17181400954723358, 0.06274638324975967, -0.09324630349874496, 0.07391625642776489, -0.0677223727107048, -0.009191218763589859, 0.060492757707834244, 0.03664223849773407, -0.10505767166614532, 0.10066062211990356, -0.07335403561592102, -0.20842674374580383, 0.03909279406070709, 0.03482707589864731, -0.13994944095611572, -0.04668552428483963, 0.03889387100934982, 0.028424283489584923, -0.051120344549417496, 0.001660786452703178, 0.1600220799446106, 0.031337182968854904, 0.1413603276014328, -0.05261686071753502, -0.05221332982182503, 0.010532363317906857, 0.10655234009027481, 0.10927791148424149, 0.08382678776979446, -1.0076772838374382e-07, 0.008409026078879833, 0.1158459410071373, 0.04839043319225311, 0.23219271004199982, 0.014236398972570896, 0.022447941824793816, -0.06256888806819916, 0.1632174551486969, 0.03551003709435463, 0.036900442093610764, 0.10220038145780563, -0.04394970089197159, -0.16094428300857544, 0.051531992852687836, -0.15030863881111145, 0.20411092042922974, 0.050665274262428284, 0.006362166255712509, -0.017936358228325844, -0.07132285088300705, 0.008555151522159576, 0.03444322198629379, 0.10146820545196533, 0.03025578148663044, -0.01813541352748871, -0.0771183967590332, 0.031803201884031296, 0.07011821120977402, -0.05773278698325157, -0.04828464984893799, -0.053118277341127396, -0.08274766802787781, -0.11323010921478271, 0.10593320429325104, 0.031157493591308594, 0.015333803370594978, 0.008698660880327225, -0.03814386576414108, 0.0355449914932251, 0.004983788356184959, -0.058487847447395325, 0.05264774709939957, -0.10225418955087662, -0.10222578048706055, 0.0996081754565239, 0.022199470549821854, -0.042925167828798294, -0.07869622856378555, 0.009533562697470188, 0.08026479184627533, 0.026757363229990005, -0.00178527703974396, -0.09584342688322067, 0.10996069014072418, 0.10309493541717529, 0.03983388468623161, -0.09430304169654846, -0.011213291436433792, -0.011668910272419453, -0.0549437515437603, -0.08723033219575882, 0.10541284829378128, 0.04570218175649643, 0.06112120300531387], metadata={'source': 'AAAMLP-569to.pdf', 'page': 287}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 288 ═════════════════════════════════════════════════════════════════════════ # config.py import os import transformers  # fetch home directory # in our docker container, it is # /home/abhishek HOME_DIR = os.path.expanduser(\"~\")  # this is the maximum number of tokens in the sentence MAX_LEN = 512  # batch sizes is low because model is huge! TRAIN_BATCH_SIZE = 8 VALID_BATCH_SIZE = 4  # let\\'s train for a maximum of 10 epochs EPOCHS = 10  # define path to BERT model files # Now we assume that all the data is stored inside # /home/abhishek/data BERT_PATH = os.path.join(HOME_DIR, \"data\", \"bert_base_uncased\")  # this is where you want to save the model MODEL_PATH = os.path.join(HOME_DIR, \"data\", \"model.bin\")  # training file TRAINING_FILE = os.path.join(HOME_DIR, \"data\", \"imdb.csv\")  TOKENIZER = transformers.BertTokenizer.from_pretrained(     BERT_PATH,      do_lower_case=True ) ═════════════════════════════════════════════════════════════════════════  Now, the code assumes everything to be inside a folder called data inside the home directory.   Note that any change in the python scripts, means that the docker container needs to be rebuilt! So, we rebuild the container and rerun the docker command but this time with a twist. However, this won’t work either if we do not have the NVIDIA docker runtimes. Don’t worry. It’s just a docker container again, and you need to'),\n",
       " VectorParams(vector=[-0.056939512491226196, 0.00014561228454113007, -0.0668649971485138, 0.04033239930868149, 0.05036497861146927, -0.08975496143102646, -0.03560364246368408, 0.027621442452073097, 0.041077613830566406, -0.05389934778213501, -0.022561006247997284, -0.1078307181596756, 0.03732112795114517, -0.006924368441104889, 0.03430730849504471, 0.00841918308287859, 0.10777352005243301, 0.022565018385648727, -0.07093396782875061, -0.0852029100060463, 0.017762543633580208, 0.10945763438940048, 0.07361231744289398, 0.054577361792325974, -0.1111021637916565, 0.006924329325556755, -0.03930128365755081, -0.07284253090620041, -0.09319771081209183, 0.004104145802557468, 0.1244037076830864, 0.08497504144906998, 0.00420483760535717, 0.020788826048374176, 0.011013703420758247, 0.16031622886657715, -0.0736970603466034, -0.08604323118925095, -0.1221034824848175, -0.0766940712928772, 0.04953906312584877, 0.019048435613512993, -0.06504429131746292, -0.037620704621076584, 0.05442347377538681, -0.11744382977485657, -0.15460403263568878, -0.09469490498304367, 0.08118166029453278, 0.022466029971837997, -0.2468017339706421, -0.07195691764354706, -0.0027759410440921783, 0.043817952275276184, -0.05714241415262222, 0.16509714722633362, 0.006196390837430954, 0.04182910919189453, -0.024361005052924156, -0.15110817551612854, 0.09507609903812408, -0.09091183543205261, -0.03216419368982315, 0.0221080519258976, 0.06462451815605164, -0.13167646527290344, -0.02463415451347828, 0.017458844929933548, 0.1267985701560974, -0.04537288099527359, -0.005043574143201113, 0.04411979019641876, -0.1012808233499527, -0.09366944432258606, -0.04691794514656067, -0.024499453604221344, 0.14108538627624512, -0.024891648441553116, -0.008079644292593002, -0.02321484312415123, -0.09320700913667679, -0.01501930970698595, 0.15446719527244568, -0.006940443068742752, 0.011848853901028633, 0.01932559721171856, 0.0990082323551178, 0.09661787748336792, 0.09552273154258728, -0.11385238915681839, -0.03796745091676712, -0.13392716646194458, -0.0016441969200968742, 0.016245737671852112, 0.15465573966503143, 0.04977906867861748, -0.048040080815553665, -0.008788755163550377, -0.11487697064876556, 0.1545635163784027, -0.11909490823745728, -0.14639520645141602, 0.04107741639018059, 0.10534520447254181, 0.12500420212745667, 0.11879675090312958, -0.024922233074903488, -0.005833425559103489, -0.035898588597774506, -0.13689449429512024, -0.048711612820625305, 0.016051633283495903, -0.07761149853467941, 0.0866883248090744, 0.007448650896549225, 0.14132535457611084, -0.10990536212921143, -0.07246953248977661, 0.0006393948569893837, 0.19224317371845245, 0.08694938570261002, -0.0609043687582016, -0.00045522116124629974, 0.005001792684197426, 0.07309446483850479, -0.082651786506176, 0.02951299399137497, 7.782032680568663e-33, 0.042087920010089874, -0.1806679368019104, 0.08311649411916733, -0.1110595092177391, 0.1990027129650116, 0.02558298036456108, 0.14157459139823914, 0.10601691901683807, -0.06292980909347534, -0.04071306437253952, -0.185633584856987, 0.183893620967865, -0.08406247198581696, 0.08244848996400833, 0.08581646531820297, -0.1927579641342163, -0.1321679800748825, 0.08884906768798828, 0.031819820404052734, 0.020111577585339546, 0.18207556009292603, 0.047048039734363556, -0.09525801241397858, -0.13106951117515564, -0.05781122297048569, -0.0033657243475317955, 0.05389198288321495, -0.07303221523761749, -0.037722520530223846, 0.0726214349269867, -0.06070847809314728, -0.032640889286994934, -0.019663726910948753, -0.0166645385324955, 0.03435185179114342, -0.14111049473285675, -0.017072927206754684, 0.05978301540017128, -0.08054470270872116, -0.06653781980276108, 0.029939230531454086, 0.07533948868513107, 0.006504136137664318, -0.1588062345981598, -0.0661492571234703, -0.03190356492996216, -0.0657229945063591, 0.02915147691965103, -0.0759301409125328, 0.1423792541027069, 0.12660962343215942, -0.023640645667910576, -0.11232475191354752, -0.09165510535240173, -0.06404142081737518, -0.03372229263186455, -0.004079748876392841, 0.0658225417137146, 0.2003408819437027, -0.025181949138641357, -0.13412189483642578, 0.02973146364092827, 0.10836168378591537, -0.022791288793087006, 0.08243091404438019, 0.05275813490152359, 0.008861221373081207, 0.04852308705449104, 0.12438997626304626, 0.05982518941164017, -0.14719092845916748, 0.11775101721286774, -0.024065738543868065, 0.027881238609552383, 0.15437373518943787, -0.04874490201473236, 0.00980093888938427, -0.132564976811409, -0.10958948731422424, -0.04791531339287758, 0.013052118942141533, 0.015816573053598404, -0.04325570911169052, -0.05196236073970795, 0.005622256547212601, 0.040895845741033554, 0.054200466722249985, -0.10507414489984512, -0.11414323002099991, 0.019821064546704292, -0.15128415822982788, 0.009519260376691818, -0.05488649755716324, -0.04186602681875229, -0.024192916229367256, -8.940383915652146e-33, 0.14366532862186432, -0.0519169420003891, -0.03143541142344475, 0.09429796040058136, 0.08465731889009476, 0.04242653027176857, 0.025191133841872215, 0.0174685250967741, 0.00022592023015022278, -0.11636284738779068, -0.17351192235946655, 0.09584155678749084, 0.029476577416062355, 0.07947027683258057, 0.02286962792277336, 0.08830449730157852, -0.05995279550552368, -0.07184626907110214, -0.06259648501873016, 0.024825718253850937, -0.1904216706752777, 0.10224118828773499, -0.10234937071800232, 0.013385390862822533, -0.06566464900970459, 0.00040434207767248154, 0.1723375916481018, 0.121090367436409, 0.007884856313467026, -0.049584101885557175, -0.09451686590909958, 0.02440611645579338, -0.2303030788898468, 0.0996328592300415, 0.03053317219018936, 0.09570056200027466, 0.08414629846811295, 0.0715777799487114, -0.09419944882392883, 0.09113162755966187, 0.23608121275901794, -0.06185157597064972, -0.13820840418338776, -0.004172840155661106, -0.03515319898724556, -0.04054788500070572, -0.05096094310283661, 0.010156363248825073, -0.17662161588668823, -0.047485046088695526, 0.03914922475814819, -0.08069457113742828, -0.1064293310046196, 0.0847809910774231, -0.045582935214042664, -0.0010061711072921753, 0.17378239333629608, 0.009954622015357018, -0.08646085858345032, -0.010920537635684013, -0.04154206067323685, -0.05116016045212746, 0.05911983177065849, -0.12337423115968704, 0.06261011958122253, -0.11782104521989822, -0.19103926420211792, 0.02090376988053322, -0.029977358877658844, 0.1388486623764038, 0.03407537192106247, 0.08298005163669586, 0.08198733627796173, 0.0030045537278056145, -0.03937091678380966, 0.08354713022708893, -0.041409239172935486, -0.15666386485099792, 0.0814804807305336, -0.022210249677300453, -0.11045688390731812, -0.03946497663855553, 0.18110689520835876, -0.004479728639125824, 0.038597844541072845, -0.007565549574792385, 0.21956776082515717, 0.030815493315458298, 0.13488177955150604, -0.03125763684511185, 0.025681154802441597, 0.009303109720349312, 0.028695354238152504, 0.05023413151502609, 0.04894981160759926, -1.0035083874981865e-07, -0.0033664656803011894, -0.03625386580824852, -0.024617651477456093, 0.3187885880470276, 0.03207196667790413, 0.10542331635951996, 0.046781063079833984, 0.04611186683177948, -0.041597504168748856, -0.07362887263298035, 0.1180180013179779, -0.05000472068786621, -0.08772777020931244, 0.012490990571677685, -0.04527280852198601, 0.17263327538967133, 0.017972879111766815, 0.08733478933572769, -0.06350966542959213, -0.01519478764384985, 0.026332590728998184, 0.04834610968828201, 0.0620945543050766, -0.058284785598516464, -0.05417414754629135, -0.09288537502288818, 0.03647970035672188, -0.046452220529317856, -0.029645878821611404, -0.07820628583431244, 0.006585040129721165, -0.05960541591048241, -0.029300177469849586, 0.10231645405292511, 0.09681808948516846, -0.031728584319353104, 0.044793009757995605, -0.055595770478248596, 0.08796299993991852, -0.03544332832098007, -0.03484031558036804, 0.02835221029818058, -0.01808534748852253, -0.1541314721107483, 0.04270076006650925, 0.053957171738147736, 0.02581590786576271, -0.12827004492282867, 0.00780867226421833, 0.10275719314813614, -0.03667902946472168, 0.013184789568185806, -0.08480168133974075, 0.08259831368923187, 0.11301390826702118, 0.034500908106565475, 0.011578049510717392, -0.18237939476966858, -0.13563071191310883, -0.056277867406606674, -0.035959623754024506, 0.10360944271087646, 0.11750130355358124, 0.10106711089611053], metadata={'source': 'AAAMLP-569to.pdf', 'page': 288}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 289 do it only once. To install the NVIDIA docker runtime, you can run the following commands in Ubuntu 18.04.  ═════════════════════════════════════════════════════════════════════════ # taken from: https://github.com/NVIDIA/nvidia-docker/ # Add the package repositories distribution=$(. /etc/os-release;echo $ID$VERSION_ID) curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list  sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit sudo systemctl restart docker ═════════════════════════════════════════════════════════════════════════  Now we can build our container again and start the training process:  ═════════════════════════════════════════════════════════════════════════ $ docker run --gpus 1 -v /home/abhishek/workspace/approaching_almost/input/:/home/abhishek/data/ -ti bert:train python3 train.py ═════════════════════════════════════════════════════════════════════════  Where –gpus 1 says that we use 1 GPU inside the docker container and -v is mounting a volume. So, we are mounting our local directory, /home/abhishek/workspace/approaching_almost/input/ to /home/abhishek/data/ in the docker container. This step is going to take a while, but when it’s done, you will have model.bin inside the local folder.  So, with some very simple changes, you have now “dockerized” your training code. You can now take this code and train on (almost) any system you want.  The next part is “serving” this model that we have trained to the end-user. Suppose, you want to extract sentiment from a stream of incoming tweets. To do this kind of task, you must create an API that can be used to input the sentence and in turns returns an output with sentiment probabilities. The most common way of building an API using Python is with Flask, which is a micro web service framework.  ═════════════════════════════════════════════════════════════════════════ # api.py import config import flask'),\n",
       " VectorParams(vector=[-0.13574178516864777, -0.14018084108829498, 0.016856715083122253, 0.15405790507793427, 0.1109415739774704, 0.04673618823289871, 0.0657469853758812, 0.12615303695201874, 0.016114067286252975, -0.12404587864875793, -0.012908942997455597, -0.1040555015206337, -0.048502858728170395, -0.01725023053586483, -0.011751484125852585, 0.16783589124679565, 0.014440704137086868, -0.05599159002304077, -0.19182278215885162, -0.21292507648468018, 0.19546544551849365, 0.11133009940385818, 0.14305153489112854, 0.0495116226375103, -0.033590417355298996, -0.04318214952945709, -0.04178294911980629, 0.02928941696882248, 0.042840130627155304, 0.05288425460457802, 0.08613093197345734, -0.06469564139842987, 0.00317400717176497, 0.15401925146579742, -0.01987885870039463, 0.01334527600556612, -0.1627928912639618, -0.083808034658432, 0.04972567409276962, -0.010984600521624088, -0.023622233420610428, -0.02441338449716568, -0.040999822318553925, 0.04284674674272537, 0.1672273725271225, -0.04410654678940773, 0.03129284456372261, -0.03782936558127403, -0.0036130319349467754, -0.026170408353209496, -0.11019265651702881, 0.03561754524707794, 0.05664467811584473, 0.027458403259515762, -0.07519245147705078, -0.052643146365880966, 0.0011508972384035587, -0.09728498756885529, 0.11080542206764221, -0.31055551767349243, 0.0194082148373127, -0.1405373066663742, 0.05648253485560417, -0.10630322992801666, -0.12565627694129944, -0.05212301015853882, -0.08205083012580872, 0.06585559993982315, 0.045013491064310074, 0.11910693347454071, 0.00658829091116786, 0.1723637729883194, -0.006893808487802744, 0.14927127957344055, -0.00395232206210494, -0.04056613892316818, 0.1824626624584198, -0.01113834884017706, 0.08125094324350357, -0.04148417338728905, -0.024778954684734344, -0.09491106122732162, 0.19478869438171387, 0.06891914457082748, 0.1823444366455078, -0.1816471964120865, 0.1193665936589241, 0.09670084714889526, -0.03270759433507919, -0.05975933372974396, -0.0820717066526413, -0.2080749273300171, 0.07422716170549393, -0.059997860342264175, 0.00344194658100605, 0.07462004572153091, 0.012588310055434704, -0.13734906911849976, -0.14811250567436218, 0.16750246286392212, -0.0056651439517736435, 0.05883577838540077, -0.0341101810336113, -0.054086241871118546, 0.020335698500275612, 0.13929729163646698, 0.026205241680145264, 0.06429553031921387, 0.06077020987868309, -0.17564630508422852, 0.02401413768529892, 0.06252620369195938, 0.009920959360897541, -0.01166661735624075, 0.0899055227637291, 0.02813706360757351, -0.06150176748633385, 0.03422010317444801, 0.019592072814702988, 0.33854013681411743, 0.01922142505645752, 0.09156700223684311, -0.15796636044979095, 0.1291622519493103, -0.07719109952449799, -0.058172550052404404, 0.093723826110363, 1.3161097768667327e-32, -0.15846705436706543, 0.06323033571243286, -0.07955378293991089, -0.1419811248779297, 0.030055593699216843, 0.007059240248054266, 0.03399614989757538, 0.06371617317199707, -0.12381400167942047, -0.06324998289346695, -0.09408015012741089, -0.057933732867240906, -0.05798583850264549, 0.03218289837241173, -0.05720272287726402, -0.08171473443508148, 0.004342556465417147, 0.03836095333099365, 0.08759119361639023, -0.05664079263806343, 0.03759525343775749, 0.0341157540678978, -0.08123379200696945, -0.11055637151002884, -0.158578559756279, 0.017661895602941513, 0.08661960810422897, -0.07822529971599579, -0.04123101383447647, 0.03496478870511055, -0.23971904814243317, 0.09057875722646713, 0.010364772751927376, -0.06443116068840027, 0.062718465924263, -0.032775960862636566, 0.05944101884961128, -0.02908536233007908, -0.008141571655869484, -0.1689065843820572, -0.10804080963134766, 0.14260271191596985, -0.001861780183389783, -0.03831011801958084, -0.06215735897421837, 0.07741384208202362, -0.07094814628362656, 0.02589467540383339, -0.053275417536497116, 0.07824500650167465, -0.030749570578336716, -0.0500490702688694, -0.056268349289894104, 0.11848711222410202, -0.04495608061552048, -0.05889618769288063, 0.08928921818733215, 0.04200831055641174, 0.22350874543190002, -0.10862449556589127, 0.06814207881689072, -0.007586705964058638, 0.04113870486617088, -0.034403201192617416, 0.01640813797712326, 0.02348395809531212, 0.012700025923550129, 0.1383112519979477, 0.08066433668136597, -0.010183651931583881, -0.10705333948135376, 0.05787474662065506, 0.018411926925182343, -0.05061111971735954, 0.005743074230849743, -0.10679013282060623, 0.0758461281657219, -0.20682145655155182, -0.16187024116516113, 0.056789580732584, 0.04159987345337868, -0.020749816671013832, -0.06405782699584961, -0.19959737360477448, -0.11179285496473312, -0.09330108016729355, 0.08409137278795242, -0.11260229349136353, -0.0931367352604866, 0.0005682915798388422, -0.15759898722171783, -0.018566470593214035, 0.1267646700143814, -0.01322221290320158, -0.08507867157459259, -1.1632915439664013e-32, -0.0432145930826664, 0.04476509615778923, -0.02866702526807785, 0.04330204054713249, -0.05832052230834961, -0.06753981858491898, -0.08476129919290543, 0.14319822192192078, 0.011851292103528976, -0.09566344320774078, -0.024723881855607033, -0.20372158288955688, -0.00741983950138092, -0.08258526027202606, 0.08823009580373764, 0.11525477468967438, -0.0765795037150383, 0.16706645488739014, 0.06227731704711914, 0.06902419775724411, -0.10776534676551819, 0.15382565557956696, -0.18916092813014984, 0.1464744210243225, -0.1814740002155304, 0.1615908294916153, 0.00256734830327332, 0.09085571020841599, 0.004153133369982243, -0.011845179833471775, -0.10569621622562408, 0.02222852036356926, -0.18375170230865479, 0.13330046832561493, -0.1320989578962326, -0.003618793096393347, 0.142581507563591, -0.11560126394033432, -0.04480290785431862, 0.10437846928834915, 0.325375497341156, 0.06306739896535873, -0.09209626168012619, 0.07190284132957458, -0.03703678771853447, 0.08804541081190109, -0.12568333745002747, 0.004648207686841488, -0.026002002879977226, -0.0434010773897171, 0.009875649586319923, 0.01607087440788746, -0.24186569452285767, 0.02252259850502014, -0.13884280622005463, -0.10175497829914093, 0.026413114741444588, -0.11536779999732971, -0.12229396402835846, 0.014864949509501457, -0.12019623070955276, -0.036267511546611786, 0.13697215914726257, -0.022427184507250786, 0.13915804028511047, -0.10711730271577835, -0.07636551558971405, 0.24845951795578003, 0.0747498944401741, 0.06256338953971863, -0.11294778436422348, 0.1361871361732483, 0.08947763592004776, 0.10969292372465134, 0.013744651339948177, 0.14973507821559906, -0.007370206993073225, -0.1611507534980774, -0.05122549459338188, 0.010295230895280838, -0.13699936866760254, -0.0549008809030056, 0.10038064420223236, 0.03581199795007706, -0.006690746173262596, 0.06873282790184021, 0.1450333148241043, 0.12115994095802307, 0.0187226552516222, -0.08092636615037918, -0.018043043091893196, -0.06458791345357895, 0.19241108000278473, 0.09644342958927155, 0.035419195890426636, -9.980606563431138e-08, -0.0621933788061142, -0.04732199385762215, -0.046749845147132874, 0.21272172033786774, -0.039042189717292786, 0.02595270425081253, -0.02193877287209034, 0.03472122177481651, -0.04731027036905289, -0.11695576459169388, 0.1341301053762436, 0.0308820940554142, -0.12001306563615799, -0.015559187158942223, -0.09806911647319794, 0.1596486121416092, -0.07284314185380936, 0.06967111676931381, 0.07015880197286606, -0.11031636595726013, 0.07596554607152939, 0.04864360764622688, 0.06056559830904007, -0.022996345534920692, -0.004139188677072525, -0.019392957910895348, -0.024876506999135017, 0.13081417977809906, -0.12080024182796478, 0.016604270786046982, 0.02206449769437313, -0.02886212430894375, -0.04572393745183945, 0.07888812571763992, 0.05855702981352806, 0.05591333657503128, 0.05373822897672653, -0.11237592995166779, 0.02275104820728302, 0.04484764486551285, 0.04088204726576805, 0.1350291669368744, -0.1942128986120224, -0.02748766727745533, 0.10435900092124939, -0.001353497034870088, 0.1293819099664688, -0.1401817947626114, 0.12047529220581055, 0.05811971426010132, 0.09440407156944275, -0.04745207354426384, -0.06336265802383423, 0.08745763450860977, 0.07718988507986069, -0.052894096821546555, -0.14242461323738098, 0.03818577527999878, -0.12806668877601624, -0.03880727291107178, 0.07258222997188568, 0.034843605011701584, 0.03714493289589882, 0.038396205753088], metadata={'source': 'AAAMLP-569to.pdf', 'page': 289}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 290 import time import torch import torch.nn as nn from flask import Flask from flask import request from model import BERTBaseUncased  app = Flask(__name__)  # init model to None MODEL = None  # choose device # please note that we are using cuda device # you can also use cpu! DEVICE = \"cuda\"   def sentence_prediction(sentence):     \"\"\"     A prediction function that takes an input sentence     and returns the probability for it being associated     to a positive sentiment     \"\"\"     # fetch the tokenizer and max len of tokens from config.py     tokenizer = config.TOKENIZER     max_len = config.MAX_LEN      # the processing is same as it was done for training     review = str(sentence)     review = \" \".join(review.split())      # encode the sentence into ids,     # truncate to max length &     # add CLS and SEP tokens     inputs = tokenizer.encode_plus(         review,          None,          add_special_tokens=True,          max_length=max_len     )      # fetch input ids, mask & token type ids     ids = inputs[\"input_ids\"]     mask = inputs[\"attention_mask\"]     token_type_ids = inputs[\"token_type_ids\"]'),\n",
       " VectorParams(vector=[-0.058858755975961685, -0.05632602050900459, 0.0040167151018977165, 0.14356686174869537, 0.08091605454683304, -0.07478903979063034, 0.0008099388214759529, 0.0631825178861618, -0.10611878335475922, -0.17632220685482025, -0.05866200849413872, -0.1653406172990799, 0.0006583924405276775, -0.029156040400266647, -0.012624957598745823, 0.08068351447582245, -0.03326702490448952, 0.004463354591280222, -0.09901480376720428, -0.16318567097187042, 0.2004280388355255, 0.1658407598733902, 0.15012946724891663, 0.07817256450653076, -0.04076661169528961, -0.035306449979543686, 0.05515356361865997, -0.0011389685096219182, -0.05185389146208763, -0.04189177602529526, 0.0374586321413517, -0.0011581213911995292, -0.053300641477108, 0.11578258126974106, 0.08627135306596756, -0.059749070554971695, -0.220594123005867, -0.07100120931863785, -0.05043135583400726, 0.03177303820848465, 0.047246064990758896, -0.01699903979897499, -0.051839541643857956, 0.00017102720448747277, 0.00904652290046215, -0.006207806058228016, 0.006472595501691103, -0.04148632287979126, 0.09978462010622025, -0.10643941164016724, -0.06765180081129074, 0.09301478415727615, -0.046466972678899765, 0.035899654030799866, -0.10386442393064499, -0.1426553577184677, 0.0743696317076683, -0.10268578678369522, 0.01656319759786129, -0.2614345848560333, 0.011958695948123932, -0.10376518964767456, 0.03254483640193939, -0.11524256318807602, -0.06992527842521667, -0.03845002129673958, -0.0786241665482521, 0.054181233048439026, 0.07031654566526413, 0.08137331157922745, -0.04054310545325279, 0.14753247797489166, -0.13298022747039795, 0.11522766947746277, -0.09053156524896622, 0.029701747000217438, 0.25712940096855164, 0.03882310166954994, 0.05707083269953728, -0.13227415084838867, -0.049388859421014786, -0.10997788608074188, 0.07955175638198853, 0.06646177172660828, 0.0701313242316246, -0.189919114112854, 0.08992370218038559, 0.1397271752357483, 0.10664550960063934, -0.09260111302137375, -0.06875693798065186, -0.06710361689329147, -0.004016703926026821, 0.00124939635861665, 0.07755299657583237, 0.09600376337766647, 0.08305767178535461, -0.09301318973302841, -0.18504302203655243, 0.1540222018957138, -0.022105105221271515, -0.059639256447553635, -0.08878950029611588, 0.01481503713876009, 0.00804330687969923, 0.12307313084602356, 0.05194394662976265, 0.056222230195999146, 0.05143450200557709, -0.18074730038642883, 0.04700995236635208, 0.1398032158613205, -0.052257221192121506, 0.02319668047130108, 0.16094103455543518, 0.059529855847358704, -0.1045139878988266, 0.13857588171958923, -0.07024816423654556, 0.24487774074077606, -0.0051255603320896626, 0.051735471934080124, -0.08868780732154846, 0.12486311793327332, -0.03993016481399536, -0.08113411068916321, -0.005232916213572025, 1.5695011023715113e-32, -0.10333836078643799, 0.058773040771484375, -0.0775362104177475, -0.14476846158504486, 0.027700355276465416, 0.13077455759048462, 0.040949005633592606, 0.043486956506967545, -0.10514547675848007, -0.020323393866419792, -0.23657681047916412, -0.018328214064240456, -0.042635444551706314, 0.01077880896627903, -0.06165981665253639, -0.043357886373996735, 0.09547995775938034, 0.12013804912567139, 0.05575784668326378, -0.014890355989336967, 0.13320301473140717, 0.01754053868353367, -0.08995623886585236, -0.08010692894458771, -0.08226823806762695, 0.05501120164990425, -0.028993958607316017, -0.04831210523843765, -0.1817023754119873, -0.006026933901011944, -0.20919474959373474, 0.05117732286453247, 0.03945410996675491, -0.04863284155726433, 0.027113527059555054, -0.11076679825782776, 0.10632018744945526, 0.009362568147480488, -0.039020322263240814, -0.15035611391067505, -0.08407726883888245, 0.10676177591085434, -0.0732850506901741, -0.14750418066978455, -0.16833075881004333, -0.03929045423865318, -0.06389027833938599, 0.1317230761051178, -0.06022088974714279, 0.10377675294876099, -0.029970910400152206, -0.08359506726264954, -0.06167592853307724, -0.040429048240184784, -0.02055765502154827, -0.1165459156036377, 0.12616831064224243, 0.08253122121095657, 0.29959237575531006, -0.08330076932907104, 0.031153470277786255, -0.005734485574066639, -0.018372755497694016, -0.02501658909022808, 0.05481438711285591, 0.08987889438867569, 0.06939774006605148, 0.08664655685424805, 0.09691255539655685, -0.015711093321442604, -0.16931277513504028, 0.12081567943096161, -0.021430838853120804, -0.07177425175905228, -0.05891948193311691, -0.14274758100509644, 0.05477079749107361, -0.15647737681865692, -0.14255832135677338, 0.1295093446969986, -0.06146841123700142, 0.13135485351085663, -0.10478644073009491, -0.24035386741161346, -0.054352935403585434, -0.015699265524744987, 0.035320572555065155, -0.06972283124923706, -0.13813278079032898, -0.04763933643698692, -0.27026107907295227, -0.03558540716767311, 0.15433359146118164, 0.0011530424235388637, -0.07635925710201263, -1.471824574784284e-32, -0.02204752527177334, 0.08380120992660522, 0.017223358154296875, -0.007430196274071932, 0.059846509248018265, -0.05789612606167793, 0.040750402957201004, 0.10842958837747574, -0.07791608572006226, -0.10181896388530731, -0.004233337938785553, -0.18491613864898682, 0.03763333708047867, -0.12199866771697998, 0.1675945669412613, 0.05175507068634033, -0.060480695217847824, 0.1170370951294899, 0.04220016673207283, 0.08580227941274643, -0.19896185398101807, 0.24020656943321228, -0.22162912786006927, 0.015857599675655365, -0.2666603922843933, 0.13063642382621765, 0.01899845525622368, 0.13678200542926788, -0.05666587874293327, -0.15030935406684875, -0.011166540905833244, 0.02431069128215313, -0.15396492183208466, 0.09640020877122879, -0.01423182524740696, 0.051574721932411194, 0.11930740624666214, -0.04171447828412056, 0.01691468432545662, 0.14449138939380646, 0.2986193895339966, 0.04864230379462242, -0.07088643312454224, 0.12840966880321503, -0.047403302043676376, -0.03949428349733353, -0.0913965180516243, 0.04897616058588028, -0.029120013117790222, -0.029094502329826355, 0.029877377673983574, -0.11257289350032806, -0.23824504017829895, 0.008231831714510918, -0.04267089441418648, -0.03997587412595749, -0.00989170279353857, -0.052424922585487366, -0.03425116464495659, -0.028034552931785583, -0.06455807387828827, -0.06859441101551056, 0.05412103235721588, -0.021227044984698296, 0.1628950834274292, -0.013423423282802105, -0.11168839037418365, 0.07309213280677795, 0.09004450589418411, 0.05694618821144104, -0.07764852792024612, 0.11904065310955048, 0.10923778265714645, 0.11383745819330215, -0.006490807048976421, 0.07231953740119934, -0.06342989206314087, -0.04388786852359772, 0.06639329344034195, 0.03936458006501198, -0.16328325867652893, 0.013664782047271729, 0.1175592690706253, 0.09954075515270233, 0.09539089351892471, 0.07228412479162216, 0.09231214225292206, 0.23369230329990387, 0.09917039424180984, -0.0633617639541626, -0.02156451717019081, -0.048485759645700455, 0.21480508148670197, 0.2254122495651245, 0.10485569387674332, -1.0058941057877746e-07, -0.03809178248047829, 0.06141437217593193, 0.012049796059727669, 0.22700420022010803, -0.04691349342465401, 0.049676086753606796, -0.003802529303357005, -0.002160419709980488, 0.11183792352676392, -0.0925600603222847, 0.0812370702624321, -0.052779652178287506, -0.029376912862062454, 0.0592711977660656, -0.00976708997040987, 0.1626797914505005, -0.09135545790195465, 0.0014163918094709516, 0.01146051473915577, -0.03731724992394447, 0.07264868915081024, -0.11445966362953186, 0.041007038205862045, -0.02070346288383007, 0.022187301889061928, -0.09345216304063797, 0.011457142420113087, 0.11398161947727203, -0.0948319211602211, -0.017334697768092155, -0.03779056668281555, -0.14769527316093445, 0.0635010227560997, 0.11261489242315292, 0.14016632735729218, 0.05840234458446503, 0.07901809364557266, -0.025676989927887917, 0.08572745323181152, 0.16801448166370392, -0.13471661508083344, 0.09565645456314087, -0.13386788964271545, -0.08190107345581055, 0.08995243161916733, -0.012340140528976917, 0.03631070256233215, -0.13057152926921844, 0.14827722311019897, 0.1197173073887825, -0.060860857367515564, -0.07519373297691345, -0.09050317108631134, 0.08328559249639511, 0.14433211088180542, -0.057842131704092026, -0.09620586037635803, 0.009245877154171467, -0.0010768102947622538, 0.025300398468971252, 0.06299217790365219, 0.03715124353766441, -0.08579587936401367, -0.10409467667341232], metadata={'source': 'AAAMLP-569to.pdf', 'page': 290}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 291     # add padding if needed     padding_length = max_len - len(ids)     ids = ids + ([0] * padding_length)     mask = mask + ([0] * padding_length)     token_type_ids = token_type_ids + ([0] * padding_length)      # convert all the inputs to torch tensors     # we use unsqueeze(0) since we have only one sample     # this makes the batch size 1     ids = torch.tensor(ids, dtype=torch.long).unsqueeze(0)     mask = torch.tensor(mask, dtype=torch.long).unsqueeze(0)     token_type_ids = torch.tensor(token_type_ids,                                       dtype=torch.long).unsqueeze(0)      # send everything to device     ids = ids.to(DEVICE, dtype=torch.long)     token_type_ids = token_type_ids.to(DEVICE, dtype=torch.long)     mask = mask.to(DEVICE, dtype=torch.long)      # use the model to make predictions     outputs = MODEL(ids=ids, mask=mask, token_type_ids=token_type_ids)     # take sigmoid of prediction and return the output     outputs = torch.sigmoid(outputs).cpu().detach().numpy()     return outputs[0][0]   @app.route(\"/predict\", methods=[\"GET\"]) def predict():     # this is our endpoint!     # this endpoint can be accessed by http://HOST:PORT/predict     # the endpoint needs sa sentence and can only use GET     # POST request is not allowed     sentence = request.args.get(\"sentence\")      # keep track of time     start_time = time.time()      # make prediction     positive_prediction = sentence_prediction(sentence)      # negative = 1 - positive     negative_prediction = 1 - positive_prediction      # create return dictionary     response = {}     response[\"response\"] = {         \"positive\": str(positive_prediction),'),\n",
       " VectorParams(vector=[-0.1300739049911499, -0.0029859798960387707, -0.0010283231968060136, 0.073260597884655, 0.07875626534223557, -0.125921830534935, -0.04089679941534996, 0.09870465099811554, 0.05502581223845482, -0.10125664621591568, 0.021698439493775368, -0.0536838099360466, -0.03442516177892685, 0.0354645811021328, 0.030647559091448784, 0.10045360773801804, -0.020190155133605003, -0.13278959691524506, -0.07141704112291336, -0.14677222073078156, 0.2071930468082428, 0.11468465626239777, 0.07880669087171555, 0.03256117179989815, -0.0696483850479126, -0.021628890186548233, -0.007201299536973238, 0.061227064579725266, -0.02658187784254551, 0.05646192282438278, -0.0026648652274161577, -0.03497771918773651, -0.10818278789520264, 0.06510867178440094, 0.029318032786250114, 0.0746951699256897, -0.018771324306726456, -0.11185699701309204, -0.013954253867268562, 0.02183832786977291, 0.07061579823493958, -0.009122363291680813, -0.057925887405872345, -0.05003095790743828, -0.005430444609373808, -0.08362703770399094, 0.004020504653453827, -0.007160757668316364, -0.07262419164180756, -0.06680988520383835, -0.09170635044574738, 0.11411548405885696, -0.06421668827533722, 0.04147915169596672, -0.02335040085017681, -0.022413605824112892, -0.027028312906622887, -0.016720829531550407, -0.04357430711388588, -0.24563054740428925, 0.0038334736600518227, -0.0722983106970787, -0.01386738196015358, -0.07136042416095734, -0.15170270204544067, -0.021537845954298973, -0.09064528346061707, 0.08373647183179855, 0.09677495062351227, -0.007448473945260048, 0.005697816610336304, 0.02707120217382908, -0.05856488645076752, 0.05286349728703499, 0.030747132375836372, -0.0573684424161911, 0.15420112013816833, 0.014886313118040562, -0.002162015764042735, -0.035079799592494965, -0.06114906817674637, -0.10223203897476196, -0.01117622759193182, 0.13395646214485168, 0.05768020078539848, -0.1007610484957695, 0.018715988844633102, 0.10337074846029282, 0.011924589052796364, -0.052102070301771164, -0.09147433191537857, -0.14175525307655334, -0.04890428110957146, -0.026577915996313095, 0.021461347118020058, 0.10658665001392365, 0.1090426966547966, -0.06718413531780243, -0.11173295974731445, 0.14204490184783936, -0.05483375862240791, -0.0740320160984993, 0.0034273711498826742, 0.03431650251150131, 0.07356876879930496, 0.02709600329399109, -0.008672061376273632, -0.016189735382795334, 0.04855586960911751, -0.08036165684461594, -0.0221446193754673, -0.025117432698607445, -0.021471478044986725, -0.05126669630408287, 0.021353041753172874, 0.056330010294914246, -0.09958887100219727, 0.06213582679629326, -0.03841479867696762, 0.24048525094985962, 0.04993043094873428, 0.06880544871091843, -0.01903776079416275, 0.097835011780262, 0.02065083384513855, -0.06947699934244156, 0.10040175914764404, 1.1507105218031381e-32, -0.021099505946040154, -0.046007364988327026, -0.013541916385293007, -0.12578628957271576, 0.07486571371555328, -0.019398313015699387, 0.11198063939809799, 0.07510584592819214, -0.03603536635637283, -0.050186533480882645, -0.12481663376092911, 0.04641919583082199, 0.016453538089990616, -0.0731053277850151, -0.08796384185552597, 0.009707910940051079, 0.023833507671952248, 0.038893379271030426, 0.07782036811113358, 0.0401771105825901, 0.18751570582389832, -0.054479651153087616, -0.028386054560542107, -0.10543456673622131, -0.06628704816102982, -0.03179226443171501, -0.033293671905994415, 0.015584098175168037, -0.04237404838204384, 0.03200418874621391, -0.03617938607931137, 0.005883762147277594, -0.019844461232423782, -0.07378482073545456, 0.012136614881455898, -0.05361803621053696, -0.004012004006654024, -0.023281969130039215, -0.004391843918710947, -0.14197507500648499, -0.12163768708705902, 0.04670242592692375, -0.07892423123121262, -0.02556333690881729, -0.10886023938655853, 0.026249682530760765, -0.07453852146863937, 0.015921859070658684, -0.03150322660803795, 0.07353822141885757, -0.05611801519989967, -0.09366225451231003, 0.005614621099084616, 0.017899377271533012, 0.022154206410050392, 0.01281118392944336, 0.06112360581755638, 0.07357896119356155, 0.15207575261592865, -0.10463541001081467, 0.047653283923864365, 0.0038711833767592907, 0.03224408999085426, -0.017848005518317223, 0.11954479664564133, -0.01688380353152752, 0.13630293309688568, 0.0971483439207077, 0.06722494214773178, 0.03039580024778843, -0.096756711602211, 0.05663067102432251, 0.04101051390171051, -0.03061668761074543, 0.03479941561818123, -0.0899677649140358, 0.10443761199712753, -0.1339089572429657, -0.11258688569068909, 0.0685093104839325, 0.07088353484869003, -0.061176568269729614, -0.07827634364366531, -0.10197920352220535, -0.13643698394298553, 0.005644275341182947, 0.055152203887701035, -0.10219328105449677, -0.13059528172016144, 0.051702018827199936, -0.13111592829227448, -0.013949362561106682, 0.05822587385773659, -0.0077240681275725365, -0.11152691394090652, -1.154191013639129e-32, 0.04192298650741577, -0.07880324870347977, 0.013214225880801678, 0.07154905796051025, -0.021903999149799347, -0.060191575437784195, 0.004944275598973036, 0.11961942166090012, 0.009221137501299381, 0.035858914256095886, -0.006469536107033491, -0.11469411104917526, 0.007937023416161537, -0.043838925659656525, 0.061101965606212616, 0.13004380464553833, -0.03299781680107117, 0.03284468874335289, 0.14238043129444122, 0.03169577568769455, -0.1982559859752655, 0.2059684842824936, -0.16121332347393036, -0.0411674864590168, -0.1386072188615799, 0.022613096982240677, 0.03175777941942215, 0.06591884791851044, -0.136709064245224, -0.07624420523643494, -0.023883799090981483, 0.017147919163107872, -0.12125729769468307, 0.09587974101305008, -0.13230621814727783, 0.09637802094221115, 0.12316165119409561, 0.0002861777611542493, 0.022286541759967804, 0.0467555932700634, 0.25573810935020447, 0.018119147047400475, -0.174547016620636, 0.024064749479293823, -0.04818261042237282, 6.305283750407398e-05, -0.07501506060361862, 0.03717626631259918, -0.018920550122857094, -0.06826935708522797, 0.10518893599510193, 0.020077504217624664, -0.13123062252998352, 0.029842559248209, -0.0342581644654274, -0.0017081942642107606, 0.08542708307504654, -0.07676750421524048, -0.09083434194326401, 0.0054671927355229855, -0.02775689959526062, -0.21882563829421997, 0.06709595769643784, 0.04238789528608322, 0.033050213009119034, -0.05718925595283508, -0.04482709616422653, 0.061940498650074005, 0.10668833553791046, -0.026848401874303818, -0.08207564800977707, 0.1193063035607338, 0.09258952736854553, 0.06345286220312119, 0.013401421718299389, 0.11271888762712479, -0.029970742762088776, -0.03373018279671669, -0.05201834812760353, 0.027834631502628326, -0.16640140116214752, 0.020795606076717377, -0.008539818227291107, 0.07035306841135025, 0.03944692760705948, 0.015469088219106197, 0.06056609004735947, 0.14164790511131287, -0.003220310201868415, -0.057721350342035294, -0.026963593438267708, 0.02038712613284588, 0.021917596459388733, 0.17846137285232544, 0.06259500235319138, -1.0052598753418351e-07, -0.060135576874017715, 0.08192826062440872, -0.02693055011332035, 0.19744060933589935, -0.0052199894562363625, 0.12391182780265808, 0.024654565379023552, -0.06272441893815994, 0.07945013791322708, -0.043714139610528946, 0.09454029053449631, -0.01755739003419876, -0.0906287357211113, 0.026315120980143547, -0.029360288754105568, 0.09260088205337524, -0.03962051495909691, 0.012865452095866203, 0.0017844504909589887, -0.04630713909864426, 0.16089607775211334, -0.008521315641701221, 0.029943328350782394, -0.11369749158620834, 0.05059267580509186, -0.017983105033636093, -0.02108101360499859, 0.06824386864900589, -0.1628977209329605, -0.046974051743745804, -0.03809768706560135, -0.07511366903781891, 0.002484761644154787, 0.06931623071432114, 0.06560353189706802, 0.028780868276953697, 0.009482134133577347, -0.014024375937879086, -0.006607983261346817, 0.12102533131837845, 0.07120516896247864, 0.13570265471935272, -0.1731290966272354, 0.0016226702136918902, 0.11323890089988708, -0.05359690636396408, 0.013483475893735886, -0.030697347596287727, 0.12981881201267242, 0.08112210780382156, 0.06128373369574547, -0.026369059458374977, -0.025445638224482536, 0.042152635753154755, 0.04821950942277908, -0.03779470920562744, -0.052174605429172516, -0.09104908257722855, -0.12147844582796097, 0.04117957130074501, 0.10169149190187454, 0.0440681017935276, -0.007310399319976568, 0.048555027693510056], metadata={'source': 'AAAMLP-569to.pdf', 'page': 291}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 292         \"negative\": str(negative_prediction),         \"sentence\": str(sentence),         \"time_taken\": str(time.time() - start_time),     }     # we use jsonify from flask for dictionaries     return flask.jsonify(response)   if __name__ == \"__main__\":     # init the model     MODEL = BERTBaseUncased()      # load the dictionary     MODEL.load_state_dict(torch.load(         config.MODEL_PATH, map_location=torch.device(DEVICE)         ))          # send model to device     MODEL.to(DEVICE)          # put model in eval mode     MODEL.eval()      # start the application     # 0.0.0.0 means that this endpoint can be      # accessed from all computers in a network     app.run(host=\"0.0.0.0\") ═════════════════════════════════════════════════════════════════════════  And you start the API by running the command “python api.py”. The API will start on localhost on port 5000.  A sample cURL request and its response is shown as follows.  ═════════════════════════════════════════════════════════════════════════ ❯ curl $\\'http://192.168.86.48:5000/predict?sentence=this%20is%20the%20best%20book%20ever\\'  {\"response\":{\"negative\":\"0.0032927393913269043\",\"positive\":\"0.99670726\",\"sentence\":\"this is the best book ever\",\"time_taken\":\"0.029126882553100586\"}} ═════════════════════════════════════════════════════════════════════════'),\n",
       " VectorParams(vector=[-0.14154352247714996, 0.019789597019553185, -0.1247105598449707, 0.10879284143447876, 0.006481775548309088, -0.20518766343593597, 0.005490951240062714, 0.07228073477745056, 0.03396965563297272, -0.019890794530510902, -0.016817115247249603, -0.03709614649415016, -0.006460285279899836, -0.04717573523521423, 0.08338888734579086, -0.014857642352581024, 0.07951321452856064, -0.07734758406877518, -0.12764452397823334, -0.17824237048625946, 0.07185821980237961, 0.05170897766947746, 0.04487458989024162, 0.026202693581581116, -0.0528130978345871, -0.13845933973789215, -0.06257225573062897, 0.03898429870605469, -0.015744419768452644, 0.0045588137581944466, 0.06833938509225845, 0.02977512590587139, -0.11547289043664932, 0.05776558816432953, -0.06634823232889175, 0.09887271374464035, -0.06694216281175613, -0.14664143323898315, 0.013291023671627045, -0.007106272969394922, 0.0393269918859005, 0.04835440218448639, -0.09137171506881714, 0.013370174914598465, -0.025700768455863, -0.10850560665130615, -0.09173593670129776, -0.020821847021579742, 0.09257964044809341, -0.036250755190849304, -0.2159675508737564, 0.07478746771812439, -0.07751695811748505, -0.05122976005077362, -0.05565015599131584, -0.12478997558355331, -0.020741457119584084, -0.04769037291407585, -0.09413135796785355, -0.10667917877435684, -0.0433499813079834, -0.13531558215618134, -0.028352975845336914, -0.02170374058187008, 0.038199398666620255, -0.05371366813778877, -0.03387651592493057, -0.02786307968199253, 0.046170469373464584, 0.01904541626572609, -0.008373741991817951, 0.03138202428817749, -0.10496366024017334, 0.04521268606185913, 0.0031059079337865114, -0.07398542016744614, 0.053171306848526, -0.025151630863547325, 0.07079596072435379, -0.007674261927604675, -0.0319199375808239, -0.12229704856872559, 0.022213464602828026, 0.020432231947779655, 0.06071894243359566, -0.1382191777229309, 0.08114215731620789, 0.08381152898073196, 0.03702127933502197, -0.048984166234731674, 0.07409930974245071, -0.0032640539575368166, 0.09353291988372803, 0.05250263214111328, 0.09548231214284897, 0.13885000348091125, 0.1006661131978035, -0.07072636485099792, -0.12325390428304672, 0.21585561335086823, -0.04825923964381218, -0.04245533421635628, 0.1282147616147995, 0.019302625209093094, 0.001540450961329043, 0.02020573616027832, 0.04773559048771858, 0.09717502444982529, -0.018297558650374413, -0.21326345205307007, -0.07560969144105911, 0.053715985268354416, -0.026002218946814537, 0.011813814751803875, -0.02396094799041748, 0.07446349412202835, -0.00810724962502718, 0.011345616541802883, -0.021843964233994484, 0.2772422134876251, 0.033210717141628265, 0.11110316962003708, -0.05909841135144234, 0.04552062228322029, 0.028849532827734947, -0.03431105241179466, 0.061040446162223816, 1.514534986527061e-32, -0.021035367622971535, -0.01667926274240017, 0.02909998781979084, -0.14278976619243622, 0.037755321711301804, 0.02673102170228958, 0.006771067623049021, 0.07071806490421295, -0.09291281551122665, -0.08836809545755386, -0.03761494532227516, 0.02293057180941105, -0.018699897453188896, 0.04569843411445618, 0.010297097265720367, -0.04659676551818848, 0.03716154024004936, 0.0643065795302391, 0.1132269874215126, 0.049059923738241196, 0.1657423973083496, -0.030552193522453308, -0.052229613065719604, -0.060569774359464645, -0.06633121520280838, 0.0653984546661377, -0.04881120100617409, 0.014704682864248753, -0.1066829189658165, 0.06427226215600967, -0.03767191618680954, -0.027858778834342957, -0.14193080365657806, -0.06701306998729706, 0.029471108689904213, -0.07892897725105286, 0.026711007580161095, -0.05714195966720581, -0.02544855885207653, -0.12303919345140457, -0.10234900563955307, 0.09590926021337509, -0.03307818993926048, -0.01554756611585617, -0.16529227793216705, 0.04044061526656151, -0.06557995826005936, -0.008345278911292553, -0.08228015154600143, 0.08832266926765442, -0.032796651124954224, 0.023033661767840385, 0.03986931964755058, 0.021654538810253143, 0.003182149725034833, -0.006741303950548172, 0.07648799568414688, 0.08361383527517319, 0.15250444412231445, -0.011651878245174885, 0.04424954950809479, -0.052546124905347824, 0.0631859302520752, 0.03645515814423561, 0.0686955526471138, 0.0002108539192704484, 0.02582217939198017, 0.13906805217266083, 0.12679153680801392, 0.0916757881641388, -0.05723845958709717, 0.09554829448461533, 0.09437661617994308, -0.05775580182671547, 0.0192668829113245, -0.09357903152704239, 0.11576216667890549, -0.07632876187562943, -0.06717340648174286, -0.038881029933691025, 0.08995825797319412, -0.021845689043402672, -0.011414450593292713, -0.08335566520690918, -0.11844950914382935, 0.06703756004571915, 0.07577407360076904, -0.037929851561784744, -0.05289661884307861, -0.008584056980907917, -0.13609935343265533, -0.009636449627578259, 0.046384770423173904, -0.03425373509526253, -0.04784543812274933, -1.4597506314966068e-32, -0.015358969569206238, -0.07774079591035843, -0.029820231720805168, 0.06862810999155045, 0.013646763749420643, -0.02645179070532322, 0.013599719852209091, -0.004412668291479349, -0.008886502124369144, 0.010022473521530628, -0.02237933687865734, -0.03559926152229309, 0.04379996284842491, -0.033706098794937134, 0.04874391481280327, 0.08340883255004883, -0.035047437995672226, -0.001994410762563348, 0.09992394596338272, 0.042459968477487564, -0.21400578320026398, 0.18408404290676117, -0.08102913945913315, -0.037105742841959, -0.02082819677889347, 0.008413518778979778, -0.11272033303976059, -0.012664943933486938, -0.053160686045885086, -0.028696030378341675, -0.105751633644104, -0.03583047166466713, -0.12430324405431747, 0.005449180956929922, -0.025340989232063293, -0.0020670853555202484, 0.06469908356666565, 0.09687981009483337, 0.025766171514987946, 0.13665476441383362, 0.2490738183259964, -0.02313201315701008, -0.11692497879266739, -0.01406378298997879, -0.015963150188326836, 0.04960111156105995, -0.0458407998085022, -0.03609904646873474, -0.018257496878504753, 0.0297346543520689, 0.015121005475521088, 0.05057008937001228, -0.03308139741420746, 0.04836544767022133, -0.0605178028345108, -0.02205507457256317, 0.08464115858078003, -0.05191202089190483, -0.021232739090919495, -0.0014147410402074456, -0.09893554449081421, -0.09454650431871414, 0.029816865921020508, 0.027578331530094147, 0.09511587768793106, -0.0696602538228035, -0.17933110892772675, -0.024665983393788338, 0.10150887817144394, -0.037582144141197205, -0.09844785928726196, 0.017499670386314392, 0.060153279453516006, 0.032234061509370804, -0.01631917990744114, 0.1405525803565979, -0.006894239690154791, -0.026867737993597984, -0.05718936398625374, 0.06486804038286209, -0.0934174656867981, 0.07462399452924728, 0.003847698448225856, 0.010143487714231014, 0.002809900790452957, -0.08779541403055191, 0.11673793941736221, 0.0962093397974968, 0.0002886162546928972, -0.07380502671003342, -0.026341045275330544, 0.08883345872163773, 0.06278911978006363, 0.07922869920730591, 0.04791778326034546, -1.0034267461378477e-07, 0.010276805609464645, 0.02698630839586258, 0.003438187064602971, 0.22851966321468353, 0.07092331349849701, 0.0971325933933258, -0.06048554182052612, 0.020520253106951714, 0.029786327853798866, 0.04749612510204315, 0.14363761246204376, -0.011189349927008152, -0.05425691977143288, -0.014851003885269165, -0.03434262052178383, 0.1571623831987381, -0.08869951218366623, -0.021161772310733795, -0.04167120158672333, -0.02543885074555874, 0.09673503041267395, 0.0018221220234408975, 0.05101759359240532, -0.05354425311088562, 0.0005784754757769406, 0.0467577688395977, 0.035816896706819534, 0.08315213769674301, -0.13353018462657928, -0.0646507740020752, -0.12687237560749054, -0.06588274985551834, -0.10213413089513779, 0.05781673267483711, 0.08314726501703262, 0.042001932859420776, -0.05418313667178154, 0.008502064272761345, 0.029622098430991173, -0.03039500117301941, 0.015211704187095165, 0.027544522657990456, -0.10052616149187088, -0.004689718130975962, 0.17069900035858154, 0.001143586472608149, -0.0703265368938446, -0.04404926300048828, 0.15838760137557983, 0.04103366658091545, -0.00875652302056551, -0.013170424848794937, -0.012778918258845806, 0.04346655309200287, 0.12416249513626099, 0.03515205904841423, -0.0012208459665998816, -0.07934562116861343, -0.08342305570840836, 0.011546016670763493, 0.12514279782772064, 0.048815447837114334, -0.03741973266005516, -0.05430440232157707], metadata={'source': 'AAAMLP-569to.pdf', 'page': 292}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 293 As you can see that we got a high probability for positive sentiment for the provided input sentence. You can also access the results by visiting http://127.0.0.1:5000/predict?sentence=this%20book%20is%20too%20complicated%20for%20me in your favourite browser. This will return a JSON again.  ═════════════════════════════════════════════════════════════════════════ {     response: {         negative: \"0.8646619468927383\",         positive: \"0.13533805\",         sentence: \"this book is too complicated for me\",         time_taken: \"0.03852701187133789\"         } } ═════════════════════════════════════════════════════════════════════════  Now, we have created a simple API that we can use to serve a small number of users. Why small? Because this API will serve only one request at a time. Let’s use CPU and make it work for many parallel requests using gunicorn which is a python WSGI HTTP server for UNIX. Gunicorn can create multiple processes for the API, and thus, we can serve many customers at once. You can install gunicorn by using “pip install gunicorn”.  To convert the code compatible with gunicorn, we need to remove init main and move everything out of it to the global scope. Also, we are now using CPU instead of the GPU. See the modified code as follows.  ═════════════════════════════════════════════════════════════════════════ # api.py import config import flask import time import torch import torch.nn as nn from flask import Flask from flask import request from model import BERTBaseUncased  app = Flask(__name__)  # now we use cpu! DEVICE = \"cpu\"  # init the model'),\n",
       " VectorParams(vector=[-0.13287889957427979, -0.03399832546710968, -0.07723848521709442, 0.13811342418193817, 0.10470183938741684, -0.12914936244487762, -0.05153239518404007, 0.02790360152721405, -0.058416955173015594, -0.06792151927947998, -0.06654854863882065, -0.006394555792212486, -0.07701460272073746, 0.04334086552262306, 0.06285981833934784, 0.045309100300073624, 0.09401297569274902, 0.001705989707261324, -0.030901454389095306, -0.12183593958616257, 0.10119153559207916, 0.07486790418624878, 0.09374924004077911, 0.034928590059280396, -0.07409261912107468, -0.09250232577323914, 0.01556229218840599, 0.08780103176832199, -0.032355546951293945, 0.043541572988033295, 0.04221085086464882, -0.012567056342959404, -0.19019633531570435, 0.04038682207465172, 0.07420755177736282, 0.07664979249238968, -0.04241391643881798, -0.15799038112163544, -0.04443829506635666, -0.022441834211349487, 0.10955285280942917, 0.02249911054968834, -0.09014645218849182, -0.009632556699216366, -0.030950510874390602, -0.08182334899902344, -0.05260109156370163, -0.03735953941941261, -0.020760906860232353, -0.08646322041749954, -0.1683335155248642, 0.07306025177240372, -0.018995093181729317, -0.004282524809241295, -0.07907849550247192, -0.053272370249032974, 0.048481788486242294, -0.029937289655208588, 0.013353120535612106, -0.168564572930336, 0.04276718944311142, -0.10758659988641739, -0.06782139092683792, -0.001678095431998372, -0.06274647265672684, 0.042734187096357346, -0.014098569750785828, 0.028630901128053665, 0.12649968266487122, 0.01657944917678833, 0.06091805174946785, 0.008359909988939762, -0.02515632100403309, -0.05964919552206993, 0.010794018395245075, 0.038512833416461945, 0.10337945818901062, -0.018697062507271767, 0.01796436309814453, -0.008836648426949978, -0.005721647758036852, -0.14141945540905, 0.09159659594297409, -0.0033733078744262457, 0.046679504215717316, -0.10876764357089996, 0.02703295275568962, 0.0350542888045311, 0.10365495085716248, -0.05555613338947296, -0.029089050367474556, -0.08298243582248688, -0.002798474160954356, -0.04975476488471031, 0.09115045517683029, 0.05346531793475151, 0.12664175033569336, -0.12261336296796799, -0.13575567305088043, 0.15874864161014557, -0.08318790048360825, -0.12175065279006958, 0.09343962371349335, -0.0011726153315976262, 0.1287410855293274, 0.07550878077745438, -0.06551005691289902, -0.0332665778696537, -0.009511711075901985, -0.09692718088626862, -0.0032888087444007397, 0.024095788598060608, -0.011315066367387772, 0.016016146168112755, 0.004605765454471111, 0.1037646234035492, -0.11836248636245728, 0.04343225806951523, -0.07659245282411575, 0.2602013349533081, 0.045121919363737106, 0.061322737485170364, 0.0669148787856102, 0.054916899651288986, 0.027125079184770584, -0.037526145577430725, -0.028942877426743507, 5.953284527583752e-33, 0.022255973890423775, -0.10428597033023834, 0.034362953156232834, -0.1329122930765152, 0.1527135670185089, 0.009862028993666172, 0.08190356940031052, -0.022283928468823433, -0.0723671019077301, -0.04216699302196503, -0.10084455460309982, 0.11688396334648132, 0.0020978518296033144, 0.03109859488904476, -0.024380145594477654, -0.009611722081899643, 0.0020830673165619373, 0.11033464968204498, 0.07691968977451324, 0.12371190637350082, 0.14061318337917328, -0.07248735427856445, -0.10221369564533234, -0.14116354286670685, -0.061836592853069305, 0.06669553369283676, -0.03320322930812836, -0.0013401798205450177, -0.09979421645402908, 0.09917107969522476, -0.07215263694524765, 0.03773870691657066, 0.0028187998104840517, 0.024329831823706627, -0.06574464589357376, -0.10472496598958969, -0.008888566866517067, -0.12194441258907318, -0.03550928086042404, -0.11488436162471771, -0.04785462096333504, 0.014164630323648453, -0.04682391136884689, -0.06548052281141281, -0.1585802137851715, -0.04175800830125809, -0.08739911019802094, -0.01806202344596386, -0.048307809978723526, 0.044682975858449936, -0.03549720719456673, -0.06558042019605637, -0.011907326988875866, 0.01504830364137888, -0.01611698418855667, -0.058557018637657166, -0.003649494843557477, 0.036103520542383194, 0.2725798785686493, -0.08102776855230331, 0.03032347373664379, -0.03525371477007866, 0.005451429169625044, 0.0052987211383879185, 0.10846330225467682, 0.04377955570816994, 0.003035159083083272, 0.16587652266025543, 0.11901186406612396, 0.048079460859298706, -0.02424246072769165, 0.07981513440608978, 0.0988534614443779, -0.009780432097613811, 0.11470966041088104, -0.009494778700172901, 0.0894588828086853, -0.14444738626480103, -0.12210944294929504, -0.008828013204038143, 0.026007678359746933, 0.03439990058541298, -0.0721946582198143, 0.03390409052371979, -0.08600905537605286, -0.0007412500563077629, 0.011256256140768528, -0.06632531434297562, -0.14021457731723785, 0.10484154522418976, -0.19469420611858368, -0.08449986577033997, 0.07191107422113419, 0.013237272389233112, -0.13802596926689148, -7.47294819596345e-33, 0.02262907102704048, -0.03251834958791733, -0.08425113558769226, 0.08370818942785263, -0.020657720044255257, -0.02908315695822239, 0.09568078070878983, 0.0021021722350269556, -0.04124699905514717, -0.03562501072883606, -0.11899630725383759, -0.05125109478831291, 0.02455834671854973, 0.0474967360496521, 0.041329678148031235, 0.13968685269355774, -0.08223827928304672, -0.0196510199457407, 0.12236864119768143, 0.06982507556676865, -0.1661052703857422, 0.1344209909439087, -0.10948839783668518, 0.04870723560452461, -0.13990193605422974, 0.011896663345396519, -0.04518638178706169, -0.059458475559949875, -0.10655331611633301, -0.04639541357755661, -0.00905907154083252, 0.07721398025751114, -0.13107435405254364, -0.013732188381254673, -0.0824015811085701, 0.10203007608652115, 0.1364806890487671, 0.06785431504249573, 0.016211312264204025, 0.13011400401592255, 0.25109294056892395, -0.06422378122806549, -0.18576233088970184, 0.021961331367492676, -0.040252067148685455, -0.0025012586265802383, -0.030759675428271294, -0.06453070044517517, 0.008800544776022434, -0.0456065908074379, 0.007493740878999233, 0.05453164875507355, -0.16947083175182343, 0.08930600434541702, -0.1374233216047287, -0.06345684081315994, 0.07530529797077179, -0.06674647331237793, -0.15426239371299744, 0.09356958419084549, 0.047506123781204224, -0.14135585725307465, 0.0799032673239708, 0.02978537045419216, 0.11448092758655548, -0.03917025774717331, -0.14321205019950867, 0.05269462242722511, 0.12205028533935547, 0.04397648200392723, -0.031100977212190628, 0.09315408021211624, 0.17207112908363342, 0.164284810423851, 0.04315495863556862, 0.1389714479446411, -0.030695507302880287, -0.17612987756729126, -0.011966494843363762, 0.07340922951698303, -0.1381532847881317, -0.02064664661884308, -0.0033969709184020758, -0.0005189815419726074, 0.03881038352847099, -0.05527205765247345, 0.11713185161352158, 0.18268945813179016, 0.08372963219881058, -0.06594707071781158, -0.015589319169521332, -0.014562012627720833, 0.007360259536653757, 0.1084405928850174, 0.0011356158647686243, -9.983092041920827e-08, 0.060149360448122025, 0.10807497054338455, 0.015377890318632126, 0.25443822145462036, -0.14305195212364197, 0.08429912477731705, 0.08414898067712784, 0.0327378511428833, 0.02503591775894165, -0.058741483837366104, 0.056508541107177734, -0.039048679172992706, -0.03761426731944084, 0.06774669140577316, -0.010712702758610249, 0.1927703320980072, -0.0019791682716459036, 0.06554315239191055, -0.07395186275243759, -0.12692642211914062, 0.0357569120824337, 0.03023330308496952, 0.02003452181816101, -0.05443354323506355, -0.05368475615978241, 0.018562396988272667, 0.03225143998861313, 0.058606743812561035, -0.13500341773033142, 0.027749180793762207, -0.08215683698654175, -0.09221458435058594, -0.1240810826420784, 0.1315687596797943, 0.035014327615499496, 0.028052255511283875, -0.021810676902532578, -0.046609651297330856, 0.125211700797081, 0.057681646198034286, -0.03840746358036995, 0.0579407699406147, -0.18225347995758057, -0.02270919643342495, 0.17027610540390015, 0.011403943412005901, -0.044632766395807266, -0.06328391283750534, 0.10508642345666885, 0.11270463466644287, -0.003726710332557559, 0.019413087517023087, -0.10771584510803223, 0.08669344335794449, 0.24096165597438812, 0.017648298293352127, -0.05638889595866203, -0.10066408663988113, -0.0356692411005497, 0.022084645926952362, -0.0012054599355906248, 0.010444694198668003, 0.00642519211396575, -0.0013628540327772498], metadata={'source': 'AAAMLP-569to.pdf', 'page': 293}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 294 MODEL = BERTBaseUncased()  # load the dictionary MODEL.load_state_dict(torch.load(     config.MODEL_PATH, map_location=torch.device(DEVICE)     ))  # send model to device MODEL.to(DEVICE)  # put model in eval mode MODEL.eval()   def sentence_prediction(sentence):     \"\"\"     A prediction function that takes an input sentence     and returns the probability for it being associated     to a positive sentiment     \"\"\"     .     .     .     return outputs[0][0]   @app.route(\"/predict\", methods=[\"GET\"]) def predict():     # this is our endpoint!     .     .     .     return flask.jsonify(response) ═════════════════════════════════════════════════════════════════════════  And we run this API using the following command.  $ gunicorn api:app --bind 0.0.0.0:5000 --workers 4  This means we are running our flask app with 4 workers on a provided IP address and port. Since there are 4 workers, we are now serving 4 simultaneous requests. Please note that now our endpoint uses CPU and thus, it does not need a GPU machine and can run on any standard server/VM. Still, we have one problem, we have done everything in our local machine, so we must dockerize it. Take a look at the following uncommented Dockerfile which can be used to deploy this API.'),\n",
       " VectorParams(vector=[-0.02970261313021183, 0.07477919012308121, -0.07642903923988342, -0.0327010415494442, 0.004354728851467371, -0.16702744364738464, -0.03878055140376091, 0.06818921118974686, -0.03927884250879288, 0.044236622750759125, -0.01208419632166624, -0.10639790445566177, 0.062284573912620544, -0.08351575583219528, 0.025442123413085938, -0.06397762894630432, 0.01195882074534893, 0.05532833933830261, -0.0648864135146141, -0.1144099235534668, -0.04922862723469734, 0.043475840240716934, 0.04543643072247505, -0.011271265335381031, -0.12517884373664856, -0.02146836929023266, -0.06933928281068802, -0.12200073152780533, -0.10475024580955505, -0.018243635073304176, 0.06243714317679405, 0.004371794871985912, 0.0011954170186072588, -0.07272199541330338, 0.08173348754644394, 0.2454158365726471, 0.023054176941514015, 0.0015273003373295069, -0.08616872131824493, -0.021521735936403275, 0.1073584109544754, -0.011115310713648796, -0.07307165116071701, -0.03784671798348427, -0.10391979664564133, -0.03261797875165939, -0.14681939780712128, -0.12704665958881378, 0.0591869093477726, 0.0524701364338398, -0.1921800673007965, -0.003983772825449705, -0.011247572489082813, 0.0012718777870759368, -0.031402792781591415, 0.04662333428859711, 0.05869726464152336, 0.1658356636762619, 0.0016368497163057327, -0.051697541028261185, -0.06856393814086914, 0.019741127267479897, 0.04475713521242142, -0.056463029235601425, 0.08526191115379333, -0.11232322454452515, -0.019088249653577805, -0.07142632454633713, 0.08126303553581238, 0.013103559613227844, 0.009790288284420967, -0.014641785062849522, -0.11626508086919785, -0.12883983552455902, 0.014123699627816677, -0.09686853736639023, 0.044503502547740936, 0.09808564931154251, -0.13135400414466858, -0.17192183434963226, -0.05831223353743553, -0.026004621759057045, -0.016179442405700684, -0.06349238008260727, -0.14882013201713562, 0.0929073616862297, 0.01853259652853012, 0.009144012816250324, 0.11786136031150818, -0.17794586718082428, 0.15518148243427277, -0.043791648000478745, -0.11411774158477783, -0.029780667275190353, 0.21525385975837708, 0.027964524924755096, -0.031784120947122574, 0.1579466164112091, -0.09628668427467346, 0.14221613109111786, -0.09241355210542679, -0.10550986230373383, -0.010459426790475845, 0.07541953027248383, 0.18253567814826965, 0.07108601182699203, -0.021095503121614456, -0.10658956319093704, -0.04986366257071495, -0.09567609429359436, 0.03200145438313484, -0.07680042088031769, -0.03100801631808281, 0.08289314061403275, 0.02506628818809986, 0.07616055756807327, -0.03344212472438812, -0.1000380888581276, -0.004267598502337933, 0.20057564973831177, 0.1368965059518814, -0.07875708490610123, 0.1156250461935997, 0.02966173179447651, -0.07239724695682526, -0.05273251235485077, 0.034814175218343735, 8.75433034322384e-33, -0.007727408315986395, -0.17429962754249573, 0.10690618306398392, -0.028188742697238922, 0.17446094751358032, -0.0917695015668869, 0.19206438958644867, 0.08148503303527832, -0.04687599465250969, -0.0029846339020878077, -0.11847979575395584, 0.0751148983836174, -0.0576663464307785, 0.04994487389922142, 0.013206538744270802, -0.08058016747236252, -0.11190281808376312, 0.03657999262213707, -0.023180577903985977, 0.02553580328822136, 0.2083459347486496, -0.036179959774017334, -0.12857870757579803, -0.058768678456544876, 0.09209491312503815, -0.08329295367002487, 0.05467613413929939, -0.045295991003513336, -0.04076836630702019, 0.0765070915222168, -0.0011865183478221297, 0.012349610216915607, -0.07929158955812454, -0.015136344358325005, -0.06837780773639679, -0.09296703338623047, 0.01717982441186905, 0.05403649061918259, -0.130165696144104, -0.02051445096731186, -0.027470774948596954, -0.028035368770360947, 0.017808714881539345, -0.06430213898420334, -0.005874421913176775, -0.12654122710227966, -0.019472286105155945, 0.012922816909849644, -0.042036931961774826, 0.1578366756439209, 0.12155177444219589, -0.05737367272377014, -0.04068577662110329, -0.04096102714538574, -0.025747617706656456, -0.04306156933307648, -0.04882636293768883, -0.011620230041444302, 0.06191703677177429, -0.0026176117826253176, -0.0719153955578804, 0.031777240335941315, 0.02769598923623562, 0.15924203395843506, 0.04810521379113197, 0.07743613421916962, -0.014250149019062519, 0.09145867079496384, 0.15452364087104797, 0.16505752503871918, -0.07740449160337448, 0.056514255702495575, 0.06840839982032776, 0.07874300330877304, 0.08009506016969681, -0.0009897819254547358, 0.04267938435077667, -0.0762706845998764, -0.1169906035065651, -0.07072242349386215, 0.031415536999702454, 0.1340925693511963, -0.0723189190030098, -0.08226396888494492, -0.04202042520046234, -0.0004667156608775258, 0.038315873593091965, 0.03945106640458107, -0.0438818633556366, 0.03316790983080864, 0.02663479559123516, 0.02707108110189438, -0.05976184457540512, -0.04059353843331337, -0.16060693562030792, -1.0185611530101088e-32, 0.10524743795394897, 0.0010943833040073514, -0.032712217420339584, 0.03515760600566864, 0.014440569095313549, 0.008293621242046356, 0.16843481361865997, -0.027977587655186653, 0.01563635654747486, -0.016421392560005188, -0.20264025032520294, 0.040415871888399124, 0.10184689611196518, 0.10819720476865768, -0.009357246570289135, 0.1737939566373825, -0.09867823123931885, -0.04108023643493652, 0.0024170998949557543, 0.019510196521878242, -0.06372490525245667, 0.12031929939985275, 0.06665695458650589, 0.03818017616868019, -0.05967674404382706, -0.013852104544639587, -0.003693319158628583, 0.09639737755060196, -0.03294891119003296, -0.06234859302639961, -0.04935120791196823, 0.038835491985082626, -0.16045540571212769, 0.08055934309959412, -0.03972630202770233, 0.023465968668460846, -0.06900805979967117, 0.2502363324165344, -0.07599156349897385, 0.0709218680858612, 0.1161726787686348, -0.08303800225257874, -0.05540132150053978, -0.019318697974085808, 0.0013914111768826842, -0.044748324900865555, -0.005177123937755823, -0.0989672914147377, -0.15515226125717163, -0.04480845853686333, 0.051155369728803635, -0.07001256197690964, 0.008188546635210514, 0.1220768392086029, -0.06077924743294716, 0.006465911865234375, 0.18097686767578125, 0.059052105993032455, -0.14554540812969208, 0.05473591759800911, 0.1082863137125969, -0.06606552749872208, 0.1280188411474228, 0.08143041282892227, 0.03145371749997139, 0.0027404960710555315, -0.1521977037191391, 0.00021392434427980334, -0.07376264035701752, 0.11564311385154724, 0.020219800993800163, -0.011806987226009369, 0.05288710072636604, 0.01781892590224743, -0.02152482233941555, 0.1365133374929428, -0.07133489847183228, -0.11498656868934631, -0.023918522521853447, 0.09310293942689896, -0.17352195084095, 0.08120384067296982, 0.04421805962920189, -0.03285897523164749, -0.117083340883255, 0.009363692253828049, 0.11801750957965851, 0.04701206088066101, 0.06042475998401642, -0.09175456315279007, 0.09079606086015701, -0.06999941915273666, -0.028636155650019646, -0.004937912803143263, 0.08246751874685287, -1.003069058924666e-07, 0.1084345132112503, 0.011696948669850826, -0.06151478365063667, 0.2105291336774826, 0.038587551563978195, -0.006525023374706507, 0.0037091306876391172, 0.0835171788930893, -0.04912462458014488, -0.038852207362651825, -0.031981974840164185, -0.055017754435539246, -0.06641118973493576, 0.04494239389896393, 0.0523386225104332, 0.098723866045475, 0.060798246413469315, -0.016350209712982178, -0.0761178582906723, -0.12488562613725662, -0.004735604394227266, 0.011770159937441349, 0.0285759549587965, 0.007452299352735281, -0.0765703096985817, -0.015129189006984234, 0.08708379417657852, -0.020336853340268135, -0.07440973818302155, -0.018655335530638695, -0.058232374489307404, -0.06807862967252731, -0.14500738680362701, 0.058776985853910446, 0.12196701020002365, -0.013486144132912159, -0.09404509514570236, 0.014601817354559898, -0.022975986823439598, 0.08841775357723236, -0.11882635205984116, -0.03569411486387253, 0.01611495390534401, -0.09551223367452621, 0.1054210513830185, -0.017111174762248993, -0.09302181750535965, -0.0697331354022026, 0.017490370199084282, 0.046843208372592926, 0.05764620751142502, -0.00671105831861496, -0.004201321396976709, 0.03082890994846821, 0.18722403049468994, 0.08197304606437683, -0.0568404346704483, -0.11211758106946945, -0.03591560944914818, 0.020164666697382927, 0.04466188699007034, 0.1406884640455246, 0.14744411408901215, 0.10445913672447205], metadata={'source': 'AAAMLP-569to.pdf', 'page': 294}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 295 Notice the difference between the old Dockerfile for training and this one. There are not many differences.  ═════════════════════════════════════════════════════════════════════════ # CPU Dockerfile FROM ubuntu:18.04  RUN apt-get update && apt-get install -y \\\\     git \\\\     curl \\\\     ca-certificates \\\\     python3 \\\\     python3-pip \\\\     sudo \\\\     && rm -rf /var/lib/apt/lists/*  RUN useradd -m abhishek  RUN chown -R abhishek:abhishek /home/abhishek/  COPY --chown=abhishek *.* /home/abhishek/app/  USER abhishek RUN mkdir /home/abhishek/data/  RUN cd /home/abhishek/app/ && pip3 install -r requirements.txt RUN pip3 install mkl  WORKDIR /home/abhishek/app ═════════════════════════════════════════════════════════════════════════  Let’s build a new docker container.  $ docker build -f Dockerfile -t bert:api .  When the docker container is built, we can now run the API directly by using the following command.  $ docker run -p 5000:5000 -v /home/abhishek/workspace/approaching_almost/input/:/home/abhishek/data/ -ti bert:api /home/abhishek/.local/bin/gunicorn api:app --bind 0.0.0.0:5000 --workers 4  Please note that we expose port 5000 from the container to 5000 outside the container. This can also be done in a nice way if you use docker-compose. Docker'),\n",
       " VectorParams(vector=[-0.07153156399726868, -0.08019252866506577, 0.02612178772687912, 0.028797049075365067, 0.02201152965426445, -0.13493749499320984, -0.069251149892807, 0.0845896303653717, -0.05586358159780502, 0.06754336506128311, -0.045518483966588974, -0.07419199496507645, 0.10081261396408081, -0.0569111704826355, 0.15504102408885956, -0.07404732704162598, 0.19147861003875732, 0.013785470277071, -0.04153401777148247, -0.03100358135998249, -0.039541296660900116, 0.0800338089466095, 0.005530349910259247, 0.024087322875857353, -0.07738883793354034, -0.0527166984975338, -0.01594739966094494, -0.06085386499762535, -0.10780951380729675, -0.08488583564758301, -0.023847103118896484, 0.0826936811208725, -0.021416936069726944, 0.040800340473651886, 0.055223822593688965, 0.22419868409633636, 0.06770633161067963, -0.07580529898405075, -0.0933966338634491, -0.06585860252380371, 0.08507321029901505, -0.06715245544910431, -0.087689608335495, -0.09566445648670197, -0.045991528779268265, -0.17416076362133026, -0.1067899763584137, -0.1579570174217224, 0.09661978483200073, 0.04422323405742645, -0.20364534854888916, -0.1578255593776703, -0.08832629770040512, 0.03527329862117767, -0.009649110026657581, -0.0003256285563111305, 0.021524915471673012, 0.03794636204838753, 0.0461861789226532, 0.02670341357588768, -0.004427468404173851, 0.027769578620791435, 0.024278363212943077, 0.023546768352389336, 0.06380251049995422, -0.09531071037054062, -0.004759840667247772, 0.0030469160992652178, 0.10158883035182953, -0.08154024183750153, 0.02548118680715561, 0.009489960968494415, -0.026003092527389526, -0.1039198637008667, -0.10418307036161423, -0.04719997197389603, 0.10842669010162354, 0.022709401324391365, -0.07465250790119171, -0.043018825352191925, -0.013462288305163383, 0.09438636898994446, 0.04248671978712082, 0.04244060069322586, -0.18394379317760468, -0.0006819143891334534, -0.02909846231341362, 0.019021648913621902, 0.085159532725811, -0.15042972564697266, 0.09041823446750641, -0.09186407923698425, -0.04434267431497574, -0.048846784979104996, 0.12680676579475403, 0.03538285195827484, 0.056990738958120346, -0.04384712874889374, -0.03901797533035278, 0.12772491574287415, -0.06022593379020691, -0.11416000127792358, 0.043766915798187256, -0.061479464173316956, 0.22028031945228577, 0.026810824871063232, -0.046088289469480515, -0.0769876092672348, -0.024776587262749672, -0.03746446967124939, -0.03056490793824196, -0.02666078880429268, -0.16640566289424896, -0.0013180896639823914, -0.017338357865810394, 0.05302441120147705, -0.0006941105239093304, -0.08227236568927765, -0.0028252778574824333, 0.14355787634849548, 0.13938239216804504, -0.01851838454604149, 0.08163884282112122, -0.003497408702969551, 0.014801092445850372, -0.038824744522571564, 0.0020353104919195175, 7.475261715782663e-33, 0.07627594470977783, -0.1600857675075531, 0.10945809632539749, 0.03881780430674553, 0.27006304264068604, -0.09760571271181107, 0.07851409912109375, -0.04708053171634674, -0.03570391237735748, -0.09149596840143204, -0.05155520141124725, 0.18783321976661682, -0.07559860497713089, 0.09235744923353195, 0.028034504503011703, -0.1333192139863968, -0.11517739295959473, 0.10357512533664703, 0.1298067718744278, 0.02676421031355858, 0.05687687546014786, -0.1376924216747284, -0.16931051015853882, -0.049954853951931, 0.11758081614971161, -0.04810285195708275, 0.04610064625740051, -0.06816065311431885, -0.07814236730337143, 0.0561562217772007, -0.019977129995822906, 0.007084406912326813, -0.038954250514507294, 0.09122541546821594, -0.11479818820953369, -0.1706145703792572, -0.10352773219347, -0.01789897494018078, -0.14511334896087646, -0.027346115559339523, 0.006692945957183838, -0.029164709150791168, -0.11453327536582947, -0.06090620160102844, 0.007147188298404217, -0.011507770977914333, 0.0011041865218430758, 0.026081284508109093, 0.07957582175731659, 0.007041978649795055, 0.13989554345607758, -0.08731745928525925, 0.03480943664908409, 0.002677489072084427, 0.0012895556865260005, 0.025052186101675034, 0.018612025305628777, -0.11438533663749695, 0.09349261224269867, -0.09054044634103775, -0.0837341770529747, -0.021797306835651398, -0.0037167351692914963, 0.08855801075696945, 0.03884722292423248, 0.06353795528411865, -0.010118184611201286, 0.10101445019245148, 0.1256805807352066, 0.09973825514316559, -0.06571613252162933, 0.05984114855527878, 0.021328076720237732, 0.054383162409067154, 0.10120329260826111, -0.06842602789402008, 0.0341341532766819, -0.06266418844461441, -0.12234801799058914, 0.07150325924158096, 0.0022168783470988274, 0.14355111122131348, -0.19570192694664001, 0.09771916270256042, 0.011798208579421043, -0.020613456144928932, 0.14070963859558105, 0.004755019675940275, -0.10097698867321014, 0.007850113324820995, -0.03769097477197647, -0.022403599694371223, -0.041460949927568436, -0.07010041177272797, -0.1859535127878189, -8.373994737911474e-33, 0.07703982293605804, -0.03613311052322388, -0.08424419909715652, 0.07583034038543701, -0.029615268111228943, -0.08234433829784393, 0.17396694421768188, 0.08533862233161926, -0.08690910786390305, -0.13715019822120667, -0.12720465660095215, 0.06356597691774368, -0.001776617020368576, -0.01954248920083046, -0.19587329030036926, 0.1300295889377594, -0.09953953325748444, -0.05608116090297699, 0.002831052988767624, 0.018697001039981842, -0.1335790753364563, 0.07593409717082977, 0.057306304574012756, -0.01253139041364193, -0.07876446843147278, -0.020174644887447357, -0.00095377117395401, 0.07176278531551361, -0.09573208540678024, -0.058909907937049866, -0.039543140679597855, 0.011902684345841408, -0.02129748836159706, 0.015927907079458237, -0.008968431502580643, 0.07256805896759033, -0.015833966434001923, 0.16574552655220032, -0.012356754392385483, -0.02788415737450123, 0.15261593461036682, -0.1255941390991211, -0.11648613214492798, -0.0221622996032238, -0.08333060145378113, -0.045720938593149185, 0.02356206625699997, -0.05818696320056915, -0.022723346948623657, -0.07482393831014633, -0.04130776226520538, -0.07865409553050995, -0.08777277171611786, 0.06084691733121872, -0.05440029874444008, 0.03731837868690491, 0.07400467991828918, 0.022040314972400665, -0.11256607621908188, 0.10112427175045013, 0.10334053635597229, -0.12252824008464813, 0.13325326144695282, 0.09594421088695526, 0.05563103407621384, 0.010631493292748928, -0.14835041761398315, -0.01872730441391468, -0.13867542147636414, 0.11196117103099823, 0.04490112513303757, -0.02780728042125702, 0.10032491385936737, 0.122043676674366, 0.018975768238306046, -0.0793694257736206, 0.043533727526664734, -0.10050371289253235, -0.008309129625558853, 0.03987063467502594, -0.07728621363639832, 0.06444977223873138, -0.05353453755378723, 0.0027588186785578728, -0.024303633719682693, 0.029925623908638954, 0.1831820160150528, 0.12563933432102203, 0.10014496743679047, 0.013345921412110329, -0.003519064746797085, 0.01692890003323555, -0.026386428624391556, 0.11731639504432678, 0.06585521996021271, -9.97135387592607e-08, 0.03672302886843681, 0.09334763139486313, 0.016306698322296143, 0.17867696285247803, -0.069920115172863, 0.05512642860412598, 0.1084124967455864, 0.02679995447397232, 0.03824285790324211, 0.06779159605503082, -0.04561678692698479, 0.053731903433799744, -0.10189826786518097, 0.09219606965780258, 0.023170866072177887, 0.19698607921600342, 0.10215824842453003, 0.03946368396282196, -0.06458833068609238, -0.14787665009498596, 0.0017996430397033691, 0.025536000728607178, 0.11119353026151657, -0.052444279193878174, 0.011392742395401001, 0.11857245862483978, -0.02276409976184368, -0.012125765904784203, 0.04610471427440643, 0.005750101059675217, -0.025352882221341133, -0.07628390192985535, -0.11674715578556061, 0.12849055230617523, 0.03958793729543686, -0.05093291401863098, -0.12631645798683167, -0.017696348950266838, 0.06248530000448227, 0.07158134877681732, -0.05200846493244171, 0.009876416996121407, -0.012923994101583958, -0.12950563430786133, 0.11301389336585999, 0.01658814027905464, -0.03889428824186325, 0.011394667439162731, -0.020034752786159515, 0.14572331309318542, 0.04664524272084236, -0.038292258977890015, 0.030202843248844147, 0.06889095902442932, 0.20032942295074463, 0.09825000166893005, 0.03120657429099083, -0.05165867879986763, 0.08243826776742935, 0.13244622945785522, -0.05153345316648483, 0.09951959550380707, 0.12932921946048737, 0.0809956043958664], metadata={'source': 'AAAMLP-569to.pdf', 'page': 295}, content=\"Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 296 compose is a tool that can allow you to run different services from different or the same containers at the same time. You can install docker-compose using “pip install docker-compose” and then run “docker-compose up” after building the container. To use docker-compose, you need a docker-compose.yml file.  ═════════════════════════════════════════════════════════════════════════ # docker-compose.yml # specify a version of the compose version: '3.7'  # you can add multiple services services:   # specify service name. we call our service: api    api:     # specify image name     image: bert:api     # the command that you would like to run inside the container     command: /home/abhishek/.local/bin/gunicorn api:app --bind 0.0.0.0:5000 --workers 4     # mount the volume     volumes:       - /home/abhishek/workspace/approaching_almost/input/:/home/abhishek/data/     # this ensures that our ports from container will be      # exposed as it is     network_mode: host ═════════════════════════════════════════════════════════════════════════  Now you can rerun the API just by using the command mentioned above, and it will work the same way as before. Congratulations! Now you have managed to dockerized the prediction API too, and it is ready for deployment anywhere you want. In this chapter, we learned docker, building APIs using flask, serving API using gunicorn and docker and docker-compose. There is a lot more to docker than we have seen here, but this should give you a start. Rest can be learned as you progress. We have also skipped on many tools like kubernetes, bean-stalk, sagemaker, heroku and many others that people use these days for deploying models in production. “What am I going to write? Click on modify docker container in figure X”? It’s not feasible and advisable to describe these in a book, so I will be using a different medium complimenting this part of the book. Remember that once you have dockerized your application, deploying using any of these technologies/platforms is a piece of cake. Always remember to make your code and model usable and well-documented for others so that anyone can use what you have developed without asking you several times. This will save you time, and it will\"),\n",
       " VectorParams(vector=[-0.27770063281059265, -0.11709638684988022, -0.07561688125133514, 0.050558846443891525, 0.14973239600658417, -0.028480758890509605, -0.09364715963602066, -0.10721106827259064, -0.30347394943237305, -0.06820391118526459, -0.09950413554906845, 0.16377384960651398, -0.03624408319592476, -0.11110881716012955, -0.03434333950281143, 0.19509382545948029, 0.029182206839323044, 0.2759007215499878, 0.061807166785001755, -0.3074134588241577, -0.2683020234107971, -0.0610848069190979, 0.10473223775625229, 0.04915314167737961, 0.020994560793042183, -0.05385296046733856, 0.2749447822570801, 0.16966690123081207, -0.009398361667990685, -0.06767150014638901, -0.010234207846224308, 0.0008127369801513851, 0.012621192261576653, -0.032026708126068115, -0.12059075385332108, 0.21163438260555267, -0.20915167033672333, 0.09995275735855103, 0.02287299372255802, 0.051201894879341125, -0.14239515364170074, 0.07754981517791748, 0.08790399134159088, -0.02143775299191475, 0.3082362711429596, 0.0016325698234140873, -0.054510295391082764, -0.08917740732431412, 0.1368071436882019, -0.0795978531241417, -0.2564427852630615, -0.24319718778133392, -0.10500846058130264, -0.11539561301469803, -0.2100803107023239, -0.1457478404045105, 0.042536862194538116, -0.32822635769844055, -0.043567951768636703, -0.22548551857471466, 0.11020531505346298, -0.06000373512506485, -0.03770321607589722, -0.0017978156683966517, 0.021748563274741173, 0.1015511006116867, -0.0279519185423851, 0.29929155111312866, 0.03628286346793175, -0.016983307898044586, -0.014376256614923477, 0.1480260193347931, -0.17802652716636658, 0.3291705846786499, 0.021367689594626427, -0.008415243588387966, 0.04088781774044037, -0.059565894305706024, 0.1855512410402298, -0.05829683318734169, -0.04185820370912552, 0.004119958728551865, -0.0596918947994709, 0.0987752377986908, 0.31812918186187744, -0.2210228443145752, 0.01686113327741623, 0.15455114841461182, -0.0021849062759429216, -0.022670898586511612, 0.13642756640911102, 0.116082102060318, 0.3008092939853668, -0.10510427504777908, -0.1581299751996994, 0.06677287071943283, 0.10044388473033905, -0.23664520680904388, -0.1321173906326294, 0.2293015718460083, -0.2617141008377075, -0.019475867971777916, 0.066126249730587, 0.017554305493831635, -0.05051586031913757, 0.12528549134731293, 0.30133453011512756, 0.16382713615894318, 0.16095800697803497, -0.1506175696849823, 0.03639066964387894, 0.04786227270960808, -0.227098748087883, -0.20091749727725983, 0.02924453094601631, 0.1679229587316513, -0.16131016612052917, -0.010945489630103111, 0.06183183565735817, 0.4046292304992676, -0.1921120136976242, -0.0011090869084000587, -0.11352778971195221, -0.0148758040741086, 0.009657513350248337, -0.05780690908432007, -0.153278186917305, 1.3949595869311901e-32, -0.15609584748744965, 0.08791869878768921, 0.05318267643451691, -0.06719137728214264, 0.12141658365726471, -0.21184735000133514, 0.046494729816913605, -0.03623589873313904, -0.12769193947315216, -0.14101412892341614, -0.02689780481159687, 0.12378492951393127, -0.0848342552781105, 0.14995138347148895, -0.003111144294962287, -0.2464427649974823, 0.04281548038125038, 0.16981439292430878, 0.058080196380615234, -0.19391100108623505, -0.05826728418469429, -0.2192094922065735, 0.09162545949220657, 0.09872451424598694, 0.06580300629138947, 0.11547267436981201, 0.048159126192331314, -0.08407468348741531, 0.10938018560409546, 0.13846451044082642, 0.06920744478702545, 0.11984122544527054, -0.21800588071346283, 0.013134005479514599, 0.026027975603938103, -0.09631849080324173, -0.11868872493505478, -0.14287486672401428, 0.02034641243517399, 0.12580113112926483, -0.17403344810009003, 0.09457991272211075, 0.18802286684513092, -0.11318432539701462, -0.06975352019071579, -0.014481666497886181, -0.019225740805268288, 0.10662665218114853, 0.031938083469867706, 0.09772735834121704, -0.006030629388988018, -0.05872234329581261, -0.10634735971689224, 0.11640685051679611, -0.22804902493953705, 0.056705743074417114, 0.03319886699318886, -0.07778137177228928, 0.031054366379976273, 0.06955055892467499, 0.18230880796909332, -0.03015260025858879, 0.04089079052209854, -0.21805037558078766, 0.0472182035446167, 0.02772909216582775, 0.06571110337972641, -0.0016396569553762674, 0.03887393698096275, 0.0221828892827034, 0.09321489930152893, 0.05303052440285683, 0.3081430196762085, -0.12245407700538635, 0.12965421378612518, -0.059901654720306396, 0.11868618428707123, -0.007049675565212965, -0.16332852840423584, -0.08155664801597595, 0.04047763720154762, 0.0339544415473938, 0.1162218227982521, -0.2160664051771164, 0.03857823833823204, 0.002785689663141966, 0.13018764555454254, -0.21513785421848297, -0.16078674793243408, 0.28269731998443604, -0.17756864428520203, 0.175754576921463, 0.0306343212723732, 0.09376776963472366, 0.030249793082475662, -7.031063706442029e-33, -0.12769515812397003, 0.08848634362220764, 0.1140436977148056, 0.1665625423192978, 0.07640822976827621, -0.11844618618488312, -0.26618698239326477, 0.21149277687072754, 0.00907536968588829, -0.017154715955257416, 0.048935022205114365, -0.1723184883594513, 0.036051779985427856, 0.021038733422756195, -0.03669581934809685, 0.007738610729575157, -0.13926127552986145, -0.15556004643440247, -0.06339786946773529, -0.007018009200692177, -0.06047108769416809, 0.2566276490688324, -0.0315098762512207, -0.07636073976755142, -0.07298059016466141, 0.05140408128499985, -0.1817389726638794, 0.15873460471630096, -0.0033899748232215643, -0.11268527060747147, -0.24517594277858734, 0.10937421023845673, -0.11992315948009491, -0.049605824053287506, -0.06488475203514099, 0.12730945646762848, 0.009784494526684284, -0.03763972222805023, -0.018859168514609337, 0.26585182547569275, 0.1981237679719925, 0.062265362590551376, -0.016393957659602165, -0.2287459522485733, -0.01886795274913311, -0.08469843119382858, -0.19048543274402618, 0.2896588146686554, 0.1059151142835617, -0.05465023219585419, -0.0303263608366251, 0.12739141285419464, -0.103293277323246, -0.17198047041893005, -0.01913856528699398, 0.10856449604034424, 0.03736022487282753, -0.05988842621445656, 0.06773842871189117, 0.06707774847745895, -0.4424854516983032, -0.05757639929652214, 0.16768194735050201, 0.050770353525877, 0.14949364960193634, -0.10105668008327484, -0.04249812290072441, 0.22146858274936676, -0.047572169452905655, -0.061564214527606964, -0.04652096703648567, -0.01352648064494133, 0.0022947846446186304, 0.04539724066853523, -0.20686738193035126, -0.05988554656505585, 0.02034316398203373, 0.048963513225317, -0.018092958256602287, 0.028745276853442192, 0.2312396913766861, -0.10693146288394928, 0.03167315945029259, 0.17164131999015808, 0.13220493495464325, 0.3253766596317291, 0.13105064630508423, -0.24969105422496796, 0.12753413617610931, 0.012011486105620861, -0.15298976004123688, 0.21671029925346375, 0.2024269551038742, 0.06926827877759933, 0.003144744783639908, -9.798943523264825e-08, -0.11493782699108124, 0.06536898016929626, 0.0625949576497078, 0.0502709299325943, 0.11929798126220703, 0.06670409440994263, -0.06731248646974564, 0.26740509271621704, -0.17646189033985138, 0.03614768013358116, 0.2562323212623596, -0.0724896565079689, -0.14605170488357544, 0.18467018008232117, -0.2625827193260193, 0.022825801745057106, -0.03656558692455292, 0.06757361441850662, -0.1343677043914795, 0.016260210424661636, 0.16999311745166779, 0.20989736914634705, 0.2386503964662552, 0.038770463317632675, -0.0709099993109703, -0.1443435102701187, 0.04397616907954216, -0.050431977957487106, 0.17746390402317047, -0.1655663102865219, -0.16935762763023376, 0.15386532247066498, 0.17261765897274017, -0.05953899398446083, 0.28388524055480957, 0.2164497822523117, -0.05414769798517227, -0.06281808018684387, -0.2858198583126068, 0.027773119509220123, 0.10149829089641571, 0.036941494792699814, -0.07438000291585922, -0.09044190496206284, 0.22396452724933624, -0.005036617163568735, 0.2315322756767273, -0.15880021452903748, 0.05126291513442993, -0.008879110217094421, -0.023771528154611588, -0.09743618965148926, -0.15082791447639465, 0.008495520800352097, 0.23556536436080933, 0.012570459395647049, -0.14015451073646545, -0.025517992675304413, 0.16620610654354095, 0.24393844604492188, -6.388672773027793e-05, -0.07139275968074799, -0.20291979610919952, 0.1599520593881607], metadata={'source': 'AAAMLP-569to.pdf', 'page': 296}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 297 also save their time. Good, open-source, re-usable code also looks good in your portfolio. J'),\n",
       " VectorParams(vector=[-0.28134584426879883, -0.024020319804549217, 0.27241531014442444, -0.009847373701632023, 0.1889738291501999, 0.07400375604629517, 0.04343894124031067, -0.22828693687915802, -0.3608250021934509, -0.02950771152973175, -0.16076838970184326, -0.06397253274917603, 0.2496921867132187, -0.37845999002456665, -0.22370167076587677, 0.3549741506576538, -0.07550530135631561, 0.046747900545597076, -0.12812909483909607, -0.15768583118915558, -0.23103845119476318, 0.2262948453426361, -0.14589181542396545, 0.24200108647346497, -0.15616728365421295, -0.12603583931922913, 0.5087276697158813, 0.20270510017871857, 0.02316376008093357, -0.05032860115170479, 0.01853083074092865, -0.025230659171938896, 0.019642271101474762, 0.07055541127920151, -0.0237856637686491, 0.1347184032201767, -0.25473058223724365, 0.059447456151247025, 0.15747472643852234, 0.13379181921482086, 0.21832887828350067, -0.02063264697790146, -0.061682865023612976, 0.07381182909011841, 0.32778286933898926, 0.2312164008617401, -0.19162698090076447, -0.18297803401947021, -0.12524211406707764, -0.07197253406047821, -0.5148813128471375, -0.0357382670044899, -0.27689242362976074, 0.008568068966269493, -0.31306448578834534, -0.4761483073234558, -0.015146028250455856, 0.000772331899497658, 0.04334234818816185, -0.1484287828207016, 0.12860716879367828, -0.47380492091178894, -0.18817739188671112, -0.1609783172607422, 0.12758198380470276, 0.06775237619876862, 0.14117680490016937, 0.15598396956920624, -0.16614139080047607, 0.3562471568584442, 0.11036999523639679, 0.45262086391448975, -0.32591456174850464, 0.47399431467056274, 0.10848361253738403, -0.15151581168174744, 0.20325198769569397, 0.10373659431934357, 0.23525747656822205, -0.06536883115768433, -0.1288970559835434, -0.32542750239372253, 0.13788077235221863, 0.15658961236476898, 0.221744567155838, -0.28553032875061035, -0.3717171549797058, -0.04817608743906021, 0.1303883045911789, -0.25087079405784607, 0.013572115451097488, -0.20695316791534424, 0.11871757358312607, -0.2210596799850464, -0.08474332094192505, 0.20656698942184448, 0.1406891942024231, -0.17856299877166748, 0.13515402376651764, 0.49353671073913574, -0.3134830594062805, 0.31973573565483093, 0.2490701675415039, 0.010632985271513462, 0.005793455522507429, 0.11035266518592834, 0.021672392264008522, -0.03980182483792305, 0.2919042706489563, -0.6252062916755676, 0.13346491754055023, -0.191739022731781, -0.019952937960624695, 0.07722115516662598, 0.011460176669061184, -0.21544857323169708, -0.011470499448478222, -0.08053641021251678, -0.13580508530139923, 0.33164098858833313, -0.18210963904857635, -0.07400428503751755, -0.06882888823747635, 0.27648410201072693, -0.11442101746797562, -0.025029893964529037, -0.23493275046348572, 8.972288301701401e-33, -0.16208995878696442, -0.07935454696416855, 0.10695666074752808, -0.3549082577228546, 0.1508294641971588, -0.21085859835147858, -0.04984278231859207, -0.2161453664302826, 0.07893715053796768, 0.042522408068180084, -0.05903366208076477, 0.030366627499461174, 0.07228488475084305, 0.06804468482732773, 0.12972724437713623, -0.09896276146173477, 0.2372569739818573, 0.01625834032893181, -0.010171713307499886, -0.44827547669410706, 0.3302813470363617, -0.18925237655639648, 0.05921608582139015, -0.10306486487388611, -0.20397073030471802, 0.001792359515093267, 0.21818117797374725, -0.17403917014598846, 0.060622334480285645, 0.16441476345062256, -0.12267125397920609, 0.11362972110509872, -0.18140023946762085, 0.15678255259990692, 0.09928504377603531, -0.18928539752960205, 0.09995122998952866, 0.10192517191171646, -0.01561351865530014, -0.13158635795116425, -0.20428624749183655, 0.14710667729377747, 0.3424789309501648, -0.3228374421596527, -0.14128093421459198, 0.22312986850738525, 0.09966979175806046, 0.04753277823328972, 0.07465924322605133, 0.09532401710748672, -0.22425641119480133, -0.20482602715492249, -0.2813074588775635, -0.07792413979768753, 0.07393510639667511, 0.12708505988121033, -0.16878220438957214, -0.015863727778196335, 0.0984296202659607, 0.08208969980478287, 0.35451292991638184, -0.14552487432956696, 0.12211742997169495, 0.05397413298487663, -0.10070165991783142, 0.04645729809999466, 0.15457136929035187, -0.15717069804668427, 0.31580087542533875, -0.03694797679781914, 0.12359177321195602, 0.024126753211021423, 0.13639627397060394, -0.37809503078460693, 0.15378472208976746, 0.010973477736115456, 0.2263668179512024, -0.024688012897968292, -0.011708129197359085, -0.01701771467924118, -0.19853109121322632, 0.23624706268310547, -0.05651712417602539, -0.4541574716567993, -0.1105770692229271, -0.10909434407949448, 0.013094269670546055, -0.3412242829799652, -0.2198481559753418, 0.2526163160800934, -0.44434255361557007, 0.1973225623369217, 0.011945536360144615, 0.010095748119056225, -0.05928561091423035, -1.0995015063091067e-32, -0.34365248680114746, 0.09790303558111191, -0.09459627419710159, 0.19470779597759247, 0.012293106876313686, 0.02447374165058136, -0.24195308983325958, 0.20053642988204956, 0.04019414260983467, -0.01713806390762329, 0.010456089861690998, 0.045744068920612335, 0.1848922073841095, 0.0015532750403508544, -0.2352861911058426, 0.29504144191741943, 0.08738988637924194, 0.24769434332847595, 0.006561872083693743, 0.10454697161912918, -0.08325231075286865, 0.35599979758262634, -0.1214381530880928, 0.1430336833000183, 0.10857381671667099, 0.13098862767219543, -0.13390545547008514, 0.3743058145046234, -0.04233621805906296, 0.18715235590934753, -0.25277528166770935, -0.2040964961051941, -0.35822629928588867, 0.02801816165447235, -0.1954064965248108, -0.049202706664800644, 0.1430284082889557, 0.1242026761174202, -0.09342457354068756, 0.38148775696754456, 0.2647712230682373, 0.02076459489762783, -0.5794103145599365, -0.07841262966394424, 0.19326013326644897, -0.21136635541915894, -0.2323949933052063, -0.03382116183638573, 0.08579692989587784, -0.1714809387922287, 0.14480283856391907, -0.02961781807243824, 0.08443429321050644, -0.055825162678956985, -0.2295362800359726, 0.4401324391365051, 0.007303233258426189, -0.017830049619078636, 0.1136222630739212, 0.1427643746137619, -0.38178524374961853, -0.06436159461736679, -0.0720091462135315, 0.14302515983581543, 0.12168347090482712, -0.09883670508861542, 0.10957171767950058, 0.24217656254768372, 0.11451249569654465, -0.01219947263598442, -0.24989484250545502, -0.08156079053878784, -0.19489586353302002, 0.06386449187994003, -0.12444915622472763, 0.14907345175743103, -0.06845888495445251, -0.19153818488121033, -0.15851637721061707, -0.13007839024066925, 0.060759514570236206, 0.01808706670999527, 0.20532123744487762, 0.3141787052154541, 0.24861541390419006, 0.03229793906211853, 0.5262649059295654, -0.1712518036365509, 0.16158489882946014, -0.3146774470806122, 0.018921658396720886, 0.12926745414733887, 0.11657243221998215, 0.24878092110157013, -0.11284804344177246, -9.734739592204278e-08, -0.2103605419397354, -0.06246719881892204, 0.00363619695417583, -0.04064298793673515, 0.6743962168693542, 0.07204347848892212, -0.2783890664577484, 0.33241692185401917, -0.44524750113487244, 0.1537499874830246, 0.17184264957904816, 0.03565142676234245, -0.0779973566532135, 0.2487296611070633, -0.29577332735061646, 0.1803804636001587, -0.19093728065490723, 0.19099241495132446, -0.24589373171329498, -0.013482324779033661, 0.4705619215965271, 0.18610435724258423, 0.2659352719783783, -0.17545506358146667, 0.0769224762916565, -0.22278238832950592, -0.16783122718334198, -0.04859524592757225, 0.17633338272571564, 0.3589599132537842, -0.36262568831443787, 0.12956388294696808, 0.09369068592786789, -0.01488787867128849, 0.18135231733322144, 0.10989397764205933, 0.052143871784210205, -0.06179521605372429, -0.4479762613773346, -0.0919986292719841, -0.09465932101011276, 0.12275476008653641, -0.2295161336660385, -0.02010164223611355, 0.27433913946151733, -0.10260073840618134, 0.21300473809242249, -0.17524230480194092, -0.008019763045012951, 0.2178467959165573, 0.014457134529948235, -0.058356981724500656, 0.1335342526435852, 0.1861722320318222, 0.37793436646461487, -0.14794093370437622, -0.027697045356035233, -0.17329999804496765, -0.1085091233253479, -0.004525487311184406, 0.39136970043182373, 0.19461287558078766, -0.1880837380886078, 0.0601225271821022], metadata={'source': 'AAAMLP-569to.pdf', 'page': 297}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 298 Notes'),\n",
       " VectorParams(vector=[-0.284787654876709, 0.004322150722146034, 0.2753988206386566, 0.010269123129546642, 0.24836044013500214, 0.05679328739643097, 0.02518174983561039, -0.22282050549983978, -0.38943204283714294, -0.02643454633653164, -0.1781013011932373, -0.08414766937494278, 0.24845921993255615, -0.3754456639289856, -0.21410073339939117, 0.3541349172592163, -0.05048399418592453, 0.07410241663455963, -0.10769455134868622, -0.18686892092227936, -0.284787654876709, 0.19910629093647003, -0.12018504738807678, 0.23351307213306427, -0.14637619256973267, -0.14588995277881622, 0.5014742016792297, 0.19147998094558716, -0.009346120990812778, -0.06534877419471741, 0.05813172459602356, -0.015598569996654987, -0.03236659616231918, 0.06685788184404373, -0.05542469024658203, 0.17390789091587067, -0.24034276604652405, 0.10359063744544983, 0.18434996902942657, 0.09160304814577103, 0.26914897561073303, -0.04143131524324417, -0.09934452921152115, 0.0741112008690834, 0.3270726501941681, 0.2141534835100174, -0.17491868138313293, -0.1481614112854004, -0.12302953004837036, -0.04582462087273598, -0.5212761163711548, -0.06088462471961975, -0.30345937609672546, 0.02035597153007984, -0.35569697618484497, -0.4777553379535675, -0.0438031330704689, -0.00951414555311203, 0.06112094223499298, -0.11149407923221588, 0.12601804733276367, -0.4902454614639282, -0.18345169723033905, -0.11377010494470596, 0.1519845873117447, 0.09392887353897095, 0.13849294185638428, 0.1388329565525055, -0.15985625982284546, 0.3747945725917816, 0.15811578929424286, 0.4115948975086212, -0.33201712369918823, 0.40902572870254517, 0.15302318334579468, -0.13987703621387482, 0.19562235474586487, 0.10121550410985947, 0.190334290266037, -0.037436939775943756, -0.135010227560997, -0.2751533091068268, 0.13040761649608612, 0.1453264355659485, 0.22311675548553467, -0.28407254815101624, -0.3371233642101288, -0.0924801379442215, 0.11038503795862198, -0.27233657240867615, 0.03021288849413395, -0.2483491599559784, 0.09065379947423935, -0.19830380380153656, -0.03306427225470543, 0.15968237817287445, 0.14597921073436737, -0.20061369240283966, 0.09588459879159927, 0.47469425201416016, -0.3041042983531952, 0.2997361421585083, 0.2416951209306717, 0.05581136792898178, 0.041429828852415085, 0.09856908023357391, 0.04239647462964058, -0.0944492295384407, 0.25098299980163574, -0.5911727547645569, 0.12492164969444275, -0.20515742897987366, -0.05275497958064079, 0.07124684005975723, -0.028335705399513245, -0.22711648046970367, 0.013087986037135124, -0.05346046760678291, -0.10688939690589905, 0.3330687880516052, -0.16053731739521027, -0.0694594606757164, -0.05484221503138542, 0.2870514392852783, -0.07659873366355896, -0.0317169725894928, -0.22844254970550537, 9.146613379244377e-33, -0.16399706900119781, -0.06453309953212738, 0.10226629674434662, -0.3490076959133148, 0.1087682843208313, -0.23577414453029633, -0.008026786148548126, -0.18874520063400269, 0.05014276131987572, 0.06222410500049591, -0.023908831179142, 0.04279640316963196, 0.08947299420833588, 0.07258574664592743, 0.10205677896738052, -0.10526629537343979, 0.203250914812088, 0.019004564732313156, -0.011360466480255127, -0.4626530110836029, 0.31573939323425293, -0.1774049699306488, 0.05014359578490257, -0.11943653970956802, -0.1757797747850418, 0.006871286779642105, 0.23363131284713745, -0.14471380412578583, 0.10568106919527054, 0.17591719329357147, -0.09423189610242844, 0.1356547623872757, -0.13189680874347687, 0.19655653834342957, 0.11983732134103775, -0.16638772189617157, 0.11756999790668488, 0.1007910892367363, 0.002050951821729541, -0.12898457050323486, -0.20847973227500916, 0.10934041440486908, 0.2997174561023712, -0.381033331155777, -0.15201310813426971, 0.1699892282485962, 0.09253229945898056, 0.07722244411706924, 0.06675087660551071, 0.08209171146154404, -0.24155819416046143, -0.18652376532554626, -0.24750930070877075, -0.050694119185209274, 0.08446372300386429, 0.06760609894990921, -0.18847736716270447, -0.020394302904605865, 0.12544284760951996, 0.11379583179950714, 0.34744733572006226, -0.16235117614269257, 0.08370411396026611, 0.06655818223953247, -0.1819574385881424, 0.021702652797102928, 0.09472623467445374, -0.13772423565387726, 0.32933804392814636, 0.009266199544072151, 0.1151411384344101, 0.04287554696202278, 0.0964563861489296, -0.36036548018455505, 0.16745416820049286, 0.026840291917324066, 0.27931249141693115, -0.0010294757084921002, -0.010786375030875206, -0.02116975747048855, -0.18196050822734833, 0.2518842816352844, -0.07770087569952011, -0.3866419196128845, -0.12500637769699097, -0.15201406180858612, 0.025632286444306374, -0.29827815294265747, -0.2619786262512207, 0.20221570134162903, -0.35095569491386414, 0.20768064260482788, -0.013491006568074226, 0.03844345733523369, -0.08993694186210632, -1.0180961715259617e-32, -0.33469489216804504, 0.08825951814651489, -0.09477616846561432, 0.2324458658695221, 0.004777177236974239, 0.018570929765701294, -0.2098938524723053, 0.1919918656349182, 0.035415299236774445, 0.025935465469956398, -0.02519594132900238, 0.048530735075473785, 0.1461968868970871, -0.00837845541536808, -0.18774601817131042, 0.2583206593990326, 0.12924005091190338, 0.20749172568321228, -0.02059316076338291, 0.1485702395439148, -0.014154622331261635, 0.41270923614501953, -0.1520906239748001, 0.06478521972894669, 0.05444299429655075, 0.1710897535085678, -0.12926031649112701, 0.3848675787448883, -0.05589589849114418, 0.14504699409008026, -0.26620668172836304, -0.18976342678070068, -0.38305678963661194, 0.013320083729922771, -0.19131718575954437, -0.006639894563704729, 0.10746875405311584, 0.16749142110347748, -0.12580366432666779, 0.3813762664794922, 0.2762526571750641, 0.036884915083646774, -0.6043792963027954, -0.06757593154907227, 0.24560025334358215, -0.25109368562698364, -0.21591784060001373, -0.03358812630176544, 0.10554486513137817, -0.17015992105007172, 0.10813857614994049, -0.004472704138606787, 0.09436660259962082, -0.07574079185724258, -0.23898468911647797, 0.4321810007095337, 0.06038486957550049, -0.02609330043196678, 0.1375335305929184, 0.14150913059711456, -0.40262675285339355, -0.06525103002786636, -0.028639281168580055, 0.13118238747119904, 0.11818190664052963, -0.09226137399673462, 0.08859346061944962, 0.22656260430812836, 0.16331301629543304, 0.036133140325546265, -0.25980544090270996, -0.06673576682806015, -0.23888583481311798, -0.021712463349103928, -0.15975473821163177, 0.17742733657360077, -0.06092872843146324, -0.1488994061946869, -0.1294911950826645, -0.08191761374473572, 0.10767355561256409, 0.007540902588516474, 0.20546044409275055, 0.3452220857143402, 0.27981290221214294, 0.0914318710565567, 0.5033426880836487, -0.1732422262430191, 0.1787973791360855, -0.3003791868686676, 0.030303556472063065, 0.09360957145690918, 0.10495494306087494, 0.2698467969894409, -0.12105472385883331, -9.698450043060802e-08, -0.24123799800872803, -0.04516303911805153, 0.008276405744254589, -0.0026327630039304495, 0.6709101796150208, 0.048006828874349594, -0.23443008959293365, 0.3197343349456787, -0.45876210927963257, 0.1760154813528061, 0.15981121361255646, 0.026838308200240135, -0.08726873248815536, 0.2513464689254761, -0.2614913284778595, 0.1996205896139145, -0.20844879746437073, 0.199563130736351, -0.261344850063324, -0.007564541418105364, 0.3985956609249115, 0.1840846985578537, 0.2713169753551483, -0.1860707700252533, 0.0665663406252861, -0.1939156949520111, -0.1423921287059784, -0.030185304582118988, 0.19597184658050537, 0.35311657190322876, -0.38563230633735657, 0.10622536391019821, 0.07312217354774475, -0.030413445085287094, 0.1873687356710434, 0.12271809577941895, 0.058873288333415985, -0.028699966147542, -0.4499766230583191, -0.10933758318424225, -0.12679217755794525, 0.1199134811758995, -0.21774743497371674, -0.004735483322292566, 0.26113563776016235, -0.06659751385450363, 0.18481352925300598, -0.17399466037750244, -0.05609823390841484, 0.21025368571281433, 0.05030066892504692, -0.06565195322036743, 0.07950014621019363, 0.16365079581737518, 0.3719150722026825, -0.1487053483724594, -0.047302983701229095, -0.21093779802322388, -0.13209907710552216, 0.026866843923926353, 0.3886832892894745, 0.2065393477678299, -0.23931804299354553, 0.08513520658016205], metadata={'source': 'AAAMLP-569to.pdf', 'page': 298}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 299 Notes'),\n",
       " VectorParams(vector=[-0.34882545471191406, -0.02346143312752247, 0.13064312934875488, -0.08486051112413406, 0.09907718747854233, 0.0996711403131485, -0.0023351500276476145, -0.2269466370344162, -0.3610219657421112, -0.03024262562394142, -0.14005045592784882, -0.05011984705924988, 0.2521573603153229, -0.4017322361469269, -0.15414875745773315, 0.39126071333885193, -0.03551995009183884, 0.08556942641735077, -0.10640281438827515, -0.34930533170700073, -0.25524529814720154, 0.19731231033802032, -0.062261056154966354, 0.17155294120311737, -0.1398492008447647, -0.0859396904706955, 0.48732390999794006, 0.1784982979297638, 0.007883697748184204, -0.01481056958436966, 0.026653584092855453, -0.016352593898773193, 9.411259816261008e-05, -0.020157447084784508, -0.0821952074766159, 0.2753382623195648, -0.355045884847641, 0.10926364362239838, 0.23089838027954102, 0.11750668287277222, 0.2797073721885681, 0.016046255826950073, -0.05725355073809624, 0.03591388836503029, 0.3789975941181183, 0.1855531930923462, -0.2661781311035156, -0.1416863352060318, -0.07821100950241089, -0.01082564052194357, -0.5190945267677307, -0.02696031890809536, -0.29739150404930115, 0.05190667882561684, -0.28795579075813293, -0.5215681791305542, 0.022425977513194084, 0.028316067531704903, 0.06865259259939194, -0.18146273493766785, 0.06082966923713684, -0.5239341855049133, -0.13173933327198029, -0.16207797825336456, 0.18819859623908997, 0.06476078182458878, 0.10051842778921127, 0.16450831294059753, -0.22127605974674225, 0.3905430734157562, 0.1785639524459839, 0.4737609028816223, -0.30346623063087463, 0.46365663409233093, 0.11836490035057068, -0.20842485129833221, 0.19347316026687622, 0.00970490649342537, 0.13272680342197418, -0.038076695054769516, -0.12085215747356415, -0.3623664677143097, 0.24078208208084106, 0.13636218011379242, 0.09447647631168365, -0.287515252828598, -0.32024911046028137, -0.08178777247667313, 0.016122858971357346, -0.2525028884410858, 0.06082233786582947, -0.21880289912223816, 0.11317119747400284, -0.23505820333957672, -0.0998065248131752, 0.2882969081401825, 0.1242125928401947, -0.19906392693519592, 0.05515182763338089, 0.5199431777000427, -0.2639119029045105, 0.2885572612285614, 0.272962361574173, -0.00786172691732645, 0.008324292488396168, 0.043355632573366165, 0.07807453721761703, -0.015183028765022755, 0.30113306641578674, -0.6470037698745728, 0.10075321048498154, -0.15720872581005096, 0.03344155475497246, 0.0989590436220169, 0.017645107582211494, -0.2269468754529953, -0.03610698878765106, -0.08099637180566788, -0.05769459903240204, 0.37046632170677185, -0.1127597913146019, 0.00866091437637806, -0.044250085949897766, 0.3088935911655426, -0.06251148879528046, -0.042541973292827606, -0.3064785897731781, 1.0682376912126526e-32, -0.12985101342201233, -0.040145013481378555, 0.11385639011859894, -0.3456908166408539, 0.18079356849193573, -0.3392007052898407, -0.06813641637563705, -0.19228433072566986, 0.04695776477456093, 0.01656542718410492, 0.03790632262825966, -0.02611289545893669, 0.09672591835260391, 0.04836905747652054, 0.051027704030275345, -0.0694909542798996, 0.16874705255031586, 0.045395925641059875, -0.027788007631897926, -0.35185232758522034, 0.2978128492832184, -0.17987005412578583, 0.12476873397827148, -0.10528454184532166, -0.1724664270877838, 0.10768507421016693, 0.2922922372817993, -0.1673920899629593, 0.10507017374038696, 0.15015175938606262, -0.15667662024497986, 0.12317050248384476, -0.21929220855236053, 0.09588393568992615, 0.04528919607400894, -0.16719664633274078, 0.08924715220928192, 0.02388742007315159, -0.013634653761982918, -0.16747289896011353, -0.23917274177074432, 0.07641752064228058, 0.31385698914527893, -0.31523704528808594, -0.21459241211414337, 0.3621319830417633, 0.07149337232112885, 0.06778943538665771, 0.12177502363920212, 0.14103193581104279, -0.16658562421798706, -0.18142181634902954, -0.21851257979869843, 0.006238593254238367, 0.06509406864643097, 0.008745722472667694, -0.16136713325977325, -0.025822313502430916, 0.19046558439731598, 0.09225684404373169, 0.3996264636516571, -0.16521666944026947, 0.1103331446647644, 0.10351461172103882, -0.1570597141981125, 0.08135472983121872, 0.08223429322242737, -0.13547135889530182, 0.3879019021987915, 0.0028933859430253506, 0.09859249740839005, -0.02262089028954506, 0.09680051356554031, -0.338899701833725, 0.12204091250896454, -0.028183940798044205, 0.2406090646982193, -0.042503368109464645, -0.0018858439289033413, -0.07666406780481339, -0.20765165984630585, 0.2781476080417633, -0.01765691675245762, -0.39061152935028076, -0.16170743107795715, -0.09073120355606079, 0.03320716693997383, -0.3704105317592621, -0.21076682209968567, 0.20856064558029175, -0.4385669231414795, 0.22204434871673584, -0.007878055796027184, -0.025392979383468628, -0.12359581142663956, -1.1224092463443438e-32, -0.3475990891456604, 0.19191300868988037, -0.09801081568002701, 0.2382107526063919, 0.07226630300283432, 0.0650855079293251, -0.17019957304000854, 0.2599926292896271, 0.10836738348007202, 0.04642443731427193, 0.0656019002199173, 0.050128672271966934, 0.10937800258398056, 0.01228562742471695, -0.23906956613063812, 0.17903216183185577, 0.11376681923866272, 0.25972968339920044, 0.06277385354042053, 0.08995737880468369, -0.06118430569767952, 0.3361484408378601, -0.1667342483997345, 0.1153181716799736, 0.009737077169120312, 0.1903003752231598, -0.19317400455474854, 0.3043624758720398, -0.08081656694412231, 0.15094999969005585, -0.30009713768959045, -0.27227285504341125, -0.3695141077041626, 0.06108984351158142, -0.242750346660614, -0.004941218066960573, 0.1355414092540741, 0.04909983277320862, -0.18278713524341583, 0.4290255606174469, 0.38091740012168884, 0.04925864562392235, -0.6565579175949097, -0.046685878187417984, 0.14426063001155853, -0.20021523535251617, -0.26883649826049805, 0.08769011497497559, 0.08998597413301468, -0.14311331510543823, 0.18397673964500427, -0.013991161249577999, 0.12065641582012177, -0.09567619860172272, -0.2637350261211395, 0.3815069794654846, 0.02999235689640045, -0.06717205792665482, 0.06727590411901474, 0.17935071885585785, -0.48684003949165344, -0.06694844365119934, 0.025605063885450363, 0.14594107866287231, 0.1043098047375679, -0.07026782631874084, 0.14817285537719727, 0.2527078092098236, 0.10138824582099915, 0.03643359616398811, -0.23428770899772644, -0.010062004439532757, -0.20450977981090546, 0.006419708952307701, -0.10898055881261826, 0.21771541237831116, -0.19989171624183655, -0.13782472908496857, -0.13541364669799805, -0.14964647591114044, 0.09017801284790039, -0.026761099696159363, 0.22039997577667236, 0.3566403090953827, 0.22977936267852783, 0.20569653809070587, 0.43225327134132385, -0.18922322988510132, 0.19117659330368042, -0.28668004274368286, 0.04837155342102051, 0.12516777217388153, 0.22313687205314636, 0.29729506373405457, -0.15261662006378174, -9.68465982964517e-08, -0.25697922706604004, 0.025356553494930267, -0.07424596697092056, -0.035043757408857346, 0.6462963223457336, 0.09141740947961807, -0.23387333750724792, 0.2175106257200241, -0.4635756015777588, 0.22787430882453918, 0.1922076940536499, -0.02228105440735817, -0.05074349045753479, 0.20660020411014557, -0.27801570296287537, 0.17536383867263794, -0.019807783886790276, 0.20327039062976837, -0.2581028938293457, -0.08338236808776855, 0.4751376211643219, 0.26507484912872314, 0.2926853895187378, -0.1776001900434494, 0.1298052817583084, -0.17205817997455597, -0.205917626619339, -0.0377858504652977, 0.18334755301475525, 0.4109472930431366, -0.36468270421028137, 0.11759716272354126, 0.06656514108181, -0.01278720237314701, 0.25700005888938904, 0.1277182251214981, 0.031020458787679672, -0.033516254276037216, -0.3962174355983734, -0.07377731055021286, -0.18891902267932892, 0.13848109543323517, -0.2524014711380005, -0.004112107213586569, 0.2829567492008209, -0.13868175446987152, 0.13920263946056366, -0.27352583408355713, 0.01785368286073208, 0.18797272443771362, -0.05834956467151642, -0.05926038697361946, 0.10068219155073166, 0.12587185204029083, 0.3766375184059143, -0.09605167806148529, -0.07646065205335617, -0.12656518816947937, -0.18570275604724884, -0.029173387214541435, 0.41677629947662354, 0.1068800613284111, -0.19252517819404602, 0.07794502377510071], metadata={'source': 'AAAMLP-569to.pdf', 'page': 299}, content='Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 300 Notes')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors added successfully.\n"
     ]
    }
   ],
   "source": [
    "vector_store.add(vectors_params=vector_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is machine learning?\"\n",
    "embedding  = tokenizer.create_embedding(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search from all\n",
    "\n",
    "docs = vector_store.search_from_all(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'metadata': 'Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 1            Approaching (Almost) Any Machine Learning Problem',\n",
       "  'content': '{\"source\": \"AAAMLP-569to.pdf\", \"page\": 0}'},\n",
       " {'metadata': 'Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 7 Supervised vs unsupervised learning  When dealing with machine learning problems, there are generally two types of data (and machine learning models): • Supervised data: always has one or multiple targets associated with it. • Unsupervised data: does not have any target variable.  A supervised problem is considerably easier to tackle than an unsupervised one. A problem in which we are required to predict a value is known as a supervised problem. For example, if the problem is to predict house prices given historical house prices, with features like presence of a hospital, school or supermarket, distance to nearest public transport, etc. is a supervised problem. Similarly, when we are provided with images of cats and dogs, and we know beforehand which ones are cats and which ones are dogs, and if the task is to create a model which predicts whether a provided image is of a cat or a dog, the problem is considered to be supervised.  \\n Figure 1: A supervised dataset.  As we see in figure 1, every row of the data is associated with a target or label. The columns are different features and rows represent different data points which are usually called samples. The example shows ten samples with ten features and a target variable which can be either a number or a category. If the target is categorical, the problem becomes a classification problem. And if the target is a real',\n",
       "  'content': '{\"source\": \"AAAMLP-569to.pdf\", \"page\": 6}'},\n",
       " {'metadata': 'Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 298 Notes',\n",
       "  'content': '{\"source\": \"AAAMLP-569to.pdf\", \"page\": 297}'},\n",
       " {'metadata': 'Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 299 Notes',\n",
       "  'content': '{\"source\": \"AAAMLP-569to.pdf\", \"page\": 298}'},\n",
       " {'metadata': 'Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 300 Notes',\n",
       "  'content': '{\"source\": \"AAAMLP-569to.pdf\", \"page\": 299}'},\n",
       " {'metadata': 'Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 14 Cross-validation  We did not build any models in the previous chapter. The reason for that is simple. Before creating any kind of machine learning model, we must know what cross-validation is and how to choose the best cross-validation depending on your datasets.  So, what is cross-validation, and why should we care about it?  We can find multiple definitions as to what cross-validation is. Mine is a one-liner: cross-validation is a step in the process of building a machine learning model which helps us ensure that our models fit the data accurately and also ensures that we do not overfit. But this leads to another term: overfitting.   To explain overfitting, I think it’s best if we look at a dataset. There is a red wine-quality dataset2 which is quite famous. This dataset has 11 different attributes that decide the quality of red wine.   These attributes include: • fixed acidity • volatile acidity • citric acid • residual sugar • chlorides • free sulfur dioxide • total sulfur dioxide • density • pH • sulphates • alcohol  Based on these different attributes, we are required to predict the quality of red wine which is a value between 0 and 10.   2 P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis; Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.',\n",
       "  'content': '{\"source\": \"AAAMLP-569to.pdf\", \"page\": 13}'},\n",
       " {'metadata': 'Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 166 training data and validate the model on validation data for proper selection of features without overfitting the model.',\n",
       "  'content': '{\"source\": \"AAAMLP-569to.pdf\", \"page\": 165}'},\n",
       " {'metadata': 'Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 22 • hold-out based validation • leave-one-out cross-validation • group k-fold cross-validation  Cross-validation is dividing training data into a few parts. We train the model on some of these parts and test on the remaining parts. Take a look at figure 4.  \\n Figure 4: Splitting a dataset into training and validation sets  Figure 4 & 5 say that when you get a dataset to build machine learning models, you separate them into two different sets: training and validation. Many people also split it into a third set and call it a test set. We will, however, be using only two sets. As you can see, we divide the samples and the targets associated with them. We can divide the data into k different sets which are exclusive of each other. This is known as k-fold cross-validation.   Figure 5: K-fold cross-validation',\n",
       "  'content': '{\"source\": \"AAAMLP-569to.pdf\", \"page\": 21}'},\n",
       " {'metadata': 'Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 9  \\n Figure 2: An unsupervised dataset.  Most of the time, when people start with data science or machine learning, they begin with very well-known datasets, for example, Titanic dataset, or Iris dataset which are supervised problems. In the Titanic dataset, you have to predict the survival of people aboard Titanic based on factors like their ticket class, gender, age, etc. Similarly, in the iris dataset, you have to predict the species of flower based on factors like sepal width, petal length, sepal length and petal width.   Unsupervised datasets may include datasets for customer segmentation. For example, you have data for the customers visiting your e-commerce website or the data for customers visiting a store or a mall, and you would like to segment them or cluster them in different categories. Another example of unsupervised datasets may include things like credit card fraud detection or just clustering several images.  Most of the time, it’s also possible to convert a supervised dataset to unsupervised to see how they look like when plotted.  For example, let’s take a look at the dataset in figure 3. Figure 3 shows MNIST dataset which is a very popular dataset of handwritten digits, and it is a supervised problem in which you are given the images of the numbers and the correct label associated with them. You have to build a model that can identify which digit is it when provided only with the image.   This dataset can easily be converted to an unsupervised setting for basic visualization.',\n",
       "  'content': '{\"source\": \"AAAMLP-569to.pdf\", \"page\": 8}'},\n",
       " {'metadata': 'Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 183 We get an accuracy which is a little better than before and a set of parameters that we can use. Please note that criterion is 1 in the final result. This implies that choice 1 was selected, i.e., entropy.  The ways of tuning hyperparameters described above are the most common, and these will work with almost all models: linear regression, logistic regression, tree-based methods, gradient boosting models such as xgboost, lightgbm, and even neural networks!  Although, these methods exist, to learn, one must start with tuning the hyper-parameters manually, i.e., by hand. Hand tuning will help you learn the basics, for example, in gradient boosting, when you increase the depth, you should reduce the learning rate. It won’t be possible to learn this if you use automated tools. Refer to the following table to know what to tune. RS* implies random search should be better.  Once you get better with hand-tuning the parameters, you might not even need any automated hyper-parameter tuning. When you create large models or introduce a lot of features, you also make it susceptible to overfitting the training data. To avoid overfitting, you need to introduce noise in training data features or penalize the cost function. This penalization is called regularization and helps with generalizing the model. In linear models, the most common types of regularizations are L1 and L2. L1 is also known as Lasso regression and L2 as Ridge regression. When it comes to neural networks, we use dropouts, the addition of augmentations, noise, etc. to regularize our models. Using hyper-parameter optimization, you can also find the correct penalty to use.',\n",
       "  'content': '{\"source\": \"AAAMLP-569to.pdf\", \"page\": 182}'},\n",
       " {'metadata': 'Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 8 number, the problem is defined as a regression problem. Thus, supervised problems can be divided into two sub-classes:  • Classification: predicting a category, e.g. dog or cat. • Regression: predicting a value, e.g. house prices.  It must be noted that sometimes we might use regression in a classification setting depending on the metric used for evaluation. But we will come to that later.  Another type of machine learning problem is the unsupervised type. Unsupervised datasets do not have a target associated with them and in general, are more challenging to deal with when compared to supervised problems.  Let’s say you work in a financial firm which deals with credit card transactions. There is a lot of data that comes in every second. The only problem is that it is difficult to find humans who will mark each and every transaction either as a valid or genuine transaction or a fraud. When we do not have any information about a transaction being fraud or genuine, the problem becomes an unsupervised problem. To tackle these kinds of problems we have to think about how many clusters can data be divided into. Clustering is one of the approaches that you can use for problems like this, but it must be noted that there are several other approaches available that can be applied to unsupervised problems. For a fraud detection problem, we can say that data can be divided into two classes (fraud or genuine).  When we know the number of clusters, we can use a clustering algorithm for unsupervised problems. In figure 2, the data is assumed to have two classes, dark colour represents fraud, and light colour represents genuine transactions. These classes, however, are not known to us before the clustering approach. After a clustering algorithm is applied, we should be able to distinguish between the two assumed targets. To make sense of unsupervised problems, we can also use numerous decomposition techniques such as Principal Component Analysis (PCA), t-distributed Stochastic Neighbour Embedding (t-SNE) etc.   Supervised problems are easier to tackle in the sense that they can be evaluated easily. We will read more about evaluation techniques in the following chapters. However, it is challenging to assess the results of unsupervised algorithms and a lot of human interference or heuristics are required. In this book, we will majorly be focusing on supervised data and models, but it does not mean that we will be ignoring the unsupervised data problems.',\n",
       "  'content': '{\"source\": \"AAAMLP-569to.pdf\", \"page\": 7}'},\n",
       " {'metadata': 'Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 297 also save their time. Good, open-source, re-usable code also looks good in your portfolio. J',\n",
       "  'content': '{\"source\": \"AAAMLP-569to.pdf\", \"page\": 296}'},\n",
       " {'metadata': 'Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 30 Evaluation metrics  When it comes to machine learning problems, you will encounter a lot of different types of metrics in the real world. Sometimes, people even end up creating metrics that suit the business problem. It’s out of the scope of this book to introduce and explain each and every type of metric. Instead, we will see some of the most common metrics that you can use when starting with your very first few projects.  At the start of the book, we introduced supervised and unsupervised learning. Although there are some kinds of metrics that you can use for unsupervised learning, we will only focus on supervised. The reason for this is because supervised problems are in abundance compared to un-supervised, and evaluation of unsupervised methods is quite subjective.  If we talk about classification problems, the most common metrics used are: - Accuracy - Precision (P) - Recall (R) - F1 score (F1) - Area under the ROC (Receiver Operating Characteristic) curve or simply AUC (AUC) - Log loss - Precision at k (P@k) - Average precision at k (AP@k) - Mean average precision at k (MAP@k)  When it comes to regression, the most commonly used evaluation metrics are: - Mean absolute error (MAE) - Mean squared error (MSE) - Root mean squared error (RMSE) - Root mean squared logarithmic error (RMSLE) - Mean percentage error (MPE) - Mean absolute percentage error (MAPE) - R2  Knowing about how the aforementioned metrics work is not the only thing we have to understand. We must also know when to use which metrics, and that depends on',\n",
       "  'content': '{\"source\": \"AAAMLP-569to.pdf\", \"page\": 29}'},\n",
       " {'metadata': 'Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 225 Approaching text classification/regression  Text problems are my favourite. In general, these problems are also known as Natural Language Processing (NLP) problems. NLP problems are also like images in the sense that, it’s quite different. You need to create pipelines you have never created before for tabular problems. You need to understand the business case to build a good model. By the way, that is true for anything in machine learning. Building models will take you to a certain level, but to improve and contribute to a business you are building the model for, you must understand how it impacts the business. Let’s not get too philosophical here.   There are many different types of NLP problems, and the most common type is the classification of strings. Many times, it is seen that people are doing well with tabular data or with images, but when it comes to text, they don’t even have a clue where to start from. Text data is no different than other types of datasets. For computers, everything is numbers.  Let’s say we start with a fundamental task of sentiment classification. We will try to classify sentiment from movie reviews. So, you have a text, and there is a sentiment associated with it. How will you approach this kind of problem? Apply a deep neural network right, or maybe muppets can come and save you? No, absolutely wrong. You start with the basics. Let’s see what this data looks like first.  We start with IMDB movie review dataset15 that consists of 25000 reviews for positive sentiment and 25000 reviews for negative sentiment.   The concepts that I will discuss here can be applied to almost any text classification dataset.  This dataset is quite easy to understand. One review maps to one target variable. Note that I wrote review instead of sentence. A review is a bunch of sentences. So, until now you must have seen classifying only a single sentence, but in this problem, we will be classifying multiple sentences. In simple words, it means that not only  15 Maas, Andrew L, Daly, Raymond E, Pham, Peter T, Huang, Dan, Ng, Andrew Y, and Potts, Christopher. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pp. 142–150. Association for Computational Linguistics, 2011.',\n",
       "  'content': '{\"source\": \"AAAMLP-569to.pdf\", \"page\": 224}'},\n",
       " {'metadata': \"Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 29 Cross-validation is the first and most essential step when it comes to building machine learning models. If you want to do feature engineering, split your data first. If you're going to build models, split your data first. If you have a good cross-validation scheme in which validation data is representative of training and real-world data, you will be able to build a good machine learning model which is highly generalizable.   The types of cross-validation presented in this chapter can be applied to almost any machine learning problem. Still, you must keep in mind that cross-validation also depends a lot on the data and you might need to adopt new forms of cross-validation depending on your problem and data.   For example, let’s say we have a problem in which we would like to build a model to detect skin cancer from skin images of patients. Our task is to build a binary classifier which takes an input image and predicts the probability for it being benign or malignant.   In these kinds of datasets, you might have multiple images for the same patient in the training dataset. So, to build a good cross-validation system here, you must have stratified k-folds, but you must also make sure that patients in training data do not appear in validation data. Fortunately, scikit-learn offers a type of cross-validation known as GroupKFold. Here the patients can be considered as groups. But unfortunately, there is no way to combine GroupKFold with StratifiedKFold in scikit-learn. So you need to do that yourself. I’ll leave it as an exercise for the reader.\",\n",
       "  'content': '{\"source\": \"AAAMLP-569to.pdf\", \"page\": 28}'},\n",
       " {'metadata': 'Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 20 This is called overfitting.   The model fits perfectly on the training set and performs poorly when it comes to the test set. This means that the model will learn the training data well but will not generalize on unseen samples. In the dataset above, one can build a model with very high max_depth which will have outstanding results on training data, but that kind of model is not useful as it will not provide a similar result on the real-world samples or live data. \\n Figure 2: Training and test accuracies for different values of max_depth.  One might argue that this approach isn’t overfitting as the accuracy of the test set more or less remains the same. Another definition of overfitting would be when the test loss increases as we keep improving training loss. This is very common when it comes to neural networks.   Whenever we train a neural network, we must monitor loss during the training time for both training and test set. If we have a very large network for a dataset which is quite small (i.e. very less number of samples), we will observe that the loss for both training and test set will decrease as we keep training. However, at some point, test loss will reach its minima, and after that, it will start increasing even though training loss decreases further. We must stop training where the validation loss reaches its minimum value.   This is the most common explanation of overfitting.',\n",
       "  'content': '{\"source\": \"AAAMLP-569to.pdf\", \"page\": 19}'},\n",
       " {'metadata': 'Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 3 Before you start, there are a few things that you must be aware of while going through this book.   This is not a traditional book.  The book expects you to have basic knowledge of machine learning and deep learning.   Important terms are bold.   Variable names and function/class names are italic.   ═════════════════════════════════════════════════════════════════════════ All the code is between these two lines ═════════════════════════════════════════════════════════════════════════  Most of the times, the output is provided right after the code blocks.  Figures are locally defined. For example, figure 1 is the first figure   Code is very important in this book and there is a lot of it. You must go through the code carefully and implement it on your own if you want to understand what’s going on.  Comments in Python begin with a hash (#). All the code in this book is explained line-by-line only using comments. Thus, these comments must not be ignored.  Bash commands start with $ or ❯.  If you find a pirated copy of this book (print or e-book or pdf), contact me directly with the details so that I can take necessary actions.       If you didn’t code, you didn’t learn.',\n",
       "  'content': '{\"source\": \"AAAMLP-569to.pdf\", \"page\": 2}'},\n",
       " {'metadata': 'Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 190 I won’t go into the history of deep learning and who invented what. Instead, let’s take a look at one of the most famous deep learning models AlexNet and see what’s happening there.   \\n Figure 3: AlexNet architecture9. Please note that the input size in this figure is not 224x224 but 227x227  Nowadays, you might say that it is a basic deep convolutional neural network, but it is the foundation of many new deep nets (deep neural networks). We see that the network in figure 3 is a convolutional neural network with five convolution layers, two dense layers and an output layer. We see that there is also max pooling. What is it? Let’s look at some terms which you will come across when doing deep learning. \\n Figure 4: An image of size 8x8 with a filter of size 3x3 and stride of 2.  Figure 4 introduces two new terms: filter and strides. Filters are nothing but two-dimensional matrices which are initialized by a given function. “He initialization”  9 A. Krizhevsky, I. Sutskever, and G. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, 2012',\n",
       "  'content': '{\"source\": \"AAAMLP-569to.pdf\", \"page\": 189}'},\n",
       " {'metadata': 'Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 2       It would not have been possible for me to write this book without the support of my family and friends. I would also like to thank the reviewers who selflessly devoted their time in reviewing this book (names in alphabetical order).   Aakash Nain Aditya Soni Andreas Müller Andrey Lukyanenko Ayon Roy Bojan Tunguz Gilberto Titericz Jr. Konrad Banachewicz Luca Massaron Nabajeet Barman Parul Pandey Ram Ramrakhya Sanyam Bhutani Sudalai Rajkumar Tanishq Abraham Walter Reade Yuval Reina   I hope I did not miss anyone.',\n",
       "  'content': '{\"source\": \"AAAMLP-569to.pdf\", \"page\": 1}'},\n",
       " {'metadata': \"Approaching (Almost) Any Machine Learning Problem – Abhishek Thakur \\n 60 plt.ylabel('Actual Labels', fontsize=20) plt.xlabel('Predicted Labels', fontsize=20) ═════════════════════════════════════════════════════════════════════════  So, until now, we have tackled metrics for binary and multi-class classification. Then comes another type of classification problem called multi-label classification. In multi-label classification, each sample can have one or more classes associated with it. One simple example of this type of problem would be a task in which you are asked to predict different objects in a given image.  \\n Figure 9: Different objects in an image4  Figure 9 shows an example image from a well-known dataset. Note that this dataset’s objective is something different but let’s not go there. Let’s assume that the aim is only to predict if an object is present in an image or not. For figure 9, we have a chair, flower-pot, window, but we don’t have other objects such as computer, bed, tv, etc. So, one image can have multiple targets associated with it. This type of problem is the multi-label classification problem.  The metrics for this type of classification problem are a bit different. Some suitable and most common metrics are:  - Precision at k (P@k) - Average precision at k (AP@k)  4 https://www.flickr.com/photos/krakluski/2950388100 License: CC BY 2.0\",\n",
       "  'content': '{\"source\": \"AAAMLP-569to.pdf\", \"page\": 59}'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
